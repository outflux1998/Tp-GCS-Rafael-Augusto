<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.feature_extraction.tests.test_text Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1feature__extraction.html">feature_extraction</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html">test_text</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.feature_extraction.tests.test_text Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:aca32d7b8cc237faa414f9584b5422b5e" id="r_aca32d7b8cc237faa414f9584b5422b5e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#aca32d7b8cc237faa414f9584b5422b5e">uppercase</a> (s)</td></tr>
<tr class="separator:aca32d7b8cc237faa414f9584b5422b5e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae739cc1cbc9cd66eae58a2610628af91" id="r_ae739cc1cbc9cd66eae58a2610628af91"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae739cc1cbc9cd66eae58a2610628af91">strip_eacute</a> (s)</td></tr>
<tr class="separator:ae739cc1cbc9cd66eae58a2610628af91"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a742ccc6ccc7c7d3c2144133cc066c67a" id="r_a742ccc6ccc7c7d3c2144133cc066c67a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a742ccc6ccc7c7d3c2144133cc066c67a">split_tokenize</a> (s)</td></tr>
<tr class="separator:a742ccc6ccc7c7d3c2144133cc066c67a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3805ad5190defbfe52b727ab4d575ed" id="r_ab3805ad5190defbfe52b727ab4d575ed"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ab3805ad5190defbfe52b727ab4d575ed">lazy_analyze</a> (s)</td></tr>
<tr class="separator:ab3805ad5190defbfe52b727ab4d575ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3fd054341f4779df1465e511f47c2852" id="r_a3fd054341f4779df1465e511f47c2852"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a3fd054341f4779df1465e511f47c2852">test_strip_accents</a> ()</td></tr>
<tr class="separator:a3fd054341f4779df1465e511f47c2852"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46c76f7c3965734fcc0df120389cc0ca" id="r_a46c76f7c3965734fcc0df120389cc0ca"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a46c76f7c3965734fcc0df120389cc0ca">test_to_ascii</a> ()</td></tr>
<tr class="separator:a46c76f7c3965734fcc0df120389cc0ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c6df3d618e5253703ad8ed524701d2a" id="r_a9c6df3d618e5253703ad8ed524701d2a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a9c6df3d618e5253703ad8ed524701d2a">test_word_analyzer_unigrams</a> (Vectorizer)</td></tr>
<tr class="separator:a9c6df3d618e5253703ad8ed524701d2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a10dc18d56e344919689dd597fa9ddbef" id="r_a10dc18d56e344919689dd597fa9ddbef"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a10dc18d56e344919689dd597fa9ddbef">test_word_analyzer_unigrams_and_bigrams</a> ()</td></tr>
<tr class="separator:a10dc18d56e344919689dd597fa9ddbef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae53cb7a6b4f30fb8eb4114cc103b8a26" id="r_ae53cb7a6b4f30fb8eb4114cc103b8a26"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae53cb7a6b4f30fb8eb4114cc103b8a26">test_unicode_decode_error</a> ()</td></tr>
<tr class="separator:ae53cb7a6b4f30fb8eb4114cc103b8a26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6c31e1f1fb00e290c44c1240422a225" id="r_ae6c31e1f1fb00e290c44c1240422a225"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae6c31e1f1fb00e290c44c1240422a225">test_char_ngram_analyzer</a> ()</td></tr>
<tr class="separator:ae6c31e1f1fb00e290c44c1240422a225"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5b0d1e6cb85e7e07961118235dad429" id="r_ac5b0d1e6cb85e7e07961118235dad429"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ac5b0d1e6cb85e7e07961118235dad429">test_char_wb_ngram_analyzer</a> ()</td></tr>
<tr class="separator:ac5b0d1e6cb85e7e07961118235dad429"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3eac0286bcfb73d6900fa5d66d4220d" id="r_ae3eac0286bcfb73d6900fa5d66d4220d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae3eac0286bcfb73d6900fa5d66d4220d">test_word_ngram_analyzer</a> ()</td></tr>
<tr class="separator:ae3eac0286bcfb73d6900fa5d66d4220d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeee1e7c399945a0a845e0cd94639b2f6" id="r_aeee1e7c399945a0a845e0cd94639b2f6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#aeee1e7c399945a0a845e0cd94639b2f6">test_countvectorizer_custom_vocabulary</a> ()</td></tr>
<tr class="separator:aeee1e7c399945a0a845e0cd94639b2f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ba8fe8339af7f027d316ab3521b008a" id="r_a9ba8fe8339af7f027d316ab3521b008a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a9ba8fe8339af7f027d316ab3521b008a">test_countvectorizer_custom_vocabulary_pipeline</a> ()</td></tr>
<tr class="separator:a9ba8fe8339af7f027d316ab3521b008a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33d6e34c6fbaeb7172e4f60ec0f371ba" id="r_a33d6e34c6fbaeb7172e4f60ec0f371ba"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a33d6e34c6fbaeb7172e4f60ec0f371ba">test_countvectorizer_custom_vocabulary_repeated_indices</a> ()</td></tr>
<tr class="separator:a33d6e34c6fbaeb7172e4f60ec0f371ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abca562d7d767d1aae2189089378af6a2" id="r_abca562d7d767d1aae2189089378af6a2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#abca562d7d767d1aae2189089378af6a2">test_countvectorizer_custom_vocabulary_gap_index</a> ()</td></tr>
<tr class="separator:abca562d7d767d1aae2189089378af6a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00b37b5db7fa3b3659a99dc54e2996ea" id="r_a00b37b5db7fa3b3659a99dc54e2996ea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a00b37b5db7fa3b3659a99dc54e2996ea">test_countvectorizer_stop_words</a> ()</td></tr>
<tr class="separator:a00b37b5db7fa3b3659a99dc54e2996ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2601d118113109075d4a8c2f9470445" id="r_ae2601d118113109075d4a8c2f9470445"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae2601d118113109075d4a8c2f9470445">test_countvectorizer_empty_vocabulary</a> ()</td></tr>
<tr class="separator:ae2601d118113109075d4a8c2f9470445"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c469ae8355251bdb6731e27d8e429e4" id="r_a3c469ae8355251bdb6731e27d8e429e4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a3c469ae8355251bdb6731e27d8e429e4">test_fit_countvectorizer_twice</a> ()</td></tr>
<tr class="separator:a3c469ae8355251bdb6731e27d8e429e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac54253d945d359f90e71b1e619433cfc" id="r_ac54253d945d359f90e71b1e619433cfc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ac54253d945d359f90e71b1e619433cfc">test_countvectorizer_custom_token_pattern</a> ()</td></tr>
<tr class="separator:ac54253d945d359f90e71b1e619433cfc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77e574bb766b18279d1a9a7d62b69825" id="r_a77e574bb766b18279d1a9a7d62b69825"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a77e574bb766b18279d1a9a7d62b69825">test_countvectorizer_custom_token_pattern_with_several_group</a> ()</td></tr>
<tr class="separator:a77e574bb766b18279d1a9a7d62b69825"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeddfbbe6540f17eea58e0c6c26bb3165" id="r_aeddfbbe6540f17eea58e0c6c26bb3165"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#aeddfbbe6540f17eea58e0c6c26bb3165">test_countvectorizer_uppercase_in_vocab</a> ()</td></tr>
<tr class="separator:aeddfbbe6540f17eea58e0c6c26bb3165"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a557512858124fb8cd8ac2369d112b4c1" id="r_a557512858124fb8cd8ac2369d112b4c1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a557512858124fb8cd8ac2369d112b4c1">test_tf_transformer_feature_names_out</a> ()</td></tr>
<tr class="separator:a557512858124fb8cd8ac2369d112b4c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3cee4f88b496ba3dab4071c5ac6342d" id="r_ae3cee4f88b496ba3dab4071c5ac6342d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae3cee4f88b496ba3dab4071c5ac6342d">test_tf_idf_smoothing</a> ()</td></tr>
<tr class="separator:ae3cee4f88b496ba3dab4071c5ac6342d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae446719b16cb9c120b5c7eb2476d2b64" id="r_ae446719b16cb9c120b5c7eb2476d2b64"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae446719b16cb9c120b5c7eb2476d2b64">test_tfidf_no_smoothing</a> ()</td></tr>
<tr class="separator:ae446719b16cb9c120b5c7eb2476d2b64"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45a9378977cacaa682a5e7391f1a70c7" id="r_a45a9378977cacaa682a5e7391f1a70c7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a45a9378977cacaa682a5e7391f1a70c7">test_sublinear_tf</a> ()</td></tr>
<tr class="separator:a45a9378977cacaa682a5e7391f1a70c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2545651a7ec5306619651a78face6a60" id="r_a2545651a7ec5306619651a78face6a60"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a2545651a7ec5306619651a78face6a60">test_vectorizer</a> ()</td></tr>
<tr class="separator:a2545651a7ec5306619651a78face6a60"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bd4907f8771278084f1f107383247b2" id="r_a4bd4907f8771278084f1f107383247b2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a4bd4907f8771278084f1f107383247b2">test_tfidf_vectorizer_setters</a> ()</td></tr>
<tr class="separator:a4bd4907f8771278084f1f107383247b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6378116402e9f8d538d0b4183b6614ff" id="r_a6378116402e9f8d538d0b4183b6614ff"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a6378116402e9f8d538d0b4183b6614ff">test_hashing_vectorizer</a> ()</td></tr>
<tr class="separator:a6378116402e9f8d538d0b4183b6614ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61fef55ea8d0101e2dc50395857f13bd" id="r_a61fef55ea8d0101e2dc50395857f13bd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a61fef55ea8d0101e2dc50395857f13bd">test_feature_names</a> ()</td></tr>
<tr class="separator:a61fef55ea8d0101e2dc50395857f13bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d6aa95795b98379f7a837fbb6aaffed" id="r_a6d6aa95795b98379f7a837fbb6aaffed"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a6d6aa95795b98379f7a837fbb6aaffed">test_vectorizer_max_features</a> (Vectorizer)</td></tr>
<tr class="separator:a6d6aa95795b98379f7a837fbb6aaffed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9910b6914a9f3623b553ae451dc083dc" id="r_a9910b6914a9f3623b553ae451dc083dc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a9910b6914a9f3623b553ae451dc083dc">test_count_vectorizer_max_features</a> ()</td></tr>
<tr class="separator:a9910b6914a9f3623b553ae451dc083dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af16e6cb1406c79ef96177487faa0c9bf" id="r_af16e6cb1406c79ef96177487faa0c9bf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#af16e6cb1406c79ef96177487faa0c9bf">test_vectorizer_max_df</a> ()</td></tr>
<tr class="separator:af16e6cb1406c79ef96177487faa0c9bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a295bdb5e7d3a39c61eddc9132e011812" id="r_a295bdb5e7d3a39c61eddc9132e011812"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a295bdb5e7d3a39c61eddc9132e011812">test_vectorizer_min_df</a> ()</td></tr>
<tr class="separator:a295bdb5e7d3a39c61eddc9132e011812"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0f34e4832812ab7888e8d2e251fb4de" id="r_af0f34e4832812ab7888e8d2e251fb4de"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#af0f34e4832812ab7888e8d2e251fb4de">test_count_binary_occurrences</a> ()</td></tr>
<tr class="separator:af0f34e4832812ab7888e8d2e251fb4de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18e26f99350ac22ab1f24b327afa05d9" id="r_a18e26f99350ac22ab1f24b327afa05d9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a18e26f99350ac22ab1f24b327afa05d9">test_hashed_binary_occurrences</a> ()</td></tr>
<tr class="separator:a18e26f99350ac22ab1f24b327afa05d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1d7e05a1a1986abd8f816287e36f4bd" id="r_ab1d7e05a1a1986abd8f816287e36f4bd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ab1d7e05a1a1986abd8f816287e36f4bd">test_vectorizer_inverse_transform</a> (Vectorizer)</td></tr>
<tr class="separator:ab1d7e05a1a1986abd8f816287e36f4bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34f1f6d898729435143f313f37063180" id="r_a34f1f6d898729435143f313f37063180"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a34f1f6d898729435143f313f37063180">test_count_vectorizer_pipeline_grid_selection</a> ()</td></tr>
<tr class="separator:a34f1f6d898729435143f313f37063180"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa6966f27f117f17a5204b515f9a6454" id="r_aaa6966f27f117f17a5204b515f9a6454"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#aaa6966f27f117f17a5204b515f9a6454">test_vectorizer_pipeline_grid_selection</a> ()</td></tr>
<tr class="separator:aaa6966f27f117f17a5204b515f9a6454"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a934b03a7cddc1244aa5251507a0ed201" id="r_a934b03a7cddc1244aa5251507a0ed201"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a934b03a7cddc1244aa5251507a0ed201">test_vectorizer_pipeline_cross_validation</a> ()</td></tr>
<tr class="separator:a934b03a7cddc1244aa5251507a0ed201"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d50ce489a983fd3484bcceeb49edfc9" id="r_a9d50ce489a983fd3484bcceeb49edfc9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a9d50ce489a983fd3484bcceeb49edfc9">test_vectorizer_unicode</a> ()</td></tr>
<tr class="separator:a9d50ce489a983fd3484bcceeb49edfc9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3184474ee6db94ea00fa8ca9d1204edf" id="r_a3184474ee6db94ea00fa8ca9d1204edf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a3184474ee6db94ea00fa8ca9d1204edf">test_tfidf_vectorizer_with_fixed_vocabulary</a> ()</td></tr>
<tr class="separator:a3184474ee6db94ea00fa8ca9d1204edf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9663f5bb3ff28a71659cee9cea44950" id="r_aa9663f5bb3ff28a71659cee9cea44950"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#aa9663f5bb3ff28a71659cee9cea44950">test_pickling_vectorizer</a> ()</td></tr>
<tr class="separator:aa9663f5bb3ff28a71659cee9cea44950"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae36066f25159e8b99ceb1e4b71911346" id="r_ae36066f25159e8b99ceb1e4b71911346"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae36066f25159e8b99ceb1e4b71911346">test_pickling_built_processors</a> (factory)</td></tr>
<tr class="separator:ae36066f25159e8b99ceb1e4b71911346"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57915bb5eada476085c2eb13989c0e98" id="r_a57915bb5eada476085c2eb13989c0e98"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a57915bb5eada476085c2eb13989c0e98">test_countvectorizer_vocab_sets_when_pickling</a> ()</td></tr>
<tr class="separator:a57915bb5eada476085c2eb13989c0e98"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a578af87c6372f402a258e0646de8a0ae" id="r_a578af87c6372f402a258e0646de8a0ae"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a578af87c6372f402a258e0646de8a0ae">test_countvectorizer_vocab_dicts_when_pickling</a> ()</td></tr>
<tr class="separator:a578af87c6372f402a258e0646de8a0ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9d0383f97fd86a08d2655b24c09be1c" id="r_af9d0383f97fd86a08d2655b24c09be1c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#af9d0383f97fd86a08d2655b24c09be1c">test_stop_words_removal</a> ()</td></tr>
<tr class="separator:af9d0383f97fd86a08d2655b24c09be1c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae95543f5e850e0f686e1a1828a786961" id="r_ae95543f5e850e0f686e1a1828a786961"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae95543f5e850e0f686e1a1828a786961">test_pickling_transformer</a> ()</td></tr>
<tr class="separator:ae95543f5e850e0f686e1a1828a786961"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39555e7c1bb618d6c1856cd4af6d5e71" id="r_a39555e7c1bb618d6c1856cd4af6d5e71"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a39555e7c1bb618d6c1856cd4af6d5e71">test_transformer_idf_setter</a> ()</td></tr>
<tr class="separator:a39555e7c1bb618d6c1856cd4af6d5e71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a137fed41aa0d7bec6001ba438355ef49" id="r_a137fed41aa0d7bec6001ba438355ef49"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a137fed41aa0d7bec6001ba438355ef49">test_tfidf_vectorizer_setter</a> ()</td></tr>
<tr class="separator:a137fed41aa0d7bec6001ba438355ef49"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2e353ee6a51dbac840d01a68cd0ddac" id="r_ac2e353ee6a51dbac840d01a68cd0ddac"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ac2e353ee6a51dbac840d01a68cd0ddac">test_tfidfvectorizer_invalid_idf_attr</a> ()</td></tr>
<tr class="separator:ac2e353ee6a51dbac840d01a68cd0ddac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b890cdd89eac66e68f42cc0cf137270" id="r_a4b890cdd89eac66e68f42cc0cf137270"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a4b890cdd89eac66e68f42cc0cf137270">test_non_unique_vocab</a> ()</td></tr>
<tr class="separator:a4b890cdd89eac66e68f42cc0cf137270"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5bf76b02c01e7fa888d35582cfeb4bc" id="r_ae5bf76b02c01e7fa888d35582cfeb4bc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae5bf76b02c01e7fa888d35582cfeb4bc">test_hashingvectorizer_nan_in_docs</a> ()</td></tr>
<tr class="separator:ae5bf76b02c01e7fa888d35582cfeb4bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0276186cfac0adcad54611926ccdae0f" id="r_a0276186cfac0adcad54611926ccdae0f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a0276186cfac0adcad54611926ccdae0f">test_tfidfvectorizer_binary</a> ()</td></tr>
<tr class="separator:a0276186cfac0adcad54611926ccdae0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cbe9d61b61c2252291a74a42583d2ac" id="r_a8cbe9d61b61c2252291a74a42583d2ac"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a8cbe9d61b61c2252291a74a42583d2ac">test_tfidfvectorizer_export_idf</a> ()</td></tr>
<tr class="separator:a8cbe9d61b61c2252291a74a42583d2ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24ce8d9460fe2778e956722065948877" id="r_a24ce8d9460fe2778e956722065948877"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a24ce8d9460fe2778e956722065948877">test_vectorizer_vocab_clone</a> ()</td></tr>
<tr class="separator:a24ce8d9460fe2778e956722065948877"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9962dc356ef1cd82e7dc140ce549effe" id="r_a9962dc356ef1cd82e7dc140ce549effe"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a9962dc356ef1cd82e7dc140ce549effe">test_vectorizer_string_object_as_input</a> (Vectorizer)</td></tr>
<tr class="separator:a9962dc356ef1cd82e7dc140ce549effe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab18177ae8d526004ebf8bc71bf7a4d88" id="r_ab18177ae8d526004ebf8bc71bf7a4d88"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ab18177ae8d526004ebf8bc71bf7a4d88">test_tfidf_transformer_type</a> (X_dtype)</td></tr>
<tr class="separator:ab18177ae8d526004ebf8bc71bf7a4d88"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae44d47cbb762da7c4d12271b226d4015" id="r_ae44d47cbb762da7c4d12271b226d4015"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae44d47cbb762da7c4d12271b226d4015">test_tfidf_transformer_sparse</a> ()</td></tr>
<tr class="separator:ae44d47cbb762da7c4d12271b226d4015"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38a1db250c9c85d7a5e1b1471287e2c4" id="r_a38a1db250c9c85d7a5e1b1471287e2c4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a38a1db250c9c85d7a5e1b1471287e2c4">test_tfidf_vectorizer_type</a> (vectorizer_dtype, output_dtype, warning_expected)</td></tr>
<tr class="separator:a38a1db250c9c85d7a5e1b1471287e2c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95970e57876ce22fc92c4a14c99e037e" id="r_a95970e57876ce22fc92c4a14c99e037e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a95970e57876ce22fc92c4a14c99e037e">test_vectorizers_invalid_ngram_range</a> (vec)</td></tr>
<tr class="separator:a95970e57876ce22fc92c4a14c99e037e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bb040b6d983f4671b976c89fc1fe864" id="r_a5bb040b6d983f4671b976c89fc1fe864"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a5bb040b6d983f4671b976c89fc1fe864">_check_stop_words_consistency</a> (estimator)</td></tr>
<tr class="separator:a5bb040b6d983f4671b976c89fc1fe864"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a422901591e2d209870bbf6465c09c2" id="r_a8a422901591e2d209870bbf6465c09c2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a8a422901591e2d209870bbf6465c09c2">test_vectorizer_stop_words_inconsistent</a> ()</td></tr>
<tr class="separator:a8a422901591e2d209870bbf6465c09c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0048701c9b143372ba394fd4254abf1" id="r_aa0048701c9b143372ba394fd4254abf1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#aa0048701c9b143372ba394fd4254abf1">test_countvectorizer_sort_features_64bit_sparse_indices</a> ()</td></tr>
<tr class="separator:aa0048701c9b143372ba394fd4254abf1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7010fc7ba8e0a8e20579ffad66068304" id="r_a7010fc7ba8e0a8e20579ffad66068304"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a7010fc7ba8e0a8e20579ffad66068304">test_stop_word_validation_custom_preprocessor</a> (Estimator)</td></tr>
<tr class="separator:a7010fc7ba8e0a8e20579ffad66068304"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a164446f461fccb2482c91aeed89d8fba" id="r_a164446f461fccb2482c91aeed89d8fba"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a164446f461fccb2482c91aeed89d8fba">test_callable_analyzer_error</a> (Estimator, input_type, err_type, err_msg)</td></tr>
<tr class="separator:a164446f461fccb2482c91aeed89d8fba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa557fb27b948f8498dd787147315438d" id="r_aa557fb27b948f8498dd787147315438d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#aa557fb27b948f8498dd787147315438d">test_callable_analyzer_change_behavior</a> (Estimator, analyzer, input_type)</td></tr>
<tr class="separator:aa557fb27b948f8498dd787147315438d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23aab8c8b36d6256f14c6519663a9318" id="r_a23aab8c8b36d6256f14c6519663a9318"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a23aab8c8b36d6256f14c6519663a9318">test_callable_analyzer_reraise_error</a> (tmpdir, Estimator)</td></tr>
<tr class="separator:a23aab8c8b36d6256f14c6519663a9318"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad4fd2fa9802e010e580800a56ea461ea" id="r_ad4fd2fa9802e010e580800a56ea461ea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ad4fd2fa9802e010e580800a56ea461ea">test_unused_parameters_warn</a> (Vectorizer, stop_words, tokenizer, preprocessor, ngram_range, token_pattern, analyzer, unused_name, ovrd_name, ovrd_msg)</td></tr>
<tr class="separator:ad4fd2fa9802e010e580800a56ea461ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab956f75c4aa43ee851b7bb96b9ea28f3" id="r_ab956f75c4aa43ee851b7bb96b9ea28f3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ab956f75c4aa43ee851b7bb96b9ea28f3">test_n_features_in</a> (Vectorizer, X)</td></tr>
<tr class="separator:ab956f75c4aa43ee851b7bb96b9ea28f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff27b9f1b6a49ecdeba9ef77b68bcd5d" id="r_aff27b9f1b6a49ecdeba9ef77b68bcd5d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#aff27b9f1b6a49ecdeba9ef77b68bcd5d">test_tie_breaking_sample_order_invariance</a> ()</td></tr>
<tr class="separator:aff27b9f1b6a49ecdeba9ef77b68bcd5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c78e5a70e8318efc28bdf22895ba5c4" id="r_a4c78e5a70e8318efc28bdf22895ba5c4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a4c78e5a70e8318efc28bdf22895ba5c4">test_nonnegative_hashing_vectorizer_result_indices</a> ()</td></tr>
<tr class="separator:a4c78e5a70e8318efc28bdf22895ba5c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6319d7ec6d1cbb09a4b27f55a0b79482" id="r_a6319d7ec6d1cbb09a4b27f55a0b79482"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a6319d7ec6d1cbb09a4b27f55a0b79482">test_vectorizers_do_not_have_set_output</a> (Estimator)</td></tr>
<tr class="separator:a6319d7ec6d1cbb09a4b27f55a0b79482"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:ad3d3f152fc1af1b8d75aeff55c65b04e" id="r_ad3d3f152fc1af1b8d75aeff55c65b04e"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ad3d3f152fc1af1b8d75aeff55c65b04e">JUNK_FOOD_DOCS</a></td></tr>
<tr class="separator:ad3d3f152fc1af1b8d75aeff55c65b04e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a915f0b1639fa8ce70c229041e7edccdf" id="r_a915f0b1639fa8ce70c229041e7edccdf"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a915f0b1639fa8ce70c229041e7edccdf">NOTJUNK_FOOD_DOCS</a></td></tr>
<tr class="separator:a915f0b1639fa8ce70c229041e7edccdf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8511ee7660ed9a977e39c26fe6d03d33" id="r_a8511ee7660ed9a977e39c26fe6d03d33"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a8511ee7660ed9a977e39c26fe6d03d33">ALL_FOOD_DOCS</a> = <a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ad3d3f152fc1af1b8d75aeff55c65b04e">JUNK_FOOD_DOCS</a> + <a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a915f0b1639fa8ce70c229041e7edccdf">NOTJUNK_FOOD_DOCS</a></td></tr>
<tr class="separator:a8511ee7660ed9a977e39c26fe6d03d33"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a5bb040b6d983f4671b976c89fc1fe864" name="a5bb040b6d983f4671b976c89fc1fe864"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5bb040b6d983f4671b976c89fc1fe864">&#9670;&#160;</a></span>_check_stop_words_consistency()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text._check_stop_words_consistency </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>estimator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1358</span><span class="keyword">def </span>_check_stop_words_consistency(estimator):</div>
<div class="line"><span class="lineno"> 1359</span>    stop_words = estimator.get_stop_words()</div>
<div class="line"><span class="lineno"> 1360</span>    tokenize = estimator.build_tokenizer()</div>
<div class="line"><span class="lineno"> 1361</span>    preprocess = estimator.build_preprocessor()</div>
<div class="line"><span class="lineno"> 1362</span>    <span class="keywordflow">return</span> estimator._check_stop_words_consistency(stop_words, preprocess, tokenize)</div>
<div class="line"><span class="lineno"> 1363</span> </div>
<div class="line"><span class="lineno"> 1364</span> </div>
<div class="line"><span class="lineno"> 1365</span><span class="preprocessor">@fails_if_pypy</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab3805ad5190defbfe52b727ab4d575ed" name="ab3805ad5190defbfe52b727ab4d575ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3805ad5190defbfe52b727ab4d575ed">&#9670;&#160;</a></span>lazy_analyze()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.lazy_analyze </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   74</span><span class="keyword">def </span>lazy_analyze(s):</div>
<div class="line"><span class="lineno">   75</span>    <span class="keywordflow">return</span> [<span class="stringliteral">&quot;the_ultimate_feature&quot;</span>]</div>
<div class="line"><span class="lineno">   76</span> </div>
<div class="line"><span class="lineno">   77</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a742ccc6ccc7c7d3c2144133cc066c67a" name="a742ccc6ccc7c7d3c2144133cc066c67a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a742ccc6ccc7c7d3c2144133cc066c67a">&#9670;&#160;</a></span>split_tokenize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.split_tokenize </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   70</span><span class="keyword">def </span>split_tokenize(s):</div>
<div class="line"><span class="lineno">   71</span>    <span class="keywordflow">return</span> s.split()</div>
<div class="line"><span class="lineno">   72</span> </div>
<div class="line"><span class="lineno">   73</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae739cc1cbc9cd66eae58a2610628af91" name="ae739cc1cbc9cd66eae58a2610628af91"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae739cc1cbc9cd66eae58a2610628af91">&#9670;&#160;</a></span>strip_eacute()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.strip_eacute </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   66</span><span class="keyword">def </span>strip_eacute(s):</div>
<div class="line"><span class="lineno">   67</span>    <span class="keywordflow">return</span> s.replace(<span class="stringliteral">&quot;Ã©&quot;</span>, <span class="stringliteral">&quot;e&quot;</span>)</div>
<div class="line"><span class="lineno">   68</span> </div>
<div class="line"><span class="lineno">   69</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa557fb27b948f8498dd787147315438d" name="aa557fb27b948f8498dd787147315438d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa557fb27b948f8498dd787147315438d">&#9670;&#160;</a></span>test_callable_analyzer_change_behavior()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_callable_analyzer_change_behavior </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Estimator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>analyzer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_type</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1477</span><span class="keyword">def </span>test_callable_analyzer_change_behavior(Estimator, analyzer, input_type):</div>
<div class="line"><span class="lineno"> 1478</span>    data = [<span class="stringliteral">&quot;this is text, not file or filename&quot;</span>]</div>
<div class="line"><span class="lineno"> 1479</span>    <span class="keyword">with</span> pytest.raises((FileNotFoundError, AttributeError)):</div>
<div class="line"><span class="lineno"> 1480</span>        Estimator(analyzer=analyzer, input=input_type).fit_transform(data)</div>
<div class="line"><span class="lineno"> 1481</span> </div>
<div class="line"><span class="lineno"> 1482</span> </div>
<div class="line"><span class="lineno"> 1483</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1484</span>    <span class="stringliteral">&quot;Estimator&quot;</span>, [CountVectorizer, TfidfVectorizer, HashingVectorizer]</div>
<div class="line"><span class="lineno"> 1485</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a164446f461fccb2482c91aeed89d8fba" name="a164446f461fccb2482c91aeed89d8fba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a164446f461fccb2482c91aeed89d8fba">&#9670;&#160;</a></span>test_callable_analyzer_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_callable_analyzer_error </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Estimator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>err_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>err_msg</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1457</span><span class="keyword">def </span>test_callable_analyzer_error(Estimator, input_type, err_type, err_msg):</div>
<div class="line"><span class="lineno"> 1458</span>    <span class="keywordflow">if</span> issubclass(Estimator, HashingVectorizer) <span class="keywordflow">and</span> IS_PYPY:</div>
<div class="line"><span class="lineno"> 1459</span>        pytest.xfail(<span class="stringliteral">&quot;HashingVectorizer is not supported on PyPy&quot;</span>)</div>
<div class="line"><span class="lineno"> 1460</span>    data = [<span class="stringliteral">&quot;this is text, not file or filename&quot;</span>]</div>
<div class="line"><span class="lineno"> 1461</span>    <span class="keyword">with</span> pytest.raises(err_type, match=err_msg):</div>
<div class="line"><span class="lineno"> 1462</span>        Estimator(analyzer=<span class="keyword">lambda</span> x: x.split(), input=input_type).fit_transform(data)</div>
<div class="line"><span class="lineno"> 1463</span> </div>
<div class="line"><span class="lineno"> 1464</span> </div>
<div class="line"><span class="lineno"> 1465</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1466</span>    <span class="stringliteral">&quot;Estimator&quot;</span>,</div>
<div class="line"><span class="lineno"> 1467</span>    [</div>
<div class="line"><span class="lineno"> 1468</span>        CountVectorizer,</div>
<div class="line"><span class="lineno"> 1469</span>        TfidfVectorizer,</div>
<div class="line"><span class="lineno"> 1470</span>        pytest.param(HashingVectorizer, marks=fails_if_pypy),</div>
<div class="line"><span class="lineno"> 1471</span>    ],</div>
<div class="line"><span class="lineno"> 1472</span>)</div>
<div class="line"><span class="lineno"> 1473</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1474</span>    <span class="stringliteral">&quot;analyzer&quot;</span>, [<span class="keyword">lambda</span> doc: open(doc, <span class="stringliteral">&quot;r&quot;</span>), <span class="keyword">lambda</span> doc: doc.read()]</div>
<div class="line"><span class="lineno"> 1475</span>)</div>
<div class="line"><span class="lineno"> 1476</span><span class="preprocessor">@pytest.mark.parametrize(&quot;input_type&quot;, [&quot;file&quot;, &quot;filename&quot;])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a23aab8c8b36d6256f14c6519663a9318" name="a23aab8c8b36d6256f14c6519663a9318"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a23aab8c8b36d6256f14c6519663a9318">&#9670;&#160;</a></span>test_callable_analyzer_reraise_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_callable_analyzer_reraise_error </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tmpdir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Estimator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1486</span><span class="keyword">def </span>test_callable_analyzer_reraise_error(tmpdir, Estimator):</div>
<div class="line"><span class="lineno"> 1487</span>    <span class="comment"># check if a custom exception from the analyzer is shown to the user</span></div>
<div class="line"><span class="lineno"> 1488</span>    <span class="keyword">def </span>analyzer(doc):</div>
<div class="line"><span class="lineno"> 1489</span>        <span class="keywordflow">raise</span> Exception(<span class="stringliteral">&quot;testing&quot;</span>)</div>
<div class="line"><span class="lineno"> 1490</span> </div>
<div class="line"><span class="lineno"> 1491</span>    <span class="keywordflow">if</span> issubclass(Estimator, HashingVectorizer) <span class="keywordflow">and</span> IS_PYPY:</div>
<div class="line"><span class="lineno"> 1492</span>        pytest.xfail(<span class="stringliteral">&quot;HashingVectorizer is not supported on PyPy&quot;</span>)</div>
<div class="line"><span class="lineno"> 1493</span> </div>
<div class="line"><span class="lineno"> 1494</span>    f = tmpdir.join(<span class="stringliteral">&quot;file.txt&quot;</span>)</div>
<div class="line"><span class="lineno"> 1495</span>    f.write(<span class="stringliteral">&quot;sample content\n&quot;</span>)</div>
<div class="line"><span class="lineno"> 1496</span> </div>
<div class="line"><span class="lineno"> 1497</span>    <span class="keyword">with</span> pytest.raises(Exception, match=<span class="stringliteral">&quot;testing&quot;</span>):</div>
<div class="line"><span class="lineno"> 1498</span>        Estimator(analyzer=analyzer, input=<span class="stringliteral">&quot;file&quot;</span>).fit_transform([f])</div>
<div class="line"><span class="lineno"> 1499</span> </div>
<div class="line"><span class="lineno"> 1500</span> </div>
<div class="line"><span class="lineno"> 1501</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1502</span>    <span class="stringliteral">&quot;Vectorizer&quot;</span>, [CountVectorizer, HashingVectorizer, TfidfVectorizer]</div>
<div class="line"><span class="lineno"> 1503</span>)</div>
<div class="line"><span class="lineno"> 1504</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1505</span>    <span class="stringliteral">&quot;stop_words, tokenizer, preprocessor, ngram_range, token_pattern,&quot;</span></div>
<div class="line"><span class="lineno"> 1506</span>    <span class="stringliteral">&quot;analyzer, unused_name, ovrd_name, ovrd_msg&quot;</span>,</div>
<div class="line"><span class="lineno"> 1507</span>    [</div>
<div class="line"><span class="lineno"> 1508</span>        (</div>
<div class="line"><span class="lineno"> 1509</span>            [<span class="stringliteral">&quot;you&#39;ve&quot;</span>, <span class="stringliteral">&quot;you&#39;ll&quot;</span>],</div>
<div class="line"><span class="lineno"> 1510</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1511</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1512</span>            (1, 1),</div>
<div class="line"><span class="lineno"> 1513</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1514</span>            <span class="stringliteral">&quot;char&quot;</span>,</div>
<div class="line"><span class="lineno"> 1515</span>            <span class="stringliteral">&quot;&#39;stop_words&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1516</span>            <span class="stringliteral">&quot;&#39;analyzer&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1517</span>            <span class="stringliteral">&quot;!= &#39;word&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1518</span>        ),</div>
<div class="line"><span class="lineno"> 1519</span>        (</div>
<div class="line"><span class="lineno"> 1520</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1521</span>            <span class="keyword">lambda</span> s: s.split(),</div>
<div class="line"><span class="lineno"> 1522</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1523</span>            (1, 1),</div>
<div class="line"><span class="lineno"> 1524</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1525</span>            <span class="stringliteral">&quot;char&quot;</span>,</div>
<div class="line"><span class="lineno"> 1526</span>            <span class="stringliteral">&quot;&#39;tokenizer&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1527</span>            <span class="stringliteral">&quot;&#39;analyzer&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1528</span>            <span class="stringliteral">&quot;!= &#39;word&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1529</span>        ),</div>
<div class="line"><span class="lineno"> 1530</span>        (</div>
<div class="line"><span class="lineno"> 1531</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1532</span>            <span class="keyword">lambda</span> s: s.split(),</div>
<div class="line"><span class="lineno"> 1533</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1534</span>            (1, 1),</div>
<div class="line"><span class="lineno"> 1535</span>            <span class="stringliteral">r&quot;\w+&quot;</span>,</div>
<div class="line"><span class="lineno"> 1536</span>            <span class="stringliteral">&quot;word&quot;</span>,</div>
<div class="line"><span class="lineno"> 1537</span>            <span class="stringliteral">&quot;&#39;token_pattern&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1538</span>            <span class="stringliteral">&quot;&#39;tokenizer&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1539</span>            <span class="stringliteral">&quot;is not None&quot;</span>,</div>
<div class="line"><span class="lineno"> 1540</span>        ),</div>
<div class="line"><span class="lineno"> 1541</span>        (</div>
<div class="line"><span class="lineno"> 1542</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1543</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1544</span>            <span class="keyword">lambda</span> s: s.upper(),</div>
<div class="line"><span class="lineno"> 1545</span>            (1, 1),</div>
<div class="line"><span class="lineno"> 1546</span>            <span class="stringliteral">r&quot;\w+&quot;</span>,</div>
<div class="line"><span class="lineno"> 1547</span>            <span class="keyword">lambda</span> s: s.upper(),</div>
<div class="line"><span class="lineno"> 1548</span>            <span class="stringliteral">&quot;&#39;preprocessor&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1549</span>            <span class="stringliteral">&quot;&#39;analyzer&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1550</span>            <span class="stringliteral">&quot;is callable&quot;</span>,</div>
<div class="line"><span class="lineno"> 1551</span>        ),</div>
<div class="line"><span class="lineno"> 1552</span>        (</div>
<div class="line"><span class="lineno"> 1553</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1554</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1555</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1556</span>            (1, 2),</div>
<div class="line"><span class="lineno"> 1557</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1558</span>            <span class="keyword">lambda</span> s: s.upper(),</div>
<div class="line"><span class="lineno"> 1559</span>            <span class="stringliteral">&quot;&#39;ngram_range&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1560</span>            <span class="stringliteral">&quot;&#39;analyzer&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1561</span>            <span class="stringliteral">&quot;is callable&quot;</span>,</div>
<div class="line"><span class="lineno"> 1562</span>        ),</div>
<div class="line"><span class="lineno"> 1563</span>        (</div>
<div class="line"><span class="lineno"> 1564</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1565</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1566</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1567</span>            (1, 1),</div>
<div class="line"><span class="lineno"> 1568</span>            <span class="stringliteral">r&quot;\w+&quot;</span>,</div>
<div class="line"><span class="lineno"> 1569</span>            <span class="stringliteral">&quot;char&quot;</span>,</div>
<div class="line"><span class="lineno"> 1570</span>            <span class="stringliteral">&quot;&#39;token_pattern&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1571</span>            <span class="stringliteral">&quot;&#39;analyzer&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1572</span>            <span class="stringliteral">&quot;!= &#39;word&#39;&quot;</span>,</div>
<div class="line"><span class="lineno"> 1573</span>        ),</div>
<div class="line"><span class="lineno"> 1574</span>    ],</div>
<div class="line"><span class="lineno"> 1575</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae6c31e1f1fb00e290c44c1240422a225" name="ae6c31e1f1fb00e290c44c1240422a225"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6c31e1f1fb00e290c44c1240422a225">&#9670;&#160;</a></span>test_char_ngram_analyzer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_char_ngram_analyzer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  246</span><span class="keyword">def </span>test_char_ngram_analyzer():</div>
<div class="line"><span class="lineno">  247</span>    cnga = CountVectorizer(</div>
<div class="line"><span class="lineno">  248</span>        analyzer=<span class="stringliteral">&quot;char&quot;</span>, strip_accents=<span class="stringliteral">&quot;unicode&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><span class="lineno">  249</span>    ).build_analyzer()</div>
<div class="line"><span class="lineno">  250</span> </div>
<div class="line"><span class="lineno">  251</span>    text = <span class="stringliteral">&quot;J&#39;ai mangÃ© du kangourou  ce midi, c&#39;Ã©tait pas trÃ¨s bon&quot;</span></div>
<div class="line"><span class="lineno">  252</span>    expected = [<span class="stringliteral">&quot;j&#39;a&quot;</span>, <span class="stringliteral">&quot;&#39;ai&quot;</span>, <span class="stringliteral">&quot;ai &quot;</span>, <span class="stringliteral">&quot;i m&quot;</span>, <span class="stringliteral">&quot; ma&quot;</span>]</div>
<div class="line"><span class="lineno">  253</span>    <span class="keyword">assert</span> cnga(text)[:5] == expected</div>
<div class="line"><span class="lineno">  254</span>    expected = [<span class="stringliteral">&quot;s tres&quot;</span>, <span class="stringliteral">&quot; tres &quot;</span>, <span class="stringliteral">&quot;tres b&quot;</span>, <span class="stringliteral">&quot;res bo&quot;</span>, <span class="stringliteral">&quot;es bon&quot;</span>]</div>
<div class="line"><span class="lineno">  255</span>    <span class="keyword">assert</span> cnga(text)[-5:] == expected</div>
<div class="line"><span class="lineno">  256</span> </div>
<div class="line"><span class="lineno">  257</span>    text = <span class="stringliteral">&quot;This \n\tis a test, really.\n\n I met Harry yesterday&quot;</span></div>
<div class="line"><span class="lineno">  258</span>    expected = [<span class="stringliteral">&quot;thi&quot;</span>, <span class="stringliteral">&quot;his&quot;</span>, <span class="stringliteral">&quot;is &quot;</span>, <span class="stringliteral">&quot;s i&quot;</span>, <span class="stringliteral">&quot; is&quot;</span>]</div>
<div class="line"><span class="lineno">  259</span>    <span class="keyword">assert</span> cnga(text)[:5] == expected</div>
<div class="line"><span class="lineno">  260</span> </div>
<div class="line"><span class="lineno">  261</span>    expected = [<span class="stringliteral">&quot; yeste&quot;</span>, <span class="stringliteral">&quot;yester&quot;</span>, <span class="stringliteral">&quot;esterd&quot;</span>, <span class="stringliteral">&quot;sterda&quot;</span>, <span class="stringliteral">&quot;terday&quot;</span>]</div>
<div class="line"><span class="lineno">  262</span>    <span class="keyword">assert</span> cnga(text)[-5:] == expected</div>
<div class="line"><span class="lineno">  263</span> </div>
<div class="line"><span class="lineno">  264</span>    cnga = CountVectorizer(</div>
<div class="line"><span class="lineno">  265</span>        input=<span class="stringliteral">&quot;file&quot;</span>, analyzer=<span class="stringliteral">&quot;char&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><span class="lineno">  266</span>    ).build_analyzer()</div>
<div class="line"><span class="lineno">  267</span>    text = StringIO(<span class="stringliteral">&quot;This is a test with a file-like object!&quot;</span>)</div>
<div class="line"><span class="lineno">  268</span>    expected = [<span class="stringliteral">&quot;thi&quot;</span>, <span class="stringliteral">&quot;his&quot;</span>, <span class="stringliteral">&quot;is &quot;</span>, <span class="stringliteral">&quot;s i&quot;</span>, <span class="stringliteral">&quot; is&quot;</span>]</div>
<div class="line"><span class="lineno">  269</span>    <span class="keyword">assert</span> cnga(text)[:5] == expected</div>
<div class="line"><span class="lineno">  270</span> </div>
<div class="line"><span class="lineno">  271</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac5b0d1e6cb85e7e07961118235dad429" name="ac5b0d1e6cb85e7e07961118235dad429"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac5b0d1e6cb85e7e07961118235dad429">&#9670;&#160;</a></span>test_char_wb_ngram_analyzer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_char_wb_ngram_analyzer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  272</span><span class="keyword">def </span>test_char_wb_ngram_analyzer():</div>
<div class="line"><span class="lineno">  273</span>    cnga = CountVectorizer(</div>
<div class="line"><span class="lineno">  274</span>        analyzer=<span class="stringliteral">&quot;char_wb&quot;</span>, strip_accents=<span class="stringliteral">&quot;unicode&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><span class="lineno">  275</span>    ).build_analyzer()</div>
<div class="line"><span class="lineno">  276</span> </div>
<div class="line"><span class="lineno">  277</span>    text = <span class="stringliteral">&quot;This \n\tis a test, really.\n\n I met Harry yesterday&quot;</span></div>
<div class="line"><span class="lineno">  278</span>    expected = [<span class="stringliteral">&quot; th&quot;</span>, <span class="stringliteral">&quot;thi&quot;</span>, <span class="stringliteral">&quot;his&quot;</span>, <span class="stringliteral">&quot;is &quot;</span>, <span class="stringliteral">&quot; thi&quot;</span>]</div>
<div class="line"><span class="lineno">  279</span>    <span class="keyword">assert</span> cnga(text)[:5] == expected</div>
<div class="line"><span class="lineno">  280</span> </div>
<div class="line"><span class="lineno">  281</span>    expected = [<span class="stringliteral">&quot;yester&quot;</span>, <span class="stringliteral">&quot;esterd&quot;</span>, <span class="stringliteral">&quot;sterda&quot;</span>, <span class="stringliteral">&quot;terday&quot;</span>, <span class="stringliteral">&quot;erday &quot;</span>]</div>
<div class="line"><span class="lineno">  282</span>    <span class="keyword">assert</span> cnga(text)[-5:] == expected</div>
<div class="line"><span class="lineno">  283</span> </div>
<div class="line"><span class="lineno">  284</span>    cnga = CountVectorizer(</div>
<div class="line"><span class="lineno">  285</span>        input=<span class="stringliteral">&quot;file&quot;</span>, analyzer=<span class="stringliteral">&quot;char_wb&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><span class="lineno">  286</span>    ).build_analyzer()</div>
<div class="line"><span class="lineno">  287</span>    text = StringIO(<span class="stringliteral">&quot;A test with a file-like object!&quot;</span>)</div>
<div class="line"><span class="lineno">  288</span>    expected = [<span class="stringliteral">&quot; a &quot;</span>, <span class="stringliteral">&quot; te&quot;</span>, <span class="stringliteral">&quot;tes&quot;</span>, <span class="stringliteral">&quot;est&quot;</span>, <span class="stringliteral">&quot;st &quot;</span>, <span class="stringliteral">&quot; tes&quot;</span>]</div>
<div class="line"><span class="lineno">  289</span>    <span class="keyword">assert</span> cnga(text)[:6] == expected</div>
<div class="line"><span class="lineno">  290</span> </div>
<div class="line"><span class="lineno">  291</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af0f34e4832812ab7888e8d2e251fb4de" name="af0f34e4832812ab7888e8d2e251fb4de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0f34e4832812ab7888e8d2e251fb4de">&#9670;&#160;</a></span>test_count_binary_occurrences()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_count_binary_occurrences </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  846</span><span class="keyword">def </span>test_count_binary_occurrences():</div>
<div class="line"><span class="lineno">  847</span>    <span class="comment"># by default multiple occurrences are counted as longs</span></div>
<div class="line"><span class="lineno">  848</span>    test_data = [<span class="stringliteral">&quot;aaabc&quot;</span>, <span class="stringliteral">&quot;abbde&quot;</span>]</div>
<div class="line"><span class="lineno">  849</span>    vect = CountVectorizer(analyzer=<span class="stringliteral">&quot;char&quot;</span>, max_df=1.0)</div>
<div class="line"><span class="lineno">  850</span>    X = vect.fit_transform(test_data).toarray()</div>
<div class="line"><span class="lineno">  851</span>    assert_array_equal([<span class="stringliteral">&quot;a&quot;</span>, <span class="stringliteral">&quot;b&quot;</span>, <span class="stringliteral">&quot;c&quot;</span>, <span class="stringliteral">&quot;d&quot;</span>, <span class="stringliteral">&quot;e&quot;</span>], vect.get_feature_names_out())</div>
<div class="line"><span class="lineno">  852</span>    assert_array_equal([[3, 1, 1, 0, 0], [1, 2, 0, 1, 1]], X)</div>
<div class="line"><span class="lineno">  853</span> </div>
<div class="line"><span class="lineno">  854</span>    <span class="comment"># using boolean features, we can fetch the binary occurrence info</span></div>
<div class="line"><span class="lineno">  855</span>    <span class="comment"># instead.</span></div>
<div class="line"><span class="lineno">  856</span>    vect = CountVectorizer(analyzer=<span class="stringliteral">&quot;char&quot;</span>, max_df=1.0, binary=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  857</span>    X = vect.fit_transform(test_data).toarray()</div>
<div class="line"><span class="lineno">  858</span>    assert_array_equal([[1, 1, 1, 0, 0], [1, 1, 0, 1, 1]], X)</div>
<div class="line"><span class="lineno">  859</span> </div>
<div class="line"><span class="lineno">  860</span>    <span class="comment"># check the ability to change the dtype</span></div>
<div class="line"><span class="lineno">  861</span>    vect = CountVectorizer(analyzer=<span class="stringliteral">&quot;char&quot;</span>, max_df=1.0, binary=<span class="keyword">True</span>, dtype=np.float32)</div>
<div class="line"><span class="lineno">  862</span>    X_sparse = vect.fit_transform(test_data)</div>
<div class="line"><span class="lineno">  863</span>    <span class="keyword">assert</span> X_sparse.dtype == np.float32</div>
<div class="line"><span class="lineno">  864</span> </div>
<div class="line"><span class="lineno">  865</span> </div>
<div class="line"><span class="lineno">  866</span><span class="preprocessor">@fails_if_pypy</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a9910b6914a9f3623b553ae451dc083dc" name="a9910b6914a9f3623b553ae451dc083dc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9910b6914a9f3623b553ae451dc083dc">&#9670;&#160;</a></span>test_count_vectorizer_max_features()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_count_vectorizer_max_features </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  774</span><span class="keyword">def </span>test_count_vectorizer_max_features():</div>
<div class="line"><span class="lineno">  775</span>    <span class="comment"># Regression test: max_features didn&#39;t work correctly in 0.14.</span></div>
<div class="line"><span class="lineno">  776</span> </div>
<div class="line"><span class="lineno">  777</span>    cv_1 = CountVectorizer(max_features=1)</div>
<div class="line"><span class="lineno">  778</span>    cv_3 = CountVectorizer(max_features=3)</div>
<div class="line"><span class="lineno">  779</span>    cv_None = CountVectorizer(max_features=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  780</span> </div>
<div class="line"><span class="lineno">  781</span>    counts_1 = cv_1.fit_transform(JUNK_FOOD_DOCS).sum(axis=0)</div>
<div class="line"><span class="lineno">  782</span>    counts_3 = cv_3.fit_transform(JUNK_FOOD_DOCS).sum(axis=0)</div>
<div class="line"><span class="lineno">  783</span>    counts_None = cv_None.fit_transform(JUNK_FOOD_DOCS).sum(axis=0)</div>
<div class="line"><span class="lineno">  784</span> </div>
<div class="line"><span class="lineno">  785</span>    features_1 = cv_1.get_feature_names_out()</div>
<div class="line"><span class="lineno">  786</span>    features_3 = cv_3.get_feature_names_out()</div>
<div class="line"><span class="lineno">  787</span>    features_None = cv_None.get_feature_names_out()</div>
<div class="line"><span class="lineno">  788</span> </div>
<div class="line"><span class="lineno">  789</span>    <span class="comment"># The most common feature is &quot;the&quot;, with frequency 7.</span></div>
<div class="line"><span class="lineno">  790</span>    <span class="keyword">assert</span> 7 == counts_1.max()</div>
<div class="line"><span class="lineno">  791</span>    <span class="keyword">assert</span> 7 == counts_3.max()</div>
<div class="line"><span class="lineno">  792</span>    <span class="keyword">assert</span> 7 == counts_None.max()</div>
<div class="line"><span class="lineno">  793</span> </div>
<div class="line"><span class="lineno">  794</span>    <span class="comment"># The most common feature should be the same</span></div>
<div class="line"><span class="lineno">  795</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;the&quot;</span> == features_1[np.argmax(counts_1)]</div>
<div class="line"><span class="lineno">  796</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;the&quot;</span> == features_3[np.argmax(counts_3)]</div>
<div class="line"><span class="lineno">  797</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;the&quot;</span> == features_None[np.argmax(counts_None)]</div>
<div class="line"><span class="lineno">  798</span> </div>
<div class="line"><span class="lineno">  799</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a34f1f6d898729435143f313f37063180" name="a34f1f6d898729435143f313f37063180"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34f1f6d898729435143f313f37063180">&#9670;&#160;</a></span>test_count_vectorizer_pipeline_grid_selection()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_count_vectorizer_pipeline_grid_selection </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  925</span><span class="keyword">def </span>test_count_vectorizer_pipeline_grid_selection():</div>
<div class="line"><span class="lineno">  926</span>    <span class="comment"># raw documents</span></div>
<div class="line"><span class="lineno">  927</span>    data = JUNK_FOOD_DOCS + NOTJUNK_FOOD_DOCS</div>
<div class="line"><span class="lineno">  928</span> </div>
<div class="line"><span class="lineno">  929</span>    <span class="comment"># label junk food as -1, the others as +1</span></div>
<div class="line"><span class="lineno">  930</span>    target = [-1] * len(JUNK_FOOD_DOCS) + [1] * len(NOTJUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  931</span> </div>
<div class="line"><span class="lineno">  932</span>    <span class="comment"># split the dataset for model development and final evaluation</span></div>
<div class="line"><span class="lineno">  933</span>    train_data, test_data, target_train, target_test = train_test_split(</div>
<div class="line"><span class="lineno">  934</span>        data, target, test_size=0.2, random_state=0</div>
<div class="line"><span class="lineno">  935</span>    )</div>
<div class="line"><span class="lineno">  936</span> </div>
<div class="line"><span class="lineno">  937</span>    pipeline = Pipeline([(<span class="stringliteral">&quot;vect&quot;</span>, CountVectorizer()), (<span class="stringliteral">&quot;svc&quot;</span>, LinearSVC())])</div>
<div class="line"><span class="lineno">  938</span> </div>
<div class="line"><span class="lineno">  939</span>    parameters = {</div>
<div class="line"><span class="lineno">  940</span>        <span class="stringliteral">&quot;vect__ngram_range&quot;</span>: [(1, 1), (1, 2)],</div>
<div class="line"><span class="lineno">  941</span>        <span class="stringliteral">&quot;svc__loss&quot;</span>: (<span class="stringliteral">&quot;hinge&quot;</span>, <span class="stringliteral">&quot;squared_hinge&quot;</span>),</div>
<div class="line"><span class="lineno">  942</span>    }</div>
<div class="line"><span class="lineno">  943</span> </div>
<div class="line"><span class="lineno">  944</span>    <span class="comment"># find the best parameters for both the feature extraction and the</span></div>
<div class="line"><span class="lineno">  945</span>    <span class="comment"># classifier</span></div>
<div class="line"><span class="lineno">  946</span>    grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, cv=3)</div>
<div class="line"><span class="lineno">  947</span> </div>
<div class="line"><span class="lineno">  948</span>    <span class="comment"># Check that the best model found by grid search is 100% correct on the</span></div>
<div class="line"><span class="lineno">  949</span>    <span class="comment"># held out evaluation set.</span></div>
<div class="line"><span class="lineno">  950</span>    pred = grid_search.fit(train_data, target_train).predict(test_data)</div>
<div class="line"><span class="lineno">  951</span>    assert_array_equal(pred, target_test)</div>
<div class="line"><span class="lineno">  952</span> </div>
<div class="line"><span class="lineno">  953</span>    <span class="comment"># on this toy dataset bigram representation which is used in the last of</span></div>
<div class="line"><span class="lineno">  954</span>    <span class="comment"># the grid_search is considered the best estimator since they all converge</span></div>
<div class="line"><span class="lineno">  955</span>    <span class="comment"># to 100% accuracy models</span></div>
<div class="line"><span class="lineno">  956</span>    <span class="keyword">assert</span> grid_search.best_score_ == 1.0</div>
<div class="line"><span class="lineno">  957</span>    best_vectorizer = grid_search.best_estimator_.named_steps[<span class="stringliteral">&quot;vect&quot;</span>]</div>
<div class="line"><span class="lineno">  958</span>    <span class="keyword">assert</span> best_vectorizer.ngram_range == (1, 1)</div>
<div class="line"><span class="lineno">  959</span> </div>
<div class="line"><span class="lineno">  960</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac54253d945d359f90e71b1e619433cfc" name="ac54253d945d359f90e71b1e619433cfc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac54253d945d359f90e71b1e619433cfc">&#9670;&#160;</a></span>test_countvectorizer_custom_token_pattern()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_custom_token_pattern </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check `get_feature_names_out()` when a custom token pattern is passed.
Non-regression test for:
https://github.com/scikit-learn/scikit-learn/issues/12971
</pre> <div class="fragment"><div class="line"><span class="lineno">  397</span><span class="keyword">def </span>test_countvectorizer_custom_token_pattern():</div>
<div class="line"><span class="lineno">  398</span>    <span class="stringliteral">&quot;&quot;&quot;Check `get_feature_names_out()` when a custom token pattern is passed.</span></div>
<div class="line"><span class="lineno">  399</span><span class="stringliteral">    Non-regression test for:</span></div>
<div class="line"><span class="lineno">  400</span><span class="stringliteral">    https://github.com/scikit-learn/scikit-learn/issues/12971</span></div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  402</span>    corpus = [</div>
<div class="line"><span class="lineno">  403</span>        <span class="stringliteral">&quot;This is the 1st document in my corpus.&quot;</span>,</div>
<div class="line"><span class="lineno">  404</span>        <span class="stringliteral">&quot;This document is the 2nd sample.&quot;</span>,</div>
<div class="line"><span class="lineno">  405</span>        <span class="stringliteral">&quot;And this is the 3rd one.&quot;</span>,</div>
<div class="line"><span class="lineno">  406</span>        <span class="stringliteral">&quot;Is this the 4th document?&quot;</span>,</div>
<div class="line"><span class="lineno">  407</span>    ]</div>
<div class="line"><span class="lineno">  408</span>    token_pattern = <span class="stringliteral">r&quot;[0-9]{1,3}(?:st|nd|rd|th)\s\b(\w{2,})\b&quot;</span></div>
<div class="line"><span class="lineno">  409</span>    vectorizer = CountVectorizer(token_pattern=token_pattern)</div>
<div class="line"><span class="lineno">  410</span>    vectorizer.fit_transform(corpus)</div>
<div class="line"><span class="lineno">  411</span>    expected = [<span class="stringliteral">&quot;document&quot;</span>, <span class="stringliteral">&quot;one&quot;</span>, <span class="stringliteral">&quot;sample&quot;</span>]</div>
<div class="line"><span class="lineno">  412</span>    feature_names_out = vectorizer.get_feature_names_out()</div>
<div class="line"><span class="lineno">  413</span>    assert_array_equal(feature_names_out, expected)</div>
<div class="line"><span class="lineno">  414</span> </div>
<div class="line"><span class="lineno">  415</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a77e574bb766b18279d1a9a7d62b69825" name="a77e574bb766b18279d1a9a7d62b69825"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a77e574bb766b18279d1a9a7d62b69825">&#9670;&#160;</a></span>test_countvectorizer_custom_token_pattern_with_several_group()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_custom_token_pattern_with_several_group </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that we raise an error if token pattern capture several groups.
Non-regression test for:
https://github.com/scikit-learn/scikit-learn/issues/12971
</pre> <div class="fragment"><div class="line"><span class="lineno">  416</span><span class="keyword">def </span>test_countvectorizer_custom_token_pattern_with_several_group():</div>
<div class="line"><span class="lineno">  417</span>    <span class="stringliteral">&quot;&quot;&quot;Check that we raise an error if token pattern capture several groups.</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">    Non-regression test for:</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">    https://github.com/scikit-learn/scikit-learn/issues/12971</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  421</span>    corpus = [</div>
<div class="line"><span class="lineno">  422</span>        <span class="stringliteral">&quot;This is the 1st document in my corpus.&quot;</span>,</div>
<div class="line"><span class="lineno">  423</span>        <span class="stringliteral">&quot;This document is the 2nd sample.&quot;</span>,</div>
<div class="line"><span class="lineno">  424</span>        <span class="stringliteral">&quot;And this is the 3rd one.&quot;</span>,</div>
<div class="line"><span class="lineno">  425</span>        <span class="stringliteral">&quot;Is this the 4th document?&quot;</span>,</div>
<div class="line"><span class="lineno">  426</span>    ]</div>
<div class="line"><span class="lineno">  427</span> </div>
<div class="line"><span class="lineno">  428</span>    token_pattern = <span class="stringliteral">r&quot;([0-9]{1,3}(?:st|nd|rd|th))\s\b(\w{2,})\b&quot;</span></div>
<div class="line"><span class="lineno">  429</span>    err_msg = <span class="stringliteral">&quot;More than 1 capturing group in token pattern&quot;</span></div>
<div class="line"><span class="lineno">  430</span>    vectorizer = CountVectorizer(token_pattern=token_pattern)</div>
<div class="line"><span class="lineno">  431</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=err_msg):</div>
<div class="line"><span class="lineno">  432</span>        vectorizer.fit(corpus)</div>
<div class="line"><span class="lineno">  433</span> </div>
<div class="line"><span class="lineno">  434</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aeee1e7c399945a0a845e0cd94639b2f6" name="aeee1e7c399945a0a845e0cd94639b2f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeee1e7c399945a0a845e0cd94639b2f6">&#9670;&#160;</a></span>test_countvectorizer_custom_vocabulary()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_custom_vocabulary </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  315</span><span class="keyword">def </span>test_countvectorizer_custom_vocabulary():</div>
<div class="line"><span class="lineno">  316</span>    vocab = {<span class="stringliteral">&quot;pizza&quot;</span>: 0, <span class="stringliteral">&quot;beer&quot;</span>: 1}</div>
<div class="line"><span class="lineno">  317</span>    terms = set(vocab.keys())</div>
<div class="line"><span class="lineno">  318</span> </div>
<div class="line"><span class="lineno">  319</span>    <span class="comment"># Try a few of the supported types.</span></div>
<div class="line"><span class="lineno">  320</span>    <span class="keywordflow">for</span> typ <span class="keywordflow">in</span> [dict, list, iter, partial(defaultdict, int)]:</div>
<div class="line"><span class="lineno">  321</span>        v = typ(vocab)</div>
<div class="line"><span class="lineno">  322</span>        vect = CountVectorizer(vocabulary=v)</div>
<div class="line"><span class="lineno">  323</span>        vect.fit(JUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  324</span>        <span class="keywordflow">if</span> isinstance(v, Mapping):</div>
<div class="line"><span class="lineno">  325</span>            <span class="keyword">assert</span> vect.vocabulary_ == vocab</div>
<div class="line"><span class="lineno">  326</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  327</span>            <span class="keyword">assert</span> set(vect.vocabulary_) == terms</div>
<div class="line"><span class="lineno">  328</span>        X = vect.transform(JUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  329</span>        <span class="keyword">assert</span> X.shape[1] == len(terms)</div>
<div class="line"><span class="lineno">  330</span>        v = typ(vocab)</div>
<div class="line"><span class="lineno">  331</span>        vect = CountVectorizer(vocabulary=v)</div>
<div class="line"><span class="lineno">  332</span>        inv = vect.inverse_transform(X)</div>
<div class="line"><span class="lineno">  333</span>        <span class="keyword">assert</span> len(inv) == X.shape[0]</div>
<div class="line"><span class="lineno">  334</span> </div>
<div class="line"><span class="lineno">  335</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abca562d7d767d1aae2189089378af6a2" name="abca562d7d767d1aae2189089378af6a2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abca562d7d767d1aae2189089378af6a2">&#9670;&#160;</a></span>test_countvectorizer_custom_vocabulary_gap_index()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_custom_vocabulary_gap_index </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  357</span><span class="keyword">def </span>test_countvectorizer_custom_vocabulary_gap_index():</div>
<div class="line"><span class="lineno">  358</span>    vocab = {<span class="stringliteral">&quot;pizza&quot;</span>: 1, <span class="stringliteral">&quot;beer&quot;</span>: 2}</div>
<div class="line"><span class="lineno">  359</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;doesn&#39;t contain index&quot;</span>):</div>
<div class="line"><span class="lineno">  360</span>        vect = CountVectorizer(vocabulary=vocab)</div>
<div class="line"><span class="lineno">  361</span>        vect.fit([<span class="stringliteral">&quot;pasta_verdura&quot;</span>])</div>
<div class="line"><span class="lineno">  362</span> </div>
<div class="line"><span class="lineno">  363</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9ba8fe8339af7f027d316ab3521b008a" name="a9ba8fe8339af7f027d316ab3521b008a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9ba8fe8339af7f027d316ab3521b008a">&#9670;&#160;</a></span>test_countvectorizer_custom_vocabulary_pipeline()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_custom_vocabulary_pipeline </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  336</span><span class="keyword">def </span>test_countvectorizer_custom_vocabulary_pipeline():</div>
<div class="line"><span class="lineno">  337</span>    what_we_like = [<span class="stringliteral">&quot;pizza&quot;</span>, <span class="stringliteral">&quot;beer&quot;</span>]</div>
<div class="line"><span class="lineno">  338</span>    pipe = Pipeline(</div>
<div class="line"><span class="lineno">  339</span>        [</div>
<div class="line"><span class="lineno">  340</span>            (<span class="stringliteral">&quot;count&quot;</span>, CountVectorizer(vocabulary=what_we_like)),</div>
<div class="line"><span class="lineno">  341</span>            (<span class="stringliteral">&quot;tfidf&quot;</span>, TfidfTransformer()),</div>
<div class="line"><span class="lineno">  342</span>        ]</div>
<div class="line"><span class="lineno">  343</span>    )</div>
<div class="line"><span class="lineno">  344</span>    X = pipe.fit_transform(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  345</span>    <span class="keyword">assert</span> set(pipe.named_steps[<span class="stringliteral">&quot;count&quot;</span>].vocabulary_) == set(what_we_like)</div>
<div class="line"><span class="lineno">  346</span>    <span class="keyword">assert</span> X.shape[1] == len(what_we_like)</div>
<div class="line"><span class="lineno">  347</span> </div>
<div class="line"><span class="lineno">  348</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a33d6e34c6fbaeb7172e4f60ec0f371ba" name="a33d6e34c6fbaeb7172e4f60ec0f371ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a33d6e34c6fbaeb7172e4f60ec0f371ba">&#9670;&#160;</a></span>test_countvectorizer_custom_vocabulary_repeated_indices()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_custom_vocabulary_repeated_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  349</span><span class="keyword">def </span>test_countvectorizer_custom_vocabulary_repeated_indices():</div>
<div class="line"><span class="lineno">  350</span>    vocab = {<span class="stringliteral">&quot;pizza&quot;</span>: 0, <span class="stringliteral">&quot;beer&quot;</span>: 0}</div>
<div class="line"><span class="lineno">  351</span>    msg = <span class="stringliteral">&quot;Vocabulary contains repeated indices&quot;</span></div>
<div class="line"><span class="lineno">  352</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  353</span>        vect = CountVectorizer(vocabulary=vocab)</div>
<div class="line"><span class="lineno">  354</span>        vect.fit([<span class="stringliteral">&quot;pasta_siziliana&quot;</span>])</div>
<div class="line"><span class="lineno">  355</span> </div>
<div class="line"><span class="lineno">  356</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae2601d118113109075d4a8c2f9470445" name="ae2601d118113109075d4a8c2f9470445"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae2601d118113109075d4a8c2f9470445">&#9670;&#160;</a></span>test_countvectorizer_empty_vocabulary()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_empty_vocabulary </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  379</span><span class="keyword">def </span>test_countvectorizer_empty_vocabulary():</div>
<div class="line"><span class="lineno">  380</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;empty vocabulary&quot;</span>):</div>
<div class="line"><span class="lineno">  381</span>        vect = CountVectorizer(vocabulary=[])</div>
<div class="line"><span class="lineno">  382</span>        vect.fit([<span class="stringliteral">&quot;foo&quot;</span>])</div>
<div class="line"><span class="lineno">  383</span> </div>
<div class="line"><span class="lineno">  384</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;empty vocabulary&quot;</span>):</div>
<div class="line"><span class="lineno">  385</span>        v = CountVectorizer(max_df=1.0, stop_words=<span class="stringliteral">&quot;english&quot;</span>)</div>
<div class="line"><span class="lineno">  386</span>        <span class="comment"># fit on stopwords only</span></div>
<div class="line"><span class="lineno">  387</span>        v.fit([<span class="stringliteral">&quot;to be or not to be&quot;</span>, <span class="stringliteral">&quot;and me too&quot;</span>, <span class="stringliteral">&quot;and so do you&quot;</span>])</div>
<div class="line"><span class="lineno">  388</span> </div>
<div class="line"><span class="lineno">  389</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa0048701c9b143372ba394fd4254abf1" name="aa0048701c9b143372ba394fd4254abf1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0048701c9b143372ba394fd4254abf1">&#9670;&#160;</a></span>test_countvectorizer_sort_features_64bit_sparse_indices()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_sort_features_64bit_sparse_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that CountVectorizer._sort_features preserves the dtype of its sparse
feature matrix.

This test is skipped on 32bit platforms, see:
    https://github.com/scikit-learn/scikit-learn/pull/11295
for more details.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1394</span><span class="keyword">def </span>test_countvectorizer_sort_features_64bit_sparse_indices():</div>
<div class="line"><span class="lineno"> 1395</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1396</span><span class="stringliteral">    Check that CountVectorizer._sort_features preserves the dtype of its sparse</span></div>
<div class="line"><span class="lineno"> 1397</span><span class="stringliteral">    feature matrix.</span></div>
<div class="line"><span class="lineno"> 1398</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1399</span><span class="stringliteral">    This test is skipped on 32bit platforms, see:</span></div>
<div class="line"><span class="lineno"> 1400</span><span class="stringliteral">        https://github.com/scikit-learn/scikit-learn/pull/11295</span></div>
<div class="line"><span class="lineno"> 1401</span><span class="stringliteral">    for more details.</span></div>
<div class="line"><span class="lineno"> 1402</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1403</span> </div>
<div class="line"><span class="lineno"> 1404</span>    X = sparse.csr_matrix((5, 5), dtype=np.int64)</div>
<div class="line"><span class="lineno"> 1405</span> </div>
<div class="line"><span class="lineno"> 1406</span>    <span class="comment"># force indices and indptr to int64.</span></div>
<div class="line"><span class="lineno"> 1407</span>    INDICES_DTYPE = np.int64</div>
<div class="line"><span class="lineno"> 1408</span>    X.indices = X.indices.astype(INDICES_DTYPE)</div>
<div class="line"><span class="lineno"> 1409</span>    X.indptr = X.indptr.astype(INDICES_DTYPE)</div>
<div class="line"><span class="lineno"> 1410</span> </div>
<div class="line"><span class="lineno"> 1411</span>    vocabulary = {<span class="stringliteral">&quot;scikit-learn&quot;</span>: 0, <span class="stringliteral">&quot;is&quot;</span>: 1, <span class="stringliteral">&quot;great!&quot;</span>: 2}</div>
<div class="line"><span class="lineno"> 1412</span> </div>
<div class="line"><span class="lineno"> 1413</span>    Xs = CountVectorizer()._sort_features(X, vocabulary)</div>
<div class="line"><span class="lineno"> 1414</span> </div>
<div class="line"><span class="lineno"> 1415</span>    <span class="keyword">assert</span> INDICES_DTYPE == Xs.indices.dtype</div>
<div class="line"><span class="lineno"> 1416</span> </div>
<div class="line"><span class="lineno"> 1417</span> </div>
<div class="line"><span class="lineno"> 1418</span><span class="preprocessor">@fails_if_pypy</span></div>
<div class="line"><span class="lineno"> 1419</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1420</span>    <span class="stringliteral">&quot;Estimator&quot;</span>, [CountVectorizer, TfidfVectorizer, HashingVectorizer]</div>
<div class="line"><span class="lineno"> 1421</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a00b37b5db7fa3b3659a99dc54e2996ea" name="a00b37b5db7fa3b3659a99dc54e2996ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a00b37b5db7fa3b3659a99dc54e2996ea">&#9670;&#160;</a></span>test_countvectorizer_stop_words()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_stop_words </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  364</span><span class="keyword">def </span>test_countvectorizer_stop_words():</div>
<div class="line"><span class="lineno">  365</span>    cv = CountVectorizer()</div>
<div class="line"><span class="lineno">  366</span>    cv.set_params(stop_words=<span class="stringliteral">&quot;english&quot;</span>)</div>
<div class="line"><span class="lineno">  367</span>    <span class="keyword">assert</span> cv.get_stop_words() == ENGLISH_STOP_WORDS</div>
<div class="line"><span class="lineno">  368</span>    cv.set_params(stop_words=<span class="stringliteral">&quot;_bad_str_stop_&quot;</span>)</div>
<div class="line"><span class="lineno">  369</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  370</span>        cv.get_stop_words()</div>
<div class="line"><span class="lineno">  371</span>    cv.set_params(stop_words=<span class="stringliteral">&quot;_bad_unicode_stop_&quot;</span>)</div>
<div class="line"><span class="lineno">  372</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  373</span>        cv.get_stop_words()</div>
<div class="line"><span class="lineno">  374</span>    stoplist = [<span class="stringliteral">&quot;some&quot;</span>, <span class="stringliteral">&quot;other&quot;</span>, <span class="stringliteral">&quot;words&quot;</span>]</div>
<div class="line"><span class="lineno">  375</span>    cv.set_params(stop_words=stoplist)</div>
<div class="line"><span class="lineno">  376</span>    <span class="keyword">assert</span> cv.get_stop_words() == set(stoplist)</div>
<div class="line"><span class="lineno">  377</span> </div>
<div class="line"><span class="lineno">  378</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aeddfbbe6540f17eea58e0c6c26bb3165" name="aeddfbbe6540f17eea58e0c6c26bb3165"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeddfbbe6540f17eea58e0c6c26bb3165">&#9670;&#160;</a></span>test_countvectorizer_uppercase_in_vocab()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_uppercase_in_vocab </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  435</span><span class="keyword">def </span>test_countvectorizer_uppercase_in_vocab():</div>
<div class="line"><span class="lineno">  436</span>    <span class="comment"># Check that the check for uppercase in the provided vocabulary is only done at fit</span></div>
<div class="line"><span class="lineno">  437</span>    <span class="comment"># time and not at transform time (#21251)</span></div>
<div class="line"><span class="lineno">  438</span>    vocabulary = [<span class="stringliteral">&quot;Sample&quot;</span>, <span class="stringliteral">&quot;Upper&quot;</span>, <span class="stringliteral">&quot;Case&quot;</span>, <span class="stringliteral">&quot;Vocabulary&quot;</span>]</div>
<div class="line"><span class="lineno">  439</span>    message = (</div>
<div class="line"><span class="lineno">  440</span>        <span class="stringliteral">&quot;Upper case characters found in&quot;</span></div>
<div class="line"><span class="lineno">  441</span>        <span class="stringliteral">&quot; vocabulary while &#39;lowercase&#39;&quot;</span></div>
<div class="line"><span class="lineno">  442</span>        <span class="stringliteral">&quot; is True. These entries will not&quot;</span></div>
<div class="line"><span class="lineno">  443</span>        <span class="stringliteral">&quot; be matched with any documents&quot;</span></div>
<div class="line"><span class="lineno">  444</span>    )</div>
<div class="line"><span class="lineno">  445</span> </div>
<div class="line"><span class="lineno">  446</span>    vectorizer = CountVectorizer(lowercase=<span class="keyword">True</span>, vocabulary=vocabulary)</div>
<div class="line"><span class="lineno">  447</span> </div>
<div class="line"><span class="lineno">  448</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=message):</div>
<div class="line"><span class="lineno">  449</span>        vectorizer.fit(vocabulary)</div>
<div class="line"><span class="lineno">  450</span> </div>
<div class="line"><span class="lineno">  451</span>    <span class="keyword">with</span> warnings.catch_warnings():</div>
<div class="line"><span class="lineno">  452</span>        warnings.simplefilter(<span class="stringliteral">&quot;error&quot;</span>, UserWarning)</div>
<div class="line"><span class="lineno">  453</span>        vectorizer.transform(vocabulary)</div>
<div class="line"><span class="lineno">  454</span> </div>
<div class="line"><span class="lineno">  455</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a578af87c6372f402a258e0646de8a0ae" name="a578af87c6372f402a258e0646de8a0ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a578af87c6372f402a258e0646de8a0ae">&#9670;&#160;</a></span>test_countvectorizer_vocab_dicts_when_pickling()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_vocab_dicts_when_pickling </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1127</span><span class="keyword">def </span>test_countvectorizer_vocab_dicts_when_pickling():</div>
<div class="line"><span class="lineno"> 1128</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno"> 1129</span>    vocab_words = np.array(</div>
<div class="line"><span class="lineno"> 1130</span>        [</div>
<div class="line"><span class="lineno"> 1131</span>            <span class="stringliteral">&quot;beer&quot;</span>,</div>
<div class="line"><span class="lineno"> 1132</span>            <span class="stringliteral">&quot;burger&quot;</span>,</div>
<div class="line"><span class="lineno"> 1133</span>            <span class="stringliteral">&quot;celeri&quot;</span>,</div>
<div class="line"><span class="lineno"> 1134</span>            <span class="stringliteral">&quot;coke&quot;</span>,</div>
<div class="line"><span class="lineno"> 1135</span>            <span class="stringliteral">&quot;pizza&quot;</span>,</div>
<div class="line"><span class="lineno"> 1136</span>            <span class="stringliteral">&quot;salad&quot;</span>,</div>
<div class="line"><span class="lineno"> 1137</span>            <span class="stringliteral">&quot;sparkling&quot;</span>,</div>
<div class="line"><span class="lineno"> 1138</span>            <span class="stringliteral">&quot;tomato&quot;</span>,</div>
<div class="line"><span class="lineno"> 1139</span>            <span class="stringliteral">&quot;water&quot;</span>,</div>
<div class="line"><span class="lineno"> 1140</span>        ]</div>
<div class="line"><span class="lineno"> 1141</span>    )</div>
<div class="line"><span class="lineno"> 1142</span>    <span class="keywordflow">for</span> x <span class="keywordflow">in</span> range(0, 100):</div>
<div class="line"><span class="lineno"> 1143</span>        vocab_dict = dict()</div>
<div class="line"><span class="lineno"> 1144</span>        words = rng.choice(vocab_words, size=5, replace=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1145</span>        <span class="keywordflow">for</span> y <span class="keywordflow">in</span> range(0, 5):</div>
<div class="line"><span class="lineno"> 1146</span>            vocab_dict[words[y]] = y</div>
<div class="line"><span class="lineno"> 1147</span>        cv = CountVectorizer(vocabulary=vocab_dict)</div>
<div class="line"><span class="lineno"> 1148</span>        unpickled_cv = pickle.loads(pickle.dumps(cv))</div>
<div class="line"><span class="lineno"> 1149</span>        cv.fit(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1150</span>        unpickled_cv.fit(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1151</span>        assert_array_equal(</div>
<div class="line"><span class="lineno"> 1152</span>            cv.get_feature_names_out(), unpickled_cv.get_feature_names_out()</div>
<div class="line"><span class="lineno"> 1153</span>        )</div>
<div class="line"><span class="lineno"> 1154</span> </div>
<div class="line"><span class="lineno"> 1155</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a57915bb5eada476085c2eb13989c0e98" name="a57915bb5eada476085c2eb13989c0e98"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a57915bb5eada476085c2eb13989c0e98">&#9670;&#160;</a></span>test_countvectorizer_vocab_sets_when_pickling()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_countvectorizer_vocab_sets_when_pickling </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1099</span><span class="keyword">def </span>test_countvectorizer_vocab_sets_when_pickling():</div>
<div class="line"><span class="lineno"> 1100</span>    <span class="comment"># ensure that vocabulary of type set is coerced to a list to</span></div>
<div class="line"><span class="lineno"> 1101</span>    <span class="comment"># preserve iteration ordering after deserialization</span></div>
<div class="line"><span class="lineno"> 1102</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno"> 1103</span>    vocab_words = np.array(</div>
<div class="line"><span class="lineno"> 1104</span>        [</div>
<div class="line"><span class="lineno"> 1105</span>            <span class="stringliteral">&quot;beer&quot;</span>,</div>
<div class="line"><span class="lineno"> 1106</span>            <span class="stringliteral">&quot;burger&quot;</span>,</div>
<div class="line"><span class="lineno"> 1107</span>            <span class="stringliteral">&quot;celeri&quot;</span>,</div>
<div class="line"><span class="lineno"> 1108</span>            <span class="stringliteral">&quot;coke&quot;</span>,</div>
<div class="line"><span class="lineno"> 1109</span>            <span class="stringliteral">&quot;pizza&quot;</span>,</div>
<div class="line"><span class="lineno"> 1110</span>            <span class="stringliteral">&quot;salad&quot;</span>,</div>
<div class="line"><span class="lineno"> 1111</span>            <span class="stringliteral">&quot;sparkling&quot;</span>,</div>
<div class="line"><span class="lineno"> 1112</span>            <span class="stringliteral">&quot;tomato&quot;</span>,</div>
<div class="line"><span class="lineno"> 1113</span>            <span class="stringliteral">&quot;water&quot;</span>,</div>
<div class="line"><span class="lineno"> 1114</span>        ]</div>
<div class="line"><span class="lineno"> 1115</span>    )</div>
<div class="line"><span class="lineno"> 1116</span>    <span class="keywordflow">for</span> x <span class="keywordflow">in</span> range(0, 100):</div>
<div class="line"><span class="lineno"> 1117</span>        vocab_set = set(rng.choice(vocab_words, size=5, replace=<span class="keyword">False</span>))</div>
<div class="line"><span class="lineno"> 1118</span>        cv = CountVectorizer(vocabulary=vocab_set)</div>
<div class="line"><span class="lineno"> 1119</span>        unpickled_cv = pickle.loads(pickle.dumps(cv))</div>
<div class="line"><span class="lineno"> 1120</span>        cv.fit(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1121</span>        unpickled_cv.fit(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1122</span>        assert_array_equal(</div>
<div class="line"><span class="lineno"> 1123</span>            cv.get_feature_names_out(), unpickled_cv.get_feature_names_out()</div>
<div class="line"><span class="lineno"> 1124</span>        )</div>
<div class="line"><span class="lineno"> 1125</span> </div>
<div class="line"><span class="lineno"> 1126</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a61fef55ea8d0101e2dc50395857f13bd" name="a61fef55ea8d0101e2dc50395857f13bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a61fef55ea8d0101e2dc50395857f13bd">&#9670;&#160;</a></span>test_feature_names()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_feature_names </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  683</span><span class="keyword">def </span>test_feature_names():</div>
<div class="line"><span class="lineno">  684</span>    cv = CountVectorizer(max_df=0.5)</div>
<div class="line"><span class="lineno">  685</span> </div>
<div class="line"><span class="lineno">  686</span>    <span class="comment"># test for Value error on unfitted/empty vocabulary</span></div>
<div class="line"><span class="lineno">  687</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  688</span>        cv.get_feature_names_out()</div>
<div class="line"><span class="lineno">  689</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> cv.fixed_vocabulary_</div>
<div class="line"><span class="lineno">  690</span> </div>
<div class="line"><span class="lineno">  691</span>    <span class="comment"># test for vocabulary learned from data</span></div>
<div class="line"><span class="lineno">  692</span>    X = cv.fit_transform(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  693</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  694</span>    <span class="keyword">assert</span> len(cv.vocabulary_) == n_features</div>
<div class="line"><span class="lineno">  695</span> </div>
<div class="line"><span class="lineno">  696</span>    feature_names = cv.get_feature_names_out()</div>
<div class="line"><span class="lineno">  697</span>    <span class="keyword">assert</span> isinstance(feature_names, np.ndarray)</div>
<div class="line"><span class="lineno">  698</span>    <span class="keyword">assert</span> feature_names.dtype == object</div>
<div class="line"><span class="lineno">  699</span> </div>
<div class="line"><span class="lineno">  700</span>    <span class="keyword">assert</span> len(feature_names) == n_features</div>
<div class="line"><span class="lineno">  701</span>    assert_array_equal(</div>
<div class="line"><span class="lineno">  702</span>        [</div>
<div class="line"><span class="lineno">  703</span>            <span class="stringliteral">&quot;beer&quot;</span>,</div>
<div class="line"><span class="lineno">  704</span>            <span class="stringliteral">&quot;burger&quot;</span>,</div>
<div class="line"><span class="lineno">  705</span>            <span class="stringliteral">&quot;celeri&quot;</span>,</div>
<div class="line"><span class="lineno">  706</span>            <span class="stringliteral">&quot;coke&quot;</span>,</div>
<div class="line"><span class="lineno">  707</span>            <span class="stringliteral">&quot;pizza&quot;</span>,</div>
<div class="line"><span class="lineno">  708</span>            <span class="stringliteral">&quot;salad&quot;</span>,</div>
<div class="line"><span class="lineno">  709</span>            <span class="stringliteral">&quot;sparkling&quot;</span>,</div>
<div class="line"><span class="lineno">  710</span>            <span class="stringliteral">&quot;tomato&quot;</span>,</div>
<div class="line"><span class="lineno">  711</span>            <span class="stringliteral">&quot;water&quot;</span>,</div>
<div class="line"><span class="lineno">  712</span>        ],</div>
<div class="line"><span class="lineno">  713</span>        feature_names,</div>
<div class="line"><span class="lineno">  714</span>    )</div>
<div class="line"><span class="lineno">  715</span> </div>
<div class="line"><span class="lineno">  716</span>    <span class="keywordflow">for</span> idx, name <span class="keywordflow">in</span> enumerate(feature_names):</div>
<div class="line"><span class="lineno">  717</span>        <span class="keyword">assert</span> idx == cv.vocabulary_.get(name)</div>
<div class="line"><span class="lineno">  718</span> </div>
<div class="line"><span class="lineno">  719</span>    <span class="comment"># test for custom vocabulary</span></div>
<div class="line"><span class="lineno">  720</span>    vocab = [</div>
<div class="line"><span class="lineno">  721</span>        <span class="stringliteral">&quot;beer&quot;</span>,</div>
<div class="line"><span class="lineno">  722</span>        <span class="stringliteral">&quot;burger&quot;</span>,</div>
<div class="line"><span class="lineno">  723</span>        <span class="stringliteral">&quot;celeri&quot;</span>,</div>
<div class="line"><span class="lineno">  724</span>        <span class="stringliteral">&quot;coke&quot;</span>,</div>
<div class="line"><span class="lineno">  725</span>        <span class="stringliteral">&quot;pizza&quot;</span>,</div>
<div class="line"><span class="lineno">  726</span>        <span class="stringliteral">&quot;salad&quot;</span>,</div>
<div class="line"><span class="lineno">  727</span>        <span class="stringliteral">&quot;sparkling&quot;</span>,</div>
<div class="line"><span class="lineno">  728</span>        <span class="stringliteral">&quot;tomato&quot;</span>,</div>
<div class="line"><span class="lineno">  729</span>        <span class="stringliteral">&quot;water&quot;</span>,</div>
<div class="line"><span class="lineno">  730</span>    ]</div>
<div class="line"><span class="lineno">  731</span> </div>
<div class="line"><span class="lineno">  732</span>    cv = CountVectorizer(vocabulary=vocab)</div>
<div class="line"><span class="lineno">  733</span>    feature_names = cv.get_feature_names_out()</div>
<div class="line"><span class="lineno">  734</span>    assert_array_equal(</div>
<div class="line"><span class="lineno">  735</span>        [</div>
<div class="line"><span class="lineno">  736</span>            <span class="stringliteral">&quot;beer&quot;</span>,</div>
<div class="line"><span class="lineno">  737</span>            <span class="stringliteral">&quot;burger&quot;</span>,</div>
<div class="line"><span class="lineno">  738</span>            <span class="stringliteral">&quot;celeri&quot;</span>,</div>
<div class="line"><span class="lineno">  739</span>            <span class="stringliteral">&quot;coke&quot;</span>,</div>
<div class="line"><span class="lineno">  740</span>            <span class="stringliteral">&quot;pizza&quot;</span>,</div>
<div class="line"><span class="lineno">  741</span>            <span class="stringliteral">&quot;salad&quot;</span>,</div>
<div class="line"><span class="lineno">  742</span>            <span class="stringliteral">&quot;sparkling&quot;</span>,</div>
<div class="line"><span class="lineno">  743</span>            <span class="stringliteral">&quot;tomato&quot;</span>,</div>
<div class="line"><span class="lineno">  744</span>            <span class="stringliteral">&quot;water&quot;</span>,</div>
<div class="line"><span class="lineno">  745</span>        ],</div>
<div class="line"><span class="lineno">  746</span>        feature_names,</div>
<div class="line"><span class="lineno">  747</span>    )</div>
<div class="line"><span class="lineno">  748</span>    <span class="keyword">assert</span> cv.fixed_vocabulary_</div>
<div class="line"><span class="lineno">  749</span> </div>
<div class="line"><span class="lineno">  750</span>    <span class="keywordflow">for</span> idx, name <span class="keywordflow">in</span> enumerate(feature_names):</div>
<div class="line"><span class="lineno">  751</span>        <span class="keyword">assert</span> idx == cv.vocabulary_.get(name)</div>
<div class="line"><span class="lineno">  752</span> </div>
<div class="line"><span class="lineno">  753</span> </div>
<div class="line"><span class="lineno">  754</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Vectorizer&quot;, (CountVectorizer, TfidfVectorizer)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a3c469ae8355251bdb6731e27d8e429e4" name="a3c469ae8355251bdb6731e27d8e429e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3c469ae8355251bdb6731e27d8e429e4">&#9670;&#160;</a></span>test_fit_countvectorizer_twice()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_fit_countvectorizer_twice </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  390</span><span class="keyword">def </span>test_fit_countvectorizer_twice():</div>
<div class="line"><span class="lineno">  391</span>    cv = CountVectorizer()</div>
<div class="line"><span class="lineno">  392</span>    X1 = cv.fit_transform(ALL_FOOD_DOCS[:5])</div>
<div class="line"><span class="lineno">  393</span>    X2 = cv.fit_transform(ALL_FOOD_DOCS[5:])</div>
<div class="line"><span class="lineno">  394</span>    <span class="keyword">assert</span> X1.shape[1] != X2.shape[1]</div>
<div class="line"><span class="lineno">  395</span> </div>
<div class="line"><span class="lineno">  396</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a18e26f99350ac22ab1f24b327afa05d9" name="a18e26f99350ac22ab1f24b327afa05d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18e26f99350ac22ab1f24b327afa05d9">&#9670;&#160;</a></span>test_hashed_binary_occurrences()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_hashed_binary_occurrences </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  867</span><span class="keyword">def </span>test_hashed_binary_occurrences():</div>
<div class="line"><span class="lineno">  868</span>    <span class="comment"># by default multiple occurrences are counted as longs</span></div>
<div class="line"><span class="lineno">  869</span>    test_data = [<span class="stringliteral">&quot;aaabc&quot;</span>, <span class="stringliteral">&quot;abbde&quot;</span>]</div>
<div class="line"><span class="lineno">  870</span>    vect = HashingVectorizer(alternate_sign=<span class="keyword">False</span>, analyzer=<span class="stringliteral">&quot;char&quot;</span>, norm=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  871</span>    X = vect.transform(test_data)</div>
<div class="line"><span class="lineno">  872</span>    <span class="keyword">assert</span> np.max(X[0:1].data) == 3</div>
<div class="line"><span class="lineno">  873</span>    <span class="keyword">assert</span> np.max(X[1:2].data) == 2</div>
<div class="line"><span class="lineno">  874</span>    <span class="keyword">assert</span> X.dtype == np.float64</div>
<div class="line"><span class="lineno">  875</span> </div>
<div class="line"><span class="lineno">  876</span>    <span class="comment"># using boolean features, we can fetch the binary occurrence info</span></div>
<div class="line"><span class="lineno">  877</span>    <span class="comment"># instead.</span></div>
<div class="line"><span class="lineno">  878</span>    vect = HashingVectorizer(</div>
<div class="line"><span class="lineno">  879</span>        analyzer=<span class="stringliteral">&quot;char&quot;</span>, alternate_sign=<span class="keyword">False</span>, binary=<span class="keyword">True</span>, norm=<span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  880</span>    )</div>
<div class="line"><span class="lineno">  881</span>    X = vect.transform(test_data)</div>
<div class="line"><span class="lineno">  882</span>    <span class="keyword">assert</span> np.max(X.data) == 1</div>
<div class="line"><span class="lineno">  883</span>    <span class="keyword">assert</span> X.dtype == np.float64</div>
<div class="line"><span class="lineno">  884</span> </div>
<div class="line"><span class="lineno">  885</span>    <span class="comment"># check the ability to change the dtype</span></div>
<div class="line"><span class="lineno">  886</span>    vect = HashingVectorizer(</div>
<div class="line"><span class="lineno">  887</span>        analyzer=<span class="stringliteral">&quot;char&quot;</span>, alternate_sign=<span class="keyword">False</span>, binary=<span class="keyword">True</span>, norm=<span class="keywordtype">None</span>, dtype=np.float64</div>
<div class="line"><span class="lineno">  888</span>    )</div>
<div class="line"><span class="lineno">  889</span>    X = vect.transform(test_data)</div>
<div class="line"><span class="lineno">  890</span>    <span class="keyword">assert</span> X.dtype == np.float64</div>
<div class="line"><span class="lineno">  891</span> </div>
<div class="line"><span class="lineno">  892</span> </div>
<div class="line"><span class="lineno">  893</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Vectorizer&quot;, (CountVectorizer, TfidfVectorizer)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a6378116402e9f8d538d0b4183b6614ff" name="a6378116402e9f8d538d0b4183b6614ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6378116402e9f8d538d0b4183b6614ff">&#9670;&#160;</a></span>test_hashing_vectorizer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_hashing_vectorizer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  645</span><span class="keyword">def </span>test_hashing_vectorizer():</div>
<div class="line"><span class="lineno">  646</span>    v = HashingVectorizer()</div>
<div class="line"><span class="lineno">  647</span>    X = v.transform(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  648</span>    token_nnz = X.nnz</div>
<div class="line"><span class="lineno">  649</span>    <span class="keyword">assert</span> X.shape == (len(ALL_FOOD_DOCS), v.n_features)</div>
<div class="line"><span class="lineno">  650</span>    <span class="keyword">assert</span> X.dtype == v.dtype</div>
<div class="line"><span class="lineno">  651</span> </div>
<div class="line"><span class="lineno">  652</span>    <span class="comment"># By default the hashed values receive a random sign and l2 normalization</span></div>
<div class="line"><span class="lineno">  653</span>    <span class="comment"># makes the feature values bounded</span></div>
<div class="line"><span class="lineno">  654</span>    <span class="keyword">assert</span> np.min(X.data) &gt; -1</div>
<div class="line"><span class="lineno">  655</span>    <span class="keyword">assert</span> np.min(X.data) &lt; 0</div>
<div class="line"><span class="lineno">  656</span>    <span class="keyword">assert</span> np.max(X.data) &gt; 0</div>
<div class="line"><span class="lineno">  657</span>    <span class="keyword">assert</span> np.max(X.data) &lt; 1</div>
<div class="line"><span class="lineno">  658</span> </div>
<div class="line"><span class="lineno">  659</span>    <span class="comment"># Check that the rows are normalized</span></div>
<div class="line"><span class="lineno">  660</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(X.shape[0]):</div>
<div class="line"><span class="lineno">  661</span>        assert_almost_equal(np.linalg.norm(X[0].data, 2), 1.0)</div>
<div class="line"><span class="lineno">  662</span> </div>
<div class="line"><span class="lineno">  663</span>    <span class="comment"># Check vectorization with some non-default parameters</span></div>
<div class="line"><span class="lineno">  664</span>    v = HashingVectorizer(ngram_range=(1, 2), norm=<span class="stringliteral">&quot;l1&quot;</span>)</div>
<div class="line"><span class="lineno">  665</span>    X = v.transform(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  666</span>    <span class="keyword">assert</span> X.shape == (len(ALL_FOOD_DOCS), v.n_features)</div>
<div class="line"><span class="lineno">  667</span>    <span class="keyword">assert</span> X.dtype == v.dtype</div>
<div class="line"><span class="lineno">  668</span> </div>
<div class="line"><span class="lineno">  669</span>    <span class="comment"># ngrams generate more non zeros</span></div>
<div class="line"><span class="lineno">  670</span>    ngrams_nnz = X.nnz</div>
<div class="line"><span class="lineno">  671</span>    <span class="keyword">assert</span> ngrams_nnz &gt; token_nnz</div>
<div class="line"><span class="lineno">  672</span>    <span class="keyword">assert</span> ngrams_nnz &lt; 2 * token_nnz</div>
<div class="line"><span class="lineno">  673</span> </div>
<div class="line"><span class="lineno">  674</span>    <span class="comment"># makes the feature values bounded</span></div>
<div class="line"><span class="lineno">  675</span>    <span class="keyword">assert</span> np.min(X.data) &gt; -1</div>
<div class="line"><span class="lineno">  676</span>    <span class="keyword">assert</span> np.max(X.data) &lt; 1</div>
<div class="line"><span class="lineno">  677</span> </div>
<div class="line"><span class="lineno">  678</span>    <span class="comment"># Check that the rows are normalized</span></div>
<div class="line"><span class="lineno">  679</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(X.shape[0]):</div>
<div class="line"><span class="lineno">  680</span>        assert_almost_equal(np.linalg.norm(X[0].data, 1), 1.0)</div>
<div class="line"><span class="lineno">  681</span> </div>
<div class="line"><span class="lineno">  682</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae5bf76b02c01e7fa888d35582cfeb4bc" name="ae5bf76b02c01e7fa888d35582cfeb4bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5bf76b02c01e7fa888d35582cfeb4bc">&#9670;&#160;</a></span>test_hashingvectorizer_nan_in_docs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_hashingvectorizer_nan_in_docs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1229</span><span class="keyword">def </span>test_hashingvectorizer_nan_in_docs():</div>
<div class="line"><span class="lineno"> 1230</span>    <span class="comment"># np.nan can appear when using pandas to load text fields from a csv file</span></div>
<div class="line"><span class="lineno"> 1231</span>    <span class="comment"># with missing values.</span></div>
<div class="line"><span class="lineno"> 1232</span>    message = <span class="stringliteral">&quot;np.nan is an invalid document, expected byte or unicode string.&quot;</span></div>
<div class="line"><span class="lineno"> 1233</span>    exception = ValueError</div>
<div class="line"><span class="lineno"> 1234</span> </div>
<div class="line"><span class="lineno"> 1235</span>    <span class="keyword">def </span><a class="code hl_function" href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a>():</div>
<div class="line"><span class="lineno"> 1236</span>        hv = HashingVectorizer()</div>
<div class="line"><span class="lineno"> 1237</span>        hv.fit_transform([<span class="stringliteral">&quot;hello world&quot;</span>, np.nan, <span class="stringliteral">&quot;hello hello&quot;</span>])</div>
<div class="line"><span class="lineno"> 1238</span> </div>
<div class="line"><span class="lineno"> 1239</span>    <span class="keyword">with</span> pytest.raises(exception, match=message):</div>
<div class="line"><span class="lineno"> 1240</span>        <a class="code hl_function" href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a>()</div>
<div class="line"><span class="lineno"> 1241</span> </div>
<div class="line"><span class="lineno"> 1242</span> </div>
<div class="ttc" id="acallback_2foo_8f_html_a565fe2cc583df102f120752b0011c330"><div class="ttname"><a href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a></div><div class="ttdeci">subroutine func(a)</div><div class="ttdef"><b>Definition</b> foo.f:9</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab956f75c4aa43ee851b7bb96b9ea28f3" name="ab956f75c4aa43ee851b7bb96b9ea28f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab956f75c4aa43ee851b7bb96b9ea28f3">&#9670;&#160;</a></span>test_n_features_in()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_n_features_in </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Vectorizer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1616</span><span class="keyword">def </span>test_n_features_in(Vectorizer, X):</div>
<div class="line"><span class="lineno"> 1617</span>    <span class="comment"># For vectorizers, n_features_in_ does not make sense</span></div>
<div class="line"><span class="lineno"> 1618</span>    vectorizer = Vectorizer()</div>
<div class="line"><span class="lineno"> 1619</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> hasattr(vectorizer, <span class="stringliteral">&quot;n_features_in_&quot;</span>)</div>
<div class="line"><span class="lineno"> 1620</span>    vectorizer.fit(X)</div>
<div class="line"><span class="lineno"> 1621</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> hasattr(vectorizer, <span class="stringliteral">&quot;n_features_in_&quot;</span>)</div>
<div class="line"><span class="lineno"> 1622</span> </div>
<div class="line"><span class="lineno"> 1623</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4b890cdd89eac66e68f42cc0cf137270" name="a4b890cdd89eac66e68f42cc0cf137270"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4b890cdd89eac66e68f42cc0cf137270">&#9670;&#160;</a></span>test_non_unique_vocab()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_non_unique_vocab </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1221</span><span class="keyword">def </span>test_non_unique_vocab():</div>
<div class="line"><span class="lineno"> 1222</span>    vocab = [<span class="stringliteral">&quot;a&quot;</span>, <span class="stringliteral">&quot;b&quot;</span>, <span class="stringliteral">&quot;c&quot;</span>, <span class="stringliteral">&quot;a&quot;</span>, <span class="stringliteral">&quot;a&quot;</span>]</div>
<div class="line"><span class="lineno"> 1223</span>    vect = CountVectorizer(vocabulary=vocab)</div>
<div class="line"><span class="lineno"> 1224</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno"> 1225</span>        vect.fit([])</div>
<div class="line"><span class="lineno"> 1226</span> </div>
<div class="line"><span class="lineno"> 1227</span> </div>
<div class="line"><span class="lineno"> 1228</span><span class="preprocessor">@fails_if_pypy</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a4c78e5a70e8318efc28bdf22895ba5c4" name="a4c78e5a70e8318efc28bdf22895ba5c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c78e5a70e8318efc28bdf22895ba5c4">&#9670;&#160;</a></span>test_nonnegative_hashing_vectorizer_result_indices()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_nonnegative_hashing_vectorizer_result_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1634</span><span class="keyword">def </span>test_nonnegative_hashing_vectorizer_result_indices():</div>
<div class="line"><span class="lineno"> 1635</span>    <span class="comment"># add test for pr 19035</span></div>
<div class="line"><span class="lineno"> 1636</span>    hashing = HashingVectorizer(n_features=1000000, ngram_range=(2, 3))</div>
<div class="line"><span class="lineno"> 1637</span>    indices = hashing.transform([<span class="stringliteral">&quot;22pcs efuture&quot;</span>]).indices</div>
<div class="line"><span class="lineno"> 1638</span>    <span class="keyword">assert</span> indices[0] &gt;= 0</div>
<div class="line"><span class="lineno"> 1639</span> </div>
<div class="line"><span class="lineno"> 1640</span> </div>
<div class="line"><span class="lineno"> 1641</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1642</span>    <span class="stringliteral">&quot;Estimator&quot;</span>, [CountVectorizer, TfidfVectorizer, TfidfTransformer, HashingVectorizer]</div>
<div class="line"><span class="lineno"> 1643</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae36066f25159e8b99ceb1e4b71911346" name="ae36066f25159e8b99ceb1e4b71911346"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae36066f25159e8b99ceb1e4b71911346">&#9670;&#160;</a></span>test_pickling_built_processors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_pickling_built_processors </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>factory</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Tokenizers cannot be pickled
https://github.com/scikit-learn/scikit-learn/issues/12833
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1086</span><span class="keyword">def </span>test_pickling_built_processors(factory):</div>
<div class="line"><span class="lineno"> 1087</span>    <span class="stringliteral">&quot;&quot;&quot;Tokenizers cannot be pickled</span></div>
<div class="line"><span class="lineno"> 1088</span><span class="stringliteral">    https://github.com/scikit-learn/scikit-learn/issues/12833</span></div>
<div class="line"><span class="lineno"> 1089</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1090</span>    vec = CountVectorizer()</div>
<div class="line"><span class="lineno"> 1091</span>    function = factory(vec)</div>
<div class="line"><span class="lineno"> 1092</span>    text = <span class="stringliteral">&quot;J&#39;ai mangÃ© du kangourou  ce midi, c&#39;Ã©tait pas trÃ¨s bon.&quot;</span></div>
<div class="line"><span class="lineno"> 1093</span>    roundtripped_function = pickle.loads(pickle.dumps(function))</div>
<div class="line"><span class="lineno"> 1094</span>    expected = function(text)</div>
<div class="line"><span class="lineno"> 1095</span>    result = roundtripped_function(text)</div>
<div class="line"><span class="lineno"> 1096</span>    <span class="keyword">assert</span> result == expected</div>
<div class="line"><span class="lineno"> 1097</span> </div>
<div class="line"><span class="lineno"> 1098</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae95543f5e850e0f686e1a1828a786961" name="ae95543f5e850e0f686e1a1828a786961"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae95543f5e850e0f686e1a1828a786961">&#9670;&#160;</a></span>test_pickling_transformer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_pickling_transformer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1178</span><span class="keyword">def </span>test_pickling_transformer():</div>
<div class="line"><span class="lineno"> 1179</span>    X = CountVectorizer().fit_transform(JUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1180</span>    orig = TfidfTransformer().fit(X)</div>
<div class="line"><span class="lineno"> 1181</span>    s = pickle.dumps(orig)</div>
<div class="line"><span class="lineno"> 1182</span>    copy = pickle.loads(s)</div>
<div class="line"><span class="lineno"> 1183</span>    <span class="keyword">assert</span> type(copy) == orig.__class__</div>
<div class="line"><span class="lineno"> 1184</span>    assert_array_equal(copy.fit_transform(X).toarray(), orig.fit_transform(X).toarray())</div>
<div class="line"><span class="lineno"> 1185</span> </div>
<div class="line"><span class="lineno"> 1186</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa9663f5bb3ff28a71659cee9cea44950" name="aa9663f5bb3ff28a71659cee9cea44950"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa9663f5bb3ff28a71659cee9cea44950">&#9670;&#160;</a></span>test_pickling_vectorizer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_pickling_vectorizer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1048</span><span class="keyword">def </span>test_pickling_vectorizer():</div>
<div class="line"><span class="lineno"> 1049</span>    instances = [</div>
<div class="line"><span class="lineno"> 1050</span>        HashingVectorizer(),</div>
<div class="line"><span class="lineno"> 1051</span>        HashingVectorizer(norm=<span class="stringliteral">&quot;l1&quot;</span>),</div>
<div class="line"><span class="lineno"> 1052</span>        HashingVectorizer(binary=<span class="keyword">True</span>),</div>
<div class="line"><span class="lineno"> 1053</span>        HashingVectorizer(ngram_range=(1, 2)),</div>
<div class="line"><span class="lineno"> 1054</span>        CountVectorizer(),</div>
<div class="line"><span class="lineno"> 1055</span>        CountVectorizer(preprocessor=strip_tags),</div>
<div class="line"><span class="lineno"> 1056</span>        CountVectorizer(analyzer=lazy_analyze),</div>
<div class="line"><span class="lineno"> 1057</span>        CountVectorizer(preprocessor=strip_tags).fit(JUNK_FOOD_DOCS),</div>
<div class="line"><span class="lineno"> 1058</span>        CountVectorizer(strip_accents=strip_eacute).fit(JUNK_FOOD_DOCS),</div>
<div class="line"><span class="lineno"> 1059</span>        TfidfVectorizer(),</div>
<div class="line"><span class="lineno"> 1060</span>        TfidfVectorizer(analyzer=lazy_analyze),</div>
<div class="line"><span class="lineno"> 1061</span>        TfidfVectorizer().fit(JUNK_FOOD_DOCS),</div>
<div class="line"><span class="lineno"> 1062</span>    ]</div>
<div class="line"><span class="lineno"> 1063</span> </div>
<div class="line"><span class="lineno"> 1064</span>    <span class="keywordflow">for</span> orig <span class="keywordflow">in</span> instances:</div>
<div class="line"><span class="lineno"> 1065</span>        s = pickle.dumps(orig)</div>
<div class="line"><span class="lineno"> 1066</span>        copy = pickle.loads(s)</div>
<div class="line"><span class="lineno"> 1067</span>        <span class="keyword">assert</span> type(copy) == orig.__class__</div>
<div class="line"><span class="lineno"> 1068</span>        <span class="keyword">assert</span> copy.get_params() == orig.get_params()</div>
<div class="line"><span class="lineno"> 1069</span>        <span class="keywordflow">if</span> IS_PYPY <span class="keywordflow">and</span> isinstance(orig, HashingVectorizer):</div>
<div class="line"><span class="lineno"> 1070</span>            <span class="keywordflow">continue</span></div>
<div class="line"><span class="lineno"> 1071</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1072</span>            assert_allclose_dense_sparse(</div>
<div class="line"><span class="lineno"> 1073</span>                copy.fit_transform(JUNK_FOOD_DOCS),</div>
<div class="line"><span class="lineno"> 1074</span>                orig.fit_transform(JUNK_FOOD_DOCS),</div>
<div class="line"><span class="lineno"> 1075</span>            )</div>
<div class="line"><span class="lineno"> 1076</span> </div>
<div class="line"><span class="lineno"> 1077</span> </div>
<div class="line"><span class="lineno"> 1078</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1079</span>    <span class="stringliteral">&quot;factory&quot;</span>,</div>
<div class="line"><span class="lineno"> 1080</span>    [</div>
<div class="line"><span class="lineno"> 1081</span>        CountVectorizer.build_analyzer,</div>
<div class="line"><span class="lineno"> 1082</span>        CountVectorizer.build_preprocessor,</div>
<div class="line"><span class="lineno"> 1083</span>        CountVectorizer.build_tokenizer,</div>
<div class="line"><span class="lineno"> 1084</span>    ],</div>
<div class="line"><span class="lineno"> 1085</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a7010fc7ba8e0a8e20579ffad66068304" name="a7010fc7ba8e0a8e20579ffad66068304"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7010fc7ba8e0a8e20579ffad66068304">&#9670;&#160;</a></span>test_stop_word_validation_custom_preprocessor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_stop_word_validation_custom_preprocessor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Estimator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1422</span><span class="keyword">def </span>test_stop_word_validation_custom_preprocessor(Estimator):</div>
<div class="line"><span class="lineno"> 1423</span>    data = [{<span class="stringliteral">&quot;text&quot;</span>: <span class="stringliteral">&quot;some text&quot;</span>}]</div>
<div class="line"><span class="lineno"> 1424</span> </div>
<div class="line"><span class="lineno"> 1425</span>    vec = Estimator()</div>
<div class="line"><span class="lineno"> 1426</span>    <span class="keyword">assert</span> _check_stop_words_consistency(vec) <span class="keywordflow">is</span> <span class="keyword">True</span></div>
<div class="line"><span class="lineno"> 1427</span> </div>
<div class="line"><span class="lineno"> 1428</span>    vec = Estimator(preprocessor=<span class="keyword">lambda</span> x: x[<span class="stringliteral">&quot;text&quot;</span>], stop_words=[<span class="stringliteral">&quot;and&quot;</span>])</div>
<div class="line"><span class="lineno"> 1429</span>    <span class="keyword">assert</span> _check_stop_words_consistency(vec) == <span class="stringliteral">&quot;error&quot;</span></div>
<div class="line"><span class="lineno"> 1430</span>    <span class="comment"># checks are cached</span></div>
<div class="line"><span class="lineno"> 1431</span>    <span class="keyword">assert</span> _check_stop_words_consistency(vec) <span class="keywordflow">is</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1432</span>    vec.fit_transform(data)</div>
<div class="line"><span class="lineno"> 1433</span> </div>
<div class="line"><span class="lineno"> 1434</span>    <span class="keyword">class </span>CustomEstimator(Estimator):</div>
<div class="line"><span class="lineno"> 1435</span>        <span class="keyword">def </span>build_preprocessor(self):</div>
<div class="line"><span class="lineno"> 1436</span>            <span class="keywordflow">return</span> <span class="keyword">lambda</span> x: x[<span class="stringliteral">&quot;text&quot;</span>]</div>
<div class="line"><span class="lineno"> 1437</span> </div>
<div class="line"><span class="lineno"> 1438</span>    vec = CustomEstimator(stop_words=[<span class="stringliteral">&quot;and&quot;</span>])</div>
<div class="line"><span class="lineno"> 1439</span>    <span class="keyword">assert</span> _check_stop_words_consistency(vec) == <span class="stringliteral">&quot;error&quot;</span></div>
<div class="line"><span class="lineno"> 1440</span> </div>
<div class="line"><span class="lineno"> 1441</span>    vec = Estimator(</div>
<div class="line"><span class="lineno"> 1442</span>        tokenizer=<span class="keyword">lambda</span> doc: re.compile(<span class="stringliteral">r&quot;\w{1,}&quot;</span>).findall(doc), stop_words=[<span class="stringliteral">&quot;and&quot;</span>]</div>
<div class="line"><span class="lineno"> 1443</span>    )</div>
<div class="line"><span class="lineno"> 1444</span>    <span class="keyword">assert</span> _check_stop_words_consistency(vec) <span class="keywordflow">is</span> <span class="keyword">True</span></div>
<div class="line"><span class="lineno"> 1445</span> </div>
<div class="line"><span class="lineno"> 1446</span> </div>
<div class="line"><span class="lineno"> 1447</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1448</span>    <span class="stringliteral">&quot;Estimator&quot;</span>, [CountVectorizer, TfidfVectorizer, HashingVectorizer]</div>
<div class="line"><span class="lineno"> 1449</span>)</div>
<div class="line"><span class="lineno"> 1450</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1451</span>    <span class="stringliteral">&quot;input_type, err_type, err_msg&quot;</span>,</div>
<div class="line"><span class="lineno"> 1452</span>    [</div>
<div class="line"><span class="lineno"> 1453</span>        (<span class="stringliteral">&quot;filename&quot;</span>, FileNotFoundError, <span class="stringliteral">&quot;&quot;</span>),</div>
<div class="line"><span class="lineno"> 1454</span>        (<span class="stringliteral">&quot;file&quot;</span>, AttributeError, <span class="stringliteral">&quot;&#39;str&#39; object has no attribute &#39;read&#39;&quot;</span>),</div>
<div class="line"><span class="lineno"> 1455</span>    ],</div>
<div class="line"><span class="lineno"> 1456</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="af9d0383f97fd86a08d2655b24c09be1c" name="af9d0383f97fd86a08d2655b24c09be1c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af9d0383f97fd86a08d2655b24c09be1c">&#9670;&#160;</a></span>test_stop_words_removal()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_stop_words_removal </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1156</span><span class="keyword">def </span>test_stop_words_removal():</div>
<div class="line"><span class="lineno"> 1157</span>    <span class="comment"># Ensure that deleting the stop_words_ attribute doesn&#39;t affect transform</span></div>
<div class="line"><span class="lineno"> 1158</span> </div>
<div class="line"><span class="lineno"> 1159</span>    fitted_vectorizers = (</div>
<div class="line"><span class="lineno"> 1160</span>        TfidfVectorizer().fit(JUNK_FOOD_DOCS),</div>
<div class="line"><span class="lineno"> 1161</span>        CountVectorizer(preprocessor=strip_tags).fit(JUNK_FOOD_DOCS),</div>
<div class="line"><span class="lineno"> 1162</span>        CountVectorizer(strip_accents=strip_eacute).fit(JUNK_FOOD_DOCS),</div>
<div class="line"><span class="lineno"> 1163</span>    )</div>
<div class="line"><span class="lineno"> 1164</span> </div>
<div class="line"><span class="lineno"> 1165</span>    <span class="keywordflow">for</span> vect <span class="keywordflow">in</span> fitted_vectorizers:</div>
<div class="line"><span class="lineno"> 1166</span>        vect_transform = vect.transform(JUNK_FOOD_DOCS).toarray()</div>
<div class="line"><span class="lineno"> 1167</span> </div>
<div class="line"><span class="lineno"> 1168</span>        vect.stop_words_ = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1169</span>        stop_None_transform = vect.transform(JUNK_FOOD_DOCS).toarray()</div>
<div class="line"><span class="lineno"> 1170</span> </div>
<div class="line"><span class="lineno"> 1171</span>        delattr(vect, <span class="stringliteral">&quot;stop_words_&quot;</span>)</div>
<div class="line"><span class="lineno"> 1172</span>        stop_del_transform = vect.transform(JUNK_FOOD_DOCS).toarray()</div>
<div class="line"><span class="lineno"> 1173</span> </div>
<div class="line"><span class="lineno"> 1174</span>        assert_array_equal(stop_None_transform, vect_transform)</div>
<div class="line"><span class="lineno"> 1175</span>        assert_array_equal(stop_del_transform, vect_transform)</div>
<div class="line"><span class="lineno"> 1176</span> </div>
<div class="line"><span class="lineno"> 1177</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3fd054341f4779df1465e511f47c2852" name="a3fd054341f4779df1465e511f47c2852"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3fd054341f4779df1465e511f47c2852">&#9670;&#160;</a></span>test_strip_accents()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_strip_accents </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   78</span><span class="keyword">def </span>test_strip_accents():</div>
<div class="line"><span class="lineno">   79</span>    <span class="comment"># check some classical latin accentuated symbols</span></div>
<div class="line"><span class="lineno">   80</span>    a = <span class="stringliteral">&quot;Ã Ã¡Ã¢Ã£Ã¤Ã¥Ã§Ã¨Ã©ÃªÃ«&quot;</span></div>
<div class="line"><span class="lineno">   81</span>    expected = <span class="stringliteral">&quot;aaaaaaceeee&quot;</span></div>
<div class="line"><span class="lineno">   82</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><span class="lineno">   83</span> </div>
<div class="line"><span class="lineno">   84</span>    a = <span class="stringliteral">&quot;Ã¬Ã­Ã®Ã¯Ã±Ã²Ã³Ã´ÃµÃ¶Ã¹ÃºÃ»Ã¼Ã½&quot;</span></div>
<div class="line"><span class="lineno">   85</span>    expected = <span class="stringliteral">&quot;iiiinooooouuuuy&quot;</span></div>
<div class="line"><span class="lineno">   86</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><span class="lineno">   87</span> </div>
<div class="line"><span class="lineno">   88</span>    <span class="comment"># check some arabic</span></div>
<div class="line"><span class="lineno">   89</span>    a = <span class="stringliteral">&quot;\u0625&quot;</span>  <span class="comment"># alef with a hamza below: Ø¥</span></div>
<div class="line"><span class="lineno">   90</span>    expected = <span class="stringliteral">&quot;\u0627&quot;</span>  <span class="comment"># simple alef: Ø§</span></div>
<div class="line"><span class="lineno">   91</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><span class="lineno">   92</span> </div>
<div class="line"><span class="lineno">   93</span>    <span class="comment"># mix letters accentuated and not</span></div>
<div class="line"><span class="lineno">   94</span>    a = <span class="stringliteral">&quot;this is Ã  test&quot;</span></div>
<div class="line"><span class="lineno">   95</span>    expected = <span class="stringliteral">&quot;this is a test&quot;</span></div>
<div class="line"><span class="lineno">   96</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><span class="lineno">   97</span> </div>
<div class="line"><span class="lineno">   98</span>    <span class="comment"># strings that are already decomposed</span></div>
<div class="line"><span class="lineno">   99</span>    a = <span class="stringliteral">&quot;o\u0308&quot;</span>  <span class="comment"># o with diaeresis</span></div>
<div class="line"><span class="lineno">  100</span>    expected = <span class="stringliteral">&quot;o&quot;</span></div>
<div class="line"><span class="lineno">  101</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><span class="lineno">  102</span> </div>
<div class="line"><span class="lineno">  103</span>    <span class="comment"># combining marks by themselves</span></div>
<div class="line"><span class="lineno">  104</span>    a = <span class="stringliteral">&quot;\u0300\u0301\u0302\u0303&quot;</span></div>
<div class="line"><span class="lineno">  105</span>    expected = <span class="stringliteral">&quot;&quot;</span></div>
<div class="line"><span class="lineno">  106</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><span class="lineno">  107</span> </div>
<div class="line"><span class="lineno">  108</span>    <span class="comment"># Multiple combining marks on one character</span></div>
<div class="line"><span class="lineno">  109</span>    a = <span class="stringliteral">&quot;o\u0308\u0304&quot;</span></div>
<div class="line"><span class="lineno">  110</span>    expected = <span class="stringliteral">&quot;o&quot;</span></div>
<div class="line"><span class="lineno">  111</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><span class="lineno">  112</span> </div>
<div class="line"><span class="lineno">  113</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a45a9378977cacaa682a5e7391f1a70c7" name="a45a9378977cacaa682a5e7391f1a70c7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45a9378977cacaa682a5e7391f1a70c7">&#9670;&#160;</a></span>test_sublinear_tf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_sublinear_tf </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  501</span><span class="keyword">def </span>test_sublinear_tf():</div>
<div class="line"><span class="lineno">  502</span>    X = [[1], [2], [3]]</div>
<div class="line"><span class="lineno">  503</span>    tr = TfidfTransformer(sublinear_tf=<span class="keyword">True</span>, use_idf=<span class="keyword">False</span>, norm=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  504</span>    tfidf = tr.fit_transform(X).toarray()</div>
<div class="line"><span class="lineno">  505</span>    <span class="keyword">assert</span> tfidf[0] == 1</div>
<div class="line"><span class="lineno">  506</span>    <span class="keyword">assert</span> tfidf[1] &gt; tfidf[0]</div>
<div class="line"><span class="lineno">  507</span>    <span class="keyword">assert</span> tfidf[2] &gt; tfidf[1]</div>
<div class="line"><span class="lineno">  508</span>    <span class="keyword">assert</span> tfidf[1] &lt; 2</div>
<div class="line"><span class="lineno">  509</span>    <span class="keyword">assert</span> tfidf[2] &lt; 3</div>
<div class="line"><span class="lineno">  510</span> </div>
<div class="line"><span class="lineno">  511</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae3cee4f88b496ba3dab4071c5ac6342d" name="ae3cee4f88b496ba3dab4071c5ac6342d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae3cee4f88b496ba3dab4071c5ac6342d">&#9670;&#160;</a></span>test_tf_idf_smoothing()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tf_idf_smoothing </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  466</span><span class="keyword">def </span>test_tf_idf_smoothing():</div>
<div class="line"><span class="lineno">  467</span>    X = [[1, 1, 1], [1, 1, 0], [1, 0, 0]]</div>
<div class="line"><span class="lineno">  468</span>    tr = TfidfTransformer(smooth_idf=<span class="keyword">True</span>, norm=<span class="stringliteral">&quot;l2&quot;</span>)</div>
<div class="line"><span class="lineno">  469</span>    tfidf = tr.fit_transform(X).toarray()</div>
<div class="line"><span class="lineno">  470</span>    <span class="keyword">assert</span> (tfidf &gt;= 0).all()</div>
<div class="line"><span class="lineno">  471</span> </div>
<div class="line"><span class="lineno">  472</span>    <span class="comment"># check normalization</span></div>
<div class="line"><span class="lineno">  473</span>    assert_array_almost_equal((tfidf**2).sum(axis=1), [1.0, 1.0, 1.0])</div>
<div class="line"><span class="lineno">  474</span> </div>
<div class="line"><span class="lineno">  475</span>    <span class="comment"># this is robust to features with only zeros</span></div>
<div class="line"><span class="lineno">  476</span>    X = [[1, 1, 0], [1, 1, 0], [1, 0, 0]]</div>
<div class="line"><span class="lineno">  477</span>    tr = TfidfTransformer(smooth_idf=<span class="keyword">True</span>, norm=<span class="stringliteral">&quot;l2&quot;</span>)</div>
<div class="line"><span class="lineno">  478</span>    tfidf = tr.fit_transform(X).toarray()</div>
<div class="line"><span class="lineno">  479</span>    <span class="keyword">assert</span> (tfidf &gt;= 0).all()</div>
<div class="line"><span class="lineno">  480</span> </div>
<div class="line"><span class="lineno">  481</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a557512858124fb8cd8ac2369d112b4c1" name="a557512858124fb8cd8ac2369d112b4c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a557512858124fb8cd8ac2369d112b4c1">&#9670;&#160;</a></span>test_tf_transformer_feature_names_out()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tf_transformer_feature_names_out </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check get_feature_names_out for TfidfTransformer</pre> <div class="fragment"><div class="line"><span class="lineno">  456</span><span class="keyword">def </span>test_tf_transformer_feature_names_out():</div>
<div class="line"><span class="lineno">  457</span>    <span class="stringliteral">&quot;&quot;&quot;Check get_feature_names_out for TfidfTransformer&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  458</span><span class="stringliteral">    X = [[1, 1, 1], [1, 1, 0], [1, 0, 0]]</span></div>
<div class="line"><span class="lineno">  459</span><span class="stringliteral">    tr = TfidfTransformer(smooth_idf=True, norm=&quot;l2&quot;).fit(X)</span></div>
<div class="line"><span class="lineno">  460</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  461</span><span class="stringliteral">    feature_names_in = [&quot;a&quot;, &quot;c&quot;, &quot;b&quot;]</span></div>
<div class="line"><span class="lineno">  462</span><span class="stringliteral">    feature_names_out = tr.get_feature_names_out(feature_names_in)</span></div>
<div class="line"><span class="lineno">  463</span><span class="stringliteral">    assert_array_equal(feature_names_in, feature_names_out)</span></div>
<div class="line"><span class="lineno">  464</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  465</span><span class="stringliteral"></span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae446719b16cb9c120b5c7eb2476d2b64" name="ae446719b16cb9c120b5c7eb2476d2b64"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae446719b16cb9c120b5c7eb2476d2b64">&#9670;&#160;</a></span>test_tfidf_no_smoothing()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tfidf_no_smoothing </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  482</span><span class="keyword">def </span>test_tfidf_no_smoothing():</div>
<div class="line"><span class="lineno">  483</span>    X = [[1, 1, 1], [1, 1, 0], [1, 0, 0]]</div>
<div class="line"><span class="lineno">  484</span>    tr = TfidfTransformer(smooth_idf=<span class="keyword">False</span>, norm=<span class="stringliteral">&quot;l2&quot;</span>)</div>
<div class="line"><span class="lineno">  485</span>    tfidf = tr.fit_transform(X).toarray()</div>
<div class="line"><span class="lineno">  486</span>    <span class="keyword">assert</span> (tfidf &gt;= 0).all()</div>
<div class="line"><span class="lineno">  487</span> </div>
<div class="line"><span class="lineno">  488</span>    <span class="comment"># check normalization</span></div>
<div class="line"><span class="lineno">  489</span>    assert_array_almost_equal((tfidf**2).sum(axis=1), [1.0, 1.0, 1.0])</div>
<div class="line"><span class="lineno">  490</span> </div>
<div class="line"><span class="lineno">  491</span>    <span class="comment"># the lack of smoothing make IDF fragile in the presence of feature with</span></div>
<div class="line"><span class="lineno">  492</span>    <span class="comment"># only zeros</span></div>
<div class="line"><span class="lineno">  493</span>    X = [[1, 1, 0], [1, 1, 0], [1, 0, 0]]</div>
<div class="line"><span class="lineno">  494</span>    tr = TfidfTransformer(smooth_idf=<span class="keyword">False</span>, norm=<span class="stringliteral">&quot;l2&quot;</span>)</div>
<div class="line"><span class="lineno">  495</span> </div>
<div class="line"><span class="lineno">  496</span>    in_warning_message = <span class="stringliteral">&quot;divide by zero&quot;</span></div>
<div class="line"><span class="lineno">  497</span>    <span class="keyword">with</span> pytest.warns(RuntimeWarning, match=in_warning_message):</div>
<div class="line"><span class="lineno">  498</span>        tr.fit_transform(X).toarray()</div>
<div class="line"><span class="lineno">  499</span> </div>
<div class="line"><span class="lineno">  500</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae44d47cbb762da7c4d12271b226d4015" name="ae44d47cbb762da7c4d12271b226d4015"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae44d47cbb762da7c4d12271b226d4015">&#9670;&#160;</a></span>test_tfidf_transformer_sparse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tfidf_transformer_sparse </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1293</span><span class="keyword">def </span>test_tfidf_transformer_sparse():</div>
<div class="line"><span class="lineno"> 1294</span>    X = sparse.rand(10, 20000, dtype=np.float64, random_state=42)</div>
<div class="line"><span class="lineno"> 1295</span>    X_csc = sparse.csc_matrix(X)</div>
<div class="line"><span class="lineno"> 1296</span>    X_csr = sparse.csr_matrix(X)</div>
<div class="line"><span class="lineno"> 1297</span> </div>
<div class="line"><span class="lineno"> 1298</span>    X_trans_csc = TfidfTransformer().fit_transform(X_csc)</div>
<div class="line"><span class="lineno"> 1299</span>    X_trans_csr = TfidfTransformer().fit_transform(X_csr)</div>
<div class="line"><span class="lineno"> 1300</span>    assert_allclose_dense_sparse(X_trans_csc, X_trans_csr)</div>
<div class="line"><span class="lineno"> 1301</span>    <span class="keyword">assert</span> X_trans_csc.format == X_trans_csr.format</div>
<div class="line"><span class="lineno"> 1302</span> </div>
<div class="line"><span class="lineno"> 1303</span> </div>
<div class="line"><span class="lineno"> 1304</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1305</span>    <span class="stringliteral">&quot;vectorizer_dtype, output_dtype, warning_expected&quot;</span>,</div>
<div class="line"><span class="lineno"> 1306</span>    [</div>
<div class="line"><span class="lineno"> 1307</span>        (np.int32, np.float64, <span class="keyword">True</span>),</div>
<div class="line"><span class="lineno"> 1308</span>        (np.int64, np.float64, <span class="keyword">True</span>),</div>
<div class="line"><span class="lineno"> 1309</span>        (np.float32, np.float32, <span class="keyword">False</span>),</div>
<div class="line"><span class="lineno"> 1310</span>        (np.float64, np.float64, <span class="keyword">False</span>),</div>
<div class="line"><span class="lineno"> 1311</span>    ],</div>
<div class="line"><span class="lineno"> 1312</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ab18177ae8d526004ebf8bc71bf7a4d88" name="ab18177ae8d526004ebf8bc71bf7a4d88"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab18177ae8d526004ebf8bc71bf7a4d88">&#9670;&#160;</a></span>test_tfidf_transformer_type()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tfidf_transformer_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_dtype</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1287</span><span class="keyword">def </span>test_tfidf_transformer_type(X_dtype):</div>
<div class="line"><span class="lineno"> 1288</span>    X = sparse.rand(10, 20000, dtype=X_dtype, random_state=42)</div>
<div class="line"><span class="lineno"> 1289</span>    X_trans = TfidfTransformer().fit_transform(X)</div>
<div class="line"><span class="lineno"> 1290</span>    <span class="keyword">assert</span> X_trans.dtype == X.dtype</div>
<div class="line"><span class="lineno"> 1291</span> </div>
<div class="line"><span class="lineno"> 1292</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a137fed41aa0d7bec6001ba438355ef49" name="a137fed41aa0d7bec6001ba438355ef49"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a137fed41aa0d7bec6001ba438355ef49">&#9670;&#160;</a></span>test_tfidf_vectorizer_setter()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tfidf_vectorizer_setter </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1195</span><span class="keyword">def </span>test_tfidf_vectorizer_setter():</div>
<div class="line"><span class="lineno"> 1196</span>    orig = TfidfVectorizer(use_idf=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1197</span>    orig.fit(JUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1198</span>    copy = TfidfVectorizer(vocabulary=orig.vocabulary_, use_idf=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1199</span>    copy.idf_ = orig.idf_</div>
<div class="line"><span class="lineno"> 1200</span>    assert_array_equal(</div>
<div class="line"><span class="lineno"> 1201</span>        copy.transform(JUNK_FOOD_DOCS).toarray(),</div>
<div class="line"><span class="lineno"> 1202</span>        orig.transform(JUNK_FOOD_DOCS).toarray(),</div>
<div class="line"><span class="lineno"> 1203</span>    )</div>
<div class="line"><span class="lineno"> 1204</span>    <span class="comment"># `idf_` cannot be set with `use_idf=False`</span></div>
<div class="line"><span class="lineno"> 1205</span>    copy = TfidfVectorizer(vocabulary=orig.vocabulary_, use_idf=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1206</span>    err_msg = <span class="stringliteral">&quot;`idf_` cannot be set when `user_idf=False`.&quot;</span></div>
<div class="line"><span class="lineno"> 1207</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=err_msg):</div>
<div class="line"><span class="lineno"> 1208</span>        copy.idf_ = orig.idf_</div>
<div class="line"><span class="lineno"> 1209</span> </div>
<div class="line"><span class="lineno"> 1210</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4bd4907f8771278084f1f107383247b2" name="a4bd4907f8771278084f1f107383247b2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4bd4907f8771278084f1f107383247b2">&#9670;&#160;</a></span>test_tfidf_vectorizer_setters()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tfidf_vectorizer_setters </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  615</span><span class="keyword">def </span>test_tfidf_vectorizer_setters():</div>
<div class="line"><span class="lineno">  616</span>    norm, use_idf, smooth_idf, sublinear_tf = <span class="stringliteral">&quot;l2&quot;</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  617</span>    tv = TfidfVectorizer(</div>
<div class="line"><span class="lineno">  618</span>        norm=norm, use_idf=use_idf, smooth_idf=smooth_idf, sublinear_tf=sublinear_tf</div>
<div class="line"><span class="lineno">  619</span>    )</div>
<div class="line"><span class="lineno">  620</span>    tv.fit(JUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  621</span>    <span class="keyword">assert</span> tv._tfidf.norm == norm</div>
<div class="line"><span class="lineno">  622</span>    <span class="keyword">assert</span> tv._tfidf.use_idf == use_idf</div>
<div class="line"><span class="lineno">  623</span>    <span class="keyword">assert</span> tv._tfidf.smooth_idf == smooth_idf</div>
<div class="line"><span class="lineno">  624</span>    <span class="keyword">assert</span> tv._tfidf.sublinear_tf == sublinear_tf</div>
<div class="line"><span class="lineno">  625</span> </div>
<div class="line"><span class="lineno">  626</span>    <span class="comment"># assigning value to `TfidfTransformer` should not have any effect until</span></div>
<div class="line"><span class="lineno">  627</span>    <span class="comment"># fitting</span></div>
<div class="line"><span class="lineno">  628</span>    tv.norm = <span class="stringliteral">&quot;l1&quot;</span></div>
<div class="line"><span class="lineno">  629</span>    tv.use_idf = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  630</span>    tv.smooth_idf = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  631</span>    tv.sublinear_tf = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  632</span>    <span class="keyword">assert</span> tv._tfidf.norm == norm</div>
<div class="line"><span class="lineno">  633</span>    <span class="keyword">assert</span> tv._tfidf.use_idf == use_idf</div>
<div class="line"><span class="lineno">  634</span>    <span class="keyword">assert</span> tv._tfidf.smooth_idf == smooth_idf</div>
<div class="line"><span class="lineno">  635</span>    <span class="keyword">assert</span> tv._tfidf.sublinear_tf == sublinear_tf</div>
<div class="line"><span class="lineno">  636</span> </div>
<div class="line"><span class="lineno">  637</span>    tv.fit(JUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  638</span>    <span class="keyword">assert</span> tv._tfidf.norm == tv.norm</div>
<div class="line"><span class="lineno">  639</span>    <span class="keyword">assert</span> tv._tfidf.use_idf == tv.use_idf</div>
<div class="line"><span class="lineno">  640</span>    <span class="keyword">assert</span> tv._tfidf.smooth_idf == tv.smooth_idf</div>
<div class="line"><span class="lineno">  641</span>    <span class="keyword">assert</span> tv._tfidf.sublinear_tf == tv.sublinear_tf</div>
<div class="line"><span class="lineno">  642</span> </div>
<div class="line"><span class="lineno">  643</span> </div>
<div class="line"><span class="lineno">  644</span><span class="preprocessor">@fails_if_pypy</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a38a1db250c9c85d7a5e1b1471287e2c4" name="a38a1db250c9c85d7a5e1b1471287e2c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38a1db250c9c85d7a5e1b1471287e2c4">&#9670;&#160;</a></span>test_tfidf_vectorizer_type()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tfidf_vectorizer_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vectorizer_dtype</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_dtype</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>warning_expected</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1313</span><span class="keyword">def </span>test_tfidf_vectorizer_type(vectorizer_dtype, output_dtype, warning_expected):</div>
<div class="line"><span class="lineno"> 1314</span>    X = np.array([<span class="stringliteral">&quot;numpy&quot;</span>, <span class="stringliteral">&quot;scipy&quot;</span>, <span class="stringliteral">&quot;sklearn&quot;</span>])</div>
<div class="line"><span class="lineno"> 1315</span>    vectorizer = TfidfVectorizer(dtype=vectorizer_dtype)</div>
<div class="line"><span class="lineno"> 1316</span> </div>
<div class="line"><span class="lineno"> 1317</span>    warning_msg_match = <span class="stringliteral">&quot;&#39;dtype&#39; should be used.&quot;</span></div>
<div class="line"><span class="lineno"> 1318</span>    <span class="keywordflow">if</span> warning_expected:</div>
<div class="line"><span class="lineno"> 1319</span>        <span class="keyword">with</span> pytest.warns(UserWarning, match=warning_msg_match):</div>
<div class="line"><span class="lineno"> 1320</span>            X_idf = vectorizer.fit_transform(X)</div>
<div class="line"><span class="lineno"> 1321</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1322</span>        <span class="keyword">with</span> warnings.catch_warnings():</div>
<div class="line"><span class="lineno"> 1323</span>            warnings.simplefilter(<span class="stringliteral">&quot;error&quot;</span>, UserWarning)</div>
<div class="line"><span class="lineno"> 1324</span>            X_idf = vectorizer.fit_transform(X)</div>
<div class="line"><span class="lineno"> 1325</span>    <span class="keyword">assert</span> X_idf.dtype == output_dtype</div>
<div class="line"><span class="lineno"> 1326</span> </div>
<div class="line"><span class="lineno"> 1327</span> </div>
<div class="line"><span class="lineno"> 1328</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1329</span>    <span class="stringliteral">&quot;vec&quot;</span>,</div>
<div class="line"><span class="lineno"> 1330</span>    [</div>
<div class="line"><span class="lineno"> 1331</span>        HashingVectorizer(ngram_range=(2, 1)),</div>
<div class="line"><span class="lineno"> 1332</span>        CountVectorizer(ngram_range=(2, 1)),</div>
<div class="line"><span class="lineno"> 1333</span>        TfidfVectorizer(ngram_range=(2, 1)),</div>
<div class="line"><span class="lineno"> 1334</span>    ],</div>
<div class="line"><span class="lineno"> 1335</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a3184474ee6db94ea00fa8ca9d1204edf" name="a3184474ee6db94ea00fa8ca9d1204edf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3184474ee6db94ea00fa8ca9d1204edf">&#9670;&#160;</a></span>test_tfidf_vectorizer_with_fixed_vocabulary()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tfidf_vectorizer_with_fixed_vocabulary </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1038</span><span class="keyword">def </span>test_tfidf_vectorizer_with_fixed_vocabulary():</div>
<div class="line"><span class="lineno"> 1039</span>    <span class="comment"># non regression smoke test for inheritance issues</span></div>
<div class="line"><span class="lineno"> 1040</span>    vocabulary = [<span class="stringliteral">&quot;pizza&quot;</span>, <span class="stringliteral">&quot;celeri&quot;</span>]</div>
<div class="line"><span class="lineno"> 1041</span>    vect = TfidfVectorizer(vocabulary=vocabulary)</div>
<div class="line"><span class="lineno"> 1042</span>    X_1 = vect.fit_transform(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1043</span>    X_2 = vect.transform(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1044</span>    assert_array_almost_equal(X_1.toarray(), X_2.toarray())</div>
<div class="line"><span class="lineno"> 1045</span>    <span class="keyword">assert</span> vect.fixed_vocabulary_</div>
<div class="line"><span class="lineno"> 1046</span> </div>
<div class="line"><span class="lineno"> 1047</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0276186cfac0adcad54611926ccdae0f" name="a0276186cfac0adcad54611926ccdae0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0276186cfac0adcad54611926ccdae0f">&#9670;&#160;</a></span>test_tfidfvectorizer_binary()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tfidfvectorizer_binary </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1243</span><span class="keyword">def </span>test_tfidfvectorizer_binary():</div>
<div class="line"><span class="lineno"> 1244</span>    <span class="comment"># Non-regression test: TfidfVectorizer used to ignore its &quot;binary&quot; param.</span></div>
<div class="line"><span class="lineno"> 1245</span>    v = TfidfVectorizer(binary=<span class="keyword">True</span>, use_idf=<span class="keyword">False</span>, norm=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno"> 1246</span>    <span class="keyword">assert</span> v.binary</div>
<div class="line"><span class="lineno"> 1247</span> </div>
<div class="line"><span class="lineno"> 1248</span>    X = v.fit_transform([<span class="stringliteral">&quot;hello world&quot;</span>, <span class="stringliteral">&quot;hello hello&quot;</span>]).toarray()</div>
<div class="line"><span class="lineno"> 1249</span>    assert_array_equal(X.ravel(), [1, 1, 1, 0])</div>
<div class="line"><span class="lineno"> 1250</span>    X2 = v.transform([<span class="stringliteral">&quot;hello world&quot;</span>, <span class="stringliteral">&quot;hello hello&quot;</span>]).toarray()</div>
<div class="line"><span class="lineno"> 1251</span>    assert_array_equal(X2.ravel(), [1, 1, 1, 0])</div>
<div class="line"><span class="lineno"> 1252</span> </div>
<div class="line"><span class="lineno"> 1253</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8cbe9d61b61c2252291a74a42583d2ac" name="a8cbe9d61b61c2252291a74a42583d2ac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8cbe9d61b61c2252291a74a42583d2ac">&#9670;&#160;</a></span>test_tfidfvectorizer_export_idf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tfidfvectorizer_export_idf </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1254</span><span class="keyword">def </span>test_tfidfvectorizer_export_idf():</div>
<div class="line"><span class="lineno"> 1255</span>    vect = TfidfVectorizer(use_idf=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1256</span>    vect.fit(JUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1257</span>    assert_array_almost_equal(vect.idf_, vect._tfidf.idf_)</div>
<div class="line"><span class="lineno"> 1258</span> </div>
<div class="line"><span class="lineno"> 1259</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac2e353ee6a51dbac840d01a68cd0ddac" name="ac2e353ee6a51dbac840d01a68cd0ddac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac2e353ee6a51dbac840d01a68cd0ddac">&#9670;&#160;</a></span>test_tfidfvectorizer_invalid_idf_attr()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tfidfvectorizer_invalid_idf_attr </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1211</span><span class="keyword">def </span>test_tfidfvectorizer_invalid_idf_attr():</div>
<div class="line"><span class="lineno"> 1212</span>    vect = TfidfVectorizer(use_idf=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1213</span>    vect.fit(JUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1214</span>    copy = TfidfVectorizer(vocabulary=vect.vocabulary_, use_idf=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1215</span>    expected_idf_len = len(vect.idf_)</div>
<div class="line"><span class="lineno"> 1216</span>    invalid_idf = [1.0] * (expected_idf_len + 1)</div>
<div class="line"><span class="lineno"> 1217</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno"> 1218</span>        setattr(copy, <span class="stringliteral">&quot;idf_&quot;</span>, invalid_idf)</div>
<div class="line"><span class="lineno"> 1219</span> </div>
<div class="line"><span class="lineno"> 1220</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aff27b9f1b6a49ecdeba9ef77b68bcd5d" name="aff27b9f1b6a49ecdeba9ef77b68bcd5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff27b9f1b6a49ecdeba9ef77b68bcd5d">&#9670;&#160;</a></span>test_tie_breaking_sample_order_invariance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_tie_breaking_sample_order_invariance </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1624</span><span class="keyword">def </span>test_tie_breaking_sample_order_invariance():</div>
<div class="line"><span class="lineno"> 1625</span>    <span class="comment"># Checks the sample order invariance when setting max_features</span></div>
<div class="line"><span class="lineno"> 1626</span>    <span class="comment"># non-regression test for #17939</span></div>
<div class="line"><span class="lineno"> 1627</span>    vec = CountVectorizer(max_features=1)</div>
<div class="line"><span class="lineno"> 1628</span>    vocab1 = vec.fit([<span class="stringliteral">&quot;hello&quot;</span>, <span class="stringliteral">&quot;world&quot;</span>]).vocabulary_</div>
<div class="line"><span class="lineno"> 1629</span>    vocab2 = vec.fit([<span class="stringliteral">&quot;world&quot;</span>, <span class="stringliteral">&quot;hello&quot;</span>]).vocabulary_</div>
<div class="line"><span class="lineno"> 1630</span>    <span class="keyword">assert</span> vocab1 == vocab2</div>
<div class="line"><span class="lineno"> 1631</span> </div>
<div class="line"><span class="lineno"> 1632</span> </div>
<div class="line"><span class="lineno"> 1633</span><span class="preprocessor">@fails_if_pypy</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a46c76f7c3965734fcc0df120389cc0ca" name="a46c76f7c3965734fcc0df120389cc0ca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46c76f7c3965734fcc0df120389cc0ca">&#9670;&#160;</a></span>test_to_ascii()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_to_ascii </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  114</span><span class="keyword">def </span>test_to_ascii():</div>
<div class="line"><span class="lineno">  115</span>    <span class="comment"># check some classical latin accentuated symbols</span></div>
<div class="line"><span class="lineno">  116</span>    a = <span class="stringliteral">&quot;Ã Ã¡Ã¢Ã£Ã¤Ã¥Ã§Ã¨Ã©ÃªÃ«&quot;</span></div>
<div class="line"><span class="lineno">  117</span>    expected = <span class="stringliteral">&quot;aaaaaaceeee&quot;</span></div>
<div class="line"><span class="lineno">  118</span>    <span class="keyword">assert</span> strip_accents_ascii(a) == expected</div>
<div class="line"><span class="lineno">  119</span> </div>
<div class="line"><span class="lineno">  120</span>    a = <span class="stringliteral">&quot;Ã¬Ã­Ã®Ã¯Ã±Ã²Ã³Ã´ÃµÃ¶Ã¹ÃºÃ»Ã¼Ã½&quot;</span></div>
<div class="line"><span class="lineno">  121</span>    expected = <span class="stringliteral">&quot;iiiinooooouuuuy&quot;</span></div>
<div class="line"><span class="lineno">  122</span>    <span class="keyword">assert</span> strip_accents_ascii(a) == expected</div>
<div class="line"><span class="lineno">  123</span> </div>
<div class="line"><span class="lineno">  124</span>    <span class="comment"># check some arabic</span></div>
<div class="line"><span class="lineno">  125</span>    a = <span class="stringliteral">&quot;\u0625&quot;</span>  <span class="comment"># halef with a hamza below</span></div>
<div class="line"><span class="lineno">  126</span>    expected = <span class="stringliteral">&quot;&quot;</span>  <span class="comment"># halef has no direct ascii match</span></div>
<div class="line"><span class="lineno">  127</span>    <span class="keyword">assert</span> strip_accents_ascii(a) == expected</div>
<div class="line"><span class="lineno">  128</span> </div>
<div class="line"><span class="lineno">  129</span>    <span class="comment"># mix letters accentuated and not</span></div>
<div class="line"><span class="lineno">  130</span>    a = <span class="stringliteral">&quot;this is Ã  test&quot;</span></div>
<div class="line"><span class="lineno">  131</span>    expected = <span class="stringliteral">&quot;this is a test&quot;</span></div>
<div class="line"><span class="lineno">  132</span>    <span class="keyword">assert</span> strip_accents_ascii(a) == expected</div>
<div class="line"><span class="lineno">  133</span> </div>
<div class="line"><span class="lineno">  134</span> </div>
<div class="line"><span class="lineno">  135</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Vectorizer&quot;, (CountVectorizer, HashingVectorizer)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a39555e7c1bb618d6c1856cd4af6d5e71" name="a39555e7c1bb618d6c1856cd4af6d5e71"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a39555e7c1bb618d6c1856cd4af6d5e71">&#9670;&#160;</a></span>test_transformer_idf_setter()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_transformer_idf_setter </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1187</span><span class="keyword">def </span>test_transformer_idf_setter():</div>
<div class="line"><span class="lineno"> 1188</span>    X = CountVectorizer().fit_transform(JUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1189</span>    orig = TfidfTransformer().fit(X)</div>
<div class="line"><span class="lineno"> 1190</span>    copy = TfidfTransformer()</div>
<div class="line"><span class="lineno"> 1191</span>    copy.idf_ = orig.idf_</div>
<div class="line"><span class="lineno"> 1192</span>    assert_array_equal(copy.transform(X).toarray(), orig.transform(X).toarray())</div>
<div class="line"><span class="lineno"> 1193</span> </div>
<div class="line"><span class="lineno"> 1194</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae53cb7a6b4f30fb8eb4114cc103b8a26" name="ae53cb7a6b4f30fb8eb4114cc103b8a26"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae53cb7a6b4f30fb8eb4114cc103b8a26">&#9670;&#160;</a></span>test_unicode_decode_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_unicode_decode_error </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  227</span><span class="keyword">def </span>test_unicode_decode_error():</div>
<div class="line"><span class="lineno">  228</span>    <span class="comment"># decode_error default to strict, so this should fail</span></div>
<div class="line"><span class="lineno">  229</span>    <span class="comment"># First, encode (as bytes) a unicode string.</span></div>
<div class="line"><span class="lineno">  230</span>    text = <span class="stringliteral">&quot;J&#39;ai mangÃ© du kangourou  ce midi, c&#39;Ã©tait pas trÃ¨s bon.&quot;</span></div>
<div class="line"><span class="lineno">  231</span>    text_bytes = text.encode(<span class="stringliteral">&quot;utf-8&quot;</span>)</div>
<div class="line"><span class="lineno">  232</span> </div>
<div class="line"><span class="lineno">  233</span>    <span class="comment"># Then let the Analyzer try to decode it as ascii. It should fail,</span></div>
<div class="line"><span class="lineno">  234</span>    <span class="comment"># because we have given it an incorrect encoding.</span></div>
<div class="line"><span class="lineno">  235</span>    wa = CountVectorizer(ngram_range=(1, 2), encoding=<span class="stringliteral">&quot;ascii&quot;</span>).build_analyzer()</div>
<div class="line"><span class="lineno">  236</span>    <span class="keyword">with</span> pytest.raises(UnicodeDecodeError):</div>
<div class="line"><span class="lineno">  237</span>        wa(text_bytes)</div>
<div class="line"><span class="lineno">  238</span> </div>
<div class="line"><span class="lineno">  239</span>    ca = CountVectorizer(</div>
<div class="line"><span class="lineno">  240</span>        analyzer=<span class="stringliteral">&quot;char&quot;</span>, ngram_range=(3, 6), encoding=<span class="stringliteral">&quot;ascii&quot;</span></div>
<div class="line"><span class="lineno">  241</span>    ).build_analyzer()</div>
<div class="line"><span class="lineno">  242</span>    <span class="keyword">with</span> pytest.raises(UnicodeDecodeError):</div>
<div class="line"><span class="lineno">  243</span>        <a class="code hl_variable" href="__blas__subroutines_8h.html#ac948c91f64cee069718b8121de7f4146">ca</a>(text_bytes)</div>
<div class="line"><span class="lineno">  244</span> </div>
<div class="line"><span class="lineno">  245</span> </div>
<div class="ttc" id="a__blas__subroutines_8h_html_ac948c91f64cee069718b8121de7f4146"><div class="ttname"><a href="__blas__subroutines_8h.html#ac948c91f64cee069718b8121de7f4146">ca</a></div><div class="ttdeci">void char * ca</div><div class="ttdef"><b>Definition</b> _blas_subroutines.h:26</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="ad4fd2fa9802e010e580800a56ea461ea" name="ad4fd2fa9802e010e580800a56ea461ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad4fd2fa9802e010e580800a56ea461ea">&#9670;&#160;</a></span>test_unused_parameters_warn()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_unused_parameters_warn </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Vectorizer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>stop_words</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tokenizer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>preprocessor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ngram_range</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>token_pattern</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>analyzer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>unused_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ovrd_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ovrd_msg</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1587</span>):</div>
<div class="line"><span class="lineno"> 1588</span> </div>
<div class="line"><span class="lineno"> 1589</span>    train_data = JUNK_FOOD_DOCS</div>
<div class="line"><span class="lineno"> 1590</span>    <span class="comment"># setting parameter and checking for corresponding warning messages</span></div>
<div class="line"><span class="lineno"> 1591</span>    vect = Vectorizer()</div>
<div class="line"><span class="lineno"> 1592</span>    vect.set_params(</div>
<div class="line"><span class="lineno"> 1593</span>        stop_words=stop_words,</div>
<div class="line"><span class="lineno"> 1594</span>        tokenizer=tokenizer,</div>
<div class="line"><span class="lineno"> 1595</span>        preprocessor=preprocessor,</div>
<div class="line"><span class="lineno"> 1596</span>        ngram_range=ngram_range,</div>
<div class="line"><span class="lineno"> 1597</span>        token_pattern=token_pattern,</div>
<div class="line"><span class="lineno"> 1598</span>        analyzer=analyzer,</div>
<div class="line"><span class="lineno"> 1599</span>    )</div>
<div class="line"><span class="lineno"> 1600</span>    msg = <span class="stringliteral">&quot;The parameter %s will not be used since %s %s&quot;</span> % (</div>
<div class="line"><span class="lineno"> 1601</span>        unused_name,</div>
<div class="line"><span class="lineno"> 1602</span>        ovrd_name,</div>
<div class="line"><span class="lineno"> 1603</span>        ovrd_msg,</div>
<div class="line"><span class="lineno"> 1604</span>    )</div>
<div class="line"><span class="lineno"> 1605</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno"> 1606</span>        vect.fit(train_data)</div>
<div class="line"><span class="lineno"> 1607</span> </div>
<div class="line"><span class="lineno"> 1608</span> </div>
<div class="line"><span class="lineno"> 1609</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1610</span>    <span class="stringliteral">&quot;Vectorizer, X&quot;</span>,</div>
<div class="line"><span class="lineno"> 1611</span>    (</div>
<div class="line"><span class="lineno"> 1612</span>        (HashingVectorizer, [{<span class="stringliteral">&quot;foo&quot;</span>: 1, <span class="stringliteral">&quot;bar&quot;</span>: 2}, {<span class="stringliteral">&quot;foo&quot;</span>: 3, <span class="stringliteral">&quot;baz&quot;</span>: 1}]),</div>
<div class="line"><span class="lineno"> 1613</span>        (CountVectorizer, JUNK_FOOD_DOCS),</div>
<div class="line"><span class="lineno"> 1614</span>    ),</div>
<div class="line"><span class="lineno"> 1615</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a2545651a7ec5306619651a78face6a60" name="a2545651a7ec5306619651a78face6a60"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2545651a7ec5306619651a78face6a60">&#9670;&#160;</a></span>test_vectorizer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  512</span><span class="keyword">def </span>test_vectorizer():</div>
<div class="line"><span class="lineno">  513</span>    <span class="comment"># raw documents as an iterator</span></div>
<div class="line"><span class="lineno">  514</span>    train_data = <a class="code hl_variable" href="__lapack__subroutines_8h.html#a60590d91febfcb54d88443940cd5f23e">iter</a>(ALL_FOOD_DOCS[:-1])</div>
<div class="line"><span class="lineno">  515</span>    test_data = [ALL_FOOD_DOCS[-1]]</div>
<div class="line"><span class="lineno">  516</span>    n_train = len(ALL_FOOD_DOCS) - 1</div>
<div class="line"><span class="lineno">  517</span> </div>
<div class="line"><span class="lineno">  518</span>    <span class="comment"># test without vocabulary</span></div>
<div class="line"><span class="lineno">  519</span>    v1 = CountVectorizer(max_df=0.5)</div>
<div class="line"><span class="lineno">  520</span>    counts_train = v1.fit_transform(train_data)</div>
<div class="line"><span class="lineno">  521</span>    <span class="keywordflow">if</span> hasattr(counts_train, <span class="stringliteral">&quot;tocsr&quot;</span>):</div>
<div class="line"><span class="lineno">  522</span>        counts_train = counts_train.tocsr()</div>
<div class="line"><span class="lineno">  523</span>    <span class="keyword">assert</span> counts_train[0, v1.vocabulary_[<span class="stringliteral">&quot;pizza&quot;</span>]] == 2</div>
<div class="line"><span class="lineno">  524</span> </div>
<div class="line"><span class="lineno">  525</span>    <span class="comment"># build a vectorizer v1 with the same vocabulary as the one fitted by v1</span></div>
<div class="line"><span class="lineno">  526</span>    v2 = CountVectorizer(vocabulary=v1.vocabulary_)</div>
<div class="line"><span class="lineno">  527</span> </div>
<div class="line"><span class="lineno">  528</span>    <span class="comment"># compare that the two vectorizer give the same output on the test sample</span></div>
<div class="line"><span class="lineno">  529</span>    <span class="keywordflow">for</span> v <span class="keywordflow">in</span> (v1, v2):</div>
<div class="line"><span class="lineno">  530</span>        counts_test = v.transform(test_data)</div>
<div class="line"><span class="lineno">  531</span>        <span class="keywordflow">if</span> hasattr(counts_test, <span class="stringliteral">&quot;tocsr&quot;</span>):</div>
<div class="line"><span class="lineno">  532</span>            counts_test = counts_test.tocsr()</div>
<div class="line"><span class="lineno">  533</span> </div>
<div class="line"><span class="lineno">  534</span>        vocabulary = v.vocabulary_</div>
<div class="line"><span class="lineno">  535</span>        <span class="keyword">assert</span> counts_test[0, vocabulary[<span class="stringliteral">&quot;salad&quot;</span>]] == 1</div>
<div class="line"><span class="lineno">  536</span>        <span class="keyword">assert</span> counts_test[0, vocabulary[<span class="stringliteral">&quot;tomato&quot;</span>]] == 1</div>
<div class="line"><span class="lineno">  537</span>        <span class="keyword">assert</span> counts_test[0, vocabulary[<span class="stringliteral">&quot;water&quot;</span>]] == 1</div>
<div class="line"><span class="lineno">  538</span> </div>
<div class="line"><span class="lineno">  539</span>        <span class="comment"># stop word from the fixed list</span></div>
<div class="line"><span class="lineno">  540</span>        <span class="keyword">assert</span> <span class="stringliteral">&quot;the&quot;</span> <span class="keywordflow">not</span> <span class="keywordflow">in</span> vocabulary</div>
<div class="line"><span class="lineno">  541</span> </div>
<div class="line"><span class="lineno">  542</span>        <span class="comment"># stop word found automatically by the vectorizer DF thresholding</span></div>
<div class="line"><span class="lineno">  543</span>        <span class="comment"># words that are high frequent across the complete corpus are likely</span></div>
<div class="line"><span class="lineno">  544</span>        <span class="comment"># to be not informative (either real stop words of extraction</span></div>
<div class="line"><span class="lineno">  545</span>        <span class="comment"># artifacts)</span></div>
<div class="line"><span class="lineno">  546</span>        <span class="keyword">assert</span> <span class="stringliteral">&quot;copyright&quot;</span> <span class="keywordflow">not</span> <span class="keywordflow">in</span> vocabulary</div>
<div class="line"><span class="lineno">  547</span> </div>
<div class="line"><span class="lineno">  548</span>        <span class="comment"># not present in the sample</span></div>
<div class="line"><span class="lineno">  549</span>        <span class="keyword">assert</span> counts_test[0, vocabulary[<span class="stringliteral">&quot;coke&quot;</span>]] == 0</div>
<div class="line"><span class="lineno">  550</span>        <span class="keyword">assert</span> counts_test[0, vocabulary[<span class="stringliteral">&quot;burger&quot;</span>]] == 0</div>
<div class="line"><span class="lineno">  551</span>        <span class="keyword">assert</span> counts_test[0, vocabulary[<span class="stringliteral">&quot;beer&quot;</span>]] == 0</div>
<div class="line"><span class="lineno">  552</span>        <span class="keyword">assert</span> counts_test[0, vocabulary[<span class="stringliteral">&quot;pizza&quot;</span>]] == 0</div>
<div class="line"><span class="lineno">  553</span> </div>
<div class="line"><span class="lineno">  554</span>    <span class="comment"># test tf-idf</span></div>
<div class="line"><span class="lineno">  555</span>    t1 = TfidfTransformer(norm=<span class="stringliteral">&quot;l1&quot;</span>)</div>
<div class="line"><span class="lineno">  556</span>    tfidf = t1.fit(counts_train).transform(counts_train).toarray()</div>
<div class="line"><span class="lineno">  557</span>    <span class="keyword">assert</span> len(t1.idf_) == len(v1.vocabulary_)</div>
<div class="line"><span class="lineno">  558</span>    <span class="keyword">assert</span> tfidf.shape == (n_train, len(v1.vocabulary_))</div>
<div class="line"><span class="lineno">  559</span> </div>
<div class="line"><span class="lineno">  560</span>    <span class="comment"># test tf-idf with new data</span></div>
<div class="line"><span class="lineno">  561</span>    tfidf_test = t1.transform(counts_test).toarray()</div>
<div class="line"><span class="lineno">  562</span>    <span class="keyword">assert</span> tfidf_test.shape == (len(test_data), len(v1.vocabulary_))</div>
<div class="line"><span class="lineno">  563</span> </div>
<div class="line"><span class="lineno">  564</span>    <span class="comment"># test tf alone</span></div>
<div class="line"><span class="lineno">  565</span>    t2 = TfidfTransformer(norm=<span class="stringliteral">&quot;l1&quot;</span>, use_idf=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  566</span>    tf = t2.fit(counts_train).transform(counts_train).toarray()</div>
<div class="line"><span class="lineno">  567</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> hasattr(t2, <span class="stringliteral">&quot;idf_&quot;</span>)</div>
<div class="line"><span class="lineno">  568</span> </div>
<div class="line"><span class="lineno">  569</span>    <span class="comment"># test idf transform with unlearned idf vector</span></div>
<div class="line"><span class="lineno">  570</span>    t3 = TfidfTransformer(use_idf=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  571</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  572</span>        t3.transform(counts_train)</div>
<div class="line"><span class="lineno">  573</span> </div>
<div class="line"><span class="lineno">  574</span>    <span class="comment"># L1-normalized term frequencies sum to one</span></div>
<div class="line"><span class="lineno">  575</span>    assert_array_almost_equal(np.sum(tf, axis=1), [1.0] * n_train)</div>
<div class="line"><span class="lineno">  576</span> </div>
<div class="line"><span class="lineno">  577</span>    <span class="comment"># test the direct tfidf vectorizer</span></div>
<div class="line"><span class="lineno">  578</span>    <span class="comment"># (equivalent to term count vectorizer + tfidf transformer)</span></div>
<div class="line"><span class="lineno">  579</span>    train_data = <a class="code hl_variable" href="__lapack__subroutines_8h.html#a60590d91febfcb54d88443940cd5f23e">iter</a>(ALL_FOOD_DOCS[:-1])</div>
<div class="line"><span class="lineno">  580</span>    tv = TfidfVectorizer(norm=<span class="stringliteral">&quot;l1&quot;</span>)</div>
<div class="line"><span class="lineno">  581</span> </div>
<div class="line"><span class="lineno">  582</span>    tv.max_df = v1.max_df</div>
<div class="line"><span class="lineno">  583</span>    tfidf2 = tv.fit_transform(train_data).toarray()</div>
<div class="line"><span class="lineno">  584</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> tv.fixed_vocabulary_</div>
<div class="line"><span class="lineno">  585</span>    assert_array_almost_equal(tfidf, tfidf2)</div>
<div class="line"><span class="lineno">  586</span> </div>
<div class="line"><span class="lineno">  587</span>    <span class="comment"># test the direct tfidf vectorizer with new data</span></div>
<div class="line"><span class="lineno">  588</span>    tfidf_test2 = tv.transform(test_data).toarray()</div>
<div class="line"><span class="lineno">  589</span>    assert_array_almost_equal(tfidf_test, tfidf_test2)</div>
<div class="line"><span class="lineno">  590</span> </div>
<div class="line"><span class="lineno">  591</span>    <span class="comment"># test transform on unfitted vectorizer with empty vocabulary</span></div>
<div class="line"><span class="lineno">  592</span>    v3 = CountVectorizer(vocabulary=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  593</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  594</span>        v3.transform(train_data)</div>
<div class="line"><span class="lineno">  595</span> </div>
<div class="line"><span class="lineno">  596</span>    <span class="comment"># ascii preprocessor?</span></div>
<div class="line"><span class="lineno">  597</span>    v3.set_params(strip_accents=<span class="stringliteral">&quot;ascii&quot;</span>, lowercase=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  598</span>    processor = v3.build_preprocessor()</div>
<div class="line"><span class="lineno">  599</span>    text = <span class="stringliteral">&quot;J&#39;ai mangÃ© du kangourou  ce midi, c&#39;Ã©tait pas trÃ¨s bon.&quot;</span></div>
<div class="line"><span class="lineno">  600</span>    expected = strip_accents_ascii(text)</div>
<div class="line"><span class="lineno">  601</span>    result = processor(text)</div>
<div class="line"><span class="lineno">  602</span>    <span class="keyword">assert</span> expected == result</div>
<div class="line"><span class="lineno">  603</span> </div>
<div class="line"><span class="lineno">  604</span>    <span class="comment"># error on bad strip_accents param</span></div>
<div class="line"><span class="lineno">  605</span>    v3.set_params(strip_accents=<span class="stringliteral">&quot;_gabbledegook_&quot;</span>, preprocessor=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  606</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  607</span>        v3.build_preprocessor()</div>
<div class="line"><span class="lineno">  608</span> </div>
<div class="line"><span class="lineno">  609</span>    <span class="comment"># error with bad analyzer type</span></div>
<div class="line"><span class="lineno">  610</span>    v3.set_params = <span class="stringliteral">&quot;_invalid_analyzer_type_&quot;</span></div>
<div class="line"><span class="lineno">  611</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  612</span>        v3.build_analyzer()</div>
<div class="line"><span class="lineno">  613</span> </div>
<div class="line"><span class="lineno">  614</span> </div>
<div class="ttc" id="a__lapack__subroutines_8h_html_a60590d91febfcb54d88443940cd5f23e"><div class="ttname"><a href="__lapack__subroutines_8h.html#a60590d91febfcb54d88443940cd5f23e">iter</a></div><div class="ttdeci">void int double int double double double double int int * iter</div><div class="ttdef"><b>Definition</b> _lapack_subroutines.h:623</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab1d7e05a1a1986abd8f816287e36f4bd" name="ab1d7e05a1a1986abd8f816287e36f4bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1d7e05a1a1986abd8f816287e36f4bd">&#9670;&#160;</a></span>test_vectorizer_inverse_transform()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer_inverse_transform </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Vectorizer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  894</span><span class="keyword">def </span>test_vectorizer_inverse_transform(Vectorizer):</div>
<div class="line"><span class="lineno">  895</span>    <span class="comment"># raw documents</span></div>
<div class="line"><span class="lineno">  896</span>    data = ALL_FOOD_DOCS</div>
<div class="line"><span class="lineno">  897</span>    vectorizer = Vectorizer()</div>
<div class="line"><span class="lineno">  898</span>    transformed_data = vectorizer.fit_transform(data)</div>
<div class="line"><span class="lineno">  899</span>    inversed_data = vectorizer.inverse_transform(transformed_data)</div>
<div class="line"><span class="lineno">  900</span>    <span class="keyword">assert</span> isinstance(inversed_data, list)</div>
<div class="line"><span class="lineno">  901</span> </div>
<div class="line"><span class="lineno">  902</span>    analyze = vectorizer.build_analyzer()</div>
<div class="line"><span class="lineno">  903</span>    <span class="keywordflow">for</span> doc, inversed_terms <span class="keywordflow">in</span> zip(data, inversed_data):</div>
<div class="line"><span class="lineno">  904</span>        terms = np.sort(np.unique(analyze(doc)))</div>
<div class="line"><span class="lineno">  905</span>        inversed_terms = np.sort(np.unique(inversed_terms))</div>
<div class="line"><span class="lineno">  906</span>        assert_array_equal(terms, inversed_terms)</div>
<div class="line"><span class="lineno">  907</span> </div>
<div class="line"><span class="lineno">  908</span>    <span class="keyword">assert</span> sparse.issparse(transformed_data)</div>
<div class="line"><span class="lineno">  909</span>    <span class="keyword">assert</span> transformed_data.format == <span class="stringliteral">&quot;csr&quot;</span></div>
<div class="line"><span class="lineno">  910</span> </div>
<div class="line"><span class="lineno">  911</span>    <span class="comment"># Test that inverse_transform also works with numpy arrays and</span></div>
<div class="line"><span class="lineno">  912</span>    <span class="comment"># scipy</span></div>
<div class="line"><span class="lineno">  913</span>    transformed_data2 = transformed_data.toarray()</div>
<div class="line"><span class="lineno">  914</span>    inversed_data2 = vectorizer.inverse_transform(transformed_data2)</div>
<div class="line"><span class="lineno">  915</span>    <span class="keywordflow">for</span> terms, terms2 <span class="keywordflow">in</span> zip(inversed_data, inversed_data2):</div>
<div class="line"><span class="lineno">  916</span>        assert_array_equal(np.sort(terms), np.sort(terms2))</div>
<div class="line"><span class="lineno">  917</span> </div>
<div class="line"><span class="lineno">  918</span>    <span class="comment"># Check that inverse_transform also works on non CSR sparse data:</span></div>
<div class="line"><span class="lineno">  919</span>    transformed_data3 = transformed_data.tocsc()</div>
<div class="line"><span class="lineno">  920</span>    inversed_data3 = vectorizer.inverse_transform(transformed_data3)</div>
<div class="line"><span class="lineno">  921</span>    <span class="keywordflow">for</span> terms, terms3 <span class="keywordflow">in</span> zip(inversed_data, inversed_data3):</div>
<div class="line"><span class="lineno">  922</span>        assert_array_equal(np.sort(terms), np.sort(terms3))</div>
<div class="line"><span class="lineno">  923</span> </div>
<div class="line"><span class="lineno">  924</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af16e6cb1406c79ef96177487faa0c9bf" name="af16e6cb1406c79ef96177487faa0c9bf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af16e6cb1406c79ef96177487faa0c9bf">&#9670;&#160;</a></span>test_vectorizer_max_df()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer_max_df </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  800</span><span class="keyword">def </span>test_vectorizer_max_df():</div>
<div class="line"><span class="lineno">  801</span>    test_data = [<span class="stringliteral">&quot;abc&quot;</span>, <span class="stringliteral">&quot;dea&quot;</span>, <span class="stringliteral">&quot;eat&quot;</span>]</div>
<div class="line"><span class="lineno">  802</span>    vect = CountVectorizer(analyzer=<span class="stringliteral">&quot;char&quot;</span>, max_df=1.0)</div>
<div class="line"><span class="lineno">  803</span>    vect.fit(test_data)</div>
<div class="line"><span class="lineno">  804</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;a&quot;</span> <span class="keywordflow">in</span> vect.vocabulary_.keys()</div>
<div class="line"><span class="lineno">  805</span>    <span class="keyword">assert</span> len(vect.vocabulary_.keys()) == 6</div>
<div class="line"><span class="lineno">  806</span>    <span class="keyword">assert</span> len(vect.stop_words_) == 0</div>
<div class="line"><span class="lineno">  807</span> </div>
<div class="line"><span class="lineno">  808</span>    vect.max_df = 0.5  <span class="comment"># 0.5 * 3 documents -&gt; max_doc_count == 1.5</span></div>
<div class="line"><span class="lineno">  809</span>    vect.fit(test_data)</div>
<div class="line"><span class="lineno">  810</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;a&quot;</span> <span class="keywordflow">not</span> <span class="keywordflow">in</span> vect.vocabulary_.keys()  <span class="comment"># {ae} ignored</span></div>
<div class="line"><span class="lineno">  811</span>    <span class="keyword">assert</span> len(vect.vocabulary_.keys()) == 4  <span class="comment"># {bcdt} remain</span></div>
<div class="line"><span class="lineno">  812</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;a&quot;</span> <span class="keywordflow">in</span> vect.stop_words_</div>
<div class="line"><span class="lineno">  813</span>    <span class="keyword">assert</span> len(vect.stop_words_) == 2</div>
<div class="line"><span class="lineno">  814</span> </div>
<div class="line"><span class="lineno">  815</span>    vect.max_df = 1</div>
<div class="line"><span class="lineno">  816</span>    vect.fit(test_data)</div>
<div class="line"><span class="lineno">  817</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;a&quot;</span> <span class="keywordflow">not</span> <span class="keywordflow">in</span> vect.vocabulary_.keys()  <span class="comment"># {ae} ignored</span></div>
<div class="line"><span class="lineno">  818</span>    <span class="keyword">assert</span> len(vect.vocabulary_.keys()) == 4  <span class="comment"># {bcdt} remain</span></div>
<div class="line"><span class="lineno">  819</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;a&quot;</span> <span class="keywordflow">in</span> vect.stop_words_</div>
<div class="line"><span class="lineno">  820</span>    <span class="keyword">assert</span> len(vect.stop_words_) == 2</div>
<div class="line"><span class="lineno">  821</span> </div>
<div class="line"><span class="lineno">  822</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6d6aa95795b98379f7a837fbb6aaffed" name="a6d6aa95795b98379f7a837fbb6aaffed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6d6aa95795b98379f7a837fbb6aaffed">&#9670;&#160;</a></span>test_vectorizer_max_features()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer_max_features </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Vectorizer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  755</span><span class="keyword">def </span>test_vectorizer_max_features(Vectorizer):</div>
<div class="line"><span class="lineno">  756</span>    expected_vocabulary = {<span class="stringliteral">&quot;burger&quot;</span>, <span class="stringliteral">&quot;beer&quot;</span>, <span class="stringliteral">&quot;salad&quot;</span>, <span class="stringliteral">&quot;pizza&quot;</span>}</div>
<div class="line"><span class="lineno">  757</span>    expected_stop_words = {</div>
<div class="line"><span class="lineno">  758</span>        <span class="stringliteral">&quot;celeri&quot;</span>,</div>
<div class="line"><span class="lineno">  759</span>        <span class="stringliteral">&quot;tomato&quot;</span>,</div>
<div class="line"><span class="lineno">  760</span>        <span class="stringliteral">&quot;copyright&quot;</span>,</div>
<div class="line"><span class="lineno">  761</span>        <span class="stringliteral">&quot;coke&quot;</span>,</div>
<div class="line"><span class="lineno">  762</span>        <span class="stringliteral">&quot;sparkling&quot;</span>,</div>
<div class="line"><span class="lineno">  763</span>        <span class="stringliteral">&quot;water&quot;</span>,</div>
<div class="line"><span class="lineno">  764</span>        <span class="stringliteral">&quot;the&quot;</span>,</div>
<div class="line"><span class="lineno">  765</span>    }</div>
<div class="line"><span class="lineno">  766</span> </div>
<div class="line"><span class="lineno">  767</span>    <span class="comment"># test bounded number of extracted features</span></div>
<div class="line"><span class="lineno">  768</span>    vectorizer = Vectorizer(max_df=0.6, max_features=4)</div>
<div class="line"><span class="lineno">  769</span>    vectorizer.fit(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  770</span>    <span class="keyword">assert</span> set(vectorizer.vocabulary_) == expected_vocabulary</div>
<div class="line"><span class="lineno">  771</span>    <span class="keyword">assert</span> vectorizer.stop_words_ == expected_stop_words</div>
<div class="line"><span class="lineno">  772</span> </div>
<div class="line"><span class="lineno">  773</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a295bdb5e7d3a39c61eddc9132e011812" name="a295bdb5e7d3a39c61eddc9132e011812"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a295bdb5e7d3a39c61eddc9132e011812">&#9670;&#160;</a></span>test_vectorizer_min_df()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer_min_df </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  823</span><span class="keyword">def </span>test_vectorizer_min_df():</div>
<div class="line"><span class="lineno">  824</span>    test_data = [<span class="stringliteral">&quot;abc&quot;</span>, <span class="stringliteral">&quot;dea&quot;</span>, <span class="stringliteral">&quot;eat&quot;</span>]</div>
<div class="line"><span class="lineno">  825</span>    vect = CountVectorizer(analyzer=<span class="stringliteral">&quot;char&quot;</span>, min_df=1)</div>
<div class="line"><span class="lineno">  826</span>    vect.fit(test_data)</div>
<div class="line"><span class="lineno">  827</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;a&quot;</span> <span class="keywordflow">in</span> vect.vocabulary_.keys()</div>
<div class="line"><span class="lineno">  828</span>    <span class="keyword">assert</span> len(vect.vocabulary_.keys()) == 6</div>
<div class="line"><span class="lineno">  829</span>    <span class="keyword">assert</span> len(vect.stop_words_) == 0</div>
<div class="line"><span class="lineno">  830</span> </div>
<div class="line"><span class="lineno">  831</span>    vect.min_df = 2</div>
<div class="line"><span class="lineno">  832</span>    vect.fit(test_data)</div>
<div class="line"><span class="lineno">  833</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;c&quot;</span> <span class="keywordflow">not</span> <span class="keywordflow">in</span> vect.vocabulary_.keys()  <span class="comment"># {bcdt} ignored</span></div>
<div class="line"><span class="lineno">  834</span>    <span class="keyword">assert</span> len(vect.vocabulary_.keys()) == 2  <span class="comment"># {ae} remain</span></div>
<div class="line"><span class="lineno">  835</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;c&quot;</span> <span class="keywordflow">in</span> vect.stop_words_</div>
<div class="line"><span class="lineno">  836</span>    <span class="keyword">assert</span> len(vect.stop_words_) == 4</div>
<div class="line"><span class="lineno">  837</span> </div>
<div class="line"><span class="lineno">  838</span>    vect.min_df = 0.8  <span class="comment"># 0.8 * 3 documents -&gt; min_doc_count == 2.4</span></div>
<div class="line"><span class="lineno">  839</span>    vect.fit(test_data)</div>
<div class="line"><span class="lineno">  840</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;c&quot;</span> <span class="keywordflow">not</span> <span class="keywordflow">in</span> vect.vocabulary_.keys()  <span class="comment"># {bcdet} ignored</span></div>
<div class="line"><span class="lineno">  841</span>    <span class="keyword">assert</span> len(vect.vocabulary_.keys()) == 1  <span class="comment"># {a} remains</span></div>
<div class="line"><span class="lineno">  842</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;c&quot;</span> <span class="keywordflow">in</span> vect.stop_words_</div>
<div class="line"><span class="lineno">  843</span>    <span class="keyword">assert</span> len(vect.stop_words_) == 5</div>
<div class="line"><span class="lineno">  844</span> </div>
<div class="line"><span class="lineno">  845</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a934b03a7cddc1244aa5251507a0ed201" name="a934b03a7cddc1244aa5251507a0ed201"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a934b03a7cddc1244aa5251507a0ed201">&#9670;&#160;</a></span>test_vectorizer_pipeline_cross_validation()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer_pipeline_cross_validation </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1000</span><span class="keyword">def </span>test_vectorizer_pipeline_cross_validation():</div>
<div class="line"><span class="lineno"> 1001</span>    <span class="comment"># raw documents</span></div>
<div class="line"><span class="lineno"> 1002</span>    data = JUNK_FOOD_DOCS + NOTJUNK_FOOD_DOCS</div>
<div class="line"><span class="lineno"> 1003</span> </div>
<div class="line"><span class="lineno"> 1004</span>    <span class="comment"># label junk food as -1, the others as +1</span></div>
<div class="line"><span class="lineno"> 1005</span>    target = [-1] * len(JUNK_FOOD_DOCS) + [1] * len(NOTJUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1006</span> </div>
<div class="line"><span class="lineno"> 1007</span>    pipeline = Pipeline([(<span class="stringliteral">&quot;vect&quot;</span>, TfidfVectorizer()), (<span class="stringliteral">&quot;svc&quot;</span>, LinearSVC())])</div>
<div class="line"><span class="lineno"> 1008</span> </div>
<div class="line"><span class="lineno"> 1009</span>    cv_scores = cross_val_score(pipeline, data, target, cv=3)</div>
<div class="line"><span class="lineno"> 1010</span>    assert_array_equal(cv_scores, [1.0, 1.0, 1.0])</div>
<div class="line"><span class="lineno"> 1011</span> </div>
<div class="line"><span class="lineno"> 1012</span> </div>
<div class="line"><span class="lineno"> 1013</span><span class="preprocessor">@fails_if_pypy</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aaa6966f27f117f17a5204b515f9a6454" name="aaa6966f27f117f17a5204b515f9a6454"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaa6966f27f117f17a5204b515f9a6454">&#9670;&#160;</a></span>test_vectorizer_pipeline_grid_selection()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer_pipeline_grid_selection </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  961</span><span class="keyword">def </span>test_vectorizer_pipeline_grid_selection():</div>
<div class="line"><span class="lineno">  962</span>    <span class="comment"># raw documents</span></div>
<div class="line"><span class="lineno">  963</span>    data = JUNK_FOOD_DOCS + NOTJUNK_FOOD_DOCS</div>
<div class="line"><span class="lineno">  964</span> </div>
<div class="line"><span class="lineno">  965</span>    <span class="comment"># label junk food as -1, the others as +1</span></div>
<div class="line"><span class="lineno">  966</span>    target = [-1] * len(JUNK_FOOD_DOCS) + [1] * len(NOTJUNK_FOOD_DOCS)</div>
<div class="line"><span class="lineno">  967</span> </div>
<div class="line"><span class="lineno">  968</span>    <span class="comment"># split the dataset for model development and final evaluation</span></div>
<div class="line"><span class="lineno">  969</span>    train_data, test_data, target_train, target_test = train_test_split(</div>
<div class="line"><span class="lineno">  970</span>        data, target, test_size=0.1, random_state=0</div>
<div class="line"><span class="lineno">  971</span>    )</div>
<div class="line"><span class="lineno">  972</span> </div>
<div class="line"><span class="lineno">  973</span>    pipeline = Pipeline([(<span class="stringliteral">&quot;vect&quot;</span>, TfidfVectorizer()), (<span class="stringliteral">&quot;svc&quot;</span>, LinearSVC())])</div>
<div class="line"><span class="lineno">  974</span> </div>
<div class="line"><span class="lineno">  975</span>    parameters = {</div>
<div class="line"><span class="lineno">  976</span>        <span class="stringliteral">&quot;vect__ngram_range&quot;</span>: [(1, 1), (1, 2)],</div>
<div class="line"><span class="lineno">  977</span>        <span class="stringliteral">&quot;vect__norm&quot;</span>: (<span class="stringliteral">&quot;l1&quot;</span>, <span class="stringliteral">&quot;l2&quot;</span>),</div>
<div class="line"><span class="lineno">  978</span>        <span class="stringliteral">&quot;svc__loss&quot;</span>: (<span class="stringliteral">&quot;hinge&quot;</span>, <span class="stringliteral">&quot;squared_hinge&quot;</span>),</div>
<div class="line"><span class="lineno">  979</span>    }</div>
<div class="line"><span class="lineno">  980</span> </div>
<div class="line"><span class="lineno">  981</span>    <span class="comment"># find the best parameters for both the feature extraction and the</span></div>
<div class="line"><span class="lineno">  982</span>    <span class="comment"># classifier</span></div>
<div class="line"><span class="lineno">  983</span>    grid_search = GridSearchCV(pipeline, parameters, n_jobs=1)</div>
<div class="line"><span class="lineno">  984</span> </div>
<div class="line"><span class="lineno">  985</span>    <span class="comment"># Check that the best model found by grid search is 100% correct on the</span></div>
<div class="line"><span class="lineno">  986</span>    <span class="comment"># held out evaluation set.</span></div>
<div class="line"><span class="lineno">  987</span>    pred = grid_search.fit(train_data, target_train).predict(test_data)</div>
<div class="line"><span class="lineno">  988</span>    assert_array_equal(pred, target_test)</div>
<div class="line"><span class="lineno">  989</span> </div>
<div class="line"><span class="lineno">  990</span>    <span class="comment"># on this toy dataset bigram representation which is used in the last of</span></div>
<div class="line"><span class="lineno">  991</span>    <span class="comment"># the grid_search is considered the best estimator since they all converge</span></div>
<div class="line"><span class="lineno">  992</span>    <span class="comment"># to 100% accuracy models</span></div>
<div class="line"><span class="lineno">  993</span>    <span class="keyword">assert</span> grid_search.best_score_ == 1.0</div>
<div class="line"><span class="lineno">  994</span>    best_vectorizer = grid_search.best_estimator_.named_steps[<span class="stringliteral">&quot;vect&quot;</span>]</div>
<div class="line"><span class="lineno">  995</span>    <span class="keyword">assert</span> best_vectorizer.ngram_range == (1, 1)</div>
<div class="line"><span class="lineno">  996</span>    <span class="keyword">assert</span> best_vectorizer.norm == <span class="stringliteral">&quot;l2&quot;</span></div>
<div class="line"><span class="lineno">  997</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> best_vectorizer.fixed_vocabulary_</div>
<div class="line"><span class="lineno">  998</span> </div>
<div class="line"><span class="lineno">  999</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8a422901591e2d209870bbf6465c09c2" name="a8a422901591e2d209870bbf6465c09c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a422901591e2d209870bbf6465c09c2">&#9670;&#160;</a></span>test_vectorizer_stop_words_inconsistent()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer_stop_words_inconsistent </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1366</span><span class="keyword">def </span>test_vectorizer_stop_words_inconsistent():</div>
<div class="line"><span class="lineno"> 1367</span>    lstr = <span class="stringliteral">r&quot;\[&#39;and&#39;, &#39;ll&#39;, &#39;ve&#39;\]&quot;</span></div>
<div class="line"><span class="lineno"> 1368</span>    message = (</div>
<div class="line"><span class="lineno"> 1369</span>        <span class="stringliteral">&quot;Your stop_words may be inconsistent with your &quot;</span></div>
<div class="line"><span class="lineno"> 1370</span>        <span class="stringliteral">&quot;preprocessing. Tokenizing the stop words generated &quot;</span></div>
<div class="line"><span class="lineno"> 1371</span>        <span class="stringliteral">&quot;tokens %s not in stop_words.&quot;</span> % lstr</div>
<div class="line"><span class="lineno"> 1372</span>    )</div>
<div class="line"><span class="lineno"> 1373</span>    <span class="keywordflow">for</span> vec <span class="keywordflow">in</span> [CountVectorizer(), TfidfVectorizer(), HashingVectorizer()]:</div>
<div class="line"><span class="lineno"> 1374</span>        vec.set_params(stop_words=[<span class="stringliteral">&quot;you&#39;ve&quot;</span>, <span class="stringliteral">&quot;you&quot;</span>, <span class="stringliteral">&quot;you&#39;ll&quot;</span>, <span class="stringliteral">&quot;AND&quot;</span>])</div>
<div class="line"><span class="lineno"> 1375</span>        <span class="keyword">with</span> pytest.warns(UserWarning, match=message):</div>
<div class="line"><span class="lineno"> 1376</span>            vec.fit_transform([<span class="stringliteral">&quot;hello world&quot;</span>])</div>
<div class="line"><span class="lineno"> 1377</span>        <span class="comment"># reset stop word validation</span></div>
<div class="line"><span class="lineno"> 1378</span>        del vec._stop_words_id</div>
<div class="line"><span class="lineno"> 1379</span>        <span class="keyword">assert</span> _check_stop_words_consistency(vec) <span class="keywordflow">is</span> <span class="keyword">False</span></div>
<div class="line"><span class="lineno"> 1380</span> </div>
<div class="line"><span class="lineno"> 1381</span>    <span class="comment"># Only one warning per stop list</span></div>
<div class="line"><span class="lineno"> 1382</span>    <span class="keyword">with</span> warnings.catch_warnings():</div>
<div class="line"><span class="lineno"> 1383</span>        warnings.simplefilter(<span class="stringliteral">&quot;error&quot;</span>, UserWarning)</div>
<div class="line"><span class="lineno"> 1384</span>        vec.fit_transform([<span class="stringliteral">&quot;hello world&quot;</span>])</div>
<div class="line"><span class="lineno"> 1385</span>    <span class="keyword">assert</span> _check_stop_words_consistency(vec) <span class="keywordflow">is</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1386</span> </div>
<div class="line"><span class="lineno"> 1387</span>    <span class="comment"># Test caching of inconsistency assessment</span></div>
<div class="line"><span class="lineno"> 1388</span>    vec.set_params(stop_words=[<span class="stringliteral">&quot;you&#39;ve&quot;</span>, <span class="stringliteral">&quot;you&quot;</span>, <span class="stringliteral">&quot;you&#39;ll&quot;</span>, <span class="stringliteral">&quot;blah&quot;</span>, <span class="stringliteral">&quot;AND&quot;</span>])</div>
<div class="line"><span class="lineno"> 1389</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=message):</div>
<div class="line"><span class="lineno"> 1390</span>        vec.fit_transform([<span class="stringliteral">&quot;hello world&quot;</span>])</div>
<div class="line"><span class="lineno"> 1391</span> </div>
<div class="line"><span class="lineno"> 1392</span> </div>
<div class="line"><span class="lineno"> 1393</span><span class="preprocessor">@skip_if_32bit</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a9962dc356ef1cd82e7dc140ce549effe" name="a9962dc356ef1cd82e7dc140ce549effe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9962dc356ef1cd82e7dc140ce549effe">&#9670;&#160;</a></span>test_vectorizer_string_object_as_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer_string_object_as_input </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Vectorizer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1271</span><span class="keyword">def </span>test_vectorizer_string_object_as_input(Vectorizer):</div>
<div class="line"><span class="lineno"> 1272</span>    message = <span class="stringliteral">&quot;Iterable over raw text documents expected, string object received.&quot;</span></div>
<div class="line"><span class="lineno"> 1273</span>    vec = Vectorizer()</div>
<div class="line"><span class="lineno"> 1274</span> </div>
<div class="line"><span class="lineno"> 1275</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=message):</div>
<div class="line"><span class="lineno"> 1276</span>        vec.fit_transform(<span class="stringliteral">&quot;hello world!&quot;</span>)</div>
<div class="line"><span class="lineno"> 1277</span> </div>
<div class="line"><span class="lineno"> 1278</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=message):</div>
<div class="line"><span class="lineno"> 1279</span>        vec.fit(<span class="stringliteral">&quot;hello world!&quot;</span>)</div>
<div class="line"><span class="lineno"> 1280</span>    vec.fit([<span class="stringliteral">&quot;some text&quot;</span>, <span class="stringliteral">&quot;some other text&quot;</span>])</div>
<div class="line"><span class="lineno"> 1281</span> </div>
<div class="line"><span class="lineno"> 1282</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=message):</div>
<div class="line"><span class="lineno"> 1283</span>        vec.transform(<span class="stringliteral">&quot;hello world!&quot;</span>)</div>
<div class="line"><span class="lineno"> 1284</span> </div>
<div class="line"><span class="lineno"> 1285</span> </div>
<div class="line"><span class="lineno"> 1286</span><span class="preprocessor">@pytest.mark.parametrize(&quot;X_dtype&quot;, [np.float32, np.float64])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a9d50ce489a983fd3484bcceeb49edfc9" name="a9d50ce489a983fd3484bcceeb49edfc9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9d50ce489a983fd3484bcceeb49edfc9">&#9670;&#160;</a></span>test_vectorizer_unicode()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer_unicode </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1014</span><span class="keyword">def </span>test_vectorizer_unicode():</div>
<div class="line"><span class="lineno"> 1015</span>    <span class="comment"># tests that the count vectorizer works with cyrillic.</span></div>
<div class="line"><span class="lineno"> 1016</span>    document = (</div>
<div class="line"><span class="lineno"> 1017</span>        <span class="stringliteral">&quot;ÐÐ°ÑÐ¸Ð½Ð½Ð¾Ðµ Ð¾Ð±ÑÑÐµÐ½Ð¸Ðµ â Ð¾Ð±ÑÐ¸ÑÐ½ÑÐ¹ Ð¿Ð¾Ð´ÑÐ°Ð·Ð´ÐµÐ» Ð¸ÑÐºÑÑÑÑÐ²ÐµÐ½Ð½Ð¾Ð³Ð¾ &quot;</span></div>
<div class="line"><span class="lineno"> 1018</span>        <span class="stringliteral">&quot;Ð¸Ð½ÑÐµÐ»Ð»ÐµÐºÑÐ°, Ð¸Ð·ÑÑÐ°ÑÑÐ¸Ð¹ Ð¼ÐµÑÐ¾Ð´Ñ Ð¿Ð¾ÑÑÑÐ¾ÐµÐ½Ð¸Ñ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼Ð¾Ð², &quot;</span></div>
<div class="line"><span class="lineno"> 1019</span>        <span class="stringliteral">&quot;ÑÐ¿Ð¾ÑÐ¾Ð±Ð½ÑÑ Ð¾Ð±ÑÑÐ°ÑÑÑÑ.&quot;</span></div>
<div class="line"><span class="lineno"> 1020</span>    )</div>
<div class="line"><span class="lineno"> 1021</span> </div>
<div class="line"><span class="lineno"> 1022</span>    vect = CountVectorizer()</div>
<div class="line"><span class="lineno"> 1023</span>    X_counted = vect.fit_transform([document])</div>
<div class="line"><span class="lineno"> 1024</span>    <span class="keyword">assert</span> X_counted.shape == (1, 12)</div>
<div class="line"><span class="lineno"> 1025</span> </div>
<div class="line"><span class="lineno"> 1026</span>    vect = HashingVectorizer(norm=<span class="keywordtype">None</span>, alternate_sign=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1027</span>    X_hashed = vect.transform([document])</div>
<div class="line"><span class="lineno"> 1028</span>    <span class="keyword">assert</span> X_hashed.shape == (1, 2**20)</div>
<div class="line"><span class="lineno"> 1029</span> </div>
<div class="line"><span class="lineno"> 1030</span>    <span class="comment"># No collisions on such a small dataset</span></div>
<div class="line"><span class="lineno"> 1031</span>    <span class="keyword">assert</span> X_counted.nnz == X_hashed.nnz</div>
<div class="line"><span class="lineno"> 1032</span> </div>
<div class="line"><span class="lineno"> 1033</span>    <span class="comment"># When norm is None and not alternate_sign, the tokens are counted up to</span></div>
<div class="line"><span class="lineno"> 1034</span>    <span class="comment"># collisions</span></div>
<div class="line"><span class="lineno"> 1035</span>    assert_array_equal(np.sort(X_counted.data), np.sort(X_hashed.data))</div>
<div class="line"><span class="lineno"> 1036</span> </div>
<div class="line"><span class="lineno"> 1037</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a24ce8d9460fe2778e956722065948877" name="a24ce8d9460fe2778e956722065948877"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24ce8d9460fe2778e956722065948877">&#9670;&#160;</a></span>test_vectorizer_vocab_clone()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizer_vocab_clone </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1260</span><span class="keyword">def </span>test_vectorizer_vocab_clone():</div>
<div class="line"><span class="lineno"> 1261</span>    vect_vocab = TfidfVectorizer(vocabulary=[<span class="stringliteral">&quot;the&quot;</span>])</div>
<div class="line"><span class="lineno"> 1262</span>    vect_vocab_clone = clone(vect_vocab)</div>
<div class="line"><span class="lineno"> 1263</span>    vect_vocab.fit(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1264</span>    vect_vocab_clone.fit(ALL_FOOD_DOCS)</div>
<div class="line"><span class="lineno"> 1265</span>    <span class="keyword">assert</span> vect_vocab_clone.vocabulary_ == vect_vocab.vocabulary_</div>
<div class="line"><span class="lineno"> 1266</span> </div>
<div class="line"><span class="lineno"> 1267</span> </div>
<div class="line"><span class="lineno"> 1268</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1269</span>    <span class="stringliteral">&quot;Vectorizer&quot;</span>, (CountVectorizer, TfidfVectorizer, HashingVectorizer)</div>
<div class="line"><span class="lineno"> 1270</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a6319d7ec6d1cbb09a4b27f55a0b79482" name="a6319d7ec6d1cbb09a4b27f55a0b79482"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6319d7ec6d1cbb09a4b27f55a0b79482">&#9670;&#160;</a></span>test_vectorizers_do_not_have_set_output()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizers_do_not_have_set_output </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Estimator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that vectorizers do not define set_output.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1644</span><span class="keyword">def </span>test_vectorizers_do_not_have_set_output(Estimator):</div>
<div class="line"><span class="lineno"> 1645</span>    <span class="stringliteral">&quot;&quot;&quot;Check that vectorizers do not define set_output.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1646</span>    est = Estimator()</div>
<div class="line"><span class="lineno"> 1647</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> hasattr(est, <span class="stringliteral">&quot;set_output&quot;</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a95970e57876ce22fc92c4a14c99e037e" name="a95970e57876ce22fc92c4a14c99e037e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a95970e57876ce22fc92c4a14c99e037e">&#9670;&#160;</a></span>test_vectorizers_invalid_ngram_range()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_vectorizers_invalid_ngram_range </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vec</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1336</span><span class="keyword">def </span>test_vectorizers_invalid_ngram_range(vec):</div>
<div class="line"><span class="lineno"> 1337</span>    <span class="comment"># vectorizers could be initialized with invalid ngram range</span></div>
<div class="line"><span class="lineno"> 1338</span>    <span class="comment"># test for raising error message</span></div>
<div class="line"><span class="lineno"> 1339</span>    invalid_range = vec.ngram_range</div>
<div class="line"><span class="lineno"> 1340</span>    message = re.escape(</div>
<div class="line"><span class="lineno"> 1341</span>        f<span class="stringliteral">&quot;Invalid value for ngram_range={invalid_range} &quot;</span></div>
<div class="line"><span class="lineno"> 1342</span>        <span class="stringliteral">&quot;lower boundary larger than the upper boundary.&quot;</span></div>
<div class="line"><span class="lineno"> 1343</span>    )</div>
<div class="line"><span class="lineno"> 1344</span>    <span class="keywordflow">if</span> isinstance(vec, HashingVectorizer) <span class="keywordflow">and</span> IS_PYPY:</div>
<div class="line"><span class="lineno"> 1345</span>        pytest.xfail(reason=<span class="stringliteral">&quot;HashingVectorizer is not supported on PyPy&quot;</span>)</div>
<div class="line"><span class="lineno"> 1346</span> </div>
<div class="line"><span class="lineno"> 1347</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=message):</div>
<div class="line"><span class="lineno"> 1348</span>        vec.fit([<span class="stringliteral">&quot;good news everyone&quot;</span>])</div>
<div class="line"><span class="lineno"> 1349</span> </div>
<div class="line"><span class="lineno"> 1350</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=message):</div>
<div class="line"><span class="lineno"> 1351</span>        vec.fit_transform([<span class="stringliteral">&quot;good news everyone&quot;</span>])</div>
<div class="line"><span class="lineno"> 1352</span> </div>
<div class="line"><span class="lineno"> 1353</span>    <span class="keywordflow">if</span> isinstance(vec, HashingVectorizer):</div>
<div class="line"><span class="lineno"> 1354</span>        <span class="keyword">with</span> pytest.raises(ValueError, match=message):</div>
<div class="line"><span class="lineno"> 1355</span>            vec.transform([<span class="stringliteral">&quot;good news everyone&quot;</span>])</div>
<div class="line"><span class="lineno"> 1356</span> </div>
<div class="line"><span class="lineno"> 1357</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9c6df3d618e5253703ad8ed524701d2a" name="a9c6df3d618e5253703ad8ed524701d2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c6df3d618e5253703ad8ed524701d2a">&#9670;&#160;</a></span>test_word_analyzer_unigrams()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_word_analyzer_unigrams </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Vectorizer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  136</span><span class="keyword">def </span>test_word_analyzer_unigrams(Vectorizer):</div>
<div class="line"><span class="lineno">  137</span>    wa = Vectorizer(strip_accents=<span class="stringliteral">&quot;ascii&quot;</span>).build_analyzer()</div>
<div class="line"><span class="lineno">  138</span>    text = <span class="stringliteral">&quot;J&#39;ai mangÃ© du kangourou  ce midi, c&#39;Ã©tait pas trÃ¨s bon.&quot;</span></div>
<div class="line"><span class="lineno">  139</span>    expected = [</div>
<div class="line"><span class="lineno">  140</span>        <span class="stringliteral">&quot;ai&quot;</span>,</div>
<div class="line"><span class="lineno">  141</span>        <span class="stringliteral">&quot;mange&quot;</span>,</div>
<div class="line"><span class="lineno">  142</span>        <span class="stringliteral">&quot;du&quot;</span>,</div>
<div class="line"><span class="lineno">  143</span>        <span class="stringliteral">&quot;kangourou&quot;</span>,</div>
<div class="line"><span class="lineno">  144</span>        <span class="stringliteral">&quot;ce&quot;</span>,</div>
<div class="line"><span class="lineno">  145</span>        <span class="stringliteral">&quot;midi&quot;</span>,</div>
<div class="line"><span class="lineno">  146</span>        <span class="stringliteral">&quot;etait&quot;</span>,</div>
<div class="line"><span class="lineno">  147</span>        <span class="stringliteral">&quot;pas&quot;</span>,</div>
<div class="line"><span class="lineno">  148</span>        <span class="stringliteral">&quot;tres&quot;</span>,</div>
<div class="line"><span class="lineno">  149</span>        <span class="stringliteral">&quot;bon&quot;</span>,</div>
<div class="line"><span class="lineno">  150</span>    ]</div>
<div class="line"><span class="lineno">  151</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><span class="lineno">  152</span> </div>
<div class="line"><span class="lineno">  153</span>    text = <span class="stringliteral">&quot;This is a test, really.\n\n I met Harry yesterday.&quot;</span></div>
<div class="line"><span class="lineno">  154</span>    expected = [<span class="stringliteral">&quot;this&quot;</span>, <span class="stringliteral">&quot;is&quot;</span>, <span class="stringliteral">&quot;test&quot;</span>, <span class="stringliteral">&quot;really&quot;</span>, <span class="stringliteral">&quot;met&quot;</span>, <span class="stringliteral">&quot;harry&quot;</span>, <span class="stringliteral">&quot;yesterday&quot;</span>]</div>
<div class="line"><span class="lineno">  155</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><span class="lineno">  156</span> </div>
<div class="line"><span class="lineno">  157</span>    wa = Vectorizer(input=<span class="stringliteral">&quot;file&quot;</span>).build_analyzer()</div>
<div class="line"><span class="lineno">  158</span>    text = StringIO(<span class="stringliteral">&quot;This is a test with a file-like object!&quot;</span>)</div>
<div class="line"><span class="lineno">  159</span>    expected = [<span class="stringliteral">&quot;this&quot;</span>, <span class="stringliteral">&quot;is&quot;</span>, <span class="stringliteral">&quot;test&quot;</span>, <span class="stringliteral">&quot;with&quot;</span>, <span class="stringliteral">&quot;file&quot;</span>, <span class="stringliteral">&quot;like&quot;</span>, <span class="stringliteral">&quot;object&quot;</span>]</div>
<div class="line"><span class="lineno">  160</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><span class="lineno">  161</span> </div>
<div class="line"><span class="lineno">  162</span>    <span class="comment"># with custom preprocessor</span></div>
<div class="line"><span class="lineno">  163</span>    wa = Vectorizer(preprocessor=uppercase).build_analyzer()</div>
<div class="line"><span class="lineno">  164</span>    text = <span class="stringliteral">&quot;J&#39;ai mangÃ© du kangourou  ce midi,  c&#39;Ã©tait pas trÃ¨s bon.&quot;</span></div>
<div class="line"><span class="lineno">  165</span>    expected = [</div>
<div class="line"><span class="lineno">  166</span>        <span class="stringliteral">&quot;AI&quot;</span>,</div>
<div class="line"><span class="lineno">  167</span>        <span class="stringliteral">&quot;MANGE&quot;</span>,</div>
<div class="line"><span class="lineno">  168</span>        <span class="stringliteral">&quot;DU&quot;</span>,</div>
<div class="line"><span class="lineno">  169</span>        <span class="stringliteral">&quot;KANGOUROU&quot;</span>,</div>
<div class="line"><span class="lineno">  170</span>        <span class="stringliteral">&quot;CE&quot;</span>,</div>
<div class="line"><span class="lineno">  171</span>        <span class="stringliteral">&quot;MIDI&quot;</span>,</div>
<div class="line"><span class="lineno">  172</span>        <span class="stringliteral">&quot;ETAIT&quot;</span>,</div>
<div class="line"><span class="lineno">  173</span>        <span class="stringliteral">&quot;PAS&quot;</span>,</div>
<div class="line"><span class="lineno">  174</span>        <span class="stringliteral">&quot;TRES&quot;</span>,</div>
<div class="line"><span class="lineno">  175</span>        <span class="stringliteral">&quot;BON&quot;</span>,</div>
<div class="line"><span class="lineno">  176</span>    ]</div>
<div class="line"><span class="lineno">  177</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><span class="lineno">  178</span> </div>
<div class="line"><span class="lineno">  179</span>    <span class="comment"># with custom tokenizer</span></div>
<div class="line"><span class="lineno">  180</span>    wa = Vectorizer(tokenizer=split_tokenize, strip_accents=<span class="stringliteral">&quot;ascii&quot;</span>).build_analyzer()</div>
<div class="line"><span class="lineno">  181</span>    text = <span class="stringliteral">&quot;J&#39;ai mangÃ© du kangourou  ce midi, c&#39;Ã©tait pas trÃ¨s bon.&quot;</span></div>
<div class="line"><span class="lineno">  182</span>    expected = [</div>
<div class="line"><span class="lineno">  183</span>        <span class="stringliteral">&quot;j&#39;ai&quot;</span>,</div>
<div class="line"><span class="lineno">  184</span>        <span class="stringliteral">&quot;mange&quot;</span>,</div>
<div class="line"><span class="lineno">  185</span>        <span class="stringliteral">&quot;du&quot;</span>,</div>
<div class="line"><span class="lineno">  186</span>        <span class="stringliteral">&quot;kangourou&quot;</span>,</div>
<div class="line"><span class="lineno">  187</span>        <span class="stringliteral">&quot;ce&quot;</span>,</div>
<div class="line"><span class="lineno">  188</span>        <span class="stringliteral">&quot;midi,&quot;</span>,</div>
<div class="line"><span class="lineno">  189</span>        <span class="stringliteral">&quot;c&#39;etait&quot;</span>,</div>
<div class="line"><span class="lineno">  190</span>        <span class="stringliteral">&quot;pas&quot;</span>,</div>
<div class="line"><span class="lineno">  191</span>        <span class="stringliteral">&quot;tres&quot;</span>,</div>
<div class="line"><span class="lineno">  192</span>        <span class="stringliteral">&quot;bon.&quot;</span>,</div>
<div class="line"><span class="lineno">  193</span>    ]</div>
<div class="line"><span class="lineno">  194</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><span class="lineno">  195</span> </div>
<div class="line"><span class="lineno">  196</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a10dc18d56e344919689dd597fa9ddbef" name="a10dc18d56e344919689dd597fa9ddbef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a10dc18d56e344919689dd597fa9ddbef">&#9670;&#160;</a></span>test_word_analyzer_unigrams_and_bigrams()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_word_analyzer_unigrams_and_bigrams </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  197</span><span class="keyword">def </span>test_word_analyzer_unigrams_and_bigrams():</div>
<div class="line"><span class="lineno">  198</span>    wa = CountVectorizer(</div>
<div class="line"><span class="lineno">  199</span>        analyzer=<span class="stringliteral">&quot;word&quot;</span>, strip_accents=<span class="stringliteral">&quot;unicode&quot;</span>, ngram_range=(1, 2)</div>
<div class="line"><span class="lineno">  200</span>    ).build_analyzer()</div>
<div class="line"><span class="lineno">  201</span> </div>
<div class="line"><span class="lineno">  202</span>    text = <span class="stringliteral">&quot;J&#39;ai mangÃ© du kangourou  ce midi, c&#39;Ã©tait pas trÃ¨s bon.&quot;</span></div>
<div class="line"><span class="lineno">  203</span>    expected = [</div>
<div class="line"><span class="lineno">  204</span>        <span class="stringliteral">&quot;ai&quot;</span>,</div>
<div class="line"><span class="lineno">  205</span>        <span class="stringliteral">&quot;mange&quot;</span>,</div>
<div class="line"><span class="lineno">  206</span>        <span class="stringliteral">&quot;du&quot;</span>,</div>
<div class="line"><span class="lineno">  207</span>        <span class="stringliteral">&quot;kangourou&quot;</span>,</div>
<div class="line"><span class="lineno">  208</span>        <span class="stringliteral">&quot;ce&quot;</span>,</div>
<div class="line"><span class="lineno">  209</span>        <span class="stringliteral">&quot;midi&quot;</span>,</div>
<div class="line"><span class="lineno">  210</span>        <span class="stringliteral">&quot;etait&quot;</span>,</div>
<div class="line"><span class="lineno">  211</span>        <span class="stringliteral">&quot;pas&quot;</span>,</div>
<div class="line"><span class="lineno">  212</span>        <span class="stringliteral">&quot;tres&quot;</span>,</div>
<div class="line"><span class="lineno">  213</span>        <span class="stringliteral">&quot;bon&quot;</span>,</div>
<div class="line"><span class="lineno">  214</span>        <span class="stringliteral">&quot;ai mange&quot;</span>,</div>
<div class="line"><span class="lineno">  215</span>        <span class="stringliteral">&quot;mange du&quot;</span>,</div>
<div class="line"><span class="lineno">  216</span>        <span class="stringliteral">&quot;du kangourou&quot;</span>,</div>
<div class="line"><span class="lineno">  217</span>        <span class="stringliteral">&quot;kangourou ce&quot;</span>,</div>
<div class="line"><span class="lineno">  218</span>        <span class="stringliteral">&quot;ce midi&quot;</span>,</div>
<div class="line"><span class="lineno">  219</span>        <span class="stringliteral">&quot;midi etait&quot;</span>,</div>
<div class="line"><span class="lineno">  220</span>        <span class="stringliteral">&quot;etait pas&quot;</span>,</div>
<div class="line"><span class="lineno">  221</span>        <span class="stringliteral">&quot;pas tres&quot;</span>,</div>
<div class="line"><span class="lineno">  222</span>        <span class="stringliteral">&quot;tres bon&quot;</span>,</div>
<div class="line"><span class="lineno">  223</span>    ]</div>
<div class="line"><span class="lineno">  224</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><span class="lineno">  225</span> </div>
<div class="line"><span class="lineno">  226</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae3eac0286bcfb73d6900fa5d66d4220d" name="ae3eac0286bcfb73d6900fa5d66d4220d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae3eac0286bcfb73d6900fa5d66d4220d">&#9670;&#160;</a></span>test_word_ngram_analyzer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.test_word_ngram_analyzer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  292</span><span class="keyword">def </span>test_word_ngram_analyzer():</div>
<div class="line"><span class="lineno">  293</span>    cnga = CountVectorizer(</div>
<div class="line"><span class="lineno">  294</span>        analyzer=<span class="stringliteral">&quot;word&quot;</span>, strip_accents=<span class="stringliteral">&quot;unicode&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><span class="lineno">  295</span>    ).build_analyzer()</div>
<div class="line"><span class="lineno">  296</span> </div>
<div class="line"><span class="lineno">  297</span>    text = <span class="stringliteral">&quot;This \n\tis a test, really.\n\n I met Harry yesterday&quot;</span></div>
<div class="line"><span class="lineno">  298</span>    expected = [<span class="stringliteral">&quot;this is test&quot;</span>, <span class="stringliteral">&quot;is test really&quot;</span>, <span class="stringliteral">&quot;test really met&quot;</span>]</div>
<div class="line"><span class="lineno">  299</span>    <span class="keyword">assert</span> cnga(text)[:3] == expected</div>
<div class="line"><span class="lineno">  300</span> </div>
<div class="line"><span class="lineno">  301</span>    expected = [</div>
<div class="line"><span class="lineno">  302</span>        <span class="stringliteral">&quot;test really met harry yesterday&quot;</span>,</div>
<div class="line"><span class="lineno">  303</span>        <span class="stringliteral">&quot;this is test really met harry&quot;</span>,</div>
<div class="line"><span class="lineno">  304</span>        <span class="stringliteral">&quot;is test really met harry yesterday&quot;</span>,</div>
<div class="line"><span class="lineno">  305</span>    ]</div>
<div class="line"><span class="lineno">  306</span>    <span class="keyword">assert</span> cnga(text)[-3:] == expected</div>
<div class="line"><span class="lineno">  307</span> </div>
<div class="line"><span class="lineno">  308</span>    cnga_file = CountVectorizer(</div>
<div class="line"><span class="lineno">  309</span>        input=<span class="stringliteral">&quot;file&quot;</span>, analyzer=<span class="stringliteral">&quot;word&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><span class="lineno">  310</span>    ).build_analyzer()</div>
<div class="line"><span class="lineno">  311</span>    file = StringIO(text)</div>
<div class="line"><span class="lineno">  312</span>    <span class="keyword">assert</span> cnga_file(file) == cnga(text)</div>
<div class="line"><span class="lineno">  313</span> </div>
<div class="line"><span class="lineno">  314</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aca32d7b8cc237faa414f9584b5422b5e" name="aca32d7b8cc237faa414f9584b5422b5e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca32d7b8cc237faa414f9584b5422b5e">&#9670;&#160;</a></span>uppercase()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_extraction.tests.test_text.uppercase </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   62</span><span class="keyword">def </span>uppercase(s):</div>
<div class="line"><span class="lineno">   63</span>    <span class="keywordflow">return</span> strip_accents_unicode(s).upper()</div>
<div class="line"><span class="lineno">   64</span> </div>
<div class="line"><span class="lineno">   65</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a8511ee7660ed9a977e39c26fe6d03d33" name="a8511ee7660ed9a977e39c26fe6d03d33"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8511ee7660ed9a977e39c26fe6d03d33">&#9670;&#160;</a></span>ALL_FOOD_DOCS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple sklearn.feature_extraction.tests.test_text.ALL_FOOD_DOCS = <a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ad3d3f152fc1af1b8d75aeff55c65b04e">JUNK_FOOD_DOCS</a> + <a class="el" href="namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a915f0b1639fa8ce70c229041e7edccdf">NOTJUNK_FOOD_DOCS</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad3d3f152fc1af1b8d75aeff55c65b04e" name="ad3d3f152fc1af1b8d75aeff55c65b04e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad3d3f152fc1af1b8d75aeff55c65b04e">&#9670;&#160;</a></span>JUNK_FOOD_DOCS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple sklearn.feature_extraction.tests.test_text.JUNK_FOOD_DOCS</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  (</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;the pizza pizza beer copyright&quot;</span>,</div>
<div class="line"><span class="lineno">    3</span>    <span class="stringliteral">&quot;the pizza burger beer copyright&quot;</span>,</div>
<div class="line"><span class="lineno">    4</span>    <span class="stringliteral">&quot;the the pizza beer beer copyright&quot;</span>,</div>
<div class="line"><span class="lineno">    5</span>    <span class="stringliteral">&quot;the burger beer beer copyright&quot;</span>,</div>
<div class="line"><span class="lineno">    6</span>    <span class="stringliteral">&quot;the coke burger coke copyright&quot;</span>,</div>
<div class="line"><span class="lineno">    7</span>    <span class="stringliteral">&quot;the coke burger burger&quot;</span>,</div>
<div class="line"><span class="lineno">    8</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a915f0b1639fa8ce70c229041e7edccdf" name="a915f0b1639fa8ce70c229041e7edccdf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a915f0b1639fa8ce70c229041e7edccdf">&#9670;&#160;</a></span>NOTJUNK_FOOD_DOCS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple sklearn.feature_extraction.tests.test_text.NOTJUNK_FOOD_DOCS</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  (</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;the salad celeri copyright&quot;</span>,</div>
<div class="line"><span class="lineno">    3</span>    <span class="stringliteral">&quot;the salad salad sparkling water copyright&quot;</span>,</div>
<div class="line"><span class="lineno">    4</span>    <span class="stringliteral">&quot;the the celeri celeri copyright&quot;</span>,</div>
<div class="line"><span class="lineno">    5</span>    <span class="stringliteral">&quot;the tomato tomato salad water&quot;</span>,</div>
<div class="line"><span class="lineno">    6</span>    <span class="stringliteral">&quot;the tomato salad water copyright&quot;</span>,</div>
<div class="line"><span class="lineno">    7</span>)</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
