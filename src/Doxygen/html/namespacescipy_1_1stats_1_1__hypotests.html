<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: scipy.stats._hypotests Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacescipy.html">scipy</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1stats.html">stats</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html">_hypotests</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">scipy.stats._hypotests Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classscipy_1_1stats_1_1__hypotests_1_1_cramer_von_mises_result.html">CramerVonMisesResult</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classscipy_1_1stats_1_1__hypotests_1_1_tukey_h_s_d_result.html">TukeyHSDResult</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ade49f50bc7740c5eed78e17309590a3c" id="r_ade49f50bc7740c5eed78e17309590a3c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#ade49f50bc7740c5eed78e17309590a3c">epps_singleton_2samp</a> (x, y, <a class="el" href="namespacescipy_1_1stats_1_1__continuous__distns.html#ad9d2b06b505e69d16256a02b7c928a69">t</a>=(0.4, 0.8))</td></tr>
<tr class="separator:ade49f50bc7740c5eed78e17309590a3c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a959d606f29bc461a5f200a7afed53515" id="r_a959d606f29bc461a5f200a7afed53515"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#a959d606f29bc461a5f200a7afed53515">_psi1_mod</a> (x)</td></tr>
<tr class="separator:a959d606f29bc461a5f200a7afed53515"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2f7dc7ca6455ba7e757166a2a0b6341" id="r_aa2f7dc7ca6455ba7e757166a2a0b6341"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#aa2f7dc7ca6455ba7e757166a2a0b6341">_cdf_cvm_inf</a> (x)</td></tr>
<tr class="separator:aa2f7dc7ca6455ba7e757166a2a0b6341"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab962c6513bc9f7e9c531a919d16d395e" id="r_ab962c6513bc9f7e9c531a919d16d395e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#ab962c6513bc9f7e9c531a919d16d395e">_cdf_cvm</a> (x, <a class="el" href="__blas__subroutines_8h.html#a25eafceb38c8e75bc60701fea6623f71">n</a>=None)</td></tr>
<tr class="separator:ab962c6513bc9f7e9c531a919d16d395e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7f83ced89d2318a8a9e56ec9870f069" id="r_ab7f83ced89d2318a8a9e56ec9870f069"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#ab7f83ced89d2318a8a9e56ec9870f069">cramervonmises</a> (rvs, cdf, args=())</td></tr>
<tr class="separator:ab7f83ced89d2318a8a9e56ec9870f069"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8a3a0780c9647797a3f4c8a912f8644" id="r_ae8a3a0780c9647797a3f4c8a912f8644"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#ae8a3a0780c9647797a3f4c8a912f8644">_get_wilcoxon_distr</a> (<a class="el" href="__blas__subroutines_8h.html#a25eafceb38c8e75bc60701fea6623f71">n</a>)</td></tr>
<tr class="separator:ae8a3a0780c9647797a3f4c8a912f8644"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6216edb11e21a8e7a16f786314eb354" id="r_ab6216edb11e21a8e7a16f786314eb354"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#ab6216edb11e21a8e7a16f786314eb354">_get_wilcoxon_distr2</a> (<a class="el" href="__blas__subroutines_8h.html#a25eafceb38c8e75bc60701fea6623f71">n</a>)</td></tr>
<tr class="separator:ab6216edb11e21a8e7a16f786314eb354"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab402ca584d555bd7801ecda854f4fe26" id="r_ab402ca584d555bd7801ecda854f4fe26"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#ab402ca584d555bd7801ecda854f4fe26">_tau_b</a> (A)</td></tr>
<tr class="separator:ab402ca584d555bd7801ecda854f4fe26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a074f0b90d49d817a98c595d8828c8285" id="r_a074f0b90d49d817a98c595d8828c8285"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#a074f0b90d49d817a98c595d8828c8285">_somers_d</a> (A, alternative='two-sided')</td></tr>
<tr class="separator:a074f0b90d49d817a98c595d8828c8285"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30dc3c3fcba32b99672684269768e0ad" id="r_a30dc3c3fcba32b99672684269768e0ad"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#a30dc3c3fcba32b99672684269768e0ad">somersd</a> (x, y=None, alternative='two-sided')</td></tr>
<tr class="separator:a30dc3c3fcba32b99672684269768e0ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe6e1ec1b838cc5aa94f5763ef4d6c73" id="r_abe6e1ec1b838cc5aa94f5763ef4d6c73"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#abe6e1ec1b838cc5aa94f5763ef4d6c73">_all_partitions</a> (nx, ny)</td></tr>
<tr class="separator:abe6e1ec1b838cc5aa94f5763ef4d6c73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a049da303b8d2e7ca77354273262dfce1" id="r_a049da303b8d2e7ca77354273262dfce1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#a049da303b8d2e7ca77354273262dfce1">_compute_log_combinations</a> (<a class="el" href="__blas__subroutines_8h.html#a25eafceb38c8e75bc60701fea6623f71">n</a>)</td></tr>
<tr class="separator:a049da303b8d2e7ca77354273262dfce1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf3a3f656d72cd4dd010f781d4adfd3b" id="r_aaf3a3f656d72cd4dd010f781d4adfd3b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#aaf3a3f656d72cd4dd010f781d4adfd3b">barnard_exact</a> (table, alternative=&quot;two-sided&quot;, pooled=True, <a class="el" href="__blas__subroutines_8h.html#a25eafceb38c8e75bc60701fea6623f71">n</a>=32)</td></tr>
<tr class="separator:aaf3a3f656d72cd4dd010f781d4adfd3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a052b6fccc61a5edda7e687af88f5306f" id="r_a052b6fccc61a5edda7e687af88f5306f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#a052b6fccc61a5edda7e687af88f5306f">boschloo_exact</a> (table, alternative=&quot;two-sided&quot;, <a class="el" href="__blas__subroutines_8h.html#a25eafceb38c8e75bc60701fea6623f71">n</a>=32)</td></tr>
<tr class="separator:a052b6fccc61a5edda7e687af88f5306f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23f38a1f93c7b64e0f8a84998c5bf773" id="r_a23f38a1f93c7b64e0f8a84998c5bf773"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#a23f38a1f93c7b64e0f8a84998c5bf773">_get_binomial_log_p_value_with_nuisance_param</a> (nuisance_param, x1_sum_x2, x1_sum_x2_log_comb, index_arr)</td></tr>
<tr class="separator:a23f38a1f93c7b64e0f8a84998c5bf773"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3712906581da621fdf31e9a902435a7c" id="r_a3712906581da621fdf31e9a902435a7c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#a3712906581da621fdf31e9a902435a7c">_pval_cvm_2samp_exact</a> (s, nx, ny)</td></tr>
<tr class="separator:a3712906581da621fdf31e9a902435a7c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa1e4adb733eee8e9bb9fff1aca50ccea" id="r_aa1e4adb733eee8e9bb9fff1aca50ccea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#aa1e4adb733eee8e9bb9fff1aca50ccea">cramervonmises_2samp</a> (x, y, <a class="el" href="namespacescipy_1_1stats_1_1__multivariate.html#ad5850caf3faceef835b3baacc93038ee">method</a>='auto')</td></tr>
<tr class="separator:aa1e4adb733eee8e9bb9fff1aca50ccea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5cc887a889de984a6db2beca108ab3f" id="r_af5cc887a889de984a6db2beca108ab3f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#af5cc887a889de984a6db2beca108ab3f">_tukey_hsd_iv</a> (args)</td></tr>
<tr class="separator:af5cc887a889de984a6db2beca108ab3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4607ea9d99c9f1c317fc3eb75e234953" id="r_a4607ea9d99c9f1c317fc3eb75e234953"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#a4607ea9d99c9f1c317fc3eb75e234953">tukey_hsd</a> (*args)</td></tr>
<tr class="separator:a4607ea9d99c9f1c317fc3eb75e234953"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:ae2a84451be9d11611837fae22a5c57f1" id="r_ae2a84451be9d11611837fae22a5c57f1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#ae2a84451be9d11611837fae22a5c57f1">Epps_Singleton_2sampResult</a></td></tr>
<tr class="separator:ae2a84451be9d11611837fae22a5c57f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2902b2457de9fa8b25d97cc0edb71a6" id="r_aa2902b2457de9fa8b25d97cc0edb71a6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#aa2902b2457de9fa8b25d97cc0edb71a6">SomersDResult</a></td></tr>
<tr class="separator:aa2902b2457de9fa8b25d97cc0edb71a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08713966f8e9c1e73c9340fcfd7acb22" id="r_a08713966f8e9c1e73c9340fcfd7acb22"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#a08713966f8e9c1e73c9340fcfd7acb22">BarnardExactResult</a></td></tr>
<tr class="separator:a08713966f8e9c1e73c9340fcfd7acb22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae76ac75a487d0f7e9588bbe758dbc559" id="r_ae76ac75a487d0f7e9588bbe758dbc559"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__hypotests.html#ae76ac75a487d0f7e9588bbe758dbc559">BoschlooExactResult</a></td></tr>
<tr class="separator:ae76ac75a487d0f7e9588bbe758dbc559"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="abe6e1ec1b838cc5aa94f5763ef4d6c73" name="abe6e1ec1b838cc5aa94f5763ef4d6c73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe6e1ec1b838cc5aa94f5763ef4d6c73">&#9670;&#160;</a></span>_all_partitions()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._all_partitions </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>nx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ny</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Partition a set of indices into two fixed-length sets in all possible ways

Partition a set of indices 0 ... nx + ny - 1 into two sets of length nx and
ny in all possible ways (ignoring order of elements).
</pre> <div class="fragment"><div class="line"><span class="lineno">  671</span><span class="keyword">def </span>_all_partitions(nx, ny):</div>
<div class="line"><span class="lineno">  672</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  673</span><span class="stringliteral">    Partition a set of indices into two fixed-length sets in all possible ways</span></div>
<div class="line"><span class="lineno">  674</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  675</span><span class="stringliteral">    Partition a set of indices 0 ... nx + ny - 1 into two sets of length nx and</span></div>
<div class="line"><span class="lineno">  676</span><span class="stringliteral">    ny in all possible ways (ignoring order of elements).</span></div>
<div class="line"><span class="lineno">  677</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  678</span>    z = np.arange(nx+ny)</div>
<div class="line"><span class="lineno">  679</span>    <span class="keywordflow">for</span> c <span class="keywordflow">in</span> combinations(z, nx):</div>
<div class="line"><span class="lineno">  680</span>        x = np.array(c)</div>
<div class="line"><span class="lineno">  681</span>        mask = np.ones(nx+ny, bool)</div>
<div class="line"><span class="lineno">  682</span>        mask[x] = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  683</span>        y = z[mask]</div>
<div class="line"><span class="lineno">  684</span>        <span class="keywordflow">yield</span> x, y</div>
<div class="line"><span class="lineno">  685</span> </div>
<div class="line"><span class="lineno">  686</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab962c6513bc9f7e9c531a919d16d395e" name="ab962c6513bc9f7e9c531a919d16d395e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab962c6513bc9f7e9c531a919d16d395e">&#9670;&#160;</a></span>_cdf_cvm()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._cdf_cvm </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Calculate the cdf of the Cramér-von Mises statistic for a finite sample
size n. If N is None, use the asymptotic cdf (n=inf).

See equation 1.8 in Csörgő, S. and Faraway, J. (1996) for finite samples,
1.2 for the asymptotic cdf.

The function is not expected to be accurate for large values of x, say
x &gt; 2, when the cdf is very close to 1 and it might return values &gt; 1
in that case, e.g. _cdf_cvm(2.0, 12) = 1.0000027556716846. Moreover, it
is not accurate for small values of n, especially close to the bounds of
the distribution's domain, [1/(12*n), n/3], where the value jumps to 0
and 1, respectively. These are limitations of the approximation by Csörgő
and Faraway (1996) implemented in this function.
</pre> <div class="fragment"><div class="line"><span class="lineno">  243</span><span class="keyword">def </span>_cdf_cvm(x, n=None):</div>
<div class="line"><span class="lineno">  244</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">    Calculate the cdf of the Cramér-von Mises statistic for a finite sample</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">    size n. If N is None, use the asymptotic cdf (n=inf).</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">    See equation 1.8 in Csörgő, S. and Faraway, J. (1996) for finite samples,</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">    1.2 for the asymptotic cdf.</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">    The function is not expected to be accurate for large values of x, say</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">    x &gt; 2, when the cdf is very close to 1 and it might return values &gt; 1</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">    in that case, e.g. _cdf_cvm(2.0, 12) = 1.0000027556716846. Moreover, it</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">    is not accurate for small values of n, especially close to the bounds of</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">    the distribution&#39;s domain, [1/(12*n), n/3], where the value jumps to 0</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">    and 1, respectively. These are limitations of the approximation by Csörgő</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">    and Faraway (1996) implemented in this function.</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  259</span>    x = np.asarray(x)</div>
<div class="line"><span class="lineno">  260</span>    <span class="keywordflow">if</span> n <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  261</span>        y = _cdf_cvm_inf(x)</div>
<div class="line"><span class="lineno">  262</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  263</span>        <span class="comment"># support of the test statistic is [12/n, n/3], see 1.1 in [2]</span></div>
<div class="line"><span class="lineno">  264</span>        y = np.zeros_like(x, dtype=<span class="stringliteral">&#39;float&#39;</span>)</div>
<div class="line"><span class="lineno">  265</span>        sup = (1./(12*n) &lt; x) &amp; (x &lt; n/3.)</div>
<div class="line"><span class="lineno">  266</span>        <span class="comment"># note: _psi1_mod does not include the term _cdf_cvm_inf(x) / 12</span></div>
<div class="line"><span class="lineno">  267</span>        <span class="comment"># therefore, we need to add it here</span></div>
<div class="line"><span class="lineno">  268</span>        y[sup] = _cdf_cvm_inf(x[sup]) * (1 + 1./(12*n)) + _psi1_mod(x[sup]) / n</div>
<div class="line"><span class="lineno">  269</span>        y[x &gt;= n/3] = 1</div>
<div class="line"><span class="lineno">  270</span> </div>
<div class="line"><span class="lineno">  271</span>    <span class="keywordflow">if</span> y.ndim == 0:</div>
<div class="line"><span class="lineno">  272</span>        <span class="keywordflow">return</span> y[()]</div>
<div class="line"><span class="lineno">  273</span>    <span class="keywordflow">return</span> y</div>
<div class="line"><span class="lineno">  274</span> </div>
<div class="line"><span class="lineno">  275</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa2f7dc7ca6455ba7e757166a2a0b6341" name="aa2f7dc7ca6455ba7e757166a2a0b6341"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa2f7dc7ca6455ba7e757166a2a0b6341">&#9670;&#160;</a></span>_cdf_cvm_inf()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._cdf_cvm_inf </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Calculate the cdf of the Cramér-von Mises statistic (infinite sample size).

See equation 1.2 in Csörgő, S. and Faraway, J. (1996).

Implementation based on MAPLE code of Julian Faraway and R code of the
function pCvM in the package goftest (v1.1.1), permission granted
by Adrian Baddeley. Main difference in the implementation: the code
here keeps adding terms of the series until the terms are small enough.

The function is not expected to be accurate for large values of x, say
x &gt; 4, when the cdf is very close to 1.
</pre> <div class="fragment"><div class="line"><span class="lineno">  207</span><span class="keyword">def </span>_cdf_cvm_inf(x):</div>
<div class="line"><span class="lineno">  208</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">    Calculate the cdf of the Cramér-von Mises statistic (infinite sample size).</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">    See equation 1.2 in Csörgő, S. and Faraway, J. (1996).</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral">    Implementation based on MAPLE code of Julian Faraway and R code of the</span></div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">    function pCvM in the package goftest (v1.1.1), permission granted</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">    by Adrian Baddeley. Main difference in the implementation: the code</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">    here keeps adding terms of the series until the terms are small enough.</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">    The function is not expected to be accurate for large values of x, say</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">    x &gt; 4, when the cdf is very close to 1.</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  221</span>    x = np.asarray(x)</div>
<div class="line"><span class="lineno">  222</span> </div>
<div class="line"><span class="lineno">  223</span>    <span class="keyword">def </span>term(x, k):</div>
<div class="line"><span class="lineno">  224</span>        <span class="comment"># this expression can be found in [2], second line of (1.3)</span></div>
<div class="line"><span class="lineno">  225</span>        u = np.exp(gammaln(k + 0.5) - gammaln(k+1)) / (np.pi**1.5 * np.sqrt(x))</div>
<div class="line"><span class="lineno">  226</span>        y = 4*k + 1</div>
<div class="line"><span class="lineno">  227</span>        q = y**2 / (16*x)</div>
<div class="line"><span class="lineno">  228</span>        b = kv(0.25, q)</div>
<div class="line"><span class="lineno">  229</span>        <span class="keywordflow">return</span> u * np.sqrt(y) * np.exp(-q) * b</div>
<div class="line"><span class="lineno">  230</span> </div>
<div class="line"><span class="lineno">  231</span>    tot = np.zeros_like(x, dtype=<span class="stringliteral">&#39;float&#39;</span>)</div>
<div class="line"><span class="lineno">  232</span>    cond = np.ones_like(x, dtype=<span class="stringliteral">&#39;bool&#39;</span>)</div>
<div class="line"><span class="lineno">  233</span>    k = 0</div>
<div class="line"><span class="lineno">  234</span>    <span class="keywordflow">while</span> np.any(cond):</div>
<div class="line"><span class="lineno">  235</span>        z = term(x[cond], k)</div>
<div class="line"><span class="lineno">  236</span>        tot[cond] = tot[cond] + z</div>
<div class="line"><span class="lineno">  237</span>        cond[cond] = np.abs(z) &gt;= 1e-7</div>
<div class="line"><span class="lineno">  238</span>        k += 1</div>
<div class="line"><span class="lineno">  239</span> </div>
<div class="line"><span class="lineno">  240</span>    <span class="keywordflow">return</span> tot</div>
<div class="line"><span class="lineno">  241</span> </div>
<div class="line"><span class="lineno">  242</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a049da303b8d2e7ca77354273262dfce1" name="a049da303b8d2e7ca77354273262dfce1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a049da303b8d2e7ca77354273262dfce1">&#9670;&#160;</a></span>_compute_log_combinations()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._compute_log_combinations </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute all log combination of C(n, k).</pre> <div class="fragment"><div class="line"><span class="lineno">  687</span><span class="keyword">def </span>_compute_log_combinations(n):</div>
<div class="line"><span class="lineno">  688</span>    <span class="stringliteral">&quot;&quot;&quot;Compute all log combination of C(n, k).&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  689</span>    gammaln_arr = gammaln(np.arange(n + 1) + 1)</div>
<div class="line"><span class="lineno">  690</span>    <span class="keywordflow">return</span> gammaln(n + 1) - gammaln_arr - gammaln_arr[::-1]</div>
<div class="line"><span class="lineno">  691</span> </div>
<div class="line"><span class="lineno">  692</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a23f38a1f93c7b64e0f8a84998c5bf773" name="a23f38a1f93c7b64e0f8a84998c5bf773"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a23f38a1f93c7b64e0f8a84998c5bf773">&#9670;&#160;</a></span>_get_binomial_log_p_value_with_nuisance_param()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._get_binomial_log_p_value_with_nuisance_param </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>nuisance_param</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x1_sum_x2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x1_sum_x2_log_comb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>index_arr</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute the log pvalue in respect of a nuisance parameter considering
a 2x2 sample space.

Parameters
----------
nuisance_param : float
    nuisance parameter used in the computation of the maximisation of
    the p-value. Must be between 0 and 1

x1_sum_x2 : ndarray
    Sum of x1 and x2 inside barnard_exact

x1_sum_x2_log_comb : ndarray
    sum of the log combination of x1 and x2

index_arr : ndarray of boolean

Returns
-------
p_value : float
    Return the maximum p-value considering every nuisance paramater
    between 0 and 1

Notes
-----

Both Barnard's test and Boschloo's test iterate over a nuisance parameter
:math:`\pi \in [0, 1]` to find the maximum p-value. To search this
maxima, this function return the negative log pvalue with respect to the
nuisance parameter passed in params. This negative log p-value is then
used in `shgo` to find the minimum negative pvalue which is our maximum
pvalue.

Also, to compute the different combination used in the
p-values' computation formula, this function uses `gammaln` which is
more tolerant for large value than `scipy.special.comb`. `gammaln` gives
a log combination. For the little precision loss, performances are
improved a lot.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1179</span>):</div>
<div class="line"><span class="lineno"> 1180</span>    <span class="stringliteral">r&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1181</span><span class="stringliteral">    Compute the log pvalue in respect of a nuisance parameter considering</span></div>
<div class="line"><span class="lineno"> 1182</span><span class="stringliteral">    a 2x2 sample space.</span></div>
<div class="line"><span class="lineno"> 1183</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1184</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1185</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1186</span><span class="stringliteral">    nuisance_param : float</span></div>
<div class="line"><span class="lineno"> 1187</span><span class="stringliteral">        nuisance parameter used in the computation of the maximisation of</span></div>
<div class="line"><span class="lineno"> 1188</span><span class="stringliteral">        the p-value. Must be between 0 and 1</span></div>
<div class="line"><span class="lineno"> 1189</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1190</span><span class="stringliteral">    x1_sum_x2 : ndarray</span></div>
<div class="line"><span class="lineno"> 1191</span><span class="stringliteral">        Sum of x1 and x2 inside barnard_exact</span></div>
<div class="line"><span class="lineno"> 1192</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1193</span><span class="stringliteral">    x1_sum_x2_log_comb : ndarray</span></div>
<div class="line"><span class="lineno"> 1194</span><span class="stringliteral">        sum of the log combination of x1 and x2</span></div>
<div class="line"><span class="lineno"> 1195</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1196</span><span class="stringliteral">    index_arr : ndarray of boolean</span></div>
<div class="line"><span class="lineno"> 1197</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1198</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1199</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1200</span><span class="stringliteral">    p_value : float</span></div>
<div class="line"><span class="lineno"> 1201</span><span class="stringliteral">        Return the maximum p-value considering every nuisance paramater</span></div>
<div class="line"><span class="lineno"> 1202</span><span class="stringliteral">        between 0 and 1</span></div>
<div class="line"><span class="lineno"> 1203</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1204</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1205</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1206</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1207</span><span class="stringliteral">    Both Barnard&#39;s test and Boschloo&#39;s test iterate over a nuisance parameter</span></div>
<div class="line"><span class="lineno"> 1208</span><span class="stringliteral">    :math:`\pi \in [0, 1]` to find the maximum p-value. To search this</span></div>
<div class="line"><span class="lineno"> 1209</span><span class="stringliteral">    maxima, this function return the negative log pvalue with respect to the</span></div>
<div class="line"><span class="lineno"> 1210</span><span class="stringliteral">    nuisance parameter passed in params. This negative log p-value is then</span></div>
<div class="line"><span class="lineno"> 1211</span><span class="stringliteral">    used in `shgo` to find the minimum negative pvalue which is our maximum</span></div>
<div class="line"><span class="lineno"> 1212</span><span class="stringliteral">    pvalue.</span></div>
<div class="line"><span class="lineno"> 1213</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1214</span><span class="stringliteral">    Also, to compute the different combination used in the</span></div>
<div class="line"><span class="lineno"> 1215</span><span class="stringliteral">    p-values&#39; computation formula, this function uses `gammaln` which is</span></div>
<div class="line"><span class="lineno"> 1216</span><span class="stringliteral">    more tolerant for large value than `scipy.special.comb`. `gammaln` gives</span></div>
<div class="line"><span class="lineno"> 1217</span><span class="stringliteral">    a log combination. For the little precision loss, performances are</span></div>
<div class="line"><span class="lineno"> 1218</span><span class="stringliteral">    improved a lot.</span></div>
<div class="line"><span class="lineno"> 1219</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1220</span>    t1, t2 = x1_sum_x2.shape</div>
<div class="line"><span class="lineno"> 1221</span>    n = t1 + t2 - 2</div>
<div class="line"><span class="lineno"> 1222</span>    <span class="keyword">with</span> np.errstate(divide=<span class="stringliteral">&quot;ignore&quot;</span>, invalid=<span class="stringliteral">&quot;ignore&quot;</span>):</div>
<div class="line"><span class="lineno"> 1223</span>        log_nuisance = np.log(</div>
<div class="line"><span class="lineno"> 1224</span>            nuisance_param,</div>
<div class="line"><span class="lineno"> 1225</span>            out=np.zeros_like(nuisance_param),</div>
<div class="line"><span class="lineno"> 1226</span>            where=nuisance_param &gt;= 0,</div>
<div class="line"><span class="lineno"> 1227</span>        )</div>
<div class="line"><span class="lineno"> 1228</span>        log_1_minus_nuisance = np.log(</div>
<div class="line"><span class="lineno"> 1229</span>            1 - nuisance_param,</div>
<div class="line"><span class="lineno"> 1230</span>            out=np.zeros_like(nuisance_param),</div>
<div class="line"><span class="lineno"> 1231</span>            where=1 - nuisance_param &gt;= 0,</div>
<div class="line"><span class="lineno"> 1232</span>        )</div>
<div class="line"><span class="lineno"> 1233</span> </div>
<div class="line"><span class="lineno"> 1234</span>        nuisance_power_x1_x2 = log_nuisance * x1_sum_x2</div>
<div class="line"><span class="lineno"> 1235</span>        nuisance_power_x1_x2[(x1_sum_x2 == 0)[:, :]] = 0</div>
<div class="line"><span class="lineno"> 1236</span> </div>
<div class="line"><span class="lineno"> 1237</span>        nuisance_power_n_minus_x1_x2 = log_1_minus_nuisance * (n - x1_sum_x2)</div>
<div class="line"><span class="lineno"> 1238</span>        nuisance_power_n_minus_x1_x2[(x1_sum_x2 == n)[:, :]] = 0</div>
<div class="line"><span class="lineno"> 1239</span> </div>
<div class="line"><span class="lineno"> 1240</span>        tmp_log_values_arr = (</div>
<div class="line"><span class="lineno"> 1241</span>            x1_sum_x2_log_comb</div>
<div class="line"><span class="lineno"> 1242</span>            + nuisance_power_x1_x2</div>
<div class="line"><span class="lineno"> 1243</span>            + nuisance_power_n_minus_x1_x2</div>
<div class="line"><span class="lineno"> 1244</span>        )</div>
<div class="line"><span class="lineno"> 1245</span> </div>
<div class="line"><span class="lineno"> 1246</span>    tmp_values_from_index = tmp_log_values_arr[index_arr]</div>
<div class="line"><span class="lineno"> 1247</span> </div>
<div class="line"><span class="lineno"> 1248</span>    <span class="comment"># To avoid dividing by zero in log function and getting inf value,</span></div>
<div class="line"><span class="lineno"> 1249</span>    <span class="comment"># values are centered according to the max</span></div>
<div class="line"><span class="lineno"> 1250</span>    max_value = tmp_values_from_index.max()</div>
<div class="line"><span class="lineno"> 1251</span> </div>
<div class="line"><span class="lineno"> 1252</span>    <span class="comment"># To have better result&#39;s precision, the log pvalue is taken here.</span></div>
<div class="line"><span class="lineno"> 1253</span>    <span class="comment"># Indeed, pvalue is included inside [0, 1] interval. Passing the</span></div>
<div class="line"><span class="lineno"> 1254</span>    <span class="comment"># pvalue to log makes the interval a lot bigger ([-inf, 0]), and thus</span></div>
<div class="line"><span class="lineno"> 1255</span>    <span class="comment"># help us to achieve better precision</span></div>
<div class="line"><span class="lineno"> 1256</span>    <span class="keyword">with</span> np.errstate(divide=<span class="stringliteral">&quot;ignore&quot;</span>, invalid=<span class="stringliteral">&quot;ignore&quot;</span>):</div>
<div class="line"><span class="lineno"> 1257</span>        log_probs = np.exp(tmp_values_from_index - max_value).sum()</div>
<div class="line"><span class="lineno"> 1258</span>        log_pvalue = max_value + np.log(</div>
<div class="line"><span class="lineno"> 1259</span>            log_probs,</div>
<div class="line"><span class="lineno"> 1260</span>            out=np.full_like(log_probs, -np.inf),</div>
<div class="line"><span class="lineno"> 1261</span>            where=log_probs &gt; 0,</div>
<div class="line"><span class="lineno"> 1262</span>        )</div>
<div class="line"><span class="lineno"> 1263</span> </div>
<div class="line"><span class="lineno"> 1264</span>    <span class="comment"># Since shgo find the minima, minus log pvalue is returned</span></div>
<div class="line"><span class="lineno"> 1265</span>    <span class="keywordflow">return</span> -log_pvalue</div>
<div class="line"><span class="lineno"> 1266</span> </div>
<div class="line"><span class="lineno"> 1267</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae8a3a0780c9647797a3f4c8a912f8644" name="ae8a3a0780c9647797a3f4c8a912f8644"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae8a3a0780c9647797a3f4c8a912f8644">&#9670;&#160;</a></span>_get_wilcoxon_distr()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._get_wilcoxon_distr </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Distribution of probability of the Wilcoxon ranksum statistic r_plus (sum
of ranks of positive differences).
Returns an array with the probabilities of all the possible ranks
r = 0, ..., n*(n+1)/2
</pre> <div class="fragment"><div class="line"><span class="lineno">  392</span><span class="keyword">def </span>_get_wilcoxon_distr(n):</div>
<div class="line"><span class="lineno">  393</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  394</span><span class="stringliteral">    Distribution of probability of the Wilcoxon ranksum statistic r_plus (sum</span></div>
<div class="line"><span class="lineno">  395</span><span class="stringliteral">    of ranks of positive differences).</span></div>
<div class="line"><span class="lineno">  396</span><span class="stringliteral">    Returns an array with the probabilities of all the possible ranks</span></div>
<div class="line"><span class="lineno">  397</span><span class="stringliteral">    r = 0, ..., n*(n+1)/2</span></div>
<div class="line"><span class="lineno">  398</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  399</span>    c = np.ones(1, dtype=np.double)</div>
<div class="line"><span class="lineno">  400</span>    <span class="keywordflow">for</span> k <span class="keywordflow">in</span> range(1, n + 1):</div>
<div class="line"><span class="lineno">  401</span>        prev_c = c</div>
<div class="line"><span class="lineno">  402</span>        c = np.zeros(k * (k + 1) // 2 + 1, dtype=np.double)</div>
<div class="line"><span class="lineno">  403</span>        m = len(prev_c)</div>
<div class="line"><span class="lineno">  404</span>        c[:m] = prev_c * 0.5</div>
<div class="line"><span class="lineno">  405</span>        c[-m:] += prev_c * 0.5</div>
<div class="line"><span class="lineno">  406</span>    <span class="keywordflow">return</span> c</div>
<div class="line"><span class="lineno">  407</span> </div>
<div class="line"><span class="lineno">  408</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab6216edb11e21a8e7a16f786314eb354" name="ab6216edb11e21a8e7a16f786314eb354"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab6216edb11e21a8e7a16f786314eb354">&#9670;&#160;</a></span>_get_wilcoxon_distr2()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._get_wilcoxon_distr2 </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Distribution of probability of the Wilcoxon ranksum statistic r_plus (sum
of ranks of positive differences).
Returns an array with the probabilities of all the possible ranks
r = 0, ..., n*(n+1)/2
This is a slower reference function
References
----------
.. [1] 1. Harris T, Hardin JW. Exact Wilcoxon Signed-Rank and Wilcoxon
    Mann-Whitney Ranksum Tests. The Stata Journal. 2013;13(2):337-343.
</pre> <div class="fragment"><div class="line"><span class="lineno">  409</span><span class="keyword">def </span>_get_wilcoxon_distr2(n):</div>
<div class="line"><span class="lineno">  410</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral">    Distribution of probability of the Wilcoxon ranksum statistic r_plus (sum</span></div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral">    of ranks of positive differences).</span></div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral">    Returns an array with the probabilities of all the possible ranks</span></div>
<div class="line"><span class="lineno">  414</span><span class="stringliteral">    r = 0, ..., n*(n+1)/2</span></div>
<div class="line"><span class="lineno">  415</span><span class="stringliteral">    This is a slower reference function</span></div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">    .. [1] 1. Harris T, Hardin JW. Exact Wilcoxon Signed-Rank and Wilcoxon</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">        Mann-Whitney Ranksum Tests. The Stata Journal. 2013;13(2):337-343.</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  421</span>    ai = np.arange(1, n+1)[:, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  422</span>    t = n*(n+1)/2</div>
<div class="line"><span class="lineno">  423</span>    q = 2*t</div>
<div class="line"><span class="lineno">  424</span>    j = np.arange(q)</div>
<div class="line"><span class="lineno">  425</span>    theta = 2*np.pi/q*j</div>
<div class="line"><span class="lineno">  426</span>    phi_sp = np.prod(np.cos(theta*ai), axis=0)</div>
<div class="line"><span class="lineno">  427</span>    phi_s = np.exp(1j*theta*t) * phi_sp</div>
<div class="line"><span class="lineno">  428</span>    p = np.real(ifft(phi_s))</div>
<div class="line"><span class="lineno">  429</span>    res = np.zeros(int(t)+1)</div>
<div class="line"><span class="lineno">  430</span>    res[:-1:] = p[::2]</div>
<div class="line"><span class="lineno">  431</span>    res[0] /= 2</div>
<div class="line"><span class="lineno">  432</span>    res[-1] = res[0]</div>
<div class="line"><span class="lineno">  433</span>    <span class="keywordflow">return</span> res</div>
<div class="line"><span class="lineno">  434</span> </div>
<div class="line"><span class="lineno">  435</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a959d606f29bc461a5f200a7afed53515" name="a959d606f29bc461a5f200a7afed53515"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a959d606f29bc461a5f200a7afed53515">&#9670;&#160;</a></span>_psi1_mod()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._psi1_mod </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">psi1 is defined in equation 1.10 in Csörgő, S. and Faraway, J. (1996).
This implements a modified version by excluding the term V(x) / 12
(here: _cdf_cvm_inf(x) / 12) to avoid evaluating _cdf_cvm_inf(x)
twice in _cdf_cvm.

Implementation based on MAPLE code of Julian Faraway and R code of the
function pCvM in the package goftest (v1.1.1), permission granted
by Adrian Baddeley. Main difference in the implementation: the code
here keeps adding terms of the series until the terms are small enough.
</pre> <div class="fragment"><div class="line"><span class="lineno">  157</span><span class="keyword">def </span>_psi1_mod(x):</div>
<div class="line"><span class="lineno">  158</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">    psi1 is defined in equation 1.10 in Csörgő, S. and Faraway, J. (1996).</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">    This implements a modified version by excluding the term V(x) / 12</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">    (here: _cdf_cvm_inf(x) / 12) to avoid evaluating _cdf_cvm_inf(x)</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">    twice in _cdf_cvm.</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">    Implementation based on MAPLE code of Julian Faraway and R code of the</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">    function pCvM in the package goftest (v1.1.1), permission granted</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">    by Adrian Baddeley. Main difference in the implementation: the code</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">    here keeps adding terms of the series until the terms are small enough.</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  169</span> </div>
<div class="line"><span class="lineno">  170</span>    <span class="keyword">def </span>_ed2(y):</div>
<div class="line"><span class="lineno">  171</span>        z = y**2 / 4</div>
<div class="line"><span class="lineno">  172</span>        b = kv(1/4, z) + kv(3/4, z)</div>
<div class="line"><span class="lineno">  173</span>        <span class="keywordflow">return</span> np.exp(-z) * (y/2)**(3/2) * b / np.sqrt(np.pi)</div>
<div class="line"><span class="lineno">  174</span> </div>
<div class="line"><span class="lineno">  175</span>    <span class="keyword">def </span>_ed3(y):</div>
<div class="line"><span class="lineno">  176</span>        z = y**2 / 4</div>
<div class="line"><span class="lineno">  177</span>        c = np.exp(-z) / np.sqrt(np.pi)</div>
<div class="line"><span class="lineno">  178</span>        <span class="keywordflow">return</span> c * (y/2)**(5/2) * (2*kv(1/4, z) + 3*kv(3/4, z) - kv(5/4, z))</div>
<div class="line"><span class="lineno">  179</span> </div>
<div class="line"><span class="lineno">  180</span>    <span class="keyword">def </span>_Ak(k, x):</div>
<div class="line"><span class="lineno">  181</span>        m = 2*k + 1</div>
<div class="line"><span class="lineno">  182</span>        sx = 2 * np.sqrt(x)</div>
<div class="line"><span class="lineno">  183</span>        y1 = x**(3/4)</div>
<div class="line"><span class="lineno">  184</span>        y2 = x**(5/4)</div>
<div class="line"><span class="lineno">  185</span> </div>
<div class="line"><span class="lineno">  186</span>        e1 = m * gamma(k + 1/2) * _ed2((4 * k + 3)/sx) / (9 * y1)</div>
<div class="line"><span class="lineno">  187</span>        e2 = gamma(k + 1/2) * _ed3((4 * k + 1) / sx) / (72 * y2)</div>
<div class="line"><span class="lineno">  188</span>        e3 = 2 * (m + 2) * gamma(k + 3/2) * _ed3((4 * k + 5) / sx) / (12 * y2)</div>
<div class="line"><span class="lineno">  189</span>        e4 = 7 * m * gamma(k + 1/2) * _ed2((4 * k + 1) / sx) / (144 * y1)</div>
<div class="line"><span class="lineno">  190</span>        e5 = 7 * m * gamma(k + 1/2) * _ed2((4 * k + 5) / sx) / (144 * y1)</div>
<div class="line"><span class="lineno">  191</span> </div>
<div class="line"><span class="lineno">  192</span>        <span class="keywordflow">return</span> e1 + e2 + e3 + e4 + e5</div>
<div class="line"><span class="lineno">  193</span> </div>
<div class="line"><span class="lineno">  194</span>    x = np.asarray(x)</div>
<div class="line"><span class="lineno">  195</span>    tot = np.zeros_like(x, dtype=<span class="stringliteral">&#39;float&#39;</span>)</div>
<div class="line"><span class="lineno">  196</span>    cond = np.ones_like(x, dtype=<span class="stringliteral">&#39;bool&#39;</span>)</div>
<div class="line"><span class="lineno">  197</span>    k = 0</div>
<div class="line"><span class="lineno">  198</span>    <span class="keywordflow">while</span> np.any(cond):</div>
<div class="line"><span class="lineno">  199</span>        z = -_Ak(k, x[cond]) / (np.pi * gamma(k + 1))</div>
<div class="line"><span class="lineno">  200</span>        tot[cond] = tot[cond] + z</div>
<div class="line"><span class="lineno">  201</span>        cond[cond] = np.abs(z) &gt;= 1e-7</div>
<div class="line"><span class="lineno">  202</span>        k += 1</div>
<div class="line"><span class="lineno">  203</span> </div>
<div class="line"><span class="lineno">  204</span>    <span class="keywordflow">return</span> tot</div>
<div class="line"><span class="lineno">  205</span> </div>
<div class="line"><span class="lineno">  206</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3712906581da621fdf31e9a902435a7c" name="a3712906581da621fdf31e9a902435a7c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3712906581da621fdf31e9a902435a7c">&#9670;&#160;</a></span>_pval_cvm_2samp_exact()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._pval_cvm_2samp_exact </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>nx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ny</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute the exact p-value of the Cramer-von Mises two-sample test
for a given value s (float) of the test statistic by enumerating
all possible combinations. nx and ny are the sizes of the samples.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1268</span><span class="keyword">def </span>_pval_cvm_2samp_exact(s, nx, ny):</div>
<div class="line"><span class="lineno"> 1269</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1270</span><span class="stringliteral">    Compute the exact p-value of the Cramer-von Mises two-sample test</span></div>
<div class="line"><span class="lineno"> 1271</span><span class="stringliteral">    for a given value s (float) of the test statistic by enumerating</span></div>
<div class="line"><span class="lineno"> 1272</span><span class="stringliteral">    all possible combinations. nx and ny are the sizes of the samples.</span></div>
<div class="line"><span class="lineno"> 1273</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1274</span>    rangex = np.arange(nx)</div>
<div class="line"><span class="lineno"> 1275</span>    rangey = np.arange(ny)</div>
<div class="line"><span class="lineno"> 1276</span> </div>
<div class="line"><span class="lineno"> 1277</span>    us = []</div>
<div class="line"><span class="lineno"> 1278</span> </div>
<div class="line"><span class="lineno"> 1279</span>    <span class="comment"># x and y are all possible partitions of ranks from 0 to nx + ny - 1</span></div>
<div class="line"><span class="lineno"> 1280</span>    <span class="comment"># into two sets of length nx and ny</span></div>
<div class="line"><span class="lineno"> 1281</span>    <span class="comment"># Here, ranks are from 0 to nx + ny - 1 instead of 1 to nx + ny, but</span></div>
<div class="line"><span class="lineno"> 1282</span>    <span class="comment"># this does not change the value of the statistic.</span></div>
<div class="line"><span class="lineno"> 1283</span>    <span class="keywordflow">for</span> x, y <span class="keywordflow">in</span> _all_partitions(nx, ny):</div>
<div class="line"><span class="lineno"> 1284</span>        <span class="comment"># compute the statistic</span></div>
<div class="line"><span class="lineno"> 1285</span>        u = nx * np.sum((x - rangex)**2)</div>
<div class="line"><span class="lineno"> 1286</span>        u += ny * np.sum((y - rangey)**2)</div>
<div class="line"><span class="lineno"> 1287</span>        us.append(u)</div>
<div class="line"><span class="lineno"> 1288</span> </div>
<div class="line"><span class="lineno"> 1289</span>    <span class="comment"># compute the values of u and the frequencies</span></div>
<div class="line"><span class="lineno"> 1290</span>    u, cnt = np.unique(us, return_counts=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1291</span>    <span class="keywordflow">return</span> np.sum(cnt[u &gt;= s]) / np.sum(cnt)</div>
<div class="line"><span class="lineno"> 1292</span> </div>
<div class="line"><span class="lineno"> 1293</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a074f0b90d49d817a98c595d8828c8285" name="a074f0b90d49d817a98c595d8828c8285"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a074f0b90d49d817a98c595d8828c8285">&#9670;&#160;</a></span>_somers_d()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._somers_d </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alternative</em> = <code>'two-sided'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Calculate Somers' D and p-value from contingency table.</pre> <div class="fragment"><div class="line"><span class="lineno">  463</span><span class="keyword">def </span>_somers_d(A, alternative=&#39;two-sided&#39;):</div>
<div class="line"><span class="lineno">  464</span>    <span class="stringliteral">&quot;&quot;&quot;Calculate Somers&#39; D and p-value from contingency table.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  465</span>    <span class="comment"># See [3] page 1740</span></div>
<div class="line"><span class="lineno">  466</span> </div>
<div class="line"><span class="lineno">  467</span>    <span class="comment"># contingency table must be truly 2D</span></div>
<div class="line"><span class="lineno">  468</span>    <span class="keywordflow">if</span> A.shape[0] &lt;= 1 <span class="keywordflow">or</span> A.shape[1] &lt;= 1:</div>
<div class="line"><span class="lineno">  469</span>        <span class="keywordflow">return</span> np.nan, np.nan</div>
<div class="line"><span class="lineno">  470</span> </div>
<div class="line"><span class="lineno">  471</span>    NA = A.sum()</div>
<div class="line"><span class="lineno">  472</span>    NA2 = NA**2</div>
<div class="line"><span class="lineno">  473</span>    PA = _P(A)</div>
<div class="line"><span class="lineno">  474</span>    QA = _Q(A)</div>
<div class="line"><span class="lineno">  475</span>    Sri2 = (A.sum(axis=1)**2).sum()</div>
<div class="line"><span class="lineno">  476</span> </div>
<div class="line"><span class="lineno">  477</span>    d = (PA - QA)/(NA2 - Sri2)</div>
<div class="line"><span class="lineno">  478</span> </div>
<div class="line"><span class="lineno">  479</span>    S = _a_ij_Aij_Dij2(A) - (PA-QA)**2/NA</div>
<div class="line"><span class="lineno">  480</span> </div>
<div class="line"><span class="lineno">  481</span>    <span class="keyword">with</span> np.errstate(divide=<span class="stringliteral">&#39;ignore&#39;</span>):</div>
<div class="line"><span class="lineno">  482</span>        Z = (PA - QA)/(4*(S))**0.5</div>
<div class="line"><span class="lineno">  483</span> </div>
<div class="line"><span class="lineno">  484</span>    _, p = <a class="code hl_function" href="namespacescipy_1_1stats_1_1__stats__py.html#a0e20026493d260d023531ce41e26c269">scipy.stats._stats_py._normtest_finish</a>(Z, alternative)</div>
<div class="line"><span class="lineno">  485</span> </div>
<div class="line"><span class="lineno">  486</span>    <span class="keywordflow">return</span> d, p</div>
<div class="line"><span class="lineno">  487</span> </div>
<div class="line"><span class="lineno">  488</span> </div>
<div class="ttc" id="anamespacescipy_1_1stats_1_1__stats__py_html_a0e20026493d260d023531ce41e26c269"><div class="ttname"><a href="namespacescipy_1_1stats_1_1__stats__py.html#a0e20026493d260d023531ce41e26c269">scipy.stats._stats_py._normtest_finish</a></div><div class="ttdeci">_normtest_finish(z, alternative)</div><div class="ttdoc">NORMALITY TESTS #.</div><div class="ttdef"><b>Definition</b> _stats_py.py:1569</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab402ca584d555bd7801ecda854f4fe26" name="ab402ca584d555bd7801ecda854f4fe26"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab402ca584d555bd7801ecda854f4fe26">&#9670;&#160;</a></span>_tau_b()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._tau_b </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Calculate Kendall's tau-b and p-value from contingency table.</pre> <div class="fragment"><div class="line"><span class="lineno">  436</span><span class="keyword">def </span>_tau_b(A):</div>
<div class="line"><span class="lineno">  437</span>    <span class="stringliteral">&quot;&quot;&quot;Calculate Kendall&#39;s tau-b and p-value from contingency table.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  438</span>    <span class="comment"># See [2] 2.2 and 4.2</span></div>
<div class="line"><span class="lineno">  439</span> </div>
<div class="line"><span class="lineno">  440</span>    <span class="comment"># contingency table must be truly 2D</span></div>
<div class="line"><span class="lineno">  441</span>    <span class="keywordflow">if</span> A.shape[0] == 1 <span class="keywordflow">or</span> A.shape[1] == 1:</div>
<div class="line"><span class="lineno">  442</span>        <span class="keywordflow">return</span> np.nan, np.nan</div>
<div class="line"><span class="lineno">  443</span> </div>
<div class="line"><span class="lineno">  444</span>    NA = A.sum()</div>
<div class="line"><span class="lineno">  445</span>    PA = _P(A)</div>
<div class="line"><span class="lineno">  446</span>    QA = _Q(A)</div>
<div class="line"><span class="lineno">  447</span>    Sri2 = (A.sum(axis=1)**2).sum()</div>
<div class="line"><span class="lineno">  448</span>    Scj2 = (A.sum(axis=0)**2).sum()</div>
<div class="line"><span class="lineno">  449</span>    denominator = (NA**2 - Sri2)*(NA**2 - Scj2)</div>
<div class="line"><span class="lineno">  450</span> </div>
<div class="line"><span class="lineno">  451</span>    tau = (PA-QA)/(denominator)**0.5</div>
<div class="line"><span class="lineno">  452</span> </div>
<div class="line"><span class="lineno">  453</span>    numerator = 4*(_a_ij_Aij_Dij2(A) - (PA - QA)**2 / NA)</div>
<div class="line"><span class="lineno">  454</span>    s02_tau_b = numerator/denominator</div>
<div class="line"><span class="lineno">  455</span>    <span class="keywordflow">if</span> s02_tau_b == 0:  <span class="comment"># Avoid divide by zero</span></div>
<div class="line"><span class="lineno">  456</span>        <span class="keywordflow">return</span> tau, 0</div>
<div class="line"><span class="lineno">  457</span>    Z = tau/s02_tau_b**0.5</div>
<div class="line"><span class="lineno">  458</span>    p = 2*norm.sf(abs(Z))  <span class="comment"># 2-sided p-value</span></div>
<div class="line"><span class="lineno">  459</span> </div>
<div class="line"><span class="lineno">  460</span>    <span class="keywordflow">return</span> tau, p</div>
<div class="line"><span class="lineno">  461</span> </div>
<div class="line"><span class="lineno">  462</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af5cc887a889de984a6db2beca108ab3f" name="af5cc887a889de984a6db2beca108ab3f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5cc887a889de984a6db2beca108ab3f">&#9670;&#160;</a></span>_tukey_hsd_iv()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests._tukey_hsd_iv </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>args</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1573</span><span class="keyword">def </span>_tukey_hsd_iv(args):</div>
<div class="line"><span class="lineno"> 1574</span>    <span class="keywordflow">if</span> (len(args)) &lt; 2:</div>
<div class="line"><span class="lineno"> 1575</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;There must be more than 1 treatment.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1576</span>    args = [np.asarray(arg) <span class="keywordflow">for</span> arg <span class="keywordflow">in</span> args]</div>
<div class="line"><span class="lineno"> 1577</span>    <span class="keywordflow">for</span> arg <span class="keywordflow">in</span> args:</div>
<div class="line"><span class="lineno"> 1578</span>        <span class="keywordflow">if</span> arg.ndim != 1:</div>
<div class="line"><span class="lineno"> 1579</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Input samples must be one-dimensional.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1580</span>        <span class="keywordflow">if</span> arg.size &lt;= 1:</div>
<div class="line"><span class="lineno"> 1581</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Input sample size must be greater than one.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1582</span>        <span class="keywordflow">if</span> np.isinf(arg).any():</div>
<div class="line"><span class="lineno"> 1583</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Input samples must be finite.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1584</span>    <span class="keywordflow">return</span> args</div>
<div class="line"><span class="lineno"> 1585</span> </div>
<div class="line"><span class="lineno"> 1586</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aaf3a3f656d72cd4dd010f781d4adfd3b" name="aaf3a3f656d72cd4dd010f781d4adfd3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf3a3f656d72cd4dd010f781d4adfd3b">&#9670;&#160;</a></span>barnard_exact()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.barnard_exact </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>table</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alternative</em> = <code>&quot;two-sided&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pooled</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em> = <code>32</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Perform a Barnard exact test on a 2x2 contingency table.

Parameters
----------
table : array_like of ints
    A 2x2 contingency table.  Elements should be non-negative integers.

alternative : {'two-sided', 'less', 'greater'}, optional
    Defines the null and alternative hypotheses. Default is 'two-sided'.
    Please see explanations in the Notes section below.

pooled : bool, optional
    Whether to compute score statistic with pooled variance (as in
    Student's t-test, for example) or unpooled variance (as in Welch's
    t-test). Default is ``True``.

n : int, optional
    Number of sampling points used in the construction of the sampling
    method. Note that this argument will automatically be converted to
    the next higher power of 2 since `scipy.stats.qmc.Sobol` is used to
    select sample points. Default is 32. Must be positive. In most cases,
    32 points is enough to reach good precision. More points comes at
    performance cost.

Returns
-------
ber : BarnardExactResult
    A result object with the following attributes.

    statistic : float
        The Wald statistic with pooled or unpooled variance, depending
        on the user choice of `pooled`.

    pvalue : float
        P-value, the probability of obtaining a distribution at least as
        extreme as the one that was actually observed, assuming that the
        null hypothesis is true.

See Also
--------
chi2_contingency : Chi-square test of independence of variables in a
    contingency table.
fisher_exact : Fisher exact test on a 2x2 contingency table.
boschloo_exact : Boschloo's exact test on a 2x2 contingency table,
    which is an uniformly more powerful alternative to Fisher's exact test.

Notes
-----
Barnard's test is an exact test used in the analysis of contingency
tables. It examines the association of two categorical variables, and
is a more powerful alternative than Fisher's exact test
for 2x2 contingency tables.

Let's define :math:`X_0` a 2x2 matrix representing the observed sample,
where each column stores the binomial experiment, as in the example
below. Let's also define :math:`p_1, p_2` the theoretical binomial
probabilities for  :math:`x_{11}` and :math:`x_{12}`. When using
Barnard exact test, we can assert three different null hypotheses :

- :math:`H_0 : p_1 \geq p_2` versus :math:`H_1 : p_1 &lt; p_2`,
  with `alternative` = "less"

- :math:`H_0 : p_1 \leq p_2` versus :math:`H_1 : p_1 &gt; p_2`,
  with `alternative` = "greater"

- :math:`H_0 : p_1 = p_2` versus :math:`H_1 : p_1 \neq p_2`,
  with `alternative` = "two-sided" (default one)

In order to compute Barnard's exact test, we are using the Wald
statistic [3]_ with pooled or unpooled variance.
Under the default assumption that both variances are equal
(``pooled = True``), the statistic is computed as:

.. math::

    T(X) = \frac{
        \hat{p}_1 - \hat{p}_2
    }{
        \sqrt{
            \hat{p}(1 - \hat{p})
            (\frac{1}{c_1} +
            \frac{1}{c_2})
        }
    }

with :math:`\hat{p}_1, \hat{p}_2` and :math:`\hat{p}` the estimator of
:math:`p_1, p_2` and :math:`p`, the latter being the combined probability,
given the assumption that :math:`p_1 = p_2`.

If this assumption is invalid (``pooled = False``), the statistic is:

.. math::

    T(X) = \frac{
        \hat{p}_1 - \hat{p}_2
    }{
        \sqrt{
            \frac{\hat{p}_1 (1 - \hat{p}_1)}{c_1} +
            \frac{\hat{p}_2 (1 - \hat{p}_2)}{c_2}
        }
    }

The p-value is then computed as:

.. math::

    \sum
        \binom{c_1}{x_{11}}
        \binom{c_2}{x_{12}}
        \pi^{x_{11} + x_{12}}
        (1 - \pi)^{t - x_{11} - x_{12}}

where the sum is over all  2x2 contingency tables :math:`X` such that:
* :math:`T(X) \leq T(X_0)` when `alternative` = "less",
* :math:`T(X) \geq T(X_0)` when `alternative` = "greater", or
* :math:`T(X) \geq |T(X_0)|` when `alternative` = "two-sided".
Above, :math:`c_1, c_2` are the sum of the columns 1 and 2,
and :math:`t` the total (sum of the 4 sample's element).

The returned p-value is the maximum p-value taken over the nuisance
parameter :math:`\pi`, where :math:`0 \leq \pi \leq 1`.

This function's complexity is :math:`O(n c_1 c_2)`, where `n` is the
number of sample points.

References
----------
.. [1] Barnard, G. A. "Significance Tests for 2x2 Tables". *Biometrika*.
       34.1/2 (1947): 123-138. :doi:`dpgkg3`

.. [2] Mehta, Cyrus R., and Pralay Senchaudhuri. "Conditional versus
       unconditional exact tests for comparing two binomials."
       *Cytel Software Corporation* 675 (2003): 1-5.

.. [3] "Wald Test". *Wikipedia*. https://en.wikipedia.org/wiki/Wald_test

Examples
--------
An example use of Barnard's test is presented in [2]_.

    Consider the following example of a vaccine efficacy study
    (Chan, 1998). In a randomized clinical trial of 30 subjects, 15 were
    inoculated with a recombinant DNA influenza vaccine and the 15 were
    inoculated with a placebo. Twelve of the 15 subjects in the placebo
    group (80%) eventually became infected with influenza whereas for the
    vaccine group, only 7 of the 15 subjects (47%) became infected. The
    data are tabulated as a 2 x 2 table::

            Vaccine  Placebo
        Yes     7        12
        No      8        3

When working with statistical hypothesis testing, we usually use a
threshold probability or significance level upon which we decide
to reject the null hypothesis :math:`H_0`. Suppose we choose the common
significance level of 5%.

Our alternative hypothesis is that the vaccine will lower the chance of
becoming infected with the virus; that is, the probability :math:`p_1` of
catching the virus with the vaccine will be *less than* the probability
:math:`p_2` of catching the virus without the vaccine.  Therefore, we call
`barnard_exact` with the ``alternative="less"`` option:

&gt;&gt;&gt; import scipy.stats as stats
&gt;&gt;&gt; res = stats.barnard_exact([[7, 12], [8, 3]], alternative="less")
&gt;&gt;&gt; res.statistic
-1.894...
&gt;&gt;&gt; res.pvalue
0.03407...

Under the null hypothesis that the vaccine will not lower the chance of
becoming infected, the probability of obtaining test results at least as
extreme as the observed data is approximately 3.4%. Since this p-value is
less than our chosen significance level, we have evidence to reject
:math:`H_0` in favor of the alternative.

Suppose we had used Fisher's exact test instead:

&gt;&gt;&gt; _, pvalue = stats.fisher_exact([[7, 12], [8, 3]], alternative="less")
&gt;&gt;&gt; pvalue
0.0640...

With the same threshold significance of 5%, we would not have been able
to reject the null hypothesis in favor of the alternative. As stated in
[2]_, Barnard's test is uniformly more powerful than Fisher's exact test
because Barnard's test does not condition on any margin. Fisher's test
should only be used when both sets of marginals are fixed.</pre> <div class="fragment"><div class="line"><span class="lineno">  698</span><span class="keyword">def </span>barnard_exact(table, alternative=&quot;two-sided&quot;, pooled=True, n=32):</div>
<div class="line"><span class="lineno">  699</span>    <span class="stringliteral">r&quot;&quot;&quot;Perform a Barnard exact test on a 2x2 contingency table.</span></div>
<div class="line"><span class="lineno">  700</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  701</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  702</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  703</span><span class="stringliteral">    table : array_like of ints</span></div>
<div class="line"><span class="lineno">  704</span><span class="stringliteral">        A 2x2 contingency table.  Elements should be non-negative integers.</span></div>
<div class="line"><span class="lineno">  705</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  706</span><span class="stringliteral">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span></div>
<div class="line"><span class="lineno">  707</span><span class="stringliteral">        Defines the null and alternative hypotheses. Default is &#39;two-sided&#39;.</span></div>
<div class="line"><span class="lineno">  708</span><span class="stringliteral">        Please see explanations in the Notes section below.</span></div>
<div class="line"><span class="lineno">  709</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  710</span><span class="stringliteral">    pooled : bool, optional</span></div>
<div class="line"><span class="lineno">  711</span><span class="stringliteral">        Whether to compute score statistic with pooled variance (as in</span></div>
<div class="line"><span class="lineno">  712</span><span class="stringliteral">        Student&#39;s t-test, for example) or unpooled variance (as in Welch&#39;s</span></div>
<div class="line"><span class="lineno">  713</span><span class="stringliteral">        t-test). Default is ``True``.</span></div>
<div class="line"><span class="lineno">  714</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  715</span><span class="stringliteral">    n : int, optional</span></div>
<div class="line"><span class="lineno">  716</span><span class="stringliteral">        Number of sampling points used in the construction of the sampling</span></div>
<div class="line"><span class="lineno">  717</span><span class="stringliteral">        method. Note that this argument will automatically be converted to</span></div>
<div class="line"><span class="lineno">  718</span><span class="stringliteral">        the next higher power of 2 since `scipy.stats.qmc.Sobol` is used to</span></div>
<div class="line"><span class="lineno">  719</span><span class="stringliteral">        select sample points. Default is 32. Must be positive. In most cases,</span></div>
<div class="line"><span class="lineno">  720</span><span class="stringliteral">        32 points is enough to reach good precision. More points comes at</span></div>
<div class="line"><span class="lineno">  721</span><span class="stringliteral">        performance cost.</span></div>
<div class="line"><span class="lineno">  722</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  723</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  724</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  725</span><span class="stringliteral">    ber : BarnardExactResult</span></div>
<div class="line"><span class="lineno">  726</span><span class="stringliteral">        A result object with the following attributes.</span></div>
<div class="line"><span class="lineno">  727</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  728</span><span class="stringliteral">        statistic : float</span></div>
<div class="line"><span class="lineno">  729</span><span class="stringliteral">            The Wald statistic with pooled or unpooled variance, depending</span></div>
<div class="line"><span class="lineno">  730</span><span class="stringliteral">            on the user choice of `pooled`.</span></div>
<div class="line"><span class="lineno">  731</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  732</span><span class="stringliteral">        pvalue : float</span></div>
<div class="line"><span class="lineno">  733</span><span class="stringliteral">            P-value, the probability of obtaining a distribution at least as</span></div>
<div class="line"><span class="lineno">  734</span><span class="stringliteral">            extreme as the one that was actually observed, assuming that the</span></div>
<div class="line"><span class="lineno">  735</span><span class="stringliteral">            null hypothesis is true.</span></div>
<div class="line"><span class="lineno">  736</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  737</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  738</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  739</span><span class="stringliteral">    chi2_contingency : Chi-square test of independence of variables in a</span></div>
<div class="line"><span class="lineno">  740</span><span class="stringliteral">        contingency table.</span></div>
<div class="line"><span class="lineno">  741</span><span class="stringliteral">    fisher_exact : Fisher exact test on a 2x2 contingency table.</span></div>
<div class="line"><span class="lineno">  742</span><span class="stringliteral">    boschloo_exact : Boschloo&#39;s exact test on a 2x2 contingency table,</span></div>
<div class="line"><span class="lineno">  743</span><span class="stringliteral">        which is an uniformly more powerful alternative to Fisher&#39;s exact test.</span></div>
<div class="line"><span class="lineno">  744</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  745</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  746</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  747</span><span class="stringliteral">    Barnard&#39;s test is an exact test used in the analysis of contingency</span></div>
<div class="line"><span class="lineno">  748</span><span class="stringliteral">    tables. It examines the association of two categorical variables, and</span></div>
<div class="line"><span class="lineno">  749</span><span class="stringliteral">    is a more powerful alternative than Fisher&#39;s exact test</span></div>
<div class="line"><span class="lineno">  750</span><span class="stringliteral">    for 2x2 contingency tables.</span></div>
<div class="line"><span class="lineno">  751</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  752</span><span class="stringliteral">    Let&#39;s define :math:`X_0` a 2x2 matrix representing the observed sample,</span></div>
<div class="line"><span class="lineno">  753</span><span class="stringliteral">    where each column stores the binomial experiment, as in the example</span></div>
<div class="line"><span class="lineno">  754</span><span class="stringliteral">    below. Let&#39;s also define :math:`p_1, p_2` the theoretical binomial</span></div>
<div class="line"><span class="lineno">  755</span><span class="stringliteral">    probabilities for  :math:`x_{11}` and :math:`x_{12}`. When using</span></div>
<div class="line"><span class="lineno">  756</span><span class="stringliteral">    Barnard exact test, we can assert three different null hypotheses :</span></div>
<div class="line"><span class="lineno">  757</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  758</span><span class="stringliteral">    - :math:`H_0 : p_1 \geq p_2` versus :math:`H_1 : p_1 &lt; p_2`,</span></div>
<div class="line"><span class="lineno">  759</span><span class="stringliteral">      with `alternative` = &quot;less&quot;</span></div>
<div class="line"><span class="lineno">  760</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  761</span><span class="stringliteral">    - :math:`H_0 : p_1 \leq p_2` versus :math:`H_1 : p_1 &gt; p_2`,</span></div>
<div class="line"><span class="lineno">  762</span><span class="stringliteral">      with `alternative` = &quot;greater&quot;</span></div>
<div class="line"><span class="lineno">  763</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  764</span><span class="stringliteral">    - :math:`H_0 : p_1 = p_2` versus :math:`H_1 : p_1 \neq p_2`,</span></div>
<div class="line"><span class="lineno">  765</span><span class="stringliteral">      with `alternative` = &quot;two-sided&quot; (default one)</span></div>
<div class="line"><span class="lineno">  766</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  767</span><span class="stringliteral">    In order to compute Barnard&#39;s exact test, we are using the Wald</span></div>
<div class="line"><span class="lineno">  768</span><span class="stringliteral">    statistic [3]_ with pooled or unpooled variance.</span></div>
<div class="line"><span class="lineno">  769</span><span class="stringliteral">    Under the default assumption that both variances are equal</span></div>
<div class="line"><span class="lineno">  770</span><span class="stringliteral">    (``pooled = True``), the statistic is computed as:</span></div>
<div class="line"><span class="lineno">  771</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  772</span><span class="stringliteral">    .. math::</span></div>
<div class="line"><span class="lineno">  773</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  774</span><span class="stringliteral">        T(X) = \frac{</span></div>
<div class="line"><span class="lineno">  775</span><span class="stringliteral">            \hat{p}_1 - \hat{p}_2</span></div>
<div class="line"><span class="lineno">  776</span><span class="stringliteral">        }{</span></div>
<div class="line"><span class="lineno">  777</span><span class="stringliteral">            \sqrt{</span></div>
<div class="line"><span class="lineno">  778</span><span class="stringliteral">                \hat{p}(1 - \hat{p})</span></div>
<div class="line"><span class="lineno">  779</span><span class="stringliteral">                (\frac{1}{c_1} +</span></div>
<div class="line"><span class="lineno">  780</span><span class="stringliteral">                \frac{1}{c_2})</span></div>
<div class="line"><span class="lineno">  781</span><span class="stringliteral">            }</span></div>
<div class="line"><span class="lineno">  782</span><span class="stringliteral">        }</span></div>
<div class="line"><span class="lineno">  783</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  784</span><span class="stringliteral">    with :math:`\hat{p}_1, \hat{p}_2` and :math:`\hat{p}` the estimator of</span></div>
<div class="line"><span class="lineno">  785</span><span class="stringliteral">    :math:`p_1, p_2` and :math:`p`, the latter being the combined probability,</span></div>
<div class="line"><span class="lineno">  786</span><span class="stringliteral">    given the assumption that :math:`p_1 = p_2`.</span></div>
<div class="line"><span class="lineno">  787</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  788</span><span class="stringliteral">    If this assumption is invalid (``pooled = False``), the statistic is:</span></div>
<div class="line"><span class="lineno">  789</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  790</span><span class="stringliteral">    .. math::</span></div>
<div class="line"><span class="lineno">  791</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  792</span><span class="stringliteral">        T(X) = \frac{</span></div>
<div class="line"><span class="lineno">  793</span><span class="stringliteral">            \hat{p}_1 - \hat{p}_2</span></div>
<div class="line"><span class="lineno">  794</span><span class="stringliteral">        }{</span></div>
<div class="line"><span class="lineno">  795</span><span class="stringliteral">            \sqrt{</span></div>
<div class="line"><span class="lineno">  796</span><span class="stringliteral">                \frac{\hat{p}_1 (1 - \hat{p}_1)}{c_1} +</span></div>
<div class="line"><span class="lineno">  797</span><span class="stringliteral">                \frac{\hat{p}_2 (1 - \hat{p}_2)}{c_2}</span></div>
<div class="line"><span class="lineno">  798</span><span class="stringliteral">            }</span></div>
<div class="line"><span class="lineno">  799</span><span class="stringliteral">        }</span></div>
<div class="line"><span class="lineno">  800</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  801</span><span class="stringliteral">    The p-value is then computed as:</span></div>
<div class="line"><span class="lineno">  802</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  803</span><span class="stringliteral">    .. math::</span></div>
<div class="line"><span class="lineno">  804</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  805</span><span class="stringliteral">        \sum</span></div>
<div class="line"><span class="lineno">  806</span><span class="stringliteral">            \binom{c_1}{x_{11}}</span></div>
<div class="line"><span class="lineno">  807</span><span class="stringliteral">            \binom{c_2}{x_{12}}</span></div>
<div class="line"><span class="lineno">  808</span><span class="stringliteral">            \pi^{x_{11} + x_{12}}</span></div>
<div class="line"><span class="lineno">  809</span><span class="stringliteral">            (1 - \pi)^{t - x_{11} - x_{12}}</span></div>
<div class="line"><span class="lineno">  810</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  811</span><span class="stringliteral">    where the sum is over all  2x2 contingency tables :math:`X` such that:</span></div>
<div class="line"><span class="lineno">  812</span><span class="stringliteral">    * :math:`T(X) \leq T(X_0)` when `alternative` = &quot;less&quot;,</span></div>
<div class="line"><span class="lineno">  813</span><span class="stringliteral">    * :math:`T(X) \geq T(X_0)` when `alternative` = &quot;greater&quot;, or</span></div>
<div class="line"><span class="lineno">  814</span><span class="stringliteral">    * :math:`T(X) \geq |T(X_0)|` when `alternative` = &quot;two-sided&quot;.</span></div>
<div class="line"><span class="lineno">  815</span><span class="stringliteral">    Above, :math:`c_1, c_2` are the sum of the columns 1 and 2,</span></div>
<div class="line"><span class="lineno">  816</span><span class="stringliteral">    and :math:`t` the total (sum of the 4 sample&#39;s element).</span></div>
<div class="line"><span class="lineno">  817</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  818</span><span class="stringliteral">    The returned p-value is the maximum p-value taken over the nuisance</span></div>
<div class="line"><span class="lineno">  819</span><span class="stringliteral">    parameter :math:`\pi`, where :math:`0 \leq \pi \leq 1`.</span></div>
<div class="line"><span class="lineno">  820</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  821</span><span class="stringliteral">    This function&#39;s complexity is :math:`O(n c_1 c_2)`, where `n` is the</span></div>
<div class="line"><span class="lineno">  822</span><span class="stringliteral">    number of sample points.</span></div>
<div class="line"><span class="lineno">  823</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  824</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  825</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  826</span><span class="stringliteral">    .. [1] Barnard, G. A. &quot;Significance Tests for 2x2 Tables&quot;. *Biometrika*.</span></div>
<div class="line"><span class="lineno">  827</span><span class="stringliteral">           34.1/2 (1947): 123-138. :doi:`dpgkg3`</span></div>
<div class="line"><span class="lineno">  828</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  829</span><span class="stringliteral">    .. [2] Mehta, Cyrus R., and Pralay Senchaudhuri. &quot;Conditional versus</span></div>
<div class="line"><span class="lineno">  830</span><span class="stringliteral">           unconditional exact tests for comparing two binomials.&quot;</span></div>
<div class="line"><span class="lineno">  831</span><span class="stringliteral">           *Cytel Software Corporation* 675 (2003): 1-5.</span></div>
<div class="line"><span class="lineno">  832</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  833</span><span class="stringliteral">    .. [3] &quot;Wald Test&quot;. *Wikipedia*. https://en.wikipedia.org/wiki/Wald_test</span></div>
<div class="line"><span class="lineno">  834</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  835</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  836</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  837</span><span class="stringliteral">    An example use of Barnard&#39;s test is presented in [2]_.</span></div>
<div class="line"><span class="lineno">  838</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  839</span><span class="stringliteral">        Consider the following example of a vaccine efficacy study</span></div>
<div class="line"><span class="lineno">  840</span><span class="stringliteral">        (Chan, 1998). In a randomized clinical trial of 30 subjects, 15 were</span></div>
<div class="line"><span class="lineno">  841</span><span class="stringliteral">        inoculated with a recombinant DNA influenza vaccine and the 15 were</span></div>
<div class="line"><span class="lineno">  842</span><span class="stringliteral">        inoculated with a placebo. Twelve of the 15 subjects in the placebo</span></div>
<div class="line"><span class="lineno">  843</span><span class="stringliteral">        group (80%) eventually became infected with influenza whereas for the</span></div>
<div class="line"><span class="lineno">  844</span><span class="stringliteral">        vaccine group, only 7 of the 15 subjects (47%) became infected. The</span></div>
<div class="line"><span class="lineno">  845</span><span class="stringliteral">        data are tabulated as a 2 x 2 table::</span></div>
<div class="line"><span class="lineno">  846</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  847</span><span class="stringliteral">                Vaccine  Placebo</span></div>
<div class="line"><span class="lineno">  848</span><span class="stringliteral">            Yes     7        12</span></div>
<div class="line"><span class="lineno">  849</span><span class="stringliteral">            No      8        3</span></div>
<div class="line"><span class="lineno">  850</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  851</span><span class="stringliteral">    When working with statistical hypothesis testing, we usually use a</span></div>
<div class="line"><span class="lineno">  852</span><span class="stringliteral">    threshold probability or significance level upon which we decide</span></div>
<div class="line"><span class="lineno">  853</span><span class="stringliteral">    to reject the null hypothesis :math:`H_0`. Suppose we choose the common</span></div>
<div class="line"><span class="lineno">  854</span><span class="stringliteral">    significance level of 5%.</span></div>
<div class="line"><span class="lineno">  855</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  856</span><span class="stringliteral">    Our alternative hypothesis is that the vaccine will lower the chance of</span></div>
<div class="line"><span class="lineno">  857</span><span class="stringliteral">    becoming infected with the virus; that is, the probability :math:`p_1` of</span></div>
<div class="line"><span class="lineno">  858</span><span class="stringliteral">    catching the virus with the vaccine will be *less than* the probability</span></div>
<div class="line"><span class="lineno">  859</span><span class="stringliteral">    :math:`p_2` of catching the virus without the vaccine.  Therefore, we call</span></div>
<div class="line"><span class="lineno">  860</span><span class="stringliteral">    `barnard_exact` with the ``alternative=&quot;less&quot;`` option:</span></div>
<div class="line"><span class="lineno">  861</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  862</span><span class="stringliteral">    &gt;&gt;&gt; import scipy.stats as stats</span></div>
<div class="line"><span class="lineno">  863</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.barnard_exact([[7, 12], [8, 3]], alternative=&quot;less&quot;)</span></div>
<div class="line"><span class="lineno">  864</span><span class="stringliteral">    &gt;&gt;&gt; res.statistic</span></div>
<div class="line"><span class="lineno">  865</span><span class="stringliteral">    -1.894...</span></div>
<div class="line"><span class="lineno">  866</span><span class="stringliteral">    &gt;&gt;&gt; res.pvalue</span></div>
<div class="line"><span class="lineno">  867</span><span class="stringliteral">    0.03407...</span></div>
<div class="line"><span class="lineno">  868</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  869</span><span class="stringliteral">    Under the null hypothesis that the vaccine will not lower the chance of</span></div>
<div class="line"><span class="lineno">  870</span><span class="stringliteral">    becoming infected, the probability of obtaining test results at least as</span></div>
<div class="line"><span class="lineno">  871</span><span class="stringliteral">    extreme as the observed data is approximately 3.4%. Since this p-value is</span></div>
<div class="line"><span class="lineno">  872</span><span class="stringliteral">    less than our chosen significance level, we have evidence to reject</span></div>
<div class="line"><span class="lineno">  873</span><span class="stringliteral">    :math:`H_0` in favor of the alternative.</span></div>
<div class="line"><span class="lineno">  874</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  875</span><span class="stringliteral">    Suppose we had used Fisher&#39;s exact test instead:</span></div>
<div class="line"><span class="lineno">  876</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  877</span><span class="stringliteral">    &gt;&gt;&gt; _, pvalue = stats.fisher_exact([[7, 12], [8, 3]], alternative=&quot;less&quot;)</span></div>
<div class="line"><span class="lineno">  878</span><span class="stringliteral">    &gt;&gt;&gt; pvalue</span></div>
<div class="line"><span class="lineno">  879</span><span class="stringliteral">    0.0640...</span></div>
<div class="line"><span class="lineno">  880</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  881</span><span class="stringliteral">    With the same threshold significance of 5%, we would not have been able</span></div>
<div class="line"><span class="lineno">  882</span><span class="stringliteral">    to reject the null hypothesis in favor of the alternative. As stated in</span></div>
<div class="line"><span class="lineno">  883</span><span class="stringliteral">    [2]_, Barnard&#39;s test is uniformly more powerful than Fisher&#39;s exact test</span></div>
<div class="line"><span class="lineno">  884</span><span class="stringliteral">    because Barnard&#39;s test does not condition on any margin. Fisher&#39;s test</span></div>
<div class="line"><span class="lineno">  885</span><span class="stringliteral">    should only be used when both sets of marginals are fixed.</span></div>
<div class="line"><span class="lineno">  886</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  887</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  888</span>    <span class="keywordflow">if</span> n &lt;= 0:</div>
<div class="line"><span class="lineno">  889</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  890</span>            <span class="stringliteral">&quot;Number of points `n` must be strictly positive, &quot;</span></div>
<div class="line"><span class="lineno">  891</span>            f<span class="stringliteral">&quot;found {n!r}&quot;</span></div>
<div class="line"><span class="lineno">  892</span>        )</div>
<div class="line"><span class="lineno">  893</span> </div>
<div class="line"><span class="lineno">  894</span>    table = np.asarray(table, dtype=np.int64)</div>
<div class="line"><span class="lineno">  895</span> </div>
<div class="line"><span class="lineno">  896</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> table.shape == (2, 2):</div>
<div class="line"><span class="lineno">  897</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;The input `table` must be of shape (2, 2).&quot;</span>)</div>
<div class="line"><span class="lineno">  898</span> </div>
<div class="line"><span class="lineno">  899</span>    <span class="keywordflow">if</span> np.any(table &lt; 0):</div>
<div class="line"><span class="lineno">  900</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;All values in `table` must be nonnegative.&quot;</span>)</div>
<div class="line"><span class="lineno">  901</span> </div>
<div class="line"><span class="lineno">  902</span>    <span class="keywordflow">if</span> 0 <span class="keywordflow">in</span> table.sum(axis=0):</div>
<div class="line"><span class="lineno">  903</span>        <span class="comment"># If both values in column are zero, the p-value is 1 and</span></div>
<div class="line"><span class="lineno">  904</span>        <span class="comment"># the score&#39;s statistic is NaN.</span></div>
<div class="line"><span class="lineno">  905</span>        <span class="keywordflow">return</span> BarnardExactResult(np.nan, 1.0)</div>
<div class="line"><span class="lineno">  906</span> </div>
<div class="line"><span class="lineno">  907</span>    total_col_1, total_col_2 = table.sum(axis=0)</div>
<div class="line"><span class="lineno">  908</span> </div>
<div class="line"><span class="lineno">  909</span>    x1 = np.arange(total_col_1 + 1, dtype=np.int64).reshape(-1, 1)</div>
<div class="line"><span class="lineno">  910</span>    x2 = np.arange(total_col_2 + 1, dtype=np.int64).reshape(1, -1)</div>
<div class="line"><span class="lineno">  911</span> </div>
<div class="line"><span class="lineno">  912</span>    <span class="comment"># We need to calculate the wald statistics for each combination of x1 and</span></div>
<div class="line"><span class="lineno">  913</span>    <span class="comment"># x2.</span></div>
<div class="line"><span class="lineno">  914</span>    p1, p2 = x1 / total_col_1, x2 / total_col_2</div>
<div class="line"><span class="lineno">  915</span> </div>
<div class="line"><span class="lineno">  916</span>    <span class="keywordflow">if</span> pooled:</div>
<div class="line"><span class="lineno">  917</span>        p = (x1 + x2) / (total_col_1 + total_col_2)</div>
<div class="line"><span class="lineno">  918</span>        variances = p * (1 - p) * (1 / total_col_1 + 1 / total_col_2)</div>
<div class="line"><span class="lineno">  919</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  920</span>        variances = p1 * (1 - p1) / total_col_1 + p2 * (1 - p2) / total_col_2</div>
<div class="line"><span class="lineno">  921</span> </div>
<div class="line"><span class="lineno">  922</span>    <span class="comment"># To avoid warning when dividing by 0</span></div>
<div class="line"><span class="lineno">  923</span>    <span class="keyword">with</span> np.errstate(divide=<span class="stringliteral">&quot;ignore&quot;</span>, invalid=<span class="stringliteral">&quot;ignore&quot;</span>):</div>
<div class="line"><span class="lineno">  924</span>        wald_statistic = np.divide((p1 - p2), np.sqrt(variances))</div>
<div class="line"><span class="lineno">  925</span> </div>
<div class="line"><span class="lineno">  926</span>    wald_statistic[p1 == p2] = 0  <span class="comment"># Removing NaN values</span></div>
<div class="line"><span class="lineno">  927</span> </div>
<div class="line"><span class="lineno">  928</span>    wald_stat_obs = wald_statistic[table[0, 0], table[0, 1]]</div>
<div class="line"><span class="lineno">  929</span> </div>
<div class="line"><span class="lineno">  930</span>    <span class="keywordflow">if</span> alternative == <span class="stringliteral">&quot;two-sided&quot;</span>:</div>
<div class="line"><span class="lineno">  931</span>        index_arr = np.abs(wald_statistic) &gt;= abs(wald_stat_obs)</div>
<div class="line"><span class="lineno">  932</span>    <span class="keywordflow">elif</span> alternative == <span class="stringliteral">&quot;less&quot;</span>:</div>
<div class="line"><span class="lineno">  933</span>        index_arr = wald_statistic &lt;= wald_stat_obs</div>
<div class="line"><span class="lineno">  934</span>    <span class="keywordflow">elif</span> alternative == <span class="stringliteral">&quot;greater&quot;</span>:</div>
<div class="line"><span class="lineno">  935</span>        index_arr = wald_statistic &gt;= wald_stat_obs</div>
<div class="line"><span class="lineno">  936</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  937</span>        msg = (</div>
<div class="line"><span class="lineno">  938</span>            <span class="stringliteral">&quot;`alternative` should be one of {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;},&quot;</span></div>
<div class="line"><span class="lineno">  939</span>            f<span class="stringliteral">&quot; found {alternative!r}&quot;</span></div>
<div class="line"><span class="lineno">  940</span>        )</div>
<div class="line"><span class="lineno">  941</span>        <span class="keywordflow">raise</span> ValueError(msg)</div>
<div class="line"><span class="lineno">  942</span> </div>
<div class="line"><span class="lineno">  943</span>    x1_sum_x2 = x1 + x2</div>
<div class="line"><span class="lineno">  944</span> </div>
<div class="line"><span class="lineno">  945</span>    x1_log_comb = _compute_log_combinations(total_col_1)</div>
<div class="line"><span class="lineno">  946</span>    x2_log_comb = _compute_log_combinations(total_col_2)</div>
<div class="line"><span class="lineno">  947</span>    x1_sum_x2_log_comb = x1_log_comb[x1] + x2_log_comb[x2]</div>
<div class="line"><span class="lineno">  948</span> </div>
<div class="line"><span class="lineno">  949</span>    result = shgo(</div>
<div class="line"><span class="lineno">  950</span>        _get_binomial_log_p_value_with_nuisance_param,</div>
<div class="line"><span class="lineno">  951</span>        args=(x1_sum_x2, x1_sum_x2_log_comb, index_arr),</div>
<div class="line"><span class="lineno">  952</span>        bounds=((0, 1),),</div>
<div class="line"><span class="lineno">  953</span>        n=n,</div>
<div class="line"><span class="lineno">  954</span>        sampling_method=<span class="stringliteral">&quot;sobol&quot;</span>,</div>
<div class="line"><span class="lineno">  955</span>    )</div>
<div class="line"><span class="lineno">  956</span> </div>
<div class="line"><span class="lineno">  957</span>    <span class="comment"># result.fun is the negative log pvalue and therefore needs to be</span></div>
<div class="line"><span class="lineno">  958</span>    <span class="comment"># changed before return</span></div>
<div class="line"><span class="lineno">  959</span>    p_value = np.clip(np.exp(-result.fun), a_min=0, a_max=1)</div>
<div class="line"><span class="lineno">  960</span>    <span class="keywordflow">return</span> BarnardExactResult(wald_stat_obs, p_value)</div>
<div class="line"><span class="lineno">  961</span> </div>
<div class="line"><span class="lineno">  962</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a052b6fccc61a5edda7e687af88f5306f" name="a052b6fccc61a5edda7e687af88f5306f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a052b6fccc61a5edda7e687af88f5306f">&#9670;&#160;</a></span>boschloo_exact()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.boschloo_exact </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>table</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alternative</em> = <code>&quot;two-sided&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em> = <code>32</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Perform Boschloo's exact test on a 2x2 contingency table.

Parameters
----------
table : array_like of ints
    A 2x2 contingency table.  Elements should be non-negative integers.

alternative : {'two-sided', 'less', 'greater'}, optional
    Defines the null and alternative hypotheses. Default is 'two-sided'.
    Please see explanations in the Notes section below.

n : int, optional
    Number of sampling points used in the construction of the sampling
    method. Note that this argument will automatically be converted to
    the next higher power of 2 since `scipy.stats.qmc.Sobol` is used to
    select sample points. Default is 32. Must be positive. In most cases,
    32 points is enough to reach good precision. More points comes at
    performance cost.

Returns
-------
ber : BoschlooExactResult
    A result object with the following attributes.

    statistic : float
        The statistic used in Boschloo's test; that is, the p-value
        from Fisher's exact test.

    pvalue : float
        P-value, the probability of obtaining a distribution at least as
        extreme as the one that was actually observed, assuming that the
        null hypothesis is true.

See Also
--------
chi2_contingency : Chi-square test of independence of variables in a
    contingency table.
fisher_exact : Fisher exact test on a 2x2 contingency table.
barnard_exact : Barnard's exact test, which is a more powerful alternative
    than Fisher's exact test for 2x2 contingency tables.

Notes
-----
Boschloo's test is an exact test used in the analysis of contingency
tables. It examines the association of two categorical variables, and
is a uniformly more powerful alternative to Fisher's exact test
for 2x2 contingency tables.

Boschloo's exact test uses the p-value of Fisher's exact test as a
statistic, and Boschloo's p-value is the probability under the null
hypothesis of observing such an extreme value of this statistic.

Let's define :math:`X_0` a 2x2 matrix representing the observed sample,
where each column stores the binomial experiment, as in the example
below. Let's also define :math:`p_1, p_2` the theoretical binomial
probabilities for  :math:`x_{11}` and :math:`x_{12}`. When using
Boschloo exact test, we can assert three different alternative hypotheses:

- :math:`H_0 : p_1=p_2` versus :math:`H_1 : p_1 &lt; p_2`,
  with `alternative` = "less"

- :math:`H_0 : p_1=p_2` versus :math:`H_1 : p_1 &gt; p_2`,
  with `alternative` = "greater"

- :math:`H_0 : p_1=p_2` versus :math:`H_1 : p_1 \neq p_2`,
  with `alternative` = "two-sided" (default)

There are multiple conventions for computing a two-sided p-value when the
null distribution is asymmetric. Here, we apply the convention that the
p-value of a two-sided test is twice the minimum of the p-values of the
one-sided tests (clipped to 1.0). Note that `fisher_exact` follows a
different convention, so for a given `table`, the statistic reported by
`boschloo_exact` may differ from the p-value reported by `fisher_exact`
when ``alternative='two-sided'``.

.. versionadded:: 1.7.0

References
----------
.. [1] R.D. Boschloo. "Raised conditional level of significance for the
   2 x 2-table when testing the equality of two probabilities",
   Statistica Neerlandica, 24(1), 1970

.. [2] "Boschloo's test", Wikipedia,
   https://en.wikipedia.org/wiki/Boschloo%27s_test

.. [3] Lise M. Saari et al. "Employee attitudes and job satisfaction",
   Human Resource Management, 43(4), 395-407, 2004,
   :doi:`10.1002/hrm.20032`.

Examples
--------
In the following example, we consider the article "Employee
attitudes and job satisfaction" [3]_
which reports the results of a survey from 63 scientists and 117 college
professors. Of the 63 scientists, 31 said they were very satisfied with
their jobs, whereas 74 of the college professors were very satisfied
with their work. Is this significant evidence that college
professors are happier with their work than scientists?
The following table summarizes the data mentioned above::

                     college professors   scientists
    Very Satisfied   74                     31
    Dissatisfied     43                     32

When working with statistical hypothesis testing, we usually use a
threshold probability or significance level upon which we decide
to reject the null hypothesis :math:`H_0`. Suppose we choose the common
significance level of 5%.

Our alternative hypothesis is that college professors are truly more
satisfied with their work than scientists. Therefore, we expect
:math:`p_1` the proportion of very satisfied college professors to be
greater than :math:`p_2`, the proportion of very satisfied scientists.
We thus call `boschloo_exact` with the ``alternative="greater"`` option:

&gt;&gt;&gt; import scipy.stats as stats
&gt;&gt;&gt; res = stats.boschloo_exact([[74, 31], [43, 32]], alternative="greater")
&gt;&gt;&gt; res.statistic
0.0483...
&gt;&gt;&gt; res.pvalue
0.0355...

Under the null hypothesis that scientists are happier in their work than
college professors, the probability of obtaining test
results at least as extreme as the observed data is approximately 3.55%.
Since this p-value is less than our chosen significance level, we have
evidence to reject :math:`H_0` in favor of the alternative hypothesis.</pre> <div class="fragment"><div class="line"><span class="lineno">  968</span><span class="keyword">def </span>boschloo_exact(table, alternative=&quot;two-sided&quot;, n=32):</div>
<div class="line"><span class="lineno">  969</span>    <span class="stringliteral">r&quot;&quot;&quot;Perform Boschloo&#39;s exact test on a 2x2 contingency table.</span></div>
<div class="line"><span class="lineno">  970</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  971</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  972</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  973</span><span class="stringliteral">    table : array_like of ints</span></div>
<div class="line"><span class="lineno">  974</span><span class="stringliteral">        A 2x2 contingency table.  Elements should be non-negative integers.</span></div>
<div class="line"><span class="lineno">  975</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  976</span><span class="stringliteral">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span></div>
<div class="line"><span class="lineno">  977</span><span class="stringliteral">        Defines the null and alternative hypotheses. Default is &#39;two-sided&#39;.</span></div>
<div class="line"><span class="lineno">  978</span><span class="stringliteral">        Please see explanations in the Notes section below.</span></div>
<div class="line"><span class="lineno">  979</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  980</span><span class="stringliteral">    n : int, optional</span></div>
<div class="line"><span class="lineno">  981</span><span class="stringliteral">        Number of sampling points used in the construction of the sampling</span></div>
<div class="line"><span class="lineno">  982</span><span class="stringliteral">        method. Note that this argument will automatically be converted to</span></div>
<div class="line"><span class="lineno">  983</span><span class="stringliteral">        the next higher power of 2 since `scipy.stats.qmc.Sobol` is used to</span></div>
<div class="line"><span class="lineno">  984</span><span class="stringliteral">        select sample points. Default is 32. Must be positive. In most cases,</span></div>
<div class="line"><span class="lineno">  985</span><span class="stringliteral">        32 points is enough to reach good precision. More points comes at</span></div>
<div class="line"><span class="lineno">  986</span><span class="stringliteral">        performance cost.</span></div>
<div class="line"><span class="lineno">  987</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  988</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  989</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  990</span><span class="stringliteral">    ber : BoschlooExactResult</span></div>
<div class="line"><span class="lineno">  991</span><span class="stringliteral">        A result object with the following attributes.</span></div>
<div class="line"><span class="lineno">  992</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  993</span><span class="stringliteral">        statistic : float</span></div>
<div class="line"><span class="lineno">  994</span><span class="stringliteral">            The statistic used in Boschloo&#39;s test; that is, the p-value</span></div>
<div class="line"><span class="lineno">  995</span><span class="stringliteral">            from Fisher&#39;s exact test.</span></div>
<div class="line"><span class="lineno">  996</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  997</span><span class="stringliteral">        pvalue : float</span></div>
<div class="line"><span class="lineno">  998</span><span class="stringliteral">            P-value, the probability of obtaining a distribution at least as</span></div>
<div class="line"><span class="lineno">  999</span><span class="stringliteral">            extreme as the one that was actually observed, assuming that the</span></div>
<div class="line"><span class="lineno"> 1000</span><span class="stringliteral">            null hypothesis is true.</span></div>
<div class="line"><span class="lineno"> 1001</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1002</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 1003</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1004</span><span class="stringliteral">    chi2_contingency : Chi-square test of independence of variables in a</span></div>
<div class="line"><span class="lineno"> 1005</span><span class="stringliteral">        contingency table.</span></div>
<div class="line"><span class="lineno"> 1006</span><span class="stringliteral">    fisher_exact : Fisher exact test on a 2x2 contingency table.</span></div>
<div class="line"><span class="lineno"> 1007</span><span class="stringliteral">    barnard_exact : Barnard&#39;s exact test, which is a more powerful alternative</span></div>
<div class="line"><span class="lineno"> 1008</span><span class="stringliteral">        than Fisher&#39;s exact test for 2x2 contingency tables.</span></div>
<div class="line"><span class="lineno"> 1009</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1010</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1011</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1012</span><span class="stringliteral">    Boschloo&#39;s test is an exact test used in the analysis of contingency</span></div>
<div class="line"><span class="lineno"> 1013</span><span class="stringliteral">    tables. It examines the association of two categorical variables, and</span></div>
<div class="line"><span class="lineno"> 1014</span><span class="stringliteral">    is a uniformly more powerful alternative to Fisher&#39;s exact test</span></div>
<div class="line"><span class="lineno"> 1015</span><span class="stringliteral">    for 2x2 contingency tables.</span></div>
<div class="line"><span class="lineno"> 1016</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1017</span><span class="stringliteral">    Boschloo&#39;s exact test uses the p-value of Fisher&#39;s exact test as a</span></div>
<div class="line"><span class="lineno"> 1018</span><span class="stringliteral">    statistic, and Boschloo&#39;s p-value is the probability under the null</span></div>
<div class="line"><span class="lineno"> 1019</span><span class="stringliteral">    hypothesis of observing such an extreme value of this statistic.</span></div>
<div class="line"><span class="lineno"> 1020</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1021</span><span class="stringliteral">    Let&#39;s define :math:`X_0` a 2x2 matrix representing the observed sample,</span></div>
<div class="line"><span class="lineno"> 1022</span><span class="stringliteral">    where each column stores the binomial experiment, as in the example</span></div>
<div class="line"><span class="lineno"> 1023</span><span class="stringliteral">    below. Let&#39;s also define :math:`p_1, p_2` the theoretical binomial</span></div>
<div class="line"><span class="lineno"> 1024</span><span class="stringliteral">    probabilities for  :math:`x_{11}` and :math:`x_{12}`. When using</span></div>
<div class="line"><span class="lineno"> 1025</span><span class="stringliteral">    Boschloo exact test, we can assert three different alternative hypotheses:</span></div>
<div class="line"><span class="lineno"> 1026</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1027</span><span class="stringliteral">    - :math:`H_0 : p_1=p_2` versus :math:`H_1 : p_1 &lt; p_2`,</span></div>
<div class="line"><span class="lineno"> 1028</span><span class="stringliteral">      with `alternative` = &quot;less&quot;</span></div>
<div class="line"><span class="lineno"> 1029</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1030</span><span class="stringliteral">    - :math:`H_0 : p_1=p_2` versus :math:`H_1 : p_1 &gt; p_2`,</span></div>
<div class="line"><span class="lineno"> 1031</span><span class="stringliteral">      with `alternative` = &quot;greater&quot;</span></div>
<div class="line"><span class="lineno"> 1032</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1033</span><span class="stringliteral">    - :math:`H_0 : p_1=p_2` versus :math:`H_1 : p_1 \neq p_2`,</span></div>
<div class="line"><span class="lineno"> 1034</span><span class="stringliteral">      with `alternative` = &quot;two-sided&quot; (default)</span></div>
<div class="line"><span class="lineno"> 1035</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1036</span><span class="stringliteral">    There are multiple conventions for computing a two-sided p-value when the</span></div>
<div class="line"><span class="lineno"> 1037</span><span class="stringliteral">    null distribution is asymmetric. Here, we apply the convention that the</span></div>
<div class="line"><span class="lineno"> 1038</span><span class="stringliteral">    p-value of a two-sided test is twice the minimum of the p-values of the</span></div>
<div class="line"><span class="lineno"> 1039</span><span class="stringliteral">    one-sided tests (clipped to 1.0). Note that `fisher_exact` follows a</span></div>
<div class="line"><span class="lineno"> 1040</span><span class="stringliteral">    different convention, so for a given `table`, the statistic reported by</span></div>
<div class="line"><span class="lineno"> 1041</span><span class="stringliteral">    `boschloo_exact` may differ from the p-value reported by `fisher_exact`</span></div>
<div class="line"><span class="lineno"> 1042</span><span class="stringliteral">    when ``alternative=&#39;two-sided&#39;``.</span></div>
<div class="line"><span class="lineno"> 1043</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1044</span><span class="stringliteral">    .. versionadded:: 1.7.0</span></div>
<div class="line"><span class="lineno"> 1045</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1046</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1047</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1048</span><span class="stringliteral">    .. [1] R.D. Boschloo. &quot;Raised conditional level of significance for the</span></div>
<div class="line"><span class="lineno"> 1049</span><span class="stringliteral">       2 x 2-table when testing the equality of two probabilities&quot;,</span></div>
<div class="line"><span class="lineno"> 1050</span><span class="stringliteral">       Statistica Neerlandica, 24(1), 1970</span></div>
<div class="line"><span class="lineno"> 1051</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1052</span><span class="stringliteral">    .. [2] &quot;Boschloo&#39;s test&quot;, Wikipedia,</span></div>
<div class="line"><span class="lineno"> 1053</span><span class="stringliteral">       https://en.wikipedia.org/wiki/Boschloo%27s_test</span></div>
<div class="line"><span class="lineno"> 1054</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1055</span><span class="stringliteral">    .. [3] Lise M. Saari et al. &quot;Employee attitudes and job satisfaction&quot;,</span></div>
<div class="line"><span class="lineno"> 1056</span><span class="stringliteral">       Human Resource Management, 43(4), 395-407, 2004,</span></div>
<div class="line"><span class="lineno"> 1057</span><span class="stringliteral">       :doi:`10.1002/hrm.20032`.</span></div>
<div class="line"><span class="lineno"> 1058</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1059</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1060</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1061</span><span class="stringliteral">    In the following example, we consider the article &quot;Employee</span></div>
<div class="line"><span class="lineno"> 1062</span><span class="stringliteral">    attitudes and job satisfaction&quot; [3]_</span></div>
<div class="line"><span class="lineno"> 1063</span><span class="stringliteral">    which reports the results of a survey from 63 scientists and 117 college</span></div>
<div class="line"><span class="lineno"> 1064</span><span class="stringliteral">    professors. Of the 63 scientists, 31 said they were very satisfied with</span></div>
<div class="line"><span class="lineno"> 1065</span><span class="stringliteral">    their jobs, whereas 74 of the college professors were very satisfied</span></div>
<div class="line"><span class="lineno"> 1066</span><span class="stringliteral">    with their work. Is this significant evidence that college</span></div>
<div class="line"><span class="lineno"> 1067</span><span class="stringliteral">    professors are happier with their work than scientists?</span></div>
<div class="line"><span class="lineno"> 1068</span><span class="stringliteral">    The following table summarizes the data mentioned above::</span></div>
<div class="line"><span class="lineno"> 1069</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1070</span><span class="stringliteral">                         college professors   scientists</span></div>
<div class="line"><span class="lineno"> 1071</span><span class="stringliteral">        Very Satisfied   74                     31</span></div>
<div class="line"><span class="lineno"> 1072</span><span class="stringliteral">        Dissatisfied     43                     32</span></div>
<div class="line"><span class="lineno"> 1073</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1074</span><span class="stringliteral">    When working with statistical hypothesis testing, we usually use a</span></div>
<div class="line"><span class="lineno"> 1075</span><span class="stringliteral">    threshold probability or significance level upon which we decide</span></div>
<div class="line"><span class="lineno"> 1076</span><span class="stringliteral">    to reject the null hypothesis :math:`H_0`. Suppose we choose the common</span></div>
<div class="line"><span class="lineno"> 1077</span><span class="stringliteral">    significance level of 5%.</span></div>
<div class="line"><span class="lineno"> 1078</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1079</span><span class="stringliteral">    Our alternative hypothesis is that college professors are truly more</span></div>
<div class="line"><span class="lineno"> 1080</span><span class="stringliteral">    satisfied with their work than scientists. Therefore, we expect</span></div>
<div class="line"><span class="lineno"> 1081</span><span class="stringliteral">    :math:`p_1` the proportion of very satisfied college professors to be</span></div>
<div class="line"><span class="lineno"> 1082</span><span class="stringliteral">    greater than :math:`p_2`, the proportion of very satisfied scientists.</span></div>
<div class="line"><span class="lineno"> 1083</span><span class="stringliteral">    We thus call `boschloo_exact` with the ``alternative=&quot;greater&quot;`` option:</span></div>
<div class="line"><span class="lineno"> 1084</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1085</span><span class="stringliteral">    &gt;&gt;&gt; import scipy.stats as stats</span></div>
<div class="line"><span class="lineno"> 1086</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.boschloo_exact([[74, 31], [43, 32]], alternative=&quot;greater&quot;)</span></div>
<div class="line"><span class="lineno"> 1087</span><span class="stringliteral">    &gt;&gt;&gt; res.statistic</span></div>
<div class="line"><span class="lineno"> 1088</span><span class="stringliteral">    0.0483...</span></div>
<div class="line"><span class="lineno"> 1089</span><span class="stringliteral">    &gt;&gt;&gt; res.pvalue</span></div>
<div class="line"><span class="lineno"> 1090</span><span class="stringliteral">    0.0355...</span></div>
<div class="line"><span class="lineno"> 1091</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1092</span><span class="stringliteral">    Under the null hypothesis that scientists are happier in their work than</span></div>
<div class="line"><span class="lineno"> 1093</span><span class="stringliteral">    college professors, the probability of obtaining test</span></div>
<div class="line"><span class="lineno"> 1094</span><span class="stringliteral">    results at least as extreme as the observed data is approximately 3.55%.</span></div>
<div class="line"><span class="lineno"> 1095</span><span class="stringliteral">    Since this p-value is less than our chosen significance level, we have</span></div>
<div class="line"><span class="lineno"> 1096</span><span class="stringliteral">    evidence to reject :math:`H_0` in favor of the alternative hypothesis.</span></div>
<div class="line"><span class="lineno"> 1097</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1098</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1099</span>    hypergeom = distributions.hypergeom</div>
<div class="line"><span class="lineno"> 1100</span> </div>
<div class="line"><span class="lineno"> 1101</span>    <span class="keywordflow">if</span> n &lt;= 0:</div>
<div class="line"><span class="lineno"> 1102</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1103</span>            <span class="stringliteral">&quot;Number of points `n` must be strictly positive,&quot;</span></div>
<div class="line"><span class="lineno"> 1104</span>            f<span class="stringliteral">&quot; found {n!r}&quot;</span></div>
<div class="line"><span class="lineno"> 1105</span>        )</div>
<div class="line"><span class="lineno"> 1106</span> </div>
<div class="line"><span class="lineno"> 1107</span>    table = np.asarray(table, dtype=np.int64)</div>
<div class="line"><span class="lineno"> 1108</span> </div>
<div class="line"><span class="lineno"> 1109</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> table.shape == (2, 2):</div>
<div class="line"><span class="lineno"> 1110</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;The input `table` must be of shape (2, 2).&quot;</span>)</div>
<div class="line"><span class="lineno"> 1111</span> </div>
<div class="line"><span class="lineno"> 1112</span>    <span class="keywordflow">if</span> np.any(table &lt; 0):</div>
<div class="line"><span class="lineno"> 1113</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;All values in `table` must be nonnegative.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1114</span> </div>
<div class="line"><span class="lineno"> 1115</span>    <span class="keywordflow">if</span> 0 <span class="keywordflow">in</span> table.sum(axis=0):</div>
<div class="line"><span class="lineno"> 1116</span>        <span class="comment"># If both values in column are zero, the p-value is 1 and</span></div>
<div class="line"><span class="lineno"> 1117</span>        <span class="comment"># the score&#39;s statistic is NaN.</span></div>
<div class="line"><span class="lineno"> 1118</span>        <span class="keywordflow">return</span> BoschlooExactResult(np.nan, np.nan)</div>
<div class="line"><span class="lineno"> 1119</span> </div>
<div class="line"><span class="lineno"> 1120</span>    total_col_1, total_col_2 = table.sum(axis=0)</div>
<div class="line"><span class="lineno"> 1121</span>    total = total_col_1 + total_col_2</div>
<div class="line"><span class="lineno"> 1122</span>    x1 = np.arange(total_col_1 + 1, dtype=np.int64).reshape(1, -1)</div>
<div class="line"><span class="lineno"> 1123</span>    x2 = np.arange(total_col_2 + 1, dtype=np.int64).reshape(-1, 1)</div>
<div class="line"><span class="lineno"> 1124</span>    x1_sum_x2 = x1 + x2</div>
<div class="line"><span class="lineno"> 1125</span> </div>
<div class="line"><span class="lineno"> 1126</span>    <span class="keywordflow">if</span> alternative == <span class="stringliteral">&#39;less&#39;</span>:</div>
<div class="line"><span class="lineno"> 1127</span>        pvalues = hypergeom.cdf(x1, total, x1_sum_x2, total_col_1).T</div>
<div class="line"><span class="lineno"> 1128</span>    <span class="keywordflow">elif</span> alternative == <span class="stringliteral">&#39;greater&#39;</span>:</div>
<div class="line"><span class="lineno"> 1129</span>        <span class="comment"># Same formula as the &#39;less&#39; case, but with the second column.</span></div>
<div class="line"><span class="lineno"> 1130</span>        pvalues = hypergeom.cdf(x2, total, x1_sum_x2, total_col_2).T</div>
<div class="line"><span class="lineno"> 1131</span>    <span class="keywordflow">elif</span> alternative == <span class="stringliteral">&#39;two-sided&#39;</span>:</div>
<div class="line"><span class="lineno"> 1132</span>        boschloo_less = boschloo_exact(table, alternative=<span class="stringliteral">&quot;less&quot;</span>, n=n)</div>
<div class="line"><span class="lineno"> 1133</span>        boschloo_greater = boschloo_exact(table, alternative=<span class="stringliteral">&quot;greater&quot;</span>, n=n)</div>
<div class="line"><span class="lineno"> 1134</span> </div>
<div class="line"><span class="lineno"> 1135</span>        res = (</div>
<div class="line"><span class="lineno"> 1136</span>            boschloo_less <span class="keywordflow">if</span> boschloo_less.pvalue &lt; boschloo_greater.pvalue</div>
<div class="line"><span class="lineno"> 1137</span>            <span class="keywordflow">else</span> boschloo_greater</div>
<div class="line"><span class="lineno"> 1138</span>        )</div>
<div class="line"><span class="lineno"> 1139</span> </div>
<div class="line"><span class="lineno"> 1140</span>        <span class="comment"># Two-sided p-value is defined as twice the minimum of the one-sided</span></div>
<div class="line"><span class="lineno"> 1141</span>        <span class="comment"># p-values</span></div>
<div class="line"><span class="lineno"> 1142</span>        pvalue = np.clip(2 * res.pvalue, a_min=0, a_max=1)</div>
<div class="line"><span class="lineno"> 1143</span>        <span class="keywordflow">return</span> BoschlooExactResult(res.statistic, pvalue)</div>
<div class="line"><span class="lineno"> 1144</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1145</span>        msg = (</div>
<div class="line"><span class="lineno"> 1146</span>            f<span class="stringliteral">&quot;`alternative` should be one of {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;},&quot;</span></div>
<div class="line"><span class="lineno"> 1147</span>            f<span class="stringliteral">&quot; found {alternative!r}&quot;</span></div>
<div class="line"><span class="lineno"> 1148</span>        )</div>
<div class="line"><span class="lineno"> 1149</span>        <span class="keywordflow">raise</span> ValueError(msg)</div>
<div class="line"><span class="lineno"> 1150</span> </div>
<div class="line"><span class="lineno"> 1151</span>    fisher_stat = pvalues[table[0, 0], table[0, 1]]</div>
<div class="line"><span class="lineno"> 1152</span> </div>
<div class="line"><span class="lineno"> 1153</span>    <span class="comment"># fisher_stat * (1+1e-13) guards us from small numerical error. It is</span></div>
<div class="line"><span class="lineno"> 1154</span>    <span class="comment"># equivalent to np.isclose with relative tol of 1e-13 and absolute tol of 0</span></div>
<div class="line"><span class="lineno"> 1155</span>    <span class="comment"># For more throughout explanations, see gh-14178</span></div>
<div class="line"><span class="lineno"> 1156</span>    index_arr = pvalues &lt;= fisher_stat * (1+1e-13)</div>
<div class="line"><span class="lineno"> 1157</span> </div>
<div class="line"><span class="lineno"> 1158</span>    x1, x2, x1_sum_x2 = x1.T, x2.T, x1_sum_x2.T</div>
<div class="line"><span class="lineno"> 1159</span>    x1_log_comb = _compute_log_combinations(total_col_1)</div>
<div class="line"><span class="lineno"> 1160</span>    x2_log_comb = _compute_log_combinations(total_col_2)</div>
<div class="line"><span class="lineno"> 1161</span>    x1_sum_x2_log_comb = x1_log_comb[x1] + x2_log_comb[x2]</div>
<div class="line"><span class="lineno"> 1162</span> </div>
<div class="line"><span class="lineno"> 1163</span>    result = shgo(</div>
<div class="line"><span class="lineno"> 1164</span>        _get_binomial_log_p_value_with_nuisance_param,</div>
<div class="line"><span class="lineno"> 1165</span>        args=(x1_sum_x2, x1_sum_x2_log_comb, index_arr),</div>
<div class="line"><span class="lineno"> 1166</span>        bounds=((0, 1),),</div>
<div class="line"><span class="lineno"> 1167</span>        n=n,</div>
<div class="line"><span class="lineno"> 1168</span>        sampling_method=<span class="stringliteral">&quot;sobol&quot;</span>,</div>
<div class="line"><span class="lineno"> 1169</span>    )</div>
<div class="line"><span class="lineno"> 1170</span> </div>
<div class="line"><span class="lineno"> 1171</span>    <span class="comment"># result.fun is the negative log pvalue and therefore needs to be</span></div>
<div class="line"><span class="lineno"> 1172</span>    <span class="comment"># changed before return</span></div>
<div class="line"><span class="lineno"> 1173</span>    p_value = np.clip(np.exp(-result.fun), a_min=0, a_max=1)</div>
<div class="line"><span class="lineno"> 1174</span>    <span class="keywordflow">return</span> BoschlooExactResult(fisher_stat, p_value)</div>
<div class="line"><span class="lineno"> 1175</span> </div>
<div class="line"><span class="lineno"> 1176</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab7f83ced89d2318a8a9e56ec9870f069" name="ab7f83ced89d2318a8a9e56ec9870f069"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab7f83ced89d2318a8a9e56ec9870f069">&#9670;&#160;</a></span>cramervonmises()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.cramervonmises </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rvs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cdf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>args</em> = <code>()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Perform the one-sample Cramér-von Mises test for goodness of fit.

This performs a test of the goodness of fit of a cumulative distribution
function (cdf) :math:`F` compared to the empirical distribution function
:math:`F_n` of observed random variates :math:`X_1, ..., X_n` that are
assumed to be independent and identically distributed ([1]_).
The null hypothesis is that the :math:`X_i` have cumulative distribution
:math:`F`.

Parameters
----------
rvs : array_like
    A 1-D array of observed values of the random variables :math:`X_i`.
cdf : str or callable
    The cumulative distribution function :math:`F` to test the
    observations against. If a string, it should be the name of a
    distribution in `scipy.stats`. If a callable, that callable is used
    to calculate the cdf: ``cdf(x, *args) -&gt; float``.
args : tuple, optional
    Distribution parameters. These are assumed to be known; see Notes.

Returns
-------
res : object with attributes
    statistic : float
        Cramér-von Mises statistic.
    pvalue : float
        The p-value.

See Also
--------
kstest, cramervonmises_2samp

Notes
-----
.. versionadded:: 1.6.0

The p-value relies on the approximation given by equation 1.8 in [2]_.
It is important to keep in mind that the p-value is only accurate if
one tests a simple hypothesis, i.e. the parameters of the reference
distribution are known. If the parameters are estimated from the data
(composite hypothesis), the computed p-value is not reliable.

References
----------
.. [1] Cramér-von Mises criterion, Wikipedia,
       https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93von_Mises_criterion
.. [2] Csörgő, S. and Faraway, J. (1996). The Exact and Asymptotic
       Distribution of Cramér-von Mises Statistics. Journal of the
       Royal Statistical Society, pp. 221-234.

Examples
--------

Suppose we wish to test whether data generated by ``scipy.stats.norm.rvs``
were, in fact, drawn from the standard normal distribution. We choose a
significance level of alpha=0.05.

&gt;&gt;&gt; from scipy import stats
&gt;&gt;&gt; rng = np.random.default_rng()
&gt;&gt;&gt; x = stats.norm.rvs(size=500, random_state=rng)
&gt;&gt;&gt; res = stats.cramervonmises(x, 'norm')
&gt;&gt;&gt; res.statistic, res.pvalue
(0.49121480855028343, 0.04189256516661377)

The p-value 0.79 exceeds our chosen significance level, so we do not
reject the null hypothesis that the observed sample is drawn from the
standard normal distribution.

Now suppose we wish to check whether the same samples shifted by 2.1 is
consistent with being drawn from a normal distribution with a mean of 2.

&gt;&gt;&gt; y = x + 2.1
&gt;&gt;&gt; res = stats.cramervonmises(y, 'norm', args=(2,))
&gt;&gt;&gt; res.statistic, res.pvalue
(0.07400330012187435, 0.7274595666160468)

Here we have used the `args` keyword to specify the mean (``loc``)
of the normal distribution to test the data against. This is equivalent
to the following, in which we create a frozen normal distribution with
mean 2.1, then pass its ``cdf`` method as an argument.

&gt;&gt;&gt; frozen_dist = stats.norm(loc=2)
&gt;&gt;&gt; res = stats.cramervonmises(y, frozen_dist.cdf)
&gt;&gt;&gt; res.statistic, res.pvalue
(0.07400330012187435, 0.7274595666160468)

In either case, we would reject the null hypothesis that the observed
sample is drawn from a normal distribution with a mean of 2 (and default
variance of 1) because the p-value 0.04 is less than our chosen
significance level.</pre> <div class="fragment"><div class="line"><span class="lineno">  276</span><span class="keyword">def </span>cramervonmises(rvs, cdf, args=()):</div>
<div class="line"><span class="lineno">  277</span>    <span class="stringliteral">&quot;&quot;&quot;Perform the one-sample Cramér-von Mises test for goodness of fit.</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">    This performs a test of the goodness of fit of a cumulative distribution</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">    function (cdf) :math:`F` compared to the empirical distribution function</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    :math:`F_n` of observed random variates :math:`X_1, ..., X_n` that are</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">    assumed to be independent and identically distributed ([1]_).</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">    The null hypothesis is that the :math:`X_i` have cumulative distribution</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">    :math:`F`.</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">    rvs : array_like</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">        A 1-D array of observed values of the random variables :math:`X_i`.</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">    cdf : str or callable</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">        The cumulative distribution function :math:`F` to test the</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">        observations against. If a string, it should be the name of a</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">        distribution in `scipy.stats`. If a callable, that callable is used</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">        to calculate the cdf: ``cdf(x, *args) -&gt; float``.</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">    args : tuple, optional</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">        Distribution parameters. These are assumed to be known; see Notes.</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">    res : object with attributes</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">        statistic : float</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">            Cramér-von Mises statistic.</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">        pvalue : float</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">            The p-value.</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">    kstest, cramervonmises_2samp</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">    .. versionadded:: 1.6.0</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral">    The p-value relies on the approximation given by equation 1.8 in [2]_.</span></div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">    It is important to keep in mind that the p-value is only accurate if</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral">    one tests a simple hypothesis, i.e. the parameters of the reference</span></div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral">    distribution are known. If the parameters are estimated from the data</span></div>
<div class="line"><span class="lineno">  318</span><span class="stringliteral">    (composite hypothesis), the computed p-value is not reliable.</span></div>
<div class="line"><span class="lineno">  319</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  320</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  321</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  322</span><span class="stringliteral">    .. [1] Cramér-von Mises criterion, Wikipedia,</span></div>
<div class="line"><span class="lineno">  323</span><span class="stringliteral">           https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93von_Mises_criterion</span></div>
<div class="line"><span class="lineno">  324</span><span class="stringliteral">    .. [2] Csörgő, S. and Faraway, J. (1996). The Exact and Asymptotic</span></div>
<div class="line"><span class="lineno">  325</span><span class="stringliteral">           Distribution of Cramér-von Mises Statistics. Journal of the</span></div>
<div class="line"><span class="lineno">  326</span><span class="stringliteral">           Royal Statistical Society, pp. 221-234.</span></div>
<div class="line"><span class="lineno">  327</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral">    Suppose we wish to test whether data generated by ``scipy.stats.norm.rvs``</span></div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">    were, in fact, drawn from the standard normal distribution. We choose a</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral">    significance level of alpha=0.05.</span></div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">    &gt;&gt;&gt; from scipy import stats</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral">    &gt;&gt;&gt; rng = np.random.default_rng()</span></div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral">    &gt;&gt;&gt; x = stats.norm.rvs(size=500, random_state=rng)</span></div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.cramervonmises(x, &#39;norm&#39;)</span></div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral">    &gt;&gt;&gt; res.statistic, res.pvalue</span></div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">    (0.49121480855028343, 0.04189256516661377)</span></div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral">    The p-value 0.79 exceeds our chosen significance level, so we do not</span></div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral">    reject the null hypothesis that the observed sample is drawn from the</span></div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">    standard normal distribution.</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">    Now suppose we wish to check whether the same samples shifted by 2.1 is</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">    consistent with being drawn from a normal distribution with a mean of 2.</span></div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">    &gt;&gt;&gt; y = x + 2.1</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.cramervonmises(y, &#39;norm&#39;, args=(2,))</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">    &gt;&gt;&gt; res.statistic, res.pvalue</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral">    (0.07400330012187435, 0.7274595666160468)</span></div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">    Here we have used the `args` keyword to specify the mean (``loc``)</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">    of the normal distribution to test the data against. This is equivalent</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral">    to the following, in which we create a frozen normal distribution with</span></div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">    mean 2.1, then pass its ``cdf`` method as an argument.</span></div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral">    &gt;&gt;&gt; frozen_dist = stats.norm(loc=2)</span></div>
<div class="line"><span class="lineno">  360</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.cramervonmises(y, frozen_dist.cdf)</span></div>
<div class="line"><span class="lineno">  361</span><span class="stringliteral">    &gt;&gt;&gt; res.statistic, res.pvalue</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral">    (0.07400330012187435, 0.7274595666160468)</span></div>
<div class="line"><span class="lineno">  363</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  364</span><span class="stringliteral">    In either case, we would reject the null hypothesis that the observed</span></div>
<div class="line"><span class="lineno">  365</span><span class="stringliteral">    sample is drawn from a normal distribution with a mean of 2 (and default</span></div>
<div class="line"><span class="lineno">  366</span><span class="stringliteral">    variance of 1) because the p-value 0.04 is less than our chosen</span></div>
<div class="line"><span class="lineno">  367</span><span class="stringliteral">    significance level.</span></div>
<div class="line"><span class="lineno">  368</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  369</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  370</span>    <span class="keywordflow">if</span> isinstance(cdf, str):</div>
<div class="line"><span class="lineno">  371</span>        cdf = getattr(distributions, cdf).cdf</div>
<div class="line"><span class="lineno">  372</span> </div>
<div class="line"><span class="lineno">  373</span>    vals = np.sort(np.asarray(rvs))</div>
<div class="line"><span class="lineno">  374</span> </div>
<div class="line"><span class="lineno">  375</span>    <span class="keywordflow">if</span> vals.size &lt;= 1:</div>
<div class="line"><span class="lineno">  376</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;The sample must contain at least two observations.&#39;</span>)</div>
<div class="line"><span class="lineno">  377</span>    <span class="keywordflow">if</span> vals.ndim &gt; 1:</div>
<div class="line"><span class="lineno">  378</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;The sample must be one-dimensional.&#39;</span>)</div>
<div class="line"><span class="lineno">  379</span> </div>
<div class="line"><span class="lineno">  380</span>    n = len(vals)</div>
<div class="line"><span class="lineno">  381</span>    cdfvals = cdf(vals, *args)</div>
<div class="line"><span class="lineno">  382</span> </div>
<div class="line"><span class="lineno">  383</span>    u = (2*np.arange(1, n+1) - 1)/(2*n)</div>
<div class="line"><span class="lineno">  384</span>    w = 1/(12*n) + np.sum((u - cdfvals)**2)</div>
<div class="line"><span class="lineno">  385</span> </div>
<div class="line"><span class="lineno">  386</span>    <span class="comment"># avoid small negative values that can occur due to the approximation</span></div>
<div class="line"><span class="lineno">  387</span>    p = max(0, 1. - _cdf_cvm(w, n))</div>
<div class="line"><span class="lineno">  388</span> </div>
<div class="line"><span class="lineno">  389</span>    <span class="keywordflow">return</span> CramerVonMisesResult(statistic=w, pvalue=p)</div>
<div class="line"><span class="lineno">  390</span> </div>
<div class="line"><span class="lineno">  391</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa1e4adb733eee8e9bb9fff1aca50ccea" name="aa1e4adb733eee8e9bb9fff1aca50ccea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa1e4adb733eee8e9bb9fff1aca50ccea">&#9670;&#160;</a></span>cramervonmises_2samp()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.cramervonmises_2samp </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em> = <code>'auto'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Perform the two-sample Cramér-von Mises test for goodness of fit.

This is the two-sample version of the Cramér-von Mises test ([1]_):
for two independent samples :math:`X_1, ..., X_n` and
:math:`Y_1, ..., Y_m`, the null hypothesis is that the samples
come from the same (unspecified) continuous distribution.

Parameters
----------
x : array_like
    A 1-D array of observed values of the random variables :math:`X_i`.
y : array_like
    A 1-D array of observed values of the random variables :math:`Y_i`.
method : {'auto', 'asymptotic', 'exact'}, optional
    The method used to compute the p-value, see Notes for details.
    The default is 'auto'.

Returns
-------
res : object with attributes
    statistic : float
        Cramér-von Mises statistic.
    pvalue : float
        The p-value.

See Also
--------
cramervonmises, anderson_ksamp, epps_singleton_2samp, ks_2samp

Notes
-----
.. versionadded:: 1.7.0

The statistic is computed according to equation 9 in [2]_. The
calculation of the p-value depends on the keyword `method`:

- ``asymptotic``: The p-value is approximated by using the limiting
  distribution of the test statistic.
- ``exact``: The exact p-value is computed by enumerating all
  possible combinations of the test statistic, see [2]_.

The exact calculation will be very slow even for moderate sample
sizes as the number of combinations increases rapidly with the
size of the samples. If ``method=='auto'``, the exact approach
is used if both samples contain less than 10 observations,
otherwise the asymptotic distribution is used.

If the underlying distribution is not continuous, the p-value is likely to
be conservative (Section 6.2 in [3]_). When ranking the data to compute
the test statistic, midranks are used if there are ties.

References
----------
.. [1] https://en.wikipedia.org/wiki/Cramer-von_Mises_criterion
.. [2] Anderson, T.W. (1962). On the distribution of the two-sample
       Cramer-von-Mises criterion. The Annals of Mathematical
       Statistics, pp. 1148-1159.
.. [3] Conover, W.J., Practical Nonparametric Statistics, 1971.

Examples
--------

Suppose we wish to test whether two samples generated by
``scipy.stats.norm.rvs`` have the same distribution. We choose a
significance level of alpha=0.05.

&gt;&gt;&gt; from scipy import stats
&gt;&gt;&gt; rng = np.random.default_rng()
&gt;&gt;&gt; x = stats.norm.rvs(size=100, random_state=rng)
&gt;&gt;&gt; y = stats.norm.rvs(size=70, random_state=rng)
&gt;&gt;&gt; res = stats.cramervonmises_2samp(x, y)
&gt;&gt;&gt; res.statistic, res.pvalue
(0.29376470588235293, 0.1412873014573014)

The p-value exceeds our chosen significance level, so we do not
reject the null hypothesis that the observed samples are drawn from the
same distribution.

For small sample sizes, one can compute the exact p-values:

&gt;&gt;&gt; x = stats.norm.rvs(size=7, random_state=rng)
&gt;&gt;&gt; y = stats.t.rvs(df=2, size=6, random_state=rng)
&gt;&gt;&gt; res = stats.cramervonmises_2samp(x, y, method='exact')
&gt;&gt;&gt; res.statistic, res.pvalue
(0.197802197802198, 0.31643356643356646)

The p-value based on the asymptotic distribution is a good approximation
even though the sample size is small.

&gt;&gt;&gt; res = stats.cramervonmises_2samp(x, y, method='asymptotic')
&gt;&gt;&gt; res.statistic, res.pvalue
(0.197802197802198, 0.2966041181527128)

Independent of the method, one would not reject the null hypothesis at the
chosen significance level in this example.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1294</span><span class="keyword">def </span>cramervonmises_2samp(x, y, method=&#39;auto&#39;):</div>
<div class="line"><span class="lineno"> 1295</span>    <span class="stringliteral">&quot;&quot;&quot;Perform the two-sample Cramér-von Mises test for goodness of fit.</span></div>
<div class="line"><span class="lineno"> 1296</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1297</span><span class="stringliteral">    This is the two-sample version of the Cramér-von Mises test ([1]_):</span></div>
<div class="line"><span class="lineno"> 1298</span><span class="stringliteral">    for two independent samples :math:`X_1, ..., X_n` and</span></div>
<div class="line"><span class="lineno"> 1299</span><span class="stringliteral">    :math:`Y_1, ..., Y_m`, the null hypothesis is that the samples</span></div>
<div class="line"><span class="lineno"> 1300</span><span class="stringliteral">    come from the same (unspecified) continuous distribution.</span></div>
<div class="line"><span class="lineno"> 1301</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1302</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1303</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1304</span><span class="stringliteral">    x : array_like</span></div>
<div class="line"><span class="lineno"> 1305</span><span class="stringliteral">        A 1-D array of observed values of the random variables :math:`X_i`.</span></div>
<div class="line"><span class="lineno"> 1306</span><span class="stringliteral">    y : array_like</span></div>
<div class="line"><span class="lineno"> 1307</span><span class="stringliteral">        A 1-D array of observed values of the random variables :math:`Y_i`.</span></div>
<div class="line"><span class="lineno"> 1308</span><span class="stringliteral">    method : {&#39;auto&#39;, &#39;asymptotic&#39;, &#39;exact&#39;}, optional</span></div>
<div class="line"><span class="lineno"> 1309</span><span class="stringliteral">        The method used to compute the p-value, see Notes for details.</span></div>
<div class="line"><span class="lineno"> 1310</span><span class="stringliteral">        The default is &#39;auto&#39;.</span></div>
<div class="line"><span class="lineno"> 1311</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1312</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1313</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1314</span><span class="stringliteral">    res : object with attributes</span></div>
<div class="line"><span class="lineno"> 1315</span><span class="stringliteral">        statistic : float</span></div>
<div class="line"><span class="lineno"> 1316</span><span class="stringliteral">            Cramér-von Mises statistic.</span></div>
<div class="line"><span class="lineno"> 1317</span><span class="stringliteral">        pvalue : float</span></div>
<div class="line"><span class="lineno"> 1318</span><span class="stringliteral">            The p-value.</span></div>
<div class="line"><span class="lineno"> 1319</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1320</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 1321</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1322</span><span class="stringliteral">    cramervonmises, anderson_ksamp, epps_singleton_2samp, ks_2samp</span></div>
<div class="line"><span class="lineno"> 1323</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1324</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1325</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1326</span><span class="stringliteral">    .. versionadded:: 1.7.0</span></div>
<div class="line"><span class="lineno"> 1327</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1328</span><span class="stringliteral">    The statistic is computed according to equation 9 in [2]_. The</span></div>
<div class="line"><span class="lineno"> 1329</span><span class="stringliteral">    calculation of the p-value depends on the keyword `method`:</span></div>
<div class="line"><span class="lineno"> 1330</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1331</span><span class="stringliteral">    - ``asymptotic``: The p-value is approximated by using the limiting</span></div>
<div class="line"><span class="lineno"> 1332</span><span class="stringliteral">      distribution of the test statistic.</span></div>
<div class="line"><span class="lineno"> 1333</span><span class="stringliteral">    - ``exact``: The exact p-value is computed by enumerating all</span></div>
<div class="line"><span class="lineno"> 1334</span><span class="stringliteral">      possible combinations of the test statistic, see [2]_.</span></div>
<div class="line"><span class="lineno"> 1335</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1336</span><span class="stringliteral">    The exact calculation will be very slow even for moderate sample</span></div>
<div class="line"><span class="lineno"> 1337</span><span class="stringliteral">    sizes as the number of combinations increases rapidly with the</span></div>
<div class="line"><span class="lineno"> 1338</span><span class="stringliteral">    size of the samples. If ``method==&#39;auto&#39;``, the exact approach</span></div>
<div class="line"><span class="lineno"> 1339</span><span class="stringliteral">    is used if both samples contain less than 10 observations,</span></div>
<div class="line"><span class="lineno"> 1340</span><span class="stringliteral">    otherwise the asymptotic distribution is used.</span></div>
<div class="line"><span class="lineno"> 1341</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1342</span><span class="stringliteral">    If the underlying distribution is not continuous, the p-value is likely to</span></div>
<div class="line"><span class="lineno"> 1343</span><span class="stringliteral">    be conservative (Section 6.2 in [3]_). When ranking the data to compute</span></div>
<div class="line"><span class="lineno"> 1344</span><span class="stringliteral">    the test statistic, midranks are used if there are ties.</span></div>
<div class="line"><span class="lineno"> 1345</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1346</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1347</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1348</span><span class="stringliteral">    .. [1] https://en.wikipedia.org/wiki/Cramer-von_Mises_criterion</span></div>
<div class="line"><span class="lineno"> 1349</span><span class="stringliteral">    .. [2] Anderson, T.W. (1962). On the distribution of the two-sample</span></div>
<div class="line"><span class="lineno"> 1350</span><span class="stringliteral">           Cramer-von-Mises criterion. The Annals of Mathematical</span></div>
<div class="line"><span class="lineno"> 1351</span><span class="stringliteral">           Statistics, pp. 1148-1159.</span></div>
<div class="line"><span class="lineno"> 1352</span><span class="stringliteral">    .. [3] Conover, W.J., Practical Nonparametric Statistics, 1971.</span></div>
<div class="line"><span class="lineno"> 1353</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1354</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1355</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1356</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1357</span><span class="stringliteral">    Suppose we wish to test whether two samples generated by</span></div>
<div class="line"><span class="lineno"> 1358</span><span class="stringliteral">    ``scipy.stats.norm.rvs`` have the same distribution. We choose a</span></div>
<div class="line"><span class="lineno"> 1359</span><span class="stringliteral">    significance level of alpha=0.05.</span></div>
<div class="line"><span class="lineno"> 1360</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1361</span><span class="stringliteral">    &gt;&gt;&gt; from scipy import stats</span></div>
<div class="line"><span class="lineno"> 1362</span><span class="stringliteral">    &gt;&gt;&gt; rng = np.random.default_rng()</span></div>
<div class="line"><span class="lineno"> 1363</span><span class="stringliteral">    &gt;&gt;&gt; x = stats.norm.rvs(size=100, random_state=rng)</span></div>
<div class="line"><span class="lineno"> 1364</span><span class="stringliteral">    &gt;&gt;&gt; y = stats.norm.rvs(size=70, random_state=rng)</span></div>
<div class="line"><span class="lineno"> 1365</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.cramervonmises_2samp(x, y)</span></div>
<div class="line"><span class="lineno"> 1366</span><span class="stringliteral">    &gt;&gt;&gt; res.statistic, res.pvalue</span></div>
<div class="line"><span class="lineno"> 1367</span><span class="stringliteral">    (0.29376470588235293, 0.1412873014573014)</span></div>
<div class="line"><span class="lineno"> 1368</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1369</span><span class="stringliteral">    The p-value exceeds our chosen significance level, so we do not</span></div>
<div class="line"><span class="lineno"> 1370</span><span class="stringliteral">    reject the null hypothesis that the observed samples are drawn from the</span></div>
<div class="line"><span class="lineno"> 1371</span><span class="stringliteral">    same distribution.</span></div>
<div class="line"><span class="lineno"> 1372</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1373</span><span class="stringliteral">    For small sample sizes, one can compute the exact p-values:</span></div>
<div class="line"><span class="lineno"> 1374</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1375</span><span class="stringliteral">    &gt;&gt;&gt; x = stats.norm.rvs(size=7, random_state=rng)</span></div>
<div class="line"><span class="lineno"> 1376</span><span class="stringliteral">    &gt;&gt;&gt; y = stats.t.rvs(df=2, size=6, random_state=rng)</span></div>
<div class="line"><span class="lineno"> 1377</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.cramervonmises_2samp(x, y, method=&#39;exact&#39;)</span></div>
<div class="line"><span class="lineno"> 1378</span><span class="stringliteral">    &gt;&gt;&gt; res.statistic, res.pvalue</span></div>
<div class="line"><span class="lineno"> 1379</span><span class="stringliteral">    (0.197802197802198, 0.31643356643356646)</span></div>
<div class="line"><span class="lineno"> 1380</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1381</span><span class="stringliteral">    The p-value based on the asymptotic distribution is a good approximation</span></div>
<div class="line"><span class="lineno"> 1382</span><span class="stringliteral">    even though the sample size is small.</span></div>
<div class="line"><span class="lineno"> 1383</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1384</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.cramervonmises_2samp(x, y, method=&#39;asymptotic&#39;)</span></div>
<div class="line"><span class="lineno"> 1385</span><span class="stringliteral">    &gt;&gt;&gt; res.statistic, res.pvalue</span></div>
<div class="line"><span class="lineno"> 1386</span><span class="stringliteral">    (0.197802197802198, 0.2966041181527128)</span></div>
<div class="line"><span class="lineno"> 1387</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1388</span><span class="stringliteral">    Independent of the method, one would not reject the null hypothesis at the</span></div>
<div class="line"><span class="lineno"> 1389</span><span class="stringliteral">    chosen significance level in this example.</span></div>
<div class="line"><span class="lineno"> 1390</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1391</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1392</span>    xa = np.sort(np.asarray(x))</div>
<div class="line"><span class="lineno"> 1393</span>    ya = np.sort(np.asarray(y))</div>
<div class="line"><span class="lineno"> 1394</span> </div>
<div class="line"><span class="lineno"> 1395</span>    <span class="keywordflow">if</span> xa.size &lt;= 1 <span class="keywordflow">or</span> ya.size &lt;= 1:</div>
<div class="line"><span class="lineno"> 1396</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;x and y must contain at least two observations.&#39;</span>)</div>
<div class="line"><span class="lineno"> 1397</span>    <span class="keywordflow">if</span> xa.ndim &gt; 1 <span class="keywordflow">or</span> ya.ndim &gt; 1:</div>
<div class="line"><span class="lineno"> 1398</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;The samples must be one-dimensional.&#39;</span>)</div>
<div class="line"><span class="lineno"> 1399</span>    <span class="keywordflow">if</span> method <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&#39;auto&#39;</span>, <span class="stringliteral">&#39;exact&#39;</span>, <span class="stringliteral">&#39;asymptotic&#39;</span>]:</div>
<div class="line"><span class="lineno"> 1400</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;method must be either auto, exact or asymptotic.&#39;</span>)</div>
<div class="line"><span class="lineno"> 1401</span> </div>
<div class="line"><span class="lineno"> 1402</span>    nx = len(xa)</div>
<div class="line"><span class="lineno"> 1403</span>    ny = len(ya)</div>
<div class="line"><span class="lineno"> 1404</span> </div>
<div class="line"><span class="lineno"> 1405</span>    <span class="keywordflow">if</span> method == <span class="stringliteral">&#39;auto&#39;</span>:</div>
<div class="line"><span class="lineno"> 1406</span>        <span class="keywordflow">if</span> max(nx, ny) &gt; 10:</div>
<div class="line"><span class="lineno"> 1407</span>            method = <span class="stringliteral">&#39;asymptotic&#39;</span></div>
<div class="line"><span class="lineno"> 1408</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1409</span>            method = <span class="stringliteral">&#39;exact&#39;</span></div>
<div class="line"><span class="lineno"> 1410</span> </div>
<div class="line"><span class="lineno"> 1411</span>    <span class="comment"># get ranks of x and y in the pooled sample</span></div>
<div class="line"><span class="lineno"> 1412</span>    z = np.concatenate([xa, ya])</div>
<div class="line"><span class="lineno"> 1413</span>    <span class="comment"># in case of ties, use midrank (see [1])</span></div>
<div class="line"><span class="lineno"> 1414</span>    r = scipy.stats.rankdata(z, method=<span class="stringliteral">&#39;average&#39;</span>)</div>
<div class="line"><span class="lineno"> 1415</span>    rx = r[:nx]</div>
<div class="line"><span class="lineno"> 1416</span>    ry = r[nx:]</div>
<div class="line"><span class="lineno"> 1417</span> </div>
<div class="line"><span class="lineno"> 1418</span>    <span class="comment"># compute U (eq. 10 in [2])</span></div>
<div class="line"><span class="lineno"> 1419</span>    u = nx * np.sum((rx - np.arange(1, nx+1))**2)</div>
<div class="line"><span class="lineno"> 1420</span>    u += ny * np.sum((ry - np.arange(1, ny+1))**2)</div>
<div class="line"><span class="lineno"> 1421</span> </div>
<div class="line"><span class="lineno"> 1422</span>    <span class="comment"># compute T (eq. 9 in [2])</span></div>
<div class="line"><span class="lineno"> 1423</span>    k, N = nx*ny, nx + ny</div>
<div class="line"><span class="lineno"> 1424</span>    t = u / (k*N) - (4*k - 1)/(6*N)</div>
<div class="line"><span class="lineno"> 1425</span> </div>
<div class="line"><span class="lineno"> 1426</span>    <span class="keywordflow">if</span> method == <span class="stringliteral">&#39;exact&#39;</span>:</div>
<div class="line"><span class="lineno"> 1427</span>        p = _pval_cvm_2samp_exact(u, nx, ny)</div>
<div class="line"><span class="lineno"> 1428</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1429</span>        <span class="comment"># compute expected value and variance of T (eq. 11 and 14 in [2])</span></div>
<div class="line"><span class="lineno"> 1430</span>        et = (1 + 1/N)/6</div>
<div class="line"><span class="lineno"> 1431</span>        vt = (N+1) * (4*k*N - 3*(nx**2 + ny**2) - 2*k)</div>
<div class="line"><span class="lineno"> 1432</span>        vt = vt / (45 * N**2 * 4 * k)</div>
<div class="line"><span class="lineno"> 1433</span> </div>
<div class="line"><span class="lineno"> 1434</span>        <span class="comment"># computed the normalized statistic (eq. 15 in [2])</span></div>
<div class="line"><span class="lineno"> 1435</span>        tn = 1/6 + (t - et) / np.sqrt(45 * vt)</div>
<div class="line"><span class="lineno"> 1436</span> </div>
<div class="line"><span class="lineno"> 1437</span>        <span class="comment"># approximate distribution of tn with limiting distribution</span></div>
<div class="line"><span class="lineno"> 1438</span>        <span class="comment"># of the one-sample test statistic</span></div>
<div class="line"><span class="lineno"> 1439</span>        <span class="comment"># if tn &lt; 0.003, the _cdf_cvm_inf(tn) &lt; 1.28*1e-18, return 1.0 directly</span></div>
<div class="line"><span class="lineno"> 1440</span>        <span class="keywordflow">if</span> tn &lt; 0.003:</div>
<div class="line"><span class="lineno"> 1441</span>            p = 1.0</div>
<div class="line"><span class="lineno"> 1442</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1443</span>            p = max(0, 1. - _cdf_cvm_inf(tn))</div>
<div class="line"><span class="lineno"> 1444</span> </div>
<div class="line"><span class="lineno"> 1445</span>    <span class="keywordflow">return</span> CramerVonMisesResult(statistic=t, pvalue=p)</div>
<div class="line"><span class="lineno"> 1446</span> </div>
<div class="line"><span class="lineno"> 1447</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ade49f50bc7740c5eed78e17309590a3c" name="ade49f50bc7740c5eed78e17309590a3c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade49f50bc7740c5eed78e17309590a3c">&#9670;&#160;</a></span>epps_singleton_2samp()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.epps_singleton_2samp </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>t</em> = <code>(0.4,&#160;0.8)</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the Epps-Singleton (ES) test statistic.

Test the null hypothesis that two samples have the same underlying
probability distribution.

Parameters
----------
x, y : array-like
    The two samples of observations to be tested. Input must not have more
    than one dimension. Samples can have different lengths.
t : array-like, optional
    The points (t1, ..., tn) where the empirical characteristic function is
    to be evaluated. It should be positive distinct numbers. The default
    value (0.4, 0.8) is proposed in [1]_. Input must not have more than
    one dimension.

Returns
-------
statistic : float
    The test statistic.
pvalue : float
    The associated p-value based on the asymptotic chi2-distribution.

See Also
--------
ks_2samp, anderson_ksamp

Notes
-----
Testing whether two samples are generated by the same underlying
distribution is a classical question in statistics. A widely used test is
the Kolmogorov-Smirnov (KS) test which relies on the empirical
distribution function. Epps and Singleton introduce a test based on the
empirical characteristic function in [1]_.

One advantage of the ES test compared to the KS test is that is does
not assume a continuous distribution. In [1]_, the authors conclude
that the test also has a higher power than the KS test in many
examples. They recommend the use of the ES test for discrete samples as
well as continuous samples with at least 25 observations each, whereas
`anderson_ksamp` is recommended for smaller sample sizes in the
continuous case.

The p-value is computed from the asymptotic distribution of the test
statistic which follows a `chi2` distribution. If the sample size of both
`x` and `y` is below 25, the small sample correction proposed in [1]_ is
applied to the test statistic.

The default values of `t` are determined in [1]_ by considering
various distributions and finding good values that lead to a high power
of the test in general. Table III in [1]_ gives the optimal values for
the distributions tested in that study. The values of `t` are scaled by
the semi-interquartile range in the implementation, see [1]_.

References
----------
.. [1] T. W. Epps and K. J. Singleton, "An omnibus test for the two-sample
   problem using the empirical characteristic function", Journal of
   Statistical Computation and Simulation 26, p. 177--203, 1986.

.. [2] S. J. Goerg and J. Kaiser, "Nonparametric testing of distributions
   - the Epps-Singleton two-sample test using the empirical characteristic
   function", The Stata Journal 9(3), p. 454--465, 2009.</pre> <div class="fragment"><div class="line"><span class="lineno">   26</span><span class="keyword">def </span>epps_singleton_2samp(x, y, t=(0.4, 0.8)):</div>
<div class="line"><span class="lineno">   27</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the Epps-Singleton (ES) test statistic.</span></div>
<div class="line"><span class="lineno">   28</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">    Test the null hypothesis that two samples have the same underlying</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral">    probability distribution.</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">    x, y : array-like</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">        The two samples of observations to be tested. Input must not have more</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">        than one dimension. Samples can have different lengths.</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral">    t : array-like, optional</span></div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral">        The points (t1, ..., tn) where the empirical characteristic function is</span></div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">        to be evaluated. It should be positive distinct numbers. The default</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">        value (0.4, 0.8) is proposed in [1]_. Input must not have more than</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">        one dimension.</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">    statistic : float</span></div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">        The test statistic.</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">    pvalue : float</span></div>
<div class="line"><span class="lineno">   48</span><span class="stringliteral">        The associated p-value based on the asymptotic chi2-distribution.</span></div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">    ks_2samp, anderson_ksamp</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral">    Testing whether two samples are generated by the same underlying</span></div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral">    distribution is a classical question in statistics. A widely used test is</span></div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral">    the Kolmogorov-Smirnov (KS) test which relies on the empirical</span></div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">    distribution function. Epps and Singleton introduce a test based on the</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">    empirical characteristic function in [1]_.</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">    One advantage of the ES test compared to the KS test is that is does</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">    not assume a continuous distribution. In [1]_, the authors conclude</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    that the test also has a higher power than the KS test in many</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">    examples. They recommend the use of the ES test for discrete samples as</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">    well as continuous samples with at least 25 observations each, whereas</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    `anderson_ksamp` is recommended for smaller sample sizes in the</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">    continuous case.</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    The p-value is computed from the asymptotic distribution of the test</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">    statistic which follows a `chi2` distribution. If the sample size of both</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">    `x` and `y` is below 25, the small sample correction proposed in [1]_ is</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">    applied to the test statistic.</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">    The default values of `t` are determined in [1]_ by considering</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">    various distributions and finding good values that lead to a high power</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    of the test in general. Table III in [1]_ gives the optimal values for</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">    the distributions tested in that study. The values of `t` are scaled by</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">    the semi-interquartile range in the implementation, see [1]_.</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">    .. [1] T. W. Epps and K. J. Singleton, &quot;An omnibus test for the two-sample</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral">       problem using the empirical characteristic function&quot;, Journal of</span></div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">       Statistical Computation and Simulation 26, p. 177--203, 1986.</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">    .. [2] S. J. Goerg and J. Kaiser, &quot;Nonparametric testing of distributions</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">       - the Epps-Singleton two-sample test using the empirical characteristic</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">       function&quot;, The Stata Journal 9(3), p. 454--465, 2009.</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   92</span>    x, y, t = np.asarray(x), np.asarray(y), np.asarray(t)</div>
<div class="line"><span class="lineno">   93</span>    <span class="comment"># check if x and y are valid inputs</span></div>
<div class="line"><span class="lineno">   94</span>    <span class="keywordflow">if</span> x.ndim &gt; 1:</div>
<div class="line"><span class="lineno">   95</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;x must be 1d, but x.ndim equals {}.&#39;</span>.format(x.ndim))</div>
<div class="line"><span class="lineno">   96</span>    <span class="keywordflow">if</span> y.ndim &gt; 1:</div>
<div class="line"><span class="lineno">   97</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;y must be 1d, but y.ndim equals {}.&#39;</span>.format(y.ndim))</div>
<div class="line"><span class="lineno">   98</span>    nx, ny = len(x), len(y)</div>
<div class="line"><span class="lineno">   99</span>    <span class="keywordflow">if</span> (nx &lt; 5) <span class="keywordflow">or</span> (ny &lt; 5):</div>
<div class="line"><span class="lineno">  100</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;x and y should have at least 5 elements, but len(x) &#39;</span></div>
<div class="line"><span class="lineno">  101</span>                         <span class="stringliteral">&#39;= {} and len(y) = {}.&#39;</span>.format(nx, ny))</div>
<div class="line"><span class="lineno">  102</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.isfinite(x).all():</div>
<div class="line"><span class="lineno">  103</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;x must not contain nonfinite values.&#39;</span>)</div>
<div class="line"><span class="lineno">  104</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.isfinite(y).all():</div>
<div class="line"><span class="lineno">  105</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;y must not contain nonfinite values.&#39;</span>)</div>
<div class="line"><span class="lineno">  106</span>    n = nx + ny</div>
<div class="line"><span class="lineno">  107</span> </div>
<div class="line"><span class="lineno">  108</span>    <span class="comment"># check if t is valid</span></div>
<div class="line"><span class="lineno">  109</span>    <span class="keywordflow">if</span> t.ndim &gt; 1:</div>
<div class="line"><span class="lineno">  110</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;t must be 1d, but t.ndim equals {}.&#39;</span>.format(t.ndim))</div>
<div class="line"><span class="lineno">  111</span>    <span class="keywordflow">if</span> np.less_equal(t, 0).any():</div>
<div class="line"><span class="lineno">  112</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;t must contain positive elements only.&#39;</span>)</div>
<div class="line"><span class="lineno">  113</span> </div>
<div class="line"><span class="lineno">  114</span>    <span class="comment"># rescale t with semi-iqr as proposed in [1]; import iqr here to avoid</span></div>
<div class="line"><span class="lineno">  115</span>    <span class="comment"># circular import</span></div>
<div class="line"><span class="lineno">  116</span>    <span class="keyword">from</span> <a class="code hl_namespace" href="namespacescipy_1_1stats.html">scipy.stats</a> <span class="keyword">import</span> iqr</div>
<div class="line"><span class="lineno">  117</span>    sigma = iqr(np.hstack((x, y))) / 2</div>
<div class="line"><span class="lineno">  118</span>    ts = np.reshape(t, (-1, 1)) / sigma</div>
<div class="line"><span class="lineno">  119</span> </div>
<div class="line"><span class="lineno">  120</span>    <span class="comment"># covariance estimation of ES test</span></div>
<div class="line"><span class="lineno">  121</span>    gx = np.vstack((np.cos(ts*x), np.sin(ts*x))).T  <span class="comment"># shape = (nx, 2*len(t))</span></div>
<div class="line"><span class="lineno">  122</span>    gy = np.vstack((np.cos(ts*y), np.sin(ts*y))).T</div>
<div class="line"><span class="lineno">  123</span>    cov_x = np.cov(gx.T, bias=<span class="keyword">True</span>)  <span class="comment"># the test uses biased cov-estimate</span></div>
<div class="line"><span class="lineno">  124</span>    cov_y = np.cov(gy.T, bias=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  125</span>    est_cov = (n/nx)*cov_x + (n/ny)*cov_y</div>
<div class="line"><span class="lineno">  126</span>    est_cov_inv = np.linalg.pinv(est_cov)</div>
<div class="line"><span class="lineno">  127</span>    r = np.linalg.matrix_rank(est_cov_inv)</div>
<div class="line"><span class="lineno">  128</span>    <span class="keywordflow">if</span> r &lt; 2*len(t):</div>
<div class="line"><span class="lineno">  129</span>        warnings.warn(<span class="stringliteral">&#39;Estimated covariance matrix does not have full rank. &#39;</span></div>
<div class="line"><span class="lineno">  130</span>                      <span class="stringliteral">&#39;This indicates a bad choice of the input t and the &#39;</span></div>
<div class="line"><span class="lineno">  131</span>                      <span class="stringliteral">&#39;test might not be consistent.&#39;</span>)  <span class="comment"># see p. 183 in [1]_</span></div>
<div class="line"><span class="lineno">  132</span> </div>
<div class="line"><span class="lineno">  133</span>    <span class="comment"># compute test statistic w distributed asympt. as chisquare with df=r</span></div>
<div class="line"><span class="lineno">  134</span>    g_diff = np.mean(gx, axis=0) - np.mean(gy, axis=0)</div>
<div class="line"><span class="lineno">  135</span>    w = n*np.dot(g_diff.T, np.dot(est_cov_inv, g_diff))</div>
<div class="line"><span class="lineno">  136</span> </div>
<div class="line"><span class="lineno">  137</span>    <span class="comment"># apply small-sample correction</span></div>
<div class="line"><span class="lineno">  138</span>    <span class="keywordflow">if</span> (max(nx, ny) &lt; 25):</div>
<div class="line"><span class="lineno">  139</span>        corr = 1.0/(1.0 + n**(-0.45) + 10.1*(nx**(-1.7) + ny**(-1.7)))</div>
<div class="line"><span class="lineno">  140</span>        w = corr * w</div>
<div class="line"><span class="lineno">  141</span> </div>
<div class="line"><span class="lineno">  142</span>    p = chi2.sf(w, r)</div>
<div class="line"><span class="lineno">  143</span> </div>
<div class="line"><span class="lineno">  144</span>    <span class="keywordflow">return</span> Epps_Singleton_2sampResult(w, p)</div>
<div class="line"><span class="lineno">  145</span> </div>
<div class="line"><span class="lineno">  146</span> </div>
<div class="ttc" id="anamespacescipy_1_1stats_html"><div class="ttname"><a href="namespacescipy_1_1stats.html">scipy.stats</a></div><div class="ttdef"><b>Definition</b> __init__.py:1</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a30dc3c3fcba32b99672684269768e0ad" name="a30dc3c3fcba32b99672684269768e0ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30dc3c3fcba32b99672684269768e0ad">&#9670;&#160;</a></span>somersd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.somersd </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alternative</em> = <code>'two-sided'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Calculates Somers' D, an asymmetric measure of ordinal association.

Like Kendall's :math:`\tau`, Somers' :math:`D` is a measure of the
correspondence between two rankings. Both statistics consider the
difference between the number of concordant and discordant pairs in two
rankings :math:`X` and :math:`Y`, and both are normalized such that values
close  to 1 indicate strong agreement and values close to -1 indicate
strong disagreement. They differ in how they are normalized. To show the
relationship, Somers' :math:`D` can be defined in terms of Kendall's
:math:`\tau_a`:

.. math::
    D(Y|X) = \frac{\tau_a(X, Y)}{\tau_a(X, X)}

Suppose the first ranking :math:`X` has :math:`r` distinct ranks and the
second ranking :math:`Y` has :math:`s` distinct ranks. These two lists of
:math:`n` rankings can also be viewed as an :math:`r \times s` contingency
table in which element :math:`i, j` is the number of rank pairs with rank
:math:`i` in ranking :math:`X` and rank :math:`j` in ranking :math:`Y`.
Accordingly, `somersd` also allows the input data to be supplied as a
single, 2D contingency table instead of as two separate, 1D rankings.

Note that the definition of Somers' :math:`D` is asymmetric: in general,
:math:`D(Y|X) \neq D(X|Y)`. ``somersd(x, y)`` calculates Somers'
:math:`D(Y|X)`: the "row" variable :math:`X` is treated as an independent
variable, and the "column" variable :math:`Y` is dependent. For Somers'
:math:`D(X|Y)`, swap the input lists or transpose the input table.

Parameters
----------
x : array_like
    1D array of rankings, treated as the (row) independent variable.
    Alternatively, a 2D contingency table.
y : array_like, optional
    If `x` is a 1D array of rankings, `y` is a 1D array of rankings of the
    same length, treated as the (column) dependent variable.
    If `x` is 2D, `y` is ignored.
alternative : {'two-sided', 'less', 'greater'}, optional
    Defines the alternative hypothesis. Default is 'two-sided'.
    The following options are available:
    * 'two-sided': the rank correlation is nonzero
    * 'less': the rank correlation is negative (less than zero)
    * 'greater':  the rank correlation is positive (greater than zero)

Returns
-------
res : SomersDResult
    A `SomersDResult` object with the following fields:

        correlation : float
           The Somers' :math:`D` statistic.
        pvalue : float
           The p-value for a hypothesis test whose null
           hypothesis is an absence of association, :math:`D=0`.
           See notes for more information.
        table : 2D array
           The contingency table formed from rankings `x` and `y` (or the
           provided contingency table, if `x` is a 2D array)

See Also
--------
kendalltau : Calculates Kendall's tau, another correlation measure.
weightedtau : Computes a weighted version of Kendall's tau.
spearmanr : Calculates a Spearman rank-order correlation coefficient.
pearsonr : Calculates a Pearson correlation coefficient.

Notes
-----
This function follows the contingency table approach of [2]_ and
[3]_. *p*-values are computed based on an asymptotic approximation of
the test statistic distribution under the null hypothesis :math:`D=0`.

Theoretically, hypothesis tests based on Kendall's :math:`tau` and Somers'
:math:`D` should be identical.
However, the *p*-values returned by `kendalltau` are based
on the null hypothesis of *independence* between :math:`X` and :math:`Y`
(i.e. the population from which pairs in :math:`X` and :math:`Y` are
sampled contains equal numbers of all possible pairs), which is more
specific than the null hypothesis :math:`D=0` used here. If the null
hypothesis of independence is desired, it is acceptable to use the
*p*-value returned by `kendalltau` with the statistic returned by
`somersd` and vice versa. For more information, see [2]_.

Contingency tables are formatted according to the convention used by
SAS and R: the first ranking supplied (``x``) is the "row" variable, and
the second ranking supplied (``y``) is the "column" variable. This is
opposite the convention of Somers' original paper [1]_.

References
----------
.. [1] Robert H. Somers, "A New Asymmetric Measure of Association for
       Ordinal Variables", *American Sociological Review*, Vol. 27, No. 6,
       pp. 799--811, 1962.

.. [2] Morton B. Brown and Jacqueline K. Benedetti, "Sampling Behavior of
       Tests for Correlation in Two-Way Contingency Tables", *Journal of
       the American Statistical Association* Vol. 72, No. 358, pp.
       309--315, 1977.

.. [3] SAS Institute, Inc., "The FREQ Procedure (Book Excerpt)",
       *SAS/STAT 9.2 User's Guide, Second Edition*, SAS Publishing, 2009.

.. [4] Laerd Statistics, "Somers' d using SPSS Statistics", *SPSS
       Statistics Tutorials and Statistical Guides*,
       https://statistics.laerd.com/spss-tutorials/somers-d-using-spss-statistics.php,
       Accessed July 31, 2020.

Examples
--------
We calculate Somers' D for the example given in [4]_, in which a hotel
chain owner seeks to determine the association between hotel room
cleanliness and customer satisfaction. The independent variable, hotel
room cleanliness, is ranked on an ordinal scale: "below average (1)",
"average (2)", or "above average (3)". The dependent variable, customer
satisfaction, is ranked on a second scale: "very dissatisfied (1)",
"moderately dissatisfied (2)", "neither dissatisfied nor satisfied (3)",
"moderately satisfied (4)", or "very satisfied (5)". 189 customers
respond to the survey, and the results are cast into a contingency table
with the hotel room cleanliness as the "row" variable and customer
satisfaction as the "column" variable.

+-----+-----+-----+-----+-----+-----+
|     | (1) | (2) | (3) | (4) | (5) |
+=====+=====+=====+=====+=====+=====+
| (1) | 27  | 25  | 14  | 7   | 0   |
+-----+-----+-----+-----+-----+-----+
| (2) | 7   | 14  | 18  | 35  | 12  |
+-----+-----+-----+-----+-----+-----+
| (3) | 1   | 3   | 2   | 7   | 17  |
+-----+-----+-----+-----+-----+-----+

For example, 27 customers assigned their room a cleanliness ranking of
"below average (1)" and a corresponding satisfaction of "very
dissatisfied (1)". We perform the analysis as follows.

&gt;&gt;&gt; from scipy.stats import somersd
&gt;&gt;&gt; table = [[27, 25, 14, 7, 0], [7, 14, 18, 35, 12], [1, 3, 2, 7, 17]]
&gt;&gt;&gt; res = somersd(table)
&gt;&gt;&gt; res.statistic
0.6032766111513396
&gt;&gt;&gt; res.pvalue
1.0007091191074533e-27

The value of the Somers' D statistic is approximately 0.6, indicating
a positive correlation between room cleanliness and customer satisfaction
in the sample.
The *p*-value is very small, indicating a very small probability of
observing such an extreme value of the statistic under the null
hypothesis that the statistic of the entire population (from which
our sample of 189 customers is drawn) is zero. This supports the
alternative hypothesis that the true value of Somers' D for the population
is nonzero.</pre> <div class="fragment"><div class="line"><span class="lineno">  493</span><span class="keyword">def </span>somersd(x, y=None, alternative=&#39;two-sided&#39;):</div>
<div class="line"><span class="lineno">  494</span>    <span class="stringliteral">r&quot;&quot;&quot;Calculates Somers&#39; D, an asymmetric measure of ordinal association.</span></div>
<div class="line"><span class="lineno">  495</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  496</span><span class="stringliteral">    Like Kendall&#39;s :math:`\tau`, Somers&#39; :math:`D` is a measure of the</span></div>
<div class="line"><span class="lineno">  497</span><span class="stringliteral">    correspondence between two rankings. Both statistics consider the</span></div>
<div class="line"><span class="lineno">  498</span><span class="stringliteral">    difference between the number of concordant and discordant pairs in two</span></div>
<div class="line"><span class="lineno">  499</span><span class="stringliteral">    rankings :math:`X` and :math:`Y`, and both are normalized such that values</span></div>
<div class="line"><span class="lineno">  500</span><span class="stringliteral">    close  to 1 indicate strong agreement and values close to -1 indicate</span></div>
<div class="line"><span class="lineno">  501</span><span class="stringliteral">    strong disagreement. They differ in how they are normalized. To show the</span></div>
<div class="line"><span class="lineno">  502</span><span class="stringliteral">    relationship, Somers&#39; :math:`D` can be defined in terms of Kendall&#39;s</span></div>
<div class="line"><span class="lineno">  503</span><span class="stringliteral">    :math:`\tau_a`:</span></div>
<div class="line"><span class="lineno">  504</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  505</span><span class="stringliteral">    .. math::</span></div>
<div class="line"><span class="lineno">  506</span><span class="stringliteral">        D(Y|X) = \frac{\tau_a(X, Y)}{\tau_a(X, X)}</span></div>
<div class="line"><span class="lineno">  507</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  508</span><span class="stringliteral">    Suppose the first ranking :math:`X` has :math:`r` distinct ranks and the</span></div>
<div class="line"><span class="lineno">  509</span><span class="stringliteral">    second ranking :math:`Y` has :math:`s` distinct ranks. These two lists of</span></div>
<div class="line"><span class="lineno">  510</span><span class="stringliteral">    :math:`n` rankings can also be viewed as an :math:`r \times s` contingency</span></div>
<div class="line"><span class="lineno">  511</span><span class="stringliteral">    table in which element :math:`i, j` is the number of rank pairs with rank</span></div>
<div class="line"><span class="lineno">  512</span><span class="stringliteral">    :math:`i` in ranking :math:`X` and rank :math:`j` in ranking :math:`Y`.</span></div>
<div class="line"><span class="lineno">  513</span><span class="stringliteral">    Accordingly, `somersd` also allows the input data to be supplied as a</span></div>
<div class="line"><span class="lineno">  514</span><span class="stringliteral">    single, 2D contingency table instead of as two separate, 1D rankings.</span></div>
<div class="line"><span class="lineno">  515</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  516</span><span class="stringliteral">    Note that the definition of Somers&#39; :math:`D` is asymmetric: in general,</span></div>
<div class="line"><span class="lineno">  517</span><span class="stringliteral">    :math:`D(Y|X) \neq D(X|Y)`. ``somersd(x, y)`` calculates Somers&#39;</span></div>
<div class="line"><span class="lineno">  518</span><span class="stringliteral">    :math:`D(Y|X)`: the &quot;row&quot; variable :math:`X` is treated as an independent</span></div>
<div class="line"><span class="lineno">  519</span><span class="stringliteral">    variable, and the &quot;column&quot; variable :math:`Y` is dependent. For Somers&#39;</span></div>
<div class="line"><span class="lineno">  520</span><span class="stringliteral">    :math:`D(X|Y)`, swap the input lists or transpose the input table.</span></div>
<div class="line"><span class="lineno">  521</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  522</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  523</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  524</span><span class="stringliteral">    x : array_like</span></div>
<div class="line"><span class="lineno">  525</span><span class="stringliteral">        1D array of rankings, treated as the (row) independent variable.</span></div>
<div class="line"><span class="lineno">  526</span><span class="stringliteral">        Alternatively, a 2D contingency table.</span></div>
<div class="line"><span class="lineno">  527</span><span class="stringliteral">    y : array_like, optional</span></div>
<div class="line"><span class="lineno">  528</span><span class="stringliteral">        If `x` is a 1D array of rankings, `y` is a 1D array of rankings of the</span></div>
<div class="line"><span class="lineno">  529</span><span class="stringliteral">        same length, treated as the (column) dependent variable.</span></div>
<div class="line"><span class="lineno">  530</span><span class="stringliteral">        If `x` is 2D, `y` is ignored.</span></div>
<div class="line"><span class="lineno">  531</span><span class="stringliteral">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span></div>
<div class="line"><span class="lineno">  532</span><span class="stringliteral">        Defines the alternative hypothesis. Default is &#39;two-sided&#39;.</span></div>
<div class="line"><span class="lineno">  533</span><span class="stringliteral">        The following options are available:</span></div>
<div class="line"><span class="lineno">  534</span><span class="stringliteral">        * &#39;two-sided&#39;: the rank correlation is nonzero</span></div>
<div class="line"><span class="lineno">  535</span><span class="stringliteral">        * &#39;less&#39;: the rank correlation is negative (less than zero)</span></div>
<div class="line"><span class="lineno">  536</span><span class="stringliteral">        * &#39;greater&#39;:  the rank correlation is positive (greater than zero)</span></div>
<div class="line"><span class="lineno">  537</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  538</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  539</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  540</span><span class="stringliteral">    res : SomersDResult</span></div>
<div class="line"><span class="lineno">  541</span><span class="stringliteral">        A `SomersDResult` object with the following fields:</span></div>
<div class="line"><span class="lineno">  542</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  543</span><span class="stringliteral">            correlation : float</span></div>
<div class="line"><span class="lineno">  544</span><span class="stringliteral">               The Somers&#39; :math:`D` statistic.</span></div>
<div class="line"><span class="lineno">  545</span><span class="stringliteral">            pvalue : float</span></div>
<div class="line"><span class="lineno">  546</span><span class="stringliteral">               The p-value for a hypothesis test whose null</span></div>
<div class="line"><span class="lineno">  547</span><span class="stringliteral">               hypothesis is an absence of association, :math:`D=0`.</span></div>
<div class="line"><span class="lineno">  548</span><span class="stringliteral">               See notes for more information.</span></div>
<div class="line"><span class="lineno">  549</span><span class="stringliteral">            table : 2D array</span></div>
<div class="line"><span class="lineno">  550</span><span class="stringliteral">               The contingency table formed from rankings `x` and `y` (or the</span></div>
<div class="line"><span class="lineno">  551</span><span class="stringliteral">               provided contingency table, if `x` is a 2D array)</span></div>
<div class="line"><span class="lineno">  552</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  553</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  554</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  555</span><span class="stringliteral">    kendalltau : Calculates Kendall&#39;s tau, another correlation measure.</span></div>
<div class="line"><span class="lineno">  556</span><span class="stringliteral">    weightedtau : Computes a weighted version of Kendall&#39;s tau.</span></div>
<div class="line"><span class="lineno">  557</span><span class="stringliteral">    spearmanr : Calculates a Spearman rank-order correlation coefficient.</span></div>
<div class="line"><span class="lineno">  558</span><span class="stringliteral">    pearsonr : Calculates a Pearson correlation coefficient.</span></div>
<div class="line"><span class="lineno">  559</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  560</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  561</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  562</span><span class="stringliteral">    This function follows the contingency table approach of [2]_ and</span></div>
<div class="line"><span class="lineno">  563</span><span class="stringliteral">    [3]_. *p*-values are computed based on an asymptotic approximation of</span></div>
<div class="line"><span class="lineno">  564</span><span class="stringliteral">    the test statistic distribution under the null hypothesis :math:`D=0`.</span></div>
<div class="line"><span class="lineno">  565</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  566</span><span class="stringliteral">    Theoretically, hypothesis tests based on Kendall&#39;s :math:`tau` and Somers&#39;</span></div>
<div class="line"><span class="lineno">  567</span><span class="stringliteral">    :math:`D` should be identical.</span></div>
<div class="line"><span class="lineno">  568</span><span class="stringliteral">    However, the *p*-values returned by `kendalltau` are based</span></div>
<div class="line"><span class="lineno">  569</span><span class="stringliteral">    on the null hypothesis of *independence* between :math:`X` and :math:`Y`</span></div>
<div class="line"><span class="lineno">  570</span><span class="stringliteral">    (i.e. the population from which pairs in :math:`X` and :math:`Y` are</span></div>
<div class="line"><span class="lineno">  571</span><span class="stringliteral">    sampled contains equal numbers of all possible pairs), which is more</span></div>
<div class="line"><span class="lineno">  572</span><span class="stringliteral">    specific than the null hypothesis :math:`D=0` used here. If the null</span></div>
<div class="line"><span class="lineno">  573</span><span class="stringliteral">    hypothesis of independence is desired, it is acceptable to use the</span></div>
<div class="line"><span class="lineno">  574</span><span class="stringliteral">    *p*-value returned by `kendalltau` with the statistic returned by</span></div>
<div class="line"><span class="lineno">  575</span><span class="stringliteral">    `somersd` and vice versa. For more information, see [2]_.</span></div>
<div class="line"><span class="lineno">  576</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  577</span><span class="stringliteral">    Contingency tables are formatted according to the convention used by</span></div>
<div class="line"><span class="lineno">  578</span><span class="stringliteral">    SAS and R: the first ranking supplied (``x``) is the &quot;row&quot; variable, and</span></div>
<div class="line"><span class="lineno">  579</span><span class="stringliteral">    the second ranking supplied (``y``) is the &quot;column&quot; variable. This is</span></div>
<div class="line"><span class="lineno">  580</span><span class="stringliteral">    opposite the convention of Somers&#39; original paper [1]_.</span></div>
<div class="line"><span class="lineno">  581</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  582</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  583</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  584</span><span class="stringliteral">    .. [1] Robert H. Somers, &quot;A New Asymmetric Measure of Association for</span></div>
<div class="line"><span class="lineno">  585</span><span class="stringliteral">           Ordinal Variables&quot;, *American Sociological Review*, Vol. 27, No. 6,</span></div>
<div class="line"><span class="lineno">  586</span><span class="stringliteral">           pp. 799--811, 1962.</span></div>
<div class="line"><span class="lineno">  587</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  588</span><span class="stringliteral">    .. [2] Morton B. Brown and Jacqueline K. Benedetti, &quot;Sampling Behavior of</span></div>
<div class="line"><span class="lineno">  589</span><span class="stringliteral">           Tests for Correlation in Two-Way Contingency Tables&quot;, *Journal of</span></div>
<div class="line"><span class="lineno">  590</span><span class="stringliteral">           the American Statistical Association* Vol. 72, No. 358, pp.</span></div>
<div class="line"><span class="lineno">  591</span><span class="stringliteral">           309--315, 1977.</span></div>
<div class="line"><span class="lineno">  592</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  593</span><span class="stringliteral">    .. [3] SAS Institute, Inc., &quot;The FREQ Procedure (Book Excerpt)&quot;,</span></div>
<div class="line"><span class="lineno">  594</span><span class="stringliteral">           *SAS/STAT 9.2 User&#39;s Guide, Second Edition*, SAS Publishing, 2009.</span></div>
<div class="line"><span class="lineno">  595</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  596</span><span class="stringliteral">    .. [4] Laerd Statistics, &quot;Somers&#39; d using SPSS Statistics&quot;, *SPSS</span></div>
<div class="line"><span class="lineno">  597</span><span class="stringliteral">           Statistics Tutorials and Statistical Guides*,</span></div>
<div class="line"><span class="lineno">  598</span><span class="stringliteral">           https://statistics.laerd.com/spss-tutorials/somers-d-using-spss-statistics.php,</span></div>
<div class="line"><span class="lineno">  599</span><span class="stringliteral">           Accessed July 31, 2020.</span></div>
<div class="line"><span class="lineno">  600</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  601</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  602</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  603</span><span class="stringliteral">    We calculate Somers&#39; D for the example given in [4]_, in which a hotel</span></div>
<div class="line"><span class="lineno">  604</span><span class="stringliteral">    chain owner seeks to determine the association between hotel room</span></div>
<div class="line"><span class="lineno">  605</span><span class="stringliteral">    cleanliness and customer satisfaction. The independent variable, hotel</span></div>
<div class="line"><span class="lineno">  606</span><span class="stringliteral">    room cleanliness, is ranked on an ordinal scale: &quot;below average (1)&quot;,</span></div>
<div class="line"><span class="lineno">  607</span><span class="stringliteral">    &quot;average (2)&quot;, or &quot;above average (3)&quot;. The dependent variable, customer</span></div>
<div class="line"><span class="lineno">  608</span><span class="stringliteral">    satisfaction, is ranked on a second scale: &quot;very dissatisfied (1)&quot;,</span></div>
<div class="line"><span class="lineno">  609</span><span class="stringliteral">    &quot;moderately dissatisfied (2)&quot;, &quot;neither dissatisfied nor satisfied (3)&quot;,</span></div>
<div class="line"><span class="lineno">  610</span><span class="stringliteral">    &quot;moderately satisfied (4)&quot;, or &quot;very satisfied (5)&quot;. 189 customers</span></div>
<div class="line"><span class="lineno">  611</span><span class="stringliteral">    respond to the survey, and the results are cast into a contingency table</span></div>
<div class="line"><span class="lineno">  612</span><span class="stringliteral">    with the hotel room cleanliness as the &quot;row&quot; variable and customer</span></div>
<div class="line"><span class="lineno">  613</span><span class="stringliteral">    satisfaction as the &quot;column&quot; variable.</span></div>
<div class="line"><span class="lineno">  614</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  615</span><span class="stringliteral">    +-----+-----+-----+-----+-----+-----+</span></div>
<div class="line"><span class="lineno">  616</span><span class="stringliteral">    |     | (1) | (2) | (3) | (4) | (5) |</span></div>
<div class="line"><span class="lineno">  617</span><span class="stringliteral">    +=====+=====+=====+=====+=====+=====+</span></div>
<div class="line"><span class="lineno">  618</span><span class="stringliteral">    | (1) | 27  | 25  | 14  | 7   | 0   |</span></div>
<div class="line"><span class="lineno">  619</span><span class="stringliteral">    +-----+-----+-----+-----+-----+-----+</span></div>
<div class="line"><span class="lineno">  620</span><span class="stringliteral">    | (2) | 7   | 14  | 18  | 35  | 12  |</span></div>
<div class="line"><span class="lineno">  621</span><span class="stringliteral">    +-----+-----+-----+-----+-----+-----+</span></div>
<div class="line"><span class="lineno">  622</span><span class="stringliteral">    | (3) | 1   | 3   | 2   | 7   | 17  |</span></div>
<div class="line"><span class="lineno">  623</span><span class="stringliteral">    +-----+-----+-----+-----+-----+-----+</span></div>
<div class="line"><span class="lineno">  624</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  625</span><span class="stringliteral">    For example, 27 customers assigned their room a cleanliness ranking of</span></div>
<div class="line"><span class="lineno">  626</span><span class="stringliteral">    &quot;below average (1)&quot; and a corresponding satisfaction of &quot;very</span></div>
<div class="line"><span class="lineno">  627</span><span class="stringliteral">    dissatisfied (1)&quot;. We perform the analysis as follows.</span></div>
<div class="line"><span class="lineno">  628</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  629</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.stats import somersd</span></div>
<div class="line"><span class="lineno">  630</span><span class="stringliteral">    &gt;&gt;&gt; table = [[27, 25, 14, 7, 0], [7, 14, 18, 35, 12], [1, 3, 2, 7, 17]]</span></div>
<div class="line"><span class="lineno">  631</span><span class="stringliteral">    &gt;&gt;&gt; res = somersd(table)</span></div>
<div class="line"><span class="lineno">  632</span><span class="stringliteral">    &gt;&gt;&gt; res.statistic</span></div>
<div class="line"><span class="lineno">  633</span><span class="stringliteral">    0.6032766111513396</span></div>
<div class="line"><span class="lineno">  634</span><span class="stringliteral">    &gt;&gt;&gt; res.pvalue</span></div>
<div class="line"><span class="lineno">  635</span><span class="stringliteral">    1.0007091191074533e-27</span></div>
<div class="line"><span class="lineno">  636</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  637</span><span class="stringliteral">    The value of the Somers&#39; D statistic is approximately 0.6, indicating</span></div>
<div class="line"><span class="lineno">  638</span><span class="stringliteral">    a positive correlation between room cleanliness and customer satisfaction</span></div>
<div class="line"><span class="lineno">  639</span><span class="stringliteral">    in the sample.</span></div>
<div class="line"><span class="lineno">  640</span><span class="stringliteral">    The *p*-value is very small, indicating a very small probability of</span></div>
<div class="line"><span class="lineno">  641</span><span class="stringliteral">    observing such an extreme value of the statistic under the null</span></div>
<div class="line"><span class="lineno">  642</span><span class="stringliteral">    hypothesis that the statistic of the entire population (from which</span></div>
<div class="line"><span class="lineno">  643</span><span class="stringliteral">    our sample of 189 customers is drawn) is zero. This supports the</span></div>
<div class="line"><span class="lineno">  644</span><span class="stringliteral">    alternative hypothesis that the true value of Somers&#39; D for the population</span></div>
<div class="line"><span class="lineno">  645</span><span class="stringliteral">    is nonzero.</span></div>
<div class="line"><span class="lineno">  646</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  647</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  648</span>    x, y = np.array(x), np.array(y)</div>
<div class="line"><span class="lineno">  649</span>    <span class="keywordflow">if</span> x.ndim == 1:</div>
<div class="line"><span class="lineno">  650</span>        <span class="keywordflow">if</span> x.size != y.size:</div>
<div class="line"><span class="lineno">  651</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Rankings must be of equal length.&quot;</span>)</div>
<div class="line"><span class="lineno">  652</span>        table = scipy.stats.contingency.crosstab(x, y)[1]</div>
<div class="line"><span class="lineno">  653</span>    <span class="keywordflow">elif</span> x.ndim == 2:</div>
<div class="line"><span class="lineno">  654</span>        <span class="keywordflow">if</span> np.any(x &lt; 0):</div>
<div class="line"><span class="lineno">  655</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;All elements of the contingency table must be &quot;</span></div>
<div class="line"><span class="lineno">  656</span>                             <span class="stringliteral">&quot;non-negative.&quot;</span>)</div>
<div class="line"><span class="lineno">  657</span>        <span class="keywordflow">if</span> np.any(x != x.astype(int)):</div>
<div class="line"><span class="lineno">  658</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;All elements of the contingency table must be &quot;</span></div>
<div class="line"><span class="lineno">  659</span>                             <span class="stringliteral">&quot;integer.&quot;</span>)</div>
<div class="line"><span class="lineno">  660</span>        <span class="keywordflow">if</span> x.nonzero()[0].size &lt; 2:</div>
<div class="line"><span class="lineno">  661</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;At least two elements of the contingency table &quot;</span></div>
<div class="line"><span class="lineno">  662</span>                             <span class="stringliteral">&quot;must be nonzero.&quot;</span>)</div>
<div class="line"><span class="lineno">  663</span>        table = x</div>
<div class="line"><span class="lineno">  664</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  665</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;x must be either a 1D or 2D array&quot;</span>)</div>
<div class="line"><span class="lineno">  666</span>    d, p = _somers_d(table, alternative)</div>
<div class="line"><span class="lineno">  667</span>    <span class="keywordflow">return</span> SomersDResult(d, p, table)</div>
<div class="line"><span class="lineno">  668</span> </div>
<div class="line"><span class="lineno">  669</span> </div>
<div class="line"><span class="lineno">  670</span><span class="comment"># This could be combined with `_all_partitions` in `_resampling.py`</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a4607ea9d99c9f1c317fc3eb75e234953" name="a4607ea9d99c9f1c317fc3eb75e234953"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4607ea9d99c9f1c317fc3eb75e234953">&#9670;&#160;</a></span>tukey_hsd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.tukey_hsd </td>
          <td>(</td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>args</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Perform Tukey's HSD test for equality of means over multiple treatments.

Tukey's honestly significant difference (HSD) test performs pairwise
comparison of means for a set of samples. Whereas ANOVA (e.g. `f_oneway`)
assesses whether the true means underlying each sample are identical,
Tukey's HSD is a post hoc test used to compare the mean of each sample
to the mean of each other sample.

The null hypothesis is that the distributions underlying the samples all
have the same mean. The test statistic, which is computed for every
possible pairing of samples, is simply the difference between the sample
means. For each pair, the p-value is the probability under the null
hypothesis (and other assumptions; see notes) of observing such an extreme
value of the statistic, considering that many pairwise comparisons are
being performed. Confidence intervals for the difference between each pair
of means are also available.

Parameters
----------
sample1, sample2, ... : array_like
    The sample measurements for each group. There must be at least
    two arguments.

Returns
-------
result : `~scipy.stats._result_classes.TukeyHSDResult` instance
    The return value is an object with the following attributes:

    statistic : float ndarray
        The computed statistic of the test for each comparison. The element
        at index ``(i, j)`` is the statistic for the comparison between
        groups ``i`` and ``j``.
    pvalue : float ndarray
        The computed p-value of the test for each comparison. The element
        at index ``(i, j)`` is the p-value for the comparison between
        groups ``i`` and ``j``.

    The object has the following methods:

    confidence_interval(confidence_level=0.95):
        Compute the confidence interval for the specified confidence level.

Notes
-----
The use of this test relies on several assumptions.

1. The observations are independent within and among groups.
2. The observations within each group are normally distributed.
3. The distributions from which the samples are drawn have the same finite
   variance.

The original formulation of the test was for samples of equal size [6]_.
In case of unequal sample sizes, the test uses the Tukey-Kramer method
[4]_.

References
----------
.. [1] NIST/SEMATECH e-Handbook of Statistical Methods, "7.4.7.1. Tukey's
       Method."
       https://www.itl.nist.gov/div898/handbook/prc/section4/prc471.htm,
       28 November 2020.
.. [2] Abdi, Herve &amp; Williams, Lynne. (2021). "Tukey's Honestly Significant
       Difference (HSD) Test."
       https://personal.utdallas.edu/~herve/abdi-HSD2010-pretty.pdf
.. [3] "One-Way ANOVA Using SAS PROC ANOVA &amp; PROC GLM." SAS
       Tutorials, 2007, www.stattutorials.com/SAS/TUTORIAL-PROC-GLM.htm.
.. [4] Kramer, Clyde Young. "Extension of Multiple Range Tests to Group
       Means with Unequal Numbers of Replications." Biometrics, vol. 12,
       no. 3, 1956, pp. 307-310. JSTOR, www.jstor.org/stable/3001469.
       Accessed 25 May 2021.
.. [5] NIST/SEMATECH e-Handbook of Statistical Methods, "7.4.3.3.
       The ANOVA table and tests of hypotheses about means"
       https://www.itl.nist.gov/div898/handbook/prc/section4/prc433.htm,
       2 June 2021.
.. [6] Tukey, John W. "Comparing Individual Means in the Analysis of
       Variance." Biometrics, vol. 5, no. 2, 1949, pp. 99-114. JSTOR,
       www.jstor.org/stable/3001913. Accessed 14 June 2021.


Examples
--------
Here are some data comparing the time to relief of three brands of
headache medicine, reported in minutes. Data adapted from [3]_.

&gt;&gt;&gt; from scipy.stats import tukey_hsd
&gt;&gt;&gt; group0 = [24.5, 23.5, 26.4, 27.1, 29.9]
&gt;&gt;&gt; group1 = [28.4, 34.2, 29.5, 32.2, 30.1]
&gt;&gt;&gt; group2 = [26.1, 28.3, 24.3, 26.2, 27.8]

We would like to see if the means between any of the groups are
significantly different. First, visually examine a box and whisker plot.

&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; fig, ax = plt.subplots(1, 1)
&gt;&gt;&gt; ax.boxplot([group0, group1, group2])
&gt;&gt;&gt; ax.set_xticklabels(["group0", "group1", "group2"]) # doctest: +SKIP
&gt;&gt;&gt; ax.set_ylabel("mean") # doctest: +SKIP
&gt;&gt;&gt; plt.show()

From the box and whisker plot, we can see overlap in the interquartile
ranges group 1 to group 2 and group 3, but we can apply the ``tukey_hsd``
test to determine if the difference between means is significant. We
set a significance level of .05 to reject the null hypothesis.

&gt;&gt;&gt; res = tukey_hsd(group0, group1, group2)
&gt;&gt;&gt; print(res)
Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)
Comparison  Statistic  p-value   Lower CI   Upper CI
(0 - 1)     -4.600      0.014     -8.249     -0.951
(0 - 2)     -0.260      0.980     -3.909      3.389
(1 - 0)      4.600      0.014      0.951      8.249
(1 - 2)      4.340      0.020      0.691      7.989
(2 - 0)      0.260      0.980     -3.389      3.909
(2 - 1)     -4.340      0.020     -7.989     -0.691

The null hypothesis is that each group has the same mean. The p-value for
comparisons between ``group0`` and ``group1`` as well as ``group1`` and
``group2`` do not exceed .05, so we reject the null hypothesis that they
have the same means. The p-value of the comparison between ``group0``
and ``group2`` exceeds .05, so we accept the null hypothesis that there
is not a significant difference between their means.

We can also compute the confidence interval associated with our chosen
confidence level.

&gt;&gt;&gt; group0 = [24.5, 23.5, 26.4, 27.1, 29.9]
&gt;&gt;&gt; group1 = [28.4, 34.2, 29.5, 32.2, 30.1]
&gt;&gt;&gt; group2 = [26.1, 28.3, 24.3, 26.2, 27.8]
&gt;&gt;&gt; result = tukey_hsd(group0, group1, group2)
&gt;&gt;&gt; conf = res.confidence_interval(confidence_level=.99)
&gt;&gt;&gt; for ((i, j), l) in np.ndenumerate(conf.low):
...     # filter out self comparisons
...     if i != j:
...         h = conf.high[i,j]
...         print(f"({i} - {j}) {l:&gt;6.3f} {h:&gt;6.3f}")
(0 - 1) -9.480  0.280
(0 - 2) -5.140  4.620
(1 - 0) -0.280  9.480
(1 - 2) -0.540  9.220
(2 - 0) -4.620  5.140
(2 - 1) -9.220  0.540
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1587</span><span class="keyword">def </span>tukey_hsd(*args):</div>
<div class="line"><span class="lineno"> 1588</span>    <span class="stringliteral">&quot;&quot;&quot;Perform Tukey&#39;s HSD test for equality of means over multiple treatments.</span></div>
<div class="line"><span class="lineno"> 1589</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1590</span><span class="stringliteral">    Tukey&#39;s honestly significant difference (HSD) test performs pairwise</span></div>
<div class="line"><span class="lineno"> 1591</span><span class="stringliteral">    comparison of means for a set of samples. Whereas ANOVA (e.g. `f_oneway`)</span></div>
<div class="line"><span class="lineno"> 1592</span><span class="stringliteral">    assesses whether the true means underlying each sample are identical,</span></div>
<div class="line"><span class="lineno"> 1593</span><span class="stringliteral">    Tukey&#39;s HSD is a post hoc test used to compare the mean of each sample</span></div>
<div class="line"><span class="lineno"> 1594</span><span class="stringliteral">    to the mean of each other sample.</span></div>
<div class="line"><span class="lineno"> 1595</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1596</span><span class="stringliteral">    The null hypothesis is that the distributions underlying the samples all</span></div>
<div class="line"><span class="lineno"> 1597</span><span class="stringliteral">    have the same mean. The test statistic, which is computed for every</span></div>
<div class="line"><span class="lineno"> 1598</span><span class="stringliteral">    possible pairing of samples, is simply the difference between the sample</span></div>
<div class="line"><span class="lineno"> 1599</span><span class="stringliteral">    means. For each pair, the p-value is the probability under the null</span></div>
<div class="line"><span class="lineno"> 1600</span><span class="stringliteral">    hypothesis (and other assumptions; see notes) of observing such an extreme</span></div>
<div class="line"><span class="lineno"> 1601</span><span class="stringliteral">    value of the statistic, considering that many pairwise comparisons are</span></div>
<div class="line"><span class="lineno"> 1602</span><span class="stringliteral">    being performed. Confidence intervals for the difference between each pair</span></div>
<div class="line"><span class="lineno"> 1603</span><span class="stringliteral">    of means are also available.</span></div>
<div class="line"><span class="lineno"> 1604</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1605</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1606</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1607</span><span class="stringliteral">    sample1, sample2, ... : array_like</span></div>
<div class="line"><span class="lineno"> 1608</span><span class="stringliteral">        The sample measurements for each group. There must be at least</span></div>
<div class="line"><span class="lineno"> 1609</span><span class="stringliteral">        two arguments.</span></div>
<div class="line"><span class="lineno"> 1610</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1611</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1612</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1613</span><span class="stringliteral">    result : `~scipy.stats._result_classes.TukeyHSDResult` instance</span></div>
<div class="line"><span class="lineno"> 1614</span><span class="stringliteral">        The return value is an object with the following attributes:</span></div>
<div class="line"><span class="lineno"> 1615</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1616</span><span class="stringliteral">        statistic : float ndarray</span></div>
<div class="line"><span class="lineno"> 1617</span><span class="stringliteral">            The computed statistic of the test for each comparison. The element</span></div>
<div class="line"><span class="lineno"> 1618</span><span class="stringliteral">            at index ``(i, j)`` is the statistic for the comparison between</span></div>
<div class="line"><span class="lineno"> 1619</span><span class="stringliteral">            groups ``i`` and ``j``.</span></div>
<div class="line"><span class="lineno"> 1620</span><span class="stringliteral">        pvalue : float ndarray</span></div>
<div class="line"><span class="lineno"> 1621</span><span class="stringliteral">            The computed p-value of the test for each comparison. The element</span></div>
<div class="line"><span class="lineno"> 1622</span><span class="stringliteral">            at index ``(i, j)`` is the p-value for the comparison between</span></div>
<div class="line"><span class="lineno"> 1623</span><span class="stringliteral">            groups ``i`` and ``j``.</span></div>
<div class="line"><span class="lineno"> 1624</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1625</span><span class="stringliteral">        The object has the following methods:</span></div>
<div class="line"><span class="lineno"> 1626</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1627</span><span class="stringliteral">        confidence_interval(confidence_level=0.95):</span></div>
<div class="line"><span class="lineno"> 1628</span><span class="stringliteral">            Compute the confidence interval for the specified confidence level.</span></div>
<div class="line"><span class="lineno"> 1629</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1630</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1631</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1632</span><span class="stringliteral">    The use of this test relies on several assumptions.</span></div>
<div class="line"><span class="lineno"> 1633</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1634</span><span class="stringliteral">    1. The observations are independent within and among groups.</span></div>
<div class="line"><span class="lineno"> 1635</span><span class="stringliteral">    2. The observations within each group are normally distributed.</span></div>
<div class="line"><span class="lineno"> 1636</span><span class="stringliteral">    3. The distributions from which the samples are drawn have the same finite</span></div>
<div class="line"><span class="lineno"> 1637</span><span class="stringliteral">       variance.</span></div>
<div class="line"><span class="lineno"> 1638</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1639</span><span class="stringliteral">    The original formulation of the test was for samples of equal size [6]_.</span></div>
<div class="line"><span class="lineno"> 1640</span><span class="stringliteral">    In case of unequal sample sizes, the test uses the Tukey-Kramer method</span></div>
<div class="line"><span class="lineno"> 1641</span><span class="stringliteral">    [4]_.</span></div>
<div class="line"><span class="lineno"> 1642</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1643</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1644</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1645</span><span class="stringliteral">    .. [1] NIST/SEMATECH e-Handbook of Statistical Methods, &quot;7.4.7.1. Tukey&#39;s</span></div>
<div class="line"><span class="lineno"> 1646</span><span class="stringliteral">           Method.&quot;</span></div>
<div class="line"><span class="lineno"> 1647</span><span class="stringliteral">           https://www.itl.nist.gov/div898/handbook/prc/section4/prc471.htm,</span></div>
<div class="line"><span class="lineno"> 1648</span><span class="stringliteral">           28 November 2020.</span></div>
<div class="line"><span class="lineno"> 1649</span><span class="stringliteral">    .. [2] Abdi, Herve &amp; Williams, Lynne. (2021). &quot;Tukey&#39;s Honestly Significant</span></div>
<div class="line"><span class="lineno"> 1650</span><span class="stringliteral">           Difference (HSD) Test.&quot;</span></div>
<div class="line"><span class="lineno"> 1651</span><span class="stringliteral">           https://personal.utdallas.edu/~herve/abdi-HSD2010-pretty.pdf</span></div>
<div class="line"><span class="lineno"> 1652</span><span class="stringliteral">    .. [3] &quot;One-Way ANOVA Using SAS PROC ANOVA &amp; PROC GLM.&quot; SAS</span></div>
<div class="line"><span class="lineno"> 1653</span><span class="stringliteral">           Tutorials, 2007, www.stattutorials.com/SAS/TUTORIAL-PROC-GLM.htm.</span></div>
<div class="line"><span class="lineno"> 1654</span><span class="stringliteral">    .. [4] Kramer, Clyde Young. &quot;Extension of Multiple Range Tests to Group</span></div>
<div class="line"><span class="lineno"> 1655</span><span class="stringliteral">           Means with Unequal Numbers of Replications.&quot; Biometrics, vol. 12,</span></div>
<div class="line"><span class="lineno"> 1656</span><span class="stringliteral">           no. 3, 1956, pp. 307-310. JSTOR, www.jstor.org/stable/3001469.</span></div>
<div class="line"><span class="lineno"> 1657</span><span class="stringliteral">           Accessed 25 May 2021.</span></div>
<div class="line"><span class="lineno"> 1658</span><span class="stringliteral">    .. [5] NIST/SEMATECH e-Handbook of Statistical Methods, &quot;7.4.3.3.</span></div>
<div class="line"><span class="lineno"> 1659</span><span class="stringliteral">           The ANOVA table and tests of hypotheses about means&quot;</span></div>
<div class="line"><span class="lineno"> 1660</span><span class="stringliteral">           https://www.itl.nist.gov/div898/handbook/prc/section4/prc433.htm,</span></div>
<div class="line"><span class="lineno"> 1661</span><span class="stringliteral">           2 June 2021.</span></div>
<div class="line"><span class="lineno"> 1662</span><span class="stringliteral">    .. [6] Tukey, John W. &quot;Comparing Individual Means in the Analysis of</span></div>
<div class="line"><span class="lineno"> 1663</span><span class="stringliteral">           Variance.&quot; Biometrics, vol. 5, no. 2, 1949, pp. 99-114. JSTOR,</span></div>
<div class="line"><span class="lineno"> 1664</span><span class="stringliteral">           www.jstor.org/stable/3001913. Accessed 14 June 2021.</span></div>
<div class="line"><span class="lineno"> 1665</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1666</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1667</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1668</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1669</span><span class="stringliteral">    Here are some data comparing the time to relief of three brands of</span></div>
<div class="line"><span class="lineno"> 1670</span><span class="stringliteral">    headache medicine, reported in minutes. Data adapted from [3]_.</span></div>
<div class="line"><span class="lineno"> 1671</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1672</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.stats import tukey_hsd</span></div>
<div class="line"><span class="lineno"> 1673</span><span class="stringliteral">    &gt;&gt;&gt; group0 = [24.5, 23.5, 26.4, 27.1, 29.9]</span></div>
<div class="line"><span class="lineno"> 1674</span><span class="stringliteral">    &gt;&gt;&gt; group1 = [28.4, 34.2, 29.5, 32.2, 30.1]</span></div>
<div class="line"><span class="lineno"> 1675</span><span class="stringliteral">    &gt;&gt;&gt; group2 = [26.1, 28.3, 24.3, 26.2, 27.8]</span></div>
<div class="line"><span class="lineno"> 1676</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1677</span><span class="stringliteral">    We would like to see if the means between any of the groups are</span></div>
<div class="line"><span class="lineno"> 1678</span><span class="stringliteral">    significantly different. First, visually examine a box and whisker plot.</span></div>
<div class="line"><span class="lineno"> 1679</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1680</span><span class="stringliteral">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span></div>
<div class="line"><span class="lineno"> 1681</span><span class="stringliteral">    &gt;&gt;&gt; fig, ax = plt.subplots(1, 1)</span></div>
<div class="line"><span class="lineno"> 1682</span><span class="stringliteral">    &gt;&gt;&gt; ax.boxplot([group0, group1, group2])</span></div>
<div class="line"><span class="lineno"> 1683</span><span class="stringliteral">    &gt;&gt;&gt; ax.set_xticklabels([&quot;group0&quot;, &quot;group1&quot;, &quot;group2&quot;]) # doctest: +SKIP</span></div>
<div class="line"><span class="lineno"> 1684</span><span class="stringliteral">    &gt;&gt;&gt; ax.set_ylabel(&quot;mean&quot;) # doctest: +SKIP</span></div>
<div class="line"><span class="lineno"> 1685</span><span class="stringliteral">    &gt;&gt;&gt; plt.show()</span></div>
<div class="line"><span class="lineno"> 1686</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1687</span><span class="stringliteral">    From the box and whisker plot, we can see overlap in the interquartile</span></div>
<div class="line"><span class="lineno"> 1688</span><span class="stringliteral">    ranges group 1 to group 2 and group 3, but we can apply the ``tukey_hsd``</span></div>
<div class="line"><span class="lineno"> 1689</span><span class="stringliteral">    test to determine if the difference between means is significant. We</span></div>
<div class="line"><span class="lineno"> 1690</span><span class="stringliteral">    set a significance level of .05 to reject the null hypothesis.</span></div>
<div class="line"><span class="lineno"> 1691</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1692</span><span class="stringliteral">    &gt;&gt;&gt; res = tukey_hsd(group0, group1, group2)</span></div>
<div class="line"><span class="lineno"> 1693</span><span class="stringliteral">    &gt;&gt;&gt; print(res)</span></div>
<div class="line"><span class="lineno"> 1694</span><span class="stringliteral">    Tukey&#39;s HSD Pairwise Group Comparisons (95.0% Confidence Interval)</span></div>
<div class="line"><span class="lineno"> 1695</span><span class="stringliteral">    Comparison  Statistic  p-value   Lower CI   Upper CI</span></div>
<div class="line"><span class="lineno"> 1696</span><span class="stringliteral">    (0 - 1)     -4.600      0.014     -8.249     -0.951</span></div>
<div class="line"><span class="lineno"> 1697</span><span class="stringliteral">    (0 - 2)     -0.260      0.980     -3.909      3.389</span></div>
<div class="line"><span class="lineno"> 1698</span><span class="stringliteral">    (1 - 0)      4.600      0.014      0.951      8.249</span></div>
<div class="line"><span class="lineno"> 1699</span><span class="stringliteral">    (1 - 2)      4.340      0.020      0.691      7.989</span></div>
<div class="line"><span class="lineno"> 1700</span><span class="stringliteral">    (2 - 0)      0.260      0.980     -3.389      3.909</span></div>
<div class="line"><span class="lineno"> 1701</span><span class="stringliteral">    (2 - 1)     -4.340      0.020     -7.989     -0.691</span></div>
<div class="line"><span class="lineno"> 1702</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1703</span><span class="stringliteral">    The null hypothesis is that each group has the same mean. The p-value for</span></div>
<div class="line"><span class="lineno"> 1704</span><span class="stringliteral">    comparisons between ``group0`` and ``group1`` as well as ``group1`` and</span></div>
<div class="line"><span class="lineno"> 1705</span><span class="stringliteral">    ``group2`` do not exceed .05, so we reject the null hypothesis that they</span></div>
<div class="line"><span class="lineno"> 1706</span><span class="stringliteral">    have the same means. The p-value of the comparison between ``group0``</span></div>
<div class="line"><span class="lineno"> 1707</span><span class="stringliteral">    and ``group2`` exceeds .05, so we accept the null hypothesis that there</span></div>
<div class="line"><span class="lineno"> 1708</span><span class="stringliteral">    is not a significant difference between their means.</span></div>
<div class="line"><span class="lineno"> 1709</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1710</span><span class="stringliteral">    We can also compute the confidence interval associated with our chosen</span></div>
<div class="line"><span class="lineno"> 1711</span><span class="stringliteral">    confidence level.</span></div>
<div class="line"><span class="lineno"> 1712</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1713</span><span class="stringliteral">    &gt;&gt;&gt; group0 = [24.5, 23.5, 26.4, 27.1, 29.9]</span></div>
<div class="line"><span class="lineno"> 1714</span><span class="stringliteral">    &gt;&gt;&gt; group1 = [28.4, 34.2, 29.5, 32.2, 30.1]</span></div>
<div class="line"><span class="lineno"> 1715</span><span class="stringliteral">    &gt;&gt;&gt; group2 = [26.1, 28.3, 24.3, 26.2, 27.8]</span></div>
<div class="line"><span class="lineno"> 1716</span><span class="stringliteral">    &gt;&gt;&gt; result = tukey_hsd(group0, group1, group2)</span></div>
<div class="line"><span class="lineno"> 1717</span><span class="stringliteral">    &gt;&gt;&gt; conf = res.confidence_interval(confidence_level=.99)</span></div>
<div class="line"><span class="lineno"> 1718</span><span class="stringliteral">    &gt;&gt;&gt; for ((i, j), l) in np.ndenumerate(conf.low):</span></div>
<div class="line"><span class="lineno"> 1719</span><span class="stringliteral">    ...     # filter out self comparisons</span></div>
<div class="line"><span class="lineno"> 1720</span><span class="stringliteral">    ...     if i != j:</span></div>
<div class="line"><span class="lineno"> 1721</span><span class="stringliteral">    ...         h = conf.high[i,j]</span></div>
<div class="line"><span class="lineno"> 1722</span><span class="stringliteral">    ...         print(f&quot;({i} - {j}) {l:&gt;6.3f} {h:&gt;6.3f}&quot;)</span></div>
<div class="line"><span class="lineno"> 1723</span><span class="stringliteral">    (0 - 1) -9.480  0.280</span></div>
<div class="line"><span class="lineno"> 1724</span><span class="stringliteral">    (0 - 2) -5.140  4.620</span></div>
<div class="line"><span class="lineno"> 1725</span><span class="stringliteral">    (1 - 0) -0.280  9.480</span></div>
<div class="line"><span class="lineno"> 1726</span><span class="stringliteral">    (1 - 2) -0.540  9.220</span></div>
<div class="line"><span class="lineno"> 1727</span><span class="stringliteral">    (2 - 0) -4.620  5.140</span></div>
<div class="line"><span class="lineno"> 1728</span><span class="stringliteral">    (2 - 1) -9.220  0.540</span></div>
<div class="line"><span class="lineno"> 1729</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1730</span>    args = _tukey_hsd_iv(args)</div>
<div class="line"><span class="lineno"> 1731</span>    ntreatments = len(args)</div>
<div class="line"><span class="lineno"> 1732</span>    means = np.asarray([np.mean(arg) <span class="keywordflow">for</span> arg <span class="keywordflow">in</span> args])</div>
<div class="line"><span class="lineno"> 1733</span>    nsamples_treatments = np.asarray([a.size <span class="keywordflow">for</span> a <span class="keywordflow">in</span> args])</div>
<div class="line"><span class="lineno"> 1734</span>    nobs = np.sum(nsamples_treatments)</div>
<div class="line"><span class="lineno"> 1735</span> </div>
<div class="line"><span class="lineno"> 1736</span>    <span class="comment"># determine mean square error [5]. Note that this is sometimes called</span></div>
<div class="line"><span class="lineno"> 1737</span>    <span class="comment"># mean square error within.</span></div>
<div class="line"><span class="lineno"> 1738</span>    mse = (np.sum([np.var(arg, ddof=1) <span class="keywordflow">for</span> arg <span class="keywordflow">in</span> args] *</div>
<div class="line"><span class="lineno"> 1739</span>                  (nsamples_treatments - 1)) / (nobs - ntreatments))</div>
<div class="line"><span class="lineno"> 1740</span> </div>
<div class="line"><span class="lineno"> 1741</span>    <span class="comment"># The calculation of the standard error differs when treatments differ in</span></div>
<div class="line"><span class="lineno"> 1742</span>    <span class="comment"># size. See (&quot;Unequal sample sizes&quot;)[1].</span></div>
<div class="line"><span class="lineno"> 1743</span>    <span class="keywordflow">if</span> np.unique(nsamples_treatments).size == 1:</div>
<div class="line"><span class="lineno"> 1744</span>        <span class="comment"># all input groups are the same length, so only one value needs to be</span></div>
<div class="line"><span class="lineno"> 1745</span>        <span class="comment"># calculated [1].</span></div>
<div class="line"><span class="lineno"> 1746</span>        normalize = 2 / nsamples_treatments[0]</div>
<div class="line"><span class="lineno"> 1747</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1748</span>        <span class="comment"># to compare groups of differing sizes, we must compute a variance</span></div>
<div class="line"><span class="lineno"> 1749</span>        <span class="comment"># value for each individual comparison. Use broadcasting to get the</span></div>
<div class="line"><span class="lineno"> 1750</span>        <span class="comment"># resulting matrix. [3], verified against [4] (page 308).</span></div>
<div class="line"><span class="lineno"> 1751</span>        normalize = 1 / nsamples_treatments + 1 / nsamples_treatments[<span class="keywordtype">None</span>].T</div>
<div class="line"><span class="lineno"> 1752</span> </div>
<div class="line"><span class="lineno"> 1753</span>    <span class="comment"># the standard error is used in the computation of the tukey criterion and</span></div>
<div class="line"><span class="lineno"> 1754</span>    <span class="comment"># finding the p-values.</span></div>
<div class="line"><span class="lineno"> 1755</span>    stand_err = np.sqrt(normalize * mse / 2)</div>
<div class="line"><span class="lineno"> 1756</span> </div>
<div class="line"><span class="lineno"> 1757</span>    <span class="comment"># the mean difference is the test statistic.</span></div>
<div class="line"><span class="lineno"> 1758</span>    mean_differences = means[<span class="keywordtype">None</span>].T - means</div>
<div class="line"><span class="lineno"> 1759</span> </div>
<div class="line"><span class="lineno"> 1760</span>    <span class="comment"># Calculate the t-statistic to use within the survival function of the</span></div>
<div class="line"><span class="lineno"> 1761</span>    <span class="comment"># studentized range to get the p-value.</span></div>
<div class="line"><span class="lineno"> 1762</span>    t_stat = np.abs(mean_differences) / stand_err</div>
<div class="line"><span class="lineno"> 1763</span> </div>
<div class="line"><span class="lineno"> 1764</span>    params = t_stat, ntreatments, nobs - ntreatments</div>
<div class="line"><span class="lineno"> 1765</span>    pvalues = distributions.studentized_range.sf(*params)</div>
<div class="line"><span class="lineno"> 1766</span> </div>
<div class="line"><span class="lineno"> 1767</span>    <span class="keywordflow">return</span> TukeyHSDResult(mean_differences, pvalues, ntreatments,</div>
<div class="line"><span class="lineno"> 1768</span>                          nobs, stand_err)</div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a08713966f8e9c1e73c9340fcfd7acb22" name="a08713966f8e9c1e73c9340fcfd7acb22"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a08713966f8e9c1e73c9340fcfd7acb22">&#9670;&#160;</a></span>BarnardExactResult</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.BarnardExactResult</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  make_dataclass(</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;BarnardExactResult&quot;</span>, [(<span class="stringliteral">&quot;statistic&quot;</span>, float), (<span class="stringliteral">&quot;pvalue&quot;</span>, float)]</div>
<div class="line"><span class="lineno">    3</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae76ac75a487d0f7e9588bbe758dbc559" name="ae76ac75a487d0f7e9588bbe758dbc559"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae76ac75a487d0f7e9588bbe758dbc559">&#9670;&#160;</a></span>BoschlooExactResult</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.BoschlooExactResult</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  make_dataclass(</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;BoschlooExactResult&quot;</span>, [(<span class="stringliteral">&quot;statistic&quot;</span>, float), (<span class="stringliteral">&quot;pvalue&quot;</span>, float)]</div>
<div class="line"><span class="lineno">    3</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae2a84451be9d11611837fae22a5c57f1" name="ae2a84451be9d11611837fae22a5c57f1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae2a84451be9d11611837fae22a5c57f1">&#9670;&#160;</a></span>Epps_Singleton_2sampResult</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.Epps_Singleton_2sampResult</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  namedtuple(<span class="stringliteral">&#39;Epps_Singleton_2sampResult&#39;</span>,</div>
<div class="line"><span class="lineno">    2</span>                                        (<span class="stringliteral">&#39;statistic&#39;</span>, <span class="stringliteral">&#39;pvalue&#39;</span>))</div>
</div><!-- fragment -->
</div>
</div>
<a id="aa2902b2457de9fa8b25d97cc0edb71a6" name="aa2902b2457de9fa8b25d97cc0edb71a6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa2902b2457de9fa8b25d97cc0edb71a6">&#9670;&#160;</a></span>SomersDResult</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._hypotests.SomersDResult</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  make_dataclass(<span class="stringliteral">&quot;SomersDResult&quot;</span>,</div>
<div class="line"><span class="lineno">    2</span>                               (<span class="stringliteral">&quot;statistic&quot;</span>, <span class="stringliteral">&quot;pvalue&quot;</span>, <span class="stringliteral">&quot;table&quot;</span>))</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
