<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.linear_model.tests.test_logistic Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model.html">linear_model</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html">test_logistic</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.linear_model.tests.test_logistic Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a7288a8c6e9a8ca0438aae10fcd10ca00" id="r_a7288a8c6e9a8ca0438aae10fcd10ca00"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a7288a8c6e9a8ca0438aae10fcd10ca00">check_predictions</a> (clf, <a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a9a02178a87ba834f43ed4ebfe8602531">X</a>, y)</td></tr>
<tr class="separator:a7288a8c6e9a8ca0438aae10fcd10ca00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f8af8ca03b87c1d1b79fda5dca398d6" id="r_a0f8af8ca03b87c1d1b79fda5dca398d6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a0f8af8ca03b87c1d1b79fda5dca398d6">test_predict_2_classes</a> ()</td></tr>
<tr class="separator:a0f8af8ca03b87c1d1b79fda5dca398d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3067917cdf019b056a921769cca5ba51" id="r_a3067917cdf019b056a921769cca5ba51"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a3067917cdf019b056a921769cca5ba51">test_logistic_cv_mock_scorer</a> ()</td></tr>
<tr class="separator:a3067917cdf019b056a921769cca5ba51"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11bee06f84f1c3e05a1e5ae3c34e2d9e" id="r_a11bee06f84f1c3e05a1e5ae3c34e2d9e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a11bee06f84f1c3e05a1e5ae3c34e2d9e">test_lr_liblinear_warning</a> ()</td></tr>
<tr class="separator:a11bee06f84f1c3e05a1e5ae3c34e2d9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6bce7db98ecf0a5def40f60a09226e86" id="r_a6bce7db98ecf0a5def40f60a09226e86"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a6bce7db98ecf0a5def40f60a09226e86">test_predict_3_classes</a> ()</td></tr>
<tr class="separator:a6bce7db98ecf0a5def40f60a09226e86"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38553d322458ccc7f222fbcfb681f330" id="r_a38553d322458ccc7f222fbcfb681f330"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a38553d322458ccc7f222fbcfb681f330">test_predict_iris</a> (clf)</td></tr>
<tr class="separator:a38553d322458ccc7f222fbcfb681f330"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae119619aab389ee7f4af0972d79ca7f2" id="r_ae119619aab389ee7f4af0972d79ca7f2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ae119619aab389ee7f4af0972d79ca7f2">test_check_solver_option</a> (LR)</td></tr>
<tr class="separator:ae119619aab389ee7f4af0972d79ca7f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba93b75faf60c36b0cc5f2286db9091c" id="r_aba93b75faf60c36b0cc5f2286db9091c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#aba93b75faf60c36b0cc5f2286db9091c">test_multinomial_binary</a> (solver)</td></tr>
<tr class="separator:aba93b75faf60c36b0cc5f2286db9091c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae66b03afc8741b0f67977f3457e498b" id="r_aae66b03afc8741b0f67977f3457e498b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#aae66b03afc8741b0f67977f3457e498b">test_multinomial_binary_probabilities</a> ()</td></tr>
<tr class="separator:aae66b03afc8741b0f67977f3457e498b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6916a00b87758ee3c64053e6094ad67f" id="r_a6916a00b87758ee3c64053e6094ad67f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a6916a00b87758ee3c64053e6094ad67f">test_sparsify</a> ()</td></tr>
<tr class="separator:a6916a00b87758ee3c64053e6094ad67f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ad26fbf03f3898ff05da0646ffdb673" id="r_a1ad26fbf03f3898ff05da0646ffdb673"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a1ad26fbf03f3898ff05da0646ffdb673">test_inconsistent_input</a> ()</td></tr>
<tr class="separator:a1ad26fbf03f3898ff05da0646ffdb673"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53d29aa32d15f5154ec88d20a48458a9" id="r_a53d29aa32d15f5154ec88d20a48458a9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a53d29aa32d15f5154ec88d20a48458a9">test_write_parameters</a> ()</td></tr>
<tr class="separator:a53d29aa32d15f5154ec88d20a48458a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac96914f98643a39ee12ee8d8eefa554e" id="r_ac96914f98643a39ee12ee8d8eefa554e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ac96914f98643a39ee12ee8d8eefa554e">test_nan</a> ()</td></tr>
<tr class="separator:ac96914f98643a39ee12ee8d8eefa554e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8d30ff56102f3ae39c64492c0a354cb" id="r_ab8d30ff56102f3ae39c64492c0a354cb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ab8d30ff56102f3ae39c64492c0a354cb">test_consistency_path</a> ()</td></tr>
<tr class="separator:ab8d30ff56102f3ae39c64492c0a354cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03351f0260b2b892c4aba5e219f338dc" id="r_a03351f0260b2b892c4aba5e219f338dc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a03351f0260b2b892c4aba5e219f338dc">test_logistic_regression_path_convergence_fail</a> ()</td></tr>
<tr class="separator:a03351f0260b2b892c4aba5e219f338dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a148b1c5466ca3f96d15a39b7723491b0" id="r_a148b1c5466ca3f96d15a39b7723491b0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a148b1c5466ca3f96d15a39b7723491b0">test_liblinear_dual_random_state</a> ()</td></tr>
<tr class="separator:a148b1c5466ca3f96d15a39b7723491b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23db0122ed0d78fff52329a068918fe5" id="r_a23db0122ed0d78fff52329a068918fe5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a23db0122ed0d78fff52329a068918fe5">test_logistic_cv</a> ()</td></tr>
<tr class="separator:a23db0122ed0d78fff52329a068918fe5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08cdc4b88073e8973f2bd37e8484973f" id="r_a08cdc4b88073e8973f2bd37e8484973f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a08cdc4b88073e8973f2bd37e8484973f">test_logistic_cv_multinomial_score</a> (scoring, multiclass_agg_list)</td></tr>
<tr class="separator:a08cdc4b88073e8973f2bd37e8484973f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d668c26cf39586c330a1f7bb48ff232" id="r_a3d668c26cf39586c330a1f7bb48ff232"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a3d668c26cf39586c330a1f7bb48ff232">test_multinomial_logistic_regression_string_inputs</a> ()</td></tr>
<tr class="separator:a3d668c26cf39586c330a1f7bb48ff232"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acdeba50a49339103106dc686032ad48c" id="r_acdeba50a49339103106dc686032ad48c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#acdeba50a49339103106dc686032ad48c">test_logistic_cv_sparse</a> ()</td></tr>
<tr class="separator:acdeba50a49339103106dc686032ad48c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3188867e9e7adb1be8ef5df661460bc" id="r_ab3188867e9e7adb1be8ef5df661460bc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ab3188867e9e7adb1be8ef5df661460bc">test_ovr_multinomial_iris</a> ()</td></tr>
<tr class="separator:ab3188867e9e7adb1be8ef5df661460bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a731dda67339a3ffdd633c6e7ab94b49a" id="r_a731dda67339a3ffdd633c6e7ab94b49a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a731dda67339a3ffdd633c6e7ab94b49a">test_logistic_regression_solvers</a> ()</td></tr>
<tr class="separator:a731dda67339a3ffdd633c6e7ab94b49a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae37006bca018d4af94b15e2f424b6e93" id="r_ae37006bca018d4af94b15e2f424b6e93"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ae37006bca018d4af94b15e2f424b6e93">test_logistic_regression_solvers_multiclass</a> ()</td></tr>
<tr class="separator:ae37006bca018d4af94b15e2f424b6e93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a80f07182e55c88c55ea116b350d4aa" id="r_a9a80f07182e55c88c55ea116b350d4aa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a9a80f07182e55c88c55ea116b350d4aa">test_logistic_regressioncv_class_weights</a> (weight, class_weight)</td></tr>
<tr class="separator:a9a80f07182e55c88c55ea116b350d4aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba9cac5343e6306f27ceff79137e1e26" id="r_aba9cac5343e6306f27ceff79137e1e26"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#aba9cac5343e6306f27ceff79137e1e26">test_logistic_regression_sample_weights</a> ()</td></tr>
<tr class="separator:aba9cac5343e6306f27ceff79137e1e26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af28a6758b40ad94d881380bcd8784dea" id="r_af28a6758b40ad94d881380bcd8784dea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#af28a6758b40ad94d881380bcd8784dea">_compute_class_weight_dictionary</a> (y)</td></tr>
<tr class="separator:af28a6758b40ad94d881380bcd8784dea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a089afffd44ad51379fccc9cdd2ec3823" id="r_a089afffd44ad51379fccc9cdd2ec3823"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a089afffd44ad51379fccc9cdd2ec3823">test_logistic_regression_class_weights</a> ()</td></tr>
<tr class="separator:a089afffd44ad51379fccc9cdd2ec3823"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54299a02691d04b706cd7e98ba8e1812" id="r_a54299a02691d04b706cd7e98ba8e1812"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a54299a02691d04b706cd7e98ba8e1812">test_logistic_regression_multinomial</a> ()</td></tr>
<tr class="separator:a54299a02691d04b706cd7e98ba8e1812"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad457eab5d6957226046959b2ec3c91b3" id="r_ad457eab5d6957226046959b2ec3c91b3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ad457eab5d6957226046959b2ec3c91b3">test_liblinear_decision_function_zero</a> ()</td></tr>
<tr class="separator:ad457eab5d6957226046959b2ec3c91b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49ddabb50cb8a42d2f7d1f6281252228" id="r_a49ddabb50cb8a42d2f7d1f6281252228"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a49ddabb50cb8a42d2f7d1f6281252228">test_liblinear_logregcv_sparse</a> ()</td></tr>
<tr class="separator:a49ddabb50cb8a42d2f7d1f6281252228"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1ebdf9bf97bed6d41f2080774118643" id="r_ab1ebdf9bf97bed6d41f2080774118643"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ab1ebdf9bf97bed6d41f2080774118643">test_saga_sparse</a> ()</td></tr>
<tr class="separator:ab1ebdf9bf97bed6d41f2080774118643"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39d9d368094b2af8602c8a5840df6723" id="r_a39d9d368094b2af8602c8a5840df6723"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a39d9d368094b2af8602c8a5840df6723">test_logreg_intercept_scaling_zero</a> ()</td></tr>
<tr class="separator:a39d9d368094b2af8602c8a5840df6723"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38e964766c54077dbee6db6b6bfc48b6" id="r_a38e964766c54077dbee6db6b6bfc48b6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a38e964766c54077dbee6db6b6bfc48b6">test_logreg_l1</a> ()</td></tr>
<tr class="separator:a38e964766c54077dbee6db6b6bfc48b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adaaf1a0153419d997581392d49ff9520" id="r_adaaf1a0153419d997581392d49ff9520"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#adaaf1a0153419d997581392d49ff9520">test_logreg_l1_sparse_data</a> ()</td></tr>
<tr class="separator:adaaf1a0153419d997581392d49ff9520"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf54f74352aab988efb7b55c9bae0f67" id="r_acf54f74352aab988efb7b55c9bae0f67"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#acf54f74352aab988efb7b55c9bae0f67">test_logistic_regression_cv_refit</a> (random_seed, penalty)</td></tr>
<tr class="separator:acf54f74352aab988efb7b55c9bae0f67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97bc78159a5598de578ab46d4438bfa0" id="r_a97bc78159a5598de578ab46d4438bfa0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a97bc78159a5598de578ab46d4438bfa0">test_logreg_predict_proba_multinomial</a> ()</td></tr>
<tr class="separator:a97bc78159a5598de578ab46d4438bfa0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a472c25c6285608ccd9453cc46dc365a1" id="r_a472c25c6285608ccd9453cc46dc365a1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a472c25c6285608ccd9453cc46dc365a1">test_max_iter</a> (max_iter, multi_class, solver, message)</td></tr>
<tr class="separator:a472c25c6285608ccd9453cc46dc365a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f114b87b3d22996af978ec41b975d7c" id="r_a6f114b87b3d22996af978ec41b975d7c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a6f114b87b3d22996af978ec41b975d7c">test_n_iter</a> (solver)</td></tr>
<tr class="separator:a6f114b87b3d22996af978ec41b975d7c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac80a99790476a49d13f5540d796bdd36" id="r_ac80a99790476a49d13f5540d796bdd36"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ac80a99790476a49d13f5540d796bdd36">test_warm_start</a> (solver, warm_start, fit_intercept, multi_class)</td></tr>
<tr class="separator:ac80a99790476a49d13f5540d796bdd36"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a519565729c3bde29bffe808a6589dc19" id="r_a519565729c3bde29bffe808a6589dc19"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a519565729c3bde29bffe808a6589dc19">test_saga_vs_liblinear</a> ()</td></tr>
<tr class="separator:a519565729c3bde29bffe808a6589dc19"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2913fdd756327282ba43cb430fef515" id="r_ad2913fdd756327282ba43cb430fef515"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ad2913fdd756327282ba43cb430fef515">test_dtype_match</a> (solver, multi_class, fit_intercept)</td></tr>
<tr class="separator:ad2913fdd756327282ba43cb430fef515"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4542dadcf84d48a505c214263d47059d" id="r_a4542dadcf84d48a505c214263d47059d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a4542dadcf84d48a505c214263d47059d">test_warm_start_converge_LR</a> ()</td></tr>
<tr class="separator:a4542dadcf84d48a505c214263d47059d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a153a90b7e513f2256eb1d9d32198c76f" id="r_a153a90b7e513f2256eb1d9d32198c76f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a153a90b7e513f2256eb1d9d32198c76f">test_elastic_net_coeffs</a> ()</td></tr>
<tr class="separator:a153a90b7e513f2256eb1d9d32198c76f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae299aebe2167cd0efc1d02468c2d4efa" id="r_ae299aebe2167cd0efc1d02468c2d4efa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ae299aebe2167cd0efc1d02468c2d4efa">test_elastic_net_l1_l2_equivalence</a> (C, penalty, l1_ratio)</td></tr>
<tr class="separator:ae299aebe2167cd0efc1d02468c2d4efa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7af89da52d8cbc9d8ff4b070d4a85a92" id="r_a7af89da52d8cbc9d8ff4b070d4a85a92"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a7af89da52d8cbc9d8ff4b070d4a85a92">test_elastic_net_vs_l1_l2</a> (C)</td></tr>
<tr class="separator:a7af89da52d8cbc9d8ff4b070d4a85a92"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9159bb73e1d00f61da5d8b28905bd277" id="r_a9159bb73e1d00f61da5d8b28905bd277"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a9159bb73e1d00f61da5d8b28905bd277">test_LogisticRegression_elastic_net_objective</a> (C, l1_ratio)</td></tr>
<tr class="separator:a9159bb73e1d00f61da5d8b28905bd277"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02d115de9cf0f823bc4f51fa64e480dd" id="r_a02d115de9cf0f823bc4f51fa64e480dd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a02d115de9cf0f823bc4f51fa64e480dd">test_LogisticRegressionCV_GridSearchCV_elastic_net</a> (multi_class)</td></tr>
<tr class="separator:a02d115de9cf0f823bc4f51fa64e480dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a60706e57ac99bc4d2284f588186a99a3" id="r_a60706e57ac99bc4d2284f588186a99a3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a60706e57ac99bc4d2284f588186a99a3">test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr</a> ()</td></tr>
<tr class="separator:a60706e57ac99bc4d2284f588186a99a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2c04007b276f5e2cb6a2b7e89f4ac2a" id="r_ac2c04007b276f5e2cb6a2b7e89f4ac2a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ac2c04007b276f5e2cb6a2b7e89f4ac2a">test_LogisticRegressionCV_no_refit</a> (penalty, multi_class)</td></tr>
<tr class="separator:ac2c04007b276f5e2cb6a2b7e89f4ac2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7be590b24e759c6e8980cd5e94ca799f" id="r_a7be590b24e759c6e8980cd5e94ca799f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a7be590b24e759c6e8980cd5e94ca799f">test_LogisticRegressionCV_elasticnet_attribute_shapes</a> ()</td></tr>
<tr class="separator:a7be590b24e759c6e8980cd5e94ca799f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42da9373a489336822f8392044961e08" id="r_a42da9373a489336822f8392044961e08"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a42da9373a489336822f8392044961e08">test_l1_ratio_non_elasticnet</a> ()</td></tr>
<tr class="separator:a42da9373a489336822f8392044961e08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f3a510aa5aef9e6511cc4753f9cfcff" id="r_a6f3a510aa5aef9e6511cc4753f9cfcff"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a6f3a510aa5aef9e6511cc4753f9cfcff">test_elastic_net_versus_sgd</a> (C, l1_ratio)</td></tr>
<tr class="separator:a6f3a510aa5aef9e6511cc4753f9cfcff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea34792ca05958ed27144d1b4e6b96c1" id="r_aea34792ca05958ed27144d1b4e6b96c1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#aea34792ca05958ed27144d1b4e6b96c1">test_logistic_regression_path_coefs_multinomial</a> ()</td></tr>
<tr class="separator:aea34792ca05958ed27144d1b4e6b96c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab378f0cc6f9f7965eee7d257414d9ab" id="r_aab378f0cc6f9f7965eee7d257414d9ab"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#aab378f0cc6f9f7965eee7d257414d9ab">test_logistic_regression_multi_class_auto</a> (<a class="el" href="__lapack__subroutines_8h.html#a20cd275d1dea5cba0a51b3e106f3e130">est</a>, solver)</td></tr>
<tr class="separator:aab378f0cc6f9f7965eee7d257414d9ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86db358d880c6286ca1b5f5ed1ab46d5" id="r_a86db358d880c6286ca1b5f5ed1ab46d5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a86db358d880c6286ca1b5f5ed1ab46d5">test_penalty_none</a> (solver)</td></tr>
<tr class="separator:a86db358d880c6286ca1b5f5ed1ab46d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b840bb9a5d642e6f17337a4a029dad1" id="r_a8b840bb9a5d642e6f17337a4a029dad1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a8b840bb9a5d642e6f17337a4a029dad1">test_logisticregression_liblinear_sample_weight</a> (params)</td></tr>
<tr class="separator:a8b840bb9a5d642e6f17337a4a029dad1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a14dc6088a692c88e64ec308b18735765" id="r_a14dc6088a692c88e64ec308b18735765"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a14dc6088a692c88e64ec308b18735765">test_scores_attribute_layout_elasticnet</a> ()</td></tr>
<tr class="separator:a14dc6088a692c88e64ec308b18735765"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a756d4c9ca5efcd4746ea0eb7185dcec1" id="r_a756d4c9ca5efcd4746ea0eb7185dcec1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a756d4c9ca5efcd4746ea0eb7185dcec1">test_multinomial_identifiability_on_iris</a> (fit_intercept)</td></tr>
<tr class="separator:a756d4c9ca5efcd4746ea0eb7185dcec1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7511e56636c41857f0f6aa045e30669a" id="r_a7511e56636c41857f0f6aa045e30669a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a7511e56636c41857f0f6aa045e30669a">test_sample_weight_not_modified</a> (multi_class, class_weight)</td></tr>
<tr class="separator:a7511e56636c41857f0f6aa045e30669a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afff9bb393cbbe9e0c772b9d8c7854cf0" id="r_afff9bb393cbbe9e0c772b9d8c7854cf0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#afff9bb393cbbe9e0c772b9d8c7854cf0">test_large_sparse_matrix</a> (solver)</td></tr>
<tr class="separator:afff9bb393cbbe9e0c772b9d8c7854cf0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a502cb4a4e691c3fa8c9c51561acb9ea5" id="r_a502cb4a4e691c3fa8c9c51561acb9ea5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a502cb4a4e691c3fa8c9c51561acb9ea5">test_single_feature_newton_cg</a> ()</td></tr>
<tr class="separator:a502cb4a4e691c3fa8c9c51561acb9ea5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1d7598ce60d0309c6a66ea640008312" id="r_ad1d7598ce60d0309c6a66ea640008312"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#ad1d7598ce60d0309c6a66ea640008312">test_warning_on_penalty_string_none</a> ()</td></tr>
<tr class="separator:ad1d7598ce60d0309c6a66ea640008312"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:aecc05e853f067e943a749c8bb105d03c" id="r_aecc05e853f067e943a749c8bb105d03c"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#aecc05e853f067e943a749c8bb105d03c">SOLVERS</a> = (&quot;lbfgs&quot;, &quot;liblinear&quot;, &quot;newton-cg&quot;, &quot;newton-cholesky&quot;, &quot;sag&quot;, &quot;saga&quot;)</td></tr>
<tr class="separator:aecc05e853f067e943a749c8bb105d03c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a02178a87ba834f43ed4ebfe8602531" id="r_a9a02178a87ba834f43ed4ebfe8602531"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a9a02178a87ba834f43ed4ebfe8602531">X</a> = [[-1, 0], [0, 1], [1, 1]]</td></tr>
<tr class="separator:a9a02178a87ba834f43ed4ebfe8602531"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65302dd7f421789a3dc92a1c9ae4602a" id="r_a65302dd7f421789a3dc92a1c9ae4602a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a65302dd7f421789a3dc92a1c9ae4602a">X_sp</a> = sparse.csr_matrix(<a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a9a02178a87ba834f43ed4ebfe8602531">X</a>)</td></tr>
<tr class="separator:a65302dd7f421789a3dc92a1c9ae4602a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92b78d569f60954ed46e4847b484ea2c" id="r_a92b78d569f60954ed46e4847b484ea2c"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a92b78d569f60954ed46e4847b484ea2c">Y1</a> = [0, 1, 1]</td></tr>
<tr class="separator:a92b78d569f60954ed46e4847b484ea2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c50da982cb716f89bf541419ae1edd4" id="r_a6c50da982cb716f89bf541419ae1edd4"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a6c50da982cb716f89bf541419ae1edd4">Y2</a> = [2, 1, 0]</td></tr>
<tr class="separator:a6c50da982cb716f89bf541419ae1edd4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a511627da0a262cf43715760f02156b95" id="r_a511627da0a262cf43715760f02156b95"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a511627da0a262cf43715760f02156b95">iris</a> = load_iris()</td></tr>
<tr class="separator:a511627da0a262cf43715760f02156b95"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f2d9486092d28e97f280c0cdbf10840" id="r_a8f2d9486092d28e97f280c0cdbf10840"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a8f2d9486092d28e97f280c0cdbf10840">calls</a></td></tr>
<tr class="separator:a8f2d9486092d28e97f280c0cdbf10840"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2187c4003e0f93a1628e49b7d1364df4" id="r_a2187c4003e0f93a1628e49b7d1364df4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a2187c4003e0f93a1628e49b7d1364df4">scores</a></td></tr>
<tr class="separator:a2187c4003e0f93a1628e49b7d1364df4"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="af28a6758b40ad94d881380bcd8784dea" name="af28a6758b40ad94d881380bcd8784dea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af28a6758b40ad94d881380bcd8784dea">&#9670;&#160;</a></span>_compute_class_weight_dictionary()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic._compute_class_weight_dictionary </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  800</span><span class="keyword">def </span>_compute_class_weight_dictionary(y):</div>
<div class="line"><span class="lineno">  801</span>    <span class="comment"># helper for returning a dictionary instead of an array</span></div>
<div class="line"><span class="lineno">  802</span>    classes = np.unique(y)</div>
<div class="line"><span class="lineno">  803</span>    class_weight = compute_class_weight(<span class="stringliteral">&quot;balanced&quot;</span>, classes=classes, y=y)</div>
<div class="line"><span class="lineno">  804</span>    class_weight_dict = dict(zip(classes, class_weight))</div>
<div class="line"><span class="lineno">  805</span>    <span class="keywordflow">return</span> class_weight_dict</div>
<div class="line"><span class="lineno">  806</span> </div>
<div class="line"><span class="lineno">  807</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7288a8c6e9a8ca0438aae10fcd10ca00" name="a7288a8c6e9a8ca0438aae10fcd10ca00"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7288a8c6e9a8ca0438aae10fcd10ca00">&#9670;&#160;</a></span>check_predictions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.check_predictions </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that the model is able to fit the classification data</pre> <div class="fragment"><div class="line"><span class="lineno">   44</span><span class="keyword">def </span>check_predictions(clf, X, y):</div>
<div class="line"><span class="lineno">   45</span>    <span class="stringliteral">&quot;&quot;&quot;Check that the model is able to fit the classification data&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   46</span>    n_samples = len(y)</div>
<div class="line"><span class="lineno">   47</span>    classes = np.unique(y)</div>
<div class="line"><span class="lineno">   48</span>    n_classes = classes.shape[0]</div>
<div class="line"><span class="lineno">   49</span> </div>
<div class="line"><span class="lineno">   50</span>    predicted = clf.fit(X, y).predict(X)</div>
<div class="line"><span class="lineno">   51</span>    assert_array_equal(clf.classes_, classes)</div>
<div class="line"><span class="lineno">   52</span> </div>
<div class="line"><span class="lineno">   53</span>    <span class="keyword">assert</span> predicted.shape == (n_samples,)</div>
<div class="line"><span class="lineno">   54</span>    assert_array_equal(predicted, y)</div>
<div class="line"><span class="lineno">   55</span> </div>
<div class="line"><span class="lineno">   56</span>    probabilities = clf.predict_proba(X)</div>
<div class="line"><span class="lineno">   57</span>    <span class="keyword">assert</span> probabilities.shape == (n_samples, n_classes)</div>
<div class="line"><span class="lineno">   58</span>    assert_array_almost_equal(probabilities.sum(axis=1), np.ones(n_samples))</div>
<div class="line"><span class="lineno">   59</span>    assert_array_equal(probabilities.argmax(axis=1), y)</div>
<div class="line"><span class="lineno">   60</span> </div>
<div class="line"><span class="lineno">   61</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae119619aab389ee7f4af0972d79ca7f2" name="ae119619aab389ee7f4af0972d79ca7f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae119619aab389ee7f4af0972d79ca7f2">&#9670;&#160;</a></span>test_check_solver_option()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_check_solver_option </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>LR</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  179</span><span class="keyword">def </span>test_check_solver_option(LR):</div>
<div class="line"><span class="lineno">  180</span>    X, y = iris.data, iris.target</div>
<div class="line"><span class="lineno">  181</span> </div>
<div class="line"><span class="lineno">  182</span>    <span class="comment"># only &#39;liblinear&#39; and &#39;newton-cholesky&#39; solver</span></div>
<div class="line"><span class="lineno">  183</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>]:</div>
<div class="line"><span class="lineno">  184</span>        msg = f<span class="stringliteral">&quot;Solver {solver} does not support a multinomial backend.&quot;</span></div>
<div class="line"><span class="lineno">  185</span>        lr = LR(solver=solver, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>)</div>
<div class="line"><span class="lineno">  186</span>        <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  187</span>            lr.fit(X, y)</div>
<div class="line"><span class="lineno">  188</span> </div>
<div class="line"><span class="lineno">  189</span>    <span class="comment"># all solvers except &#39;liblinear&#39; and &#39;saga&#39;</span></div>
<div class="line"><span class="lineno">  190</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>, <span class="stringliteral">&quot;sag&quot;</span>]:</div>
<div class="line"><span class="lineno">  191</span>        msg = <span class="stringliteral">&quot;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties,&quot;</span> % solver</div>
<div class="line"><span class="lineno">  192</span>        lr = LR(solver=solver, penalty=<span class="stringliteral">&quot;l1&quot;</span>, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>)</div>
<div class="line"><span class="lineno">  193</span>        <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  194</span>            lr.fit(X, y)</div>
<div class="line"><span class="lineno">  195</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>, <span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]:</div>
<div class="line"><span class="lineno">  196</span>        msg = <span class="stringliteral">&quot;Solver %s supports only dual=False, got dual=True&quot;</span> % solver</div>
<div class="line"><span class="lineno">  197</span>        lr = LR(solver=solver, dual=<span class="keyword">True</span>, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>)</div>
<div class="line"><span class="lineno">  198</span>        <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  199</span>            lr.fit(X, y)</div>
<div class="line"><span class="lineno">  200</span> </div>
<div class="line"><span class="lineno">  201</span>    <span class="comment"># only saga supports elasticnet. We only test for liblinear because the</span></div>
<div class="line"><span class="lineno">  202</span>    <span class="comment"># error is raised before for the other solvers (solver %s supports only l2</span></div>
<div class="line"><span class="lineno">  203</span>    <span class="comment"># penalties)</span></div>
<div class="line"><span class="lineno">  204</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;liblinear&quot;</span>]:</div>
<div class="line"><span class="lineno">  205</span>        msg = <span class="stringliteral">&quot;Only &#39;saga&#39; solver supports elasticnet penalty, got solver={}.&quot;</span>.format(</div>
<div class="line"><span class="lineno">  206</span>            solver</div>
<div class="line"><span class="lineno">  207</span>        )</div>
<div class="line"><span class="lineno">  208</span>        lr = LR(solver=solver, penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>)</div>
<div class="line"><span class="lineno">  209</span>        <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  210</span>            lr.fit(X, y)</div>
<div class="line"><span class="lineno">  211</span> </div>
<div class="line"><span class="lineno">  212</span>    <span class="comment"># liblinear does not support penalty=&#39;none&#39;</span></div>
<div class="line"><span class="lineno">  213</span>    <span class="comment"># (LogisticRegressionCV does not supports penalty=&#39;none&#39; at all)</span></div>
<div class="line"><span class="lineno">  214</span>    <span class="keywordflow">if</span> LR <span class="keywordflow">is</span> LogisticRegression:</div>
<div class="line"><span class="lineno">  215</span>        msg = <span class="stringliteral">&quot;penalty=&#39;none&#39; is not supported for the liblinear solver&quot;</span></div>
<div class="line"><span class="lineno">  216</span>        lr = LR(penalty=<span class="stringliteral">&quot;none&quot;</span>, solver=<span class="stringliteral">&quot;liblinear&quot;</span>)</div>
<div class="line"><span class="lineno">  217</span>        <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  218</span>            lr.fit(X, y)</div>
<div class="line"><span class="lineno">  219</span> </div>
<div class="line"><span class="lineno">  220</span> </div>
<div class="line"><span class="lineno">  221</span><span class="preprocessor">@pytest.mark.parametrize(&quot;solver&quot;, [&quot;lbfgs&quot;, &quot;newton-cg&quot;, &quot;sag&quot;, &quot;saga&quot;])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab8d30ff56102f3ae39c64492c0a354cb" name="ab8d30ff56102f3ae39c64492c0a354cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab8d30ff56102f3ae39c64492c0a354cb">&#9670;&#160;</a></span>test_consistency_path()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_consistency_path </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  323</span><span class="keyword">def </span>test_consistency_path():</div>
<div class="line"><span class="lineno">  324</span>    <span class="comment"># Test that the path algorithm is consistent</span></div>
<div class="line"><span class="lineno">  325</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  326</span>    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))</div>
<div class="line"><span class="lineno">  327</span>    y = [1] * 100 + [-1] * 100</div>
<div class="line"><span class="lineno">  328</span>    Cs = np.logspace(0, 4, 10)</div>
<div class="line"><span class="lineno">  329</span> </div>
<div class="line"><span class="lineno">  330</span>    f = ignore_warnings</div>
<div class="line"><span class="lineno">  331</span>    <span class="comment"># can&#39;t test with fit_intercept=True since LIBLINEAR</span></div>
<div class="line"><span class="lineno">  332</span>    <span class="comment"># penalizes the intercept</span></div>
<div class="line"><span class="lineno">  333</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]:</div>
<div class="line"><span class="lineno">  334</span>        coefs, Cs, _ = <a class="code hl_variable" href="__lapack__subroutines_8h.html#af01a903df7bdb7a494f5827e45bf3a2a">f</a>(_logistic_regression_path)(</div>
<div class="line"><span class="lineno">  335</span>            X,</div>
<div class="line"><span class="lineno">  336</span>            y,</div>
<div class="line"><span class="lineno">  337</span>            Cs=Cs,</div>
<div class="line"><span class="lineno">  338</span>            fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  339</span>            tol=1e-5,</div>
<div class="line"><span class="lineno">  340</span>            solver=solver,</div>
<div class="line"><span class="lineno">  341</span>            max_iter=1000,</div>
<div class="line"><span class="lineno">  342</span>            multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  343</span>            random_state=0,</div>
<div class="line"><span class="lineno">  344</span>        )</div>
<div class="line"><span class="lineno">  345</span>        <span class="keywordflow">for</span> i, C <span class="keywordflow">in</span> enumerate(Cs):</div>
<div class="line"><span class="lineno">  346</span>            lr = LogisticRegression(</div>
<div class="line"><span class="lineno">  347</span>                C=C,</div>
<div class="line"><span class="lineno">  348</span>                fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  349</span>                tol=1e-5,</div>
<div class="line"><span class="lineno">  350</span>                solver=solver,</div>
<div class="line"><span class="lineno">  351</span>                multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  352</span>                random_state=0,</div>
<div class="line"><span class="lineno">  353</span>                max_iter=1000,</div>
<div class="line"><span class="lineno">  354</span>            )</div>
<div class="line"><span class="lineno">  355</span>            lr.fit(X, y)</div>
<div class="line"><span class="lineno">  356</span>            lr_coef = lr.coef_.ravel()</div>
<div class="line"><span class="lineno">  357</span>            assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  358</span>                lr_coef, coefs[i], decimal=4, err_msg=<span class="stringliteral">&quot;with solver = %s&quot;</span> % solver</div>
<div class="line"><span class="lineno">  359</span>            )</div>
<div class="line"><span class="lineno">  360</span> </div>
<div class="line"><span class="lineno">  361</span>    <span class="comment"># test for fit_intercept=True</span></div>
<div class="line"><span class="lineno">  362</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> (<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>, <span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>):</div>
<div class="line"><span class="lineno">  363</span>        Cs = [1e3]</div>
<div class="line"><span class="lineno">  364</span>        coefs, Cs, _ = <a class="code hl_variable" href="__lapack__subroutines_8h.html#af01a903df7bdb7a494f5827e45bf3a2a">f</a>(_logistic_regression_path)(</div>
<div class="line"><span class="lineno">  365</span>            X,</div>
<div class="line"><span class="lineno">  366</span>            y,</div>
<div class="line"><span class="lineno">  367</span>            Cs=Cs,</div>
<div class="line"><span class="lineno">  368</span>            tol=1e-6,</div>
<div class="line"><span class="lineno">  369</span>            solver=solver,</div>
<div class="line"><span class="lineno">  370</span>            intercept_scaling=10000.0,</div>
<div class="line"><span class="lineno">  371</span>            random_state=0,</div>
<div class="line"><span class="lineno">  372</span>            multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  373</span>        )</div>
<div class="line"><span class="lineno">  374</span>        lr = LogisticRegression(</div>
<div class="line"><span class="lineno">  375</span>            C=Cs[0],</div>
<div class="line"><span class="lineno">  376</span>            tol=1e-6,</div>
<div class="line"><span class="lineno">  377</span>            intercept_scaling=10000.0,</div>
<div class="line"><span class="lineno">  378</span>            random_state=0,</div>
<div class="line"><span class="lineno">  379</span>            multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  380</span>            solver=solver,</div>
<div class="line"><span class="lineno">  381</span>        )</div>
<div class="line"><span class="lineno">  382</span>        lr.fit(X, y)</div>
<div class="line"><span class="lineno">  383</span>        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])</div>
<div class="line"><span class="lineno">  384</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  385</span>            lr_coef, coefs[0], decimal=4, err_msg=<span class="stringliteral">&quot;with solver = %s&quot;</span> % solver</div>
<div class="line"><span class="lineno">  386</span>        )</div>
<div class="line"><span class="lineno">  387</span> </div>
<div class="line"><span class="lineno">  388</span> </div>
<div class="ttc" id="a__lapack__subroutines_8h_html_af01a903df7bdb7a494f5827e45bf3a2a"><div class="ttname"><a href="__lapack__subroutines_8h.html#af01a903df7bdb7a494f5827e45bf3a2a">f</a></div><div class="ttdeci">void int int int int npy_complex64 int int npy_complex64 float float npy_complex64 npy_complex64 * f</div><div class="ttdef"><b>Definition</b> _lapack_subroutines.h:262</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="ad2913fdd756327282ba43cb430fef515" name="ad2913fdd756327282ba43cb430fef515"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad2913fdd756327282ba43cb430fef515">&#9670;&#160;</a></span>test_dtype_match()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_dtype_match </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1264</span><span class="keyword">def </span>test_dtype_match(solver, multi_class, fit_intercept):</div>
<div class="line"><span class="lineno"> 1265</span>    <span class="comment"># Test that np.float32 input data is not cast to np.float64 when possible</span></div>
<div class="line"><span class="lineno"> 1266</span>    <span class="comment"># and that the output is approximately the same no matter the input format.</span></div>
<div class="line"><span class="lineno"> 1267</span> </div>
<div class="line"><span class="lineno"> 1268</span>    <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> (<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>) <span class="keywordflow">and</span> multi_class == <span class="stringliteral">&quot;multinomial&quot;</span>:</div>
<div class="line"><span class="lineno"> 1269</span>        pytest.skip(f<span class="stringliteral">&quot;Solver={solver} does not support multinomial logistic.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1270</span> </div>
<div class="line"><span class="lineno"> 1271</span>    out32_type = np.float64 <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;liblinear&quot;</span> <span class="keywordflow">else</span> np.float32</div>
<div class="line"><span class="lineno"> 1272</span> </div>
<div class="line"><span class="lineno"> 1273</span>    X_32 = np.array(X).astype(np.float32)</div>
<div class="line"><span class="lineno"> 1274</span>    y_32 = np.array(Y1).astype(np.float32)</div>
<div class="line"><span class="lineno"> 1275</span>    X_64 = np.array(X).astype(np.float64)</div>
<div class="line"><span class="lineno"> 1276</span>    y_64 = np.array(Y1).astype(np.float64)</div>
<div class="line"><span class="lineno"> 1277</span>    X_sparse_32 = sparse.csr_matrix(X, dtype=np.float32)</div>
<div class="line"><span class="lineno"> 1278</span>    X_sparse_64 = sparse.csr_matrix(X, dtype=np.float64)</div>
<div class="line"><span class="lineno"> 1279</span>    solver_tol = 5e-4</div>
<div class="line"><span class="lineno"> 1280</span> </div>
<div class="line"><span class="lineno"> 1281</span>    lr_templ = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1282</span>        solver=solver,</div>
<div class="line"><span class="lineno"> 1283</span>        multi_class=multi_class,</div>
<div class="line"><span class="lineno"> 1284</span>        random_state=42,</div>
<div class="line"><span class="lineno"> 1285</span>        tol=solver_tol,</div>
<div class="line"><span class="lineno"> 1286</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno"> 1287</span>    )</div>
<div class="line"><span class="lineno"> 1288</span> </div>
<div class="line"><span class="lineno"> 1289</span>    <span class="comment"># Check 32-bit type consistency</span></div>
<div class="line"><span class="lineno"> 1290</span>    lr_32 = clone(lr_templ)</div>
<div class="line"><span class="lineno"> 1291</span>    lr_32.fit(X_32, y_32)</div>
<div class="line"><span class="lineno"> 1292</span>    <span class="keyword">assert</span> lr_32.coef_.dtype == out32_type</div>
<div class="line"><span class="lineno"> 1293</span> </div>
<div class="line"><span class="lineno"> 1294</span>    <span class="comment"># Check 32-bit type consistency with sparsity</span></div>
<div class="line"><span class="lineno"> 1295</span>    lr_32_sparse = clone(lr_templ)</div>
<div class="line"><span class="lineno"> 1296</span>    lr_32_sparse.fit(X_sparse_32, y_32)</div>
<div class="line"><span class="lineno"> 1297</span>    <span class="keyword">assert</span> lr_32_sparse.coef_.dtype == out32_type</div>
<div class="line"><span class="lineno"> 1298</span> </div>
<div class="line"><span class="lineno"> 1299</span>    <span class="comment"># Check 64-bit type consistency</span></div>
<div class="line"><span class="lineno"> 1300</span>    lr_64 = clone(lr_templ)</div>
<div class="line"><span class="lineno"> 1301</span>    lr_64.fit(X_64, y_64)</div>
<div class="line"><span class="lineno"> 1302</span>    <span class="keyword">assert</span> lr_64.coef_.dtype == np.float64</div>
<div class="line"><span class="lineno"> 1303</span> </div>
<div class="line"><span class="lineno"> 1304</span>    <span class="comment"># Check 64-bit type consistency with sparsity</span></div>
<div class="line"><span class="lineno"> 1305</span>    lr_64_sparse = clone(lr_templ)</div>
<div class="line"><span class="lineno"> 1306</span>    lr_64_sparse.fit(X_sparse_64, y_64)</div>
<div class="line"><span class="lineno"> 1307</span>    <span class="keyword">assert</span> lr_64_sparse.coef_.dtype == np.float64</div>
<div class="line"><span class="lineno"> 1308</span> </div>
<div class="line"><span class="lineno"> 1309</span>    <span class="comment"># solver_tol bounds the norm of the loss gradient</span></div>
<div class="line"><span class="lineno"> 1310</span>    <span class="comment"># dw ~= inv(H)*grad ==&gt; |dw| ~= |inv(H)| * solver_tol, where H - hessian</span></div>
<div class="line"><span class="lineno"> 1311</span>    <span class="comment">#</span></div>
<div class="line"><span class="lineno"> 1312</span>    <span class="comment"># See https://github.com/scikit-learn/scikit-learn/pull/13645</span></div>
<div class="line"><span class="lineno"> 1313</span>    <span class="comment">#</span></div>
<div class="line"><span class="lineno"> 1314</span>    <span class="comment"># with  Z = np.hstack((np.ones((3,1)), np.array(X)))</span></div>
<div class="line"><span class="lineno"> 1315</span>    <span class="comment"># In [8]: np.linalg.norm(np.diag([0,2,2]) + np.linalg.inv((Z.T @ Z)/4))</span></div>
<div class="line"><span class="lineno"> 1316</span>    <span class="comment"># Out[8]: 1.7193336918135917</span></div>
<div class="line"><span class="lineno"> 1317</span> </div>
<div class="line"><span class="lineno"> 1318</span>    <span class="comment"># factor of 2 to get the ball diameter</span></div>
<div class="line"><span class="lineno"> 1319</span>    atol = 2 * 1.72 * solver_tol</div>
<div class="line"><span class="lineno"> 1320</span>    <span class="keywordflow">if</span> os.name == <span class="stringliteral">&quot;nt&quot;</span> <span class="keywordflow">and</span> _IS_32BIT:</div>
<div class="line"><span class="lineno"> 1321</span>        <span class="comment"># FIXME</span></div>
<div class="line"><span class="lineno"> 1322</span>        atol = 1e-2</div>
<div class="line"><span class="lineno"> 1323</span> </div>
<div class="line"><span class="lineno"> 1324</span>    <span class="comment"># Check accuracy consistency</span></div>
<div class="line"><span class="lineno"> 1325</span>    assert_allclose(lr_32.coef_, lr_64.coef_.astype(np.float32), atol=atol)</div>
<div class="line"><span class="lineno"> 1326</span> </div>
<div class="line"><span class="lineno"> 1327</span>    <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;saga&quot;</span> <span class="keywordflow">and</span> fit_intercept:</div>
<div class="line"><span class="lineno"> 1328</span>        <span class="comment"># FIXME: SAGA on sparse data fits the intercept inaccurately with the</span></div>
<div class="line"><span class="lineno"> 1329</span>        <span class="comment"># default tol and max_iter parameters.</span></div>
<div class="line"><span class="lineno"> 1330</span>        atol = 1e-1</div>
<div class="line"><span class="lineno"> 1331</span> </div>
<div class="line"><span class="lineno"> 1332</span>    assert_allclose(lr_32.coef_, lr_32_sparse.coef_, atol=atol)</div>
<div class="line"><span class="lineno"> 1333</span>    assert_allclose(lr_64.coef_, lr_64_sparse.coef_, atol=atol)</div>
<div class="line"><span class="lineno"> 1334</span> </div>
<div class="line"><span class="lineno"> 1335</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a153a90b7e513f2256eb1d9d32198c76f" name="a153a90b7e513f2256eb1d9d32198c76f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a153a90b7e513f2256eb1d9d32198c76f">&#9670;&#160;</a></span>test_elastic_net_coeffs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_elastic_net_coeffs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1357</span><span class="keyword">def </span>test_elastic_net_coeffs():</div>
<div class="line"><span class="lineno"> 1358</span>    <span class="comment"># make sure elasticnet penalty gives different coefficients from l1 and l2</span></div>
<div class="line"><span class="lineno"> 1359</span>    <span class="comment"># with saga solver (l1_ratio different from 0 or 1)</span></div>
<div class="line"><span class="lineno"> 1360</span>    X, y = make_classification(random_state=0)</div>
<div class="line"><span class="lineno"> 1361</span> </div>
<div class="line"><span class="lineno"> 1362</span>    C = 2.0</div>
<div class="line"><span class="lineno"> 1363</span>    l1_ratio = 0.5</div>
<div class="line"><span class="lineno"> 1364</span>    coeffs = list()</div>
<div class="line"><span class="lineno"> 1365</span>    <span class="keywordflow">for</span> penalty <span class="keywordflow">in</span> (<span class="stringliteral">&quot;elasticnet&quot;</span>, <span class="stringliteral">&quot;l1&quot;</span>, <span class="stringliteral">&quot;l2&quot;</span>):</div>
<div class="line"><span class="lineno"> 1366</span>        lr = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1367</span>            penalty=penalty, C=C, solver=<span class="stringliteral">&quot;saga&quot;</span>, random_state=0, l1_ratio=l1_ratio</div>
<div class="line"><span class="lineno"> 1368</span>        )</div>
<div class="line"><span class="lineno"> 1369</span>        lr.fit(X, y)</div>
<div class="line"><span class="lineno"> 1370</span>        coeffs.append(lr.coef_)</div>
<div class="line"><span class="lineno"> 1371</span> </div>
<div class="line"><span class="lineno"> 1372</span>    elastic_net_coeffs, l1_coeffs, l2_coeffs = coeffs</div>
<div class="line"><span class="lineno"> 1373</span>    <span class="comment"># make sure coeffs differ by at least .1</span></div>
<div class="line"><span class="lineno"> 1374</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> np.allclose(elastic_net_coeffs, l1_coeffs, rtol=0, atol=0.1)</div>
<div class="line"><span class="lineno"> 1375</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> np.allclose(elastic_net_coeffs, l2_coeffs, rtol=0, atol=0.1)</div>
<div class="line"><span class="lineno"> 1376</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> np.allclose(l2_coeffs, l1_coeffs, rtol=0, atol=0.1)</div>
<div class="line"><span class="lineno"> 1377</span> </div>
<div class="line"><span class="lineno"> 1378</span> </div>
<div class="line"><span class="lineno"> 1379</span><span class="preprocessor">@pytest.mark.parametrize(&quot;C&quot;, [0.001, 0.1, 1, 10, 100, 1000, 1e6])</span></div>
<div class="line"><span class="lineno"> 1380</span><span class="preprocessor">@pytest.mark.parametrize(&quot;penalty, l1_ratio&quot;, [(&quot;l1&quot;, 1)</span>, (<span class="stringliteral">&quot;l2&quot;</span>, 0)])</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae299aebe2167cd0efc1d02468c2d4efa" name="ae299aebe2167cd0efc1d02468c2d4efa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae299aebe2167cd0efc1d02468c2d4efa">&#9670;&#160;</a></span>test_elastic_net_l1_l2_equivalence()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_elastic_net_l1_l2_equivalence </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>penalty</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>l1_ratio</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1381</span><span class="keyword">def </span>test_elastic_net_l1_l2_equivalence(C, penalty, l1_ratio):</div>
<div class="line"><span class="lineno"> 1382</span>    <span class="comment"># Make sure elasticnet is equivalent to l1 when l1_ratio=1 and to l2 when</span></div>
<div class="line"><span class="lineno"> 1383</span>    <span class="comment"># l1_ratio=0.</span></div>
<div class="line"><span class="lineno"> 1384</span>    X, y = make_classification(random_state=0)</div>
<div class="line"><span class="lineno"> 1385</span> </div>
<div class="line"><span class="lineno"> 1386</span>    lr_enet = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1387</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>, C=C, l1_ratio=l1_ratio, solver=<span class="stringliteral">&quot;saga&quot;</span>, random_state=0</div>
<div class="line"><span class="lineno"> 1388</span>    )</div>
<div class="line"><span class="lineno"> 1389</span>    lr_expected = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1390</span>        penalty=penalty, C=C, solver=<span class="stringliteral">&quot;saga&quot;</span>, random_state=0</div>
<div class="line"><span class="lineno"> 1391</span>    )</div>
<div class="line"><span class="lineno"> 1392</span>    lr_enet.fit(X, y)</div>
<div class="line"><span class="lineno"> 1393</span>    lr_expected.fit(X, y)</div>
<div class="line"><span class="lineno"> 1394</span> </div>
<div class="line"><span class="lineno"> 1395</span>    assert_array_almost_equal(lr_enet.coef_, lr_expected.coef_)</div>
<div class="line"><span class="lineno"> 1396</span> </div>
<div class="line"><span class="lineno"> 1397</span> </div>
<div class="line"><span class="lineno"> 1398</span><span class="preprocessor">@pytest.mark.parametrize(&quot;C&quot;, [0.001, 1, 100, 1e6])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a6f3a510aa5aef9e6511cc4753f9cfcff" name="a6f3a510aa5aef9e6511cc4753f9cfcff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6f3a510aa5aef9e6511cc4753f9cfcff">&#9670;&#160;</a></span>test_elastic_net_versus_sgd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_elastic_net_versus_sgd </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>l1_ratio</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1636</span><span class="keyword">def </span>test_elastic_net_versus_sgd(C, l1_ratio):</div>
<div class="line"><span class="lineno"> 1637</span>    <span class="comment"># Compare elasticnet penalty in LogisticRegression() and SGD(loss=&#39;log&#39;)</span></div>
<div class="line"><span class="lineno"> 1638</span>    n_samples = 500</div>
<div class="line"><span class="lineno"> 1639</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno"> 1640</span>        n_samples=n_samples,</div>
<div class="line"><span class="lineno"> 1641</span>        n_classes=2,</div>
<div class="line"><span class="lineno"> 1642</span>        n_features=5,</div>
<div class="line"><span class="lineno"> 1643</span>        n_informative=5,</div>
<div class="line"><span class="lineno"> 1644</span>        n_redundant=0,</div>
<div class="line"><span class="lineno"> 1645</span>        n_repeated=0,</div>
<div class="line"><span class="lineno"> 1646</span>        random_state=1,</div>
<div class="line"><span class="lineno"> 1647</span>    )</div>
<div class="line"><span class="lineno"> 1648</span>    X = scale(X)</div>
<div class="line"><span class="lineno"> 1649</span> </div>
<div class="line"><span class="lineno"> 1650</span>    sgd = SGDClassifier(</div>
<div class="line"><span class="lineno"> 1651</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>,</div>
<div class="line"><span class="lineno"> 1652</span>        random_state=1,</div>
<div class="line"><span class="lineno"> 1653</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno"> 1654</span>        tol=<span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1655</span>        max_iter=2000,</div>
<div class="line"><span class="lineno"> 1656</span>        l1_ratio=l1_ratio,</div>
<div class="line"><span class="lineno"> 1657</span>        alpha=1.0 / C / n_samples,</div>
<div class="line"><span class="lineno"> 1658</span>        loss=<span class="stringliteral">&quot;log_loss&quot;</span>,</div>
<div class="line"><span class="lineno"> 1659</span>    )</div>
<div class="line"><span class="lineno"> 1660</span>    log = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1661</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>,</div>
<div class="line"><span class="lineno"> 1662</span>        random_state=1,</div>
<div class="line"><span class="lineno"> 1663</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno"> 1664</span>        tol=1e-5,</div>
<div class="line"><span class="lineno"> 1665</span>        max_iter=1000,</div>
<div class="line"><span class="lineno"> 1666</span>        l1_ratio=l1_ratio,</div>
<div class="line"><span class="lineno"> 1667</span>        C=C,</div>
<div class="line"><span class="lineno"> 1668</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1669</span>    )</div>
<div class="line"><span class="lineno"> 1670</span> </div>
<div class="line"><span class="lineno"> 1671</span>    sgd.fit(X, y)</div>
<div class="line"><span class="lineno"> 1672</span>    log.fit(X, y)</div>
<div class="line"><span class="lineno"> 1673</span>    assert_array_almost_equal(sgd.coef_, log.coef_, decimal=1)</div>
<div class="line"><span class="lineno"> 1674</span> </div>
<div class="line"><span class="lineno"> 1675</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7af89da52d8cbc9d8ff4b070d4a85a92" name="a7af89da52d8cbc9d8ff4b070d4a85a92"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7af89da52d8cbc9d8ff4b070d4a85a92">&#9670;&#160;</a></span>test_elastic_net_vs_l1_l2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_elastic_net_vs_l1_l2 </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>C</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1399</span><span class="keyword">def </span>test_elastic_net_vs_l1_l2(C):</div>
<div class="line"><span class="lineno"> 1400</span>    <span class="comment"># Make sure that elasticnet with grid search on l1_ratio gives same or</span></div>
<div class="line"><span class="lineno"> 1401</span>    <span class="comment"># better results than just l1 or just l2.</span></div>
<div class="line"><span class="lineno"> 1402</span> </div>
<div class="line"><span class="lineno"> 1403</span>    X, y = make_classification(500, random_state=0)</div>
<div class="line"><span class="lineno"> 1404</span>    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)</div>
<div class="line"><span class="lineno"> 1405</span> </div>
<div class="line"><span class="lineno"> 1406</span>    param_grid = {<span class="stringliteral">&quot;l1_ratio&quot;</span>: np.linspace(0, 1, 5)}</div>
<div class="line"><span class="lineno"> 1407</span> </div>
<div class="line"><span class="lineno"> 1408</span>    enet_clf = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1409</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>, C=C, solver=<span class="stringliteral">&quot;saga&quot;</span>, random_state=0</div>
<div class="line"><span class="lineno"> 1410</span>    )</div>
<div class="line"><span class="lineno"> 1411</span>    gs = GridSearchCV(enet_clf, param_grid, refit=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1412</span> </div>
<div class="line"><span class="lineno"> 1413</span>    l1_clf = LogisticRegression(penalty=<span class="stringliteral">&quot;l1&quot;</span>, C=C, solver=<span class="stringliteral">&quot;saga&quot;</span>, random_state=0)</div>
<div class="line"><span class="lineno"> 1414</span>    l2_clf = LogisticRegression(penalty=<span class="stringliteral">&quot;l2&quot;</span>, C=C, solver=<span class="stringliteral">&quot;saga&quot;</span>, random_state=0)</div>
<div class="line"><span class="lineno"> 1415</span> </div>
<div class="line"><span class="lineno"> 1416</span>    <span class="keywordflow">for</span> clf <span class="keywordflow">in</span> (gs, l1_clf, l2_clf):</div>
<div class="line"><span class="lineno"> 1417</span>        clf.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1418</span> </div>
<div class="line"><span class="lineno"> 1419</span>    <span class="keyword">assert</span> gs.score(X_test, y_test) &gt;= l1_clf.score(X_test, y_test)</div>
<div class="line"><span class="lineno"> 1420</span>    <span class="keyword">assert</span> gs.score(X_test, y_test) &gt;= l2_clf.score(X_test, y_test)</div>
<div class="line"><span class="lineno"> 1421</span> </div>
<div class="line"><span class="lineno"> 1422</span> </div>
<div class="line"><span class="lineno"> 1423</span><span class="preprocessor">@pytest.mark.parametrize(&quot;C&quot;, np.logspace(-3, 2, 4)</span>)</div>
<div class="line"><span class="lineno"> 1424</span><span class="preprocessor">@pytest.mark.parametrize(&quot;l1_ratio&quot;, [0.1, 0.5, 0.9])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a1ad26fbf03f3898ff05da0646ffdb673" name="a1ad26fbf03f3898ff05da0646ffdb673"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1ad26fbf03f3898ff05da0646ffdb673">&#9670;&#160;</a></span>test_inconsistent_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_inconsistent_input </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  283</span><span class="keyword">def </span>test_inconsistent_input():</div>
<div class="line"><span class="lineno">  284</span>    <span class="comment"># Test that an exception is raised on inconsistent input</span></div>
<div class="line"><span class="lineno">  285</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  286</span>    X_ = rng.random_sample((5, 10))</div>
<div class="line"><span class="lineno">  287</span>    y_ = np.ones(X_.shape[0])</div>
<div class="line"><span class="lineno">  288</span>    y_[0] = 0</div>
<div class="line"><span class="lineno">  289</span> </div>
<div class="line"><span class="lineno">  290</span>    clf = LogisticRegression(random_state=0)</div>
<div class="line"><span class="lineno">  291</span> </div>
<div class="line"><span class="lineno">  292</span>    <span class="comment"># Wrong dimensions for training data</span></div>
<div class="line"><span class="lineno">  293</span>    y_wrong = y_[:-1]</div>
<div class="line"><span class="lineno">  294</span> </div>
<div class="line"><span class="lineno">  295</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  296</span>        clf.fit(X, y_wrong)</div>
<div class="line"><span class="lineno">  297</span> </div>
<div class="line"><span class="lineno">  298</span>    <span class="comment"># Wrong dimensions for test data</span></div>
<div class="line"><span class="lineno">  299</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  300</span>        clf.fit(X_, y_).predict(rng.random_sample((3, 12)))</div>
<div class="line"><span class="lineno">  301</span> </div>
<div class="line"><span class="lineno">  302</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a42da9373a489336822f8392044961e08" name="a42da9373a489336822f8392044961e08"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a42da9373a489336822f8392044961e08">&#9670;&#160;</a></span>test_l1_ratio_non_elasticnet()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_l1_ratio_non_elasticnet </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1625</span><span class="keyword">def </span>test_l1_ratio_non_elasticnet():</div>
<div class="line"><span class="lineno"> 1626</span>    msg = (</div>
<div class="line"><span class="lineno"> 1627</span>        <span class="stringliteral">r&quot;l1_ratio parameter is only used when penalty is&quot;</span></div>
<div class="line"><span class="lineno"> 1628</span>        <span class="stringliteral">r&quot; &#39;elasticnet&#39;\. Got \&zwj;(penalty=l1\&zwj;)&quot;</span></div>
<div class="line"><span class="lineno"> 1629</span>    )</div>
<div class="line"><span class="lineno"> 1630</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno"> 1631</span>        LogisticRegression(penalty=<span class="stringliteral">&quot;l1&quot;</span>, solver=<span class="stringliteral">&quot;saga&quot;</span>, l1_ratio=0.5).fit(X, Y1)</div>
<div class="line"><span class="lineno"> 1632</span> </div>
<div class="line"><span class="lineno"> 1633</span> </div>
<div class="line"><span class="lineno"> 1634</span><span class="preprocessor">@pytest.mark.parametrize(&quot;C&quot;, np.logspace(-3, 2, 4)</span>)</div>
<div class="line"><span class="lineno"> 1635</span><span class="preprocessor">@pytest.mark.parametrize(&quot;l1_ratio&quot;, [0.1, 0.5, 0.9])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="afff9bb393cbbe9e0c772b9d8c7854cf0" name="afff9bb393cbbe9e0c772b9d8c7854cf0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afff9bb393cbbe9e0c772b9d8c7854cf0">&#9670;&#160;</a></span>test_large_sparse_matrix()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_large_sparse_matrix </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1934</span><span class="keyword">def </span>test_large_sparse_matrix(solver):</div>
<div class="line"><span class="lineno"> 1935</span>    <span class="comment"># Solvers either accept large sparse matrices, or raise helpful error.</span></div>
<div class="line"><span class="lineno"> 1936</span>    <span class="comment"># Non-regression test for pull-request #21093.</span></div>
<div class="line"><span class="lineno"> 1937</span> </div>
<div class="line"><span class="lineno"> 1938</span>    <span class="comment"># generate sparse matrix with int64 indices</span></div>
<div class="line"><span class="lineno"> 1939</span>    X = sparse.rand(20, 10, format=<span class="stringliteral">&quot;csr&quot;</span>)</div>
<div class="line"><span class="lineno"> 1940</span>    <span class="keywordflow">for</span> attr <span class="keywordflow">in</span> [<span class="stringliteral">&quot;indices&quot;</span>, <span class="stringliteral">&quot;indptr&quot;</span>]:</div>
<div class="line"><span class="lineno"> 1941</span>        setattr(X, attr, getattr(X, attr).astype(<span class="stringliteral">&quot;int64&quot;</span>))</div>
<div class="line"><span class="lineno"> 1942</span>    y = np.random.randint(2, size=X.shape[0])</div>
<div class="line"><span class="lineno"> 1943</span> </div>
<div class="line"><span class="lineno"> 1944</span>    <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]:</div>
<div class="line"><span class="lineno"> 1945</span>        msg = <span class="stringliteral">&quot;Only sparse matrices with 32-bit integer indices&quot;</span></div>
<div class="line"><span class="lineno"> 1946</span>        <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno"> 1947</span>            LogisticRegression(solver=solver).fit(X, y)</div>
<div class="line"><span class="lineno"> 1948</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1949</span>        LogisticRegression(solver=solver).fit(X, y)</div>
<div class="line"><span class="lineno"> 1950</span> </div>
<div class="line"><span class="lineno"> 1951</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad457eab5d6957226046959b2ec3c91b3" name="ad457eab5d6957226046959b2ec3c91b3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad457eab5d6957226046959b2ec3c91b3">&#9670;&#160;</a></span>test_liblinear_decision_function_zero()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_liblinear_decision_function_zero </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  906</span><span class="keyword">def </span>test_liblinear_decision_function_zero():</div>
<div class="line"><span class="lineno">  907</span>    <span class="comment"># Test negative prediction when decision_function values are zero.</span></div>
<div class="line"><span class="lineno">  908</span>    <span class="comment"># Liblinear predicts the positive class when decision_function values</span></div>
<div class="line"><span class="lineno">  909</span>    <span class="comment"># are zero. This is a test to verify that we do not do the same.</span></div>
<div class="line"><span class="lineno">  910</span>    <span class="comment"># See Issue: https://github.com/scikit-learn/scikit-learn/issues/3600</span></div>
<div class="line"><span class="lineno">  911</span>    <span class="comment"># and the PR https://github.com/scikit-learn/scikit-learn/pull/3623</span></div>
<div class="line"><span class="lineno">  912</span>    X, y = make_classification(n_samples=5, n_features=5, random_state=0)</div>
<div class="line"><span class="lineno">  913</span>    clf = LogisticRegression(fit_intercept=<span class="keyword">False</span>, solver=<span class="stringliteral">&quot;liblinear&quot;</span>, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>)</div>
<div class="line"><span class="lineno">  914</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  915</span> </div>
<div class="line"><span class="lineno">  916</span>    <span class="comment"># Dummy data such that the decision function becomes zero.</span></div>
<div class="line"><span class="lineno">  917</span>    X = np.zeros((5, 5))</div>
<div class="line"><span class="lineno">  918</span>    assert_array_equal(clf.predict(X), np.zeros(5))</div>
<div class="line"><span class="lineno">  919</span> </div>
<div class="line"><span class="lineno">  920</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a148b1c5466ca3f96d15a39b7723491b0" name="a148b1c5466ca3f96d15a39b7723491b0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a148b1c5466ca3f96d15a39b7723491b0">&#9670;&#160;</a></span>test_liblinear_dual_random_state()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_liblinear_dual_random_state </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  411</span><span class="keyword">def </span>test_liblinear_dual_random_state():</div>
<div class="line"><span class="lineno">  412</span>    <span class="comment"># random_state is relevant for liblinear solver only if dual=True</span></div>
<div class="line"><span class="lineno">  413</span>    X, y = make_classification(n_samples=20, random_state=0)</div>
<div class="line"><span class="lineno">  414</span>    lr1 = LogisticRegression(</div>
<div class="line"><span class="lineno">  415</span>        random_state=0,</div>
<div class="line"><span class="lineno">  416</span>        dual=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  417</span>        max_iter=1,</div>
<div class="line"><span class="lineno">  418</span>        tol=1e-15,</div>
<div class="line"><span class="lineno">  419</span>        solver=<span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno">  420</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  421</span>    )</div>
<div class="line"><span class="lineno">  422</span>    lr1.fit(X, y)</div>
<div class="line"><span class="lineno">  423</span>    lr2 = LogisticRegression(</div>
<div class="line"><span class="lineno">  424</span>        random_state=0,</div>
<div class="line"><span class="lineno">  425</span>        dual=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  426</span>        max_iter=1,</div>
<div class="line"><span class="lineno">  427</span>        tol=1e-15,</div>
<div class="line"><span class="lineno">  428</span>        solver=<span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno">  429</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  430</span>    )</div>
<div class="line"><span class="lineno">  431</span>    lr2.fit(X, y)</div>
<div class="line"><span class="lineno">  432</span>    lr3 = LogisticRegression(</div>
<div class="line"><span class="lineno">  433</span>        random_state=8,</div>
<div class="line"><span class="lineno">  434</span>        dual=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  435</span>        max_iter=1,</div>
<div class="line"><span class="lineno">  436</span>        tol=1e-15,</div>
<div class="line"><span class="lineno">  437</span>        solver=<span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno">  438</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  439</span>    )</div>
<div class="line"><span class="lineno">  440</span>    lr3.fit(X, y)</div>
<div class="line"><span class="lineno">  441</span> </div>
<div class="line"><span class="lineno">  442</span>    <span class="comment"># same result for same random state</span></div>
<div class="line"><span class="lineno">  443</span>    assert_array_almost_equal(lr1.coef_, lr2.coef_)</div>
<div class="line"><span class="lineno">  444</span>    <span class="comment"># different results for different random states</span></div>
<div class="line"><span class="lineno">  445</span>    msg = <span class="stringliteral">&quot;Arrays are not almost equal to 6 decimals&quot;</span></div>
<div class="line"><span class="lineno">  446</span>    <span class="keyword">with</span> pytest.raises(AssertionError, match=msg):</div>
<div class="line"><span class="lineno">  447</span>        assert_array_almost_equal(lr1.coef_, lr3.coef_)</div>
<div class="line"><span class="lineno">  448</span> </div>
<div class="line"><span class="lineno">  449</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a49ddabb50cb8a42d2f7d1f6281252228" name="a49ddabb50cb8a42d2f7d1f6281252228"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a49ddabb50cb8a42d2f7d1f6281252228">&#9670;&#160;</a></span>test_liblinear_logregcv_sparse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_liblinear_logregcv_sparse </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  921</span><span class="keyword">def </span>test_liblinear_logregcv_sparse():</div>
<div class="line"><span class="lineno">  922</span>    <span class="comment"># Test LogRegCV with solver=&#39;liblinear&#39; works for sparse matrices</span></div>
<div class="line"><span class="lineno">  923</span> </div>
<div class="line"><span class="lineno">  924</span>    X, y = make_classification(n_samples=10, n_features=5, random_state=0)</div>
<div class="line"><span class="lineno">  925</span>    clf = LogisticRegressionCV(solver=<span class="stringliteral">&quot;liblinear&quot;</span>, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>)</div>
<div class="line"><span class="lineno">  926</span>    clf.fit(sparse.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  927</span> </div>
<div class="line"><span class="lineno">  928</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a23db0122ed0d78fff52329a068918fe5" name="a23db0122ed0d78fff52329a068918fe5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a23db0122ed0d78fff52329a068918fe5">&#9670;&#160;</a></span>test_logistic_cv()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_cv </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  450</span><span class="keyword">def </span>test_logistic_cv():</div>
<div class="line"><span class="lineno">  451</span>    <span class="comment"># test for LogisticRegressionCV object</span></div>
<div class="line"><span class="lineno">  452</span>    n_samples, n_features = 50, 5</div>
<div class="line"><span class="lineno">  453</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  454</span>    X_ref = rng.randn(n_samples, n_features)</div>
<div class="line"><span class="lineno">  455</span>    y = np.sign(X_ref.dot(5 * rng.randn(n_features)))</div>
<div class="line"><span class="lineno">  456</span>    X_ref -= X_ref.mean()</div>
<div class="line"><span class="lineno">  457</span>    X_ref /= X_ref.std()</div>
<div class="line"><span class="lineno">  458</span>    lr_cv = LogisticRegressionCV(</div>
<div class="line"><span class="lineno">  459</span>        Cs=[1.0], fit_intercept=<span class="keyword">False</span>, solver=<span class="stringliteral">&quot;liblinear&quot;</span>, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>, cv=3</div>
<div class="line"><span class="lineno">  460</span>    )</div>
<div class="line"><span class="lineno">  461</span>    lr_cv.fit(X_ref, y)</div>
<div class="line"><span class="lineno">  462</span>    lr = LogisticRegression(</div>
<div class="line"><span class="lineno">  463</span>        C=1.0, fit_intercept=<span class="keyword">False</span>, solver=<span class="stringliteral">&quot;liblinear&quot;</span>, multi_class=<span class="stringliteral">&quot;ovr&quot;</span></div>
<div class="line"><span class="lineno">  464</span>    )</div>
<div class="line"><span class="lineno">  465</span>    lr.fit(X_ref, y)</div>
<div class="line"><span class="lineno">  466</span>    assert_array_almost_equal(lr.coef_, lr_cv.coef_)</div>
<div class="line"><span class="lineno">  467</span> </div>
<div class="line"><span class="lineno">  468</span>    assert_array_equal(lr_cv.coef_.shape, (1, n_features))</div>
<div class="line"><span class="lineno">  469</span>    assert_array_equal(lr_cv.classes_, [-1, 1])</div>
<div class="line"><span class="lineno">  470</span>    <span class="keyword">assert</span> len(lr_cv.classes_) == 2</div>
<div class="line"><span class="lineno">  471</span> </div>
<div class="line"><span class="lineno">  472</span>    coefs_paths = np.asarray(list(lr_cv.coefs_paths_.values()))</div>
<div class="line"><span class="lineno">  473</span>    assert_array_equal(coefs_paths.shape, (1, 3, 1, n_features))</div>
<div class="line"><span class="lineno">  474</span>    assert_array_equal(lr_cv.Cs_.shape, (1,))</div>
<div class="line"><span class="lineno">  475</span>    scores = np.asarray(list(lr_cv.scores_.values()))</div>
<div class="line"><span class="lineno">  476</span>    assert_array_equal(scores.shape, (1, 3, 1))</div>
<div class="line"><span class="lineno">  477</span> </div>
<div class="line"><span class="lineno">  478</span> </div>
<div class="line"><span class="lineno">  479</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  480</span>    <span class="stringliteral">&quot;scoring, multiclass_agg_list&quot;</span>,</div>
<div class="line"><span class="lineno">  481</span>    [</div>
<div class="line"><span class="lineno">  482</span>        (<span class="stringliteral">&quot;accuracy&quot;</span>, [<span class="stringliteral">&quot;&quot;</span>]),</div>
<div class="line"><span class="lineno">  483</span>        (<span class="stringliteral">&quot;precision&quot;</span>, [<span class="stringliteral">&quot;_macro&quot;</span>, <span class="stringliteral">&quot;_weighted&quot;</span>]),</div>
<div class="line"><span class="lineno">  484</span>        <span class="comment"># no need to test for micro averaging because it</span></div>
<div class="line"><span class="lineno">  485</span>        <span class="comment"># is the same as accuracy for f1, precision,</span></div>
<div class="line"><span class="lineno">  486</span>        <span class="comment"># and recall (see https://github.com/</span></div>
<div class="line"><span class="lineno">  487</span>        <span class="comment"># scikit-learn/scikit-learn/pull/</span></div>
<div class="line"><span class="lineno">  488</span>        <span class="comment"># 11578#discussion_r203250062)</span></div>
<div class="line"><span class="lineno">  489</span>        (<span class="stringliteral">&quot;f1&quot;</span>, [<span class="stringliteral">&quot;_macro&quot;</span>, <span class="stringliteral">&quot;_weighted&quot;</span>]),</div>
<div class="line"><span class="lineno">  490</span>        (<span class="stringliteral">&quot;neg_log_loss&quot;</span>, [<span class="stringliteral">&quot;&quot;</span>]),</div>
<div class="line"><span class="lineno">  491</span>        (<span class="stringliteral">&quot;recall&quot;</span>, [<span class="stringliteral">&quot;_macro&quot;</span>, <span class="stringliteral">&quot;_weighted&quot;</span>]),</div>
<div class="line"><span class="lineno">  492</span>    ],</div>
<div class="line"><span class="lineno">  493</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a3067917cdf019b056a921769cca5ba51" name="a3067917cdf019b056a921769cca5ba51"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3067917cdf019b056a921769cca5ba51">&#9670;&#160;</a></span>test_logistic_cv_mock_scorer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_cv_mock_scorer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   75</span><span class="keyword">def </span>test_logistic_cv_mock_scorer():</div>
<div class="line"><span class="lineno">   76</span>    <span class="keyword">class </span>MockScorer:</div>
<div class="line"><span class="lineno">   77</span>        <span class="keyword">def </span>__init__(self):</div>
<div class="line"><span class="lineno">   78</span>            self.calls = 0</div>
<div class="line"><span class="lineno">   79</span>            self.scores = [0.1, 0.4, 0.8, 0.5]</div>
<div class="line"><span class="lineno">   80</span> </div>
<div class="line"><span class="lineno">   81</span>        <span class="keyword">def </span>__call__(self, model, X, y, sample_weight=None):</div>
<div class="line"><span class="lineno">   82</span>            score = self.scores[self.calls % len(self.scores)]</div>
<div class="line"><span class="lineno">   83</span>            self.calls += 1</div>
<div class="line"><span class="lineno">   84</span>            <span class="keywordflow">return</span> score</div>
<div class="line"><span class="lineno">   85</span> </div>
<div class="line"><span class="lineno">   86</span>    mock_scorer = MockScorer()</div>
<div class="line"><span class="lineno">   87</span>    Cs = [1, 2, 3, 4]</div>
<div class="line"><span class="lineno">   88</span>    cv = 2</div>
<div class="line"><span class="lineno">   89</span> </div>
<div class="line"><span class="lineno">   90</span>    lr = LogisticRegressionCV(Cs=Cs, scoring=mock_scorer, cv=cv)</div>
<div class="line"><span class="lineno">   91</span>    lr.fit(X, Y1)</div>
<div class="line"><span class="lineno">   92</span> </div>
<div class="line"><span class="lineno">   93</span>    <span class="comment"># Cs[2] has the highest score (0.8) from MockScorer</span></div>
<div class="line"><span class="lineno">   94</span>    <span class="keyword">assert</span> lr.C_[0] == Cs[2]</div>
<div class="line"><span class="lineno">   95</span> </div>
<div class="line"><span class="lineno">   96</span>    <span class="comment"># scorer called 8 times (cv*len(Cs))</span></div>
<div class="line"><span class="lineno">   97</span>    <span class="keyword">assert</span> mock_scorer.calls == cv * len(Cs)</div>
<div class="line"><span class="lineno">   98</span> </div>
<div class="line"><span class="lineno">   99</span>    <span class="comment"># reset mock_scorer</span></div>
<div class="line"><span class="lineno">  100</span>    mock_scorer.calls = 0</div>
<div class="line"><span class="lineno">  101</span>    custom_score = lr.score(X, lr.predict(X))</div>
<div class="line"><span class="lineno">  102</span> </div>
<div class="line"><span class="lineno">  103</span>    <span class="keyword">assert</span> custom_score == mock_scorer.scores[0]</div>
<div class="line"><span class="lineno">  104</span>    <span class="keyword">assert</span> mock_scorer.calls == 1</div>
<div class="line"><span class="lineno">  105</span> </div>
<div class="line"><span class="lineno">  106</span> </div>
<div class="line"><span class="lineno">  107</span><span class="preprocessor">@skip_if_no_parallel</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a08cdc4b88073e8973f2bd37e8484973f" name="a08cdc4b88073e8973f2bd37e8484973f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a08cdc4b88073e8973f2bd37e8484973f">&#9670;&#160;</a></span>test_logistic_cv_multinomial_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_cv_multinomial_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>scoring</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multiclass_agg_list</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  494</span><span class="keyword">def </span>test_logistic_cv_multinomial_score(scoring, multiclass_agg_list):</div>
<div class="line"><span class="lineno">  495</span>    <span class="comment"># test that LogisticRegressionCV uses the right score to compute its</span></div>
<div class="line"><span class="lineno">  496</span>    <span class="comment"># cross-validation scores when using a multinomial scoring</span></div>
<div class="line"><span class="lineno">  497</span>    <span class="comment"># see https://github.com/scikit-learn/scikit-learn/issues/8720</span></div>
<div class="line"><span class="lineno">  498</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  499</span>        n_samples=100, random_state=0, n_classes=3, n_informative=6</div>
<div class="line"><span class="lineno">  500</span>    )</div>
<div class="line"><span class="lineno">  501</span>    train, test = np.arange(80), np.arange(80, 100)</div>
<div class="line"><span class="lineno">  502</span>    lr = LogisticRegression(C=1.0, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>)</div>
<div class="line"><span class="lineno">  503</span>    <span class="comment"># we use lbfgs to support multinomial</span></div>
<div class="line"><span class="lineno">  504</span>    params = lr.get_params()</div>
<div class="line"><span class="lineno">  505</span>    <span class="comment"># we store the params to set them further in _log_reg_scoring_path</span></div>
<div class="line"><span class="lineno">  506</span>    <span class="keywordflow">for</span> key <span class="keywordflow">in</span> [<span class="stringliteral">&quot;C&quot;</span>, <span class="stringliteral">&quot;n_jobs&quot;</span>, <span class="stringliteral">&quot;warm_start&quot;</span>]:</div>
<div class="line"><span class="lineno">  507</span>        del params[key]</div>
<div class="line"><span class="lineno">  508</span>    lr.fit(X[train], y[train])</div>
<div class="line"><span class="lineno">  509</span>    <span class="keywordflow">for</span> averaging <span class="keywordflow">in</span> multiclass_agg_list:</div>
<div class="line"><span class="lineno">  510</span>        scorer = get_scorer(scoring + averaging)</div>
<div class="line"><span class="lineno">  511</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  512</span>            _log_reg_scoring_path(</div>
<div class="line"><span class="lineno">  513</span>                X, y, train, test, Cs=[1.0], scoring=scorer, **params</div>
<div class="line"><span class="lineno">  514</span>            )[2][0],</div>
<div class="line"><span class="lineno">  515</span>            scorer(lr, X[test], y[test]),</div>
<div class="line"><span class="lineno">  516</span>        )</div>
<div class="line"><span class="lineno">  517</span> </div>
<div class="line"><span class="lineno">  518</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="acdeba50a49339103106dc686032ad48c" name="acdeba50a49339103106dc686032ad48c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acdeba50a49339103106dc686032ad48c">&#9670;&#160;</a></span>test_logistic_cv_sparse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_cv_sparse </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  560</span><span class="keyword">def </span>test_logistic_cv_sparse():</div>
<div class="line"><span class="lineno">  561</span>    X, y = make_classification(n_samples=50, n_features=5, random_state=0)</div>
<div class="line"><span class="lineno">  562</span>    X[X &lt; 1.0] = 0.0</div>
<div class="line"><span class="lineno">  563</span>    csr = sparse.csr_matrix(X)</div>
<div class="line"><span class="lineno">  564</span> </div>
<div class="line"><span class="lineno">  565</span>    clf = LogisticRegressionCV()</div>
<div class="line"><span class="lineno">  566</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  567</span>    clfs = LogisticRegressionCV()</div>
<div class="line"><span class="lineno">  568</span>    clfs.fit(csr, y)</div>
<div class="line"><span class="lineno">  569</span>    assert_array_almost_equal(clfs.coef_, clf.coef_)</div>
<div class="line"><span class="lineno">  570</span>    assert_array_almost_equal(clfs.intercept_, clf.intercept_)</div>
<div class="line"><span class="lineno">  571</span>    <span class="keyword">assert</span> clfs.C_ == clf.C_</div>
<div class="line"><span class="lineno">  572</span> </div>
<div class="line"><span class="lineno">  573</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a089afffd44ad51379fccc9cdd2ec3823" name="a089afffd44ad51379fccc9cdd2ec3823"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a089afffd44ad51379fccc9cdd2ec3823">&#9670;&#160;</a></span>test_logistic_regression_class_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_regression_class_weights </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  808</span><span class="keyword">def </span>test_logistic_regression_class_weights():</div>
<div class="line"><span class="lineno">  809</span>    <span class="comment"># Multinomial case: remove 90% of class 0</span></div>
<div class="line"><span class="lineno">  810</span>    X = iris.data[45:, :]</div>
<div class="line"><span class="lineno">  811</span>    y = iris.target[45:]</div>
<div class="line"><span class="lineno">  812</span>    solvers = (<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>)</div>
<div class="line"><span class="lineno">  813</span>    class_weight_dict = _compute_class_weight_dictionary(y)</div>
<div class="line"><span class="lineno">  814</span> </div>
<div class="line"><span class="lineno">  815</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> solvers:</div>
<div class="line"><span class="lineno">  816</span>        clf1 = LogisticRegression(</div>
<div class="line"><span class="lineno">  817</span>            solver=solver, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, class_weight=<span class="stringliteral">&quot;balanced&quot;</span></div>
<div class="line"><span class="lineno">  818</span>        )</div>
<div class="line"><span class="lineno">  819</span>        clf2 = LogisticRegression(</div>
<div class="line"><span class="lineno">  820</span>            solver=solver, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, class_weight=class_weight_dict</div>
<div class="line"><span class="lineno">  821</span>        )</div>
<div class="line"><span class="lineno">  822</span>        clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  823</span>        clf2.fit(X, y)</div>
<div class="line"><span class="lineno">  824</span>        assert_array_almost_equal(clf1.coef_, clf2.coef_, decimal=4)</div>
<div class="line"><span class="lineno">  825</span> </div>
<div class="line"><span class="lineno">  826</span>    <span class="comment"># Binary case: remove 90% of class 0 and 100% of class 2</span></div>
<div class="line"><span class="lineno">  827</span>    X = iris.data[45:100, :]</div>
<div class="line"><span class="lineno">  828</span>    y = iris.target[45:100]</div>
<div class="line"><span class="lineno">  829</span>    class_weight_dict = _compute_class_weight_dictionary(y)</div>
<div class="line"><span class="lineno">  830</span> </div>
<div class="line"><span class="lineno">  831</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> set(SOLVERS) - set((<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>)):</div>
<div class="line"><span class="lineno">  832</span>        clf1 = LogisticRegression(</div>
<div class="line"><span class="lineno">  833</span>            solver=solver, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>, class_weight=<span class="stringliteral">&quot;balanced&quot;</span></div>
<div class="line"><span class="lineno">  834</span>        )</div>
<div class="line"><span class="lineno">  835</span>        clf2 = LogisticRegression(</div>
<div class="line"><span class="lineno">  836</span>            solver=solver, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>, class_weight=class_weight_dict</div>
<div class="line"><span class="lineno">  837</span>        )</div>
<div class="line"><span class="lineno">  838</span>        clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  839</span>        clf2.fit(X, y)</div>
<div class="line"><span class="lineno">  840</span>        assert_array_almost_equal(clf1.coef_, clf2.coef_, decimal=6)</div>
<div class="line"><span class="lineno">  841</span> </div>
<div class="line"><span class="lineno">  842</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="acf54f74352aab988efb7b55c9bae0f67" name="acf54f74352aab988efb7b55c9bae0f67"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acf54f74352aab988efb7b55c9bae0f67">&#9670;&#160;</a></span>test_logistic_regression_cv_refit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_regression_cv_refit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_seed</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>penalty</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1038</span><span class="keyword">def </span>test_logistic_regression_cv_refit(random_seed, penalty):</div>
<div class="line"><span class="lineno"> 1039</span>    <span class="comment"># Test that when refit=True, logistic regression cv with the saga solver</span></div>
<div class="line"><span class="lineno"> 1040</span>    <span class="comment"># converges to the same solution as logistic regression with a fixed</span></div>
<div class="line"><span class="lineno"> 1041</span>    <span class="comment"># regularization parameter.</span></div>
<div class="line"><span class="lineno"> 1042</span>    <span class="comment"># Internally the LogisticRegressionCV model uses a warm start to refit on</span></div>
<div class="line"><span class="lineno"> 1043</span>    <span class="comment"># the full data model with the optimal C found by CV. As the penalized</span></div>
<div class="line"><span class="lineno"> 1044</span>    <span class="comment"># logistic regression loss is convex, we should still recover exactly</span></div>
<div class="line"><span class="lineno"> 1045</span>    <span class="comment"># the same solution as long as the stopping criterion is strict enough (and</span></div>
<div class="line"><span class="lineno"> 1046</span>    <span class="comment"># that there are no exactly duplicated features when penalty=&#39;l1&#39;).</span></div>
<div class="line"><span class="lineno"> 1047</span>    X, y = make_classification(n_samples=100, n_features=20, random_state=random_seed)</div>
<div class="line"><span class="lineno"> 1048</span>    common_params = dict(</div>
<div class="line"><span class="lineno"> 1049</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1050</span>        penalty=penalty,</div>
<div class="line"><span class="lineno"> 1051</span>        random_state=random_seed,</div>
<div class="line"><span class="lineno"> 1052</span>        max_iter=1000,</div>
<div class="line"><span class="lineno"> 1053</span>        tol=1e-12,</div>
<div class="line"><span class="lineno"> 1054</span>    )</div>
<div class="line"><span class="lineno"> 1055</span>    lr_cv = LogisticRegressionCV(Cs=[1.0], refit=<span class="keyword">True</span>, **common_params)</div>
<div class="line"><span class="lineno"> 1056</span>    lr_cv.fit(X, y)</div>
<div class="line"><span class="lineno"> 1057</span>    lr = LogisticRegression(C=1.0, **common_params)</div>
<div class="line"><span class="lineno"> 1058</span>    lr.fit(X, y)</div>
<div class="line"><span class="lineno"> 1059</span>    assert_array_almost_equal(lr_cv.coef_, lr.coef_)</div>
<div class="line"><span class="lineno"> 1060</span> </div>
<div class="line"><span class="lineno"> 1061</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aab378f0cc6f9f7965eee7d257414d9ab" name="aab378f0cc6f9f7965eee7d257414d9ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab378f0cc6f9f7965eee7d257414d9ab">&#9670;&#160;</a></span>test_logistic_regression_multi_class_auto()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_regression_multi_class_auto </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>est</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1717</span><span class="keyword">def </span>test_logistic_regression_multi_class_auto(est, solver):</div>
<div class="line"><span class="lineno"> 1718</span>    <span class="comment"># check multi_class=&#39;auto&#39; =&gt; multi_class=&#39;ovr&#39;</span></div>
<div class="line"><span class="lineno"> 1719</span>    <span class="comment"># iff binary y or liblinear or newton-cholesky</span></div>
<div class="line"><span class="lineno"> 1720</span> </div>
<div class="line"><span class="lineno"> 1721</span>    <span class="keyword">def </span>fit(X, y, **kw):</div>
<div class="line"><span class="lineno"> 1722</span>        <span class="keywordflow">return</span> clone(est).set_params(**kw).fit(X, y)</div>
<div class="line"><span class="lineno"> 1723</span> </div>
<div class="line"><span class="lineno"> 1724</span>    scaled_data = scale(iris.data)</div>
<div class="line"><span class="lineno"> 1725</span>    X = scaled_data[::10]</div>
<div class="line"><span class="lineno"> 1726</span>    X2 = scaled_data[1::10]</div>
<div class="line"><span class="lineno"> 1727</span>    y_multi = iris.target[::10]</div>
<div class="line"><span class="lineno"> 1728</span>    y_bin = y_multi == 0</div>
<div class="line"><span class="lineno"> 1729</span>    est_auto_bin = fit(X, y_bin, multi_class=<span class="stringliteral">&quot;auto&quot;</span>, solver=solver)</div>
<div class="line"><span class="lineno"> 1730</span>    est_ovr_bin = fit(X, y_bin, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>, solver=solver)</div>
<div class="line"><span class="lineno"> 1731</span>    assert_allclose(est_auto_bin.coef_, est_ovr_bin.coef_)</div>
<div class="line"><span class="lineno"> 1732</span>    assert_allclose(est_auto_bin.predict_proba(X2), est_ovr_bin.predict_proba(X2))</div>
<div class="line"><span class="lineno"> 1733</span> </div>
<div class="line"><span class="lineno"> 1734</span>    est_auto_multi = fit(X, y_multi, multi_class=<span class="stringliteral">&quot;auto&quot;</span>, solver=solver)</div>
<div class="line"><span class="lineno"> 1735</span>    <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> (<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>):</div>
<div class="line"><span class="lineno"> 1736</span>        est_ovr_multi = fit(X, y_multi, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>, solver=solver)</div>
<div class="line"><span class="lineno"> 1737</span>        assert_allclose(est_auto_multi.coef_, est_ovr_multi.coef_)</div>
<div class="line"><span class="lineno"> 1738</span>        assert_allclose(</div>
<div class="line"><span class="lineno"> 1739</span>            est_auto_multi.predict_proba(X2), est_ovr_multi.predict_proba(X2)</div>
<div class="line"><span class="lineno"> 1740</span>        )</div>
<div class="line"><span class="lineno"> 1741</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1742</span>        est_multi_multi = fit(X, y_multi, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, solver=solver)</div>
<div class="line"><span class="lineno"> 1743</span>        assert_allclose(est_auto_multi.coef_, est_multi_multi.coef_)</div>
<div class="line"><span class="lineno"> 1744</span>        assert_allclose(</div>
<div class="line"><span class="lineno"> 1745</span>            est_auto_multi.predict_proba(X2), est_multi_multi.predict_proba(X2)</div>
<div class="line"><span class="lineno"> 1746</span>        )</div>
<div class="line"><span class="lineno"> 1747</span> </div>
<div class="line"><span class="lineno"> 1748</span>        <span class="comment"># Make sure multi_class=&#39;ovr&#39; is distinct from =&#39;multinomial&#39;</span></div>
<div class="line"><span class="lineno"> 1749</span>        <span class="keyword">assert</span> <span class="keywordflow">not</span> np.allclose(</div>
<div class="line"><span class="lineno"> 1750</span>            est_auto_bin.coef_,</div>
<div class="line"><span class="lineno"> 1751</span>            fit(X, y_bin, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, solver=solver).coef_,</div>
<div class="line"><span class="lineno"> 1752</span>        )</div>
<div class="line"><span class="lineno"> 1753</span>        <span class="keyword">assert</span> <span class="keywordflow">not</span> np.allclose(</div>
<div class="line"><span class="lineno"> 1754</span>            est_auto_bin.coef_,</div>
<div class="line"><span class="lineno"> 1755</span>            fit(X, y_multi, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, solver=solver).coef_,</div>
<div class="line"><span class="lineno"> 1756</span>        )</div>
<div class="line"><span class="lineno"> 1757</span> </div>
<div class="line"><span class="lineno"> 1758</span> </div>
<div class="line"><span class="lineno"> 1759</span><span class="preprocessor">@pytest.mark.parametrize(&quot;solver&quot;, sorted(set(SOLVERS)</span> - set([<span class="stringliteral">&quot;liblinear&quot;</span>])))</div>
</div><!-- fragment -->
</div>
</div>
<a id="a54299a02691d04b706cd7e98ba8e1812" name="a54299a02691d04b706cd7e98ba8e1812"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54299a02691d04b706cd7e98ba8e1812">&#9670;&#160;</a></span>test_logistic_regression_multinomial()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_regression_multinomial </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  843</span><span class="keyword">def </span>test_logistic_regression_multinomial():</div>
<div class="line"><span class="lineno">  844</span>    <span class="comment"># Tests for the multinomial option in logistic regression</span></div>
<div class="line"><span class="lineno">  845</span> </div>
<div class="line"><span class="lineno">  846</span>    <span class="comment"># Some basic attributes of Logistic Regression</span></div>
<div class="line"><span class="lineno">  847</span>    n_samples, n_features, n_classes = 50, 20, 3</div>
<div class="line"><span class="lineno">  848</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  849</span>        n_samples=n_samples,</div>
<div class="line"><span class="lineno">  850</span>        n_features=n_features,</div>
<div class="line"><span class="lineno">  851</span>        n_informative=10,</div>
<div class="line"><span class="lineno">  852</span>        n_classes=n_classes,</div>
<div class="line"><span class="lineno">  853</span>        random_state=0,</div>
<div class="line"><span class="lineno">  854</span>    )</div>
<div class="line"><span class="lineno">  855</span> </div>
<div class="line"><span class="lineno">  856</span>    X = StandardScaler(with_mean=<span class="keyword">False</span>).fit_transform(X)</div>
<div class="line"><span class="lineno">  857</span> </div>
<div class="line"><span class="lineno">  858</span>    <span class="comment"># &#39;lbfgs&#39; is used as a referenced</span></div>
<div class="line"><span class="lineno">  859</span>    solver = <span class="stringliteral">&quot;lbfgs&quot;</span></div>
<div class="line"><span class="lineno">  860</span>    ref_i = LogisticRegression(solver=solver, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>)</div>
<div class="line"><span class="lineno">  861</span>    ref_w = LogisticRegression(</div>
<div class="line"><span class="lineno">  862</span>        solver=solver, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, fit_intercept=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  863</span>    )</div>
<div class="line"><span class="lineno">  864</span>    ref_i.fit(X, y)</div>
<div class="line"><span class="lineno">  865</span>    ref_w.fit(X, y)</div>
<div class="line"><span class="lineno">  866</span>    <span class="keyword">assert</span> ref_i.coef_.shape == (n_classes, n_features)</div>
<div class="line"><span class="lineno">  867</span>    <span class="keyword">assert</span> ref_w.coef_.shape == (n_classes, n_features)</div>
<div class="line"><span class="lineno">  868</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>]:</div>
<div class="line"><span class="lineno">  869</span>        clf_i = LogisticRegression(</div>
<div class="line"><span class="lineno">  870</span>            solver=solver,</div>
<div class="line"><span class="lineno">  871</span>            multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>,</div>
<div class="line"><span class="lineno">  872</span>            random_state=42,</div>
<div class="line"><span class="lineno">  873</span>            max_iter=2000,</div>
<div class="line"><span class="lineno">  874</span>            tol=1e-7,</div>
<div class="line"><span class="lineno">  875</span>        )</div>
<div class="line"><span class="lineno">  876</span>        clf_w = LogisticRegression(</div>
<div class="line"><span class="lineno">  877</span>            solver=solver,</div>
<div class="line"><span class="lineno">  878</span>            multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>,</div>
<div class="line"><span class="lineno">  879</span>            random_state=42,</div>
<div class="line"><span class="lineno">  880</span>            max_iter=2000,</div>
<div class="line"><span class="lineno">  881</span>            tol=1e-7,</div>
<div class="line"><span class="lineno">  882</span>            fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  883</span>        )</div>
<div class="line"><span class="lineno">  884</span>        clf_i.fit(X, y)</div>
<div class="line"><span class="lineno">  885</span>        clf_w.fit(X, y)</div>
<div class="line"><span class="lineno">  886</span>        <span class="keyword">assert</span> clf_i.coef_.shape == (n_classes, n_features)</div>
<div class="line"><span class="lineno">  887</span>        <span class="keyword">assert</span> clf_w.coef_.shape == (n_classes, n_features)</div>
<div class="line"><span class="lineno">  888</span> </div>
<div class="line"><span class="lineno">  889</span>        <span class="comment"># Compare solutions between lbfgs and the other solvers</span></div>
<div class="line"><span class="lineno">  890</span>        assert_allclose(ref_i.coef_, clf_i.coef_, rtol=1e-2)</div>
<div class="line"><span class="lineno">  891</span>        assert_allclose(ref_w.coef_, clf_w.coef_, rtol=1e-2)</div>
<div class="line"><span class="lineno">  892</span>        assert_allclose(ref_i.intercept_, clf_i.intercept_, rtol=1e-2)</div>
<div class="line"><span class="lineno">  893</span> </div>
<div class="line"><span class="lineno">  894</span>    <span class="comment"># Test that the path give almost the same results. However since in this</span></div>
<div class="line"><span class="lineno">  895</span>    <span class="comment"># case we take the average of the coefs after fitting across all the</span></div>
<div class="line"><span class="lineno">  896</span>    <span class="comment"># folds, it need not be exactly the same.</span></div>
<div class="line"><span class="lineno">  897</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>, <span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]:</div>
<div class="line"><span class="lineno">  898</span>        clf_path = LogisticRegressionCV(</div>
<div class="line"><span class="lineno">  899</span>            solver=solver, max_iter=2000, tol=1e-6, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, Cs=[1.0]</div>
<div class="line"><span class="lineno">  900</span>        )</div>
<div class="line"><span class="lineno">  901</span>        clf_path.fit(X, y)</div>
<div class="line"><span class="lineno">  902</span>        assert_allclose(clf_path.coef_, ref_i.coef_, rtol=2e-2)</div>
<div class="line"><span class="lineno">  903</span>        assert_allclose(clf_path.intercept_, ref_i.intercept_, rtol=2e-2)</div>
<div class="line"><span class="lineno">  904</span> </div>
<div class="line"><span class="lineno">  905</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aea34792ca05958ed27144d1b4e6b96c1" name="aea34792ca05958ed27144d1b4e6b96c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea34792ca05958ed27144d1b4e6b96c1">&#9670;&#160;</a></span>test_logistic_regression_path_coefs_multinomial()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_regression_path_coefs_multinomial </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1676</span><span class="keyword">def </span>test_logistic_regression_path_coefs_multinomial():</div>
<div class="line"><span class="lineno"> 1677</span>    <span class="comment"># Make sure that the returned coefs by logistic_regression_path when</span></div>
<div class="line"><span class="lineno"> 1678</span>    <span class="comment"># multi_class=&#39;multinomial&#39; don&#39;t override each other (used to be a</span></div>
<div class="line"><span class="lineno"> 1679</span>    <span class="comment"># bug).</span></div>
<div class="line"><span class="lineno"> 1680</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno"> 1681</span>        n_samples=200,</div>
<div class="line"><span class="lineno"> 1682</span>        n_classes=3,</div>
<div class="line"><span class="lineno"> 1683</span>        n_informative=2,</div>
<div class="line"><span class="lineno"> 1684</span>        n_redundant=0,</div>
<div class="line"><span class="lineno"> 1685</span>        n_clusters_per_class=1,</div>
<div class="line"><span class="lineno"> 1686</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1687</span>        n_features=2,</div>
<div class="line"><span class="lineno"> 1688</span>    )</div>
<div class="line"><span class="lineno"> 1689</span>    Cs = [0.00001, 1, 10000]</div>
<div class="line"><span class="lineno"> 1690</span>    coefs, _, _ = _logistic_regression_path(</div>
<div class="line"><span class="lineno"> 1691</span>        X,</div>
<div class="line"><span class="lineno"> 1692</span>        y,</div>
<div class="line"><span class="lineno"> 1693</span>        penalty=<span class="stringliteral">&quot;l1&quot;</span>,</div>
<div class="line"><span class="lineno"> 1694</span>        Cs=Cs,</div>
<div class="line"><span class="lineno"> 1695</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1696</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1697</span>        multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>,</div>
<div class="line"><span class="lineno"> 1698</span>    )</div>
<div class="line"><span class="lineno"> 1699</span> </div>
<div class="line"><span class="lineno"> 1700</span>    <span class="keyword">with</span> pytest.raises(AssertionError):</div>
<div class="line"><span class="lineno"> 1701</span>        assert_array_almost_equal(coefs[0], coefs[1], decimal=1)</div>
<div class="line"><span class="lineno"> 1702</span>    <span class="keyword">with</span> pytest.raises(AssertionError):</div>
<div class="line"><span class="lineno"> 1703</span>        assert_array_almost_equal(coefs[0], coefs[2], decimal=1)</div>
<div class="line"><span class="lineno"> 1704</span>    <span class="keyword">with</span> pytest.raises(AssertionError):</div>
<div class="line"><span class="lineno"> 1705</span>        assert_array_almost_equal(coefs[1], coefs[2], decimal=1)</div>
<div class="line"><span class="lineno"> 1706</span> </div>
<div class="line"><span class="lineno"> 1707</span> </div>
<div class="line"><span class="lineno"> 1708</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1709</span>    <span class="stringliteral">&quot;est&quot;</span>,</div>
<div class="line"><span class="lineno"> 1710</span>    [</div>
<div class="line"><span class="lineno"> 1711</span>        LogisticRegression(random_state=0, max_iter=500),</div>
<div class="line"><span class="lineno"> 1712</span>        LogisticRegressionCV(random_state=0, cv=3, Cs=3, tol=1e-3, max_iter=500),</div>
<div class="line"><span class="lineno"> 1713</span>    ],</div>
<div class="line"><span class="lineno"> 1714</span>    ids=<span class="keyword">lambda</span> x: x.__class__.__name__,</div>
<div class="line"><span class="lineno"> 1715</span>)</div>
<div class="line"><span class="lineno"> 1716</span><span class="preprocessor">@pytest.mark.parametrize(&quot;solver&quot;, SOLVERS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a03351f0260b2b892c4aba5e219f338dc" name="a03351f0260b2b892c4aba5e219f338dc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a03351f0260b2b892c4aba5e219f338dc">&#9670;&#160;</a></span>test_logistic_regression_path_convergence_fail()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_regression_path_convergence_fail </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  389</span><span class="keyword">def </span>test_logistic_regression_path_convergence_fail():</div>
<div class="line"><span class="lineno">  390</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  391</span>    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))</div>
<div class="line"><span class="lineno">  392</span>    y = [1] * 100 + [-1] * 100</div>
<div class="line"><span class="lineno">  393</span>    Cs = [1e3]</div>
<div class="line"><span class="lineno">  394</span> </div>
<div class="line"><span class="lineno">  395</span>    <span class="comment"># Check that the convergence message points to both a model agnostic</span></div>
<div class="line"><span class="lineno">  396</span>    <span class="comment"># advice (scaling the data) and to the logistic regression specific</span></div>
<div class="line"><span class="lineno">  397</span>    <span class="comment"># documentation that includes hints on the solver configuration.</span></div>
<div class="line"><span class="lineno">  398</span>    <span class="keyword">with</span> pytest.warns(ConvergenceWarning) <span class="keyword">as</span> record:</div>
<div class="line"><span class="lineno">  399</span>        _logistic_regression_path(</div>
<div class="line"><span class="lineno">  400</span>            X, y, Cs=Cs, tol=0.0, max_iter=1, random_state=0, verbose=0</div>
<div class="line"><span class="lineno">  401</span>        )</div>
<div class="line"><span class="lineno">  402</span> </div>
<div class="line"><span class="lineno">  403</span>    <span class="keyword">assert</span> len(record) == 1</div>
<div class="line"><span class="lineno">  404</span>    warn_msg = record[0].message.args[0]</div>
<div class="line"><span class="lineno">  405</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;lbfgs failed to converge&quot;</span> <span class="keywordflow">in</span> warn_msg</div>
<div class="line"><span class="lineno">  406</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;Increase the number of iterations&quot;</span> <span class="keywordflow">in</span> warn_msg</div>
<div class="line"><span class="lineno">  407</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;scale the data&quot;</span> <span class="keywordflow">in</span> warn_msg</div>
<div class="line"><span class="lineno">  408</span>    <span class="keyword">assert</span> <span class="stringliteral">&quot;linear_model.html#logistic-regression&quot;</span> <span class="keywordflow">in</span> warn_msg</div>
<div class="line"><span class="lineno">  409</span> </div>
<div class="line"><span class="lineno">  410</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aba9cac5343e6306f27ceff79137e1e26" name="aba9cac5343e6306f27ceff79137e1e26"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba9cac5343e6306f27ceff79137e1e26">&#9670;&#160;</a></span>test_logistic_regression_sample_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_regression_sample_weights </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  713</span><span class="keyword">def </span>test_logistic_regression_sample_weights():</div>
<div class="line"><span class="lineno">  714</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  715</span>        n_samples=20, n_features=5, n_informative=3, n_classes=2, random_state=0</div>
<div class="line"><span class="lineno">  716</span>    )</div>
<div class="line"><span class="lineno">  717</span>    sample_weight = y + 1</div>
<div class="line"><span class="lineno">  718</span> </div>
<div class="line"><span class="lineno">  719</span>    <span class="keywordflow">for</span> LR <span class="keywordflow">in</span> [LogisticRegression, LogisticRegressionCV]:</div>
<div class="line"><span class="lineno">  720</span> </div>
<div class="line"><span class="lineno">  721</span>        kw = {<span class="stringliteral">&quot;random_state&quot;</span>: 42, <span class="stringliteral">&quot;fit_intercept&quot;</span>: <span class="keyword">False</span>, <span class="stringliteral">&quot;multi_class&quot;</span>: <span class="stringliteral">&quot;ovr&quot;</span>}</div>
<div class="line"><span class="lineno">  722</span>        <span class="keywordflow">if</span> LR <span class="keywordflow">is</span> LogisticRegressionCV:</div>
<div class="line"><span class="lineno">  723</span>            kw.update({<span class="stringliteral">&quot;Cs&quot;</span>: 3, <span class="stringliteral">&quot;cv&quot;</span>: 3})</div>
<div class="line"><span class="lineno">  724</span> </div>
<div class="line"><span class="lineno">  725</span>        <span class="comment"># Test that passing sample_weight as ones is the same as</span></div>
<div class="line"><span class="lineno">  726</span>        <span class="comment"># not passing them at all (default None)</span></div>
<div class="line"><span class="lineno">  727</span>        <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;liblinear&quot;</span>]:</div>
<div class="line"><span class="lineno">  728</span>            clf_sw_none = LR(solver=solver, **kw)</div>
<div class="line"><span class="lineno">  729</span>            clf_sw_ones = LR(solver=solver, **kw)</div>
<div class="line"><span class="lineno">  730</span>            clf_sw_none.fit(X, y)</div>
<div class="line"><span class="lineno">  731</span>            clf_sw_ones.fit(X, y, sample_weight=np.ones(y.shape[0]))</div>
<div class="line"><span class="lineno">  732</span>            assert_allclose(clf_sw_none.coef_, clf_sw_ones.coef_, rtol=1e-4)</div>
<div class="line"><span class="lineno">  733</span> </div>
<div class="line"><span class="lineno">  734</span>        <span class="comment"># Test that sample weights work the same with the lbfgs,</span></div>
<div class="line"><span class="lineno">  735</span>        <span class="comment"># newton-cg, newton-cholesky and &#39;sag&#39; solvers</span></div>
<div class="line"><span class="lineno">  736</span>        clf_sw_lbfgs = LR(**kw)</div>
<div class="line"><span class="lineno">  737</span>        clf_sw_lbfgs.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  738</span>        <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> set(SOLVERS) - set((<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>)):</div>
<div class="line"><span class="lineno">  739</span>            clf_sw = LR(solver=solver, tol=1e-10 <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;sag&quot;</span> <span class="keywordflow">else</span> 1e-5, **kw)</div>
<div class="line"><span class="lineno">  740</span>            <span class="comment"># ignore convergence warning due to small dataset with sag</span></div>
<div class="line"><span class="lineno">  741</span>            <span class="keyword">with</span> ignore_warnings():</div>
<div class="line"><span class="lineno">  742</span>                clf_sw.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  743</span>            assert_allclose(clf_sw_lbfgs.coef_, clf_sw.coef_, rtol=1e-4)</div>
<div class="line"><span class="lineno">  744</span> </div>
<div class="line"><span class="lineno">  745</span>        <span class="comment"># Test that passing class_weight as [1,2] is the same as</span></div>
<div class="line"><span class="lineno">  746</span>        <span class="comment"># passing class weight = [1,1] but adjusting sample weights</span></div>
<div class="line"><span class="lineno">  747</span>        <span class="comment"># to be 2 for all instances of class 2</span></div>
<div class="line"><span class="lineno">  748</span>        <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;liblinear&quot;</span>]:</div>
<div class="line"><span class="lineno">  749</span>            clf_cw_12 = LR(solver=solver, class_weight={0: 1, 1: 2}, **kw)</div>
<div class="line"><span class="lineno">  750</span>            clf_cw_12.fit(X, y)</div>
<div class="line"><span class="lineno">  751</span>            clf_sw_12 = LR(solver=solver, **kw)</div>
<div class="line"><span class="lineno">  752</span>            clf_sw_12.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  753</span>            assert_allclose(clf_cw_12.coef_, clf_sw_12.coef_, rtol=1e-4)</div>
<div class="line"><span class="lineno">  754</span> </div>
<div class="line"><span class="lineno">  755</span>    <span class="comment"># Test the above for l1 penalty and l2 penalty with dual=True.</span></div>
<div class="line"><span class="lineno">  756</span>    <span class="comment"># since the patched liblinear code is different.</span></div>
<div class="line"><span class="lineno">  757</span>    clf_cw = LogisticRegression(</div>
<div class="line"><span class="lineno">  758</span>        solver=<span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno">  759</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  760</span>        class_weight={0: 1, 1: 2},</div>
<div class="line"><span class="lineno">  761</span>        penalty=<span class="stringliteral">&quot;l1&quot;</span>,</div>
<div class="line"><span class="lineno">  762</span>        tol=1e-5,</div>
<div class="line"><span class="lineno">  763</span>        random_state=42,</div>
<div class="line"><span class="lineno">  764</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  765</span>    )</div>
<div class="line"><span class="lineno">  766</span>    clf_cw.fit(X, y)</div>
<div class="line"><span class="lineno">  767</span>    clf_sw = LogisticRegression(</div>
<div class="line"><span class="lineno">  768</span>        solver=<span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno">  769</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  770</span>        penalty=<span class="stringliteral">&quot;l1&quot;</span>,</div>
<div class="line"><span class="lineno">  771</span>        tol=1e-5,</div>
<div class="line"><span class="lineno">  772</span>        random_state=42,</div>
<div class="line"><span class="lineno">  773</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  774</span>    )</div>
<div class="line"><span class="lineno">  775</span>    clf_sw.fit(X, y, sample_weight)</div>
<div class="line"><span class="lineno">  776</span>    assert_array_almost_equal(clf_cw.coef_, clf_sw.coef_, decimal=4)</div>
<div class="line"><span class="lineno">  777</span> </div>
<div class="line"><span class="lineno">  778</span>    clf_cw = LogisticRegression(</div>
<div class="line"><span class="lineno">  779</span>        solver=<span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno">  780</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  781</span>        class_weight={0: 1, 1: 2},</div>
<div class="line"><span class="lineno">  782</span>        penalty=<span class="stringliteral">&quot;l2&quot;</span>,</div>
<div class="line"><span class="lineno">  783</span>        dual=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  784</span>        random_state=42,</div>
<div class="line"><span class="lineno">  785</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  786</span>    )</div>
<div class="line"><span class="lineno">  787</span>    clf_cw.fit(X, y)</div>
<div class="line"><span class="lineno">  788</span>    clf_sw = LogisticRegression(</div>
<div class="line"><span class="lineno">  789</span>        solver=<span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno">  790</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  791</span>        penalty=<span class="stringliteral">&quot;l2&quot;</span>,</div>
<div class="line"><span class="lineno">  792</span>        dual=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  793</span>        random_state=42,</div>
<div class="line"><span class="lineno">  794</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  795</span>    )</div>
<div class="line"><span class="lineno">  796</span>    clf_sw.fit(X, y, sample_weight)</div>
<div class="line"><span class="lineno">  797</span>    assert_array_almost_equal(clf_cw.coef_, clf_sw.coef_, decimal=4)</div>
<div class="line"><span class="lineno">  798</span> </div>
<div class="line"><span class="lineno">  799</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a731dda67339a3ffdd633c6e7ab94b49a" name="a731dda67339a3ffdd633c6e7ab94b49a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a731dda67339a3ffdd633c6e7ab94b49a">&#9670;&#160;</a></span>test_logistic_regression_solvers()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_regression_solvers </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test solvers converge to the same result.</pre> <div class="fragment"><div class="line"><span class="lineno">  637</span><span class="keyword">def </span>test_logistic_regression_solvers():</div>
<div class="line"><span class="lineno">  638</span>    <span class="stringliteral">&quot;&quot;&quot;Test solvers converge to the same result.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  639</span>    X, y = make_classification(n_features=10, n_informative=5, random_state=0)</div>
<div class="line"><span class="lineno">  640</span> </div>
<div class="line"><span class="lineno">  641</span>    params = dict(fit_intercept=<span class="keyword">False</span>, random_state=42, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>)</div>
<div class="line"><span class="lineno">  642</span> </div>
<div class="line"><span class="lineno">  643</span>    regressors = {</div>
<div class="line"><span class="lineno">  644</span>        solver: LogisticRegression(solver=solver, **params).fit(X, y)</div>
<div class="line"><span class="lineno">  645</span>        <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> SOLVERS</div>
<div class="line"><span class="lineno">  646</span>    }</div>
<div class="line"><span class="lineno">  647</span> </div>
<div class="line"><span class="lineno">  648</span>    <span class="keywordflow">for</span> solver_1, solver_2 <span class="keywordflow">in</span> itertools.combinations(regressors, r=2):</div>
<div class="line"><span class="lineno">  649</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  650</span>            regressors[solver_1].coef_, regressors[solver_2].coef_, decimal=3</div>
<div class="line"><span class="lineno">  651</span>        )</div>
<div class="line"><span class="lineno">  652</span> </div>
<div class="line"><span class="lineno">  653</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae37006bca018d4af94b15e2f424b6e93" name="ae37006bca018d4af94b15e2f424b6e93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae37006bca018d4af94b15e2f424b6e93">&#9670;&#160;</a></span>test_logistic_regression_solvers_multiclass()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_regression_solvers_multiclass </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test solvers converge to the same result for multiclass problems.</pre> <div class="fragment"><div class="line"><span class="lineno">  654</span><span class="keyword">def </span>test_logistic_regression_solvers_multiclass():</div>
<div class="line"><span class="lineno">  655</span>    <span class="stringliteral">&quot;&quot;&quot;Test solvers converge to the same result for multiclass problems.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  656</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  657</span>        n_samples=20, n_features=20, n_informative=10, n_classes=3, random_state=0</div>
<div class="line"><span class="lineno">  658</span>    )</div>
<div class="line"><span class="lineno">  659</span>    tol = 1e-7</div>
<div class="line"><span class="lineno">  660</span>    params = dict(fit_intercept=<span class="keyword">False</span>, tol=tol, random_state=42, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>)</div>
<div class="line"><span class="lineno">  661</span> </div>
<div class="line"><span class="lineno">  662</span>    <span class="comment"># Override max iteration count for specific solvers to allow for</span></div>
<div class="line"><span class="lineno">  663</span>    <span class="comment"># proper convergence.</span></div>
<div class="line"><span class="lineno">  664</span>    solver_max_iter = {<span class="stringliteral">&quot;sag&quot;</span>: 1000, <span class="stringliteral">&quot;saga&quot;</span>: 10000}</div>
<div class="line"><span class="lineno">  665</span> </div>
<div class="line"><span class="lineno">  666</span>    regressors = {</div>
<div class="line"><span class="lineno">  667</span>        solver: LogisticRegression(</div>
<div class="line"><span class="lineno">  668</span>            solver=solver, max_iter=solver_max_iter.get(solver, 100), **params</div>
<div class="line"><span class="lineno">  669</span>        ).fit(X, y)</div>
<div class="line"><span class="lineno">  670</span>        <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> SOLVERS</div>
<div class="line"><span class="lineno">  671</span>    }</div>
<div class="line"><span class="lineno">  672</span> </div>
<div class="line"><span class="lineno">  673</span>    <span class="keywordflow">for</span> solver_1, solver_2 <span class="keywordflow">in</span> itertools.combinations(regressors, r=2):</div>
<div class="line"><span class="lineno">  674</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  675</span>            regressors[solver_1].coef_, regressors[solver_2].coef_, decimal=4</div>
<div class="line"><span class="lineno">  676</span>        )</div>
<div class="line"><span class="lineno">  677</span> </div>
<div class="line"><span class="lineno">  678</span> </div>
<div class="line"><span class="lineno">  679</span><span class="preprocessor">@pytest.mark.parametrize(&quot;weight&quot;, [{0: 0.1, 1: 0.2}, {0: 0.1, 1: 0.2, 2: 0.5}])</span></div>
<div class="line"><span class="lineno">  680</span><span class="preprocessor">@pytest.mark.parametrize(&quot;class_weight&quot;, [&quot;weight&quot;, &quot;balanced&quot;])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a9a80f07182e55c88c55ea116b350d4aa" name="a9a80f07182e55c88c55ea116b350d4aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a80f07182e55c88c55ea116b350d4aa">&#9670;&#160;</a></span>test_logistic_regressioncv_class_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logistic_regressioncv_class_weights </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>class_weight</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test class_weight for LogisticRegressionCV.</pre> <div class="fragment"><div class="line"><span class="lineno">  681</span><span class="keyword">def </span>test_logistic_regressioncv_class_weights(weight, class_weight):</div>
<div class="line"><span class="lineno">  682</span>    <span class="stringliteral">&quot;&quot;&quot;Test class_weight for LogisticRegressionCV.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  683</span>    n_classes = len(weight)</div>
<div class="line"><span class="lineno">  684</span>    <span class="keywordflow">if</span> class_weight == <span class="stringliteral">&quot;weight&quot;</span>:</div>
<div class="line"><span class="lineno">  685</span>        class_weight = weight</div>
<div class="line"><span class="lineno">  686</span> </div>
<div class="line"><span class="lineno">  687</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  688</span>        n_samples=30,</div>
<div class="line"><span class="lineno">  689</span>        n_features=3,</div>
<div class="line"><span class="lineno">  690</span>        n_repeated=0,</div>
<div class="line"><span class="lineno">  691</span>        n_informative=3,</div>
<div class="line"><span class="lineno">  692</span>        n_redundant=0,</div>
<div class="line"><span class="lineno">  693</span>        n_classes=n_classes,</div>
<div class="line"><span class="lineno">  694</span>        random_state=0,</div>
<div class="line"><span class="lineno">  695</span>    )</div>
<div class="line"><span class="lineno">  696</span>    params = dict(</div>
<div class="line"><span class="lineno">  697</span>        Cs=1,</div>
<div class="line"><span class="lineno">  698</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  699</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  700</span>        class_weight=class_weight,</div>
<div class="line"><span class="lineno">  701</span>    )</div>
<div class="line"><span class="lineno">  702</span>    clf_lbfgs = LogisticRegressionCV(solver=<span class="stringliteral">&quot;lbfgs&quot;</span>, **params)</div>
<div class="line"><span class="lineno">  703</span>    clf_lbfgs.fit(X, y)</div>
<div class="line"><span class="lineno">  704</span> </div>
<div class="line"><span class="lineno">  705</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> set(SOLVERS) - set([<span class="stringliteral">&quot;lbfgs&quot;</span>]):</div>
<div class="line"><span class="lineno">  706</span>        clf = LogisticRegressionCV(solver=solver, **params)</div>
<div class="line"><span class="lineno">  707</span>        <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> (<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>):</div>
<div class="line"><span class="lineno">  708</span>            clf.set_params(tol=1e-5, max_iter=10000, random_state=0)</div>
<div class="line"><span class="lineno">  709</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  710</span>        assert_allclose(clf.coef_, clf_lbfgs.coef_, rtol=1e-3)</div>
<div class="line"><span class="lineno">  711</span> </div>
<div class="line"><span class="lineno">  712</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9159bb73e1d00f61da5d8b28905bd277" name="a9159bb73e1d00f61da5d8b28905bd277"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9159bb73e1d00f61da5d8b28905bd277">&#9670;&#160;</a></span>test_LogisticRegression_elastic_net_objective()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_LogisticRegression_elastic_net_objective </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>l1_ratio</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1425</span><span class="keyword">def </span>test_LogisticRegression_elastic_net_objective(C, l1_ratio):</div>
<div class="line"><span class="lineno"> 1426</span>    <span class="comment"># Check that training with a penalty matching the objective leads</span></div>
<div class="line"><span class="lineno"> 1427</span>    <span class="comment"># to a lower objective.</span></div>
<div class="line"><span class="lineno"> 1428</span>    <span class="comment"># Here we train a logistic regression with l2 (a) and elasticnet (b)</span></div>
<div class="line"><span class="lineno"> 1429</span>    <span class="comment"># penalties, and compute the elasticnet objective. That of a should be</span></div>
<div class="line"><span class="lineno"> 1430</span>    <span class="comment"># greater than that of b (both objectives are convex).</span></div>
<div class="line"><span class="lineno"> 1431</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno"> 1432</span>        n_samples=1000,</div>
<div class="line"><span class="lineno"> 1433</span>        n_classes=2,</div>
<div class="line"><span class="lineno"> 1434</span>        n_features=20,</div>
<div class="line"><span class="lineno"> 1435</span>        n_informative=10,</div>
<div class="line"><span class="lineno"> 1436</span>        n_redundant=0,</div>
<div class="line"><span class="lineno"> 1437</span>        n_repeated=0,</div>
<div class="line"><span class="lineno"> 1438</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1439</span>    )</div>
<div class="line"><span class="lineno"> 1440</span>    X = scale(X)</div>
<div class="line"><span class="lineno"> 1441</span> </div>
<div class="line"><span class="lineno"> 1442</span>    lr_enet = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1443</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>,</div>
<div class="line"><span class="lineno"> 1444</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1445</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1446</span>        C=C,</div>
<div class="line"><span class="lineno"> 1447</span>        l1_ratio=l1_ratio,</div>
<div class="line"><span class="lineno"> 1448</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno"> 1449</span>    )</div>
<div class="line"><span class="lineno"> 1450</span>    lr_l2 = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1451</span>        penalty=<span class="stringliteral">&quot;l2&quot;</span>, solver=<span class="stringliteral">&quot;saga&quot;</span>, random_state=0, C=C, fit_intercept=<span class="keyword">False</span></div>
<div class="line"><span class="lineno"> 1452</span>    )</div>
<div class="line"><span class="lineno"> 1453</span>    lr_enet.fit(X, y)</div>
<div class="line"><span class="lineno"> 1454</span>    lr_l2.fit(X, y)</div>
<div class="line"><span class="lineno"> 1455</span> </div>
<div class="line"><span class="lineno"> 1456</span>    <span class="keyword">def </span>enet_objective(lr):</div>
<div class="line"><span class="lineno"> 1457</span>        coef = lr.coef_.ravel()</div>
<div class="line"><span class="lineno"> 1458</span>        obj = C * log_loss(y, lr.predict_proba(X))</div>
<div class="line"><span class="lineno"> 1459</span>        obj += l1_ratio * np.sum(np.abs(coef))</div>
<div class="line"><span class="lineno"> 1460</span>        obj += (1.0 - l1_ratio) * 0.5 * np.dot(coef, coef)</div>
<div class="line"><span class="lineno"> 1461</span>        <span class="keywordflow">return</span> obj</div>
<div class="line"><span class="lineno"> 1462</span> </div>
<div class="line"><span class="lineno"> 1463</span>    <span class="keyword">assert</span> enet_objective(lr_enet) &lt; enet_objective(lr_l2)</div>
<div class="line"><span class="lineno"> 1464</span> </div>
<div class="line"><span class="lineno"> 1465</span> </div>
<div class="line"><span class="lineno"> 1466</span><span class="preprocessor">@pytest.mark.parametrize(&quot;multi_class&quot;, (&quot;ovr&quot;, &quot;multinomial&quot;)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a8b840bb9a5d642e6f17337a4a029dad1" name="a8b840bb9a5d642e6f17337a4a029dad1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8b840bb9a5d642e6f17337a4a029dad1">&#9670;&#160;</a></span>test_logisticregression_liblinear_sample_weight()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logisticregression_liblinear_sample_weight </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>params</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1789</span><span class="keyword">def </span>test_logisticregression_liblinear_sample_weight(params):</div>
<div class="line"><span class="lineno"> 1790</span>    <span class="comment"># check that we support sample_weight with liblinear in all possible cases:</span></div>
<div class="line"><span class="lineno"> 1791</span>    <span class="comment"># l1-primal, l2-primal, l2-dual</span></div>
<div class="line"><span class="lineno"> 1792</span>    X = np.array(</div>
<div class="line"><span class="lineno"> 1793</span>        [</div>
<div class="line"><span class="lineno"> 1794</span>            [1, 3],</div>
<div class="line"><span class="lineno"> 1795</span>            [1, 3],</div>
<div class="line"><span class="lineno"> 1796</span>            [1, 3],</div>
<div class="line"><span class="lineno"> 1797</span>            [1, 3],</div>
<div class="line"><span class="lineno"> 1798</span>            [2, 1],</div>
<div class="line"><span class="lineno"> 1799</span>            [2, 1],</div>
<div class="line"><span class="lineno"> 1800</span>            [2, 1],</div>
<div class="line"><span class="lineno"> 1801</span>            [2, 1],</div>
<div class="line"><span class="lineno"> 1802</span>            [3, 3],</div>
<div class="line"><span class="lineno"> 1803</span>            [3, 3],</div>
<div class="line"><span class="lineno"> 1804</span>            [3, 3],</div>
<div class="line"><span class="lineno"> 1805</span>            [3, 3],</div>
<div class="line"><span class="lineno"> 1806</span>            [4, 1],</div>
<div class="line"><span class="lineno"> 1807</span>            [4, 1],</div>
<div class="line"><span class="lineno"> 1808</span>            [4, 1],</div>
<div class="line"><span class="lineno"> 1809</span>            [4, 1],</div>
<div class="line"><span class="lineno"> 1810</span>        ],</div>
<div class="line"><span class="lineno"> 1811</span>        dtype=np.dtype(<span class="stringliteral">&quot;float&quot;</span>),</div>
<div class="line"><span class="lineno"> 1812</span>    )</div>
<div class="line"><span class="lineno"> 1813</span>    y = np.array(</div>
<div class="line"><span class="lineno"> 1814</span>        [1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2], dtype=np.dtype(<span class="stringliteral">&quot;int&quot;</span>)</div>
<div class="line"><span class="lineno"> 1815</span>    )</div>
<div class="line"><span class="lineno"> 1816</span> </div>
<div class="line"><span class="lineno"> 1817</span>    X2 = np.vstack([X, X])</div>
<div class="line"><span class="lineno"> 1818</span>    y2 = np.hstack([y, 3 - y])</div>
<div class="line"><span class="lineno"> 1819</span>    sample_weight = np.ones(shape=len(y) * 2)</div>
<div class="line"><span class="lineno"> 1820</span>    sample_weight[len(y) :] = 0</div>
<div class="line"><span class="lineno"> 1821</span>    X2, y2, sample_weight = shuffle(X2, y2, sample_weight, random_state=0)</div>
<div class="line"><span class="lineno"> 1822</span> </div>
<div class="line"><span class="lineno"> 1823</span>    base_clf = LogisticRegression(solver=<span class="stringliteral">&quot;liblinear&quot;</span>, random_state=42)</div>
<div class="line"><span class="lineno"> 1824</span>    base_clf.set_params(**params)</div>
<div class="line"><span class="lineno"> 1825</span>    clf_no_weight = clone(base_clf).fit(X, y)</div>
<div class="line"><span class="lineno"> 1826</span>    clf_with_weight = clone(base_clf).fit(X2, y2, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1827</span> </div>
<div class="line"><span class="lineno"> 1828</span>    <span class="keywordflow">for</span> method <span class="keywordflow">in</span> (<span class="stringliteral">&quot;predict&quot;</span>, <span class="stringliteral">&quot;predict_proba&quot;</span>, <span class="stringliteral">&quot;decision_function&quot;</span>):</div>
<div class="line"><span class="lineno"> 1829</span>        X_clf_no_weight = getattr(clf_no_weight, method)(X)</div>
<div class="line"><span class="lineno"> 1830</span>        X_clf_with_weight = getattr(clf_with_weight, method)(X)</div>
<div class="line"><span class="lineno"> 1831</span>        assert_allclose(X_clf_no_weight, X_clf_with_weight)</div>
<div class="line"><span class="lineno"> 1832</span> </div>
<div class="line"><span class="lineno"> 1833</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7be590b24e759c6e8980cd5e94ca799f" name="a7be590b24e759c6e8980cd5e94ca799f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7be590b24e759c6e8980cd5e94ca799f">&#9670;&#160;</a></span>test_LogisticRegressionCV_elasticnet_attribute_shapes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_LogisticRegressionCV_elasticnet_attribute_shapes </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1583</span><span class="keyword">def </span>test_LogisticRegressionCV_elasticnet_attribute_shapes():</div>
<div class="line"><span class="lineno"> 1584</span>    <span class="comment"># Make sure the shapes of scores_ and coefs_paths_ attributes are correct</span></div>
<div class="line"><span class="lineno"> 1585</span>    <span class="comment"># when using elasticnet (added one dimension for l1_ratios)</span></div>
<div class="line"><span class="lineno"> 1586</span> </div>
<div class="line"><span class="lineno"> 1587</span>    n_classes = 3</div>
<div class="line"><span class="lineno"> 1588</span>    n_features = 20</div>
<div class="line"><span class="lineno"> 1589</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno"> 1590</span>        n_samples=200,</div>
<div class="line"><span class="lineno"> 1591</span>        n_classes=n_classes,</div>
<div class="line"><span class="lineno"> 1592</span>        n_informative=n_classes,</div>
<div class="line"><span class="lineno"> 1593</span>        n_features=n_features,</div>
<div class="line"><span class="lineno"> 1594</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1595</span>    )</div>
<div class="line"><span class="lineno"> 1596</span> </div>
<div class="line"><span class="lineno"> 1597</span>    Cs = np.logspace(-4, 4, 3)</div>
<div class="line"><span class="lineno"> 1598</span>    l1_ratios = np.linspace(0, 1, 2)</div>
<div class="line"><span class="lineno"> 1599</span> </div>
<div class="line"><span class="lineno"> 1600</span>    n_folds = 2</div>
<div class="line"><span class="lineno"> 1601</span>    lrcv = LogisticRegressionCV(</div>
<div class="line"><span class="lineno"> 1602</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>,</div>
<div class="line"><span class="lineno"> 1603</span>        Cs=Cs,</div>
<div class="line"><span class="lineno"> 1604</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1605</span>        cv=n_folds,</div>
<div class="line"><span class="lineno"> 1606</span>        l1_ratios=l1_ratios,</div>
<div class="line"><span class="lineno"> 1607</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno"> 1608</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1609</span>    )</div>
<div class="line"><span class="lineno"> 1610</span>    lrcv.fit(X, y)</div>
<div class="line"><span class="lineno"> 1611</span>    coefs_paths = np.asarray(list(lrcv.coefs_paths_.values()))</div>
<div class="line"><span class="lineno"> 1612</span>    <span class="keyword">assert</span> coefs_paths.shape == (</div>
<div class="line"><span class="lineno"> 1613</span>        n_classes,</div>
<div class="line"><span class="lineno"> 1614</span>        n_folds,</div>
<div class="line"><span class="lineno"> 1615</span>        Cs.size,</div>
<div class="line"><span class="lineno"> 1616</span>        l1_ratios.size,</div>
<div class="line"><span class="lineno"> 1617</span>        n_features + 1,</div>
<div class="line"><span class="lineno"> 1618</span>    )</div>
<div class="line"><span class="lineno"> 1619</span>    scores = np.asarray(list(lrcv.scores_.values()))</div>
<div class="line"><span class="lineno"> 1620</span>    <span class="keyword">assert</span> scores.shape == (n_classes, n_folds, Cs.size, l1_ratios.size)</div>
<div class="line"><span class="lineno"> 1621</span> </div>
<div class="line"><span class="lineno"> 1622</span>    <span class="keyword">assert</span> lrcv.n_iter_.shape == (n_classes, n_folds, Cs.size, l1_ratios.size)</div>
<div class="line"><span class="lineno"> 1623</span> </div>
<div class="line"><span class="lineno"> 1624</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a02d115de9cf0f823bc4f51fa64e480dd" name="a02d115de9cf0f823bc4f51fa64e480dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a02d115de9cf0f823bc4f51fa64e480dd">&#9670;&#160;</a></span>test_LogisticRegressionCV_GridSearchCV_elastic_net()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_LogisticRegressionCV_GridSearchCV_elastic_net </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1467</span><span class="keyword">def </span>test_LogisticRegressionCV_GridSearchCV_elastic_net(multi_class):</div>
<div class="line"><span class="lineno"> 1468</span>    <span class="comment"># make sure LogisticRegressionCV gives same best params (l1 and C) as</span></div>
<div class="line"><span class="lineno"> 1469</span>    <span class="comment"># GridSearchCV when penalty is elasticnet</span></div>
<div class="line"><span class="lineno"> 1470</span> </div>
<div class="line"><span class="lineno"> 1471</span>    <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;ovr&quot;</span>:</div>
<div class="line"><span class="lineno"> 1472</span>        <span class="comment"># This is actually binary classification, ovr multiclass is treated in</span></div>
<div class="line"><span class="lineno"> 1473</span>        <span class="comment"># test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr</span></div>
<div class="line"><span class="lineno"> 1474</span>        X, y = make_classification(random_state=0)</div>
<div class="line"><span class="lineno"> 1475</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1476</span>        X, y = make_classification(</div>
<div class="line"><span class="lineno"> 1477</span>            n_samples=100, n_classes=3, n_informative=3, random_state=0</div>
<div class="line"><span class="lineno"> 1478</span>        )</div>
<div class="line"><span class="lineno"> 1479</span> </div>
<div class="line"><span class="lineno"> 1480</span>    cv = StratifiedKFold(5)</div>
<div class="line"><span class="lineno"> 1481</span> </div>
<div class="line"><span class="lineno"> 1482</span>    l1_ratios = np.linspace(0, 1, 3)</div>
<div class="line"><span class="lineno"> 1483</span>    Cs = np.logspace(-4, 4, 3)</div>
<div class="line"><span class="lineno"> 1484</span> </div>
<div class="line"><span class="lineno"> 1485</span>    lrcv = LogisticRegressionCV(</div>
<div class="line"><span class="lineno"> 1486</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>,</div>
<div class="line"><span class="lineno"> 1487</span>        Cs=Cs,</div>
<div class="line"><span class="lineno"> 1488</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1489</span>        cv=cv,</div>
<div class="line"><span class="lineno"> 1490</span>        l1_ratios=l1_ratios,</div>
<div class="line"><span class="lineno"> 1491</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1492</span>        multi_class=multi_class,</div>
<div class="line"><span class="lineno"> 1493</span>    )</div>
<div class="line"><span class="lineno"> 1494</span>    lrcv.fit(X, y)</div>
<div class="line"><span class="lineno"> 1495</span> </div>
<div class="line"><span class="lineno"> 1496</span>    param_grid = {<span class="stringliteral">&quot;C&quot;</span>: Cs, <span class="stringliteral">&quot;l1_ratio&quot;</span>: l1_ratios}</div>
<div class="line"><span class="lineno"> 1497</span>    lr = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1498</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>, solver=<span class="stringliteral">&quot;saga&quot;</span>, random_state=0, multi_class=multi_class</div>
<div class="line"><span class="lineno"> 1499</span>    )</div>
<div class="line"><span class="lineno"> 1500</span>    gs = GridSearchCV(lr, param_grid, cv=cv)</div>
<div class="line"><span class="lineno"> 1501</span>    gs.fit(X, y)</div>
<div class="line"><span class="lineno"> 1502</span> </div>
<div class="line"><span class="lineno"> 1503</span>    <span class="keyword">assert</span> gs.best_params_[<span class="stringliteral">&quot;l1_ratio&quot;</span>] == lrcv.l1_ratio_[0]</div>
<div class="line"><span class="lineno"> 1504</span>    <span class="keyword">assert</span> gs.best_params_[<span class="stringliteral">&quot;C&quot;</span>] == lrcv.C_[0]</div>
<div class="line"><span class="lineno"> 1505</span> </div>
<div class="line"><span class="lineno"> 1506</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a60706e57ac99bc4d2284f588186a99a3" name="a60706e57ac99bc4d2284f588186a99a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a60706e57ac99bc4d2284f588186a99a3">&#9670;&#160;</a></span>test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1507</span><span class="keyword">def </span>test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr():</div>
<div class="line"><span class="lineno"> 1508</span>    <span class="comment"># make sure LogisticRegressionCV gives same best params (l1 and C) as</span></div>
<div class="line"><span class="lineno"> 1509</span>    <span class="comment"># GridSearchCV when penalty is elasticnet and multiclass is ovr. We can&#39;t</span></div>
<div class="line"><span class="lineno"> 1510</span>    <span class="comment"># compare best_params like in the previous test because</span></div>
<div class="line"><span class="lineno"> 1511</span>    <span class="comment"># LogisticRegressionCV with multi_class=&#39;ovr&#39; will have one C and one</span></div>
<div class="line"><span class="lineno"> 1512</span>    <span class="comment"># l1_param for each class, while LogisticRegression will share the</span></div>
<div class="line"><span class="lineno"> 1513</span>    <span class="comment"># parameters over the *n_classes* classifiers.</span></div>
<div class="line"><span class="lineno"> 1514</span> </div>
<div class="line"><span class="lineno"> 1515</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno"> 1516</span>        n_samples=100, n_classes=3, n_informative=3, random_state=0</div>
<div class="line"><span class="lineno"> 1517</span>    )</div>
<div class="line"><span class="lineno"> 1518</span>    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)</div>
<div class="line"><span class="lineno"> 1519</span>    cv = StratifiedKFold(5)</div>
<div class="line"><span class="lineno"> 1520</span> </div>
<div class="line"><span class="lineno"> 1521</span>    l1_ratios = np.linspace(0, 1, 3)</div>
<div class="line"><span class="lineno"> 1522</span>    Cs = np.logspace(-4, 4, 3)</div>
<div class="line"><span class="lineno"> 1523</span> </div>
<div class="line"><span class="lineno"> 1524</span>    lrcv = LogisticRegressionCV(</div>
<div class="line"><span class="lineno"> 1525</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>,</div>
<div class="line"><span class="lineno"> 1526</span>        Cs=Cs,</div>
<div class="line"><span class="lineno"> 1527</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1528</span>        cv=cv,</div>
<div class="line"><span class="lineno"> 1529</span>        l1_ratios=l1_ratios,</div>
<div class="line"><span class="lineno"> 1530</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1531</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno"> 1532</span>    )</div>
<div class="line"><span class="lineno"> 1533</span>    lrcv.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1534</span> </div>
<div class="line"><span class="lineno"> 1535</span>    param_grid = {<span class="stringliteral">&quot;C&quot;</span>: Cs, <span class="stringliteral">&quot;l1_ratio&quot;</span>: l1_ratios}</div>
<div class="line"><span class="lineno"> 1536</span>    lr = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1537</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>, solver=<span class="stringliteral">&quot;saga&quot;</span>, random_state=0, multi_class=<span class="stringliteral">&quot;ovr&quot;</span></div>
<div class="line"><span class="lineno"> 1538</span>    )</div>
<div class="line"><span class="lineno"> 1539</span>    gs = GridSearchCV(lr, param_grid, cv=cv)</div>
<div class="line"><span class="lineno"> 1540</span>    gs.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1541</span> </div>
<div class="line"><span class="lineno"> 1542</span>    <span class="comment"># Check that predictions are 80% the same</span></div>
<div class="line"><span class="lineno"> 1543</span>    <span class="keyword">assert</span> (lrcv.predict(X_train) == gs.predict(X_train)).mean() &gt;= 0.8</div>
<div class="line"><span class="lineno"> 1544</span>    <span class="keyword">assert</span> (lrcv.predict(X_test) == gs.predict(X_test)).mean() &gt;= 0.8</div>
<div class="line"><span class="lineno"> 1545</span> </div>
<div class="line"><span class="lineno"> 1546</span> </div>
<div class="line"><span class="lineno"> 1547</span><span class="preprocessor">@pytest.mark.parametrize(&quot;penalty&quot;, (&quot;l2&quot;, &quot;elasticnet&quot;)</span>)</div>
<div class="line"><span class="lineno"> 1548</span><span class="preprocessor">@pytest.mark.parametrize(&quot;multi_class&quot;, (&quot;ovr&quot;, &quot;multinomial&quot;, &quot;auto&quot;)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ac2c04007b276f5e2cb6a2b7e89f4ac2a" name="ac2c04007b276f5e2cb6a2b7e89f4ac2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac2c04007b276f5e2cb6a2b7e89f4ac2a">&#9670;&#160;</a></span>test_LogisticRegressionCV_no_refit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_LogisticRegressionCV_no_refit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>penalty</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1549</span><span class="keyword">def </span>test_LogisticRegressionCV_no_refit(penalty, multi_class):</div>
<div class="line"><span class="lineno"> 1550</span>    <span class="comment"># Test LogisticRegressionCV attribute shapes when refit is False</span></div>
<div class="line"><span class="lineno"> 1551</span> </div>
<div class="line"><span class="lineno"> 1552</span>    n_classes = 3</div>
<div class="line"><span class="lineno"> 1553</span>    n_features = 20</div>
<div class="line"><span class="lineno"> 1554</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno"> 1555</span>        n_samples=200,</div>
<div class="line"><span class="lineno"> 1556</span>        n_classes=n_classes,</div>
<div class="line"><span class="lineno"> 1557</span>        n_informative=n_classes,</div>
<div class="line"><span class="lineno"> 1558</span>        n_features=n_features,</div>
<div class="line"><span class="lineno"> 1559</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1560</span>    )</div>
<div class="line"><span class="lineno"> 1561</span> </div>
<div class="line"><span class="lineno"> 1562</span>    Cs = np.logspace(-4, 4, 3)</div>
<div class="line"><span class="lineno"> 1563</span>    <span class="keywordflow">if</span> penalty == <span class="stringliteral">&quot;elasticnet&quot;</span>:</div>
<div class="line"><span class="lineno"> 1564</span>        l1_ratios = np.linspace(0, 1, 2)</div>
<div class="line"><span class="lineno"> 1565</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1566</span>        l1_ratios = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1567</span> </div>
<div class="line"><span class="lineno"> 1568</span>    lrcv = LogisticRegressionCV(</div>
<div class="line"><span class="lineno"> 1569</span>        penalty=penalty,</div>
<div class="line"><span class="lineno"> 1570</span>        Cs=Cs,</div>
<div class="line"><span class="lineno"> 1571</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1572</span>        l1_ratios=l1_ratios,</div>
<div class="line"><span class="lineno"> 1573</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1574</span>        multi_class=multi_class,</div>
<div class="line"><span class="lineno"> 1575</span>        refit=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno"> 1576</span>    )</div>
<div class="line"><span class="lineno"> 1577</span>    lrcv.fit(X, y)</div>
<div class="line"><span class="lineno"> 1578</span>    <span class="keyword">assert</span> lrcv.C_.shape == (n_classes,)</div>
<div class="line"><span class="lineno"> 1579</span>    <span class="keyword">assert</span> lrcv.l1_ratio_.shape == (n_classes,)</div>
<div class="line"><span class="lineno"> 1580</span>    <span class="keyword">assert</span> lrcv.coef_.shape == (n_classes, n_features)</div>
<div class="line"><span class="lineno"> 1581</span> </div>
<div class="line"><span class="lineno"> 1582</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a39d9d368094b2af8602c8a5840df6723" name="a39d9d368094b2af8602c8a5840df6723"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a39d9d368094b2af8602c8a5840df6723">&#9670;&#160;</a></span>test_logreg_intercept_scaling_zero()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logreg_intercept_scaling_zero </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  937</span><span class="keyword">def </span>test_logreg_intercept_scaling_zero():</div>
<div class="line"><span class="lineno">  938</span>    <span class="comment"># Test that intercept_scaling is ignored when fit_intercept is False</span></div>
<div class="line"><span class="lineno">  939</span> </div>
<div class="line"><span class="lineno">  940</span>    clf = LogisticRegression(fit_intercept=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  941</span>    clf.fit(X, Y1)</div>
<div class="line"><span class="lineno">  942</span>    <span class="keyword">assert</span> clf.intercept_ == 0.0</div>
<div class="line"><span class="lineno">  943</span> </div>
<div class="line"><span class="lineno">  944</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a38e964766c54077dbee6db6b6bfc48b6" name="a38e964766c54077dbee6db6b6bfc48b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38e964766c54077dbee6db6b6bfc48b6">&#9670;&#160;</a></span>test_logreg_l1()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logreg_l1 </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  945</span><span class="keyword">def </span>test_logreg_l1():</div>
<div class="line"><span class="lineno">  946</span>    <span class="comment"># Because liblinear penalizes the intercept and saga does not, we do not</span></div>
<div class="line"><span class="lineno">  947</span>    <span class="comment"># fit the intercept to make it possible to compare the coefficients of</span></div>
<div class="line"><span class="lineno">  948</span>    <span class="comment"># the two models at convergence.</span></div>
<div class="line"><span class="lineno">  949</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno">  950</span>    n_samples = 50</div>
<div class="line"><span class="lineno">  951</span>    X, y = make_classification(n_samples=n_samples, n_features=20, random_state=0)</div>
<div class="line"><span class="lineno">  952</span>    X_noise = rng.normal(size=(n_samples, 3))</div>
<div class="line"><span class="lineno">  953</span>    X_constant = np.ones(shape=(n_samples, 2))</div>
<div class="line"><span class="lineno">  954</span>    X = np.concatenate((X, X_noise, X_constant), axis=1)</div>
<div class="line"><span class="lineno">  955</span>    lr_liblinear = LogisticRegression(</div>
<div class="line"><span class="lineno">  956</span>        penalty=<span class="stringliteral">&quot;l1&quot;</span>,</div>
<div class="line"><span class="lineno">  957</span>        C=1.0,</div>
<div class="line"><span class="lineno">  958</span>        solver=<span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno">  959</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  960</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  961</span>        tol=1e-10,</div>
<div class="line"><span class="lineno">  962</span>    )</div>
<div class="line"><span class="lineno">  963</span>    lr_liblinear.fit(X, y)</div>
<div class="line"><span class="lineno">  964</span> </div>
<div class="line"><span class="lineno">  965</span>    lr_saga = LogisticRegression(</div>
<div class="line"><span class="lineno">  966</span>        penalty=<span class="stringliteral">&quot;l1&quot;</span>,</div>
<div class="line"><span class="lineno">  967</span>        C=1.0,</div>
<div class="line"><span class="lineno">  968</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno">  969</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  970</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  971</span>        max_iter=1000,</div>
<div class="line"><span class="lineno">  972</span>        tol=1e-10,</div>
<div class="line"><span class="lineno">  973</span>    )</div>
<div class="line"><span class="lineno">  974</span>    lr_saga.fit(X, y)</div>
<div class="line"><span class="lineno">  975</span>    assert_array_almost_equal(lr_saga.coef_, lr_liblinear.coef_)</div>
<div class="line"><span class="lineno">  976</span> </div>
<div class="line"><span class="lineno">  977</span>    <span class="comment"># Noise and constant features should be regularized to zero by the l1</span></div>
<div class="line"><span class="lineno">  978</span>    <span class="comment"># penalty</span></div>
<div class="line"><span class="lineno">  979</span>    assert_array_almost_equal(lr_liblinear.coef_[0, -5:], np.zeros(5))</div>
<div class="line"><span class="lineno">  980</span>    assert_array_almost_equal(lr_saga.coef_[0, -5:], np.zeros(5))</div>
<div class="line"><span class="lineno">  981</span> </div>
<div class="line"><span class="lineno">  982</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="adaaf1a0153419d997581392d49ff9520" name="adaaf1a0153419d997581392d49ff9520"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adaaf1a0153419d997581392d49ff9520">&#9670;&#160;</a></span>test_logreg_l1_sparse_data()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logreg_l1_sparse_data </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  983</span><span class="keyword">def </span>test_logreg_l1_sparse_data():</div>
<div class="line"><span class="lineno">  984</span>    <span class="comment"># Because liblinear penalizes the intercept and saga does not, we do not</span></div>
<div class="line"><span class="lineno">  985</span>    <span class="comment"># fit the intercept to make it possible to compare the coefficients of</span></div>
<div class="line"><span class="lineno">  986</span>    <span class="comment"># the two models at convergence.</span></div>
<div class="line"><span class="lineno">  987</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno">  988</span>    n_samples = 50</div>
<div class="line"><span class="lineno">  989</span>    X, y = make_classification(n_samples=n_samples, n_features=20, random_state=0)</div>
<div class="line"><span class="lineno">  990</span>    X_noise = rng.normal(scale=0.1, size=(n_samples, 3))</div>
<div class="line"><span class="lineno">  991</span>    X_constant = np.zeros(shape=(n_samples, 2))</div>
<div class="line"><span class="lineno">  992</span>    X = np.concatenate((X, X_noise, X_constant), axis=1)</div>
<div class="line"><span class="lineno">  993</span>    X[X &lt; 1] = 0</div>
<div class="line"><span class="lineno">  994</span>    X = sparse.csr_matrix(X)</div>
<div class="line"><span class="lineno">  995</span> </div>
<div class="line"><span class="lineno">  996</span>    lr_liblinear = LogisticRegression(</div>
<div class="line"><span class="lineno">  997</span>        penalty=<span class="stringliteral">&quot;l1&quot;</span>,</div>
<div class="line"><span class="lineno">  998</span>        C=1.0,</div>
<div class="line"><span class="lineno">  999</span>        solver=<span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno"> 1000</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno"> 1001</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno"> 1002</span>        tol=1e-10,</div>
<div class="line"><span class="lineno"> 1003</span>    )</div>
<div class="line"><span class="lineno"> 1004</span>    lr_liblinear.fit(X, y)</div>
<div class="line"><span class="lineno"> 1005</span> </div>
<div class="line"><span class="lineno"> 1006</span>    lr_saga = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1007</span>        penalty=<span class="stringliteral">&quot;l1&quot;</span>,</div>
<div class="line"><span class="lineno"> 1008</span>        C=1.0,</div>
<div class="line"><span class="lineno"> 1009</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1010</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno"> 1011</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno"> 1012</span>        max_iter=1000,</div>
<div class="line"><span class="lineno"> 1013</span>        tol=1e-10,</div>
<div class="line"><span class="lineno"> 1014</span>    )</div>
<div class="line"><span class="lineno"> 1015</span>    lr_saga.fit(X, y)</div>
<div class="line"><span class="lineno"> 1016</span>    assert_array_almost_equal(lr_saga.coef_, lr_liblinear.coef_)</div>
<div class="line"><span class="lineno"> 1017</span>    <span class="comment"># Noise and constant features should be regularized to zero by the l1</span></div>
<div class="line"><span class="lineno"> 1018</span>    <span class="comment"># penalty</span></div>
<div class="line"><span class="lineno"> 1019</span>    assert_array_almost_equal(lr_liblinear.coef_[0, -5:], np.zeros(5))</div>
<div class="line"><span class="lineno"> 1020</span>    assert_array_almost_equal(lr_saga.coef_[0, -5:], np.zeros(5))</div>
<div class="line"><span class="lineno"> 1021</span> </div>
<div class="line"><span class="lineno"> 1022</span>    <span class="comment"># Check that solving on the sparse and dense data yield the same results</span></div>
<div class="line"><span class="lineno"> 1023</span>    lr_saga_dense = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1024</span>        penalty=<span class="stringliteral">&quot;l1&quot;</span>,</div>
<div class="line"><span class="lineno"> 1025</span>        C=1.0,</div>
<div class="line"><span class="lineno"> 1026</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1027</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno"> 1028</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno"> 1029</span>        max_iter=1000,</div>
<div class="line"><span class="lineno"> 1030</span>        tol=1e-10,</div>
<div class="line"><span class="lineno"> 1031</span>    )</div>
<div class="line"><span class="lineno"> 1032</span>    lr_saga_dense.fit(X.toarray(), y)</div>
<div class="line"><span class="lineno"> 1033</span>    assert_array_almost_equal(lr_saga.coef_, lr_saga_dense.coef_)</div>
<div class="line"><span class="lineno"> 1034</span> </div>
<div class="line"><span class="lineno"> 1035</span> </div>
<div class="line"><span class="lineno"> 1036</span><span class="preprocessor">@pytest.mark.parametrize(&quot;random_seed&quot;, [42])</span></div>
<div class="line"><span class="lineno"> 1037</span><span class="preprocessor">@pytest.mark.parametrize(&quot;penalty&quot;, [&quot;l1&quot;, &quot;l2&quot;])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a97bc78159a5598de578ab46d4438bfa0" name="a97bc78159a5598de578ab46d4438bfa0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a97bc78159a5598de578ab46d4438bfa0">&#9670;&#160;</a></span>test_logreg_predict_proba_multinomial()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_logreg_predict_proba_multinomial </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1062</span><span class="keyword">def </span>test_logreg_predict_proba_multinomial():</div>
<div class="line"><span class="lineno"> 1063</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno"> 1064</span>        n_samples=10, n_features=20, random_state=0, n_classes=3, n_informative=10</div>
<div class="line"><span class="lineno"> 1065</span>    )</div>
<div class="line"><span class="lineno"> 1066</span> </div>
<div class="line"><span class="lineno"> 1067</span>    <span class="comment"># Predicted probabilities using the true-entropy loss should give a</span></div>
<div class="line"><span class="lineno"> 1068</span>    <span class="comment"># smaller loss than those using the ovr method.</span></div>
<div class="line"><span class="lineno"> 1069</span>    clf_multi = LogisticRegression(multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, solver=<span class="stringliteral">&quot;lbfgs&quot;</span>)</div>
<div class="line"><span class="lineno"> 1070</span>    clf_multi.fit(X, y)</div>
<div class="line"><span class="lineno"> 1071</span>    clf_multi_loss = log_loss(y, clf_multi.predict_proba(X))</div>
<div class="line"><span class="lineno"> 1072</span>    clf_ovr = LogisticRegression(multi_class=<span class="stringliteral">&quot;ovr&quot;</span>, solver=<span class="stringliteral">&quot;lbfgs&quot;</span>)</div>
<div class="line"><span class="lineno"> 1073</span>    clf_ovr.fit(X, y)</div>
<div class="line"><span class="lineno"> 1074</span>    clf_ovr_loss = log_loss(y, clf_ovr.predict_proba(X))</div>
<div class="line"><span class="lineno"> 1075</span>    <span class="keyword">assert</span> clf_ovr_loss &gt; clf_multi_loss</div>
<div class="line"><span class="lineno"> 1076</span> </div>
<div class="line"><span class="lineno"> 1077</span>    <span class="comment"># Predicted probabilities using the soft-max function should give a</span></div>
<div class="line"><span class="lineno"> 1078</span>    <span class="comment"># smaller loss than those using the logistic function.</span></div>
<div class="line"><span class="lineno"> 1079</span>    clf_multi_loss = log_loss(y, clf_multi.predict_proba(X))</div>
<div class="line"><span class="lineno"> 1080</span>    clf_wrong_loss = log_loss(y, clf_multi._predict_proba_lr(X))</div>
<div class="line"><span class="lineno"> 1081</span>    <span class="keyword">assert</span> clf_wrong_loss &gt; clf_multi_loss</div>
<div class="line"><span class="lineno"> 1082</span> </div>
<div class="line"><span class="lineno"> 1083</span> </div>
<div class="line"><span class="lineno"> 1084</span><span class="preprocessor">@pytest.mark.parametrize(&quot;max_iter&quot;, np.arange(1, 5)</span>)</div>
<div class="line"><span class="lineno"> 1085</span><span class="preprocessor">@pytest.mark.parametrize(&quot;multi_class&quot;, [&quot;ovr&quot;, &quot;multinomial&quot;])</span></div>
<div class="line"><span class="lineno"> 1086</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1087</span>    <span class="stringliteral">&quot;solver, message&quot;</span>,</div>
<div class="line"><span class="lineno"> 1088</span>    [</div>
<div class="line"><span class="lineno"> 1089</span>        (</div>
<div class="line"><span class="lineno"> 1090</span>            <span class="stringliteral">&quot;newton-cg&quot;</span>,</div>
<div class="line"><span class="lineno"> 1091</span>            <span class="stringliteral">&quot;newton-cg failed to converge. Increase the number of iterations.&quot;</span>,</div>
<div class="line"><span class="lineno"> 1092</span>        ),</div>
<div class="line"><span class="lineno"> 1093</span>        (</div>
<div class="line"><span class="lineno"> 1094</span>            <span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno"> 1095</span>            <span class="stringliteral">&quot;Liblinear failed to converge, increase the number of iterations.&quot;</span>,</div>
<div class="line"><span class="lineno"> 1096</span>        ),</div>
<div class="line"><span class="lineno"> 1097</span>        (<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;The max_iter was reached which means the coef_ did not converge&quot;</span>),</div>
<div class="line"><span class="lineno"> 1098</span>        (<span class="stringliteral">&quot;saga&quot;</span>, <span class="stringliteral">&quot;The max_iter was reached which means the coef_ did not converge&quot;</span>),</div>
<div class="line"><span class="lineno"> 1099</span>        (<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;lbfgs failed to converge&quot;</span>),</div>
<div class="line"><span class="lineno"> 1100</span>        (<span class="stringliteral">&quot;newton-cholesky&quot;</span>, <span class="stringliteral">&quot;Newton solver did not converge after [0-9]* iterations&quot;</span>),</div>
<div class="line"><span class="lineno"> 1101</span>    ],</div>
<div class="line"><span class="lineno"> 1102</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a11bee06f84f1c3e05a1e5ae3c34e2d9e" name="a11bee06f84f1c3e05a1e5ae3c34e2d9e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a11bee06f84f1c3e05a1e5ae3c34e2d9e">&#9670;&#160;</a></span>test_lr_liblinear_warning()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_lr_liblinear_warning </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  108</span><span class="keyword">def </span>test_lr_liblinear_warning():</div>
<div class="line"><span class="lineno">  109</span>    n_samples, n_features = iris.data.shape</div>
<div class="line"><span class="lineno">  110</span>    target = iris.target_names[iris.target]</div>
<div class="line"><span class="lineno">  111</span> </div>
<div class="line"><span class="lineno">  112</span>    lr = LogisticRegression(solver=<span class="stringliteral">&quot;liblinear&quot;</span>, n_jobs=2)</div>
<div class="line"><span class="lineno">  113</span>    warning_message = (</div>
<div class="line"><span class="lineno">  114</span>        <span class="stringliteral">&quot;&#39;n_jobs&#39; &gt; 1 does not have any effect when&quot;</span></div>
<div class="line"><span class="lineno">  115</span>        <span class="stringliteral">&quot; &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39;&quot;</span></div>
<div class="line"><span class="lineno">  116</span>        <span class="stringliteral">&quot; = 2.&quot;</span></div>
<div class="line"><span class="lineno">  117</span>    )</div>
<div class="line"><span class="lineno">  118</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=warning_message):</div>
<div class="line"><span class="lineno">  119</span>        lr.fit(iris.data, target)</div>
<div class="line"><span class="lineno">  120</span> </div>
<div class="line"><span class="lineno">  121</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a472c25c6285608ccd9453cc46dc365a1" name="a472c25c6285608ccd9453cc46dc365a1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a472c25c6285608ccd9453cc46dc365a1">&#9670;&#160;</a></span>test_max_iter()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_max_iter </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>message</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1103</span><span class="keyword">def </span>test_max_iter(max_iter, multi_class, solver, message):</div>
<div class="line"><span class="lineno"> 1104</span>    <span class="comment"># Test that the maximum number of iteration is reached</span></div>
<div class="line"><span class="lineno"> 1105</span>    X, y_bin = iris.data, iris.target.copy()</div>
<div class="line"><span class="lineno"> 1106</span>    y_bin[y_bin == 2] = 0</div>
<div class="line"><span class="lineno"> 1107</span> </div>
<div class="line"><span class="lineno"> 1108</span>    <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> (<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>) <span class="keywordflow">and</span> multi_class == <span class="stringliteral">&quot;multinomial&quot;</span>:</div>
<div class="line"><span class="lineno"> 1109</span>        pytest.skip(<span class="stringliteral">&quot;&#39;multinomial&#39; is not supported by liblinear and newton-cholesky&quot;</span>)</div>
<div class="line"><span class="lineno"> 1110</span>    <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;newton-cholesky&quot;</span> <span class="keywordflow">and</span> max_iter &gt; 1:</div>
<div class="line"><span class="lineno"> 1111</span>        pytest.skip(<span class="stringliteral">&quot;solver newton-cholesky might converge very fast&quot;</span>)</div>
<div class="line"><span class="lineno"> 1112</span> </div>
<div class="line"><span class="lineno"> 1113</span>    lr = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1114</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno"> 1115</span>        tol=1e-15,</div>
<div class="line"><span class="lineno"> 1116</span>        multi_class=multi_class,</div>
<div class="line"><span class="lineno"> 1117</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1118</span>        solver=solver,</div>
<div class="line"><span class="lineno"> 1119</span>    )</div>
<div class="line"><span class="lineno"> 1120</span>    <span class="keyword">with</span> pytest.warns(ConvergenceWarning, match=message):</div>
<div class="line"><span class="lineno"> 1121</span>        lr.fit(X, y_bin)</div>
<div class="line"><span class="lineno"> 1122</span> </div>
<div class="line"><span class="lineno"> 1123</span>    <span class="keyword">assert</span> lr.n_iter_[0] == max_iter</div>
<div class="line"><span class="lineno"> 1124</span> </div>
<div class="line"><span class="lineno"> 1125</span> </div>
<div class="line"><span class="lineno"> 1126</span><span class="preprocessor">@pytest.mark.parametrize(&quot;solver&quot;, SOLVERS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aba93b75faf60c36b0cc5f2286db9091c" name="aba93b75faf60c36b0cc5f2286db9091c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba93b75faf60c36b0cc5f2286db9091c">&#9670;&#160;</a></span>test_multinomial_binary()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_multinomial_binary </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  222</span><span class="keyword">def </span>test_multinomial_binary(solver):</div>
<div class="line"><span class="lineno">  223</span>    <span class="comment"># Test multinomial LR on a binary problem.</span></div>
<div class="line"><span class="lineno">  224</span>    target = (iris.target &gt; 0).astype(np.intp)</div>
<div class="line"><span class="lineno">  225</span>    target = np.array([<span class="stringliteral">&quot;setosa&quot;</span>, <span class="stringliteral">&quot;not-setosa&quot;</span>])[target]</div>
<div class="line"><span class="lineno">  226</span> </div>
<div class="line"><span class="lineno">  227</span>    clf = LogisticRegression(</div>
<div class="line"><span class="lineno">  228</span>        solver=solver, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, random_state=42, max_iter=2000</div>
<div class="line"><span class="lineno">  229</span>    )</div>
<div class="line"><span class="lineno">  230</span>    clf.fit(iris.data, target)</div>
<div class="line"><span class="lineno">  231</span> </div>
<div class="line"><span class="lineno">  232</span>    <span class="keyword">assert</span> clf.coef_.shape == (1, iris.data.shape[1])</div>
<div class="line"><span class="lineno">  233</span>    <span class="keyword">assert</span> clf.intercept_.shape == (1,)</div>
<div class="line"><span class="lineno">  234</span>    assert_array_equal(clf.predict(iris.data), target)</div>
<div class="line"><span class="lineno">  235</span> </div>
<div class="line"><span class="lineno">  236</span>    mlr = LogisticRegression(</div>
<div class="line"><span class="lineno">  237</span>        solver=solver, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, random_state=42, fit_intercept=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  238</span>    )</div>
<div class="line"><span class="lineno">  239</span>    mlr.fit(iris.data, target)</div>
<div class="line"><span class="lineno">  240</span>    pred = clf.classes_[np.argmax(clf.predict_log_proba(iris.data), axis=1)]</div>
<div class="line"><span class="lineno">  241</span>    <span class="keyword">assert</span> np.mean(pred == target) &gt; 0.9</div>
<div class="line"><span class="lineno">  242</span> </div>
<div class="line"><span class="lineno">  243</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aae66b03afc8741b0f67977f3457e498b" name="aae66b03afc8741b0f67977f3457e498b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae66b03afc8741b0f67977f3457e498b">&#9670;&#160;</a></span>test_multinomial_binary_probabilities()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_multinomial_binary_probabilities </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  244</span><span class="keyword">def </span>test_multinomial_binary_probabilities():</div>
<div class="line"><span class="lineno">  245</span>    <span class="comment"># Test multinomial LR gives expected probabilities based on the</span></div>
<div class="line"><span class="lineno">  246</span>    <span class="comment"># decision function, for a binary problem.</span></div>
<div class="line"><span class="lineno">  247</span>    X, y = make_classification()</div>
<div class="line"><span class="lineno">  248</span>    clf = LogisticRegression(multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, solver=<span class="stringliteral">&quot;saga&quot;</span>)</div>
<div class="line"><span class="lineno">  249</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  250</span> </div>
<div class="line"><span class="lineno">  251</span>    decision = clf.decision_function(X)</div>
<div class="line"><span class="lineno">  252</span>    proba = clf.predict_proba(X)</div>
<div class="line"><span class="lineno">  253</span> </div>
<div class="line"><span class="lineno">  254</span>    expected_proba_class_1 = np.exp(decision) / (np.exp(decision) + np.exp(-decision))</div>
<div class="line"><span class="lineno">  255</span>    expected_proba = np.c_[1 - expected_proba_class_1, expected_proba_class_1]</div>
<div class="line"><span class="lineno">  256</span> </div>
<div class="line"><span class="lineno">  257</span>    assert_almost_equal(proba, expected_proba)</div>
<div class="line"><span class="lineno">  258</span> </div>
<div class="line"><span class="lineno">  259</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a756d4c9ca5efcd4746ea0eb7185dcec1" name="a756d4c9ca5efcd4746ea0eb7185dcec1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a756d4c9ca5efcd4746ea0eb7185dcec1">&#9670;&#160;</a></span>test_multinomial_identifiability_on_iris()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_multinomial_identifiability_on_iris </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test that the multinomial classification is identifiable.

A multinomial with c classes can be modeled with
probability_k = exp(X@coef_k) / sum(exp(X@coef_l), l=1..c) for k=1..c.
This is not identifiable, unless one chooses a further constraint.
According to [1], the maximum of the L2 penalized likelihood automatically
satisfies the symmetric constraint:
sum(coef_k, k=1..c) = 0

Further details can be found in [2].

Reference
---------
.. [1] :doi:`Zhu, Ji and Trevor J. Hastie. "Classification of gene microarrays by
       penalized logistic regression". Biostatistics 5 3 (2004): 427-43.
       &lt;10.1093/biostatistics/kxg046&gt;`

.. [2] :arxiv:`Noah Simon and Jerome Friedman and Trevor Hastie. (2013)
       "A Blockwise Descent Algorithm for Group-penalized Multiresponse and
       Multinomial Regression". &lt;1311.6529&gt;`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1875</span><span class="keyword">def </span>test_multinomial_identifiability_on_iris(fit_intercept):</div>
<div class="line"><span class="lineno"> 1876</span>    <span class="stringliteral">&quot;&quot;&quot;Test that the multinomial classification is identifiable.</span></div>
<div class="line"><span class="lineno"> 1877</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1878</span><span class="stringliteral">    A multinomial with c classes can be modeled with</span></div>
<div class="line"><span class="lineno"> 1879</span><span class="stringliteral">    probability_k = exp(X@coef_k) / sum(exp(X@coef_l), l=1..c) for k=1..c.</span></div>
<div class="line"><span class="lineno"> 1880</span><span class="stringliteral">    This is not identifiable, unless one chooses a further constraint.</span></div>
<div class="line"><span class="lineno"> 1881</span><span class="stringliteral">    According to [1], the maximum of the L2 penalized likelihood automatically</span></div>
<div class="line"><span class="lineno"> 1882</span><span class="stringliteral">    satisfies the symmetric constraint:</span></div>
<div class="line"><span class="lineno"> 1883</span><span class="stringliteral">    sum(coef_k, k=1..c) = 0</span></div>
<div class="line"><span class="lineno"> 1884</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1885</span><span class="stringliteral">    Further details can be found in [2].</span></div>
<div class="line"><span class="lineno"> 1886</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1887</span><span class="stringliteral">    Reference</span></div>
<div class="line"><span class="lineno"> 1888</span><span class="stringliteral">    ---------</span></div>
<div class="line"><span class="lineno"> 1889</span><span class="stringliteral">    .. [1] :doi:`Zhu, Ji and Trevor J. Hastie. &quot;Classification of gene microarrays by</span></div>
<div class="line"><span class="lineno"> 1890</span><span class="stringliteral">           penalized logistic regression&quot;. Biostatistics 5 3 (2004): 427-43.</span></div>
<div class="line"><span class="lineno"> 1891</span><span class="stringliteral">           &lt;10.1093/biostatistics/kxg046&gt;`</span></div>
<div class="line"><span class="lineno"> 1892</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1893</span><span class="stringliteral">    .. [2] :arxiv:`Noah Simon and Jerome Friedman and Trevor Hastie. (2013)</span></div>
<div class="line"><span class="lineno"> 1894</span><span class="stringliteral">           &quot;A Blockwise Descent Algorithm for Group-penalized Multiresponse and</span></div>
<div class="line"><span class="lineno"> 1895</span><span class="stringliteral">           Multinomial Regression&quot;. &lt;1311.6529&gt;`</span></div>
<div class="line"><span class="lineno"> 1896</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1897</span>    <span class="comment"># Test logistic regression with the iris dataset</span></div>
<div class="line"><span class="lineno"> 1898</span>    n_samples, n_features = iris.data.shape</div>
<div class="line"><span class="lineno"> 1899</span>    target = iris.target_names[iris.target]</div>
<div class="line"><span class="lineno"> 1900</span> </div>
<div class="line"><span class="lineno"> 1901</span>    clf = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1902</span>        C=len(iris.data),</div>
<div class="line"><span class="lineno"> 1903</span>        solver=<span class="stringliteral">&quot;lbfgs&quot;</span>,</div>
<div class="line"><span class="lineno"> 1904</span>        max_iter=300,</div>
<div class="line"><span class="lineno"> 1905</span>        multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>,</div>
<div class="line"><span class="lineno"> 1906</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno"> 1907</span>    )</div>
<div class="line"><span class="lineno"> 1908</span>    clf.fit(iris.data, target)</div>
<div class="line"><span class="lineno"> 1909</span> </div>
<div class="line"><span class="lineno"> 1910</span>    <span class="comment"># axis=0 is sum over classes</span></div>
<div class="line"><span class="lineno"> 1911</span>    assert_allclose(clf.coef_.sum(axis=0), 0, atol=1e-10)</div>
<div class="line"><span class="lineno"> 1912</span>    <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno"> 1913</span>        clf.intercept_.sum(axis=0) == pytest.approx(0, abs=1e-15)</div>
<div class="line"><span class="lineno"> 1914</span> </div>
<div class="line"><span class="lineno"> 1915</span> </div>
<div class="line"><span class="lineno"> 1916</span><span class="preprocessor">@pytest.mark.parametrize(&quot;multi_class&quot;, [&quot;ovr&quot;, &quot;multinomial&quot;, &quot;auto&quot;])</span></div>
<div class="line"><span class="lineno"> 1917</span><span class="preprocessor">@pytest.mark.parametrize(&quot;class_weight&quot;, [{0: 1.0, 1: 10.0, 2: 1.0}, &quot;balanced&quot;])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a3d668c26cf39586c330a1f7bb48ff232" name="a3d668c26cf39586c330a1f7bb48ff232"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3d668c26cf39586c330a1f7bb48ff232">&#9670;&#160;</a></span>test_multinomial_logistic_regression_string_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_multinomial_logistic_regression_string_inputs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  519</span><span class="keyword">def </span>test_multinomial_logistic_regression_string_inputs():</div>
<div class="line"><span class="lineno">  520</span>    <span class="comment"># Test with string labels for LogisticRegression(CV)</span></div>
<div class="line"><span class="lineno">  521</span>    n_samples, n_features, n_classes = 50, 5, 3</div>
<div class="line"><span class="lineno">  522</span>    X_ref, y = make_classification(</div>
<div class="line"><span class="lineno">  523</span>        n_samples=n_samples,</div>
<div class="line"><span class="lineno">  524</span>        n_features=n_features,</div>
<div class="line"><span class="lineno">  525</span>        n_classes=n_classes,</div>
<div class="line"><span class="lineno">  526</span>        n_informative=3,</div>
<div class="line"><span class="lineno">  527</span>        random_state=0,</div>
<div class="line"><span class="lineno">  528</span>    )</div>
<div class="line"><span class="lineno">  529</span>    y_str = LabelEncoder().fit([<span class="stringliteral">&quot;bar&quot;</span>, <span class="stringliteral">&quot;baz&quot;</span>, <span class="stringliteral">&quot;foo&quot;</span>]).inverse_transform(y)</div>
<div class="line"><span class="lineno">  530</span>    <span class="comment"># For numerical labels, let y values be taken from set (-1, 0, 1)</span></div>
<div class="line"><span class="lineno">  531</span>    y = np.array(y) - 1</div>
<div class="line"><span class="lineno">  532</span>    <span class="comment"># Test for string labels</span></div>
<div class="line"><span class="lineno">  533</span>    lr = LogisticRegression(multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>)</div>
<div class="line"><span class="lineno">  534</span>    lr_cv = LogisticRegressionCV(multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, Cs=3)</div>
<div class="line"><span class="lineno">  535</span>    lr_str = LogisticRegression(multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>)</div>
<div class="line"><span class="lineno">  536</span>    lr_cv_str = LogisticRegressionCV(multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, Cs=3)</div>
<div class="line"><span class="lineno">  537</span> </div>
<div class="line"><span class="lineno">  538</span>    lr.fit(X_ref, y)</div>
<div class="line"><span class="lineno">  539</span>    lr_cv.fit(X_ref, y)</div>
<div class="line"><span class="lineno">  540</span>    lr_str.fit(X_ref, y_str)</div>
<div class="line"><span class="lineno">  541</span>    lr_cv_str.fit(X_ref, y_str)</div>
<div class="line"><span class="lineno">  542</span> </div>
<div class="line"><span class="lineno">  543</span>    assert_array_almost_equal(lr.coef_, lr_str.coef_)</div>
<div class="line"><span class="lineno">  544</span>    <span class="keyword">assert</span> sorted(lr_str.classes_) == [<span class="stringliteral">&quot;bar&quot;</span>, <span class="stringliteral">&quot;baz&quot;</span>, <span class="stringliteral">&quot;foo&quot;</span>]</div>
<div class="line"><span class="lineno">  545</span>    assert_array_almost_equal(lr_cv.coef_, lr_cv_str.coef_)</div>
<div class="line"><span class="lineno">  546</span>    <span class="keyword">assert</span> sorted(lr_str.classes_) == [<span class="stringliteral">&quot;bar&quot;</span>, <span class="stringliteral">&quot;baz&quot;</span>, <span class="stringliteral">&quot;foo&quot;</span>]</div>
<div class="line"><span class="lineno">  547</span>    <span class="keyword">assert</span> sorted(lr_cv_str.classes_) == [<span class="stringliteral">&quot;bar&quot;</span>, <span class="stringliteral">&quot;baz&quot;</span>, <span class="stringliteral">&quot;foo&quot;</span>]</div>
<div class="line"><span class="lineno">  548</span> </div>
<div class="line"><span class="lineno">  549</span>    <span class="comment"># The predictions should be in original labels</span></div>
<div class="line"><span class="lineno">  550</span>    <span class="keyword">assert</span> sorted(np.unique(lr_str.predict(X_ref))) == [<span class="stringliteral">&quot;bar&quot;</span>, <span class="stringliteral">&quot;baz&quot;</span>, <span class="stringliteral">&quot;foo&quot;</span>]</div>
<div class="line"><span class="lineno">  551</span>    <span class="keyword">assert</span> sorted(np.unique(lr_cv_str.predict(X_ref))) == [<span class="stringliteral">&quot;bar&quot;</span>, <span class="stringliteral">&quot;baz&quot;</span>, <span class="stringliteral">&quot;foo&quot;</span>]</div>
<div class="line"><span class="lineno">  552</span> </div>
<div class="line"><span class="lineno">  553</span>    <span class="comment"># Make sure class weights can be given with string labels</span></div>
<div class="line"><span class="lineno">  554</span>    lr_cv_str = LogisticRegression(</div>
<div class="line"><span class="lineno">  555</span>        class_weight={<span class="stringliteral">&quot;bar&quot;</span>: 1, <span class="stringliteral">&quot;baz&quot;</span>: 2, <span class="stringliteral">&quot;foo&quot;</span>: 0}, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span></div>
<div class="line"><span class="lineno">  556</span>    ).fit(X_ref, y_str)</div>
<div class="line"><span class="lineno">  557</span>    <span class="keyword">assert</span> sorted(np.unique(lr_cv_str.predict(X_ref))) == [<span class="stringliteral">&quot;bar&quot;</span>, <span class="stringliteral">&quot;baz&quot;</span>]</div>
<div class="line"><span class="lineno">  558</span> </div>
<div class="line"><span class="lineno">  559</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6f114b87b3d22996af978ec41b975d7c" name="a6f114b87b3d22996af978ec41b975d7c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6f114b87b3d22996af978ec41b975d7c">&#9670;&#160;</a></span>test_n_iter()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_n_iter </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1127</span><span class="keyword">def </span>test_n_iter(solver):</div>
<div class="line"><span class="lineno"> 1128</span>    <span class="comment"># Test that self.n_iter_ has the correct format.</span></div>
<div class="line"><span class="lineno"> 1129</span>    X, y = iris.data, iris.target</div>
<div class="line"><span class="lineno"> 1130</span>    n_classes = np.unique(y).shape[0]</div>
<div class="line"><span class="lineno"> 1131</span>    <span class="keyword">assert</span> n_classes == 3</div>
<div class="line"><span class="lineno"> 1132</span> </div>
<div class="line"><span class="lineno"> 1133</span>    <span class="comment"># Also generate a binary classification sub-problem.</span></div>
<div class="line"><span class="lineno"> 1134</span>    y_bin = y.copy()</div>
<div class="line"><span class="lineno"> 1135</span>    y_bin[y_bin == 2] = 0</div>
<div class="line"><span class="lineno"> 1136</span> </div>
<div class="line"><span class="lineno"> 1137</span>    n_Cs = 4</div>
<div class="line"><span class="lineno"> 1138</span>    n_cv_fold = 2</div>
<div class="line"><span class="lineno"> 1139</span> </div>
<div class="line"><span class="lineno"> 1140</span>    <span class="comment"># Binary classification case</span></div>
<div class="line"><span class="lineno"> 1141</span>    clf = LogisticRegression(tol=1e-2, C=1.0, solver=solver, random_state=42)</div>
<div class="line"><span class="lineno"> 1142</span>    clf.fit(X, y_bin)</div>
<div class="line"><span class="lineno"> 1143</span>    <span class="keyword">assert</span> clf.n_iter_.shape == (1,)</div>
<div class="line"><span class="lineno"> 1144</span> </div>
<div class="line"><span class="lineno"> 1145</span>    clf_cv = LogisticRegressionCV(</div>
<div class="line"><span class="lineno"> 1146</span>        tol=1e-2, solver=solver, Cs=n_Cs, cv=n_cv_fold, random_state=42</div>
<div class="line"><span class="lineno"> 1147</span>    )</div>
<div class="line"><span class="lineno"> 1148</span>    clf_cv.fit(X, y_bin)</div>
<div class="line"><span class="lineno"> 1149</span>    <span class="keyword">assert</span> clf_cv.n_iter_.shape == (1, n_cv_fold, n_Cs)</div>
<div class="line"><span class="lineno"> 1150</span> </div>
<div class="line"><span class="lineno"> 1151</span>    <span class="comment"># OvR case</span></div>
<div class="line"><span class="lineno"> 1152</span>    clf.set_params(multi_class=<span class="stringliteral">&quot;ovr&quot;</span>).fit(X, y)</div>
<div class="line"><span class="lineno"> 1153</span>    <span class="keyword">assert</span> clf.n_iter_.shape == (n_classes,)</div>
<div class="line"><span class="lineno"> 1154</span> </div>
<div class="line"><span class="lineno"> 1155</span>    clf_cv.set_params(multi_class=<span class="stringliteral">&quot;ovr&quot;</span>).fit(X, y)</div>
<div class="line"><span class="lineno"> 1156</span>    <span class="keyword">assert</span> clf_cv.n_iter_.shape == (n_classes, n_cv_fold, n_Cs)</div>
<div class="line"><span class="lineno"> 1157</span> </div>
<div class="line"><span class="lineno"> 1158</span>    <span class="comment"># multinomial case</span></div>
<div class="line"><span class="lineno"> 1159</span>    <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> (<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>):</div>
<div class="line"><span class="lineno"> 1160</span>        <span class="comment"># This solver only supports one-vs-rest multiclass classification.</span></div>
<div class="line"><span class="lineno"> 1161</span>        <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno"> 1162</span> </div>
<div class="line"><span class="lineno"> 1163</span>    <span class="comment"># When using the multinomial objective function, there is a single</span></div>
<div class="line"><span class="lineno"> 1164</span>    <span class="comment"># optimization problem to solve for all classes at once:</span></div>
<div class="line"><span class="lineno"> 1165</span>    clf.set_params(multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>).fit(X, y)</div>
<div class="line"><span class="lineno"> 1166</span>    <span class="keyword">assert</span> clf.n_iter_.shape == (1,)</div>
<div class="line"><span class="lineno"> 1167</span> </div>
<div class="line"><span class="lineno"> 1168</span>    clf_cv.set_params(multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>).fit(X, y)</div>
<div class="line"><span class="lineno"> 1169</span>    <span class="keyword">assert</span> clf_cv.n_iter_.shape == (1, n_cv_fold, n_Cs)</div>
<div class="line"><span class="lineno"> 1170</span> </div>
<div class="line"><span class="lineno"> 1171</span> </div>
<div class="line"><span class="lineno"> 1172</span><span class="preprocessor">@pytest.mark.parametrize(&quot;solver&quot;, sorted(set(SOLVERS)</span> - set([<span class="stringliteral">&quot;liblinear&quot;</span>])))</div>
<div class="line"><span class="lineno"> 1173</span><span class="preprocessor">@pytest.mark.parametrize(&quot;warm_start&quot;, (True, False)</span>)</div>
<div class="line"><span class="lineno"> 1174</span><span class="preprocessor">@pytest.mark.parametrize(&quot;fit_intercept&quot;, (True, False)</span>)</div>
<div class="line"><span class="lineno"> 1175</span><span class="preprocessor">@pytest.mark.parametrize(&quot;multi_class&quot;, [&quot;ovr&quot;, &quot;multinomial&quot;])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ac96914f98643a39ee12ee8d8eefa554e" name="ac96914f98643a39ee12ee8d8eefa554e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac96914f98643a39ee12ee8d8eefa554e">&#9670;&#160;</a></span>test_nan()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_nan </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  312</span><span class="keyword">def </span>test_nan():</div>
<div class="line"><span class="lineno">  313</span>    <span class="comment"># Test proper NaN handling.</span></div>
<div class="line"><span class="lineno">  314</span>    <span class="comment"># Regression test for Issue #252: fit used to go into an infinite loop.</span></div>
<div class="line"><span class="lineno">  315</span>    Xnan = np.array(X, dtype=np.float64)</div>
<div class="line"><span class="lineno">  316</span>    Xnan[0, 1] = np.nan</div>
<div class="line"><span class="lineno">  317</span>    logistic = LogisticRegression(random_state=0)</div>
<div class="line"><span class="lineno">  318</span> </div>
<div class="line"><span class="lineno">  319</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  320</span>        logistic.fit(Xnan, Y1)</div>
<div class="line"><span class="lineno">  321</span> </div>
<div class="line"><span class="lineno">  322</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab3188867e9e7adb1be8ef5df661460bc" name="ab3188867e9e7adb1be8ef5df661460bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3188867e9e7adb1be8ef5df661460bc">&#9670;&#160;</a></span>test_ovr_multinomial_iris()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_ovr_multinomial_iris </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  574</span><span class="keyword">def </span>test_ovr_multinomial_iris():</div>
<div class="line"><span class="lineno">  575</span>    <span class="comment"># Test that OvR and multinomial are correct using the iris dataset.</span></div>
<div class="line"><span class="lineno">  576</span>    train, target = iris.data, iris.target</div>
<div class="line"><span class="lineno">  577</span>    n_samples, n_features = train.shape</div>
<div class="line"><span class="lineno">  578</span> </div>
<div class="line"><span class="lineno">  579</span>    <span class="comment"># The cv indices from stratified kfold (where stratification is done based</span></div>
<div class="line"><span class="lineno">  580</span>    <span class="comment"># on the fine-grained iris classes, i.e, before the classes 0 and 1 are</span></div>
<div class="line"><span class="lineno">  581</span>    <span class="comment"># conflated) is used for both clf and clf1</span></div>
<div class="line"><span class="lineno">  582</span>    n_cv = 2</div>
<div class="line"><span class="lineno">  583</span>    cv = StratifiedKFold(n_cv)</div>
<div class="line"><span class="lineno">  584</span>    precomputed_folds = list(cv.split(train, target))</div>
<div class="line"><span class="lineno">  585</span> </div>
<div class="line"><span class="lineno">  586</span>    <span class="comment"># Train clf on the original dataset where classes 0 and 1 are separated</span></div>
<div class="line"><span class="lineno">  587</span>    clf = LogisticRegressionCV(cv=precomputed_folds, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>)</div>
<div class="line"><span class="lineno">  588</span>    clf.fit(train, target)</div>
<div class="line"><span class="lineno">  589</span> </div>
<div class="line"><span class="lineno">  590</span>    <span class="comment"># Conflate classes 0 and 1 and train clf1 on this modified dataset</span></div>
<div class="line"><span class="lineno">  591</span>    clf1 = LogisticRegressionCV(cv=precomputed_folds, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>)</div>
<div class="line"><span class="lineno">  592</span>    target_copy = target.copy()</div>
<div class="line"><span class="lineno">  593</span>    target_copy[target_copy == 0] = 1</div>
<div class="line"><span class="lineno">  594</span>    clf1.fit(train, target_copy)</div>
<div class="line"><span class="lineno">  595</span> </div>
<div class="line"><span class="lineno">  596</span>    <span class="comment"># Ensure that what OvR learns for class2 is same regardless of whether</span></div>
<div class="line"><span class="lineno">  597</span>    <span class="comment"># classes 0 and 1 are separated or not</span></div>
<div class="line"><span class="lineno">  598</span>    assert_allclose(clf.scores_[2], clf1.scores_[2])</div>
<div class="line"><span class="lineno">  599</span>    assert_allclose(clf.intercept_[2:], clf1.intercept_)</div>
<div class="line"><span class="lineno">  600</span>    assert_allclose(clf.coef_[2][np.newaxis, :], clf1.coef_)</div>
<div class="line"><span class="lineno">  601</span> </div>
<div class="line"><span class="lineno">  602</span>    <span class="comment"># Test the shape of various attributes.</span></div>
<div class="line"><span class="lineno">  603</span>    <span class="keyword">assert</span> clf.coef_.shape == (3, n_features)</div>
<div class="line"><span class="lineno">  604</span>    assert_array_equal(clf.classes_, [0, 1, 2])</div>
<div class="line"><span class="lineno">  605</span>    coefs_paths = np.asarray(list(clf.coefs_paths_.values()))</div>
<div class="line"><span class="lineno">  606</span>    <span class="keyword">assert</span> coefs_paths.shape == (3, n_cv, 10, n_features + 1)</div>
<div class="line"><span class="lineno">  607</span>    <span class="keyword">assert</span> clf.Cs_.shape == (10,)</div>
<div class="line"><span class="lineno">  608</span>    scores = np.asarray(list(clf.scores_.values()))</div>
<div class="line"><span class="lineno">  609</span>    <span class="keyword">assert</span> scores.shape == (3, n_cv, 10)</div>
<div class="line"><span class="lineno">  610</span> </div>
<div class="line"><span class="lineno">  611</span>    <span class="comment"># Test that for the iris data multinomial gives a better accuracy than OvR</span></div>
<div class="line"><span class="lineno">  612</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>, <span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]:</div>
<div class="line"><span class="lineno">  613</span>        max_iter = 500 <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>] <span class="keywordflow">else</span> 15</div>
<div class="line"><span class="lineno">  614</span>        clf_multi = LogisticRegressionCV(</div>
<div class="line"><span class="lineno">  615</span>            solver=solver,</div>
<div class="line"><span class="lineno">  616</span>            multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>,</div>
<div class="line"><span class="lineno">  617</span>            max_iter=max_iter,</div>
<div class="line"><span class="lineno">  618</span>            random_state=42,</div>
<div class="line"><span class="lineno">  619</span>            tol=1e-3 <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>] <span class="keywordflow">else</span> 1e-2,</div>
<div class="line"><span class="lineno">  620</span>            cv=2,</div>
<div class="line"><span class="lineno">  621</span>        )</div>
<div class="line"><span class="lineno">  622</span>        clf_multi.fit(train, target)</div>
<div class="line"><span class="lineno">  623</span>        multi_score = clf_multi.score(train, target)</div>
<div class="line"><span class="lineno">  624</span>        ovr_score = clf.score(train, target)</div>
<div class="line"><span class="lineno">  625</span>        <span class="keyword">assert</span> multi_score &gt; ovr_score</div>
<div class="line"><span class="lineno">  626</span> </div>
<div class="line"><span class="lineno">  627</span>        <span class="comment"># Test attributes of LogisticRegressionCV</span></div>
<div class="line"><span class="lineno">  628</span>        <span class="keyword">assert</span> clf.coef_.shape == clf_multi.coef_.shape</div>
<div class="line"><span class="lineno">  629</span>        assert_array_equal(clf_multi.classes_, [0, 1, 2])</div>
<div class="line"><span class="lineno">  630</span>        coefs_paths = np.asarray(list(clf_multi.coefs_paths_.values()))</div>
<div class="line"><span class="lineno">  631</span>        <span class="keyword">assert</span> coefs_paths.shape == (3, n_cv, 10, n_features + 1)</div>
<div class="line"><span class="lineno">  632</span>        <span class="keyword">assert</span> clf_multi.Cs_.shape == (10,)</div>
<div class="line"><span class="lineno">  633</span>        scores = np.asarray(list(clf_multi.scores_.values()))</div>
<div class="line"><span class="lineno">  634</span>        <span class="keyword">assert</span> scores.shape == (3, n_cv, 10)</div>
<div class="line"><span class="lineno">  635</span> </div>
<div class="line"><span class="lineno">  636</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a86db358d880c6286ca1b5f5ed1ab46d5" name="a86db358d880c6286ca1b5f5ed1ab46d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a86db358d880c6286ca1b5f5ed1ab46d5">&#9670;&#160;</a></span>test_penalty_none()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_penalty_none </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1760</span><span class="keyword">def </span>test_penalty_none(solver):</div>
<div class="line"><span class="lineno"> 1761</span>    <span class="comment"># - Make sure warning is raised if penalty=None and C is set to a</span></div>
<div class="line"><span class="lineno"> 1762</span>    <span class="comment">#   non-default value.</span></div>
<div class="line"><span class="lineno"> 1763</span>    <span class="comment"># - Make sure setting penalty=None is equivalent to setting C=np.inf with</span></div>
<div class="line"><span class="lineno"> 1764</span>    <span class="comment">#   l2 penalty.</span></div>
<div class="line"><span class="lineno"> 1765</span>    X, y = make_classification(n_samples=1000, random_state=0)</div>
<div class="line"><span class="lineno"> 1766</span> </div>
<div class="line"><span class="lineno"> 1767</span>    msg = <span class="stringliteral">&quot;Setting penalty=None will ignore the C&quot;</span></div>
<div class="line"><span class="lineno"> 1768</span>    lr = LogisticRegression(penalty=<span class="keywordtype">None</span>, solver=solver, C=4)</div>
<div class="line"><span class="lineno"> 1769</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno"> 1770</span>        lr.fit(X, y)</div>
<div class="line"><span class="lineno"> 1771</span> </div>
<div class="line"><span class="lineno"> 1772</span>    lr_none = LogisticRegression(penalty=<span class="keywordtype">None</span>, solver=solver, random_state=0)</div>
<div class="line"><span class="lineno"> 1773</span>    lr_l2_C_inf = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1774</span>        penalty=<span class="stringliteral">&quot;l2&quot;</span>, C=np.inf, solver=solver, random_state=0</div>
<div class="line"><span class="lineno"> 1775</span>    )</div>
<div class="line"><span class="lineno"> 1776</span>    pred_none = lr_none.fit(X, y).predict(X)</div>
<div class="line"><span class="lineno"> 1777</span>    pred_l2_C_inf = lr_l2_C_inf.fit(X, y).predict(X)</div>
<div class="line"><span class="lineno"> 1778</span>    assert_array_equal(pred_none, pred_l2_C_inf)</div>
<div class="line"><span class="lineno"> 1779</span> </div>
<div class="line"><span class="lineno"> 1780</span> </div>
<div class="line"><span class="lineno"> 1781</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1782</span>    <span class="stringliteral">&quot;params&quot;</span>,</div>
<div class="line"><span class="lineno"> 1783</span>    [</div>
<div class="line"><span class="lineno"> 1784</span>        {<span class="stringliteral">&quot;penalty&quot;</span>: <span class="stringliteral">&quot;l1&quot;</span>, <span class="stringliteral">&quot;dual&quot;</span>: <span class="keyword">False</span>, <span class="stringliteral">&quot;tol&quot;</span>: 1e-12, <span class="stringliteral">&quot;max_iter&quot;</span>: 1000},</div>
<div class="line"><span class="lineno"> 1785</span>        {<span class="stringliteral">&quot;penalty&quot;</span>: <span class="stringliteral">&quot;l2&quot;</span>, <span class="stringliteral">&quot;dual&quot;</span>: <span class="keyword">True</span>, <span class="stringliteral">&quot;tol&quot;</span>: 1e-12, <span class="stringliteral">&quot;max_iter&quot;</span>: 1000},</div>
<div class="line"><span class="lineno"> 1786</span>        {<span class="stringliteral">&quot;penalty&quot;</span>: <span class="stringliteral">&quot;l2&quot;</span>, <span class="stringliteral">&quot;dual&quot;</span>: <span class="keyword">False</span>, <span class="stringliteral">&quot;tol&quot;</span>: 1e-12, <span class="stringliteral">&quot;max_iter&quot;</span>: 1000},</div>
<div class="line"><span class="lineno"> 1787</span>    ],</div>
<div class="line"><span class="lineno"> 1788</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a0f8af8ca03b87c1d1b79fda5dca398d6" name="a0f8af8ca03b87c1d1b79fda5dca398d6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f8af8ca03b87c1d1b79fda5dca398d6">&#9670;&#160;</a></span>test_predict_2_classes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_predict_2_classes </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   62</span><span class="keyword">def </span>test_predict_2_classes():</div>
<div class="line"><span class="lineno">   63</span>    <span class="comment"># Simple sanity check on a 2 classes dataset</span></div>
<div class="line"><span class="lineno">   64</span>    <span class="comment"># Make sure it predicts the correct result on simple datasets.</span></div>
<div class="line"><span class="lineno">   65</span>    check_predictions(LogisticRegression(random_state=0), X, Y1)</div>
<div class="line"><span class="lineno">   66</span>    check_predictions(LogisticRegression(random_state=0), X_sp, Y1)</div>
<div class="line"><span class="lineno">   67</span> </div>
<div class="line"><span class="lineno">   68</span>    check_predictions(LogisticRegression(C=100, random_state=0), X, Y1)</div>
<div class="line"><span class="lineno">   69</span>    check_predictions(LogisticRegression(C=100, random_state=0), X_sp, Y1)</div>
<div class="line"><span class="lineno">   70</span> </div>
<div class="line"><span class="lineno">   71</span>    check_predictions(LogisticRegression(fit_intercept=<span class="keyword">False</span>, random_state=0), X, Y1)</div>
<div class="line"><span class="lineno">   72</span>    check_predictions(LogisticRegression(fit_intercept=<span class="keyword">False</span>, random_state=0), X_sp, Y1)</div>
<div class="line"><span class="lineno">   73</span> </div>
<div class="line"><span class="lineno">   74</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6bce7db98ecf0a5def40f60a09226e86" name="a6bce7db98ecf0a5def40f60a09226e86"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6bce7db98ecf0a5def40f60a09226e86">&#9670;&#160;</a></span>test_predict_3_classes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_predict_3_classes </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  122</span><span class="keyword">def </span>test_predict_3_classes():</div>
<div class="line"><span class="lineno">  123</span>    check_predictions(LogisticRegression(C=10), X, Y2)</div>
<div class="line"><span class="lineno">  124</span>    check_predictions(LogisticRegression(C=10), X_sp, Y2)</div>
<div class="line"><span class="lineno">  125</span> </div>
<div class="line"><span class="lineno">  126</span> </div>
<div class="line"><span class="lineno">  127</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  128</span>    <span class="stringliteral">&quot;clf&quot;</span>,</div>
<div class="line"><span class="lineno">  129</span>    [</div>
<div class="line"><span class="lineno">  130</span>        LogisticRegression(C=len(iris.data), solver=<span class="stringliteral">&quot;liblinear&quot;</span>, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>),</div>
<div class="line"><span class="lineno">  131</span>        LogisticRegression(C=len(iris.data), solver=<span class="stringliteral">&quot;lbfgs&quot;</span>, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>),</div>
<div class="line"><span class="lineno">  132</span>        LogisticRegression(</div>
<div class="line"><span class="lineno">  133</span>            C=len(iris.data), solver=<span class="stringliteral">&quot;newton-cg&quot;</span>, multi_class=<span class="stringliteral">&quot;multinomial&quot;</span></div>
<div class="line"><span class="lineno">  134</span>        ),</div>
<div class="line"><span class="lineno">  135</span>        LogisticRegression(</div>
<div class="line"><span class="lineno">  136</span>            C=len(iris.data), solver=<span class="stringliteral">&quot;sag&quot;</span>, tol=1e-2, multi_class=<span class="stringliteral">&quot;ovr&quot;</span>, random_state=42</div>
<div class="line"><span class="lineno">  137</span>        ),</div>
<div class="line"><span class="lineno">  138</span>        LogisticRegression(</div>
<div class="line"><span class="lineno">  139</span>            C=len(iris.data),</div>
<div class="line"><span class="lineno">  140</span>            solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno">  141</span>            tol=1e-2,</div>
<div class="line"><span class="lineno">  142</span>            multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  143</span>            random_state=42,</div>
<div class="line"><span class="lineno">  144</span>        ),</div>
<div class="line"><span class="lineno">  145</span>        LogisticRegression(</div>
<div class="line"><span class="lineno">  146</span>            C=len(iris.data), solver=<span class="stringliteral">&quot;newton-cholesky&quot;</span>, multi_class=<span class="stringliteral">&quot;ovr&quot;</span></div>
<div class="line"><span class="lineno">  147</span>        ),</div>
<div class="line"><span class="lineno">  148</span>    ],</div>
<div class="line"><span class="lineno">  149</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a38553d322458ccc7f222fbcfb681f330" name="a38553d322458ccc7f222fbcfb681f330"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38553d322458ccc7f222fbcfb681f330">&#9670;&#160;</a></span>test_predict_iris()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_predict_iris </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clf</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test logistic regression with the iris dataset.

Test that both multinomial and OvR solvers handle multiclass data correctly and
give good accuracy score (&gt;0.95) for the training data.
</pre> <div class="fragment"><div class="line"><span class="lineno">  150</span><span class="keyword">def </span>test_predict_iris(clf):</div>
<div class="line"><span class="lineno">  151</span>    <span class="stringliteral">&quot;&quot;&quot;Test logistic regression with the iris dataset.</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">    Test that both multinomial and OvR solvers handle multiclass data correctly and</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">    give good accuracy score (&gt;0.95) for the training data.</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  156</span>    n_samples, n_features = iris.data.shape</div>
<div class="line"><span class="lineno">  157</span>    target = iris.target_names[iris.target]</div>
<div class="line"><span class="lineno">  158</span> </div>
<div class="line"><span class="lineno">  159</span>    <span class="keywordflow">if</span> clf.solver == <span class="stringliteral">&quot;lbfgs&quot;</span>:</div>
<div class="line"><span class="lineno">  160</span>        <span class="comment"># lbfgs has convergence issues on the iris data with its default max_iter=100</span></div>
<div class="line"><span class="lineno">  161</span>        <span class="keyword">with</span> warnings.catch_warnings():</div>
<div class="line"><span class="lineno">  162</span>            warnings.simplefilter(<span class="stringliteral">&quot;ignore&quot;</span>, ConvergenceWarning)</div>
<div class="line"><span class="lineno">  163</span>            clf.fit(iris.data, target)</div>
<div class="line"><span class="lineno">  164</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  165</span>        clf.fit(iris.data, target)</div>
<div class="line"><span class="lineno">  166</span>    assert_array_equal(np.unique(target), clf.classes_)</div>
<div class="line"><span class="lineno">  167</span> </div>
<div class="line"><span class="lineno">  168</span>    pred = clf.predict(iris.data)</div>
<div class="line"><span class="lineno">  169</span>    <span class="keyword">assert</span> np.mean(pred == target) &gt; 0.95</div>
<div class="line"><span class="lineno">  170</span> </div>
<div class="line"><span class="lineno">  171</span>    probabilities = clf.predict_proba(iris.data)</div>
<div class="line"><span class="lineno">  172</span>    assert_allclose(probabilities.sum(axis=1), np.ones(n_samples))</div>
<div class="line"><span class="lineno">  173</span> </div>
<div class="line"><span class="lineno">  174</span>    pred = iris.target_names[probabilities.argmax(axis=1)]</div>
<div class="line"><span class="lineno">  175</span>    <span class="keyword">assert</span> np.mean(pred == target) &gt; 0.95</div>
<div class="line"><span class="lineno">  176</span> </div>
<div class="line"><span class="lineno">  177</span> </div>
<div class="line"><span class="lineno">  178</span><span class="preprocessor">@pytest.mark.parametrize(&quot;LR&quot;, [LogisticRegression, LogisticRegressionCV])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab1ebdf9bf97bed6d41f2080774118643" name="ab1ebdf9bf97bed6d41f2080774118643"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1ebdf9bf97bed6d41f2080774118643">&#9670;&#160;</a></span>test_saga_sparse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_saga_sparse </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  929</span><span class="keyword">def </span>test_saga_sparse():</div>
<div class="line"><span class="lineno">  930</span>    <span class="comment"># Test LogRegCV with solver=&#39;liblinear&#39; works for sparse matrices</span></div>
<div class="line"><span class="lineno">  931</span> </div>
<div class="line"><span class="lineno">  932</span>    X, y = make_classification(n_samples=10, n_features=5, random_state=0)</div>
<div class="line"><span class="lineno">  933</span>    clf = LogisticRegressionCV(solver=<span class="stringliteral">&quot;saga&quot;</span>)</div>
<div class="line"><span class="lineno">  934</span>    clf.fit(sparse.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  935</span> </div>
<div class="line"><span class="lineno">  936</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a519565729c3bde29bffe808a6589dc19" name="a519565729c3bde29bffe808a6589dc19"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a519565729c3bde29bffe808a6589dc19">&#9670;&#160;</a></span>test_saga_vs_liblinear()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_saga_vs_liblinear </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1212</span><span class="keyword">def </span>test_saga_vs_liblinear():</div>
<div class="line"><span class="lineno"> 1213</span>    iris = load_iris()</div>
<div class="line"><span class="lineno"> 1214</span>    X, y = iris.data, iris.target</div>
<div class="line"><span class="lineno"> 1215</span>    X = np.concatenate([X] * 3)</div>
<div class="line"><span class="lineno"> 1216</span>    y = np.concatenate([y] * 3)</div>
<div class="line"><span class="lineno"> 1217</span> </div>
<div class="line"><span class="lineno"> 1218</span>    X_bin = X[y &lt;= 1]</div>
<div class="line"><span class="lineno"> 1219</span>    y_bin = y[y &lt;= 1] * 2 - 1</div>
<div class="line"><span class="lineno"> 1220</span> </div>
<div class="line"><span class="lineno"> 1221</span>    X_sparse, y_sparse = make_classification(</div>
<div class="line"><span class="lineno"> 1222</span>        n_samples=50, n_features=20, random_state=0</div>
<div class="line"><span class="lineno"> 1223</span>    )</div>
<div class="line"><span class="lineno"> 1224</span>    X_sparse = sparse.csr_matrix(X_sparse)</div>
<div class="line"><span class="lineno"> 1225</span> </div>
<div class="line"><span class="lineno"> 1226</span>    <span class="keywordflow">for</span> X, y <span class="keywordflow">in</span> ((X_bin, y_bin), (X_sparse, y_sparse)):</div>
<div class="line"><span class="lineno"> 1227</span>        <span class="keywordflow">for</span> penalty <span class="keywordflow">in</span> [<span class="stringliteral">&quot;l1&quot;</span>, <span class="stringliteral">&quot;l2&quot;</span>]:</div>
<div class="line"><span class="lineno"> 1228</span>            n_samples = X.shape[0]</div>
<div class="line"><span class="lineno"> 1229</span>            <span class="comment"># alpha=1e-3 is time consuming</span></div>
<div class="line"><span class="lineno"> 1230</span>            <span class="keywordflow">for</span> alpha <span class="keywordflow">in</span> np.logspace(-1, 1, 3):</div>
<div class="line"><span class="lineno"> 1231</span>                saga = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1232</span>                    C=1.0 / (n_samples * alpha),</div>
<div class="line"><span class="lineno"> 1233</span>                    solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1234</span>                    multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno"> 1235</span>                    max_iter=200,</div>
<div class="line"><span class="lineno"> 1236</span>                    fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno"> 1237</span>                    penalty=penalty,</div>
<div class="line"><span class="lineno"> 1238</span>                    random_state=0,</div>
<div class="line"><span class="lineno"> 1239</span>                    tol=1e-24,</div>
<div class="line"><span class="lineno"> 1240</span>                )</div>
<div class="line"><span class="lineno"> 1241</span> </div>
<div class="line"><span class="lineno"> 1242</span>                liblinear = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1243</span>                    C=1.0 / (n_samples * alpha),</div>
<div class="line"><span class="lineno"> 1244</span>                    solver=<span class="stringliteral">&quot;liblinear&quot;</span>,</div>
<div class="line"><span class="lineno"> 1245</span>                    multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno"> 1246</span>                    max_iter=200,</div>
<div class="line"><span class="lineno"> 1247</span>                    fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno"> 1248</span>                    penalty=penalty,</div>
<div class="line"><span class="lineno"> 1249</span>                    random_state=0,</div>
<div class="line"><span class="lineno"> 1250</span>                    tol=1e-24,</div>
<div class="line"><span class="lineno"> 1251</span>                )</div>
<div class="line"><span class="lineno"> 1252</span> </div>
<div class="line"><span class="lineno"> 1253</span>                saga.fit(X, y)</div>
<div class="line"><span class="lineno"> 1254</span>                liblinear.fit(X, y)</div>
<div class="line"><span class="lineno"> 1255</span>                <span class="comment"># Convergence for alpha=1e-3 is very slow</span></div>
<div class="line"><span class="lineno"> 1256</span>                assert_array_almost_equal(saga.coef_, liblinear.coef_, 3)</div>
<div class="line"><span class="lineno"> 1257</span> </div>
<div class="line"><span class="lineno"> 1258</span> </div>
<div class="line"><span class="lineno"> 1259</span><span class="preprocessor">@pytest.mark.parametrize(&quot;multi_class&quot;, [&quot;ovr&quot;, &quot;multinomial&quot;])</span></div>
<div class="line"><span class="lineno"> 1260</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1261</span>    <span class="stringliteral">&quot;solver&quot;</span>, [<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]</div>
<div class="line"><span class="lineno"> 1262</span>)</div>
<div class="line"><span class="lineno"> 1263</span><span class="preprocessor">@pytest.mark.parametrize(&quot;fit_intercept&quot;, [False, True])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a7511e56636c41857f0f6aa045e30669a" name="a7511e56636c41857f0f6aa045e30669a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7511e56636c41857f0f6aa045e30669a">&#9670;&#160;</a></span>test_sample_weight_not_modified()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_sample_weight_not_modified </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>class_weight</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1918</span><span class="keyword">def </span>test_sample_weight_not_modified(multi_class, class_weight):</div>
<div class="line"><span class="lineno"> 1919</span>    X, y = load_iris(return_X_y=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1920</span>    n_features = len(X)</div>
<div class="line"><span class="lineno"> 1921</span>    W = np.ones(n_features)</div>
<div class="line"><span class="lineno"> 1922</span>    W[: n_features // 2] = 2</div>
<div class="line"><span class="lineno"> 1923</span> </div>
<div class="line"><span class="lineno"> 1924</span>    expected = W.copy()</div>
<div class="line"><span class="lineno"> 1925</span> </div>
<div class="line"><span class="lineno"> 1926</span>    clf = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1927</span>        random_state=0, class_weight=class_weight, max_iter=200, multi_class=multi_class</div>
<div class="line"><span class="lineno"> 1928</span>    )</div>
<div class="line"><span class="lineno"> 1929</span>    clf.fit(X, y, sample_weight=W)</div>
<div class="line"><span class="lineno"> 1930</span>    assert_allclose(expected, W)</div>
<div class="line"><span class="lineno"> 1931</span> </div>
<div class="line"><span class="lineno"> 1932</span> </div>
<div class="line"><span class="lineno"> 1933</span><span class="preprocessor">@pytest.mark.parametrize(&quot;solver&quot;, SOLVERS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a14dc6088a692c88e64ec308b18735765" name="a14dc6088a692c88e64ec308b18735765"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a14dc6088a692c88e64ec308b18735765">&#9670;&#160;</a></span>test_scores_attribute_layout_elasticnet()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_scores_attribute_layout_elasticnet </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1834</span><span class="keyword">def </span>test_scores_attribute_layout_elasticnet():</div>
<div class="line"><span class="lineno"> 1835</span>    <span class="comment"># Non regression test for issue #14955.</span></div>
<div class="line"><span class="lineno"> 1836</span>    <span class="comment"># when penalty is elastic net the scores_ attribute has shape</span></div>
<div class="line"><span class="lineno"> 1837</span>    <span class="comment"># (n_classes, n_Cs, n_l1_ratios)</span></div>
<div class="line"><span class="lineno"> 1838</span>    <span class="comment"># We here make sure that the second dimension indeed corresponds to Cs and</span></div>
<div class="line"><span class="lineno"> 1839</span>    <span class="comment"># the third dimension corresponds to l1_ratios.</span></div>
<div class="line"><span class="lineno"> 1840</span> </div>
<div class="line"><span class="lineno"> 1841</span>    X, y = make_classification(n_samples=1000, random_state=0)</div>
<div class="line"><span class="lineno"> 1842</span>    cv = StratifiedKFold(n_splits=5)</div>
<div class="line"><span class="lineno"> 1843</span> </div>
<div class="line"><span class="lineno"> 1844</span>    l1_ratios = [0.1, 0.9]</div>
<div class="line"><span class="lineno"> 1845</span>    Cs = [0.1, 1, 10]</div>
<div class="line"><span class="lineno"> 1846</span> </div>
<div class="line"><span class="lineno"> 1847</span>    lrcv = LogisticRegressionCV(</div>
<div class="line"><span class="lineno"> 1848</span>        penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>,</div>
<div class="line"><span class="lineno"> 1849</span>        solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1850</span>        l1_ratios=l1_ratios,</div>
<div class="line"><span class="lineno"> 1851</span>        Cs=Cs,</div>
<div class="line"><span class="lineno"> 1852</span>        cv=cv,</div>
<div class="line"><span class="lineno"> 1853</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1854</span>    )</div>
<div class="line"><span class="lineno"> 1855</span>    lrcv.fit(X, y)</div>
<div class="line"><span class="lineno"> 1856</span> </div>
<div class="line"><span class="lineno"> 1857</span>    avg_scores_lrcv = lrcv.scores_[1].mean(axis=0)  <span class="comment"># average over folds</span></div>
<div class="line"><span class="lineno"> 1858</span> </div>
<div class="line"><span class="lineno"> 1859</span>    <span class="keywordflow">for</span> i, C <span class="keywordflow">in</span> enumerate(Cs):</div>
<div class="line"><span class="lineno"> 1860</span>        <span class="keywordflow">for</span> j, l1_ratio <span class="keywordflow">in</span> enumerate(l1_ratios):</div>
<div class="line"><span class="lineno"> 1861</span> </div>
<div class="line"><span class="lineno"> 1862</span>            lr = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1863</span>                penalty=<span class="stringliteral">&quot;elasticnet&quot;</span>,</div>
<div class="line"><span class="lineno"> 1864</span>                solver=<span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno"> 1865</span>                C=C,</div>
<div class="line"><span class="lineno"> 1866</span>                l1_ratio=l1_ratio,</div>
<div class="line"><span class="lineno"> 1867</span>                random_state=0,</div>
<div class="line"><span class="lineno"> 1868</span>            )</div>
<div class="line"><span class="lineno"> 1869</span> </div>
<div class="line"><span class="lineno"> 1870</span>            avg_score_lr = cross_val_score(lr, X, y, cv=cv).mean()</div>
<div class="line"><span class="lineno"> 1871</span>            <span class="keyword">assert</span> avg_scores_lrcv[i, j] == pytest.approx(avg_score_lr)</div>
<div class="line"><span class="lineno"> 1872</span> </div>
<div class="line"><span class="lineno"> 1873</span> </div>
<div class="line"><span class="lineno"> 1874</span><span class="preprocessor">@pytest.mark.parametrize(&quot;fit_intercept&quot;, [False, True])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a502cb4a4e691c3fa8c9c51561acb9ea5" name="a502cb4a4e691c3fa8c9c51561acb9ea5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a502cb4a4e691c3fa8c9c51561acb9ea5">&#9670;&#160;</a></span>test_single_feature_newton_cg()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_single_feature_newton_cg </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1952</span><span class="keyword">def </span>test_single_feature_newton_cg():</div>
<div class="line"><span class="lineno"> 1953</span>    <span class="comment"># Test that Newton-CG works with a single feature and intercept.</span></div>
<div class="line"><span class="lineno"> 1954</span>    <span class="comment"># Non-regression test for issue #23605.</span></div>
<div class="line"><span class="lineno"> 1955</span> </div>
<div class="line"><span class="lineno"> 1956</span>    X = np.array([[0.5, 0.65, 1.1, 1.25, 0.8, 0.54, 0.95, 0.7]]).T</div>
<div class="line"><span class="lineno"> 1957</span>    y = np.array([1, 1, 0, 0, 1, 1, 0, 1])</div>
<div class="line"><span class="lineno"> 1958</span>    <span class="keyword">assert</span> X.shape[1] == 1</div>
<div class="line"><span class="lineno"> 1959</span>    LogisticRegression(solver=<span class="stringliteral">&quot;newton-cg&quot;</span>, fit_intercept=<span class="keyword">True</span>).fit(X, y)</div>
<div class="line"><span class="lineno"> 1960</span> </div>
<div class="line"><span class="lineno"> 1961</span> </div>
<div class="line"><span class="lineno"> 1962</span><span class="comment"># TODO(1.4): Remove</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a6916a00b87758ee3c64053e6094ad67f" name="a6916a00b87758ee3c64053e6094ad67f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6916a00b87758ee3c64053e6094ad67f">&#9670;&#160;</a></span>test_sparsify()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_sparsify </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  260</span><span class="keyword">def </span>test_sparsify():</div>
<div class="line"><span class="lineno">  261</span>    <span class="comment"># Test sparsify and densify members.</span></div>
<div class="line"><span class="lineno">  262</span>    n_samples, n_features = iris.data.shape</div>
<div class="line"><span class="lineno">  263</span>    target = iris.target_names[iris.target]</div>
<div class="line"><span class="lineno">  264</span>    clf = LogisticRegression(random_state=0).fit(iris.data, target)</div>
<div class="line"><span class="lineno">  265</span> </div>
<div class="line"><span class="lineno">  266</span>    pred_d_d = clf.decision_function(iris.data)</div>
<div class="line"><span class="lineno">  267</span> </div>
<div class="line"><span class="lineno">  268</span>    clf.sparsify()</div>
<div class="line"><span class="lineno">  269</span>    <span class="keyword">assert</span> sparse.issparse(clf.coef_)</div>
<div class="line"><span class="lineno">  270</span>    pred_s_d = clf.decision_function(iris.data)</div>
<div class="line"><span class="lineno">  271</span> </div>
<div class="line"><span class="lineno">  272</span>    sp_data = sparse.coo_matrix(iris.data)</div>
<div class="line"><span class="lineno">  273</span>    pred_s_s = clf.decision_function(sp_data)</div>
<div class="line"><span class="lineno">  274</span> </div>
<div class="line"><span class="lineno">  275</span>    clf.densify()</div>
<div class="line"><span class="lineno">  276</span>    pred_d_s = clf.decision_function(sp_data)</div>
<div class="line"><span class="lineno">  277</span> </div>
<div class="line"><span class="lineno">  278</span>    assert_array_almost_equal(pred_d_d, pred_s_d)</div>
<div class="line"><span class="lineno">  279</span>    assert_array_almost_equal(pred_d_d, pred_s_s)</div>
<div class="line"><span class="lineno">  280</span>    assert_array_almost_equal(pred_d_d, pred_d_s)</div>
<div class="line"><span class="lineno">  281</span> </div>
<div class="line"><span class="lineno">  282</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac80a99790476a49d13f5540d796bdd36" name="ac80a99790476a49d13f5540d796bdd36"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac80a99790476a49d13f5540d796bdd36">&#9670;&#160;</a></span>test_warm_start()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_warm_start </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>warm_start</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1176</span><span class="keyword">def </span>test_warm_start(solver, warm_start, fit_intercept, multi_class):</div>
<div class="line"><span class="lineno"> 1177</span>    <span class="comment"># A 1-iteration second fit on same data should give almost same result</span></div>
<div class="line"><span class="lineno"> 1178</span>    <span class="comment"># with warm starting, and quite different result without warm starting.</span></div>
<div class="line"><span class="lineno"> 1179</span>    <span class="comment"># Warm starting does not work with liblinear solver.</span></div>
<div class="line"><span class="lineno"> 1180</span>    X, y = iris.data, iris.target</div>
<div class="line"><span class="lineno"> 1181</span> </div>
<div class="line"><span class="lineno"> 1182</span>    <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;newton-cholesky&quot;</span> <span class="keywordflow">and</span> multi_class == <span class="stringliteral">&quot;multinomial&quot;</span>:</div>
<div class="line"><span class="lineno"> 1183</span>        <span class="comment"># solver does only support OvR</span></div>
<div class="line"><span class="lineno"> 1184</span>        <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno"> 1185</span> </div>
<div class="line"><span class="lineno"> 1186</span>    clf = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1187</span>        tol=1e-4,</div>
<div class="line"><span class="lineno"> 1188</span>        multi_class=multi_class,</div>
<div class="line"><span class="lineno"> 1189</span>        warm_start=warm_start,</div>
<div class="line"><span class="lineno"> 1190</span>        solver=solver,</div>
<div class="line"><span class="lineno"> 1191</span>        random_state=42,</div>
<div class="line"><span class="lineno"> 1192</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno"> 1193</span>    )</div>
<div class="line"><span class="lineno"> 1194</span>    <span class="keyword">with</span> ignore_warnings(category=ConvergenceWarning):</div>
<div class="line"><span class="lineno"> 1195</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 1196</span>        coef_1 = clf.coef_</div>
<div class="line"><span class="lineno"> 1197</span> </div>
<div class="line"><span class="lineno"> 1198</span>        clf.max_iter = 1</div>
<div class="line"><span class="lineno"> 1199</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 1200</span>    cum_diff = np.sum(np.abs(coef_1 - clf.coef_))</div>
<div class="line"><span class="lineno"> 1201</span>    msg = (</div>
<div class="line"><span class="lineno"> 1202</span>        <span class="stringliteral">&quot;Warm starting issue with %s solver in %s mode &quot;</span></div>
<div class="line"><span class="lineno"> 1203</span>        <span class="stringliteral">&quot;with fit_intercept=%s and warm_start=%s&quot;</span></div>
<div class="line"><span class="lineno"> 1204</span>        % (solver, multi_class, str(fit_intercept), str(warm_start))</div>
<div class="line"><span class="lineno"> 1205</span>    )</div>
<div class="line"><span class="lineno"> 1206</span>    <span class="keywordflow">if</span> warm_start:</div>
<div class="line"><span class="lineno"> 1207</span>        <span class="keyword">assert</span> 2.0 &gt; cum_diff, msg</div>
<div class="line"><span class="lineno"> 1208</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1209</span>        <span class="keyword">assert</span> cum_diff &gt; 2.0, msg</div>
<div class="line"><span class="lineno"> 1210</span> </div>
<div class="line"><span class="lineno"> 1211</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4542dadcf84d48a505c214263d47059d" name="a4542dadcf84d48a505c214263d47059d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4542dadcf84d48a505c214263d47059d">&#9670;&#160;</a></span>test_warm_start_converge_LR()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_warm_start_converge_LR </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1336</span><span class="keyword">def </span>test_warm_start_converge_LR():</div>
<div class="line"><span class="lineno"> 1337</span>    <span class="comment"># Test to see that the logistic regression converges on warm start,</span></div>
<div class="line"><span class="lineno"> 1338</span>    <span class="comment"># with multi_class=&#39;multinomial&#39;. Non-regressive test for #10836</span></div>
<div class="line"><span class="lineno"> 1339</span> </div>
<div class="line"><span class="lineno"> 1340</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno"> 1341</span>    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))</div>
<div class="line"><span class="lineno"> 1342</span>    y = np.array([1] * 100 + [-1] * 100)</div>
<div class="line"><span class="lineno"> 1343</span>    lr_no_ws = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1344</span>        multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, solver=<span class="stringliteral">&quot;sag&quot;</span>, warm_start=<span class="keyword">False</span>, random_state=0</div>
<div class="line"><span class="lineno"> 1345</span>    )</div>
<div class="line"><span class="lineno"> 1346</span>    lr_ws = LogisticRegression(</div>
<div class="line"><span class="lineno"> 1347</span>        multi_class=<span class="stringliteral">&quot;multinomial&quot;</span>, solver=<span class="stringliteral">&quot;sag&quot;</span>, warm_start=<span class="keyword">True</span>, random_state=0</div>
<div class="line"><span class="lineno"> 1348</span>    )</div>
<div class="line"><span class="lineno"> 1349</span> </div>
<div class="line"><span class="lineno"> 1350</span>    lr_no_ws_loss = log_loss(y, lr_no_ws.fit(X, y).predict_proba(X))</div>
<div class="line"><span class="lineno"> 1351</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(5):</div>
<div class="line"><span class="lineno"> 1352</span>        lr_ws.fit(X, y)</div>
<div class="line"><span class="lineno"> 1353</span>    lr_ws_loss = log_loss(y, lr_ws.predict_proba(X))</div>
<div class="line"><span class="lineno"> 1354</span>    assert_allclose(lr_no_ws_loss, lr_ws_loss, rtol=1e-5)</div>
<div class="line"><span class="lineno"> 1355</span> </div>
<div class="line"><span class="lineno"> 1356</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad1d7598ce60d0309c6a66ea640008312" name="ad1d7598ce60d0309c6a66ea640008312"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad1d7598ce60d0309c6a66ea640008312">&#9670;&#160;</a></span>test_warning_on_penalty_string_none()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_warning_on_penalty_string_none </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1963</span><span class="keyword">def </span>test_warning_on_penalty_string_none():</div>
<div class="line"><span class="lineno"> 1964</span>    <span class="comment"># Test that warning message is shown when penalty=&#39;none&#39;</span></div>
<div class="line"><span class="lineno"> 1965</span>    target = iris.target_names[iris.target]</div>
<div class="line"><span class="lineno"> 1966</span>    lr = LogisticRegression(penalty=<span class="stringliteral">&quot;none&quot;</span>)</div>
<div class="line"><span class="lineno"> 1967</span>    warning_message = (</div>
<div class="line"><span class="lineno"> 1968</span>        <span class="stringliteral">&quot;`penalty=&#39;none&#39;`has been deprecated in 1.2 and will be removed in 1.4.&quot;</span></div>
<div class="line"><span class="lineno"> 1969</span>        <span class="stringliteral">&quot; To keep the past behaviour, set `penalty=None`.&quot;</span></div>
<div class="line"><span class="lineno"> 1970</span>    )</div>
<div class="line"><span class="lineno"> 1971</span>    <span class="keyword">with</span> pytest.warns(FutureWarning, match=warning_message):</div>
<div class="line"><span class="lineno"> 1972</span>        lr.fit(iris.data, target)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a53d29aa32d15f5154ec88d20a48458a9" name="a53d29aa32d15f5154ec88d20a48458a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a53d29aa32d15f5154ec88d20a48458a9">&#9670;&#160;</a></span>test_write_parameters()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.test_write_parameters </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  303</span><span class="keyword">def </span>test_write_parameters():</div>
<div class="line"><span class="lineno">  304</span>    <span class="comment"># Test that we can write to coef_ and intercept_</span></div>
<div class="line"><span class="lineno">  305</span>    clf = LogisticRegression(random_state=0)</div>
<div class="line"><span class="lineno">  306</span>    clf.fit(X, Y1)</div>
<div class="line"><span class="lineno">  307</span>    clf.coef_[:] = 0</div>
<div class="line"><span class="lineno">  308</span>    clf.intercept_[:] = 0</div>
<div class="line"><span class="lineno">  309</span>    assert_array_almost_equal(clf.decision_function(X), 0)</div>
<div class="line"><span class="lineno">  310</span> </div>
<div class="line"><span class="lineno">  311</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a8f2d9486092d28e97f280c0cdbf10840" name="a8f2d9486092d28e97f280c0cdbf10840"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8f2d9486092d28e97f280c0cdbf10840">&#9670;&#160;</a></span>calls</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.calls</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a511627da0a262cf43715760f02156b95" name="a511627da0a262cf43715760f02156b95"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a511627da0a262cf43715760f02156b95">&#9670;&#160;</a></span>iris</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.iris = load_iris()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2187c4003e0f93a1628e49b7d1364df4" name="a2187c4003e0f93a1628e49b7d1364df4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2187c4003e0f93a1628e49b7d1364df4">&#9670;&#160;</a></span>scores</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.scores</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aecc05e853f067e943a749c8bb105d03c" name="aecc05e853f067e943a749c8bb105d03c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aecc05e853f067e943a749c8bb105d03c">&#9670;&#160;</a></span>SOLVERS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple sklearn.linear_model.tests.test_logistic.SOLVERS = (&quot;lbfgs&quot;, &quot;liblinear&quot;, &quot;newton-cg&quot;, &quot;newton-cholesky&quot;, &quot;sag&quot;, &quot;saga&quot;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9a02178a87ba834f43ed4ebfe8602531" name="a9a02178a87ba834f43ed4ebfe8602531"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a02178a87ba834f43ed4ebfe8602531">&#9670;&#160;</a></span>X</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.linear_model.tests.test_logistic.X = [[-1, 0], [0, 1], [1, 1]]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a65302dd7f421789a3dc92a1c9ae4602a" name="a65302dd7f421789a3dc92a1c9ae4602a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65302dd7f421789a3dc92a1c9ae4602a">&#9670;&#160;</a></span>X_sp</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_logistic.X_sp = sparse.csr_matrix(<a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__logistic.html#a9a02178a87ba834f43ed4ebfe8602531">X</a>)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a92b78d569f60954ed46e4847b484ea2c" name="a92b78d569f60954ed46e4847b484ea2c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a92b78d569f60954ed46e4847b484ea2c">&#9670;&#160;</a></span>Y1</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.linear_model.tests.test_logistic.Y1 = [0, 1, 1]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6c50da982cb716f89bf541419ae1edd4" name="a6c50da982cb716f89bf541419ae1edd4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c50da982cb716f89bf541419ae1edd4">&#9670;&#160;</a></span>Y2</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.linear_model.tests.test_logistic.Y2 = [2, 1, 0]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
