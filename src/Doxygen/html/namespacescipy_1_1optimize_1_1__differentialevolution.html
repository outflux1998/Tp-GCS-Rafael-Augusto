<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: scipy.optimize._differentialevolution Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacescipy.html">scipy</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1optimize.html">optimize</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1optimize_1_1__differentialevolution.html">_differentialevolution</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">scipy.optimize._differentialevolution Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classscipy_1_1optimize_1_1__differentialevolution_1_1___constraint_wrapper.html">_ConstraintWrapper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classscipy_1_1optimize_1_1__differentialevolution_1_1_differential_evolution_solver.html">DifferentialEvolutionSolver</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a53e393ec24a4ce452e362f7722e48633" id="r_a53e393ec24a4ce452e362f7722e48633"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__differentialevolution.html#a53e393ec24a4ce452e362f7722e48633">differential_evolution</a> (<a class="el" href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a>, bounds, args=(), strategy='best1bin', maxiter=1000, popsize=15, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=0.01, mutation=(0.5, 1), recombination=0.7, seed=None, callback=None, disp=False, polish=True, init='latinhypercube', atol=0, updating='immediate', workers=1, constraints=(), x0=None, *integrality=None, vectorized=False)</td></tr>
<tr class="separator:a53e393ec24a4ce452e362f7722e48633"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:add8b5cd8d477453c1d90f8913194a065" id="r_add8b5cd8d477453c1d90f8913194a065"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__differentialevolution.html#add8b5cd8d477453c1d90f8913194a065">_MACHEPS</a> = np.finfo(np.float64).<a class="el" href="__lapack__subroutines_8h.html#a57833d05f43fd1408080af6eec88fc43">eps</a></td></tr>
<tr class="separator:add8b5cd8d477453c1d90f8913194a065"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">differential_evolution: The differential evolution global optimization algorithm
Added by Andrew Nelson 2014
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a53e393ec24a4ce452e362f7722e48633" name="a53e393ec24a4ce452e362f7722e48633"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a53e393ec24a4ce452e362f7722e48633">&#9670;&#160;</a></span>differential_evolution()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._differentialevolution.differential_evolution </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>func</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>bounds</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>args</em> = <code>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>strategy</em> = <code>'best1bin'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>maxiter</em> = <code>1000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>popsize</em> = <code>15</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>0.01</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mutation</em> = <code>(0.5,&#160;1)</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>recombination</em> = <code>0.7</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>seed</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>callback</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>disp</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>polish</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>init</em> = <code>'latinhypercube'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>atol</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>updating</em> = <code>'immediate'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>workers</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>constraints</em> = <code>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>integrality</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vectorized</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Finds the global minimum of a multivariate function.

Differential Evolution is stochastic in nature (does not use gradient
methods) to find the minimum, and can search large areas of candidate
space, but often requires larger numbers of function evaluations than
conventional gradient-based techniques.

The algorithm is due to Storn and Price [1]_.

Parameters
----------
func : callable
    The objective function to be minimized. Must be in the form
    ``f(x, *args)``, where ``x`` is the argument in the form of a 1-D array
    and ``args`` is a tuple of any additional fixed parameters needed to
    completely specify the function. The number of parameters, N, is equal
    to ``len(x)``.
bounds : sequence or `Bounds`
    Bounds for variables. There are two ways to specify the bounds:
    1. Instance of `Bounds` class.
    2. ``(min, max)`` pairs for each element in ``x``, defining the finite
    lower and upper bounds for the optimizing argument of `func`.
    The total number of bounds is used to determine the number of
    parameters, N.
args : tuple, optional
    Any additional fixed parameters needed to
    completely specify the objective function.
strategy : str, optional
    The differential evolution strategy to use. Should be one of:

        - 'best1bin'
        - 'best1exp'
        - 'rand1exp'
        - 'randtobest1exp'
        - 'currenttobest1exp'
        - 'best2exp'
        - 'rand2exp'
        - 'randtobest1bin'
        - 'currenttobest1bin'
        - 'best2bin'
        - 'rand2bin'
        - 'rand1bin'

    The default is 'best1bin'.
maxiter : int, optional
    The maximum number of generations over which the entire population is
    evolved. The maximum number of function evaluations (with no polishing)
    is: ``(maxiter + 1) * popsize * N``
popsize : int, optional
    A multiplier for setting the total population size. The population has
    ``popsize * N`` individuals. This keyword is overridden if an
    initial population is supplied via the `init` keyword. When using
    ``init='sobol'`` the population size is calculated as the next power
    of 2 after ``popsize * N``.
tol : float, optional
    Relative tolerance for convergence, the solving stops when
    ``np.std(pop) &lt;= atol + tol * np.abs(np.mean(population_energies))``,
    where and `atol` and `tol` are the absolute and relative tolerance
    respectively.
mutation : float or tuple(float, float), optional
    The mutation constant. In the literature this is also known as
    differential weight, being denoted by F.
    If specified as a float it should be in the range [0, 2].
    If specified as a tuple ``(min, max)`` dithering is employed. Dithering
    randomly changes the mutation constant on a generation by generation
    basis. The mutation constant for that generation is taken from
    ``U[min, max)``. Dithering can help speed convergence significantly.
    Increasing the mutation constant increases the search radius, but will
    slow down convergence.
recombination : float, optional
    The recombination constant, should be in the range [0, 1]. In the
    literature this is also known as the crossover probability, being
    denoted by CR. Increasing this value allows a larger number of mutants
    to progress into the next generation, but at the risk of population
    stability.
seed : {None, int, `numpy.random.Generator`,
        `numpy.random.RandomState`}, optional

    If `seed` is None (or `np.random`), the `numpy.random.RandomState`
    singleton is used.
    If `seed` is an int, a new ``RandomState`` instance is used,
    seeded with `seed`.
    If `seed` is already a ``Generator`` or ``RandomState`` instance then
    that instance is used.
    Specify `seed` for repeatable minimizations.
disp : bool, optional
    Prints the evaluated `func` at every iteration.
callback : callable, `callback(xk, convergence=val)`, optional
    A function to follow the progress of the minimization. ``xk`` is
    the best solution found so far. ``val`` represents the fractional
    value of the population convergence.  When ``val`` is greater than one
    the function halts. If callback returns `True`, then the minimization
    is halted (any polishing is still carried out).
polish : bool, optional
    If True (default), then `scipy.optimize.minimize` with the `L-BFGS-B`
    method is used to polish the best population member at the end, which
    can improve the minimization slightly. If a constrained problem is
    being studied then the `trust-constr` method is used instead.
init : str or array-like, optional
    Specify which type of population initialization is performed. Should be
    one of:

        - 'latinhypercube'
        - 'sobol'
        - 'halton'
        - 'random'
        - array specifying the initial population. The array should have
          shape ``(S, N)``, where S is the total population size and N is
          the number of parameters.
          `init` is clipped to `bounds` before use.

    The default is 'latinhypercube'. Latin Hypercube sampling tries to
    maximize coverage of the available parameter space.

    'sobol' and 'halton' are superior alternatives and maximize even more
    the parameter space. 'sobol' will enforce an initial population
    size which is calculated as the next power of 2 after
    ``popsize * N``. 'halton' has no requirements but is a bit less
    efficient. See `scipy.stats.qmc` for more details.

    'random' initializes the population randomly - this has the drawback
    that clustering can occur, preventing the whole of parameter space
    being covered. Use of an array to specify a population could be used,
    for example, to create a tight bunch of initial guesses in an location
    where the solution is known to exist, thereby reducing time for
    convergence.
atol : float, optional
    Absolute tolerance for convergence, the solving stops when
    ``np.std(pop) &lt;= atol + tol * np.abs(np.mean(population_energies))``,
    where and `atol` and `tol` are the absolute and relative tolerance
    respectively.
updating : {'immediate', 'deferred'}, optional
    If ``'immediate'``, the best solution vector is continuously updated
    within a single generation [4]_. This can lead to faster convergence as
    trial vectors can take advantage of continuous improvements in the best
    solution.
    With ``'deferred'``, the best solution vector is updated once per
    generation. Only ``'deferred'`` is compatible with parallelization or
    vectorization, and the `workers` and `vectorized` keywords can
    over-ride this option.

    .. versionadded:: 1.2.0

workers : int or map-like callable, optional
    If `workers` is an int the population is subdivided into `workers`
    sections and evaluated in parallel
    (uses `multiprocessing.Pool &lt;multiprocessing&gt;`).
    Supply -1 to use all available CPU cores.
    Alternatively supply a map-like callable, such as
    `multiprocessing.Pool.map` for evaluating the population in parallel.
    This evaluation is carried out as ``workers(func, iterable)``.
    This option will override the `updating` keyword to
    ``updating='deferred'`` if ``workers != 1``.
    This option overrides the `vectorized` keyword if ``workers != 1``.
    Requires that `func` be pickleable.

    .. versionadded:: 1.2.0

constraints : {NonLinearConstraint, LinearConstraint, Bounds}
    Constraints on the solver, over and above those applied by the `bounds`
    kwd. Uses the approach by Lampinen [5]_.

    .. versionadded:: 1.4.0

x0 : None or array-like, optional
    Provides an initial guess to the minimization. Once the population has
    been initialized this vector replaces the first (best) member. This
    replacement is done even if `init` is given an initial population.
    ``x0.shape == (N,)``.

    .. versionadded:: 1.7.0

integrality : 1-D array, optional
    For each decision variable, a boolean value indicating whether the
    decision variable is constrained to integer values. The array is
    broadcast to ``(N,)``.
    If any decision variables are constrained to be integral, they will not
    be changed during polishing.
    Only integer values lying between the lower and upper bounds are used.
    If there are no integer values lying between the bounds then a
    `ValueError` is raised.

    .. versionadded:: 1.9.0

vectorized : bool, optional
    If ``vectorized is True``, `func` is sent an `x` array with
    ``x.shape == (N, S)``, and is expected to return an array of shape
    ``(S,)``, where `S` is the number of solution vectors to be calculated.
    If constraints are applied, each of the functions used to construct
    a `Constraint` object should accept an `x` array with
    ``x.shape == (N, S)``, and return an array of shape ``(M, S)``, where
    `M` is the number of constraint components.
    This option is an alternative to the parallelization offered by
    `workers`, and may help in optimization speed by reducing interpreter
    overhead from multiple function calls. This keyword is ignored if
    ``workers != 1``.
    This option will override the `updating` keyword to
    ``updating='deferred'``.
    See the notes section for further discussion on when to use
    ``'vectorized'``, and when to use ``'workers'``.

    .. versionadded:: 1.9.0

Returns
-------
res : OptimizeResult
    The optimization result represented as a `OptimizeResult` object.
    Important attributes are: ``x`` the solution array, ``success`` a
    Boolean flag indicating if the optimizer exited successfully and
    ``message`` which describes the cause of the termination. See
    `OptimizeResult` for a description of other attributes. If `polish`
    was employed, and a lower minimum was obtained by the polishing, then
    OptimizeResult also contains the ``jac`` attribute.
    If the eventual solution does not satisfy the applied constraints
    ``success`` will be `False`.

Notes
-----
Differential evolution is a stochastic population based method that is
useful for global optimization problems. At each pass through the population
the algorithm mutates each candidate solution by mixing with other candidate
solutions to create a trial candidate. There are several strategies [2]_ for
creating trial candidates, which suit some problems more than others. The
'best1bin' strategy is a good starting point for many systems. In this
strategy two members of the population are randomly chosen. Their difference
is used to mutate the best member (the 'best' in 'best1bin'), :math:`b_0`,
so far:

.. math::

    b' = b_0 + mutation * (population[rand0] - population[rand1])

A trial vector is then constructed. Starting with a randomly chosen ith
parameter the trial is sequentially filled (in modulo) with parameters from
``b'`` or the original candidate. The choice of whether to use ``b'`` or the
original candidate is made with a binomial distribution (the 'bin' in
'best1bin') - a random number in [0, 1) is generated. If this number is
less than the `recombination` constant then the parameter is loaded from
``b'``, otherwise it is loaded from the original candidate. The final
parameter is always loaded from ``b'``. Once the trial candidate is built
its fitness is assessed. If the trial is better than the original candidate
then it takes its place. If it is also better than the best overall
candidate it also replaces that.
To improve your chances of finding a global minimum use higher `popsize`
values, with higher `mutation` and (dithering), but lower `recombination`
values. This has the effect of widening the search radius, but slowing
convergence.
By default the best solution vector is updated continuously within a single
iteration (``updating='immediate'``). This is a modification [4]_ of the
original differential evolution algorithm which can lead to faster
convergence as trial vectors can immediately benefit from improved
solutions. To use the original Storn and Price behaviour, updating the best
solution once per iteration, set ``updating='deferred'``.
The ``'deferred'`` approach is compatible with both parallelization and
vectorization (``'workers'`` and ``'vectorized'`` keywords). These may
improve minimization speed by using computer resources more efficiently.
The ``'workers'`` distribute calculations over multiple processors. By
default the Python `multiprocessing` module is used, but other approaches
are also possible, such as the Message Passing Interface (MPI) used on
clusters [6]_ [7]_. The overhead from these approaches (creating new
Processes, etc) may be significant, meaning that computational speed
doesn't necessarily scale with the number of processors used.
Parallelization is best suited to computationally expensive objective
functions. If the objective function is less expensive, then
``'vectorized'`` may aid by only calling the objective function once per
iteration, rather than multiple times for all the population members; the
interpreter overhead is reduced.

.. versionadded:: 0.15.0

Examples
--------
Let us consider the problem of minimizing the Rosenbrock function. This
function is implemented in `rosen` in `scipy.optimize`.

&gt;&gt;&gt; from scipy.optimize import rosen, differential_evolution
&gt;&gt;&gt; bounds = [(0,2), (0, 2), (0, 2), (0, 2), (0, 2)]
&gt;&gt;&gt; result = differential_evolution(rosen, bounds)
&gt;&gt;&gt; result.x, result.fun
(array([1., 1., 1., 1., 1.]), 1.9216496320061384e-19)

Now repeat, but with parallelization.

&gt;&gt;&gt; result = differential_evolution(rosen, bounds, updating='deferred',
...                                 workers=2)
&gt;&gt;&gt; result.x, result.fun
(array([1., 1., 1., 1., 1.]), 1.9216496320061384e-19)

Let's try and do a constrained minimization

&gt;&gt;&gt; from scipy.optimize import NonlinearConstraint, Bounds
&gt;&gt;&gt; def constr_f(x):
...     return np.array(x[0] + x[1])
&gt;&gt;&gt;
&gt;&gt;&gt; # the sum of x[0] and x[1] must be less than 1.9
&gt;&gt;&gt; nlc = NonlinearConstraint(constr_f, -np.inf, 1.9)
&gt;&gt;&gt; # specify limits using a `Bounds` object.
&gt;&gt;&gt; bounds = Bounds([0., 0.], [2., 2.])
&gt;&gt;&gt; result = differential_evolution(rosen, bounds, constraints=(nlc),
...                                 seed=1)
&gt;&gt;&gt; result.x, result.fun
(array([0.96633867, 0.93363577]), 0.0011361355854792312)

Next find the minimum of the Ackley function
(https://en.wikipedia.org/wiki/Test_functions_for_optimization).

&gt;&gt;&gt; from scipy.optimize import differential_evolution
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; def ackley(x):
...     arg1 = -0.2 * np.sqrt(0.5 * (x[0] ** 2 + x[1] ** 2))
...     arg2 = 0.5 * (np.cos(2. * np.pi * x[0]) + np.cos(2. * np.pi * x[1]))
...     return -20. * np.exp(arg1) - np.exp(arg2) + 20. + np.e
&gt;&gt;&gt; bounds = [(-5, 5), (-5, 5)]
&gt;&gt;&gt; result = differential_evolution(ackley, bounds, seed=1)
&gt;&gt;&gt; result.x, result.fun, result.nfev
(array([0., 0.]), 4.440892098500626e-16, 3063)

The Ackley function is written in a vectorized manner, so the
``'vectorized'`` keyword can be employed. Note the reduced number of
function evaluations.

&gt;&gt;&gt; result = differential_evolution(
...     ackley, bounds, vectorized=True, updating='deferred', seed=1
... )
&gt;&gt;&gt; result.x, result.fun, result.nfev
(array([0., 0.]), 4.440892098500626e-16, 190)

References
----------
.. [1] Storn, R and Price, K, Differential Evolution - a Simple and
       Efficient Heuristic for Global Optimization over Continuous Spaces,
       Journal of Global Optimization, 1997, 11, 341 - 359.
.. [2] http://www1.icsi.berkeley.edu/~storn/code.html
.. [3] http://en.wikipedia.org/wiki/Differential_evolution
.. [4] Wormington, M., Panaccione, C., Matney, K. M., Bowen, D. K., -
       Characterization of structures from X-ray scattering data using
       genetic algorithms, Phil. Trans. R. Soc. Lond. A, 1999, 357,
       2827-2848
.. [5] Lampinen, J., A constraint handling approach for the differential
       evolution algorithm. Proceedings of the 2002 Congress on
       Evolutionary Computation. CEC'02 (Cat. No. 02TH8600). Vol. 2. IEEE,
       2002.
.. [6] https://mpi4py.readthedocs.io/en/stable/
.. [7] https://schwimmbad.readthedocs.io/en/latest/
</pre> <div class="fragment"><div class="line"><span class="lineno">   28</span>                           integrality=<span class="keywordtype">None</span>, vectorized=<span class="keyword">False</span>):</div>
<div class="line"><span class="lineno">   29</span>    <span class="stringliteral">&quot;&quot;&quot;Finds the global minimum of a multivariate function.</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral">    Differential Evolution is stochastic in nature (does not use gradient</span></div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">    methods) to find the minimum, and can search large areas of candidate</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">    space, but often requires larger numbers of function evaluations than</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">    conventional gradient-based techniques.</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">    The algorithm is due to Storn and Price [1]_.</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">    func : callable</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">        The objective function to be minimized. Must be in the form</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral">        ``f(x, *args)``, where ``x`` is the argument in the form of a 1-D array</span></div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">        and ``args`` is a tuple of any additional fixed parameters needed to</span></div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">        completely specify the function. The number of parameters, N, is equal</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">        to ``len(x)``.</span></div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">    bounds : sequence or `Bounds`</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">        Bounds for variables. There are two ways to specify the bounds:</span></div>
<div class="line"><span class="lineno">   48</span><span class="stringliteral">        1. Instance of `Bounds` class.</span></div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral">        2. ``(min, max)`` pairs for each element in ``x``, defining the finite</span></div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">        lower and upper bounds for the optimizing argument of `func`.</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral">        The total number of bounds is used to determine the number of</span></div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">        parameters, N.</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">    args : tuple, optional</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral">        Any additional fixed parameters needed to</span></div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">        completely specify the objective function.</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral">    strategy : str, optional</span></div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral">        The differential evolution strategy to use. Should be one of:</span></div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">            - &#39;best1bin&#39;</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">            - &#39;best1exp&#39;</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral">            - &#39;rand1exp&#39;</span></div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">            - &#39;randtobest1exp&#39;</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">            - &#39;currenttobest1exp&#39;</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">            - &#39;best2exp&#39;</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">            - &#39;rand2exp&#39;</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">            - &#39;randtobest1bin&#39;</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">            - &#39;currenttobest1bin&#39;</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">            - &#39;best2bin&#39;</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral">            - &#39;rand2bin&#39;</span></div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">            - &#39;rand1bin&#39;</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">        The default is &#39;best1bin&#39;.</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">    maxiter : int, optional</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">        The maximum number of generations over which the entire population is</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">        evolved. The maximum number of function evaluations (with no polishing)</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">        is: ``(maxiter + 1) * popsize * N``</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    popsize : int, optional</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">        A multiplier for setting the total population size. The population has</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">        ``popsize * N`` individuals. This keyword is overridden if an</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">        initial population is supplied via the `init` keyword. When using</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral">        ``init=&#39;sobol&#39;`` the population size is calculated as the next power</span></div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">        of 2 after ``popsize * N``.</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">    tol : float, optional</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral">        Relative tolerance for convergence, the solving stops when</span></div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">        ``np.std(pop) &lt;= atol + tol * np.abs(np.mean(population_energies))``,</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">        where and `atol` and `tol` are the absolute and relative tolerance</span></div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">        respectively.</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">    mutation : float or tuple(float, float), optional</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">        The mutation constant. In the literature this is also known as</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">        differential weight, being denoted by F.</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">        If specified as a float it should be in the range [0, 2].</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral">        If specified as a tuple ``(min, max)`` dithering is employed. Dithering</span></div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral">        randomly changes the mutation constant on a generation by generation</span></div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral">        basis. The mutation constant for that generation is taken from</span></div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral">        ``U[min, max)``. Dithering can help speed convergence significantly.</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral">        Increasing the mutation constant increases the search radius, but will</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral">        slow down convergence.</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">    recombination : float, optional</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">        The recombination constant, should be in the range [0, 1]. In the</span></div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">        literature this is also known as the crossover probability, being</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">        denoted by CR. Increasing this value allows a larger number of mutants</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral">        to progress into the next generation, but at the risk of population</span></div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">        stability.</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">    seed : {None, int, `numpy.random.Generator`,</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral">            `numpy.random.RandomState`}, optional</span></div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral">        If `seed` is None (or `np.random`), the `numpy.random.RandomState`</span></div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">        singleton is used.</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">        If `seed` is an int, a new ``RandomState`` instance is used,</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral">        seeded with `seed`.</span></div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral">        If `seed` is already a ``Generator`` or ``RandomState`` instance then</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral">        that instance is used.</span></div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral">        Specify `seed` for repeatable minimizations.</span></div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">    disp : bool, optional</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">        Prints the evaluated `func` at every iteration.</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral">    callback : callable, `callback(xk, convergence=val)`, optional</span></div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">        A function to follow the progress of the minimization. ``xk`` is</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">        the best solution found so far. ``val`` represents the fractional</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral">        value of the population convergence.  When ``val`` is greater than one</span></div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral">        the function halts. If callback returns `True`, then the minimization</span></div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral">        is halted (any polishing is still carried out).</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">    polish : bool, optional</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">        If True (default), then `scipy.optimize.minimize` with the `L-BFGS-B`</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">        method is used to polish the best population member at the end, which</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral">        can improve the minimization slightly. If a constrained problem is</span></div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral">        being studied then the `trust-constr` method is used instead.</span></div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral">    init : str or array-like, optional</span></div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral">        Specify which type of population initialization is performed. Should be</span></div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral">        one of:</span></div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">            - &#39;latinhypercube&#39;</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral">            - &#39;sobol&#39;</span></div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">            - &#39;halton&#39;</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">            - &#39;random&#39;</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">            - array specifying the initial population. The array should have</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">              shape ``(S, N)``, where S is the total population size and N is</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">              the number of parameters.</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">              `init` is clipped to `bounds` before use.</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">        The default is &#39;latinhypercube&#39;. Latin Hypercube sampling tries to</span></div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">        maximize coverage of the available parameter space.</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">        &#39;sobol&#39; and &#39;halton&#39; are superior alternatives and maximize even more</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">        the parameter space. &#39;sobol&#39; will enforce an initial population</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">        size which is calculated as the next power of 2 after</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">        ``popsize * N``. &#39;halton&#39; has no requirements but is a bit less</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">        efficient. See `scipy.stats.qmc` for more details.</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">        &#39;random&#39; initializes the population randomly - this has the drawback</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">        that clustering can occur, preventing the whole of parameter space</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">        being covered. Use of an array to specify a population could be used,</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">        for example, to create a tight bunch of initial guesses in an location</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">        where the solution is known to exist, thereby reducing time for</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">        convergence.</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">    atol : float, optional</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">        Absolute tolerance for convergence, the solving stops when</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">        ``np.std(pop) &lt;= atol + tol * np.abs(np.mean(population_energies))``,</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">        where and `atol` and `tol` are the absolute and relative tolerance</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">        respectively.</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">    updating : {&#39;immediate&#39;, &#39;deferred&#39;}, optional</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">        If ``&#39;immediate&#39;``, the best solution vector is continuously updated</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">        within a single generation [4]_. This can lead to faster convergence as</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">        trial vectors can take advantage of continuous improvements in the best</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        solution.</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">        With ``&#39;deferred&#39;``, the best solution vector is updated once per</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">        generation. Only ``&#39;deferred&#39;`` is compatible with parallelization or</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">        vectorization, and the `workers` and `vectorized` keywords can</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">        over-ride this option.</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">        .. versionadded:: 1.2.0</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral">    workers : int or map-like callable, optional</span></div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">        If `workers` is an int the population is subdivided into `workers`</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">        sections and evaluated in parallel</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">        (uses `multiprocessing.Pool &lt;multiprocessing&gt;`).</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">        Supply -1 to use all available CPU cores.</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">        Alternatively supply a map-like callable, such as</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral">        `multiprocessing.Pool.map` for evaluating the population in parallel.</span></div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">        This evaluation is carried out as ``workers(func, iterable)``.</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">        This option will override the `updating` keyword to</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">        ``updating=&#39;deferred&#39;`` if ``workers != 1``.</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">        This option overrides the `vectorized` keyword if ``workers != 1``.</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">        Requires that `func` be pickleable.</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">        .. versionadded:: 1.2.0</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">    constraints : {NonLinearConstraint, LinearConstraint, Bounds}</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral">        Constraints on the solver, over and above those applied by the `bounds`</span></div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">        kwd. Uses the approach by Lampinen [5]_.</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral">        .. versionadded:: 1.4.0</span></div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral">    x0 : None or array-like, optional</span></div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">        Provides an initial guess to the minimization. Once the population has</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">        been initialized this vector replaces the first (best) member. This</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral">        replacement is done even if `init` is given an initial population.</span></div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral">        ``x0.shape == (N,)``.</span></div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">        .. versionadded:: 1.7.0</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral">    integrality : 1-D array, optional</span></div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral">        For each decision variable, a boolean value indicating whether the</span></div>
<div class="line"><span class="lineno">  203</span><span class="stringliteral">        decision variable is constrained to integer values. The array is</span></div>
<div class="line"><span class="lineno">  204</span><span class="stringliteral">        broadcast to ``(N,)``.</span></div>
<div class="line"><span class="lineno">  205</span><span class="stringliteral">        If any decision variables are constrained to be integral, they will not</span></div>
<div class="line"><span class="lineno">  206</span><span class="stringliteral">        be changed during polishing.</span></div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral">        Only integer values lying between the lower and upper bounds are used.</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">        If there are no integer values lying between the bounds then a</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">        `ValueError` is raised.</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">        .. versionadded:: 1.9.0</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral">    vectorized : bool, optional</span></div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">        If ``vectorized is True``, `func` is sent an `x` array with</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">        ``x.shape == (N, S)``, and is expected to return an array of shape</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">        ``(S,)``, where `S` is the number of solution vectors to be calculated.</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">        If constraints are applied, each of the functions used to construct</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">        a `Constraint` object should accept an `x` array with</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">        ``x.shape == (N, S)``, and return an array of shape ``(M, S)``, where</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">        `M` is the number of constraint components.</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">        This option is an alternative to the parallelization offered by</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">        `workers`, and may help in optimization speed by reducing interpreter</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">        overhead from multiple function calls. This keyword is ignored if</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">        ``workers != 1``.</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">        This option will override the `updating` keyword to</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">        ``updating=&#39;deferred&#39;``.</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">        See the notes section for further discussion on when to use</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">        ``&#39;vectorized&#39;``, and when to use ``&#39;workers&#39;``.</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">        .. versionadded:: 1.9.0</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">    res : OptimizeResult</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">        The optimization result represented as a `OptimizeResult` object.</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">        Important attributes are: ``x`` the solution array, ``success`` a</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">        Boolean flag indicating if the optimizer exited successfully and</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">        ``message`` which describes the cause of the termination. See</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        `OptimizeResult` for a description of other attributes. If `polish`</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">        was employed, and a lower minimum was obtained by the polishing, then</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">        OptimizeResult also contains the ``jac`` attribute.</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">        If the eventual solution does not satisfy the applied constraints</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">        ``success`` will be `False`.</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">    Differential evolution is a stochastic population based method that is</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">    useful for global optimization problems. At each pass through the population</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">    the algorithm mutates each candidate solution by mixing with other candidate</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">    solutions to create a trial candidate. There are several strategies [2]_ for</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">    creating trial candidates, which suit some problems more than others. The</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">    &#39;best1bin&#39; strategy is a good starting point for many systems. In this</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">    strategy two members of the population are randomly chosen. Their difference</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">    is used to mutate the best member (the &#39;best&#39; in &#39;best1bin&#39;), :math:`b_0`,</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">    so far:</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">    .. math::</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">        b&#39; = b_0 + mutation * (population[rand0] - population[rand1])</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">    A trial vector is then constructed. Starting with a randomly chosen ith</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">    parameter the trial is sequentially filled (in modulo) with parameters from</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">    ``b&#39;`` or the original candidate. The choice of whether to use ``b&#39;`` or the</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">    original candidate is made with a binomial distribution (the &#39;bin&#39; in</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">    &#39;best1bin&#39;) - a random number in [0, 1) is generated. If this number is</span></div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">    less than the `recombination` constant then the parameter is loaded from</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">    ``b&#39;``, otherwise it is loaded from the original candidate. The final</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">    parameter is always loaded from ``b&#39;``. Once the trial candidate is built</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral">    its fitness is assessed. If the trial is better than the original candidate</span></div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">    then it takes its place. If it is also better than the best overall</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">    candidate it also replaces that.</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral">    To improve your chances of finding a global minimum use higher `popsize`</span></div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">    values, with higher `mutation` and (dithering), but lower `recombination`</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral">    values. This has the effect of widening the search radius, but slowing</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">    convergence.</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">    By default the best solution vector is updated continuously within a single</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral">    iteration (``updating=&#39;immediate&#39;``). This is a modification [4]_ of the</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">    original differential evolution algorithm which can lead to faster</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">    convergence as trial vectors can immediately benefit from improved</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">    solutions. To use the original Storn and Price behaviour, updating the best</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    solution once per iteration, set ``updating=&#39;deferred&#39;``.</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">    The ``&#39;deferred&#39;`` approach is compatible with both parallelization and</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">    vectorization (``&#39;workers&#39;`` and ``&#39;vectorized&#39;`` keywords). These may</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">    improve minimization speed by using computer resources more efficiently.</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">    The ``&#39;workers&#39;`` distribute calculations over multiple processors. By</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">    default the Python `multiprocessing` module is used, but other approaches</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">    are also possible, such as the Message Passing Interface (MPI) used on</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">    clusters [6]_ [7]_. The overhead from these approaches (creating new</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">    Processes, etc) may be significant, meaning that computational speed</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">    doesn&#39;t necessarily scale with the number of processors used.</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">    Parallelization is best suited to computationally expensive objective</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">    functions. If the objective function is less expensive, then</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">    ``&#39;vectorized&#39;`` may aid by only calling the objective function once per</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">    iteration, rather than multiple times for all the population members; the</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">    interpreter overhead is reduced.</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">    .. versionadded:: 0.15.0</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">    Let us consider the problem of minimizing the Rosenbrock function. This</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">    function is implemented in `rosen` in `scipy.optimize`.</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.optimize import rosen, differential_evolution</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    &gt;&gt;&gt; bounds = [(0,2), (0, 2), (0, 2), (0, 2), (0, 2)]</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    &gt;&gt;&gt; result = differential_evolution(rosen, bounds)</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">    &gt;&gt;&gt; result.x, result.fun</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">    (array([1., 1., 1., 1., 1.]), 1.9216496320061384e-19)</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">    Now repeat, but with parallelization.</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">    &gt;&gt;&gt; result = differential_evolution(rosen, bounds, updating=&#39;deferred&#39;,</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">    ...                                 workers=2)</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral">    &gt;&gt;&gt; result.x, result.fun</span></div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">    (array([1., 1., 1., 1., 1.]), 1.9216496320061384e-19)</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral">    Let&#39;s try and do a constrained minimization</span></div>
<div class="line"><span class="lineno">  318</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  319</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.optimize import NonlinearConstraint, Bounds</span></div>
<div class="line"><span class="lineno">  320</span><span class="stringliteral">    &gt;&gt;&gt; def constr_f(x):</span></div>
<div class="line"><span class="lineno">  321</span><span class="stringliteral">    ...     return np.array(x[0] + x[1])</span></div>
<div class="line"><span class="lineno">  322</span><span class="stringliteral">    &gt;&gt;&gt;</span></div>
<div class="line"><span class="lineno">  323</span><span class="stringliteral">    &gt;&gt;&gt; # the sum of x[0] and x[1] must be less than 1.9</span></div>
<div class="line"><span class="lineno">  324</span><span class="stringliteral">    &gt;&gt;&gt; nlc = NonlinearConstraint(constr_f, -np.inf, 1.9)</span></div>
<div class="line"><span class="lineno">  325</span><span class="stringliteral">    &gt;&gt;&gt; # specify limits using a `Bounds` object.</span></div>
<div class="line"><span class="lineno">  326</span><span class="stringliteral">    &gt;&gt;&gt; bounds = Bounds([0., 0.], [2., 2.])</span></div>
<div class="line"><span class="lineno">  327</span><span class="stringliteral">    &gt;&gt;&gt; result = differential_evolution(rosen, bounds, constraints=(nlc),</span></div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral">    ...                                 seed=1)</span></div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">    &gt;&gt;&gt; result.x, result.fun</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">    (array([0.96633867, 0.93363577]), 0.0011361355854792312)</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">    Next find the minimum of the Ackley function</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral">    (https://en.wikipedia.org/wiki/Test_functions_for_optimization).</span></div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.optimize import differential_evolution</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral">    &gt;&gt;&gt; def ackley(x):</span></div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral">    ...     arg1 = -0.2 * np.sqrt(0.5 * (x[0] ** 2 + x[1] ** 2))</span></div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral">    ...     arg2 = 0.5 * (np.cos(2. * np.pi * x[0]) + np.cos(2. * np.pi * x[1]))</span></div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">    ...     return -20. * np.exp(arg1) - np.exp(arg2) + 20. + np.e</span></div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral">    &gt;&gt;&gt; bounds = [(-5, 5), (-5, 5)]</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral">    &gt;&gt;&gt; result = differential_evolution(ackley, bounds, seed=1)</span></div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral">    &gt;&gt;&gt; result.x, result.fun, result.nfev</span></div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">    (array([0., 0.]), 4.440892098500626e-16, 3063)</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">    The Ackley function is written in a vectorized manner, so the</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">    ``&#39;vectorized&#39;`` keyword can be employed. Note the reduced number of</span></div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral">    function evaluations.</span></div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">    &gt;&gt;&gt; result = differential_evolution(</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">    ...     ackley, bounds, vectorized=True, updating=&#39;deferred&#39;, seed=1</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral">    ... )</span></div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral">    &gt;&gt;&gt; result.x, result.fun, result.nfev</span></div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">    (array([0., 0.]), 4.440892098500626e-16, 190)</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral">    .. [1] Storn, R and Price, K, Differential Evolution - a Simple and</span></div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral">           Efficient Heuristic for Global Optimization over Continuous Spaces,</span></div>
<div class="line"><span class="lineno">  360</span><span class="stringliteral">           Journal of Global Optimization, 1997, 11, 341 - 359.</span></div>
<div class="line"><span class="lineno">  361</span><span class="stringliteral">    .. [2] http://www1.icsi.berkeley.edu/~storn/code.html</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral">    .. [3] http://en.wikipedia.org/wiki/Differential_evolution</span></div>
<div class="line"><span class="lineno">  363</span><span class="stringliteral">    .. [4] Wormington, M., Panaccione, C., Matney, K. M., Bowen, D. K., -</span></div>
<div class="line"><span class="lineno">  364</span><span class="stringliteral">           Characterization of structures from X-ray scattering data using</span></div>
<div class="line"><span class="lineno">  365</span><span class="stringliteral">           genetic algorithms, Phil. Trans. R. Soc. Lond. A, 1999, 357,</span></div>
<div class="line"><span class="lineno">  366</span><span class="stringliteral">           2827-2848</span></div>
<div class="line"><span class="lineno">  367</span><span class="stringliteral">    .. [5] Lampinen, J., A constraint handling approach for the differential</span></div>
<div class="line"><span class="lineno">  368</span><span class="stringliteral">           evolution algorithm. Proceedings of the 2002 Congress on</span></div>
<div class="line"><span class="lineno">  369</span><span class="stringliteral">           Evolutionary Computation. CEC&#39;02 (Cat. No. 02TH8600). Vol. 2. IEEE,</span></div>
<div class="line"><span class="lineno">  370</span><span class="stringliteral">           2002.</span></div>
<div class="line"><span class="lineno">  371</span><span class="stringliteral">    .. [6] https://mpi4py.readthedocs.io/en/stable/</span></div>
<div class="line"><span class="lineno">  372</span><span class="stringliteral">    .. [7] https://schwimmbad.readthedocs.io/en/latest/</span></div>
<div class="line"><span class="lineno">  373</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  374</span> </div>
<div class="line"><span class="lineno">  375</span>    <span class="comment"># using a context manager means that any created Pool objects are</span></div>
<div class="line"><span class="lineno">  376</span>    <span class="comment"># cleared up.</span></div>
<div class="line"><span class="lineno">  377</span>    <span class="keyword">with</span> DifferentialEvolutionSolver(func, bounds, args=args,</div>
<div class="line"><span class="lineno">  378</span>                                     strategy=strategy,</div>
<div class="line"><span class="lineno">  379</span>                                     maxiter=maxiter,</div>
<div class="line"><span class="lineno">  380</span>                                     popsize=popsize, tol=tol,</div>
<div class="line"><span class="lineno">  381</span>                                     mutation=mutation,</div>
<div class="line"><span class="lineno">  382</span>                                     recombination=recombination,</div>
<div class="line"><span class="lineno">  383</span>                                     seed=seed, polish=polish,</div>
<div class="line"><span class="lineno">  384</span>                                     callback=callback,</div>
<div class="line"><span class="lineno">  385</span>                                     disp=disp, init=init, atol=atol,</div>
<div class="line"><span class="lineno">  386</span>                                     updating=updating,</div>
<div class="line"><span class="lineno">  387</span>                                     workers=workers,</div>
<div class="line"><span class="lineno">  388</span>                                     constraints=constraints,</div>
<div class="line"><span class="lineno">  389</span>                                     x0=x0,</div>
<div class="line"><span class="lineno">  390</span>                                     integrality=integrality,</div>
<div class="line"><span class="lineno">  391</span>                                     vectorized=vectorized) <span class="keyword">as</span> solver:</div>
<div class="line"><span class="lineno">  392</span>        ret = solver.solve()</div>
<div class="line"><span class="lineno">  393</span> </div>
<div class="line"><span class="lineno">  394</span>    <span class="keywordflow">return</span> ret</div>
<div class="line"><span class="lineno">  395</span> </div>
<div class="line"><span class="lineno">  396</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="add8b5cd8d477453c1d90f8913194a065" name="add8b5cd8d477453c1d90f8913194a065"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add8b5cd8d477453c1d90f8913194a065">&#9670;&#160;</a></span>_MACHEPS</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._differentialevolution._MACHEPS = np.finfo(np.float64).<a class="el" href="__lapack__subroutines_8h.html#a57833d05f43fd1408080af6eec88fc43">eps</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
