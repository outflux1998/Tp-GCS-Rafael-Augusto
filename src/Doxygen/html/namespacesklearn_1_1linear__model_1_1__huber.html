<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.linear_model._huber Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model.html">linear_model</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model_1_1__huber.html">_huber</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.linear_model._huber Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__huber_1_1_huber_regressor.html">HuberRegressor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a5ac2f64944b5884919d526eda8b8202b" id="r_a5ac2f64944b5884919d526eda8b8202b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__huber.html#a5ac2f64944b5884919d526eda8b8202b">_huber_loss_and_gradient</a> (<a class="el" href="__lapack__subroutines_8h.html#a817b85d82af73ef273fafbec623bb90b">w</a>, X, y, epsilon, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, sample_weight=None)</td></tr>
<tr class="separator:a5ac2f64944b5884919d526eda8b8202b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a5ac2f64944b5884919d526eda8b8202b" name="a5ac2f64944b5884919d526eda8b8202b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ac2f64944b5884919d526eda8b8202b">&#9670;&#160;</a></span>_huber_loss_and_gradient()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._huber._huber_loss_and_gradient </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returns the Huber loss and the gradient.

Parameters
----------
w : ndarray, shape (n_features + 1,) or (n_features + 2,)
    Feature vector.
    w[:n_features] gives the coefficients
    w[-1] gives the scale factor and if the intercept is fit w[-2]
    gives the intercept factor.

X : ndarray of shape (n_samples, n_features)
    Input data.

y : ndarray of shape (n_samples,)
    Target vector.

epsilon : float
    Robustness of the Huber estimator.

alpha : float
    Regularization parameter.

sample_weight : ndarray of shape (n_samples,), default=None
    Weight assigned to each sample.

Returns
-------
loss : float
    Huber loss.

gradient : ndarray, shape (len(w))
    Returns the derivative of the Huber loss with respect to each
    coefficient, intercept and the scale as a vector.
</pre> <div class="fragment"><div class="line"><span class="lineno">   18</span><span class="keyword">def </span>_huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):</div>
<div class="line"><span class="lineno">   19</span>    <span class="stringliteral">&quot;&quot;&quot;Returns the Huber loss and the gradient.</span></div>
<div class="line"><span class="lineno">   20</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   21</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   22</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   23</span><span class="stringliteral">    w : ndarray, shape (n_features + 1,) or (n_features + 2,)</span></div>
<div class="line"><span class="lineno">   24</span><span class="stringliteral">        Feature vector.</span></div>
<div class="line"><span class="lineno">   25</span><span class="stringliteral">        w[:n_features] gives the coefficients</span></div>
<div class="line"><span class="lineno">   26</span><span class="stringliteral">        w[-1] gives the scale factor and if the intercept is fit w[-2]</span></div>
<div class="line"><span class="lineno">   27</span><span class="stringliteral">        gives the intercept factor.</span></div>
<div class="line"><span class="lineno">   28</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">    X : ndarray of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral">        Input data.</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">    y : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">        Target vector.</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">    epsilon : float</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">        Robustness of the Huber estimator.</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral">    alpha : float</span></div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">        Regularization parameter.</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">    sample_weight : ndarray of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral">        Weight assigned to each sample.</span></div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">    loss : float</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">        Huber loss.</span></div>
<div class="line"><span class="lineno">   48</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral">    gradient : ndarray, shape (len(w))</span></div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">        Returns the derivative of the Huber loss with respect to each</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral">        coefficient, intercept and the scale as a vector.</span></div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   53</span>    _, n_features = X.shape</div>
<div class="line"><span class="lineno">   54</span>    fit_intercept = n_features + 2 == w.shape[0]</div>
<div class="line"><span class="lineno">   55</span>    <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno">   56</span>        intercept = w[-2]</div>
<div class="line"><span class="lineno">   57</span>    sigma = w[-1]</div>
<div class="line"><span class="lineno">   58</span>    w = w[:n_features]</div>
<div class="line"><span class="lineno">   59</span>    n_samples = np.sum(sample_weight)</div>
<div class="line"><span class="lineno">   60</span> </div>
<div class="line"><span class="lineno">   61</span>    <span class="comment"># Calculate the values where |y - X&#39;w -c / sigma| &gt; epsilon</span></div>
<div class="line"><span class="lineno">   62</span>    <span class="comment"># The values above this threshold are outliers.</span></div>
<div class="line"><span class="lineno">   63</span>    linear_loss = y - safe_sparse_dot(X, w)</div>
<div class="line"><span class="lineno">   64</span>    <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno">   65</span>        linear_loss -= intercept</div>
<div class="line"><span class="lineno">   66</span>    abs_linear_loss = np.abs(linear_loss)</div>
<div class="line"><span class="lineno">   67</span>    outliers_mask = abs_linear_loss &gt; epsilon * sigma</div>
<div class="line"><span class="lineno">   68</span> </div>
<div class="line"><span class="lineno">   69</span>    <span class="comment"># Calculate the linear loss due to the outliers.</span></div>
<div class="line"><span class="lineno">   70</span>    <span class="comment"># This is equal to (2 * M * |y - X&#39;w -c / sigma| - M**2) * sigma</span></div>
<div class="line"><span class="lineno">   71</span>    outliers = abs_linear_loss[outliers_mask]</div>
<div class="line"><span class="lineno">   72</span>    num_outliers = np.count_nonzero(outliers_mask)</div>
<div class="line"><span class="lineno">   73</span>    n_non_outliers = X.shape[0] - num_outliers</div>
<div class="line"><span class="lineno">   74</span> </div>
<div class="line"><span class="lineno">   75</span>    <span class="comment"># n_sq_outliers includes the weight give to the outliers while</span></div>
<div class="line"><span class="lineno">   76</span>    <span class="comment"># num_outliers is just the number of outliers.</span></div>
<div class="line"><span class="lineno">   77</span>    outliers_sw = sample_weight[outliers_mask]</div>
<div class="line"><span class="lineno">   78</span>    n_sw_outliers = np.sum(outliers_sw)</div>
<div class="line"><span class="lineno">   79</span>    outlier_loss = (</div>
<div class="line"><span class="lineno">   80</span>        2.0 * epsilon * np.sum(outliers_sw * outliers)</div>
<div class="line"><span class="lineno">   81</span>        - sigma * n_sw_outliers * epsilon**2</div>
<div class="line"><span class="lineno">   82</span>    )</div>
<div class="line"><span class="lineno">   83</span> </div>
<div class="line"><span class="lineno">   84</span>    <span class="comment"># Calculate the quadratic loss due to the non-outliers.-</span></div>
<div class="line"><span class="lineno">   85</span>    <span class="comment"># This is equal to |(y - X&#39;w - c)**2 / sigma**2| * sigma</span></div>
<div class="line"><span class="lineno">   86</span>    non_outliers = linear_loss[~outliers_mask]</div>
<div class="line"><span class="lineno">   87</span>    weighted_non_outliers = sample_weight[~outliers_mask] * non_outliers</div>
<div class="line"><span class="lineno">   88</span>    weighted_loss = np.dot(weighted_non_outliers.T, non_outliers)</div>
<div class="line"><span class="lineno">   89</span>    squared_loss = weighted_loss / sigma</div>
<div class="line"><span class="lineno">   90</span> </div>
<div class="line"><span class="lineno">   91</span>    <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno">   92</span>        grad = np.zeros(n_features + 2)</div>
<div class="line"><span class="lineno">   93</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   94</span>        grad = np.zeros(n_features + 1)</div>
<div class="line"><span class="lineno">   95</span> </div>
<div class="line"><span class="lineno">   96</span>    <span class="comment"># Gradient due to the squared loss.</span></div>
<div class="line"><span class="lineno">   97</span>    X_non_outliers = -axis0_safe_slice(X, ~outliers_mask, n_non_outliers)</div>
<div class="line"><span class="lineno">   98</span>    grad[:n_features] = (</div>
<div class="line"><span class="lineno">   99</span>        2.0 / sigma * safe_sparse_dot(weighted_non_outliers, X_non_outliers)</div>
<div class="line"><span class="lineno">  100</span>    )</div>
<div class="line"><span class="lineno">  101</span> </div>
<div class="line"><span class="lineno">  102</span>    <span class="comment"># Gradient due to the linear loss.</span></div>
<div class="line"><span class="lineno">  103</span>    signed_outliers = np.ones_like(outliers)</div>
<div class="line"><span class="lineno">  104</span>    signed_outliers_mask = linear_loss[outliers_mask] &lt; 0</div>
<div class="line"><span class="lineno">  105</span>    signed_outliers[signed_outliers_mask] = -1.0</div>
<div class="line"><span class="lineno">  106</span>    X_outliers = axis0_safe_slice(X, outliers_mask, num_outliers)</div>
<div class="line"><span class="lineno">  107</span>    sw_outliers = sample_weight[outliers_mask] * signed_outliers</div>
<div class="line"><span class="lineno">  108</span>    grad[:n_features] -= 2.0 * epsilon * (safe_sparse_dot(sw_outliers, X_outliers))</div>
<div class="line"><span class="lineno">  109</span> </div>
<div class="line"><span class="lineno">  110</span>    <span class="comment"># Gradient due to the penalty.</span></div>
<div class="line"><span class="lineno">  111</span>    grad[:n_features] += alpha * 2.0 * w</div>
<div class="line"><span class="lineno">  112</span> </div>
<div class="line"><span class="lineno">  113</span>    <span class="comment"># Gradient due to sigma.</span></div>
<div class="line"><span class="lineno">  114</span>    grad[-1] = n_samples</div>
<div class="line"><span class="lineno">  115</span>    grad[-1] -= n_sw_outliers * epsilon**2</div>
<div class="line"><span class="lineno">  116</span>    grad[-1] -= squared_loss / sigma</div>
<div class="line"><span class="lineno">  117</span> </div>
<div class="line"><span class="lineno">  118</span>    <span class="comment"># Gradient due to the intercept.</span></div>
<div class="line"><span class="lineno">  119</span>    <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno">  120</span>        grad[-2] = -2.0 * np.sum(weighted_non_outliers) / sigma</div>
<div class="line"><span class="lineno">  121</span>        grad[-2] -= 2.0 * epsilon * np.sum(sw_outliers)</div>
<div class="line"><span class="lineno">  122</span> </div>
<div class="line"><span class="lineno">  123</span>    loss = n_samples * sigma + squared_loss + outlier_loss</div>
<div class="line"><span class="lineno">  124</span>    loss += alpha * np.dot(w, w)</div>
<div class="line"><span class="lineno">  125</span>    <span class="keywordflow">return</span> loss, grad</div>
<div class="line"><span class="lineno">  126</span> </div>
<div class="line"><span class="lineno">  127</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
