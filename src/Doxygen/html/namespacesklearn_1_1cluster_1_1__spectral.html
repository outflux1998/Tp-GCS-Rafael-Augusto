<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.cluster._spectral Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1cluster.html">cluster</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1cluster_1_1__spectral.html">_spectral</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.cluster._spectral Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1cluster_1_1__spectral_1_1_spectral_clustering.html">SpectralClustering</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a29792a5e5b87373c1a30aec97aeef847" id="r_a29792a5e5b87373c1a30aec97aeef847"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1cluster_1_1__spectral.html#a29792a5e5b87373c1a30aec97aeef847">cluster_qr</a> (vectors)</td></tr>
<tr class="separator:a29792a5e5b87373c1a30aec97aeef847"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a928f6e0ec017dc1791fb788281784452" id="r_a928f6e0ec017dc1791fb788281784452"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1cluster_1_1__spectral.html#a928f6e0ec017dc1791fb788281784452">discretize</a> (vectors, *copy=True, max_svd_restarts=30, n_iter_max=20, random_state=None)</td></tr>
<tr class="separator:a928f6e0ec017dc1791fb788281784452"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e2f8a42d5198bd0d7e6b8c0a8ac1350" id="r_a1e2f8a42d5198bd0d7e6b8c0a8ac1350"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1cluster_1_1__spectral.html#a1e2f8a42d5198bd0d7e6b8c0a8ac1350">spectral_clustering</a> (affinity, *n_clusters=8, n_components=None, eigen_solver=None, random_state=None, n_init=10, eigen_tol=&quot;auto&quot;, assign_labels=&quot;kmeans&quot;, verbose=False)</td></tr>
<tr class="separator:a1e2f8a42d5198bd0d7e6b8c0a8ac1350"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Algorithms for spectral clustering</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a29792a5e5b87373c1a30aec97aeef847" name="a29792a5e5b87373c1a30aec97aeef847"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a29792a5e5b87373c1a30aec97aeef847">&#9670;&#160;</a></span>cluster_qr()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.cluster._spectral.cluster_qr </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vectors</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Find the discrete partition closest to the eigenvector embedding.

    This implementation was proposed in [1]_.

.. versionadded:: 1.1

    Parameters
    ----------
    vectors : array-like, shape: (n_samples, n_clusters)
        The embedding space of the samples.

    Returns
    -------
    labels : array of integers, shape: n_samples
        The cluster labels of vectors.

    References
    ----------
    .. [1] :doi:`Simple, direct, and efficient multi-way spectral clustering, 2019
        Anil Damle, Victor Minden, Lexing Ying
        &lt;10.1093/imaiai/iay008&gt;`</pre> <div class="fragment"><div class="line"><span class="lineno">   26</span><span class="keyword">def </span>cluster_qr(vectors):</div>
<div class="line"><span class="lineno">   27</span>    <span class="stringliteral">&quot;&quot;&quot;Find the discrete partition closest to the eigenvector embedding.</span></div>
<div class="line"><span class="lineno">   28</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">        This implementation was proposed in [1]_.</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral">    .. versionadded:: 1.1</span></div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">        vectors : array-like, shape: (n_samples, n_clusters)</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">            The embedding space of the samples.</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">        labels : array of integers, shape: n_samples</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">            The cluster labels of vectors.</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">        References</span></div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">        .. [1] :doi:`Simple, direct, and efficient multi-way spectral clustering, 2019</span></div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">            Anil Damle, Victor Minden, Lexing Ying</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">            &lt;10.1093/imaiai/iay008&gt;`</span></div>
<div class="line"><span class="lineno">   48</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   50</span> </div>
<div class="line"><span class="lineno">   51</span>    k = vectors.shape[1]</div>
<div class="line"><span class="lineno">   52</span>    _, _, piv = qr(vectors.T, pivoting=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">   53</span>    ut, _, v = svd(vectors[piv[:k], :].T)</div>
<div class="line"><span class="lineno">   54</span>    vectors = abs(np.dot(vectors, np.dot(ut, v.conj())))</div>
<div class="line"><span class="lineno">   55</span>    <span class="keywordflow">return</span> vectors.argmax(axis=1)</div>
<div class="line"><span class="lineno">   56</span> </div>
<div class="line"><span class="lineno">   57</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a928f6e0ec017dc1791fb788281784452" name="a928f6e0ec017dc1791fb788281784452"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a928f6e0ec017dc1791fb788281784452">&#9670;&#160;</a></span>discretize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.cluster._spectral.discretize </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vectors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>copy</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_svd_restarts</em> = <code>30</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_iter_max</em> = <code>20</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Search for a partition matrix which is closest to the eigenvector embedding.

This implementation was proposed in [1]_.

Parameters
----------
vectors : array-like of shape (n_samples, n_clusters)
    The embedding space of the samples.

copy : bool, default=True
    Whether to copy vectors, or perform in-place normalization.

max_svd_restarts : int, default=30
    Maximum number of attempts to restart SVD if convergence fails

n_iter_max : int, default=30
    Maximum number of iterations to attempt in rotation and partition
    matrix search if machine precision convergence is not reached

random_state : int, RandomState instance, default=None
    Determines random number generation for rotation matrix initialization.
    Use an int to make the randomness deterministic.
    See :term:`Glossary &lt;random_state&gt;`.

Returns
-------
labels : array of integers, shape: n_samples
    The labels of the clusters.

References
----------

.. [1] `Multiclass spectral clustering, 2003
       Stella X. Yu, Jianbo Shi
       &lt;https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&gt;`_

Notes
-----

The eigenvector embedding is used to iteratively search for the
closest discrete partition.  First, the eigenvector embedding is
normalized to the space of partition matrices. An optimal discrete
partition matrix closest to this normalized embedding multiplied by
an initial rotation is calculated.  Fixing this discrete partition
matrix, an optimal rotation matrix is calculated.  These two
calculations are performed until convergence.  The discrete partition
matrix is returned as the clustering solution.  Used in spectral
clustering, this method tends to be faster and more robust to random
initialization than k-means.</pre> <div class="fragment"><div class="line"><span class="lineno">   60</span>):</div>
<div class="line"><span class="lineno">   61</span>    <span class="stringliteral">&quot;&quot;&quot;Search for a partition matrix which is closest to the eigenvector embedding.</span></div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">    This implementation was proposed in [1]_.</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    vectors : array-like of shape (n_samples, n_clusters)</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">        The embedding space of the samples.</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    copy : bool, default=True</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">        Whether to copy vectors, or perform in-place normalization.</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">    max_svd_restarts : int, default=30</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">        Maximum number of attempts to restart SVD if convergence fails</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">    n_iter_max : int, default=30</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">        Maximum number of iterations to attempt in rotation and partition</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">        matrix search if machine precision convergence is not reached</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">    random_state : int, RandomState instance, default=None</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral">        Determines random number generation for rotation matrix initialization.</span></div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">        Use an int to make the randomness deterministic.</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">    labels : array of integers, shape: n_samples</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">        The labels of the clusters.</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral">    .. [1] `Multiclass spectral clustering, 2003</span></div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral">           Stella X. Yu, Jianbo Shi</span></div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral">           &lt;https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&gt;`_</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">    The eigenvector embedding is used to iteratively search for the</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">    closest discrete partition.  First, the eigenvector embedding is</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral">    normalized to the space of partition matrices. An optimal discrete</span></div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">    partition matrix closest to this normalized embedding multiplied by</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">    an initial rotation is calculated.  Fixing this discrete partition</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral">    matrix, an optimal rotation matrix is calculated.  These two</span></div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral">    calculations are performed until convergence.  The discrete partition</span></div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral">    matrix is returned as the clustering solution.  Used in spectral</span></div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">    clustering, this method tends to be faster and more robust to random</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">    initialization than k-means.</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  112</span> </div>
<div class="line"><span class="lineno">  113</span>    random_state = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  114</span> </div>
<div class="line"><span class="lineno">  115</span>    vectors = as_float_array(vectors, copy=copy)</div>
<div class="line"><span class="lineno">  116</span> </div>
<div class="line"><span class="lineno">  117</span>    eps = np.finfo(float).eps</div>
<div class="line"><span class="lineno">  118</span>    n_samples, n_components = vectors.shape</div>
<div class="line"><span class="lineno">  119</span> </div>
<div class="line"><span class="lineno">  120</span>    <span class="comment"># Normalize the eigenvectors to an equal length of a vector of ones.</span></div>
<div class="line"><span class="lineno">  121</span>    <span class="comment"># Reorient the eigenvectors to point in the negative direction with respect</span></div>
<div class="line"><span class="lineno">  122</span>    <span class="comment"># to the first element.  This may have to do with constraining the</span></div>
<div class="line"><span class="lineno">  123</span>    <span class="comment"># eigenvectors to lie in a specific quadrant to make the discretization</span></div>
<div class="line"><span class="lineno">  124</span>    <span class="comment"># search easier.</span></div>
<div class="line"><span class="lineno">  125</span>    norm_ones = np.sqrt(n_samples)</div>
<div class="line"><span class="lineno">  126</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(vectors.shape[1]):</div>
<div class="line"><span class="lineno">  127</span>        vectors[:, i] = (vectors[:, i] / np.linalg.norm(vectors[:, i])) * norm_ones</div>
<div class="line"><span class="lineno">  128</span>        <span class="keywordflow">if</span> vectors[0, i] != 0:</div>
<div class="line"><span class="lineno">  129</span>            vectors[:, i] = -1 * vectors[:, i] * np.sign(vectors[0, i])</div>
<div class="line"><span class="lineno">  130</span> </div>
<div class="line"><span class="lineno">  131</span>    <span class="comment"># Normalize the rows of the eigenvectors.  Samples should lie on the unit</span></div>
<div class="line"><span class="lineno">  132</span>    <span class="comment"># hypersphere centered at the origin.  This transforms the samples in the</span></div>
<div class="line"><span class="lineno">  133</span>    <span class="comment"># embedding space to the space of partition matrices.</span></div>
<div class="line"><span class="lineno">  134</span>    vectors = vectors / np.sqrt((vectors**2).sum(axis=1))[:, np.newaxis]</div>
<div class="line"><span class="lineno">  135</span> </div>
<div class="line"><span class="lineno">  136</span>    svd_restarts = 0</div>
<div class="line"><span class="lineno">  137</span>    has_converged = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  138</span> </div>
<div class="line"><span class="lineno">  139</span>    <span class="comment"># If there is an exception we try to randomize and rerun SVD again</span></div>
<div class="line"><span class="lineno">  140</span>    <span class="comment"># do this max_svd_restarts times.</span></div>
<div class="line"><span class="lineno">  141</span>    <span class="keywordflow">while</span> (svd_restarts &lt; max_svd_restarts) <span class="keywordflow">and</span> <span class="keywordflow">not</span> has_converged:</div>
<div class="line"><span class="lineno">  142</span> </div>
<div class="line"><span class="lineno">  143</span>        <span class="comment"># Initialize first column of rotation matrix with a row of the</span></div>
<div class="line"><span class="lineno">  144</span>        <span class="comment"># eigenvectors</span></div>
<div class="line"><span class="lineno">  145</span>        rotation = np.zeros((n_components, n_components))</div>
<div class="line"><span class="lineno">  146</span>        rotation[:, 0] = vectors[random_state.randint(n_samples), :].T</div>
<div class="line"><span class="lineno">  147</span> </div>
<div class="line"><span class="lineno">  148</span>        <span class="comment"># To initialize the rest of the rotation matrix, find the rows</span></div>
<div class="line"><span class="lineno">  149</span>        <span class="comment"># of the eigenvectors that are as orthogonal to each other as</span></div>
<div class="line"><span class="lineno">  150</span>        <span class="comment"># possible</span></div>
<div class="line"><span class="lineno">  151</span>        c = np.zeros(n_samples)</div>
<div class="line"><span class="lineno">  152</span>        <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(1, n_components):</div>
<div class="line"><span class="lineno">  153</span>            <span class="comment"># Accumulate c to ensure row is as orthogonal as possible to</span></div>
<div class="line"><span class="lineno">  154</span>            <span class="comment"># previous picks as well as current one</span></div>
<div class="line"><span class="lineno">  155</span>            c += np.abs(np.dot(vectors, rotation[:, j - 1]))</div>
<div class="line"><span class="lineno">  156</span>            rotation[:, j] = vectors[c.argmin(), :].T</div>
<div class="line"><span class="lineno">  157</span> </div>
<div class="line"><span class="lineno">  158</span>        last_objective_value = 0.0</div>
<div class="line"><span class="lineno">  159</span>        n_iter = 0</div>
<div class="line"><span class="lineno">  160</span> </div>
<div class="line"><span class="lineno">  161</span>        <span class="keywordflow">while</span> <span class="keywordflow">not</span> has_converged:</div>
<div class="line"><span class="lineno">  162</span>            n_iter += 1</div>
<div class="line"><span class="lineno">  163</span> </div>
<div class="line"><span class="lineno">  164</span>            t_discrete = np.dot(vectors, rotation)</div>
<div class="line"><span class="lineno">  165</span> </div>
<div class="line"><span class="lineno">  166</span>            labels = t_discrete.argmax(axis=1)</div>
<div class="line"><span class="lineno">  167</span>            vectors_discrete = csc_matrix(</div>
<div class="line"><span class="lineno">  168</span>                (np.ones(len(labels)), (np.arange(0, n_samples), labels)),</div>
<div class="line"><span class="lineno">  169</span>                shape=(n_samples, n_components),</div>
<div class="line"><span class="lineno">  170</span>            )</div>
<div class="line"><span class="lineno">  171</span> </div>
<div class="line"><span class="lineno">  172</span>            t_svd = vectors_discrete.T * vectors</div>
<div class="line"><span class="lineno">  173</span> </div>
<div class="line"><span class="lineno">  174</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  175</span>                U, S, Vh = np.linalg.svd(t_svd)</div>
<div class="line"><span class="lineno">  176</span>            <span class="keywordflow">except</span> LinAlgError:</div>
<div class="line"><span class="lineno">  177</span>                svd_restarts += 1</div>
<div class="line"><span class="lineno">  178</span>                print(<span class="stringliteral">&quot;SVD did not converge, randomizing and trying again&quot;</span>)</div>
<div class="line"><span class="lineno">  179</span>                <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  180</span> </div>
<div class="line"><span class="lineno">  181</span>            ncut_value = 2.0 * (n_samples - S.sum())</div>
<div class="line"><span class="lineno">  182</span>            <span class="keywordflow">if</span> (abs(ncut_value - last_objective_value) &lt; eps) <span class="keywordflow">or</span> (n_iter &gt; n_iter_max):</div>
<div class="line"><span class="lineno">  183</span>                has_converged = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  184</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  185</span>                <span class="comment"># otherwise calculate rotation and continue</span></div>
<div class="line"><span class="lineno">  186</span>                last_objective_value = ncut_value</div>
<div class="line"><span class="lineno">  187</span>                rotation = np.dot(Vh.T, U.T)</div>
<div class="line"><span class="lineno">  188</span> </div>
<div class="line"><span class="lineno">  189</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> has_converged:</div>
<div class="line"><span class="lineno">  190</span>        <span class="keywordflow">raise</span> LinAlgError(<span class="stringliteral">&quot;SVD did not converge&quot;</span>)</div>
<div class="line"><span class="lineno">  191</span>    <span class="keywordflow">return</span> labels</div>
<div class="line"><span class="lineno">  192</span> </div>
<div class="line"><span class="lineno">  193</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1e2f8a42d5198bd0d7e6b8c0a8ac1350" name="a1e2f8a42d5198bd0d7e6b8c0a8ac1350"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e2f8a42d5198bd0d7e6b8c0a8ac1350">&#9670;&#160;</a></span>spectral_clustering()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.cluster._spectral.spectral_clustering </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>affinity</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>n_clusters</em> = <code>8</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_components</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>eigen_solver</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_init</em> = <code>10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>eigen_tol</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>assign_labels</em> = <code>&quot;kmeans&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Apply clustering to a projection of the normalized Laplacian.

In practice Spectral Clustering is very useful when the structure of
the individual clusters is highly non-convex or more generally when
a measure of the center and spread of the cluster is not a suitable
description of the complete cluster. For instance, when clusters are
nested circles on the 2D plane.

If affinity is the adjacency matrix of a graph, this method can be
used to find normalized graph cuts [1]_, [2]_.

Read more in the :ref:`User Guide &lt;spectral_clustering&gt;`.

Parameters
----------
affinity : {array-like, sparse matrix} of shape (n_samples, n_samples)
    The affinity matrix describing the relationship of the samples to
    embed. **Must be symmetric**.

    Possible examples:
      - adjacency matrix of a graph,
      - heat kernel of the pairwise distance matrix of the samples,
      - symmetric k-nearest neighbours connectivity matrix of the samples.

n_clusters : int, default=None
    Number of clusters to extract.

n_components : int, default=n_clusters
    Number of eigenvectors to use for the spectral embedding.

eigen_solver : {None, 'arpack', 'lobpcg', or 'amg'}
    The eigenvalue decomposition method. If None then ``'arpack'`` is used.
    See [4]_ for more details regarding ``'lobpcg'``.
    Eigensolver ``'amg'`` runs ``'lobpcg'`` with optional
    Algebraic MultiGrid preconditioning and requires pyamg to be installed.
    It can be faster on very large sparse problems [6]_ and [7]_.

random_state : int, RandomState instance, default=None
    A pseudo random number generator used for the initialization
    of the lobpcg eigenvectors decomposition when `eigen_solver ==
    'amg'`, and for the K-Means initialization. Use an int to make
    the results deterministic across calls (See
    :term:`Glossary &lt;random_state&gt;`).

    .. note::
        When using `eigen_solver == 'amg'`,
        it is necessary to also fix the global numpy seed with
        `np.random.seed(int)` to get deterministic results. See
        https://github.com/pyamg/pyamg/issues/139 for further
        information.

n_init : int, default=10
    Number of time the k-means algorithm will be run with different
    centroid seeds. The final results will be the best output of n_init
    consecutive runs in terms of inertia. Only used if
    ``assign_labels='kmeans'``.

eigen_tol : float, default="auto"
    Stopping criterion for eigendecomposition of the Laplacian matrix.
    If `eigen_tol="auto"` then the passed tolerance will depend on the
    `eigen_solver`:

    - If `eigen_solver="arpack"`, then `eigen_tol=0.0`;
    - If `eigen_solver="lobpcg"` or `eigen_solver="amg"`, then
      `eigen_tol=None` which configures the underlying `lobpcg` solver to
      automatically resolve the value according to their heuristics. See,
      :func:`scipy.sparse.linalg.lobpcg` for details.

    Note that when using `eigen_solver="lobpcg"` or `eigen_solver="amg"`
    values of `tol&lt;1e-5` may lead to convergence issues and should be
    avoided.

    .. versionadded:: 1.2
       Added 'auto' option.

assign_labels : {'kmeans', 'discretize', 'cluster_qr'}, default='kmeans'
    The strategy to use to assign labels in the embedding
    space.  There are three ways to assign labels after the Laplacian
    embedding.  k-means can be applied and is a popular choice. But it can
    also be sensitive to initialization. Discretization is another
    approach which is less sensitive to random initialization [3]_.
    The cluster_qr method [5]_ directly extracts clusters from eigenvectors
    in spectral clustering. In contrast to k-means and discretization, cluster_qr
    has no tuning parameters and is not an iterative method, yet may outperform
    k-means and discretization in terms of both quality and speed.

    .. versionchanged:: 1.1
       Added new labeling method 'cluster_qr'.

verbose : bool, default=False
    Verbosity mode.

    .. versionadded:: 0.24

Returns
-------
labels : array of integers, shape: n_samples
    The labels of the clusters.

Notes
-----
The graph should contain only one connected component, elsewhere
the results make little sense.

This algorithm solves the normalized cut for `k=2`: it is a
normalized spectral clustering.

References
----------

.. [1] :doi:`Normalized cuts and image segmentation, 2000
       Jianbo Shi, Jitendra Malik
       &lt;10.1109/34.868688&gt;`

.. [2] :doi:`A Tutorial on Spectral Clustering, 2007
       Ulrike von Luxburg
       &lt;10.1007/s11222-007-9033-z&gt;`

.. [3] `Multiclass spectral clustering, 2003
       Stella X. Yu, Jianbo Shi
       &lt;https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&gt;`_

.. [4] :doi:`Toward the Optimal Preconditioned Eigensolver:
       Locally Optimal Block Preconditioned Conjugate Gradient Method, 2001
       A. V. Knyazev
       SIAM Journal on Scientific Computing 23, no. 2, pp. 517-541.
       &lt;10.1137/S1064827500366124&gt;`

.. [5] :doi:`Simple, direct, and efficient multi-way spectral clustering, 2019
       Anil Damle, Victor Minden, Lexing Ying
       &lt;10.1093/imaiai/iay008&gt;`

.. [6] :doi:`Multiscale Spectral Image Segmentation Multiscale preconditioning
       for computing eigenvalues of graph Laplacians in image segmentation, 2006
       Andrew Knyazev
       &lt;10.13140/RG.2.2.35280.02565&gt;`

.. [7] :doi:`Preconditioned spectral clustering for stochastic block partition
       streaming graph challenge (Preliminary version at arXiv.)
       David Zhuzhunashvili, Andrew Knyazev
       &lt;10.1109/HPEC.2017.8091045&gt;`
</pre> <div class="fragment"><div class="line"><span class="lineno">  205</span>):</div>
<div class="line"><span class="lineno">  206</span>    <span class="stringliteral">&quot;&quot;&quot;Apply clustering to a projection of the normalized Laplacian.</span></div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">    In practice Spectral Clustering is very useful when the structure of</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">    the individual clusters is highly non-convex or more generally when</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">    a measure of the center and spread of the cluster is not a suitable</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">    description of the complete cluster. For instance, when clusters are</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">    nested circles on the 2D plane.</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">    If affinity is the adjacency matrix of a graph, this method can be</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">    used to find normalized graph cuts [1]_, [2]_.</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;spectral_clustering&gt;`.</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">    affinity : {array-like, sparse matrix} of shape (n_samples, n_samples)</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">        The affinity matrix describing the relationship of the samples to</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">        embed. **Must be symmetric**.</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">        Possible examples:</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">          - adjacency matrix of a graph,</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">          - heat kernel of the pairwise distance matrix of the samples,</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">          - symmetric k-nearest neighbours connectivity matrix of the samples.</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">    n_clusters : int, default=None</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">        Number of clusters to extract.</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">    n_components : int, default=n_clusters</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">        Number of eigenvectors to use for the spectral embedding.</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">    eigen_solver : {None, &#39;arpack&#39;, &#39;lobpcg&#39;, or &#39;amg&#39;}</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">        The eigenvalue decomposition method. If None then ``&#39;arpack&#39;`` is used.</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">        See [4]_ for more details regarding ``&#39;lobpcg&#39;``.</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        Eigensolver ``&#39;amg&#39;`` runs ``&#39;lobpcg&#39;`` with optional</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">        Algebraic MultiGrid preconditioning and requires pyamg to be installed.</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">        It can be faster on very large sparse problems [6]_ and [7]_.</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">    random_state : int, RandomState instance, default=None</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">        A pseudo random number generator used for the initialization</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">        of the lobpcg eigenvectors decomposition when `eigen_solver ==</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">        &#39;amg&#39;`, and for the K-Means initialization. Use an int to make</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">        the results deterministic across calls (See</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">        :term:`Glossary &lt;random_state&gt;`).</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">        .. note::</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">            When using `eigen_solver == &#39;amg&#39;`,</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">            it is necessary to also fix the global numpy seed with</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">            `np.random.seed(int)` to get deterministic results. See</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">            https://github.com/pyamg/pyamg/issues/139 for further</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">            information.</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">    n_init : int, default=10</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">        Number of time the k-means algorithm will be run with different</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">        centroid seeds. The final results will be the best output of n_init</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">        consecutive runs in terms of inertia. Only used if</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">        ``assign_labels=&#39;kmeans&#39;``.</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">    eigen_tol : float, default=&quot;auto&quot;</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">        Stopping criterion for eigendecomposition of the Laplacian matrix.</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">        If `eigen_tol=&quot;auto&quot;` then the passed tolerance will depend on the</span></div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">        `eigen_solver`:</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">        - If `eigen_solver=&quot;arpack&quot;`, then `eigen_tol=0.0`;</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral">        - If `eigen_solver=&quot;lobpcg&quot;` or `eigen_solver=&quot;amg&quot;`, then</span></div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">          `eigen_tol=None` which configures the underlying `lobpcg` solver to</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">          automatically resolve the value according to their heuristics. See,</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral">          :func:`scipy.sparse.linalg.lobpcg` for details.</span></div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral">        Note that when using `eigen_solver=&quot;lobpcg&quot;` or `eigen_solver=&quot;amg&quot;`</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">        values of `tol&lt;1e-5` may lead to convergence issues and should be</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">        avoided.</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">        .. versionadded:: 1.2</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">           Added &#39;auto&#39; option.</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    assign_labels : {&#39;kmeans&#39;, &#39;discretize&#39;, &#39;cluster_qr&#39;}, default=&#39;kmeans&#39;</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">        The strategy to use to assign labels in the embedding</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">        space.  There are three ways to assign labels after the Laplacian</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">        embedding.  k-means can be applied and is a popular choice. But it can</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">        also be sensitive to initialization. Discretization is another</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">        approach which is less sensitive to random initialization [3]_.</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">        The cluster_qr method [5]_ directly extracts clusters from eigenvectors</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">        in spectral clustering. In contrast to k-means and discretization, cluster_qr</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">        has no tuning parameters and is not an iterative method, yet may outperform</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">        k-means and discretization in terms of both quality and speed.</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">        .. versionchanged:: 1.1</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">           Added new labeling method &#39;cluster_qr&#39;.</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">    verbose : bool, default=False</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">        Verbosity mode.</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">        .. versionadded:: 0.24</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">    labels : array of integers, shape: n_samples</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">        The labels of the clusters.</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">    The graph should contain only one connected component, elsewhere</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">    the results make little sense.</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">    This algorithm solves the normalized cut for `k=2`: it is a</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">    normalized spectral clustering.</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral">    .. [1] :doi:`Normalized cuts and image segmentation, 2000</span></div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral">           Jianbo Shi, Jitendra Malik</span></div>
<div class="line"><span class="lineno">  318</span><span class="stringliteral">           &lt;10.1109/34.868688&gt;`</span></div>
<div class="line"><span class="lineno">  319</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  320</span><span class="stringliteral">    .. [2] :doi:`A Tutorial on Spectral Clustering, 2007</span></div>
<div class="line"><span class="lineno">  321</span><span class="stringliteral">           Ulrike von Luxburg</span></div>
<div class="line"><span class="lineno">  322</span><span class="stringliteral">           &lt;10.1007/s11222-007-9033-z&gt;`</span></div>
<div class="line"><span class="lineno">  323</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  324</span><span class="stringliteral">    .. [3] `Multiclass spectral clustering, 2003</span></div>
<div class="line"><span class="lineno">  325</span><span class="stringliteral">           Stella X. Yu, Jianbo Shi</span></div>
<div class="line"><span class="lineno">  326</span><span class="stringliteral">           &lt;https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&gt;`_</span></div>
<div class="line"><span class="lineno">  327</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral">    .. [4] :doi:`Toward the Optimal Preconditioned Eigensolver:</span></div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">           Locally Optimal Block Preconditioned Conjugate Gradient Method, 2001</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">           A. V. Knyazev</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral">           SIAM Journal on Scientific Computing 23, no. 2, pp. 517-541.</span></div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">           &lt;10.1137/S1064827500366124&gt;`</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral">    .. [5] :doi:`Simple, direct, and efficient multi-way spectral clustering, 2019</span></div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">           Anil Damle, Victor Minden, Lexing Ying</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral">           &lt;10.1093/imaiai/iay008&gt;`</span></div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral">    .. [6] :doi:`Multiscale Spectral Image Segmentation Multiscale preconditioning</span></div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral">           for computing eigenvalues of graph Laplacians in image segmentation, 2006</span></div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">           Andrew Knyazev</span></div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral">           &lt;10.13140/RG.2.2.35280.02565&gt;`</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral">    .. [7] :doi:`Preconditioned spectral clustering for stochastic block partition</span></div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">           streaming graph challenge (Preliminary version at arXiv.)</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral">           David Zhuzhunashvili, Andrew Knyazev</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">           &lt;10.1109/HPEC.2017.8091045&gt;`</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  348</span>    <span class="keywordflow">if</span> assign_labels <span class="keywordflow">not</span> <span class="keywordflow">in</span> (<span class="stringliteral">&quot;kmeans&quot;</span>, <span class="stringliteral">&quot;discretize&quot;</span>, <span class="stringliteral">&quot;cluster_qr&quot;</span>):</div>
<div class="line"><span class="lineno">  349</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  350</span>            <span class="stringliteral">&quot;The &#39;assign_labels&#39; parameter should be &quot;</span></div>
<div class="line"><span class="lineno">  351</span>            <span class="stringliteral">&quot;&#39;kmeans&#39; or &#39;discretize&#39;, or &#39;cluster_qr&#39;, &quot;</span></div>
<div class="line"><span class="lineno">  352</span>            f<span class="stringliteral">&quot;but {assign_labels!r} was given&quot;</span></div>
<div class="line"><span class="lineno">  353</span>        )</div>
<div class="line"><span class="lineno">  354</span>    <span class="keywordflow">if</span> isinstance(affinity, np.matrix):</div>
<div class="line"><span class="lineno">  355</span>        <span class="keywordflow">raise</span> TypeError(</div>
<div class="line"><span class="lineno">  356</span>            <span class="stringliteral">&quot;spectral_clustering does not support passing in affinity as an &quot;</span></div>
<div class="line"><span class="lineno">  357</span>            <span class="stringliteral">&quot;np.matrix. Please convert to a numpy array with np.asarray. For &quot;</span></div>
<div class="line"><span class="lineno">  358</span>            <span class="stringliteral">&quot;more information see: &quot;</span></div>
<div class="line"><span class="lineno">  359</span>            <span class="stringliteral">&quot;https://numpy.org/doc/stable/reference/generated/numpy.matrix.html&quot;</span>,  <span class="comment"># noqa</span></div>
<div class="line"><span class="lineno">  360</span>        )</div>
<div class="line"><span class="lineno">  361</span> </div>
<div class="line"><span class="lineno">  362</span>    random_state = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  363</span>    n_components = n_clusters <span class="keywordflow">if</span> n_components <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> n_components</div>
<div class="line"><span class="lineno">  364</span> </div>
<div class="line"><span class="lineno">  365</span>    <span class="comment"># We now obtain the real valued solution matrix to the</span></div>
<div class="line"><span class="lineno">  366</span>    <span class="comment"># relaxed Ncut problem, solving the eigenvalue problem</span></div>
<div class="line"><span class="lineno">  367</span>    <span class="comment"># L_sym x = lambda x  and recovering u = D^-1/2 x.</span></div>
<div class="line"><span class="lineno">  368</span>    <span class="comment"># The first eigenvector is constant only for fully connected graphs</span></div>
<div class="line"><span class="lineno">  369</span>    <span class="comment"># and should be kept for spectral clustering (drop_first = False)</span></div>
<div class="line"><span class="lineno">  370</span>    <span class="comment"># See spectral_embedding documentation.</span></div>
<div class="line"><span class="lineno">  371</span>    maps = spectral_embedding(</div>
<div class="line"><span class="lineno">  372</span>        affinity,</div>
<div class="line"><span class="lineno">  373</span>        n_components=n_components,</div>
<div class="line"><span class="lineno">  374</span>        eigen_solver=eigen_solver,</div>
<div class="line"><span class="lineno">  375</span>        random_state=random_state,</div>
<div class="line"><span class="lineno">  376</span>        eigen_tol=eigen_tol,</div>
<div class="line"><span class="lineno">  377</span>        drop_first=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  378</span>    )</div>
<div class="line"><span class="lineno">  379</span>    <span class="keywordflow">if</span> verbose:</div>
<div class="line"><span class="lineno">  380</span>        print(f<span class="stringliteral">&quot;Computing label assignment using {assign_labels}&quot;</span>)</div>
<div class="line"><span class="lineno">  381</span> </div>
<div class="line"><span class="lineno">  382</span>    <span class="keywordflow">if</span> assign_labels == <span class="stringliteral">&quot;kmeans&quot;</span>:</div>
<div class="line"><span class="lineno">  383</span>        _, labels, _ = k_means(</div>
<div class="line"><span class="lineno">  384</span>            maps, n_clusters, random_state=random_state, n_init=n_init, verbose=verbose</div>
<div class="line"><span class="lineno">  385</span>        )</div>
<div class="line"><span class="lineno">  386</span>    <span class="keywordflow">elif</span> assign_labels == <span class="stringliteral">&quot;cluster_qr&quot;</span>:</div>
<div class="line"><span class="lineno">  387</span>        labels = cluster_qr(maps)</div>
<div class="line"><span class="lineno">  388</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  389</span>        labels = discretize(maps, random_state=random_state)</div>
<div class="line"><span class="lineno">  390</span> </div>
<div class="line"><span class="lineno">  391</span>    <span class="keywordflow">return</span> labels</div>
<div class="line"><span class="lineno">  392</span> </div>
<div class="line"><span class="lineno">  393</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
