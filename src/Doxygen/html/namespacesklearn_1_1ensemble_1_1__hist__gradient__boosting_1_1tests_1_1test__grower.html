<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.ensemble._hist_gradient_boosting.tests.test_grower Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble.html">ensemble</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting.html">_hist_gradient_boosting</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html">test_grower</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.ensemble._hist_gradient_boosting.tests.test_grower Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:aef21be39a15e4a4c30d189239104ddb6" id="r_aef21be39a15e4a4c30d189239104ddb6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#aef21be39a15e4a4c30d189239104ddb6">_make_training_data</a> (n_bins=256, constant_hessian=True)</td></tr>
<tr class="separator:aef21be39a15e4a4c30d189239104ddb6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0680eefb349fafaef0504049bfde0a3" id="r_aa0680eefb349fafaef0504049bfde0a3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#aa0680eefb349fafaef0504049bfde0a3">_check_children_consistency</a> (parent, left, right)</td></tr>
<tr class="separator:aa0680eefb349fafaef0504049bfde0a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6634d805ff4364e9e0468f4ea48f37b" id="r_ae6634d805ff4364e9e0468f4ea48f37b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#ae6634d805ff4364e9e0468f4ea48f37b">test_grow_tree</a> (n_bins, constant_hessian, stopping_param, shrinkage)</td></tr>
<tr class="separator:ae6634d805ff4364e9e0468f4ea48f37b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e4e2883beb9b18a72c91a1c4452a7c9" id="r_a9e4e2883beb9b18a72c91a1c4452a7c9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#a9e4e2883beb9b18a72c91a1c4452a7c9">test_predictor_from_grower</a> ()</td></tr>
<tr class="separator:a9e4e2883beb9b18a72c91a1c4452a7c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a8ff33e30b4021697d7bd7d16aca372" id="r_a0a8ff33e30b4021697d7bd7d16aca372"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#a0a8ff33e30b4021697d7bd7d16aca372">test_min_samples_leaf</a> (n_samples, min_samples_leaf, n_bins, constant_hessian, noise)</td></tr>
<tr class="separator:a0a8ff33e30b4021697d7bd7d16aca372"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b1518303d89db647d8b011a322e7838" id="r_a0b1518303d89db647d8b011a322e7838"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#a0b1518303d89db647d8b011a322e7838">test_min_samples_leaf_root</a> (n_samples, min_samples_leaf)</td></tr>
<tr class="separator:a0b1518303d89db647d8b011a322e7838"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b842363a370537c76cbdd86cd464ec0" id="r_a0b842363a370537c76cbdd86cd464ec0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#a0b842363a370537c76cbdd86cd464ec0">assert_is_stump</a> (grower)</td></tr>
<tr class="separator:a0b842363a370537c76cbdd86cd464ec0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95aae35beb1da68d19785dc452a8b2f2" id="r_a95aae35beb1da68d19785dc452a8b2f2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#a95aae35beb1da68d19785dc452a8b2f2">test_max_depth</a> (max_depth)</td></tr>
<tr class="separator:a95aae35beb1da68d19785dc452a8b2f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab343887655519dea63f6c3b0219eb42e" id="r_ab343887655519dea63f6c3b0219eb42e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#ab343887655519dea63f6c3b0219eb42e">test_input_validation</a> ()</td></tr>
<tr class="separator:ab343887655519dea63f6c3b0219eb42e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a292db0727c54133fac03bab86c02968a" id="r_a292db0727c54133fac03bab86c02968a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#a292db0727c54133fac03bab86c02968a">test_init_parameters_validation</a> ()</td></tr>
<tr class="separator:a292db0727c54133fac03bab86c02968a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa3955fa84e702a81265ef66026d5c9e" id="r_aaa3955fa84e702a81265ef66026d5c9e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#aaa3955fa84e702a81265ef66026d5c9e">test_missing_value_predict_only</a> ()</td></tr>
<tr class="separator:aaa3955fa84e702a81265ef66026d5c9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2cba6e2d2e0cce77c523bde9b27ad6e7" id="r_a2cba6e2d2e0cce77c523bde9b27ad6e7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#a2cba6e2d2e0cce77c523bde9b27ad6e7">test_split_on_nan_with_infinite_values</a> ()</td></tr>
<tr class="separator:a2cba6e2d2e0cce77c523bde9b27ad6e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07740c83ead19c64a26fdda5fb4b1e6f" id="r_a07740c83ead19c64a26fdda5fb4b1e6f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#a07740c83ead19c64a26fdda5fb4b1e6f">test_grow_tree_categories</a> ()</td></tr>
<tr class="separator:a07740c83ead19c64a26fdda5fb4b1e6f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae18559f14ec11bfc3579745309b42807" id="r_ae18559f14ec11bfc3579745309b42807"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#ae18559f14ec11bfc3579745309b42807">test_ohe_equivalence</a> (min_samples_leaf, n_unique_categories, target)</td></tr>
<tr class="separator:ae18559f14ec11bfc3579745309b42807"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b56bf0c902dd225afd269e90bdf3acd" id="r_a6b56bf0c902dd225afd269e90bdf3acd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#a6b56bf0c902dd225afd269e90bdf3acd">test_grower_interaction_constraints</a> ()</td></tr>
<tr class="separator:a6b56bf0c902dd225afd269e90bdf3acd"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:ac2adf66fce642f507af8b4b5f36002f3" id="r_ac2adf66fce642f507af8b4b5f36002f3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__grower.html#ac2adf66fce642f507af8b4b5f36002f3">n_threads</a> = _openmp_effective_n_threads()</td></tr>
<tr class="separator:ac2adf66fce642f507af8b4b5f36002f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="aa0680eefb349fafaef0504049bfde0a3" name="aa0680eefb349fafaef0504049bfde0a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0680eefb349fafaef0504049bfde0a3">&#9670;&#160;</a></span>_check_children_consistency()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower._check_children_consistency </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>parent</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>left</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>right</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   52</span><span class="keyword">def </span>_check_children_consistency(parent, left, right):</div>
<div class="line"><span class="lineno">   53</span>    <span class="comment"># Make sure the samples are correctly dispatched from a parent to its</span></div>
<div class="line"><span class="lineno">   54</span>    <span class="comment"># children</span></div>
<div class="line"><span class="lineno">   55</span>    <span class="keyword">assert</span> parent.left_child <span class="keywordflow">is</span> left</div>
<div class="line"><span class="lineno">   56</span>    <span class="keyword">assert</span> parent.right_child <span class="keywordflow">is</span> right</div>
<div class="line"><span class="lineno">   57</span> </div>
<div class="line"><span class="lineno">   58</span>    <span class="comment"># each sample from the parent is propagated to one of the two children</span></div>
<div class="line"><span class="lineno">   59</span>    <span class="keyword">assert</span> len(left.sample_indices) + len(right.sample_indices) == len(</div>
<div class="line"><span class="lineno">   60</span>        parent.sample_indices</div>
<div class="line"><span class="lineno">   61</span>    )</div>
<div class="line"><span class="lineno">   62</span> </div>
<div class="line"><span class="lineno">   63</span>    <span class="keyword">assert</span> set(left.sample_indices).union(set(right.sample_indices)) == set(</div>
<div class="line"><span class="lineno">   64</span>        parent.sample_indices</div>
<div class="line"><span class="lineno">   65</span>    )</div>
<div class="line"><span class="lineno">   66</span> </div>
<div class="line"><span class="lineno">   67</span>    <span class="comment"># samples are sent either to the left or the right node, never to both</span></div>
<div class="line"><span class="lineno">   68</span>    <span class="keyword">assert</span> set(left.sample_indices).intersection(set(right.sample_indices)) == set()</div>
<div class="line"><span class="lineno">   69</span> </div>
<div class="line"><span class="lineno">   70</span> </div>
<div class="line"><span class="lineno">   71</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">   72</span>    <span class="stringliteral">&quot;n_bins, constant_hessian, stopping_param, shrinkage&quot;</span>,</div>
<div class="line"><span class="lineno">   73</span>    [</div>
<div class="line"><span class="lineno">   74</span>        (11, <span class="keyword">True</span>, <span class="stringliteral">&quot;min_gain_to_split&quot;</span>, 0.5),</div>
<div class="line"><span class="lineno">   75</span>        (11, <span class="keyword">False</span>, <span class="stringliteral">&quot;min_gain_to_split&quot;</span>, 1.0),</div>
<div class="line"><span class="lineno">   76</span>        (11, <span class="keyword">True</span>, <span class="stringliteral">&quot;max_leaf_nodes&quot;</span>, 1.0),</div>
<div class="line"><span class="lineno">   77</span>        (11, <span class="keyword">False</span>, <span class="stringliteral">&quot;max_leaf_nodes&quot;</span>, 0.1),</div>
<div class="line"><span class="lineno">   78</span>        (42, <span class="keyword">True</span>, <span class="stringliteral">&quot;max_leaf_nodes&quot;</span>, 0.01),</div>
<div class="line"><span class="lineno">   79</span>        (42, <span class="keyword">False</span>, <span class="stringliteral">&quot;max_leaf_nodes&quot;</span>, 1.0),</div>
<div class="line"><span class="lineno">   80</span>        (256, <span class="keyword">True</span>, <span class="stringliteral">&quot;min_gain_to_split&quot;</span>, 1.0),</div>
<div class="line"><span class="lineno">   81</span>        (256, <span class="keyword">True</span>, <span class="stringliteral">&quot;max_leaf_nodes&quot;</span>, 0.1),</div>
<div class="line"><span class="lineno">   82</span>    ],</div>
<div class="line"><span class="lineno">   83</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="aef21be39a15e4a4c30d189239104ddb6" name="aef21be39a15e4a4c30d189239104ddb6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef21be39a15e4a4c30d189239104ddb6">&#9670;&#160;</a></span>_make_training_data()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower._make_training_data </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_bins</em> = <code>256</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>constant_hessian</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   20</span><span class="keyword">def </span>_make_training_data(n_bins=256, constant_hessian=True):</div>
<div class="line"><span class="lineno">   21</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno">   22</span>    n_samples = 10000</div>
<div class="line"><span class="lineno">   23</span> </div>
<div class="line"><span class="lineno">   24</span>    <span class="comment"># Generate some test data directly binned so as to test the grower code</span></div>
<div class="line"><span class="lineno">   25</span>    <span class="comment"># independently of the binning logic.</span></div>
<div class="line"><span class="lineno">   26</span>    X_binned = rng.randint(0, n_bins - 1, size=(n_samples, 2), dtype=X_BINNED_DTYPE)</div>
<div class="line"><span class="lineno">   27</span>    X_binned = np.asfortranarray(X_binned)</div>
<div class="line"><span class="lineno">   28</span> </div>
<div class="line"><span class="lineno">   29</span>    <span class="keyword">def </span>true_decision_function(input_features):</div>
<div class="line"><span class="lineno">   30</span>        <span class="stringliteral">&quot;&quot;&quot;Ground truth decision function</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">        This is a very simple yet asymmetric decision tree. Therefore the</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">        grower code should have no trouble recovering the decision function</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">        from 10000 training samples.</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   36</span>        <span class="keywordflow">if</span> input_features[0] &lt;= n_bins // 2:</div>
<div class="line"><span class="lineno">   37</span>            <span class="keywordflow">return</span> -1</div>
<div class="line"><span class="lineno">   38</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   39</span>            <span class="keywordflow">return</span> -1 <span class="keywordflow">if</span> input_features[1] &lt;= n_bins // 3 <span class="keywordflow">else</span> 1</div>
<div class="line"><span class="lineno">   40</span> </div>
<div class="line"><span class="lineno">   41</span>    target = np.array([true_decision_function(x) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> X_binned], dtype=Y_DTYPE)</div>
<div class="line"><span class="lineno">   42</span> </div>
<div class="line"><span class="lineno">   43</span>    <span class="comment"># Assume a square loss applied to an initial model that always predicts 0</span></div>
<div class="line"><span class="lineno">   44</span>    <span class="comment"># (hardcoded for this test):</span></div>
<div class="line"><span class="lineno">   45</span>    all_gradients = target.astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">   46</span>    shape_hessians = 1 <span class="keywordflow">if</span> constant_hessian <span class="keywordflow">else</span> all_gradients.shape</div>
<div class="line"><span class="lineno">   47</span>    all_hessians = np.ones(shape=shape_hessians, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">   48</span> </div>
<div class="line"><span class="lineno">   49</span>    <span class="keywordflow">return</span> X_binned, all_gradients, all_hessians</div>
<div class="line"><span class="lineno">   50</span> </div>
<div class="line"><span class="lineno">   51</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0b842363a370537c76cbdd86cd464ec0" name="a0b842363a370537c76cbdd86cd464ec0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b842363a370537c76cbdd86cd464ec0">&#9670;&#160;</a></span>assert_is_stump()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.assert_is_stump </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>grower</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  292</span><span class="keyword">def </span>assert_is_stump(grower):</div>
<div class="line"><span class="lineno">  293</span>    <span class="comment"># To assert that stumps are created when max_depth=1</span></div>
<div class="line"><span class="lineno">  294</span>    <span class="keywordflow">for</span> leaf <span class="keywordflow">in</span> (grower.root.left_child, grower.root.right_child):</div>
<div class="line"><span class="lineno">  295</span>        <span class="keyword">assert</span> leaf.left_child <span class="keywordflow">is</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  296</span>        <span class="keyword">assert</span> leaf.right_child <span class="keywordflow">is</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  297</span> </div>
<div class="line"><span class="lineno">  298</span> </div>
<div class="line"><span class="lineno">  299</span><span class="preprocessor">@pytest.mark.parametrize(&quot;max_depth&quot;, [1, 2, 3])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ae6634d805ff4364e9e0468f4ea48f37b" name="ae6634d805ff4364e9e0468f4ea48f37b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6634d805ff4364e9e0468f4ea48f37b">&#9670;&#160;</a></span>test_grow_tree()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_grow_tree </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_bins</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>constant_hessian</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>stopping_param</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>shrinkage</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   84</span><span class="keyword">def </span>test_grow_tree(n_bins, constant_hessian, stopping_param, shrinkage):</div>
<div class="line"><span class="lineno">   85</span>    X_binned, all_gradients, all_hessians = _make_training_data(</div>
<div class="line"><span class="lineno">   86</span>        n_bins=n_bins, constant_hessian=constant_hessian</div>
<div class="line"><span class="lineno">   87</span>    )</div>
<div class="line"><span class="lineno">   88</span>    n_samples = X_binned.shape[0]</div>
<div class="line"><span class="lineno">   89</span> </div>
<div class="line"><span class="lineno">   90</span>    <span class="keywordflow">if</span> stopping_param == <span class="stringliteral">&quot;max_leaf_nodes&quot;</span>:</div>
<div class="line"><span class="lineno">   91</span>        stopping_param = {<span class="stringliteral">&quot;max_leaf_nodes&quot;</span>: 3}</div>
<div class="line"><span class="lineno">   92</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   93</span>        stopping_param = {<span class="stringliteral">&quot;min_gain_to_split&quot;</span>: 0.01}</div>
<div class="line"><span class="lineno">   94</span> </div>
<div class="line"><span class="lineno">   95</span>    grower = TreeGrower(</div>
<div class="line"><span class="lineno">   96</span>        X_binned,</div>
<div class="line"><span class="lineno">   97</span>        all_gradients,</div>
<div class="line"><span class="lineno">   98</span>        all_hessians,</div>
<div class="line"><span class="lineno">   99</span>        n_bins=n_bins,</div>
<div class="line"><span class="lineno">  100</span>        shrinkage=shrinkage,</div>
<div class="line"><span class="lineno">  101</span>        min_samples_leaf=1,</div>
<div class="line"><span class="lineno">  102</span>        **stopping_param,</div>
<div class="line"><span class="lineno">  103</span>    )</div>
<div class="line"><span class="lineno">  104</span> </div>
<div class="line"><span class="lineno">  105</span>    <span class="comment"># The root node is not yet split, but the best possible split has</span></div>
<div class="line"><span class="lineno">  106</span>    <span class="comment"># already been evaluated:</span></div>
<div class="line"><span class="lineno">  107</span>    <span class="keyword">assert</span> grower.root.left_child <span class="keywordflow">is</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  108</span>    <span class="keyword">assert</span> grower.root.right_child <span class="keywordflow">is</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  109</span> </div>
<div class="line"><span class="lineno">  110</span>    root_split = grower.root.split_info</div>
<div class="line"><span class="lineno">  111</span>    <span class="keyword">assert</span> root_split.feature_idx == 0</div>
<div class="line"><span class="lineno">  112</span>    <span class="keyword">assert</span> root_split.bin_idx == n_bins // 2</div>
<div class="line"><span class="lineno">  113</span>    <span class="keyword">assert</span> len(grower.splittable_nodes) == 1</div>
<div class="line"><span class="lineno">  114</span> </div>
<div class="line"><span class="lineno">  115</span>    <span class="comment"># Calling split next applies the next split and computes the best split</span></div>
<div class="line"><span class="lineno">  116</span>    <span class="comment"># for each of the two newly introduced children nodes.</span></div>
<div class="line"><span class="lineno">  117</span>    left_node, right_node = grower.split_next()</div>
<div class="line"><span class="lineno">  118</span> </div>
<div class="line"><span class="lineno">  119</span>    <span class="comment"># All training samples have ben split in the two nodes, approximately</span></div>
<div class="line"><span class="lineno">  120</span>    <span class="comment"># 50%/50%</span></div>
<div class="line"><span class="lineno">  121</span>    _check_children_consistency(grower.root, left_node, right_node)</div>
<div class="line"><span class="lineno">  122</span>    <span class="keyword">assert</span> len(left_node.sample_indices) &gt; 0.4 * n_samples</div>
<div class="line"><span class="lineno">  123</span>    <span class="keyword">assert</span> len(left_node.sample_indices) &lt; 0.6 * n_samples</div>
<div class="line"><span class="lineno">  124</span> </div>
<div class="line"><span class="lineno">  125</span>    <span class="keywordflow">if</span> grower.min_gain_to_split &gt; 0:</div>
<div class="line"><span class="lineno">  126</span>        <span class="comment"># The left node is too pure: there is no gain to split it further.</span></div>
<div class="line"><span class="lineno">  127</span>        <span class="keyword">assert</span> left_node.split_info.gain &lt; grower.min_gain_to_split</div>
<div class="line"><span class="lineno">  128</span>        <span class="keyword">assert</span> left_node <span class="keywordflow">in</span> grower.finalized_leaves</div>
<div class="line"><span class="lineno">  129</span> </div>
<div class="line"><span class="lineno">  130</span>    <span class="comment"># The right node can still be split further, this time on feature #1</span></div>
<div class="line"><span class="lineno">  131</span>    split_info = right_node.split_info</div>
<div class="line"><span class="lineno">  132</span>    <span class="keyword">assert</span> split_info.gain &gt; 1.0</div>
<div class="line"><span class="lineno">  133</span>    <span class="keyword">assert</span> split_info.feature_idx == 1</div>
<div class="line"><span class="lineno">  134</span>    <span class="keyword">assert</span> split_info.bin_idx == n_bins // 3</div>
<div class="line"><span class="lineno">  135</span>    <span class="keyword">assert</span> right_node.left_child <span class="keywordflow">is</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  136</span>    <span class="keyword">assert</span> right_node.right_child <span class="keywordflow">is</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  137</span> </div>
<div class="line"><span class="lineno">  138</span>    <span class="comment"># The right split has not been applied yet. Let&#39;s do it now:</span></div>
<div class="line"><span class="lineno">  139</span>    <span class="keyword">assert</span> len(grower.splittable_nodes) == 1</div>
<div class="line"><span class="lineno">  140</span>    right_left_node, right_right_node = grower.split_next()</div>
<div class="line"><span class="lineno">  141</span>    _check_children_consistency(right_node, right_left_node, right_right_node)</div>
<div class="line"><span class="lineno">  142</span>    <span class="keyword">assert</span> len(right_left_node.sample_indices) &gt; 0.1 * n_samples</div>
<div class="line"><span class="lineno">  143</span>    <span class="keyword">assert</span> len(right_left_node.sample_indices) &lt; 0.2 * n_samples</div>
<div class="line"><span class="lineno">  144</span> </div>
<div class="line"><span class="lineno">  145</span>    <span class="keyword">assert</span> len(right_right_node.sample_indices) &gt; 0.2 * n_samples</div>
<div class="line"><span class="lineno">  146</span>    <span class="keyword">assert</span> len(right_right_node.sample_indices) &lt; 0.4 * n_samples</div>
<div class="line"><span class="lineno">  147</span> </div>
<div class="line"><span class="lineno">  148</span>    <span class="comment"># All the leafs are pure, it is not possible to split any further:</span></div>
<div class="line"><span class="lineno">  149</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> grower.splittable_nodes</div>
<div class="line"><span class="lineno">  150</span> </div>
<div class="line"><span class="lineno">  151</span>    grower._apply_shrinkage()</div>
<div class="line"><span class="lineno">  152</span> </div>
<div class="line"><span class="lineno">  153</span>    <span class="comment"># Check the values of the leaves:</span></div>
<div class="line"><span class="lineno">  154</span>    <span class="keyword">assert</span> grower.root.left_child.value == approx(shrinkage)</div>
<div class="line"><span class="lineno">  155</span>    <span class="keyword">assert</span> grower.root.right_child.left_child.value == approx(shrinkage)</div>
<div class="line"><span class="lineno">  156</span>    <span class="keyword">assert</span> grower.root.right_child.right_child.value == approx(-shrinkage, rel=1e-3)</div>
<div class="line"><span class="lineno">  157</span> </div>
<div class="line"><span class="lineno">  158</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a07740c83ead19c64a26fdda5fb4b1e6f" name="a07740c83ead19c64a26fdda5fb4b1e6f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07740c83ead19c64a26fdda5fb4b1e6f">&#9670;&#160;</a></span>test_grow_tree_categories()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_grow_tree_categories </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  443</span><span class="keyword">def </span>test_grow_tree_categories():</div>
<div class="line"><span class="lineno">  444</span>    <span class="comment"># Check that the grower produces the right predictor tree when a split is</span></div>
<div class="line"><span class="lineno">  445</span>    <span class="comment"># categorical</span></div>
<div class="line"><span class="lineno">  446</span>    X_binned = np.array([[0, 1] * 11 + [1]], dtype=X_BINNED_DTYPE).T</div>
<div class="line"><span class="lineno">  447</span>    X_binned = np.asfortranarray(X_binned)</div>
<div class="line"><span class="lineno">  448</span> </div>
<div class="line"><span class="lineno">  449</span>    all_gradients = np.array([10, 1] * 11 + [1], dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  450</span>    all_hessians = np.ones(1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  451</span>    is_categorical = np.ones(1, dtype=np.uint8)</div>
<div class="line"><span class="lineno">  452</span> </div>
<div class="line"><span class="lineno">  453</span>    grower = TreeGrower(</div>
<div class="line"><span class="lineno">  454</span>        X_binned,</div>
<div class="line"><span class="lineno">  455</span>        all_gradients,</div>
<div class="line"><span class="lineno">  456</span>        all_hessians,</div>
<div class="line"><span class="lineno">  457</span>        n_bins=4,</div>
<div class="line"><span class="lineno">  458</span>        shrinkage=1.0,</div>
<div class="line"><span class="lineno">  459</span>        min_samples_leaf=1,</div>
<div class="line"><span class="lineno">  460</span>        is_categorical=is_categorical,</div>
<div class="line"><span class="lineno">  461</span>        n_threads=n_threads,</div>
<div class="line"><span class="lineno">  462</span>    )</div>
<div class="line"><span class="lineno">  463</span>    grower.grow()</div>
<div class="line"><span class="lineno">  464</span>    <span class="keyword">assert</span> grower.n_nodes == 3</div>
<div class="line"><span class="lineno">  465</span> </div>
<div class="line"><span class="lineno">  466</span>    categories = [np.array([4, 9], dtype=X_DTYPE)]</div>
<div class="line"><span class="lineno">  467</span>    predictor = grower.make_predictor(binning_thresholds=categories)</div>
<div class="line"><span class="lineno">  468</span>    root = predictor.nodes[0]</div>
<div class="line"><span class="lineno">  469</span>    <span class="keyword">assert</span> root[<span class="stringliteral">&quot;count&quot;</span>] == 23</div>
<div class="line"><span class="lineno">  470</span>    <span class="keyword">assert</span> root[<span class="stringliteral">&quot;depth&quot;</span>] == 0</div>
<div class="line"><span class="lineno">  471</span>    <span class="keyword">assert</span> root[<span class="stringliteral">&quot;is_categorical&quot;</span>]</div>
<div class="line"><span class="lineno">  472</span> </div>
<div class="line"><span class="lineno">  473</span>    left, right = predictor.nodes[root[<span class="stringliteral">&quot;left&quot;</span>]], predictor.nodes[root[<span class="stringliteral">&quot;right&quot;</span>]]</div>
<div class="line"><span class="lineno">  474</span> </div>
<div class="line"><span class="lineno">  475</span>    <span class="comment"># arbitrary validation, but this means ones go to the left.</span></div>
<div class="line"><span class="lineno">  476</span>    <span class="keyword">assert</span> left[<span class="stringliteral">&quot;count&quot;</span>] &gt;= right[<span class="stringliteral">&quot;count&quot;</span>]</div>
<div class="line"><span class="lineno">  477</span> </div>
<div class="line"><span class="lineno">  478</span>    <span class="comment"># check binned category value (1)</span></div>
<div class="line"><span class="lineno">  479</span>    expected_binned_cat_bitset = [2**1] + [0] * 7</div>
<div class="line"><span class="lineno">  480</span>    binned_cat_bitset = predictor.binned_left_cat_bitsets</div>
<div class="line"><span class="lineno">  481</span>    assert_array_equal(binned_cat_bitset[0], expected_binned_cat_bitset)</div>
<div class="line"><span class="lineno">  482</span> </div>
<div class="line"><span class="lineno">  483</span>    <span class="comment"># check raw category value (9)</span></div>
<div class="line"><span class="lineno">  484</span>    expected_raw_cat_bitsets = [2**9] + [0] * 7</div>
<div class="line"><span class="lineno">  485</span>    raw_cat_bitsets = predictor.raw_left_cat_bitsets</div>
<div class="line"><span class="lineno">  486</span>    assert_array_equal(raw_cat_bitsets[0], expected_raw_cat_bitsets)</div>
<div class="line"><span class="lineno">  487</span> </div>
<div class="line"><span class="lineno">  488</span>    <span class="comment"># Note that since there was no missing values during training, the missing</span></div>
<div class="line"><span class="lineno">  489</span>    <span class="comment"># values aren&#39;t part of the bitsets. However, we expect the missing values</span></div>
<div class="line"><span class="lineno">  490</span>    <span class="comment"># to go to the biggest child (i.e. the left one).</span></div>
<div class="line"><span class="lineno">  491</span>    <span class="comment"># The left child has a value of -1 = negative gradient.</span></div>
<div class="line"><span class="lineno">  492</span>    <span class="keyword">assert</span> root[<span class="stringliteral">&quot;missing_go_to_left&quot;</span>]</div>
<div class="line"><span class="lineno">  493</span> </div>
<div class="line"><span class="lineno">  494</span>    <span class="comment"># make sure binned missing values are mapped to the left child during</span></div>
<div class="line"><span class="lineno">  495</span>    <span class="comment"># prediction</span></div>
<div class="line"><span class="lineno">  496</span>    prediction_binned = predictor.predict_binned(</div>
<div class="line"><span class="lineno">  497</span>        np.asarray([[6]]).astype(X_BINNED_DTYPE),</div>
<div class="line"><span class="lineno">  498</span>        missing_values_bin_idx=6,</div>
<div class="line"><span class="lineno">  499</span>        n_threads=n_threads,</div>
<div class="line"><span class="lineno">  500</span>    )</div>
<div class="line"><span class="lineno">  501</span>    assert_allclose(prediction_binned, [-1])  <span class="comment"># negative gradient</span></div>
<div class="line"><span class="lineno">  502</span> </div>
<div class="line"><span class="lineno">  503</span>    <span class="comment"># make sure raw missing values are mapped to the left child during</span></div>
<div class="line"><span class="lineno">  504</span>    <span class="comment"># prediction</span></div>
<div class="line"><span class="lineno">  505</span>    known_cat_bitsets = np.zeros((1, 8), dtype=np.uint32)  <span class="comment"># ignored anyway</span></div>
<div class="line"><span class="lineno">  506</span>    f_idx_map = np.array([0], dtype=np.uint32)</div>
<div class="line"><span class="lineno">  507</span>    prediction = predictor.predict(</div>
<div class="line"><span class="lineno">  508</span>        np.array([[np.nan]]), known_cat_bitsets, f_idx_map, n_threads</div>
<div class="line"><span class="lineno">  509</span>    )</div>
<div class="line"><span class="lineno">  510</span>    assert_allclose(prediction, [-1])</div>
<div class="line"><span class="lineno">  511</span> </div>
<div class="line"><span class="lineno">  512</span> </div>
<div class="line"><span class="lineno">  513</span><span class="preprocessor">@pytest.mark.parametrize(&quot;min_samples_leaf&quot;, (1, 20)</span>)</div>
<div class="line"><span class="lineno">  514</span><span class="preprocessor">@pytest.mark.parametrize(&quot;n_unique_categories&quot;, (2, 10, 100)</span>)</div>
<div class="line"><span class="lineno">  515</span><span class="preprocessor">@pytest.mark.parametrize(&quot;target&quot;, (&quot;binary&quot;, &quot;random&quot;, &quot;equal&quot;)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a6b56bf0c902dd225afd269e90bdf3acd" name="a6b56bf0c902dd225afd269e90bdf3acd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b56bf0c902dd225afd269e90bdf3acd">&#9670;&#160;</a></span>test_grower_interaction_constraints()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_grower_interaction_constraints </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that grower respects interaction constraints.</pre> <div class="fragment"><div class="line"><span class="lineno">  572</span><span class="keyword">def </span>test_grower_interaction_constraints():</div>
<div class="line"><span class="lineno">  573</span>    <span class="stringliteral">&quot;&quot;&quot;Check that grower respects interaction constraints.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  574</span>    n_features = 6</div>
<div class="line"><span class="lineno">  575</span>    interaction_cst = [{0, 1}, {1, 2}, {3, 4, 5}]</div>
<div class="line"><span class="lineno">  576</span>    n_samples = 10</div>
<div class="line"><span class="lineno">  577</span>    n_bins = 6</div>
<div class="line"><span class="lineno">  578</span>    root_feature_splits = []</div>
<div class="line"><span class="lineno">  579</span> </div>
<div class="line"><span class="lineno">  580</span>    <span class="keyword">def </span>get_all_children(node):</div>
<div class="line"><span class="lineno">  581</span>        res = []</div>
<div class="line"><span class="lineno">  582</span>        <span class="keywordflow">if</span> node.is_leaf:</div>
<div class="line"><span class="lineno">  583</span>            <span class="keywordflow">return</span> res</div>
<div class="line"><span class="lineno">  584</span>        <span class="keywordflow">for</span> n <span class="keywordflow">in</span> [node.left_child, node.right_child]:</div>
<div class="line"><span class="lineno">  585</span>            res.append(n)</div>
<div class="line"><span class="lineno">  586</span>            res.extend(get_all_children(n))</div>
<div class="line"><span class="lineno">  587</span>        <span class="keywordflow">return</span> res</div>
<div class="line"><span class="lineno">  588</span> </div>
<div class="line"><span class="lineno">  589</span>    <span class="keywordflow">for</span> seed <span class="keywordflow">in</span> range(20):</div>
<div class="line"><span class="lineno">  590</span>        rng = np.random.RandomState(seed)</div>
<div class="line"><span class="lineno">  591</span> </div>
<div class="line"><span class="lineno">  592</span>        X_binned = rng.randint(</div>
<div class="line"><span class="lineno">  593</span>            0, n_bins - 1, size=(n_samples, n_features), dtype=X_BINNED_DTYPE</div>
<div class="line"><span class="lineno">  594</span>        )</div>
<div class="line"><span class="lineno">  595</span>        X_binned = np.asfortranarray(X_binned)</div>
<div class="line"><span class="lineno">  596</span>        gradients = rng.normal(size=n_samples).astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">  597</span>        hessians = np.ones(shape=1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  598</span> </div>
<div class="line"><span class="lineno">  599</span>        grower = TreeGrower(</div>
<div class="line"><span class="lineno">  600</span>            X_binned,</div>
<div class="line"><span class="lineno">  601</span>            gradients,</div>
<div class="line"><span class="lineno">  602</span>            hessians,</div>
<div class="line"><span class="lineno">  603</span>            n_bins=n_bins,</div>
<div class="line"><span class="lineno">  604</span>            min_samples_leaf=1,</div>
<div class="line"><span class="lineno">  605</span>            interaction_cst=interaction_cst,</div>
<div class="line"><span class="lineno">  606</span>            n_threads=n_threads,</div>
<div class="line"><span class="lineno">  607</span>        )</div>
<div class="line"><span class="lineno">  608</span>        grower.grow()</div>
<div class="line"><span class="lineno">  609</span> </div>
<div class="line"><span class="lineno">  610</span>        root_feature_idx = grower.root.split_info.feature_idx</div>
<div class="line"><span class="lineno">  611</span>        root_feature_splits.append(root_feature_idx)</div>
<div class="line"><span class="lineno">  612</span> </div>
<div class="line"><span class="lineno">  613</span>        feature_idx_to_constraint_set = {</div>
<div class="line"><span class="lineno">  614</span>            0: {0, 1},</div>
<div class="line"><span class="lineno">  615</span>            1: {0, 1, 2},</div>
<div class="line"><span class="lineno">  616</span>            2: {1, 2},</div>
<div class="line"><span class="lineno">  617</span>            3: {3, 4, 5},</div>
<div class="line"><span class="lineno">  618</span>            4: {3, 4, 5},</div>
<div class="line"><span class="lineno">  619</span>            5: {3, 4, 5},</div>
<div class="line"><span class="lineno">  620</span>        }</div>
<div class="line"><span class="lineno">  621</span> </div>
<div class="line"><span class="lineno">  622</span>        root_constraint_set = feature_idx_to_constraint_set[root_feature_idx]</div>
<div class="line"><span class="lineno">  623</span>        <span class="keywordflow">for</span> node <span class="keywordflow">in</span> (grower.root.left_child, grower.root.right_child):</div>
<div class="line"><span class="lineno">  624</span>            <span class="comment"># Root&#39;s children&#39;s allowed_features must be the root&#39;s constraints set.</span></div>
<div class="line"><span class="lineno">  625</span>            assert_array_equal(node.allowed_features, list(root_constraint_set))</div>
<div class="line"><span class="lineno">  626</span>        <span class="keywordflow">for</span> node <span class="keywordflow">in</span> get_all_children(grower.root):</div>
<div class="line"><span class="lineno">  627</span>            <span class="keywordflow">if</span> node.is_leaf:</div>
<div class="line"><span class="lineno">  628</span>                <span class="keywordflow">continue</span></div>
<div class="line"><span class="lineno">  629</span>            <span class="comment"># Ensure that each node uses a subset of features of its parent node.</span></div>
<div class="line"><span class="lineno">  630</span>            parent_interaction_cst_indices = set(node.interaction_cst_indices)</div>
<div class="line"><span class="lineno">  631</span>            right_interactions_cst_indices = set(</div>
<div class="line"><span class="lineno">  632</span>                node.right_child.interaction_cst_indices</div>
<div class="line"><span class="lineno">  633</span>            )</div>
<div class="line"><span class="lineno">  634</span>            left_interactions_cst_indices = set(node.left_child.interaction_cst_indices)</div>
<div class="line"><span class="lineno">  635</span> </div>
<div class="line"><span class="lineno">  636</span>            <span class="keyword">assert</span> right_interactions_cst_indices.issubset(</div>
<div class="line"><span class="lineno">  637</span>                parent_interaction_cst_indices</div>
<div class="line"><span class="lineno">  638</span>            )</div>
<div class="line"><span class="lineno">  639</span>            <span class="keyword">assert</span> left_interactions_cst_indices.issubset(</div>
<div class="line"><span class="lineno">  640</span>                parent_interaction_cst_indices</div>
<div class="line"><span class="lineno">  641</span>            )</div>
<div class="line"><span class="lineno">  642</span>            <span class="comment"># The features used for split must have been present in the root&#39;s</span></div>
<div class="line"><span class="lineno">  643</span>            <span class="comment"># constraint set.</span></div>
<div class="line"><span class="lineno">  644</span>            <span class="keyword">assert</span> node.split_info.feature_idx <span class="keywordflow">in</span> root_constraint_set</div>
<div class="line"><span class="lineno">  645</span> </div>
<div class="line"><span class="lineno">  646</span>    <span class="comment"># Make sure that every feature is used at least once as split for the root node.</span></div>
<div class="line"><span class="lineno">  647</span>    <span class="keyword">assert</span> (</div>
<div class="line"><span class="lineno">  648</span>        len(set(root_feature_splits))</div>
<div class="line"><span class="lineno">  649</span>        == len(set().union(*interaction_cst))</div>
<div class="line"><span class="lineno">  650</span>        == n_features</div>
<div class="line"><span class="lineno">  651</span>    )</div>
</div><!-- fragment -->
</div>
</div>
<a id="a292db0727c54133fac03bab86c02968a" name="a292db0727c54133fac03bab86c02968a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a292db0727c54133fac03bab86c02968a">&#9670;&#160;</a></span>test_init_parameters_validation()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_init_parameters_validation </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  340</span><span class="keyword">def </span>test_init_parameters_validation():</div>
<div class="line"><span class="lineno">  341</span>    X_binned, all_gradients, all_hessians = _make_training_data()</div>
<div class="line"><span class="lineno">  342</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;min_gain_to_split=-1 must be positive&quot;</span>):</div>
<div class="line"><span class="lineno">  343</span> </div>
<div class="line"><span class="lineno">  344</span>        TreeGrower(X_binned, all_gradients, all_hessians, min_gain_to_split=-1)</div>
<div class="line"><span class="lineno">  345</span> </div>
<div class="line"><span class="lineno">  346</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;min_hessian_to_split=-1 must be positive&quot;</span>):</div>
<div class="line"><span class="lineno">  347</span>        TreeGrower(X_binned, all_gradients, all_hessians, min_hessian_to_split=-1)</div>
<div class="line"><span class="lineno">  348</span> </div>
<div class="line"><span class="lineno">  349</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab343887655519dea63f6c3b0219eb42e" name="ab343887655519dea63f6c3b0219eb42e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab343887655519dea63f6c3b0219eb42e">&#9670;&#160;</a></span>test_input_validation()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_input_validation </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  325</span><span class="keyword">def </span>test_input_validation():</div>
<div class="line"><span class="lineno">  326</span> </div>
<div class="line"><span class="lineno">  327</span>    X_binned, all_gradients, all_hessians = _make_training_data()</div>
<div class="line"><span class="lineno">  328</span> </div>
<div class="line"><span class="lineno">  329</span>    X_binned_float = X_binned.astype(np.float32)</div>
<div class="line"><span class="lineno">  330</span>    <span class="keyword">with</span> pytest.raises(NotImplementedError, match=<span class="stringliteral">&quot;X_binned must be of type uint8&quot;</span>):</div>
<div class="line"><span class="lineno">  331</span>        TreeGrower(X_binned_float, all_gradients, all_hessians)</div>
<div class="line"><span class="lineno">  332</span> </div>
<div class="line"><span class="lineno">  333</span>    X_binned_C_array = np.ascontiguousarray(X_binned)</div>
<div class="line"><span class="lineno">  334</span>    <span class="keyword">with</span> pytest.raises(</div>
<div class="line"><span class="lineno">  335</span>        ValueError, match=<span class="stringliteral">&quot;X_binned should be passed as Fortran contiguous array&quot;</span></div>
<div class="line"><span class="lineno">  336</span>    ):</div>
<div class="line"><span class="lineno">  337</span>        TreeGrower(X_binned_C_array, all_gradients, all_hessians)</div>
<div class="line"><span class="lineno">  338</span> </div>
<div class="line"><span class="lineno">  339</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a95aae35beb1da68d19785dc452a8b2f2" name="a95aae35beb1da68d19785dc452a8b2f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a95aae35beb1da68d19785dc452a8b2f2">&#9670;&#160;</a></span>test_max_depth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_max_depth </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_depth</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  300</span><span class="keyword">def </span>test_max_depth(max_depth):</div>
<div class="line"><span class="lineno">  301</span>    <span class="comment"># Make sure max_depth parameter works as expected</span></div>
<div class="line"><span class="lineno">  302</span>    rng = np.random.RandomState(seed=0)</div>
<div class="line"><span class="lineno">  303</span> </div>
<div class="line"><span class="lineno">  304</span>    n_bins = 256</div>
<div class="line"><span class="lineno">  305</span>    n_samples = 1000</div>
<div class="line"><span class="lineno">  306</span> </div>
<div class="line"><span class="lineno">  307</span>    <span class="comment"># data = linear target, 3 features, 1 irrelevant.</span></div>
<div class="line"><span class="lineno">  308</span>    X = rng.normal(size=(n_samples, 3))</div>
<div class="line"><span class="lineno">  309</span>    y = X[:, 0] - X[:, 1]</div>
<div class="line"><span class="lineno">  310</span>    mapper = _BinMapper(n_bins=n_bins)</div>
<div class="line"><span class="lineno">  311</span>    X = mapper.fit_transform(X)</div>
<div class="line"><span class="lineno">  312</span> </div>
<div class="line"><span class="lineno">  313</span>    all_gradients = y.astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">  314</span>    all_hessians = np.ones(shape=1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  315</span>    grower = TreeGrower(X, all_gradients, all_hessians, max_depth=max_depth)</div>
<div class="line"><span class="lineno">  316</span>    grower.grow()</div>
<div class="line"><span class="lineno">  317</span> </div>
<div class="line"><span class="lineno">  318</span>    depth = max(leaf.depth <span class="keywordflow">for</span> leaf <span class="keywordflow">in</span> grower.finalized_leaves)</div>
<div class="line"><span class="lineno">  319</span>    <span class="keyword">assert</span> depth == max_depth</div>
<div class="line"><span class="lineno">  320</span> </div>
<div class="line"><span class="lineno">  321</span>    <span class="keywordflow">if</span> max_depth == 1:</div>
<div class="line"><span class="lineno">  322</span>        assert_is_stump(grower)</div>
<div class="line"><span class="lineno">  323</span> </div>
<div class="line"><span class="lineno">  324</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0a8ff33e30b4021697d7bd7d16aca372" name="a0a8ff33e30b4021697d7bd7d16aca372"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a8ff33e30b4021697d7bd7d16aca372">&#9670;&#160;</a></span>test_min_samples_leaf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_min_samples_leaf </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_samples_leaf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_bins</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>constant_hessian</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>noise</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  224</span><span class="keyword">def </span>test_min_samples_leaf(n_samples, min_samples_leaf, n_bins, constant_hessian, noise):</div>
<div class="line"><span class="lineno">  225</span>    rng = np.random.RandomState(seed=0)</div>
<div class="line"><span class="lineno">  226</span>    <span class="comment"># data = linear target, 3 features, 1 irrelevant.</span></div>
<div class="line"><span class="lineno">  227</span>    X = rng.normal(size=(n_samples, 3))</div>
<div class="line"><span class="lineno">  228</span>    y = X[:, 0] - X[:, 1]</div>
<div class="line"><span class="lineno">  229</span>    <span class="keywordflow">if</span> noise:</div>
<div class="line"><span class="lineno">  230</span>        y_scale = y.std()</div>
<div class="line"><span class="lineno">  231</span>        y += rng.normal(scale=noise, size=n_samples) * y_scale</div>
<div class="line"><span class="lineno">  232</span>    mapper = _BinMapper(n_bins=n_bins)</div>
<div class="line"><span class="lineno">  233</span>    X = mapper.fit_transform(X)</div>
<div class="line"><span class="lineno">  234</span> </div>
<div class="line"><span class="lineno">  235</span>    all_gradients = y.astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">  236</span>    shape_hessian = 1 <span class="keywordflow">if</span> constant_hessian <span class="keywordflow">else</span> all_gradients.shape</div>
<div class="line"><span class="lineno">  237</span>    all_hessians = np.ones(shape=shape_hessian, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  238</span>    grower = TreeGrower(</div>
<div class="line"><span class="lineno">  239</span>        X,</div>
<div class="line"><span class="lineno">  240</span>        all_gradients,</div>
<div class="line"><span class="lineno">  241</span>        all_hessians,</div>
<div class="line"><span class="lineno">  242</span>        n_bins=n_bins,</div>
<div class="line"><span class="lineno">  243</span>        shrinkage=1.0,</div>
<div class="line"><span class="lineno">  244</span>        min_samples_leaf=min_samples_leaf,</div>
<div class="line"><span class="lineno">  245</span>        max_leaf_nodes=n_samples,</div>
<div class="line"><span class="lineno">  246</span>    )</div>
<div class="line"><span class="lineno">  247</span>    grower.grow()</div>
<div class="line"><span class="lineno">  248</span>    predictor = grower.make_predictor(binning_thresholds=mapper.bin_thresholds_)</div>
<div class="line"><span class="lineno">  249</span> </div>
<div class="line"><span class="lineno">  250</span>    <span class="keywordflow">if</span> n_samples &gt;= min_samples_leaf:</div>
<div class="line"><span class="lineno">  251</span>        <span class="keywordflow">for</span> node <span class="keywordflow">in</span> predictor.nodes:</div>
<div class="line"><span class="lineno">  252</span>            <span class="keywordflow">if</span> node[<span class="stringliteral">&quot;is_leaf&quot;</span>]:</div>
<div class="line"><span class="lineno">  253</span>                <span class="keyword">assert</span> node[<span class="stringliteral">&quot;count&quot;</span>] &gt;= min_samples_leaf</div>
<div class="line"><span class="lineno">  254</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  255</span>        <span class="keyword">assert</span> predictor.nodes.shape[0] == 1</div>
<div class="line"><span class="lineno">  256</span>        <span class="keyword">assert</span> predictor.nodes[0][<span class="stringliteral">&quot;is_leaf&quot;</span>]</div>
<div class="line"><span class="lineno">  257</span>        <span class="keyword">assert</span> predictor.nodes[0][<span class="stringliteral">&quot;count&quot;</span>] == n_samples</div>
<div class="line"><span class="lineno">  258</span> </div>
<div class="line"><span class="lineno">  259</span> </div>
<div class="line"><span class="lineno">  260</span><span class="preprocessor">@pytest.mark.parametrize(&quot;n_samples, min_samples_leaf&quot;, [(99, 50)</span>, (100, 50)])</div>
</div><!-- fragment -->
</div>
</div>
<a id="a0b1518303d89db647d8b011a322e7838" name="a0b1518303d89db647d8b011a322e7838"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b1518303d89db647d8b011a322e7838">&#9670;&#160;</a></span>test_min_samples_leaf_root()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_min_samples_leaf_root </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_samples_leaf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  261</span><span class="keyword">def </span>test_min_samples_leaf_root(n_samples, min_samples_leaf):</div>
<div class="line"><span class="lineno">  262</span>    <span class="comment"># Make sure root node isn&#39;t split if n_samples is not at least twice</span></div>
<div class="line"><span class="lineno">  263</span>    <span class="comment"># min_samples_leaf</span></div>
<div class="line"><span class="lineno">  264</span>    rng = np.random.RandomState(seed=0)</div>
<div class="line"><span class="lineno">  265</span> </div>
<div class="line"><span class="lineno">  266</span>    n_bins = 256</div>
<div class="line"><span class="lineno">  267</span> </div>
<div class="line"><span class="lineno">  268</span>    <span class="comment"># data = linear target, 3 features, 1 irrelevant.</span></div>
<div class="line"><span class="lineno">  269</span>    X = rng.normal(size=(n_samples, 3))</div>
<div class="line"><span class="lineno">  270</span>    y = X[:, 0] - X[:, 1]</div>
<div class="line"><span class="lineno">  271</span>    mapper = _BinMapper(n_bins=n_bins)</div>
<div class="line"><span class="lineno">  272</span>    X = mapper.fit_transform(X)</div>
<div class="line"><span class="lineno">  273</span> </div>
<div class="line"><span class="lineno">  274</span>    all_gradients = y.astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">  275</span>    all_hessians = np.ones(shape=1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  276</span>    grower = TreeGrower(</div>
<div class="line"><span class="lineno">  277</span>        X,</div>
<div class="line"><span class="lineno">  278</span>        all_gradients,</div>
<div class="line"><span class="lineno">  279</span>        all_hessians,</div>
<div class="line"><span class="lineno">  280</span>        n_bins=n_bins,</div>
<div class="line"><span class="lineno">  281</span>        shrinkage=1.0,</div>
<div class="line"><span class="lineno">  282</span>        min_samples_leaf=min_samples_leaf,</div>
<div class="line"><span class="lineno">  283</span>        max_leaf_nodes=n_samples,</div>
<div class="line"><span class="lineno">  284</span>    )</div>
<div class="line"><span class="lineno">  285</span>    grower.grow()</div>
<div class="line"><span class="lineno">  286</span>    <span class="keywordflow">if</span> n_samples &gt;= min_samples_leaf * 2:</div>
<div class="line"><span class="lineno">  287</span>        <span class="keyword">assert</span> len(grower.finalized_leaves) &gt;= 2</div>
<div class="line"><span class="lineno">  288</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  289</span>        <span class="keyword">assert</span> len(grower.finalized_leaves) == 1</div>
<div class="line"><span class="lineno">  290</span> </div>
<div class="line"><span class="lineno">  291</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aaa3955fa84e702a81265ef66026d5c9e" name="aaa3955fa84e702a81265ef66026d5c9e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaa3955fa84e702a81265ef66026d5c9e">&#9670;&#160;</a></span>test_missing_value_predict_only()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_missing_value_predict_only </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  350</span><span class="keyword">def </span>test_missing_value_predict_only():</div>
<div class="line"><span class="lineno">  351</span>    <span class="comment"># Make sure that missing values are supported at predict time even if they</span></div>
<div class="line"><span class="lineno">  352</span>    <span class="comment"># were not encountered in the training data: the missing values are</span></div>
<div class="line"><span class="lineno">  353</span>    <span class="comment"># assigned to whichever child has the most samples.</span></div>
<div class="line"><span class="lineno">  354</span> </div>
<div class="line"><span class="lineno">  355</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  356</span>    n_samples = 100</div>
<div class="line"><span class="lineno">  357</span>    X_binned = rng.randint(0, 256, size=(n_samples, 1), dtype=np.uint8)</div>
<div class="line"><span class="lineno">  358</span>    X_binned = np.asfortranarray(X_binned)</div>
<div class="line"><span class="lineno">  359</span> </div>
<div class="line"><span class="lineno">  360</span>    gradients = rng.normal(size=n_samples).astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">  361</span>    hessians = np.ones(shape=1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  362</span> </div>
<div class="line"><span class="lineno">  363</span>    grower = TreeGrower(</div>
<div class="line"><span class="lineno">  364</span>        X_binned, gradients, hessians, min_samples_leaf=5, has_missing_values=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  365</span>    )</div>
<div class="line"><span class="lineno">  366</span>    grower.grow()</div>
<div class="line"><span class="lineno">  367</span> </div>
<div class="line"><span class="lineno">  368</span>    <span class="comment"># We pass undefined binning_thresholds because we won&#39;t use predict anyway</span></div>
<div class="line"><span class="lineno">  369</span>    predictor = grower.make_predictor(</div>
<div class="line"><span class="lineno">  370</span>        binning_thresholds=np.zeros((X_binned.shape[1], X_binned.max() + 1))</div>
<div class="line"><span class="lineno">  371</span>    )</div>
<div class="line"><span class="lineno">  372</span> </div>
<div class="line"><span class="lineno">  373</span>    <span class="comment"># go from root to a leaf, always following node with the most samples.</span></div>
<div class="line"><span class="lineno">  374</span>    <span class="comment"># That&#39;s the path nans are supposed to take</span></div>
<div class="line"><span class="lineno">  375</span>    node = predictor.nodes[0]</div>
<div class="line"><span class="lineno">  376</span>    <span class="keywordflow">while</span> <span class="keywordflow">not</span> node[<span class="stringliteral">&quot;is_leaf&quot;</span>]:</div>
<div class="line"><span class="lineno">  377</span>        left = predictor.nodes[node[<span class="stringliteral">&quot;left&quot;</span>]]</div>
<div class="line"><span class="lineno">  378</span>        right = predictor.nodes[node[<span class="stringliteral">&quot;right&quot;</span>]]</div>
<div class="line"><span class="lineno">  379</span>        node = left <span class="keywordflow">if</span> left[<span class="stringliteral">&quot;count&quot;</span>] &gt; right[<span class="stringliteral">&quot;count&quot;</span>] <span class="keywordflow">else</span> right</div>
<div class="line"><span class="lineno">  380</span> </div>
<div class="line"><span class="lineno">  381</span>    prediction_main_path = node[<span class="stringliteral">&quot;value&quot;</span>]</div>
<div class="line"><span class="lineno">  382</span> </div>
<div class="line"><span class="lineno">  383</span>    <span class="comment"># now build X_test with only nans, and make sure all predictions are equal</span></div>
<div class="line"><span class="lineno">  384</span>    <span class="comment"># to prediction_main_path</span></div>
<div class="line"><span class="lineno">  385</span>    all_nans = np.full(shape=(n_samples, 1), fill_value=np.nan)</div>
<div class="line"><span class="lineno">  386</span>    known_cat_bitsets = np.zeros((0, 8), dtype=X_BITSET_INNER_DTYPE)</div>
<div class="line"><span class="lineno">  387</span>    f_idx_map = np.zeros(0, dtype=np.uint32)</div>
<div class="line"><span class="lineno">  388</span> </div>
<div class="line"><span class="lineno">  389</span>    y_pred = predictor.predict(all_nans, known_cat_bitsets, f_idx_map, n_threads)</div>
<div class="line"><span class="lineno">  390</span>    <span class="keyword">assert</span> np.all(y_pred == prediction_main_path)</div>
<div class="line"><span class="lineno">  391</span> </div>
<div class="line"><span class="lineno">  392</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae18559f14ec11bfc3579745309b42807" name="ae18559f14ec11bfc3579745309b42807"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae18559f14ec11bfc3579745309b42807">&#9670;&#160;</a></span>test_ohe_equivalence()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_ohe_equivalence </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_samples_leaf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_unique_categories</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>target</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  516</span><span class="keyword">def </span>test_ohe_equivalence(min_samples_leaf, n_unique_categories, target):</div>
<div class="line"><span class="lineno">  517</span>    <span class="comment"># Make sure that native categorical splits are equivalent to using a OHE,</span></div>
<div class="line"><span class="lineno">  518</span>    <span class="comment"># when given enough depth</span></div>
<div class="line"><span class="lineno">  519</span> </div>
<div class="line"><span class="lineno">  520</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  521</span>    n_samples = 10_000</div>
<div class="line"><span class="lineno">  522</span>    X_binned = rng.randint(0, n_unique_categories, size=(n_samples, 1), dtype=np.uint8)</div>
<div class="line"><span class="lineno">  523</span> </div>
<div class="line"><span class="lineno">  524</span>    X_ohe = OneHotEncoder(sparse_output=<span class="keyword">False</span>).fit_transform(X_binned)</div>
<div class="line"><span class="lineno">  525</span>    X_ohe = np.asfortranarray(X_ohe).astype(np.uint8)</div>
<div class="line"><span class="lineno">  526</span> </div>
<div class="line"><span class="lineno">  527</span>    <span class="keywordflow">if</span> target == <span class="stringliteral">&quot;equal&quot;</span>:</div>
<div class="line"><span class="lineno">  528</span>        gradients = X_binned.reshape(-1)</div>
<div class="line"><span class="lineno">  529</span>    <span class="keywordflow">elif</span> target == <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno">  530</span>        gradients = (X_binned % 2).reshape(-1)</div>
<div class="line"><span class="lineno">  531</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  532</span>        gradients = rng.randn(n_samples)</div>
<div class="line"><span class="lineno">  533</span>    gradients = gradients.astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">  534</span> </div>
<div class="line"><span class="lineno">  535</span>    hessians = np.ones(shape=1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  536</span> </div>
<div class="line"><span class="lineno">  537</span>    grower_params = {</div>
<div class="line"><span class="lineno">  538</span>        <span class="stringliteral">&quot;min_samples_leaf&quot;</span>: min_samples_leaf,</div>
<div class="line"><span class="lineno">  539</span>        <span class="stringliteral">&quot;max_depth&quot;</span>: <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  540</span>        <span class="stringliteral">&quot;max_leaf_nodes&quot;</span>: <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  541</span>    }</div>
<div class="line"><span class="lineno">  542</span> </div>
<div class="line"><span class="lineno">  543</span>    grower = TreeGrower(</div>
<div class="line"><span class="lineno">  544</span>        X_binned, gradients, hessians, is_categorical=[<span class="keyword">True</span>], **grower_params</div>
<div class="line"><span class="lineno">  545</span>    )</div>
<div class="line"><span class="lineno">  546</span>    grower.grow()</div>
<div class="line"><span class="lineno">  547</span>    <span class="comment"># we pass undefined bin_thresholds because we won&#39;t use predict()</span></div>
<div class="line"><span class="lineno">  548</span>    predictor = grower.make_predictor(</div>
<div class="line"><span class="lineno">  549</span>        binning_thresholds=np.zeros((1, n_unique_categories))</div>
<div class="line"><span class="lineno">  550</span>    )</div>
<div class="line"><span class="lineno">  551</span>    preds = predictor.predict_binned(</div>
<div class="line"><span class="lineno">  552</span>        X_binned, missing_values_bin_idx=255, n_threads=n_threads</div>
<div class="line"><span class="lineno">  553</span>    )</div>
<div class="line"><span class="lineno">  554</span> </div>
<div class="line"><span class="lineno">  555</span>    grower_ohe = TreeGrower(X_ohe, gradients, hessians, **grower_params)</div>
<div class="line"><span class="lineno">  556</span>    grower_ohe.grow()</div>
<div class="line"><span class="lineno">  557</span>    predictor_ohe = grower_ohe.make_predictor(</div>
<div class="line"><span class="lineno">  558</span>        binning_thresholds=np.zeros((X_ohe.shape[1], n_unique_categories))</div>
<div class="line"><span class="lineno">  559</span>    )</div>
<div class="line"><span class="lineno">  560</span>    preds_ohe = predictor_ohe.predict_binned(</div>
<div class="line"><span class="lineno">  561</span>        X_ohe, missing_values_bin_idx=255, n_threads=n_threads</div>
<div class="line"><span class="lineno">  562</span>    )</div>
<div class="line"><span class="lineno">  563</span> </div>
<div class="line"><span class="lineno">  564</span>    <span class="keyword">assert</span> predictor.get_max_depth() &lt;= predictor_ohe.get_max_depth()</div>
<div class="line"><span class="lineno">  565</span>    <span class="keywordflow">if</span> target == <span class="stringliteral">&quot;binary&quot;</span> <span class="keywordflow">and</span> n_unique_categories &gt; 2:</div>
<div class="line"><span class="lineno">  566</span>        <span class="comment"># OHE needs more splits to achieve the same predictions</span></div>
<div class="line"><span class="lineno">  567</span>        <span class="keyword">assert</span> predictor.get_max_depth() &lt; predictor_ohe.get_max_depth()</div>
<div class="line"><span class="lineno">  568</span> </div>
<div class="line"><span class="lineno">  569</span>    np.testing.assert_allclose(preds, preds_ohe)</div>
<div class="line"><span class="lineno">  570</span> </div>
<div class="line"><span class="lineno">  571</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9e4e2883beb9b18a72c91a1c4452a7c9" name="a9e4e2883beb9b18a72c91a1c4452a7c9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e4e2883beb9b18a72c91a1c4452a7c9">&#9670;&#160;</a></span>test_predictor_from_grower()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_predictor_from_grower </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  159</span><span class="keyword">def </span>test_predictor_from_grower():</div>
<div class="line"><span class="lineno">  160</span>    <span class="comment"># Build a tree on the toy 3-leaf dataset to extract the predictor.</span></div>
<div class="line"><span class="lineno">  161</span>    n_bins = 256</div>
<div class="line"><span class="lineno">  162</span>    X_binned, all_gradients, all_hessians = _make_training_data(n_bins=n_bins)</div>
<div class="line"><span class="lineno">  163</span>    grower = TreeGrower(</div>
<div class="line"><span class="lineno">  164</span>        X_binned,</div>
<div class="line"><span class="lineno">  165</span>        all_gradients,</div>
<div class="line"><span class="lineno">  166</span>        all_hessians,</div>
<div class="line"><span class="lineno">  167</span>        n_bins=n_bins,</div>
<div class="line"><span class="lineno">  168</span>        shrinkage=1.0,</div>
<div class="line"><span class="lineno">  169</span>        max_leaf_nodes=3,</div>
<div class="line"><span class="lineno">  170</span>        min_samples_leaf=5,</div>
<div class="line"><span class="lineno">  171</span>    )</div>
<div class="line"><span class="lineno">  172</span>    grower.grow()</div>
<div class="line"><span class="lineno">  173</span>    <span class="keyword">assert</span> grower.n_nodes == 5  <span class="comment"># (2 decision nodes + 3 leaves)</span></div>
<div class="line"><span class="lineno">  174</span> </div>
<div class="line"><span class="lineno">  175</span>    <span class="comment"># Check that the node structure can be converted into a predictor</span></div>
<div class="line"><span class="lineno">  176</span>    <span class="comment"># object to perform predictions at scale</span></div>
<div class="line"><span class="lineno">  177</span>    <span class="comment"># We pass undefined binning_thresholds because we won&#39;t use predict anyway</span></div>
<div class="line"><span class="lineno">  178</span>    predictor = grower.make_predictor(</div>
<div class="line"><span class="lineno">  179</span>        binning_thresholds=np.zeros((X_binned.shape[1], n_bins))</div>
<div class="line"><span class="lineno">  180</span>    )</div>
<div class="line"><span class="lineno">  181</span>    <span class="keyword">assert</span> predictor.nodes.shape[0] == 5</div>
<div class="line"><span class="lineno">  182</span>    <span class="keyword">assert</span> predictor.nodes[<span class="stringliteral">&quot;is_leaf&quot;</span>].sum() == 3</div>
<div class="line"><span class="lineno">  183</span> </div>
<div class="line"><span class="lineno">  184</span>    <span class="comment"># Probe some predictions for each leaf of the tree</span></div>
<div class="line"><span class="lineno">  185</span>    <span class="comment"># each group of 3 samples corresponds to a condition in _make_training_data</span></div>
<div class="line"><span class="lineno">  186</span>    input_data = np.array(</div>
<div class="line"><span class="lineno">  187</span>        [</div>
<div class="line"><span class="lineno">  188</span>            [0, 0],</div>
<div class="line"><span class="lineno">  189</span>            [42, 99],</div>
<div class="line"><span class="lineno">  190</span>            [128, 254],</div>
<div class="line"><span class="lineno">  191</span>            [129, 0],</div>
<div class="line"><span class="lineno">  192</span>            [129, 85],</div>
<div class="line"><span class="lineno">  193</span>            [254, 85],</div>
<div class="line"><span class="lineno">  194</span>            [129, 86],</div>
<div class="line"><span class="lineno">  195</span>            [129, 254],</div>
<div class="line"><span class="lineno">  196</span>            [242, 100],</div>
<div class="line"><span class="lineno">  197</span>        ],</div>
<div class="line"><span class="lineno">  198</span>        dtype=np.uint8,</div>
<div class="line"><span class="lineno">  199</span>    )</div>
<div class="line"><span class="lineno">  200</span>    missing_values_bin_idx = n_bins - 1</div>
<div class="line"><span class="lineno">  201</span>    predictions = predictor.predict_binned(</div>
<div class="line"><span class="lineno">  202</span>        input_data, missing_values_bin_idx, n_threads</div>
<div class="line"><span class="lineno">  203</span>    )</div>
<div class="line"><span class="lineno">  204</span>    expected_targets = [1, 1, 1, 1, 1, 1, -1, -1, -1]</div>
<div class="line"><span class="lineno">  205</span>    <span class="keyword">assert</span> np.allclose(predictions, expected_targets)</div>
<div class="line"><span class="lineno">  206</span> </div>
<div class="line"><span class="lineno">  207</span>    <span class="comment"># Check that training set can be recovered exactly:</span></div>
<div class="line"><span class="lineno">  208</span>    predictions = predictor.predict_binned(X_binned, missing_values_bin_idx, n_threads)</div>
<div class="line"><span class="lineno">  209</span>    <span class="keyword">assert</span> np.allclose(predictions, -all_gradients)</div>
<div class="line"><span class="lineno">  210</span> </div>
<div class="line"><span class="lineno">  211</span> </div>
<div class="line"><span class="lineno">  212</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  213</span>    <span class="stringliteral">&quot;n_samples, min_samples_leaf, n_bins, constant_hessian, noise&quot;</span>,</div>
<div class="line"><span class="lineno">  214</span>    [</div>
<div class="line"><span class="lineno">  215</span>        (11, 10, 7, <span class="keyword">True</span>, 0),</div>
<div class="line"><span class="lineno">  216</span>        (13, 10, 42, <span class="keyword">False</span>, 0),</div>
<div class="line"><span class="lineno">  217</span>        (56, 10, 255, <span class="keyword">True</span>, 0.1),</div>
<div class="line"><span class="lineno">  218</span>        (101, 3, 7, <span class="keyword">True</span>, 0),</div>
<div class="line"><span class="lineno">  219</span>        (200, 42, 42, <span class="keyword">False</span>, 0),</div>
<div class="line"><span class="lineno">  220</span>        (300, 55, 255, <span class="keyword">True</span>, 0.1),</div>
<div class="line"><span class="lineno">  221</span>        (300, 301, 255, <span class="keyword">True</span>, 0.1),</div>
<div class="line"><span class="lineno">  222</span>    ],</div>
<div class="line"><span class="lineno">  223</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a2cba6e2d2e0cce77c523bde9b27ad6e7" name="a2cba6e2d2e0cce77c523bde9b27ad6e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2cba6e2d2e0cce77c523bde9b27ad6e7">&#9670;&#160;</a></span>test_split_on_nan_with_infinite_values()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.test_split_on_nan_with_infinite_values </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  393</span><span class="keyword">def </span>test_split_on_nan_with_infinite_values():</div>
<div class="line"><span class="lineno">  394</span>    <span class="comment"># Make sure the split on nan situations are respected even when there are</span></div>
<div class="line"><span class="lineno">  395</span>    <span class="comment"># samples with +inf values (we set the threshold to +inf when we have a</span></div>
<div class="line"><span class="lineno">  396</span>    <span class="comment"># split on nan so this test makes sure this does not introduce edge-case</span></div>
<div class="line"><span class="lineno">  397</span>    <span class="comment"># bugs). We need to use the private API so that we can also test</span></div>
<div class="line"><span class="lineno">  398</span>    <span class="comment"># predict_binned().</span></div>
<div class="line"><span class="lineno">  399</span> </div>
<div class="line"><span class="lineno">  400</span>    X = np.array([0, 1, np.inf, np.nan, np.nan]).reshape(-1, 1)</div>
<div class="line"><span class="lineno">  401</span>    <span class="comment"># the gradient values will force a split on nan situation</span></div>
<div class="line"><span class="lineno">  402</span>    gradients = np.array([0, 0, 0, 100, 100], dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  403</span>    hessians = np.ones(shape=1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  404</span> </div>
<div class="line"><span class="lineno">  405</span>    bin_mapper = _BinMapper()</div>
<div class="line"><span class="lineno">  406</span>    X_binned = bin_mapper.fit_transform(X)</div>
<div class="line"><span class="lineno">  407</span> </div>
<div class="line"><span class="lineno">  408</span>    n_bins_non_missing = 3</div>
<div class="line"><span class="lineno">  409</span>    has_missing_values = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  410</span>    grower = TreeGrower(</div>
<div class="line"><span class="lineno">  411</span>        X_binned,</div>
<div class="line"><span class="lineno">  412</span>        gradients,</div>
<div class="line"><span class="lineno">  413</span>        hessians,</div>
<div class="line"><span class="lineno">  414</span>        n_bins_non_missing=n_bins_non_missing,</div>
<div class="line"><span class="lineno">  415</span>        has_missing_values=has_missing_values,</div>
<div class="line"><span class="lineno">  416</span>        min_samples_leaf=1,</div>
<div class="line"><span class="lineno">  417</span>        n_threads=n_threads,</div>
<div class="line"><span class="lineno">  418</span>    )</div>
<div class="line"><span class="lineno">  419</span> </div>
<div class="line"><span class="lineno">  420</span>    grower.grow()</div>
<div class="line"><span class="lineno">  421</span> </div>
<div class="line"><span class="lineno">  422</span>    predictor = grower.make_predictor(binning_thresholds=bin_mapper.bin_thresholds_)</div>
<div class="line"><span class="lineno">  423</span> </div>
<div class="line"><span class="lineno">  424</span>    <span class="comment"># sanity check: this was a split on nan</span></div>
<div class="line"><span class="lineno">  425</span>    <span class="keyword">assert</span> predictor.nodes[0][<span class="stringliteral">&quot;num_threshold&quot;</span>] == np.inf</div>
<div class="line"><span class="lineno">  426</span>    <span class="keyword">assert</span> predictor.nodes[0][<span class="stringliteral">&quot;bin_threshold&quot;</span>] == n_bins_non_missing - 1</div>
<div class="line"><span class="lineno">  427</span> </div>
<div class="line"><span class="lineno">  428</span>    known_cat_bitsets, f_idx_map = bin_mapper.make_known_categories_bitsets()</div>
<div class="line"><span class="lineno">  429</span> </div>
<div class="line"><span class="lineno">  430</span>    <span class="comment"># Make sure in particular that the +inf sample is mapped to the left child</span></div>
<div class="line"><span class="lineno">  431</span>    <span class="comment"># Note that lightgbm &quot;fails&quot; here and will assign the inf sample to the</span></div>
<div class="line"><span class="lineno">  432</span>    <span class="comment"># right child, even though it&#39;s a &quot;split on nan&quot; situation.</span></div>
<div class="line"><span class="lineno">  433</span>    predictions = predictor.predict(X, known_cat_bitsets, f_idx_map, n_threads)</div>
<div class="line"><span class="lineno">  434</span>    predictions_binned = predictor.predict_binned(</div>
<div class="line"><span class="lineno">  435</span>        X_binned,</div>
<div class="line"><span class="lineno">  436</span>        missing_values_bin_idx=bin_mapper.missing_values_bin_idx_,</div>
<div class="line"><span class="lineno">  437</span>        n_threads=n_threads,</div>
<div class="line"><span class="lineno">  438</span>    )</div>
<div class="line"><span class="lineno">  439</span>    np.testing.assert_allclose(predictions, -gradients)</div>
<div class="line"><span class="lineno">  440</span>    np.testing.assert_allclose(predictions_binned, -gradients)</div>
<div class="line"><span class="lineno">  441</span> </div>
<div class="line"><span class="lineno">  442</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="ac2adf66fce642f507af8b4b5f36002f3" name="ac2adf66fce642f507af8b4b5f36002f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac2adf66fce642f507af8b4b5f36002f3">&#9670;&#160;</a></span>n_threads</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_grower.n_threads = _openmp_effective_n_threads()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
