<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.random_projection Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1random__projection.html">random_projection</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.random_projection Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1random__projection_1_1_base_random_projection.html">BaseRandomProjection</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1random__projection_1_1_gaussian_random_projection.html">GaussianRandomProjection</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1random__projection_1_1_sparse_random_projection.html">SparseRandomProjection</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a3c69fa485bc9f86574f0ddbcb931d55c" id="r_a3c69fa485bc9f86574f0ddbcb931d55c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1random__projection.html#a3c69fa485bc9f86574f0ddbcb931d55c">johnson_lindenstrauss_min_dim</a> (n_samples, *<a class="el" href="__lapack__subroutines_8h.html#a57833d05f43fd1408080af6eec88fc43">eps</a>=0.1)</td></tr>
<tr class="separator:a3c69fa485bc9f86574f0ddbcb931d55c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66706d21724ce9e236c5f0c6bb41e387" id="r_a66706d21724ce9e236c5f0c6bb41e387"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1random__projection.html#a66706d21724ce9e236c5f0c6bb41e387">_check_density</a> (density, n_features)</td></tr>
<tr class="separator:a66706d21724ce9e236c5f0c6bb41e387"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72efdca9566f07c9d433955e897f9382" id="r_a72efdca9566f07c9d433955e897f9382"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1random__projection.html#a72efdca9566f07c9d433955e897f9382">_check_input_size</a> (n_components, n_features)</td></tr>
<tr class="separator:a72efdca9566f07c9d433955e897f9382"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e26fab5bcaccd2ea9d1cfddd14a3ec5" id="r_a7e26fab5bcaccd2ea9d1cfddd14a3ec5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1random__projection.html#a7e26fab5bcaccd2ea9d1cfddd14a3ec5">_gaussian_random_matrix</a> (n_components, n_features, random_state=None)</td></tr>
<tr class="separator:a7e26fab5bcaccd2ea9d1cfddd14a3ec5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ceeef82d1e6f864b03b1fac5a991ca5" id="r_a7ceeef82d1e6f864b03b1fac5a991ca5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1random__projection.html#a7ceeef82d1e6f864b03b1fac5a991ca5">_sparse_random_matrix</a> (n_components, n_features, density=&quot;auto&quot;, random_state=None)</td></tr>
<tr class="separator:a7ceeef82d1e6f864b03b1fac5a991ca5"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Random Projection transformers.

Random Projections are a simple and computationally efficient way to
reduce the dimensionality of the data by trading a controlled amount
of accuracy (as additional variance) for faster processing times and
smaller model sizes.

The dimensions and distribution of Random Projections matrices are
controlled so as to preserve the pairwise distances between any two
samples of the dataset.

The main theoretical result behind the efficiency of random projection is the
`Johnson-Lindenstrauss lemma (quoting Wikipedia)
&lt;https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma&gt;`_:

  In mathematics, the Johnson-Lindenstrauss lemma is a result
  concerning low-distortion embeddings of points from high-dimensional
  into low-dimensional Euclidean space. The lemma states that a small set
  of points in a high-dimensional space can be embedded into a space of
  much lower dimension in such a way that distances between the points are
  nearly preserved. The map used for the embedding is at least Lipschitz,
  and can even be taken to be an orthogonal projection.</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a66706d21724ce9e236c5f0c6bb41e387" name="a66706d21724ce9e236c5f0c6bb41e387"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a66706d21724ce9e236c5f0c6bb41e387">&#9670;&#160;</a></span>_check_density()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.random_projection._check_density </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>density</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_features</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Factorize density check according to Li et al.</pre> <div class="fragment"><div class="line"><span class="lineno">  136</span><span class="keyword">def </span>_check_density(density, n_features):</div>
<div class="line"><span class="lineno">  137</span>    <span class="stringliteral">&quot;&quot;&quot;Factorize density check according to Li et al.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  138</span>    <span class="keywordflow">if</span> density == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  139</span>        density = 1 / np.sqrt(n_features)</div>
<div class="line"><span class="lineno">  140</span> </div>
<div class="line"><span class="lineno">  141</span>    <span class="keywordflow">elif</span> density &lt;= 0 <span class="keywordflow">or</span> density &gt; 1:</div>
<div class="line"><span class="lineno">  142</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Expected density in range ]0, 1], got: %r&quot;</span> % density)</div>
<div class="line"><span class="lineno">  143</span>    <span class="keywordflow">return</span> density</div>
<div class="line"><span class="lineno">  144</span> </div>
<div class="line"><span class="lineno">  145</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a72efdca9566f07c9d433955e897f9382" name="a72efdca9566f07c9d433955e897f9382"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a72efdca9566f07c9d433955e897f9382">&#9670;&#160;</a></span>_check_input_size()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.random_projection._check_input_size </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_components</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_features</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Factorize argument checking for random matrix generation.</pre> <div class="fragment"><div class="line"><span class="lineno">  146</span><span class="keyword">def </span>_check_input_size(n_components, n_features):</div>
<div class="line"><span class="lineno">  147</span>    <span class="stringliteral">&quot;&quot;&quot;Factorize argument checking for random matrix generation.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  148</span>    <span class="keywordflow">if</span> n_components &lt;= 0:</div>
<div class="line"><span class="lineno">  149</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  150</span>            <span class="stringliteral">&quot;n_components must be strictly positive, got %d&quot;</span> % n_components</div>
<div class="line"><span class="lineno">  151</span>        )</div>
<div class="line"><span class="lineno">  152</span>    <span class="keywordflow">if</span> n_features &lt;= 0:</div>
<div class="line"><span class="lineno">  153</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;n_features must be strictly positive, got %d&quot;</span> % n_features)</div>
<div class="line"><span class="lineno">  154</span> </div>
<div class="line"><span class="lineno">  155</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7e26fab5bcaccd2ea9d1cfddd14a3ec5" name="a7e26fab5bcaccd2ea9d1cfddd14a3ec5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7e26fab5bcaccd2ea9d1cfddd14a3ec5">&#9670;&#160;</a></span>_gaussian_random_matrix()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.random_projection._gaussian_random_matrix </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_components</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_features</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate a dense Gaussian random matrix.

The components of the random matrix are drawn from

    N(0, 1.0 / n_components).

Read more in the :ref:`User Guide &lt;gaussian_random_matrix&gt;`.

Parameters
----------
n_components : int,
    Dimensionality of the target projection space.

n_features : int,
    Dimensionality of the original source space.

random_state : int, RandomState instance or None, default=None
    Controls the pseudo random number generator used to generate the matrix
    at fit time.
    Pass an int for reproducible output across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Returns
-------
components : ndarray of shape (n_components, n_features)
    The generated Gaussian random matrix.

See Also
--------
GaussianRandomProjection
</pre> <div class="fragment"><div class="line"><span class="lineno">  156</span><span class="keyword">def </span>_gaussian_random_matrix(n_components, n_features, random_state=None):</div>
<div class="line"><span class="lineno">  157</span>    <span class="stringliteral">&quot;&quot;&quot;Generate a dense Gaussian random matrix.</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">    The components of the random matrix are drawn from</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">        N(0, 1.0 / n_components).</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;gaussian_random_matrix&gt;`.</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">    n_components : int,</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">        Dimensionality of the target projection space.</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">    n_features : int,</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">        Dimensionality of the original source space.</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">    random_state : int, RandomState instance or None, default=None</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">        Controls the pseudo random number generator used to generate the matrix</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">        at fit time.</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">        Pass an int for reproducible output across multiple function calls.</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">    components : ndarray of shape (n_components, n_features)</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">        The generated Gaussian random matrix.</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">    GaussianRandomProjection</span></div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  188</span>    _check_input_size(n_components, n_features)</div>
<div class="line"><span class="lineno">  189</span>    rng = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  190</span>    components = rng.normal(</div>
<div class="line"><span class="lineno">  191</span>        loc=0.0, scale=1.0 / np.sqrt(n_components), size=(n_components, n_features)</div>
<div class="line"><span class="lineno">  192</span>    )</div>
<div class="line"><span class="lineno">  193</span>    <span class="keywordflow">return</span> components</div>
<div class="line"><span class="lineno">  194</span> </div>
<div class="line"><span class="lineno">  195</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7ceeef82d1e6f864b03b1fac5a991ca5" name="a7ceeef82d1e6f864b03b1fac5a991ca5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7ceeef82d1e6f864b03b1fac5a991ca5">&#9670;&#160;</a></span>_sparse_random_matrix()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.random_projection._sparse_random_matrix </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_components</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_features</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>density</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generalized Achlioptas random sparse matrix for random projection.

Setting density to 1 / 3 will yield the original matrix by Dimitris
Achlioptas while setting a lower value will yield the generalization
by Ping Li et al.

If we note :math:`s = 1 / density`, the components of the random matrix are
drawn from:

  - -sqrt(s) / sqrt(n_components)   with probability 1 / 2s
  -  0                              with probability 1 - 1 / s
  - +sqrt(s) / sqrt(n_components)   with probability 1 / 2s

Read more in the :ref:`User Guide &lt;sparse_random_matrix&gt;`.

Parameters
----------
n_components : int,
    Dimensionality of the target projection space.

n_features : int,
    Dimensionality of the original source space.

density : float or 'auto', default='auto'
    Ratio of non-zero component in the random projection matrix in the
    range `(0, 1]`

    If density = 'auto', the value is set to the minimum density
    as recommended by Ping Li et al.: 1 / sqrt(n_features).

    Use density = 1 / 3.0 if you want to reproduce the results from
    Achlioptas, 2001.

random_state : int, RandomState instance or None, default=None
    Controls the pseudo random number generator used to generate the matrix
    at fit time.
    Pass an int for reproducible output across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Returns
-------
components : {ndarray, sparse matrix} of shape (n_components, n_features)
    The generated Gaussian random matrix. Sparse matrix will be of CSR
    format.

See Also
--------
SparseRandomProjection

References
----------

.. [1] Ping Li, T. Hastie and K. W. Church, 2006,
       "Very Sparse Random Projections".
       https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf

.. [2] D. Achlioptas, 2001, "Database-friendly random projections",
       https://cgi.di.uoa.gr/~optas/papers/jl.pdf</pre> <div class="fragment"><div class="line"><span class="lineno">  196</span><span class="keyword">def </span>_sparse_random_matrix(n_components, n_features, density=&quot;auto&quot;, random_state=None):</div>
<div class="line"><span class="lineno">  197</span>    <span class="stringliteral">&quot;&quot;&quot;Generalized Achlioptas random sparse matrix for random projection.</span></div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">    Setting density to 1 / 3 will yield the original matrix by Dimitris</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral">    Achlioptas while setting a lower value will yield the generalization</span></div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral">    by Ping Li et al.</span></div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  203</span><span class="stringliteral">    If we note :math:`s = 1 / density`, the components of the random matrix are</span></div>
<div class="line"><span class="lineno">  204</span><span class="stringliteral">    drawn from:</span></div>
<div class="line"><span class="lineno">  205</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  206</span><span class="stringliteral">      - -sqrt(s) / sqrt(n_components)   with probability 1 / 2s</span></div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral">      -  0                              with probability 1 - 1 / s</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">      - +sqrt(s) / sqrt(n_components)   with probability 1 / 2s</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;sparse_random_matrix&gt;`.</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">    n_components : int,</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">        Dimensionality of the target projection space.</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">    n_features : int,</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">        Dimensionality of the original source space.</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">    density : float or &#39;auto&#39;, default=&#39;auto&#39;</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">        Ratio of non-zero component in the random projection matrix in the</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">        range `(0, 1]`</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">        If density = &#39;auto&#39;, the value is set to the minimum density</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">        as recommended by Ping Li et al.: 1 / sqrt(n_features).</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">        Use density = 1 / 3.0 if you want to reproduce the results from</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">        Achlioptas, 2001.</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">    random_state : int, RandomState instance or None, default=None</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">        Controls the pseudo random number generator used to generate the matrix</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">        at fit time.</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">        Pass an int for reproducible output across multiple function calls.</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">    components : {ndarray, sparse matrix} of shape (n_components, n_features)</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        The generated Gaussian random matrix. Sparse matrix will be of CSR</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">        format.</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">    SparseRandomProjection</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">    .. [1] Ping Li, T. Hastie and K. W. Church, 2006,</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">           &quot;Very Sparse Random Projections&quot;.</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">           https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">    .. [2] D. Achlioptas, 2001, &quot;Database-friendly random projections&quot;,</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">           https://cgi.di.uoa.gr/~optas/papers/jl.pdf</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  257</span>    _check_input_size(n_components, n_features)</div>
<div class="line"><span class="lineno">  258</span>    density = _check_density(density, n_features)</div>
<div class="line"><span class="lineno">  259</span>    rng = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  260</span> </div>
<div class="line"><span class="lineno">  261</span>    <span class="keywordflow">if</span> density == 1:</div>
<div class="line"><span class="lineno">  262</span>        <span class="comment"># skip index generation if totally dense</span></div>
<div class="line"><span class="lineno">  263</span>        components = rng.binomial(1, 0.5, (n_components, n_features)) * 2 - 1</div>
<div class="line"><span class="lineno">  264</span>        <span class="keywordflow">return</span> 1 / np.sqrt(n_components) * components</div>
<div class="line"><span class="lineno">  265</span> </div>
<div class="line"><span class="lineno">  266</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  267</span>        <span class="comment"># Generate location of non zero elements</span></div>
<div class="line"><span class="lineno">  268</span>        indices = []</div>
<div class="line"><span class="lineno">  269</span>        offset = 0</div>
<div class="line"><span class="lineno">  270</span>        indptr = [offset]</div>
<div class="line"><span class="lineno">  271</span>        <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(n_components):</div>
<div class="line"><span class="lineno">  272</span>            <span class="comment"># find the indices of the non-zero components for row i</span></div>
<div class="line"><span class="lineno">  273</span>            n_nonzero_i = rng.binomial(n_features, density)</div>
<div class="line"><span class="lineno">  274</span>            indices_i = sample_without_replacement(</div>
<div class="line"><span class="lineno">  275</span>                n_features, n_nonzero_i, random_state=rng</div>
<div class="line"><span class="lineno">  276</span>            )</div>
<div class="line"><span class="lineno">  277</span>            indices.append(indices_i)</div>
<div class="line"><span class="lineno">  278</span>            offset += n_nonzero_i</div>
<div class="line"><span class="lineno">  279</span>            indptr.append(offset)</div>
<div class="line"><span class="lineno">  280</span> </div>
<div class="line"><span class="lineno">  281</span>        indices = np.concatenate(indices)</div>
<div class="line"><span class="lineno">  282</span> </div>
<div class="line"><span class="lineno">  283</span>        <span class="comment"># Among non zero components the probability of the sign is 50%/50%</span></div>
<div class="line"><span class="lineno">  284</span>        data = rng.binomial(1, 0.5, size=np.size(indices)) * 2 - 1</div>
<div class="line"><span class="lineno">  285</span> </div>
<div class="line"><span class="lineno">  286</span>        <span class="comment"># build the CSR structure by concatenating the rows</span></div>
<div class="line"><span class="lineno">  287</span>        components = sp.csr_matrix(</div>
<div class="line"><span class="lineno">  288</span>            (data, indices, indptr), shape=(n_components, n_features)</div>
<div class="line"><span class="lineno">  289</span>        )</div>
<div class="line"><span class="lineno">  290</span> </div>
<div class="line"><span class="lineno">  291</span>        <span class="keywordflow">return</span> np.sqrt(1 / density) / np.sqrt(n_components) * components</div>
<div class="line"><span class="lineno">  292</span> </div>
<div class="line"><span class="lineno">  293</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3c69fa485bc9f86574f0ddbcb931d55c" name="a3c69fa485bc9f86574f0ddbcb931d55c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3c69fa485bc9f86574f0ddbcb931d55c">&#9670;&#160;</a></span>johnson_lindenstrauss_min_dim()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.random_projection.johnson_lindenstrauss_min_dim </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>eps</em> = <code>0.1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Find a 'safe' number of components to randomly project to.

The distortion introduced by a random projection `p` only changes the
distance between two points by a factor (1 +- eps) in an euclidean space
with good probability. The projection `p` is an eps-embedding as defined
by:

  (1 - eps) ||u - v||^2 &lt; ||p(u) - p(v)||^2 &lt; (1 + eps) ||u - v||^2

Where u and v are any rows taken from a dataset of shape (n_samples,
n_features), eps is in ]0, 1[ and p is a projection by a random Gaussian
N(0, 1) matrix of shape (n_components, n_features) (or a sparse
Achlioptas matrix).

The minimum number of components to guarantee the eps-embedding is
given by:

  n_components &gt;= 4 log(n_samples) / (eps^2 / 2 - eps^3 / 3)

Note that the number of dimensions is independent of the original
number of features but instead depends on the size of the dataset:
the larger the dataset, the higher is the minimal dimensionality of
an eps-embedding.

Read more in the :ref:`User Guide &lt;johnson_lindenstrauss&gt;`.

Parameters
----------
n_samples : int or array-like of int
    Number of samples that should be a integer greater than 0. If an array
    is given, it will compute a safe number of components array-wise.

eps : float or ndarray of shape (n_components,), dtype=float, \
        default=0.1
    Maximum distortion rate in the range (0,1 ) as defined by the
    Johnson-Lindenstrauss lemma. If an array is given, it will compute a
    safe number of components array-wise.

Returns
-------
n_components : int or ndarray of int
    The minimal number of components to guarantee with good probability
    an eps-embedding with n_samples.

References
----------

.. [1] https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma

.. [2] `Sanjoy Dasgupta and Anupam Gupta, 1999,
       "An elementary proof of the Johnson-Lindenstrauss Lemma."
       &lt;https://citeseerx.ist.psu.edu/doc_view/pid/95cd464d27c25c9c8690b378b894d337cdf021f9&gt;`_

Examples
--------
&gt;&gt;&gt; from sklearn.random_projection import johnson_lindenstrauss_min_dim
&gt;&gt;&gt; johnson_lindenstrauss_min_dim(1e6, eps=0.5)
663

&gt;&gt;&gt; johnson_lindenstrauss_min_dim(1e6, eps=[0.5, 0.1, 0.01])
array([    663,   11841, 1112658])

&gt;&gt;&gt; johnson_lindenstrauss_min_dim([1e4, 1e5, 1e6], eps=0.1)
array([ 7894,  9868, 11841])
</pre> <div class="fragment"><div class="line"><span class="lineno">   54</span><span class="keyword">def </span>johnson_lindenstrauss_min_dim(n_samples, *, eps=0.1):</div>
<div class="line"><span class="lineno">   55</span>    <span class="stringliteral">&quot;&quot;&quot;Find a &#39;safe&#39; number of components to randomly project to.</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral">    The distortion introduced by a random projection `p` only changes the</span></div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral">    distance between two points by a factor (1 +- eps) in an euclidean space</span></div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">    with good probability. The projection `p` is an eps-embedding as defined</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">    by:</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">      (1 - eps) ||u - v||^2 &lt; ||p(u) - p(v)||^2 &lt; (1 + eps) ||u - v||^2</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    Where u and v are any rows taken from a dataset of shape (n_samples,</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">    n_features), eps is in ]0, 1[ and p is a projection by a random Gaussian</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">    N(0, 1) matrix of shape (n_components, n_features) (or a sparse</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    Achlioptas matrix).</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral">    The minimum number of components to guarantee the eps-embedding is</span></div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    given by:</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">      n_components &gt;= 4 log(n_samples) / (eps^2 / 2 - eps^3 / 3)</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">    Note that the number of dimensions is independent of the original</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">    number of features but instead depends on the size of the dataset:</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">    the larger the dataset, the higher is the minimal dimensionality of</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    an eps-embedding.</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;johnson_lindenstrauss&gt;`.</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">    n_samples : int or array-like of int</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral">        Number of samples that should be a integer greater than 0. If an array</span></div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">        is given, it will compute a safe number of components array-wise.</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">    eps : float or ndarray of shape (n_components,), dtype=float, \</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">            default=0.1</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">        Maximum distortion rate in the range (0,1 ) as defined by the</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">        Johnson-Lindenstrauss lemma. If an array is given, it will compute a</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">        safe number of components array-wise.</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral">    n_components : int or ndarray of int</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral">        The minimal number of components to guarantee with good probability</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral">        an eps-embedding with n_samples.</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral">    .. [1] https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma</span></div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">    .. [2] `Sanjoy Dasgupta and Anupam Gupta, 1999,</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral">           &quot;An elementary proof of the Johnson-Lindenstrauss Lemma.&quot;</span></div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral">           &lt;https://citeseerx.ist.psu.edu/doc_view/pid/95cd464d27c25c9c8690b378b894d337cdf021f9&gt;`_</span></div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.random_projection import johnson_lindenstrauss_min_dim</span></div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral">    &gt;&gt;&gt; johnson_lindenstrauss_min_dim(1e6, eps=0.5)</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral">    663</span></div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">    &gt;&gt;&gt; johnson_lindenstrauss_min_dim(1e6, eps=[0.5, 0.1, 0.01])</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">    array([    663,   11841, 1112658])</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">    &gt;&gt;&gt; johnson_lindenstrauss_min_dim([1e4, 1e5, 1e6], eps=0.1)</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">    array([ 7894,  9868, 11841])</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  120</span>    eps = np.asarray(eps)</div>
<div class="line"><span class="lineno">  121</span>    n_samples = np.asarray(n_samples)</div>
<div class="line"><span class="lineno">  122</span> </div>
<div class="line"><span class="lineno">  123</span>    <span class="keywordflow">if</span> np.any(eps &lt;= 0.0) <span class="keywordflow">or</span> np.any(eps &gt;= 1):</div>
<div class="line"><span class="lineno">  124</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;The JL bound is defined for eps in ]0, 1[, got %r&quot;</span> % eps)</div>
<div class="line"><span class="lineno">  125</span> </div>
<div class="line"><span class="lineno">  126</span>    <span class="keywordflow">if</span> np.any(n_samples) &lt;= 0:</div>
<div class="line"><span class="lineno">  127</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  128</span>            <span class="stringliteral">&quot;The JL bound is defined for n_samples greater than zero, got %r&quot;</span></div>
<div class="line"><span class="lineno">  129</span>            % n_samples</div>
<div class="line"><span class="lineno">  130</span>        )</div>
<div class="line"><span class="lineno">  131</span> </div>
<div class="line"><span class="lineno">  132</span>    denominator = (eps**2 / 2) - (eps**3 / 3)</div>
<div class="line"><span class="lineno">  133</span>    <span class="keywordflow">return</span> (4 * np.log(n_samples) / denominator).astype(np.int64)</div>
<div class="line"><span class="lineno">  134</span> </div>
<div class="line"><span class="lineno">  135</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
