<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.linear_model._ridge Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model.html">linear_model</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html">_ridge</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.linear_model._ridge Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1___base_ridge.html">_BaseRidge</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1___base_ridge_c_v.html">_BaseRidgeCV</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1___identity_classifier.html">_IdentityClassifier</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1___identity_regressor.html">_IdentityRegressor</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1___ridge_classifier_mixin.html">_RidgeClassifierMixin</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1___ridge_g_c_v.html">_RidgeGCV</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1___x___center_stack_op.html">_X_CenterStackOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1___x_t___center_stack_op.html">_XT_CenterStackOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1_ridge.html">Ridge</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1_ridge_classifier.html">RidgeClassifier</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1_ridge_classifier_c_v.html">RidgeClassifierCV</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__ridge_1_1_ridge_c_v.html">RidgeCV</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a795b22ea17397cfd97b4d7ef98508b37" id="r_a795b22ea17397cfd97b4d7ef98508b37"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#a795b22ea17397cfd97b4d7ef98508b37">_get_rescaled_operator</a> (X, X_offset, sample_weight_sqrt)</td></tr>
<tr class="separator:a795b22ea17397cfd97b4d7ef98508b37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56d787b3475471d14facd04607a0e15a" id="r_a56d787b3475471d14facd04607a0e15a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#a56d787b3475471d14facd04607a0e15a">_solve_sparse_cg</a> (X, y, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, max_iter=None, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-4, verbose=0, X_offset=None, X_scale=None, sample_weight_sqrt=None)</td></tr>
<tr class="separator:a56d787b3475471d14facd04607a0e15a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55c3fa41a319fbd6bfb8a718f1eeff57" id="r_a55c3fa41a319fbd6bfb8a718f1eeff57"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#a55c3fa41a319fbd6bfb8a718f1eeff57">_solve_lsqr</a> (X, y, *<a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, fit_intercept=True, max_iter=None, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-4, X_offset=None, X_scale=None, sample_weight_sqrt=None)</td></tr>
<tr class="separator:a55c3fa41a319fbd6bfb8a718f1eeff57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa184b154e12613beead709efe18e1473" id="r_aa184b154e12613beead709efe18e1473"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#aa184b154e12613beead709efe18e1473">_solve_cholesky</a> (X, y, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>)</td></tr>
<tr class="separator:aa184b154e12613beead709efe18e1473"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91b5180ca5403e673bb49a1cc983c7fb" id="r_a91b5180ca5403e673bb49a1cc983c7fb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#a91b5180ca5403e673bb49a1cc983c7fb">_solve_cholesky_kernel</a> (K, y, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, sample_weight=None, copy=False)</td></tr>
<tr class="separator:a91b5180ca5403e673bb49a1cc983c7fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a922be031c6605a90386fc8179521ee44" id="r_a922be031c6605a90386fc8179521ee44"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#a922be031c6605a90386fc8179521ee44">_solve_svd</a> (X, y, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>)</td></tr>
<tr class="separator:a922be031c6605a90386fc8179521ee44"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91df6db9c40254448075d9b8920e0111" id="r_a91df6db9c40254448075d9b8920e0111"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#a91df6db9c40254448075d9b8920e0111">_solve_lbfgs</a> (X, y, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, positive=True, max_iter=None, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-4, X_offset=None, X_scale=None, sample_weight_sqrt=None)</td></tr>
<tr class="separator:a91df6db9c40254448075d9b8920e0111"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1f2e3f483b38f77b5eaa5d6ca708ab0" id="r_ae1f2e3f483b38f77b5eaa5d6ca708ab0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#ae1f2e3f483b38f77b5eaa5d6ca708ab0">_get_valid_accept_sparse</a> (is_X_sparse, solver)</td></tr>
<tr class="separator:ae1f2e3f483b38f77b5eaa5d6ca708ab0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa523d6124f2b23b752603695a2c96674" id="r_aa523d6124f2b23b752603695a2c96674"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#aa523d6124f2b23b752603695a2c96674">ridge_regression</a> (X, y, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, *sample_weight=None, solver=&quot;auto&quot;, max_iter=None, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-4, verbose=0, positive=False, random_state=None, return_n_iter=False, return_intercept=False, check_input=True)</td></tr>
<tr class="separator:aa523d6124f2b23b752603695a2c96674"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c8385ff30449f006507f315c104a323" id="r_a1c8385ff30449f006507f315c104a323"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#a1c8385ff30449f006507f315c104a323">_ridge_regression</a> (X, y, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, sample_weight=None, solver=&quot;auto&quot;, max_iter=None, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-4, verbose=0, positive=False, random_state=None, return_n_iter=False, return_intercept=False, X_scale=None, X_offset=None, check_input=True, fit_intercept=False)</td></tr>
<tr class="separator:a1c8385ff30449f006507f315c104a323"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a348f25c593d0291db80e203699ca8061" id="r_a348f25c593d0291db80e203699ca8061"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#a348f25c593d0291db80e203699ca8061">_check_gcv_mode</a> (X, gcv_mode)</td></tr>
<tr class="separator:a348f25c593d0291db80e203699ca8061"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3808616fb4e997b0aae9d88c8c8e0a8" id="r_af3808616fb4e997b0aae9d88c8c8e0a8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__ridge.html#af3808616fb4e997b0aae9d88c8c8e0a8">_find_smallest_angle</a> (query, vectors)</td></tr>
<tr class="separator:af3808616fb4e997b0aae9d88c8c8e0a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Ridge regression
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a348f25c593d0291db80e203699ca8061" name="a348f25c593d0291db80e203699ca8061"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a348f25c593d0291db80e203699ca8061">&#9670;&#160;</a></span>_check_gcv_mode()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._check_gcv_mode </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gcv_mode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1428</span><span class="keyword">def </span>_check_gcv_mode(X, gcv_mode):</div>
<div class="line"><span class="lineno"> 1429</span>    <span class="keywordflow">if</span> gcv_mode <span class="keywordflow">in</span> [<span class="stringliteral">&quot;eigen&quot;</span>, <span class="stringliteral">&quot;svd&quot;</span>]:</div>
<div class="line"><span class="lineno"> 1430</span>        <span class="keywordflow">return</span> gcv_mode</div>
<div class="line"><span class="lineno"> 1431</span>    <span class="comment"># if X has more rows than columns, use decomposition of X^T.X,</span></div>
<div class="line"><span class="lineno"> 1432</span>    <span class="comment"># otherwise X.X^T</span></div>
<div class="line"><span class="lineno"> 1433</span>    <span class="keywordflow">if</span> X.shape[0] &gt; X.shape[1]:</div>
<div class="line"><span class="lineno"> 1434</span>        <span class="keywordflow">return</span> <span class="stringliteral">&quot;svd&quot;</span></div>
<div class="line"><span class="lineno"> 1435</span>    <span class="keywordflow">return</span> <span class="stringliteral">&quot;eigen&quot;</span></div>
<div class="line"><span class="lineno"> 1436</span> </div>
<div class="line"><span class="lineno"> 1437</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af3808616fb4e997b0aae9d88c8c8e0a8" name="af3808616fb4e997b0aae9d88c8c8e0a8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af3808616fb4e997b0aae9d88c8c8e0a8">&#9670;&#160;</a></span>_find_smallest_angle()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._find_smallest_angle </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>query</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vectors</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Find the column of vectors that is most aligned with the query.

Both query and the columns of vectors must have their l2 norm equal to 1.

Parameters
----------
query : ndarray of shape (n_samples,)
    Normalized query vector.

vectors : ndarray of shape (n_samples, n_features)
    Vectors to which we compare query, as columns. Must be normalized.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1438</span><span class="keyword">def </span>_find_smallest_angle(query, vectors):</div>
<div class="line"><span class="lineno"> 1439</span>    <span class="stringliteral">&quot;&quot;&quot;Find the column of vectors that is most aligned with the query.</span></div>
<div class="line"><span class="lineno"> 1440</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1441</span><span class="stringliteral">    Both query and the columns of vectors must have their l2 norm equal to 1.</span></div>
<div class="line"><span class="lineno"> 1442</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1443</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1444</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1445</span><span class="stringliteral">    query : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1446</span><span class="stringliteral">        Normalized query vector.</span></div>
<div class="line"><span class="lineno"> 1447</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1448</span><span class="stringliteral">    vectors : ndarray of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno"> 1449</span><span class="stringliteral">        Vectors to which we compare query, as columns. Must be normalized.</span></div>
<div class="line"><span class="lineno"> 1450</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1451</span>    abs_cosine = np.abs(query.dot(vectors))</div>
<div class="line"><span class="lineno"> 1452</span>    index = np.argmax(abs_cosine)</div>
<div class="line"><span class="lineno"> 1453</span>    <span class="keywordflow">return</span> index</div>
<div class="line"><span class="lineno"> 1454</span> </div>
<div class="line"><span class="lineno"> 1455</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a795b22ea17397cfd97b4d7ef98508b37" name="a795b22ea17397cfd97b4d7ef98508b37"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a795b22ea17397cfd97b4d7ef98508b37">&#9670;&#160;</a></span>_get_rescaled_operator()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._get_rescaled_operator </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight_sqrt</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Create LinearOperator for matrix products with implicit centering.

Matrix product `LinearOperator @ coef` returns `(X - X_offset) @ coef`.
</pre> <div class="fragment"><div class="line"><span class="lineno">   47</span><span class="keyword">def </span>_get_rescaled_operator(X, X_offset, sample_weight_sqrt):</div>
<div class="line"><span class="lineno">   48</span>    <span class="stringliteral">&quot;&quot;&quot;Create LinearOperator for matrix products with implicit centering.</span></div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">    Matrix product `LinearOperator @ coef` returns `(X - X_offset) @ coef`.</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   52</span> </div>
<div class="line"><span class="lineno">   53</span>    <span class="keyword">def </span>matvec(b):</div>
<div class="line"><span class="lineno">   54</span>        <span class="keywordflow">return</span> X.dot(b) - sample_weight_sqrt * b.dot(X_offset)</div>
<div class="line"><span class="lineno">   55</span> </div>
<div class="line"><span class="lineno">   56</span>    <span class="keyword">def </span>rmatvec(b):</div>
<div class="line"><span class="lineno">   57</span>        <span class="keywordflow">return</span> X.T.dot(b) - X_offset * b.dot(sample_weight_sqrt)</div>
<div class="line"><span class="lineno">   58</span> </div>
<div class="line"><span class="lineno">   59</span>    X1 = sparse.linalg.LinearOperator(shape=X.shape, matvec=matvec, rmatvec=rmatvec)</div>
<div class="line"><span class="lineno">   60</span>    <span class="keywordflow">return</span> X1</div>
<div class="line"><span class="lineno">   61</span> </div>
<div class="line"><span class="lineno">   62</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae1f2e3f483b38f77b5eaa5d6ca708ab0" name="ae1f2e3f483b38f77b5eaa5d6ca708ab0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1f2e3f483b38f77b5eaa5d6ca708ab0">&#9670;&#160;</a></span>_get_valid_accept_sparse()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._get_valid_accept_sparse </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_X_sparse</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  368</span><span class="keyword">def </span>_get_valid_accept_sparse(is_X_sparse, solver):</div>
<div class="line"><span class="lineno">  369</span>    <span class="keywordflow">if</span> is_X_sparse <span class="keywordflow">and</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;auto&quot;</span>, <span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]:</div>
<div class="line"><span class="lineno">  370</span>        <span class="keywordflow">return</span> <span class="stringliteral">&quot;csr&quot;</span></div>
<div class="line"><span class="lineno">  371</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  372</span>        <span class="keywordflow">return</span> [<span class="stringliteral">&quot;csr&quot;</span>, <span class="stringliteral">&quot;csc&quot;</span>, <span class="stringliteral">&quot;coo&quot;</span>]</div>
<div class="line"><span class="lineno">  373</span> </div>
<div class="line"><span class="lineno">  374</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1c8385ff30449f006507f315c104a323" name="a1c8385ff30449f006507f315c104a323"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c8385ff30449f006507f315c104a323">&#9670;&#160;</a></span>_ridge_regression()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._ridge_regression </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>positive</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_n_iter</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_intercept</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_scale</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_offset</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>check_input</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  573</span>):</div>
<div class="line"><span class="lineno">  574</span> </div>
<div class="line"><span class="lineno">  575</span>    has_sw = sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  576</span> </div>
<div class="line"><span class="lineno">  577</span>    <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  578</span>        <span class="keywordflow">if</span> positive:</div>
<div class="line"><span class="lineno">  579</span>            solver = <span class="stringliteral">&quot;lbfgs&quot;</span></div>
<div class="line"><span class="lineno">  580</span>        <span class="keywordflow">elif</span> return_intercept:</div>
<div class="line"><span class="lineno">  581</span>            <span class="comment"># sag supports fitting intercept directly</span></div>
<div class="line"><span class="lineno">  582</span>            solver = <span class="stringliteral">&quot;sag&quot;</span></div>
<div class="line"><span class="lineno">  583</span>        <span class="keywordflow">elif</span> <span class="keywordflow">not</span> sparse.issparse(X):</div>
<div class="line"><span class="lineno">  584</span>            solver = <span class="stringliteral">&quot;cholesky&quot;</span></div>
<div class="line"><span class="lineno">  585</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  586</span>            solver = <span class="stringliteral">&quot;sparse_cg&quot;</span></div>
<div class="line"><span class="lineno">  587</span> </div>
<div class="line"><span class="lineno">  588</span>    <span class="keywordflow">if</span> solver <span class="keywordflow">not</span> <span class="keywordflow">in</span> (<span class="stringliteral">&quot;sparse_cg&quot;</span>, <span class="stringliteral">&quot;cholesky&quot;</span>, <span class="stringliteral">&quot;svd&quot;</span>, <span class="stringliteral">&quot;lsqr&quot;</span>, <span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>, <span class="stringliteral">&quot;lbfgs&quot;</span>):</div>
<div class="line"><span class="lineno">  589</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  590</span>            <span class="stringliteral">&quot;Known solvers are &#39;sparse_cg&#39;, &#39;cholesky&#39;, &#39;svd&#39;&quot;</span></div>
<div class="line"><span class="lineno">  591</span>            <span class="stringliteral">&quot; &#39;lsqr&#39;, &#39;sag&#39;, &#39;saga&#39; or &#39;lbfgs&#39;. Got %s.&quot;</span> % solver</div>
<div class="line"><span class="lineno">  592</span>        )</div>
<div class="line"><span class="lineno">  593</span> </div>
<div class="line"><span class="lineno">  594</span>    <span class="keywordflow">if</span> positive <span class="keywordflow">and</span> solver != <span class="stringliteral">&quot;lbfgs&quot;</span>:</div>
<div class="line"><span class="lineno">  595</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  596</span>            <span class="stringliteral">&quot;When positive=True, only &#39;lbfgs&#39; solver can be used. &quot;</span></div>
<div class="line"><span class="lineno">  597</span>            f<span class="stringliteral">&quot;Please change solver {solver} to &#39;lbfgs&#39; &quot;</span></div>
<div class="line"><span class="lineno">  598</span>            <span class="stringliteral">&quot;or set positive=False.&quot;</span></div>
<div class="line"><span class="lineno">  599</span>        )</div>
<div class="line"><span class="lineno">  600</span> </div>
<div class="line"><span class="lineno">  601</span>    <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;lbfgs&quot;</span> <span class="keywordflow">and</span> <span class="keywordflow">not</span> positive:</div>
<div class="line"><span class="lineno">  602</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  603</span>            <span class="stringliteral">&quot;&#39;lbfgs&#39; solver can be used only when positive=True. &quot;</span></div>
<div class="line"><span class="lineno">  604</span>            <span class="stringliteral">&quot;Please use another solver.&quot;</span></div>
<div class="line"><span class="lineno">  605</span>        )</div>
<div class="line"><span class="lineno">  606</span> </div>
<div class="line"><span class="lineno">  607</span>    <span class="keywordflow">if</span> return_intercept <span class="keywordflow">and</span> solver != <span class="stringliteral">&quot;sag&quot;</span>:</div>
<div class="line"><span class="lineno">  608</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  609</span>            <span class="stringliteral">&quot;In Ridge, only &#39;sag&#39; solver can directly fit the &quot;</span></div>
<div class="line"><span class="lineno">  610</span>            <span class="stringliteral">&quot;intercept. Please change solver to &#39;sag&#39; or set &quot;</span></div>
<div class="line"><span class="lineno">  611</span>            <span class="stringliteral">&quot;return_intercept=False.&quot;</span></div>
<div class="line"><span class="lineno">  612</span>        )</div>
<div class="line"><span class="lineno">  613</span> </div>
<div class="line"><span class="lineno">  614</span>    <span class="keywordflow">if</span> check_input:</div>
<div class="line"><span class="lineno">  615</span>        _dtype = [np.float64, np.float32]</div>
<div class="line"><span class="lineno">  616</span>        _accept_sparse = _get_valid_accept_sparse(sparse.issparse(X), solver)</div>
<div class="line"><span class="lineno">  617</span>        X = check_array(X, accept_sparse=_accept_sparse, dtype=_dtype, order=<span class="stringliteral">&quot;C&quot;</span>)</div>
<div class="line"><span class="lineno">  618</span>        y = check_array(y, dtype=X.dtype, ensure_2d=<span class="keyword">False</span>, order=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  619</span>    check_consistent_length(X, y)</div>
<div class="line"><span class="lineno">  620</span> </div>
<div class="line"><span class="lineno">  621</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  622</span> </div>
<div class="line"><span class="lineno">  623</span>    <span class="keywordflow">if</span> y.ndim &gt; 2:</div>
<div class="line"><span class="lineno">  624</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Target y has the wrong shape %s&quot;</span> % str(y.shape))</div>
<div class="line"><span class="lineno">  625</span> </div>
<div class="line"><span class="lineno">  626</span>    ravel = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  627</span>    <span class="keywordflow">if</span> y.ndim == 1:</div>
<div class="line"><span class="lineno">  628</span>        y = y.reshape(-1, 1)</div>
<div class="line"><span class="lineno">  629</span>        ravel = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  630</span> </div>
<div class="line"><span class="lineno">  631</span>    n_samples_, n_targets = y.shape</div>
<div class="line"><span class="lineno">  632</span> </div>
<div class="line"><span class="lineno">  633</span>    <span class="keywordflow">if</span> n_samples != n_samples_:</div>
<div class="line"><span class="lineno">  634</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  635</span>            <span class="stringliteral">&quot;Number of samples in X and y does not correspond: %d != %d&quot;</span></div>
<div class="line"><span class="lineno">  636</span>            % (n_samples, n_samples_)</div>
<div class="line"><span class="lineno">  637</span>        )</div>
<div class="line"><span class="lineno">  638</span> </div>
<div class="line"><span class="lineno">  639</span>    <span class="keywordflow">if</span> has_sw:</div>
<div class="line"><span class="lineno">  640</span>        sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)</div>
<div class="line"><span class="lineno">  641</span> </div>
<div class="line"><span class="lineno">  642</span>        <span class="keywordflow">if</span> solver <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]:</div>
<div class="line"><span class="lineno">  643</span>            <span class="comment"># SAG supports sample_weight directly. For other solvers,</span></div>
<div class="line"><span class="lineno">  644</span>            <span class="comment"># we implement sample_weight via a simple rescaling.</span></div>
<div class="line"><span class="lineno">  645</span>            X, y, sample_weight_sqrt = _rescale_data(X, y, sample_weight)</div>
<div class="line"><span class="lineno">  646</span> </div>
<div class="line"><span class="lineno">  647</span>    <span class="comment"># Some callers of this method might pass alpha as single</span></div>
<div class="line"><span class="lineno">  648</span>    <span class="comment"># element array which already has been validated.</span></div>
<div class="line"><span class="lineno">  649</span>    <span class="keywordflow">if</span> alpha <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> <span class="keywordflow">not</span> isinstance(alpha, np.ndarray):</div>
<div class="line"><span class="lineno">  650</span>        alpha = check_scalar(</div>
<div class="line"><span class="lineno">  651</span>            alpha,</div>
<div class="line"><span class="lineno">  652</span>            <span class="stringliteral">&quot;alpha&quot;</span>,</div>
<div class="line"><span class="lineno">  653</span>            target_type=numbers.Real,</div>
<div class="line"><span class="lineno">  654</span>            min_val=0.0,</div>
<div class="line"><span class="lineno">  655</span>            include_boundaries=<span class="stringliteral">&quot;left&quot;</span>,</div>
<div class="line"><span class="lineno">  656</span>        )</div>
<div class="line"><span class="lineno">  657</span> </div>
<div class="line"><span class="lineno">  658</span>    <span class="comment"># There should be either 1 or n_targets penalties</span></div>
<div class="line"><span class="lineno">  659</span>    alpha = np.asarray(alpha, dtype=X.dtype).ravel()</div>
<div class="line"><span class="lineno">  660</span>    <span class="keywordflow">if</span> alpha.size <span class="keywordflow">not</span> <span class="keywordflow">in</span> [1, n_targets]:</div>
<div class="line"><span class="lineno">  661</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  662</span>            <span class="stringliteral">&quot;Number of targets and number of penalties do not correspond: %d != %d&quot;</span></div>
<div class="line"><span class="lineno">  663</span>            % (alpha.size, n_targets)</div>
<div class="line"><span class="lineno">  664</span>        )</div>
<div class="line"><span class="lineno">  665</span> </div>
<div class="line"><span class="lineno">  666</span>    <span class="keywordflow">if</span> alpha.size == 1 <span class="keywordflow">and</span> n_targets &gt; 1:</div>
<div class="line"><span class="lineno">  667</span>        alpha = np.repeat(alpha, n_targets)</div>
<div class="line"><span class="lineno">  668</span> </div>
<div class="line"><span class="lineno">  669</span>    n_iter = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  670</span>    <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;sparse_cg&quot;</span>:</div>
<div class="line"><span class="lineno">  671</span>        coef = _solve_sparse_cg(</div>
<div class="line"><span class="lineno">  672</span>            X,</div>
<div class="line"><span class="lineno">  673</span>            y,</div>
<div class="line"><span class="lineno">  674</span>            alpha,</div>
<div class="line"><span class="lineno">  675</span>            max_iter=max_iter,</div>
<div class="line"><span class="lineno">  676</span>            tol=tol,</div>
<div class="line"><span class="lineno">  677</span>            verbose=verbose,</div>
<div class="line"><span class="lineno">  678</span>            X_offset=X_offset,</div>
<div class="line"><span class="lineno">  679</span>            X_scale=X_scale,</div>
<div class="line"><span class="lineno">  680</span>            sample_weight_sqrt=sample_weight_sqrt <span class="keywordflow">if</span> has_sw <span class="keywordflow">else</span> <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  681</span>        )</div>
<div class="line"><span class="lineno">  682</span> </div>
<div class="line"><span class="lineno">  683</span>    <span class="keywordflow">elif</span> solver == <span class="stringliteral">&quot;lsqr&quot;</span>:</div>
<div class="line"><span class="lineno">  684</span>        coef, n_iter = _solve_lsqr(</div>
<div class="line"><span class="lineno">  685</span>            X,</div>
<div class="line"><span class="lineno">  686</span>            y,</div>
<div class="line"><span class="lineno">  687</span>            alpha=alpha,</div>
<div class="line"><span class="lineno">  688</span>            fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  689</span>            max_iter=max_iter,</div>
<div class="line"><span class="lineno">  690</span>            tol=tol,</div>
<div class="line"><span class="lineno">  691</span>            X_offset=X_offset,</div>
<div class="line"><span class="lineno">  692</span>            X_scale=X_scale,</div>
<div class="line"><span class="lineno">  693</span>            sample_weight_sqrt=sample_weight_sqrt <span class="keywordflow">if</span> has_sw <span class="keywordflow">else</span> <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  694</span>        )</div>
<div class="line"><span class="lineno">  695</span> </div>
<div class="line"><span class="lineno">  696</span>    <span class="keywordflow">elif</span> solver == <span class="stringliteral">&quot;cholesky&quot;</span>:</div>
<div class="line"><span class="lineno">  697</span>        <span class="keywordflow">if</span> n_features &gt; n_samples:</div>
<div class="line"><span class="lineno">  698</span>            K = safe_sparse_dot(X, X.T, dense_output=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  699</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  700</span>                dual_coef = _solve_cholesky_kernel(K, y, alpha)</div>
<div class="line"><span class="lineno">  701</span> </div>
<div class="line"><span class="lineno">  702</span>                coef = safe_sparse_dot(X.T, dual_coef, dense_output=<span class="keyword">True</span>).T</div>
<div class="line"><span class="lineno">  703</span>            <span class="keywordflow">except</span> linalg.LinAlgError:</div>
<div class="line"><span class="lineno">  704</span>                <span class="comment"># use SVD solver if matrix is singular</span></div>
<div class="line"><span class="lineno">  705</span>                solver = <span class="stringliteral">&quot;svd&quot;</span></div>
<div class="line"><span class="lineno">  706</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  707</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  708</span>                coef = _solve_cholesky(X, y, alpha)</div>
<div class="line"><span class="lineno">  709</span>            <span class="keywordflow">except</span> linalg.LinAlgError:</div>
<div class="line"><span class="lineno">  710</span>                <span class="comment"># use SVD solver if matrix is singular</span></div>
<div class="line"><span class="lineno">  711</span>                solver = <span class="stringliteral">&quot;svd&quot;</span></div>
<div class="line"><span class="lineno">  712</span> </div>
<div class="line"><span class="lineno">  713</span>    <span class="keywordflow">elif</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]:</div>
<div class="line"><span class="lineno">  714</span>        <span class="comment"># precompute max_squared_sum for all targets</span></div>
<div class="line"><span class="lineno">  715</span>        max_squared_sum = row_norms(X, squared=<span class="keyword">True</span>).max()</div>
<div class="line"><span class="lineno">  716</span> </div>
<div class="line"><span class="lineno">  717</span>        coef = np.empty((y.shape[1], n_features), dtype=X.dtype)</div>
<div class="line"><span class="lineno">  718</span>        n_iter = np.empty(y.shape[1], dtype=np.int32)</div>
<div class="line"><span class="lineno">  719</span>        intercept = np.zeros((y.shape[1],), dtype=X.dtype)</div>
<div class="line"><span class="lineno">  720</span>        <span class="keywordflow">for</span> i, (alpha_i, target) <span class="keywordflow">in</span> enumerate(zip(alpha, y.T)):</div>
<div class="line"><span class="lineno">  721</span>            init = {</div>
<div class="line"><span class="lineno">  722</span>                <span class="stringliteral">&quot;coef&quot;</span>: np.zeros((n_features + int(return_intercept), 1), dtype=X.dtype)</div>
<div class="line"><span class="lineno">  723</span>            }</div>
<div class="line"><span class="lineno">  724</span>            coef_, n_iter_, _ = sag_solver(</div>
<div class="line"><span class="lineno">  725</span>                X,</div>
<div class="line"><span class="lineno">  726</span>                target.ravel(),</div>
<div class="line"><span class="lineno">  727</span>                sample_weight,</div>
<div class="line"><span class="lineno">  728</span>                <span class="stringliteral">&quot;squared&quot;</span>,</div>
<div class="line"><span class="lineno">  729</span>                alpha_i,</div>
<div class="line"><span class="lineno">  730</span>                0,</div>
<div class="line"><span class="lineno">  731</span>                max_iter,</div>
<div class="line"><span class="lineno">  732</span>                tol,</div>
<div class="line"><span class="lineno">  733</span>                verbose,</div>
<div class="line"><span class="lineno">  734</span>                random_state,</div>
<div class="line"><span class="lineno">  735</span>                <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  736</span>                max_squared_sum,</div>
<div class="line"><span class="lineno">  737</span>                init,</div>
<div class="line"><span class="lineno">  738</span>                is_saga=solver == <span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno">  739</span>            )</div>
<div class="line"><span class="lineno">  740</span>            <span class="keywordflow">if</span> return_intercept:</div>
<div class="line"><span class="lineno">  741</span>                coef[i] = coef_[:-1]</div>
<div class="line"><span class="lineno">  742</span>                intercept[i] = coef_[-1]</div>
<div class="line"><span class="lineno">  743</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  744</span>                coef[i] = coef_</div>
<div class="line"><span class="lineno">  745</span>            n_iter[i] = n_iter_</div>
<div class="line"><span class="lineno">  746</span> </div>
<div class="line"><span class="lineno">  747</span>        <span class="keywordflow">if</span> intercept.shape[0] == 1:</div>
<div class="line"><span class="lineno">  748</span>            intercept = intercept[0]</div>
<div class="line"><span class="lineno">  749</span>        coef = np.asarray(coef)</div>
<div class="line"><span class="lineno">  750</span> </div>
<div class="line"><span class="lineno">  751</span>    <span class="keywordflow">elif</span> solver == <span class="stringliteral">&quot;lbfgs&quot;</span>:</div>
<div class="line"><span class="lineno">  752</span>        coef = _solve_lbfgs(</div>
<div class="line"><span class="lineno">  753</span>            X,</div>
<div class="line"><span class="lineno">  754</span>            y,</div>
<div class="line"><span class="lineno">  755</span>            alpha,</div>
<div class="line"><span class="lineno">  756</span>            positive=positive,</div>
<div class="line"><span class="lineno">  757</span>            tol=tol,</div>
<div class="line"><span class="lineno">  758</span>            max_iter=max_iter,</div>
<div class="line"><span class="lineno">  759</span>            X_offset=X_offset,</div>
<div class="line"><span class="lineno">  760</span>            X_scale=X_scale,</div>
<div class="line"><span class="lineno">  761</span>            sample_weight_sqrt=sample_weight_sqrt <span class="keywordflow">if</span> has_sw <span class="keywordflow">else</span> <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  762</span>        )</div>
<div class="line"><span class="lineno">  763</span> </div>
<div class="line"><span class="lineno">  764</span>    <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;svd&quot;</span>:</div>
<div class="line"><span class="lineno">  765</span>        <span class="keywordflow">if</span> sparse.issparse(X):</div>
<div class="line"><span class="lineno">  766</span>            <span class="keywordflow">raise</span> TypeError(<span class="stringliteral">&quot;SVD solver does not support sparse inputs currently&quot;</span>)</div>
<div class="line"><span class="lineno">  767</span>        coef = _solve_svd(X, y, alpha)</div>
<div class="line"><span class="lineno">  768</span> </div>
<div class="line"><span class="lineno">  769</span>    <span class="keywordflow">if</span> ravel:</div>
<div class="line"><span class="lineno">  770</span>        <span class="comment"># When y was passed as a 1d-array, we flatten the coefficients.</span></div>
<div class="line"><span class="lineno">  771</span>        coef = coef.ravel()</div>
<div class="line"><span class="lineno">  772</span> </div>
<div class="line"><span class="lineno">  773</span>    <span class="keywordflow">if</span> return_n_iter <span class="keywordflow">and</span> return_intercept:</div>
<div class="line"><span class="lineno">  774</span>        <span class="keywordflow">return</span> coef, n_iter, intercept</div>
<div class="line"><span class="lineno">  775</span>    <span class="keywordflow">elif</span> return_intercept:</div>
<div class="line"><span class="lineno">  776</span>        <span class="keywordflow">return</span> coef, intercept</div>
<div class="line"><span class="lineno">  777</span>    <span class="keywordflow">elif</span> return_n_iter:</div>
<div class="line"><span class="lineno">  778</span>        <span class="keywordflow">return</span> coef, n_iter</div>
<div class="line"><span class="lineno">  779</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  780</span>        <span class="keywordflow">return</span> coef</div>
<div class="line"><span class="lineno">  781</span> </div>
<div class="line"><span class="lineno">  782</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa184b154e12613beead709efe18e1473" name="aa184b154e12613beead709efe18e1473"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa184b154e12613beead709efe18e1473">&#9670;&#160;</a></span>_solve_cholesky()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._solve_cholesky </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  204</span><span class="keyword">def </span>_solve_cholesky(X, y, alpha):</div>
<div class="line"><span class="lineno">  205</span>    <span class="comment"># w = inv(X^t X + alpha*Id) * X.T y</span></div>
<div class="line"><span class="lineno">  206</span>    n_features = X.shape[1]</div>
<div class="line"><span class="lineno">  207</span>    n_targets = y.shape[1]</div>
<div class="line"><span class="lineno">  208</span> </div>
<div class="line"><span class="lineno">  209</span>    A = safe_sparse_dot(X.T, X, dense_output=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  210</span>    Xy = safe_sparse_dot(X.T, y, dense_output=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  211</span> </div>
<div class="line"><span class="lineno">  212</span>    one_alpha = np.array_equal(alpha, len(alpha) * [alpha[0]])</div>
<div class="line"><span class="lineno">  213</span> </div>
<div class="line"><span class="lineno">  214</span>    <span class="keywordflow">if</span> one_alpha:</div>
<div class="line"><span class="lineno">  215</span>        A.flat[:: n_features + 1] += alpha[0]</div>
<div class="line"><span class="lineno">  216</span>        <span class="keywordflow">return</span> linalg.solve(A, Xy, assume_a=<span class="stringliteral">&quot;pos&quot;</span>, overwrite_a=<span class="keyword">True</span>).T</div>
<div class="line"><span class="lineno">  217</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  218</span>        coefs = np.empty([n_targets, n_features], dtype=X.dtype)</div>
<div class="line"><span class="lineno">  219</span>        <span class="keywordflow">for</span> coef, target, current_alpha <span class="keywordflow">in</span> zip(coefs, Xy.T, alpha):</div>
<div class="line"><span class="lineno">  220</span>            A.flat[:: n_features + 1] += current_alpha</div>
<div class="line"><span class="lineno">  221</span>            coef[:] = linalg.solve(A, target, assume_a=<span class="stringliteral">&quot;pos&quot;</span>, overwrite_a=<span class="keyword">False</span>).ravel()</div>
<div class="line"><span class="lineno">  222</span>            A.flat[:: n_features + 1] -= current_alpha</div>
<div class="line"><span class="lineno">  223</span>        <span class="keywordflow">return</span> coefs</div>
<div class="line"><span class="lineno">  224</span> </div>
<div class="line"><span class="lineno">  225</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a91b5180ca5403e673bb49a1cc983c7fb" name="a91b5180ca5403e673bb49a1cc983c7fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a91b5180ca5403e673bb49a1cc983c7fb">&#9670;&#160;</a></span>_solve_cholesky_kernel()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._solve_cholesky_kernel </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>K</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>copy</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  226</span><span class="keyword">def </span>_solve_cholesky_kernel(K, y, alpha, sample_weight=None, copy=False):</div>
<div class="line"><span class="lineno">  227</span>    <span class="comment"># dual_coef = inv(X X^t + alpha*Id) y</span></div>
<div class="line"><span class="lineno">  228</span>    n_samples = K.shape[0]</div>
<div class="line"><span class="lineno">  229</span>    n_targets = y.shape[1]</div>
<div class="line"><span class="lineno">  230</span> </div>
<div class="line"><span class="lineno">  231</span>    <span class="keywordflow">if</span> copy:</div>
<div class="line"><span class="lineno">  232</span>        K = K.copy()</div>
<div class="line"><span class="lineno">  233</span> </div>
<div class="line"><span class="lineno">  234</span>    alpha = np.atleast_1d(alpha)</div>
<div class="line"><span class="lineno">  235</span>    one_alpha = (alpha == alpha[0]).all()</div>
<div class="line"><span class="lineno">  236</span>    has_sw = isinstance(sample_weight, np.ndarray) <span class="keywordflow">or</span> sample_weight <span class="keywordflow">not</span> <span class="keywordflow">in</span> [1.0, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  237</span> </div>
<div class="line"><span class="lineno">  238</span>    <span class="keywordflow">if</span> has_sw:</div>
<div class="line"><span class="lineno">  239</span>        <span class="comment"># Unlike other solvers, we need to support sample_weight directly</span></div>
<div class="line"><span class="lineno">  240</span>        <span class="comment"># because K might be a pre-computed kernel.</span></div>
<div class="line"><span class="lineno">  241</span>        sw = np.sqrt(np.atleast_1d(sample_weight))</div>
<div class="line"><span class="lineno">  242</span>        y = y * sw[:, np.newaxis]</div>
<div class="line"><span class="lineno">  243</span>        K *= np.outer(sw, sw)</div>
<div class="line"><span class="lineno">  244</span> </div>
<div class="line"><span class="lineno">  245</span>    <span class="keywordflow">if</span> one_alpha:</div>
<div class="line"><span class="lineno">  246</span>        <span class="comment"># Only one penalty, we can solve multi-target problems in one time.</span></div>
<div class="line"><span class="lineno">  247</span>        K.flat[:: n_samples + 1] += alpha[0]</div>
<div class="line"><span class="lineno">  248</span> </div>
<div class="line"><span class="lineno">  249</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  250</span>            <span class="comment"># Note: we must use overwrite_a=False in order to be able to</span></div>
<div class="line"><span class="lineno">  251</span>            <span class="comment">#       use the fall-back solution below in case a LinAlgError</span></div>
<div class="line"><span class="lineno">  252</span>            <span class="comment">#       is raised</span></div>
<div class="line"><span class="lineno">  253</span>            dual_coef = linalg.solve(K, y, assume_a=<span class="stringliteral">&quot;pos&quot;</span>, overwrite_a=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  254</span>        <span class="keywordflow">except</span> np.linalg.LinAlgError:</div>
<div class="line"><span class="lineno">  255</span>            warnings.warn(</div>
<div class="line"><span class="lineno">  256</span>                <span class="stringliteral">&quot;Singular matrix in solving dual problem. Using &quot;</span></div>
<div class="line"><span class="lineno">  257</span>                <span class="stringliteral">&quot;least-squares solution instead.&quot;</span></div>
<div class="line"><span class="lineno">  258</span>            )</div>
<div class="line"><span class="lineno">  259</span>            dual_coef = linalg.lstsq(K, y)[0]</div>
<div class="line"><span class="lineno">  260</span> </div>
<div class="line"><span class="lineno">  261</span>        <span class="comment"># K is expensive to compute and store in memory so change it back in</span></div>
<div class="line"><span class="lineno">  262</span>        <span class="comment"># case it was user-given.</span></div>
<div class="line"><span class="lineno">  263</span>        K.flat[:: n_samples + 1] -= alpha[0]</div>
<div class="line"><span class="lineno">  264</span> </div>
<div class="line"><span class="lineno">  265</span>        <span class="keywordflow">if</span> has_sw:</div>
<div class="line"><span class="lineno">  266</span>            dual_coef *= sw[:, np.newaxis]</div>
<div class="line"><span class="lineno">  267</span> </div>
<div class="line"><span class="lineno">  268</span>        <span class="keywordflow">return</span> dual_coef</div>
<div class="line"><span class="lineno">  269</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  270</span>        <span class="comment"># One penalty per target. We need to solve each target separately.</span></div>
<div class="line"><span class="lineno">  271</span>        dual_coefs = np.empty([n_targets, n_samples], K.dtype)</div>
<div class="line"><span class="lineno">  272</span> </div>
<div class="line"><span class="lineno">  273</span>        <span class="keywordflow">for</span> dual_coef, target, current_alpha <span class="keywordflow">in</span> zip(dual_coefs, y.T, alpha):</div>
<div class="line"><span class="lineno">  274</span>            K.flat[:: n_samples + 1] += current_alpha</div>
<div class="line"><span class="lineno">  275</span> </div>
<div class="line"><span class="lineno">  276</span>            dual_coef[:] = linalg.solve(</div>
<div class="line"><span class="lineno">  277</span>                K, target, assume_a=<span class="stringliteral">&quot;pos&quot;</span>, overwrite_a=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  278</span>            ).ravel()</div>
<div class="line"><span class="lineno">  279</span> </div>
<div class="line"><span class="lineno">  280</span>            K.flat[:: n_samples + 1] -= current_alpha</div>
<div class="line"><span class="lineno">  281</span> </div>
<div class="line"><span class="lineno">  282</span>        <span class="keywordflow">if</span> has_sw:</div>
<div class="line"><span class="lineno">  283</span>            dual_coefs *= sw[np.newaxis, :]</div>
<div class="line"><span class="lineno">  284</span> </div>
<div class="line"><span class="lineno">  285</span>        <span class="keywordflow">return</span> dual_coefs.T</div>
<div class="line"><span class="lineno">  286</span> </div>
<div class="line"><span class="lineno">  287</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a91df6db9c40254448075d9b8920e0111" name="a91df6db9c40254448075d9b8920e0111"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a91df6db9c40254448075d9b8920e0111">&#9670;&#160;</a></span>_solve_lbfgs()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._solve_lbfgs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>positive</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_offset</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_scale</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight_sqrt</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Solve ridge regression with LBFGS.

The main purpose is fitting with forcing coefficients to be positive.
For unconstrained ridge regression, there are faster dedicated solver methods.
Note that with positive bounds on the coefficients, LBFGS seems faster
than scipy.optimize.lsq_linear.
</pre> <div class="fragment"><div class="line"><span class="lineno">  309</span>):</div>
<div class="line"><span class="lineno">  310</span>    <span class="stringliteral">&quot;&quot;&quot;Solve ridge regression with LBFGS.</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">    The main purpose is fitting with forcing coefficients to be positive.</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">    For unconstrained ridge regression, there are faster dedicated solver methods.</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral">    Note that with positive bounds on the coefficients, LBFGS seems faster</span></div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">    than scipy.optimize.lsq_linear.</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  317</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  318</span> </div>
<div class="line"><span class="lineno">  319</span>    options = {}</div>
<div class="line"><span class="lineno">  320</span>    <span class="keywordflow">if</span> max_iter <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  321</span>        options[<span class="stringliteral">&quot;maxiter&quot;</span>] = max_iter</div>
<div class="line"><span class="lineno">  322</span>    config = {</div>
<div class="line"><span class="lineno">  323</span>        <span class="stringliteral">&quot;method&quot;</span>: <span class="stringliteral">&quot;L-BFGS-B&quot;</span>,</div>
<div class="line"><span class="lineno">  324</span>        <span class="stringliteral">&quot;tol&quot;</span>: tol,</div>
<div class="line"><span class="lineno">  325</span>        <span class="stringliteral">&quot;jac&quot;</span>: <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  326</span>        <span class="stringliteral">&quot;options&quot;</span>: options,</div>
<div class="line"><span class="lineno">  327</span>    }</div>
<div class="line"><span class="lineno">  328</span>    <span class="keywordflow">if</span> positive:</div>
<div class="line"><span class="lineno">  329</span>        config[<span class="stringliteral">&quot;bounds&quot;</span>] = [(0, np.inf)] * n_features</div>
<div class="line"><span class="lineno">  330</span> </div>
<div class="line"><span class="lineno">  331</span>    <span class="keywordflow">if</span> X_offset <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> X_scale <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  332</span>        X_offset_scale = X_offset / X_scale</div>
<div class="line"><span class="lineno">  333</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  334</span>        X_offset_scale = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  335</span> </div>
<div class="line"><span class="lineno">  336</span>    <span class="keywordflow">if</span> sample_weight_sqrt <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  337</span>        sample_weight_sqrt = np.ones(X.shape[0], dtype=X.dtype)</div>
<div class="line"><span class="lineno">  338</span> </div>
<div class="line"><span class="lineno">  339</span>    coefs = np.empty((y.shape[1], n_features), dtype=X.dtype)</div>
<div class="line"><span class="lineno">  340</span> </div>
<div class="line"><span class="lineno">  341</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(y.shape[1]):</div>
<div class="line"><span class="lineno">  342</span>        x0 = np.zeros((n_features,))</div>
<div class="line"><span class="lineno">  343</span>        y_column = y[:, i]</div>
<div class="line"><span class="lineno">  344</span> </div>
<div class="line"><span class="lineno">  345</span>        <span class="keyword">def </span><a class="code hl_function" href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a>(w):</div>
<div class="line"><span class="lineno">  346</span>            residual = X.dot(w) - y_column</div>
<div class="line"><span class="lineno">  347</span>            <span class="keywordflow">if</span> X_offset_scale <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  348</span>                residual -= sample_weight_sqrt * w.dot(X_offset_scale)</div>
<div class="line"><span class="lineno">  349</span>            f = 0.5 * residual.dot(residual) + 0.5 * alpha[i] * w.dot(w)</div>
<div class="line"><span class="lineno">  350</span>            grad = X.T @ residual + alpha[i] * w</div>
<div class="line"><span class="lineno">  351</span>            <span class="keywordflow">if</span> X_offset_scale <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  352</span>                grad -= X_offset_scale * residual.dot(sample_weight_sqrt)</div>
<div class="line"><span class="lineno">  353</span> </div>
<div class="line"><span class="lineno">  354</span>            <span class="keywordflow">return</span> f, grad</div>
<div class="line"><span class="lineno">  355</span> </div>
<div class="line"><span class="lineno">  356</span>        result = optimize.minimize(func, x0, **config)</div>
<div class="line"><span class="lineno">  357</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> result[<span class="stringliteral">&quot;success&quot;</span>]:</div>
<div class="line"><span class="lineno">  358</span>            warnings.warn(</div>
<div class="line"><span class="lineno">  359</span>                <span class="stringliteral">&quot;The lbfgs solver did not converge. Try increasing max_iter &quot;</span></div>
<div class="line"><span class="lineno">  360</span>                f<span class="stringliteral">&quot;or tol. Currently: max_iter={max_iter} and tol={tol}&quot;</span>,</div>
<div class="line"><span class="lineno">  361</span>                ConvergenceWarning,</div>
<div class="line"><span class="lineno">  362</span>            )</div>
<div class="line"><span class="lineno">  363</span>        coefs[i] = result[<span class="stringliteral">&quot;x&quot;</span>]</div>
<div class="line"><span class="lineno">  364</span> </div>
<div class="line"><span class="lineno">  365</span>    <span class="keywordflow">return</span> coefs</div>
<div class="line"><span class="lineno">  366</span> </div>
<div class="line"><span class="lineno">  367</span> </div>
<div class="ttc" id="acallback_2foo_8f_html_a565fe2cc583df102f120752b0011c330"><div class="ttname"><a href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a></div><div class="ttdeci">subroutine func(a)</div><div class="ttdef"><b>Definition</b> foo.f:9</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a55c3fa41a319fbd6bfb8a718f1eeff57" name="a55c3fa41a319fbd6bfb8a718f1eeff57"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a55c3fa41a319fbd6bfb8a718f1eeff57">&#9670;&#160;</a></span>_solve_lsqr()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._solve_lsqr </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_offset</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_scale</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight_sqrt</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Solve Ridge regression via LSQR.

We expect that y is always mean centered.
If X is dense, we expect it to be mean centered such that we can solve
    ||y - Xw||_2^2 + alpha * ||w||_2^2

If X is sparse, we expect X_offset to be given such that we can solve
    ||y - (X - X_offset)w||_2^2 + alpha * ||w||_2^2

With sample weights S=diag(sample_weight), this becomes
    ||sqrt(S) (y - (X - X_offset) w)||_2^2 + alpha * ||w||_2^2
and we expect y and X to already be rescaled, i.e. sqrt(S) @ y, sqrt(S) @ X. In
this case, X_offset is the sample_weight weighted mean of X before scaling by
sqrt(S). The objective then reads
   ||y - (X - sqrt(S) X_offset) w)||_2^2 + alpha * ||w||_2^2
</pre> <div class="fragment"><div class="line"><span class="lineno">  159</span>):</div>
<div class="line"><span class="lineno">  160</span>    <span class="stringliteral">&quot;&quot;&quot;Solve Ridge regression via LSQR.</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">    We expect that y is always mean centered.</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">    If X is dense, we expect it to be mean centered such that we can solve</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        ||y - Xw||_2^2 + alpha * ||w||_2^2</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">    If X is sparse, we expect X_offset to be given such that we can solve</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">        ||y - (X - X_offset)w||_2^2 + alpha * ||w||_2^2</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral">    With sample weights S=diag(sample_weight), this becomes</span></div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">        ||sqrt(S) (y - (X - X_offset) w)||_2^2 + alpha * ||w||_2^2</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">    and we expect y and X to already be rescaled, i.e. sqrt(S) @ y, sqrt(S) @ X. In</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral">    this case, X_offset is the sample_weight weighted mean of X before scaling by</span></div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">    sqrt(S). The objective then reads</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">       ||y - (X - sqrt(S) X_offset) w)||_2^2 + alpha * ||w||_2^2</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  176</span>    <span class="keywordflow">if</span> sample_weight_sqrt <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  177</span>        sample_weight_sqrt = np.ones(X.shape[0], dtype=X.dtype)</div>
<div class="line"><span class="lineno">  178</span> </div>
<div class="line"><span class="lineno">  179</span>    <span class="keywordflow">if</span> sparse.issparse(X) <span class="keywordflow">and</span> fit_intercept:</div>
<div class="line"><span class="lineno">  180</span>        X_offset_scale = X_offset / X_scale</div>
<div class="line"><span class="lineno">  181</span>        X1 = _get_rescaled_operator(X, X_offset_scale, sample_weight_sqrt)</div>
<div class="line"><span class="lineno">  182</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  183</span>        <span class="comment"># No need to touch anything</span></div>
<div class="line"><span class="lineno">  184</span>        X1 = X</div>
<div class="line"><span class="lineno">  185</span> </div>
<div class="line"><span class="lineno">  186</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  187</span>    coefs = np.empty((y.shape[1], n_features), dtype=X.dtype)</div>
<div class="line"><span class="lineno">  188</span>    n_iter = np.empty(y.shape[1], dtype=np.int32)</div>
<div class="line"><span class="lineno">  189</span> </div>
<div class="line"><span class="lineno">  190</span>    <span class="comment"># According to the lsqr documentation, alpha = damp^2.</span></div>
<div class="line"><span class="lineno">  191</span>    sqrt_alpha = np.sqrt(alpha)</div>
<div class="line"><span class="lineno">  192</span> </div>
<div class="line"><span class="lineno">  193</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(y.shape[1]):</div>
<div class="line"><span class="lineno">  194</span>        y_column = y[:, i]</div>
<div class="line"><span class="lineno">  195</span>        info = sp_linalg.lsqr(</div>
<div class="line"><span class="lineno">  196</span>            X1, y_column, damp=sqrt_alpha[i], atol=tol, btol=tol, iter_lim=max_iter</div>
<div class="line"><span class="lineno">  197</span>        )</div>
<div class="line"><span class="lineno">  198</span>        coefs[i] = info[0]</div>
<div class="line"><span class="lineno">  199</span>        n_iter[i] = info[2]</div>
<div class="line"><span class="lineno">  200</span> </div>
<div class="line"><span class="lineno">  201</span>    <span class="keywordflow">return</span> coefs, n_iter</div>
<div class="line"><span class="lineno">  202</span> </div>
<div class="line"><span class="lineno">  203</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a56d787b3475471d14facd04607a0e15a" name="a56d787b3475471d14facd04607a0e15a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56d787b3475471d14facd04607a0e15a">&#9670;&#160;</a></span>_solve_sparse_cg()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._solve_sparse_cg </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_offset</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_scale</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight_sqrt</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   73</span>):</div>
<div class="line"><span class="lineno">   74</span>    <span class="keywordflow">if</span> sample_weight_sqrt <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">   75</span>        sample_weight_sqrt = np.ones(X.shape[0], dtype=X.dtype)</div>
<div class="line"><span class="lineno">   76</span> </div>
<div class="line"><span class="lineno">   77</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">   78</span> </div>
<div class="line"><span class="lineno">   79</span>    <span class="keywordflow">if</span> X_offset <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">or</span> X_scale <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">   80</span>        X1 = sp_linalg.aslinearoperator(X)</div>
<div class="line"><span class="lineno">   81</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   82</span>        X_offset_scale = X_offset / X_scale</div>
<div class="line"><span class="lineno">   83</span>        X1 = _get_rescaled_operator(X, X_offset_scale, sample_weight_sqrt)</div>
<div class="line"><span class="lineno">   84</span> </div>
<div class="line"><span class="lineno">   85</span>    coefs = np.empty((y.shape[1], n_features), dtype=X.dtype)</div>
<div class="line"><span class="lineno">   86</span> </div>
<div class="line"><span class="lineno">   87</span>    <span class="keywordflow">if</span> n_features &gt; n_samples:</div>
<div class="line"><span class="lineno">   88</span> </div>
<div class="line"><span class="lineno">   89</span>        <span class="keyword">def </span>create_mv(curr_alpha):</div>
<div class="line"><span class="lineno">   90</span>            <span class="keyword">def </span>_mv(x):</div>
<div class="line"><span class="lineno">   91</span>                <span class="keywordflow">return</span> X1.matvec(X1.rmatvec(x)) + curr_alpha * x</div>
<div class="line"><span class="lineno">   92</span> </div>
<div class="line"><span class="lineno">   93</span>            <span class="keywordflow">return</span> _mv</div>
<div class="line"><span class="lineno">   94</span> </div>
<div class="line"><span class="lineno">   95</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   96</span> </div>
<div class="line"><span class="lineno">   97</span>        <span class="keyword">def </span>create_mv(curr_alpha):</div>
<div class="line"><span class="lineno">   98</span>            <span class="keyword">def </span>_mv(x):</div>
<div class="line"><span class="lineno">   99</span>                <span class="keywordflow">return</span> X1.rmatvec(X1.matvec(x)) + curr_alpha * x</div>
<div class="line"><span class="lineno">  100</span> </div>
<div class="line"><span class="lineno">  101</span>            <span class="keywordflow">return</span> _mv</div>
<div class="line"><span class="lineno">  102</span> </div>
<div class="line"><span class="lineno">  103</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(y.shape[1]):</div>
<div class="line"><span class="lineno">  104</span>        y_column = y[:, i]</div>
<div class="line"><span class="lineno">  105</span> </div>
<div class="line"><span class="lineno">  106</span>        mv = create_mv(alpha[i])</div>
<div class="line"><span class="lineno">  107</span>        <span class="keywordflow">if</span> n_features &gt; n_samples:</div>
<div class="line"><span class="lineno">  108</span>            <span class="comment"># kernel ridge</span></div>
<div class="line"><span class="lineno">  109</span>            <span class="comment"># w = X.T * inv(X X^t + alpha*Id) y</span></div>
<div class="line"><span class="lineno">  110</span>            C = sp_linalg.LinearOperator(</div>
<div class="line"><span class="lineno">  111</span>                (n_samples, n_samples), matvec=mv, dtype=X.dtype</div>
<div class="line"><span class="lineno">  112</span>            )</div>
<div class="line"><span class="lineno">  113</span>            <span class="comment"># FIXME atol</span></div>
<div class="line"><span class="lineno">  114</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  115</span>                coef, info = sp_linalg.cg(C, y_column, tol=tol, atol=<span class="stringliteral">&quot;legacy&quot;</span>)</div>
<div class="line"><span class="lineno">  116</span>            <span class="keywordflow">except</span> TypeError:</div>
<div class="line"><span class="lineno">  117</span>                <span class="comment"># old scipy</span></div>
<div class="line"><span class="lineno">  118</span>                coef, info = sp_linalg.cg(C, y_column, tol=tol)</div>
<div class="line"><span class="lineno">  119</span>            coefs[i] = X1.rmatvec(coef)</div>
<div class="line"><span class="lineno">  120</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  121</span>            <span class="comment"># linear ridge</span></div>
<div class="line"><span class="lineno">  122</span>            <span class="comment"># w = inv(X^t X + alpha*Id) * X.T y</span></div>
<div class="line"><span class="lineno">  123</span>            y_column = X1.rmatvec(y_column)</div>
<div class="line"><span class="lineno">  124</span>            C = sp_linalg.LinearOperator(</div>
<div class="line"><span class="lineno">  125</span>                (n_features, n_features), matvec=mv, dtype=X.dtype</div>
<div class="line"><span class="lineno">  126</span>            )</div>
<div class="line"><span class="lineno">  127</span>            <span class="comment"># FIXME atol</span></div>
<div class="line"><span class="lineno">  128</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  129</span>                coefs[i], info = sp_linalg.cg(</div>
<div class="line"><span class="lineno">  130</span>                    C, y_column, maxiter=max_iter, tol=tol, atol=<span class="stringliteral">&quot;legacy&quot;</span></div>
<div class="line"><span class="lineno">  131</span>                )</div>
<div class="line"><span class="lineno">  132</span>            <span class="keywordflow">except</span> TypeError:</div>
<div class="line"><span class="lineno">  133</span>                <span class="comment"># old scipy</span></div>
<div class="line"><span class="lineno">  134</span>                coefs[i], info = sp_linalg.cg(C, y_column, maxiter=max_iter, tol=tol)</div>
<div class="line"><span class="lineno">  135</span> </div>
<div class="line"><span class="lineno">  136</span>        <span class="keywordflow">if</span> info &lt; 0:</div>
<div class="line"><span class="lineno">  137</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Failed with error code %d&quot;</span> % info)</div>
<div class="line"><span class="lineno">  138</span> </div>
<div class="line"><span class="lineno">  139</span>        <span class="keywordflow">if</span> max_iter <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> info &gt; 0 <span class="keywordflow">and</span> verbose:</div>
<div class="line"><span class="lineno">  140</span>            warnings.warn(</div>
<div class="line"><span class="lineno">  141</span>                <span class="stringliteral">&quot;sparse_cg did not converge after %d iterations.&quot;</span> % info,</div>
<div class="line"><span class="lineno">  142</span>                ConvergenceWarning,</div>
<div class="line"><span class="lineno">  143</span>            )</div>
<div class="line"><span class="lineno">  144</span> </div>
<div class="line"><span class="lineno">  145</span>    <span class="keywordflow">return</span> coefs</div>
<div class="line"><span class="lineno">  146</span> </div>
<div class="line"><span class="lineno">  147</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a922be031c6605a90386fc8179521ee44" name="a922be031c6605a90386fc8179521ee44"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a922be031c6605a90386fc8179521ee44">&#9670;&#160;</a></span>_solve_svd()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge._solve_svd </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  288</span><span class="keyword">def </span>_solve_svd(X, y, alpha):</div>
<div class="line"><span class="lineno">  289</span>    U, s, Vt = linalg.svd(X, full_matrices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  290</span>    idx = s &gt; 1e-15  <span class="comment"># same default value as scipy.linalg.pinv</span></div>
<div class="line"><span class="lineno">  291</span>    s_nnz = s[idx][:, np.newaxis]</div>
<div class="line"><span class="lineno">  292</span>    UTy = np.dot(U.T, y)</div>
<div class="line"><span class="lineno">  293</span>    d = np.zeros((s.size, alpha.size), dtype=X.dtype)</div>
<div class="line"><span class="lineno">  294</span>    d[idx] = s_nnz / (s_nnz**2 + alpha)</div>
<div class="line"><span class="lineno">  295</span>    d_UT_y = d * UTy</div>
<div class="line"><span class="lineno">  296</span>    <span class="keywordflow">return</span> np.dot(Vt.T, d_UT_y).T</div>
<div class="line"><span class="lineno">  297</span> </div>
<div class="line"><span class="lineno">  298</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa523d6124f2b23b752603695a2c96674" name="aa523d6124f2b23b752603695a2c96674"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa523d6124f2b23b752603695a2c96674">&#9670;&#160;</a></span>ridge_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._ridge.ridge_regression </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>positive</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_n_iter</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_intercept</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>check_input</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Solve the ridge equation by the method of normal equations.

Read more in the :ref:`User Guide &lt;ridge_regression&gt;`.

Parameters
----------
X : {ndarray, sparse matrix, LinearOperator} of shape \
    (n_samples, n_features)
    Training data.

y : ndarray of shape (n_samples,) or (n_samples, n_targets)
    Target values.

alpha : float or array-like of shape (n_targets,)
    Constant that multiplies the L2 term, controlling regularization
    strength. `alpha` must be a non-negative float i.e. in `[0, inf)`.

    When `alpha = 0`, the objective is equivalent to ordinary least
    squares, solved by the :class:`LinearRegression` object. For numerical
    reasons, using `alpha = 0` with the `Ridge` object is not advised.
    Instead, you should use the :class:`LinearRegression` object.

    If an array is passed, penalties are assumed to be specific to the
    targets. Hence they must correspond in number.

sample_weight : float or array-like of shape (n_samples,), default=None
    Individual weights for each sample. If given a float, every sample
    will have the same weight. If sample_weight is not None and
    solver='auto', the solver will be set to 'cholesky'.

    .. versionadded:: 0.17

solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', \
        'sag', 'saga', 'lbfgs'}, default='auto'
    Solver to use in the computational routines:

    - 'auto' chooses the solver automatically based on the type of data.

    - 'svd' uses a Singular Value Decomposition of X to compute the Ridge
      coefficients. It is the most stable solver, in particular more stable
      for singular matrices than 'cholesky' at the cost of being slower.

    - 'cholesky' uses the standard scipy.linalg.solve function to
      obtain a closed-form solution via a Cholesky decomposition of
      dot(X.T, X)

    - 'sparse_cg' uses the conjugate gradient solver as found in
      scipy.sparse.linalg.cg. As an iterative algorithm, this solver is
      more appropriate than 'cholesky' for large-scale data
      (possibility to set `tol` and `max_iter`).

    - 'lsqr' uses the dedicated regularized least-squares routine
      scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative
      procedure.

    - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses
      its improved, unbiased version named SAGA. Both methods also use an
      iterative procedure, and are often faster than other solvers when
      both n_samples and n_features are large. Note that 'sag' and
      'saga' fast convergence is only guaranteed on features with
      approximately the same scale. You can preprocess the data with a
      scaler from sklearn.preprocessing.

    - 'lbfgs' uses L-BFGS-B algorithm implemented in
      `scipy.optimize.minimize`. It can be used only when `positive`
      is True.

    All solvers except 'svd' support both dense and sparse data. However, only
    'lsqr', 'sag', 'sparse_cg', and 'lbfgs' support sparse input when
    `fit_intercept` is True.

    .. versionadded:: 0.17
       Stochastic Average Gradient descent solver.
    .. versionadded:: 0.19
       SAGA solver.

max_iter : int, default=None
    Maximum number of iterations for conjugate gradient solver.
    For the 'sparse_cg' and 'lsqr' solvers, the default value is determined
    by scipy.sparse.linalg. For 'sag' and saga solver, the default value is
    1000. For 'lbfgs' solver, the default value is 15000.

tol : float, default=1e-4
    Precision of the solution. Note that `tol` has no effect for solvers 'svd' and
    'cholesky'.

    .. versionchanged:: 1.2
       Default value changed from 1e-3 to 1e-4 for consistency with other linear
       models.

verbose : int, default=0
    Verbosity level. Setting verbose &gt; 0 will display additional
    information depending on the solver used.

positive : bool, default=False
    When set to ``True``, forces the coefficients to be positive.
    Only 'lbfgs' solver is supported in this case.

random_state : int, RandomState instance, default=None
    Used when ``solver`` == 'sag' or 'saga' to shuffle the data.
    See :term:`Glossary &lt;random_state&gt;` for details.

return_n_iter : bool, default=False
    If True, the method also returns `n_iter`, the actual number of
    iteration performed by the solver.

    .. versionadded:: 0.17

return_intercept : bool, default=False
    If True and if X is sparse, the method also returns the intercept,
    and the solver is automatically changed to 'sag'. This is only a
    temporary fix for fitting the intercept with sparse data. For dense
    data, use sklearn.linear_model._preprocess_data before your regression.

    .. versionadded:: 0.17

check_input : bool, default=True
    If False, the input arrays X and y will not be checked.

    .. versionadded:: 0.21

Returns
-------
coef : ndarray of shape (n_features,) or (n_targets, n_features)
    Weight vector(s).

n_iter : int, optional
    The actual number of iteration performed by the solver.
    Only returned if `return_n_iter` is True.

intercept : float or ndarray of shape (n_targets,)
    The intercept of the model. Only returned if `return_intercept`
    is True and if X is a scipy sparse array.

Notes
-----
This function won't compute the intercept.

Regularization improves the conditioning of the problem and
reduces the variance of the estimates. Larger values specify stronger
regularization. Alpha corresponds to ``1 / (2C)`` in other linear
models such as :class:`~sklearn.linear_model.LogisticRegression` or
:class:`~sklearn.svm.LinearSVC`. If an array is passed, penalties are
assumed to be specific to the targets. Hence they must correspond in
number.
</pre> <div class="fragment"><div class="line"><span class="lineno">  390</span>):</div>
<div class="line"><span class="lineno">  391</span>    <span class="stringliteral">&quot;&quot;&quot;Solve the ridge equation by the method of normal equations.</span></div>
<div class="line"><span class="lineno">  392</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  393</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;ridge_regression&gt;`.</span></div>
<div class="line"><span class="lineno">  394</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  395</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  396</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  397</span><span class="stringliteral">    X : {ndarray, sparse matrix, LinearOperator} of shape \</span></div>
<div class="line"><span class="lineno">  398</span><span class="stringliteral">        (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  399</span><span class="stringliteral">        Training data.</span></div>
<div class="line"><span class="lineno">  400</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral">    y : ndarray of shape (n_samples,) or (n_samples, n_targets)</span></div>
<div class="line"><span class="lineno">  402</span><span class="stringliteral">        Target values.</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  404</span><span class="stringliteral">    alpha : float or array-like of shape (n_targets,)</span></div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral">        Constant that multiplies the L2 term, controlling regularization</span></div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">        strength. `alpha` must be a non-negative float i.e. in `[0, inf)`.</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral">        When `alpha = 0`, the objective is equivalent to ordinary least</span></div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral">        squares, solved by the :class:`LinearRegression` object. For numerical</span></div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral">        reasons, using `alpha = 0` with the `Ridge` object is not advised.</span></div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral">        Instead, you should use the :class:`LinearRegression` object.</span></div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral">        If an array is passed, penalties are assumed to be specific to the</span></div>
<div class="line"><span class="lineno">  414</span><span class="stringliteral">        targets. Hence they must correspond in number.</span></div>
<div class="line"><span class="lineno">  415</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral">    sample_weight : float or array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral">        Individual weights for each sample. If given a float, every sample</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">        will have the same weight. If sample_weight is not None and</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">        solver=&#39;auto&#39;, the solver will be set to &#39;cholesky&#39;.</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  421</span><span class="stringliteral">        .. versionadded:: 0.17</span></div>
<div class="line"><span class="lineno">  422</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  423</span><span class="stringliteral">    solver : {&#39;auto&#39;, &#39;svd&#39;, &#39;cholesky&#39;, &#39;lsqr&#39;, &#39;sparse_cg&#39;, \</span></div>
<div class="line"><span class="lineno">  424</span><span class="stringliteral">            &#39;sag&#39;, &#39;saga&#39;, &#39;lbfgs&#39;}, default=&#39;auto&#39;</span></div>
<div class="line"><span class="lineno">  425</span><span class="stringliteral">        Solver to use in the computational routines:</span></div>
<div class="line"><span class="lineno">  426</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  427</span><span class="stringliteral">        - &#39;auto&#39; chooses the solver automatically based on the type of data.</span></div>
<div class="line"><span class="lineno">  428</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  429</span><span class="stringliteral">        - &#39;svd&#39; uses a Singular Value Decomposition of X to compute the Ridge</span></div>
<div class="line"><span class="lineno">  430</span><span class="stringliteral">          coefficients. It is the most stable solver, in particular more stable</span></div>
<div class="line"><span class="lineno">  431</span><span class="stringliteral">          for singular matrices than &#39;cholesky&#39; at the cost of being slower.</span></div>
<div class="line"><span class="lineno">  432</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  433</span><span class="stringliteral">        - &#39;cholesky&#39; uses the standard scipy.linalg.solve function to</span></div>
<div class="line"><span class="lineno">  434</span><span class="stringliteral">          obtain a closed-form solution via a Cholesky decomposition of</span></div>
<div class="line"><span class="lineno">  435</span><span class="stringliteral">          dot(X.T, X)</span></div>
<div class="line"><span class="lineno">  436</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  437</span><span class="stringliteral">        - &#39;sparse_cg&#39; uses the conjugate gradient solver as found in</span></div>
<div class="line"><span class="lineno">  438</span><span class="stringliteral">          scipy.sparse.linalg.cg. As an iterative algorithm, this solver is</span></div>
<div class="line"><span class="lineno">  439</span><span class="stringliteral">          more appropriate than &#39;cholesky&#39; for large-scale data</span></div>
<div class="line"><span class="lineno">  440</span><span class="stringliteral">          (possibility to set `tol` and `max_iter`).</span></div>
<div class="line"><span class="lineno">  441</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  442</span><span class="stringliteral">        - &#39;lsqr&#39; uses the dedicated regularized least-squares routine</span></div>
<div class="line"><span class="lineno">  443</span><span class="stringliteral">          scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative</span></div>
<div class="line"><span class="lineno">  444</span><span class="stringliteral">          procedure.</span></div>
<div class="line"><span class="lineno">  445</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  446</span><span class="stringliteral">        - &#39;sag&#39; uses a Stochastic Average Gradient descent, and &#39;saga&#39; uses</span></div>
<div class="line"><span class="lineno">  447</span><span class="stringliteral">          its improved, unbiased version named SAGA. Both methods also use an</span></div>
<div class="line"><span class="lineno">  448</span><span class="stringliteral">          iterative procedure, and are often faster than other solvers when</span></div>
<div class="line"><span class="lineno">  449</span><span class="stringliteral">          both n_samples and n_features are large. Note that &#39;sag&#39; and</span></div>
<div class="line"><span class="lineno">  450</span><span class="stringliteral">          &#39;saga&#39; fast convergence is only guaranteed on features with</span></div>
<div class="line"><span class="lineno">  451</span><span class="stringliteral">          approximately the same scale. You can preprocess the data with a</span></div>
<div class="line"><span class="lineno">  452</span><span class="stringliteral">          scaler from sklearn.preprocessing.</span></div>
<div class="line"><span class="lineno">  453</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  454</span><span class="stringliteral">        - &#39;lbfgs&#39; uses L-BFGS-B algorithm implemented in</span></div>
<div class="line"><span class="lineno">  455</span><span class="stringliteral">          `scipy.optimize.minimize`. It can be used only when `positive`</span></div>
<div class="line"><span class="lineno">  456</span><span class="stringliteral">          is True.</span></div>
<div class="line"><span class="lineno">  457</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  458</span><span class="stringliteral">        All solvers except &#39;svd&#39; support both dense and sparse data. However, only</span></div>
<div class="line"><span class="lineno">  459</span><span class="stringliteral">        &#39;lsqr&#39;, &#39;sag&#39;, &#39;sparse_cg&#39;, and &#39;lbfgs&#39; support sparse input when</span></div>
<div class="line"><span class="lineno">  460</span><span class="stringliteral">        `fit_intercept` is True.</span></div>
<div class="line"><span class="lineno">  461</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  462</span><span class="stringliteral">        .. versionadded:: 0.17</span></div>
<div class="line"><span class="lineno">  463</span><span class="stringliteral">           Stochastic Average Gradient descent solver.</span></div>
<div class="line"><span class="lineno">  464</span><span class="stringliteral">        .. versionadded:: 0.19</span></div>
<div class="line"><span class="lineno">  465</span><span class="stringliteral">           SAGA solver.</span></div>
<div class="line"><span class="lineno">  466</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  467</span><span class="stringliteral">    max_iter : int, default=None</span></div>
<div class="line"><span class="lineno">  468</span><span class="stringliteral">        Maximum number of iterations for conjugate gradient solver.</span></div>
<div class="line"><span class="lineno">  469</span><span class="stringliteral">        For the &#39;sparse_cg&#39; and &#39;lsqr&#39; solvers, the default value is determined</span></div>
<div class="line"><span class="lineno">  470</span><span class="stringliteral">        by scipy.sparse.linalg. For &#39;sag&#39; and saga solver, the default value is</span></div>
<div class="line"><span class="lineno">  471</span><span class="stringliteral">        1000. For &#39;lbfgs&#39; solver, the default value is 15000.</span></div>
<div class="line"><span class="lineno">  472</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  473</span><span class="stringliteral">    tol : float, default=1e-4</span></div>
<div class="line"><span class="lineno">  474</span><span class="stringliteral">        Precision of the solution. Note that `tol` has no effect for solvers &#39;svd&#39; and</span></div>
<div class="line"><span class="lineno">  475</span><span class="stringliteral">        &#39;cholesky&#39;.</span></div>
<div class="line"><span class="lineno">  476</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  477</span><span class="stringliteral">        .. versionchanged:: 1.2</span></div>
<div class="line"><span class="lineno">  478</span><span class="stringliteral">           Default value changed from 1e-3 to 1e-4 for consistency with other linear</span></div>
<div class="line"><span class="lineno">  479</span><span class="stringliteral">           models.</span></div>
<div class="line"><span class="lineno">  480</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  481</span><span class="stringliteral">    verbose : int, default=0</span></div>
<div class="line"><span class="lineno">  482</span><span class="stringliteral">        Verbosity level. Setting verbose &gt; 0 will display additional</span></div>
<div class="line"><span class="lineno">  483</span><span class="stringliteral">        information depending on the solver used.</span></div>
<div class="line"><span class="lineno">  484</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  485</span><span class="stringliteral">    positive : bool, default=False</span></div>
<div class="line"><span class="lineno">  486</span><span class="stringliteral">        When set to ``True``, forces the coefficients to be positive.</span></div>
<div class="line"><span class="lineno">  487</span><span class="stringliteral">        Only &#39;lbfgs&#39; solver is supported in this case.</span></div>
<div class="line"><span class="lineno">  488</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  489</span><span class="stringliteral">    random_state : int, RandomState instance, default=None</span></div>
<div class="line"><span class="lineno">  490</span><span class="stringliteral">        Used when ``solver`` == &#39;sag&#39; or &#39;saga&#39; to shuffle the data.</span></div>
<div class="line"><span class="lineno">  491</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;` for details.</span></div>
<div class="line"><span class="lineno">  492</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  493</span><span class="stringliteral">    return_n_iter : bool, default=False</span></div>
<div class="line"><span class="lineno">  494</span><span class="stringliteral">        If True, the method also returns `n_iter`, the actual number of</span></div>
<div class="line"><span class="lineno">  495</span><span class="stringliteral">        iteration performed by the solver.</span></div>
<div class="line"><span class="lineno">  496</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  497</span><span class="stringliteral">        .. versionadded:: 0.17</span></div>
<div class="line"><span class="lineno">  498</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  499</span><span class="stringliteral">    return_intercept : bool, default=False</span></div>
<div class="line"><span class="lineno">  500</span><span class="stringliteral">        If True and if X is sparse, the method also returns the intercept,</span></div>
<div class="line"><span class="lineno">  501</span><span class="stringliteral">        and the solver is automatically changed to &#39;sag&#39;. This is only a</span></div>
<div class="line"><span class="lineno">  502</span><span class="stringliteral">        temporary fix for fitting the intercept with sparse data. For dense</span></div>
<div class="line"><span class="lineno">  503</span><span class="stringliteral">        data, use sklearn.linear_model._preprocess_data before your regression.</span></div>
<div class="line"><span class="lineno">  504</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  505</span><span class="stringliteral">        .. versionadded:: 0.17</span></div>
<div class="line"><span class="lineno">  506</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  507</span><span class="stringliteral">    check_input : bool, default=True</span></div>
<div class="line"><span class="lineno">  508</span><span class="stringliteral">        If False, the input arrays X and y will not be checked.</span></div>
<div class="line"><span class="lineno">  509</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  510</span><span class="stringliteral">        .. versionadded:: 0.21</span></div>
<div class="line"><span class="lineno">  511</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  512</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  513</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  514</span><span class="stringliteral">    coef : ndarray of shape (n_features,) or (n_targets, n_features)</span></div>
<div class="line"><span class="lineno">  515</span><span class="stringliteral">        Weight vector(s).</span></div>
<div class="line"><span class="lineno">  516</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  517</span><span class="stringliteral">    n_iter : int, optional</span></div>
<div class="line"><span class="lineno">  518</span><span class="stringliteral">        The actual number of iteration performed by the solver.</span></div>
<div class="line"><span class="lineno">  519</span><span class="stringliteral">        Only returned if `return_n_iter` is True.</span></div>
<div class="line"><span class="lineno">  520</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  521</span><span class="stringliteral">    intercept : float or ndarray of shape (n_targets,)</span></div>
<div class="line"><span class="lineno">  522</span><span class="stringliteral">        The intercept of the model. Only returned if `return_intercept`</span></div>
<div class="line"><span class="lineno">  523</span><span class="stringliteral">        is True and if X is a scipy sparse array.</span></div>
<div class="line"><span class="lineno">  524</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  525</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  526</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  527</span><span class="stringliteral">    This function won&#39;t compute the intercept.</span></div>
<div class="line"><span class="lineno">  528</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  529</span><span class="stringliteral">    Regularization improves the conditioning of the problem and</span></div>
<div class="line"><span class="lineno">  530</span><span class="stringliteral">    reduces the variance of the estimates. Larger values specify stronger</span></div>
<div class="line"><span class="lineno">  531</span><span class="stringliteral">    regularization. Alpha corresponds to ``1 / (2C)`` in other linear</span></div>
<div class="line"><span class="lineno">  532</span><span class="stringliteral">    models such as :class:`~sklearn.linear_model.LogisticRegression` or</span></div>
<div class="line"><span class="lineno">  533</span><span class="stringliteral">    :class:`~sklearn.svm.LinearSVC`. If an array is passed, penalties are</span></div>
<div class="line"><span class="lineno">  534</span><span class="stringliteral">    assumed to be specific to the targets. Hence they must correspond in</span></div>
<div class="line"><span class="lineno">  535</span><span class="stringliteral">    number.</span></div>
<div class="line"><span class="lineno">  536</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  537</span>    <span class="keywordflow">return</span> _ridge_regression(</div>
<div class="line"><span class="lineno">  538</span>        X,</div>
<div class="line"><span class="lineno">  539</span>        y,</div>
<div class="line"><span class="lineno">  540</span>        alpha,</div>
<div class="line"><span class="lineno">  541</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  542</span>        solver=solver,</div>
<div class="line"><span class="lineno">  543</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  544</span>        tol=tol,</div>
<div class="line"><span class="lineno">  545</span>        verbose=verbose,</div>
<div class="line"><span class="lineno">  546</span>        positive=positive,</div>
<div class="line"><span class="lineno">  547</span>        random_state=random_state,</div>
<div class="line"><span class="lineno">  548</span>        return_n_iter=return_n_iter,</div>
<div class="line"><span class="lineno">  549</span>        return_intercept=return_intercept,</div>
<div class="line"><span class="lineno">  550</span>        X_scale=<span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  551</span>        X_offset=<span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  552</span>        check_input=check_input,</div>
<div class="line"><span class="lineno">  553</span>    )</div>
<div class="line"><span class="lineno">  554</span> </div>
<div class="line"><span class="lineno">  555</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
