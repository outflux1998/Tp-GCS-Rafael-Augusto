<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.utils.optimize Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1utils.html">utils</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1utils_1_1optimize.html">optimize</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.utils.optimize Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1utils_1_1optimize_1_1___line_search_error.html">_LineSearchError</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a5bd48422e037f3d35414a2ebfd47c874" id="r_a5bd48422e037f3d35414a2ebfd47c874"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1optimize.html#a5bd48422e037f3d35414a2ebfd47c874">_line_search_wolfe12</a> (<a class="el" href="__lapack__subroutines_8h.html#af01a903df7bdb7a494f5827e45bf3a2a">f</a>, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)</td></tr>
<tr class="separator:a5bd48422e037f3d35414a2ebfd47c874"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad58675fddac6e507d6143d3254177763" id="r_ad58675fddac6e507d6143d3254177763"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1optimize.html#ad58675fddac6e507d6143d3254177763">_cg</a> (fhess_p, fgrad, maxiter, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>)</td></tr>
<tr class="separator:ad58675fddac6e507d6143d3254177763"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a685b6d5f3e947dd94e1c9060e1dcd633" id="r_a685b6d5f3e947dd94e1c9060e1dcd633"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1optimize.html#a685b6d5f3e947dd94e1c9060e1dcd633">_newton_cg</a> (grad_hess, <a class="el" href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a>, grad, x0, args=(), <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-4, maxiter=100, maxinner=200, line_search=True, warn=True)</td></tr>
<tr class="separator:a685b6d5f3e947dd94e1c9060e1dcd633"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a2e6509b4cb8d5ffb9a5a8ac39ef9e9" id="r_a5a2e6509b4cb8d5ffb9a5a8ac39ef9e9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1optimize.html#a5a2e6509b4cb8d5ffb9a5a8ac39ef9e9">_check_optimize_result</a> (solver, result, max_iter=None, extra_warning_msg=None)</td></tr>
<tr class="separator:a5a2e6509b4cb8d5ffb9a5a8ac39ef9e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Our own implementation of the Newton algorithm

Unlike the scipy.optimize version, this version of the Newton conjugate
gradient solver uses only one function call to retrieve the
func value, the gradient value and a callable for the Hessian matvec
product. If the function call is very expensive (e.g. for logistic
regression with large design matrix), this approach gives very
significant speedups.
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="ad58675fddac6e507d6143d3254177763" name="ad58675fddac6e507d6143d3254177763"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad58675fddac6e507d6143d3254177763">&#9670;&#160;</a></span>_cg()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.optimize._cg </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fhess_p</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fgrad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>maxiter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Solve iteratively the linear system 'fhess_p . xsupi = fgrad'
with a conjugate gradient descent.

Parameters
----------
fhess_p : callable
    Function that takes the gradient as a parameter and returns the
    matrix product of the Hessian and gradient.

fgrad : ndarray of shape (n_features,) or (n_features + 1,)
    Gradient vector.

maxiter : int
    Number of CG iterations.

tol : float
    Stopping criterion.

Returns
-------
xsupi : ndarray of shape (n_features,) or (n_features + 1,)
    Estimated solution.
</pre> <div class="fragment"><div class="line"><span class="lineno">   53</span><span class="keyword">def </span>_cg(fhess_p, fgrad, maxiter, tol):</div>
<div class="line"><span class="lineno">   54</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">    Solve iteratively the linear system &#39;fhess_p . xsupi = fgrad&#39;</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral">    with a conjugate gradient descent.</span></div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">    fhess_p : callable</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral">        Function that takes the gradient as a parameter and returns the</span></div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">        matrix product of the Hessian and gradient.</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    fgrad : ndarray of shape (n_features,) or (n_features + 1,)</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">        Gradient vector.</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    maxiter : int</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">        Number of CG iterations.</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    tol : float</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">        Stopping criterion.</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">    xsupi : ndarray of shape (n_features,) or (n_features + 1,)</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">        Estimated solution.</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   78</span>    xsupi = np.zeros(len(fgrad), dtype=fgrad.dtype)</div>
<div class="line"><span class="lineno">   79</span>    ri = fgrad</div>
<div class="line"><span class="lineno">   80</span>    psupi = -ri</div>
<div class="line"><span class="lineno">   81</span>    i = 0</div>
<div class="line"><span class="lineno">   82</span>    dri0 = np.dot(ri, ri)</div>
<div class="line"><span class="lineno">   83</span> </div>
<div class="line"><span class="lineno">   84</span>    <span class="keywordflow">while</span> i &lt;= maxiter:</div>
<div class="line"><span class="lineno">   85</span>        <span class="keywordflow">if</span> np.sum(np.abs(ri)) &lt;= tol:</div>
<div class="line"><span class="lineno">   86</span>            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">   87</span> </div>
<div class="line"><span class="lineno">   88</span>        Ap = fhess_p(psupi)</div>
<div class="line"><span class="lineno">   89</span>        <span class="comment"># check curvature</span></div>
<div class="line"><span class="lineno">   90</span>        curv = np.dot(psupi, Ap)</div>
<div class="line"><span class="lineno">   91</span>        <span class="keywordflow">if</span> 0 &lt;= curv &lt;= 3 * np.finfo(np.float64).eps:</div>
<div class="line"><span class="lineno">   92</span>            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">   93</span>        <span class="keywordflow">elif</span> curv &lt; 0:</div>
<div class="line"><span class="lineno">   94</span>            <span class="keywordflow">if</span> i &gt; 0:</div>
<div class="line"><span class="lineno">   95</span>                <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">   96</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   97</span>                <span class="comment"># fall back to steepest descent direction</span></div>
<div class="line"><span class="lineno">   98</span>                xsupi += dri0 / curv * psupi</div>
<div class="line"><span class="lineno">   99</span>                <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  100</span>        alphai = dri0 / curv</div>
<div class="line"><span class="lineno">  101</span>        xsupi += alphai * psupi</div>
<div class="line"><span class="lineno">  102</span>        ri = ri + alphai * Ap</div>
<div class="line"><span class="lineno">  103</span>        dri1 = np.dot(ri, ri)</div>
<div class="line"><span class="lineno">  104</span>        betai = dri1 / dri0</div>
<div class="line"><span class="lineno">  105</span>        psupi = -ri + betai * psupi</div>
<div class="line"><span class="lineno">  106</span>        i = i + 1</div>
<div class="line"><span class="lineno">  107</span>        dri0 = dri1  <span class="comment"># update np.dot(ri,ri) for next time.</span></div>
<div class="line"><span class="lineno">  108</span> </div>
<div class="line"><span class="lineno">  109</span>    <span class="keywordflow">return</span> xsupi</div>
<div class="line"><span class="lineno">  110</span> </div>
<div class="line"><span class="lineno">  111</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5a2e6509b4cb8d5ffb9a5a8ac39ef9e9" name="a5a2e6509b4cb8d5ffb9a5a8ac39ef9e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5a2e6509b4cb8d5ffb9a5a8ac39ef9e9">&#9670;&#160;</a></span>_check_optimize_result()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.optimize._check_optimize_result </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>result</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>extra_warning_msg</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Check the OptimizeResult for successful convergence

Parameters
----------
solver : str
   Solver name. Currently only `lbfgs` is supported.

result : OptimizeResult
   Result of the scipy.optimize.minimize function.

max_iter : int, default=None
   Expected maximum number of iterations.

extra_warning_msg : str, default=None
    Extra warning message.

Returns
-------
n_iter : int
   Number of iterations.
</pre> <div class="fragment"><div class="line"><span class="lineno">  217</span><span class="keyword">def </span>_check_optimize_result(solver, result, max_iter=None, extra_warning_msg=None):</div>
<div class="line"><span class="lineno">  218</span>    <span class="stringliteral">&quot;&quot;&quot;Check the OptimizeResult for successful convergence</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">    solver : str</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">       Solver name. Currently only `lbfgs` is supported.</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">    result : OptimizeResult</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">       Result of the scipy.optimize.minimize function.</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">    max_iter : int, default=None</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">       Expected maximum number of iterations.</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">    extra_warning_msg : str, default=None</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">        Extra warning message.</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">    n_iter : int</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">       Number of iterations.</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  239</span>    <span class="comment"># handle both scipy and scikit-learn solver names</span></div>
<div class="line"><span class="lineno">  240</span>    <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;lbfgs&quot;</span>:</div>
<div class="line"><span class="lineno">  241</span>        <span class="keywordflow">if</span> result.status != 0:</div>
<div class="line"><span class="lineno">  242</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  243</span>                <span class="comment"># The message is already decoded in scipy&gt;=1.6.0</span></div>
<div class="line"><span class="lineno">  244</span>                result_message = result.message.decode(<span class="stringliteral">&quot;latin1&quot;</span>)</div>
<div class="line"><span class="lineno">  245</span>            <span class="keywordflow">except</span> AttributeError:</div>
<div class="line"><span class="lineno">  246</span>                result_message = result.message</div>
<div class="line"><span class="lineno">  247</span>            warning_msg = (</div>
<div class="line"><span class="lineno">  248</span>                <span class="stringliteral">&quot;{} failed to converge (status={}):\n{}.\n\n&quot;</span></div>
<div class="line"><span class="lineno">  249</span>                <span class="stringliteral">&quot;Increase the number of iterations (max_iter) &quot;</span></div>
<div class="line"><span class="lineno">  250</span>                <span class="stringliteral">&quot;or scale the data as shown in:\n&quot;</span></div>
<div class="line"><span class="lineno">  251</span>                <span class="stringliteral">&quot;    https://scikit-learn.org/stable/modules/&quot;</span></div>
<div class="line"><span class="lineno">  252</span>                <span class="stringliteral">&quot;preprocessing.html&quot;</span></div>
<div class="line"><span class="lineno">  253</span>            ).format(solver, result.status, result_message)</div>
<div class="line"><span class="lineno">  254</span>            <span class="keywordflow">if</span> extra_warning_msg <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  255</span>                warning_msg += <span class="stringliteral">&quot;\n&quot;</span> + extra_warning_msg</div>
<div class="line"><span class="lineno">  256</span>            warnings.warn(warning_msg, ConvergenceWarning, stacklevel=2)</div>
<div class="line"><span class="lineno">  257</span>        <span class="keywordflow">if</span> max_iter <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  258</span>            <span class="comment"># In scipy &lt;= 1.0.0, nit may exceed maxiter for lbfgs.</span></div>
<div class="line"><span class="lineno">  259</span>            <span class="comment"># See https://github.com/scipy/scipy/issues/7854</span></div>
<div class="line"><span class="lineno">  260</span>            n_iter_i = min(result.nit, max_iter)</div>
<div class="line"><span class="lineno">  261</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  262</span>            n_iter_i = result.nit</div>
<div class="line"><span class="lineno">  263</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  264</span>        <span class="keywordflow">raise</span> NotImplementedError</div>
<div class="line"><span class="lineno">  265</span> </div>
<div class="line"><span class="lineno">  266</span>    <span class="keywordflow">return</span> n_iter_i</div>
</div><!-- fragment -->
</div>
</div>
<a id="a5bd48422e037f3d35414a2ebfd47c874" name="a5bd48422e037f3d35414a2ebfd47c874"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5bd48422e037f3d35414a2ebfd47c874">&#9670;&#160;</a></span>_line_search_wolfe12()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.optimize._line_search_wolfe12 </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>f</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fprime</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>xk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gfk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>old_fval</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>old_old_fval</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Same as line_search_wolfe1, but fall back to line_search_wolfe2 if
suitable step length is not found, and raise an exception if a
suitable step length is not found.

Raises
------
_LineSearchError
    If no suitable step size is found.</pre> <div class="fragment"><div class="line"><span class="lineno">   27</span><span class="keyword">def </span>_line_search_wolfe12(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs):</div>
<div class="line"><span class="lineno">   28</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">    Same as line_search_wolfe1, but fall back to line_search_wolfe2 if</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral">    suitable step length is not found, and raise an exception if a</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral">    suitable step length is not found.</span></div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">    Raises</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">    ------</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">    _LineSearchError</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">        If no suitable step size is found.</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   39</span>    ret = line_search_wolfe1(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)</div>
<div class="line"><span class="lineno">   40</span> </div>
<div class="line"><span class="lineno">   41</span>    <span class="keywordflow">if</span> ret[0] <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">   42</span>        <span class="comment"># line search failed: try different one.</span></div>
<div class="line"><span class="lineno">   43</span>        ret = line_search_wolfe2(</div>
<div class="line"><span class="lineno">   44</span>            f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs</div>
<div class="line"><span class="lineno">   45</span>        )</div>
<div class="line"><span class="lineno">   46</span> </div>
<div class="line"><span class="lineno">   47</span>    <span class="keywordflow">if</span> ret[0] <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">   48</span>        <span class="keywordflow">raise</span> _LineSearchError()</div>
<div class="line"><span class="lineno">   49</span> </div>
<div class="line"><span class="lineno">   50</span>    <span class="keywordflow">return</span> ret</div>
<div class="line"><span class="lineno">   51</span> </div>
<div class="line"><span class="lineno">   52</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a685b6d5f3e947dd94e1c9060e1dcd633" name="a685b6d5f3e947dd94e1c9060e1dcd633"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a685b6d5f3e947dd94e1c9060e1dcd633">&#9670;&#160;</a></span>_newton_cg()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.optimize._newton_cg </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>grad_hess</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>func</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>args</em> = <code>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>maxiter</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>maxinner</em> = <code>200</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>line_search</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>warn</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Minimization of scalar function of one or more variables using the
Newton-CG algorithm.

Parameters
----------
grad_hess : callable
    Should return the gradient and a callable returning the matvec product
    of the Hessian.

func : callable
    Should return the value of the function.

grad : callable
    Should return the function value and the gradient. This is used
    by the linesearch functions.

x0 : array of float
    Initial guess.

args : tuple, default=()
    Arguments passed to func_grad_hess, func and grad.

tol : float, default=1e-4
    Stopping criterion. The iteration will stop when
    ``max{|g_i | i = 1, ..., n} &lt;= tol``
    where ``g_i`` is the i-th component of the gradient.

maxiter : int, default=100
    Number of Newton iterations.

maxinner : int, default=200
    Number of CG iterations.

line_search : bool, default=True
    Whether to use a line search or not.

warn : bool, default=True
    Whether to warn when didn't converge.

Returns
-------
xk : ndarray of float
    Estimated minimum.
</pre> <div class="fragment"><div class="line"><span class="lineno">  123</span>):</div>
<div class="line"><span class="lineno">  124</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral">    Minimization of scalar function of one or more variables using the</span></div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral">    Newton-CG algorithm.</span></div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral">    grad_hess : callable</span></div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">        Should return the gradient and a callable returning the matvec product</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral">        of the Hessian.</span></div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">    func : callable</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">        Should return the value of the function.</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">    grad : callable</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">        Should return the function value and the gradient. This is used</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral">        by the linesearch functions.</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">    x0 : array of float</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">        Initial guess.</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">    args : tuple, default=()</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">        Arguments passed to func_grad_hess, func and grad.</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">    tol : float, default=1e-4</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">        Stopping criterion. The iteration will stop when</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">        ``max{|g_i | i = 1, ..., n} &lt;= tol``</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">        where ``g_i`` is the i-th component of the gradient.</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">    maxiter : int, default=100</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">        Number of Newton iterations.</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">    maxinner : int, default=200</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">        Number of CG iterations.</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">    line_search : bool, default=True</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">        Whether to use a line search or not.</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">    warn : bool, default=True</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">        Whether to warn when didn&#39;t converge.</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">    xk : ndarray of float</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">        Estimated minimum.</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  169</span>    x0 = np.asarray(x0).flatten()</div>
<div class="line"><span class="lineno">  170</span>    xk = x0</div>
<div class="line"><span class="lineno">  171</span>    k = 0</div>
<div class="line"><span class="lineno">  172</span> </div>
<div class="line"><span class="lineno">  173</span>    <span class="keywordflow">if</span> line_search:</div>
<div class="line"><span class="lineno">  174</span>        old_fval = <a class="code hl_function" href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a>(x0, *args)</div>
<div class="line"><span class="lineno">  175</span>        old_old_fval = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  176</span> </div>
<div class="line"><span class="lineno">  177</span>    <span class="comment"># Outer loop: our Newton iteration</span></div>
<div class="line"><span class="lineno">  178</span>    <span class="keywordflow">while</span> k &lt; maxiter:</div>
<div class="line"><span class="lineno">  179</span>        <span class="comment"># Compute a search direction pk by applying the CG method to</span></div>
<div class="line"><span class="lineno">  180</span>        <span class="comment">#  del2 f(xk) p = - fgrad f(xk) starting from 0.</span></div>
<div class="line"><span class="lineno">  181</span>        fgrad, fhess_p = grad_hess(xk, *args)</div>
<div class="line"><span class="lineno">  182</span> </div>
<div class="line"><span class="lineno">  183</span>        absgrad = np.abs(fgrad)</div>
<div class="line"><span class="lineno">  184</span>        <span class="keywordflow">if</span> np.max(absgrad) &lt;= tol:</div>
<div class="line"><span class="lineno">  185</span>            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  186</span> </div>
<div class="line"><span class="lineno">  187</span>        maggrad = np.sum(absgrad)</div>
<div class="line"><span class="lineno">  188</span>        eta = min([0.5, np.sqrt(maggrad)])</div>
<div class="line"><span class="lineno">  189</span>        termcond = eta * maggrad</div>
<div class="line"><span class="lineno">  190</span> </div>
<div class="line"><span class="lineno">  191</span>        <span class="comment"># Inner loop: solve the Newton update by conjugate gradient, to</span></div>
<div class="line"><span class="lineno">  192</span>        <span class="comment"># avoid inverting the Hessian</span></div>
<div class="line"><span class="lineno">  193</span>        xsupi = _cg(fhess_p, fgrad, maxiter=maxinner, tol=termcond)</div>
<div class="line"><span class="lineno">  194</span> </div>
<div class="line"><span class="lineno">  195</span>        alphak = 1.0</div>
<div class="line"><span class="lineno">  196</span> </div>
<div class="line"><span class="lineno">  197</span>        <span class="keywordflow">if</span> line_search:</div>
<div class="line"><span class="lineno">  198</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  199</span>                alphak, fc, gc, old_fval, old_old_fval, gfkp1 = _line_search_wolfe12(</div>
<div class="line"><span class="lineno">  200</span>                    func, grad, xk, xsupi, fgrad, old_fval, old_old_fval, args=args</div>
<div class="line"><span class="lineno">  201</span>                )</div>
<div class="line"><span class="lineno">  202</span>            <span class="keywordflow">except</span> _LineSearchError:</div>
<div class="line"><span class="lineno">  203</span>                warnings.warn(<span class="stringliteral">&quot;Line Search failed&quot;</span>)</div>
<div class="line"><span class="lineno">  204</span>                <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  205</span> </div>
<div class="line"><span class="lineno">  206</span>        xk = xk + alphak * xsupi  <span class="comment"># upcast if necessary</span></div>
<div class="line"><span class="lineno">  207</span>        k += 1</div>
<div class="line"><span class="lineno">  208</span> </div>
<div class="line"><span class="lineno">  209</span>    <span class="keywordflow">if</span> warn <span class="keywordflow">and</span> k &gt;= maxiter:</div>
<div class="line"><span class="lineno">  210</span>        warnings.warn(</div>
<div class="line"><span class="lineno">  211</span>            <span class="stringliteral">&quot;newton-cg failed to converge. Increase the number of iterations.&quot;</span>,</div>
<div class="line"><span class="lineno">  212</span>            ConvergenceWarning,</div>
<div class="line"><span class="lineno">  213</span>        )</div>
<div class="line"><span class="lineno">  214</span>    <span class="keywordflow">return</span> xk, k</div>
<div class="line"><span class="lineno">  215</span> </div>
<div class="line"><span class="lineno">  216</span> </div>
<div class="ttc" id="acallback_2foo_8f_html_a565fe2cc583df102f120752b0011c330"><div class="ttname"><a href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a></div><div class="ttdeci">subroutine func(a)</div><div class="ttdef"><b>Definition</b> foo.f:9</div></div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
