<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.metrics._regression Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1metrics.html">metrics</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html">_regression</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.metrics._regression Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ab147e495adbcc8967a3d976ee6f9e8f9" id="r_ab147e495adbcc8967a3d976ee6f9e8f9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#ab147e495adbcc8967a3d976ee6f9e8f9">_check_reg_targets</a> (y_true, y_pred, multioutput, dtype=&quot;numeric&quot;)</td></tr>
<tr class="separator:ab147e495adbcc8967a3d976ee6f9e8f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31dc70f5bfc4e47761f2c427e1601c27" id="r_a31dc70f5bfc4e47761f2c427e1601c27"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a31dc70f5bfc4e47761f2c427e1601c27">mean_absolute_error</a> (y_true, y_pred, *sample_weight=None, multioutput=&quot;uniform_average&quot;)</td></tr>
<tr class="separator:a31dc70f5bfc4e47761f2c427e1601c27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af07e96e2ec72f6820aa3d243740bad76" id="r_af07e96e2ec72f6820aa3d243740bad76"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#af07e96e2ec72f6820aa3d243740bad76">mean_pinball_loss</a> (y_true, y_pred, *sample_weight=None, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>=0.5, multioutput=&quot;uniform_average&quot;)</td></tr>
<tr class="separator:af07e96e2ec72f6820aa3d243740bad76"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e09f27b963f5e2514e260b3a327beae" id="r_a8e09f27b963f5e2514e260b3a327beae"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a8e09f27b963f5e2514e260b3a327beae">mean_absolute_percentage_error</a> (y_true, y_pred, *sample_weight=None, multioutput=&quot;uniform_average&quot;)</td></tr>
<tr class="separator:a8e09f27b963f5e2514e260b3a327beae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9bb0aafe224fde57660c7be34331677d" id="r_a9bb0aafe224fde57660c7be34331677d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a9bb0aafe224fde57660c7be34331677d">mean_squared_error</a> (y_true, y_pred, *sample_weight=None, multioutput=&quot;uniform_average&quot;, squared=True)</td></tr>
<tr class="separator:a9bb0aafe224fde57660c7be34331677d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a371dc0c75bbb46518b2780f44c9e8090" id="r_a371dc0c75bbb46518b2780f44c9e8090"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a371dc0c75bbb46518b2780f44c9e8090">mean_squared_log_error</a> (y_true, y_pred, *sample_weight=None, multioutput=&quot;uniform_average&quot;, squared=True)</td></tr>
<tr class="separator:a371dc0c75bbb46518b2780f44c9e8090"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad20b0fabe18d48253a4e7804c8478b39" id="r_ad20b0fabe18d48253a4e7804c8478b39"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#ad20b0fabe18d48253a4e7804c8478b39">median_absolute_error</a> (y_true, y_pred, *multioutput=&quot;uniform_average&quot;, sample_weight=None)</td></tr>
<tr class="separator:ad20b0fabe18d48253a4e7804c8478b39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af83cacf54cc7c4cc7440634437ce1ea5" id="r_af83cacf54cc7c4cc7440634437ce1ea5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#af83cacf54cc7c4cc7440634437ce1ea5">_assemble_r2_explained_variance</a> (numerator, denominator, n_outputs, multioutput, force_finite)</td></tr>
<tr class="separator:af83cacf54cc7c4cc7440634437ce1ea5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe2e1ed196a96739ce70ef7a20db9372" id="r_abe2e1ed196a96739ce70ef7a20db9372"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#abe2e1ed196a96739ce70ef7a20db9372">explained_variance_score</a> (y_true, y_pred, *sample_weight=None, multioutput=&quot;uniform_average&quot;, force_finite=True)</td></tr>
<tr class="separator:abe2e1ed196a96739ce70ef7a20db9372"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a321756855a5b291846a1e738f9003bba" id="r_a321756855a5b291846a1e738f9003bba"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a321756855a5b291846a1e738f9003bba">r2_score</a> (y_true, y_pred, *sample_weight=None, multioutput=&quot;uniform_average&quot;, force_finite=True)</td></tr>
<tr class="separator:a321756855a5b291846a1e738f9003bba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9193a97a2feef27a89742321e496da3b" id="r_a9193a97a2feef27a89742321e496da3b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a9193a97a2feef27a89742321e496da3b">max_error</a> (y_true, y_pred)</td></tr>
<tr class="separator:a9193a97a2feef27a89742321e496da3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04b1ea8f3154a641738e0cfe021622df" id="r_a04b1ea8f3154a641738e0cfe021622df"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a04b1ea8f3154a641738e0cfe021622df">_mean_tweedie_deviance</a> (y_true, y_pred, sample_weight, power)</td></tr>
<tr class="separator:a04b1ea8f3154a641738e0cfe021622df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8760cb469230339c89b3b62d8536dbdc" id="r_a8760cb469230339c89b3b62d8536dbdc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a8760cb469230339c89b3b62d8536dbdc">mean_tweedie_deviance</a> (y_true, y_pred, *sample_weight=None, power=0)</td></tr>
<tr class="separator:a8760cb469230339c89b3b62d8536dbdc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf6b648d7fcfd09ff1e19ae5ac71d033" id="r_aaf6b648d7fcfd09ff1e19ae5ac71d033"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#aaf6b648d7fcfd09ff1e19ae5ac71d033">mean_poisson_deviance</a> (y_true, y_pred, *sample_weight=None)</td></tr>
<tr class="separator:aaf6b648d7fcfd09ff1e19ae5ac71d033"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a301d775644c0c902122f98aafcf9dbd0" id="r_a301d775644c0c902122f98aafcf9dbd0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a301d775644c0c902122f98aafcf9dbd0">mean_gamma_deviance</a> (y_true, y_pred, *sample_weight=None)</td></tr>
<tr class="separator:a301d775644c0c902122f98aafcf9dbd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abdde527ffcb35166f371a5ceb850a3eb" id="r_abdde527ffcb35166f371a5ceb850a3eb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#abdde527ffcb35166f371a5ceb850a3eb">d2_tweedie_score</a> (y_true, y_pred, *sample_weight=None, power=0)</td></tr>
<tr class="separator:abdde527ffcb35166f371a5ceb850a3eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0bd2df6b40b70224d2dd36734cfdeba4" id="r_a0bd2df6b40b70224d2dd36734cfdeba4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a0bd2df6b40b70224d2dd36734cfdeba4">d2_pinball_score</a> (y_true, y_pred, *sample_weight=None, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>=0.5, multioutput=&quot;uniform_average&quot;)</td></tr>
<tr class="separator:a0bd2df6b40b70224d2dd36734cfdeba4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1902af78bdbf846320c8f58e89151e8f" id="r_a1902af78bdbf846320c8f58e89151e8f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__regression.html#a1902af78bdbf846320c8f58e89151e8f">d2_absolute_error_score</a> (y_true, y_pred, *sample_weight=None, multioutput=&quot;uniform_average&quot;)</td></tr>
<tr class="separator:a1902af78bdbf846320c8f58e89151e8f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Metrics to assess performance on regression task.

Functions named as ``*_score`` return a scalar value to maximize: the higher
the better.

Function named as ``*_error`` or ``*_loss`` return a scalar value to minimize:
the lower the better.
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="af83cacf54cc7c4cc7440634437ce1ea5" name="af83cacf54cc7c4cc7440634437ce1ea5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af83cacf54cc7c4cc7440634437ce1ea5">&#9670;&#160;</a></span>_assemble_r2_explained_variance()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression._assemble_r2_explained_variance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>numerator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>denominator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>force_finite</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Common part used by explained variance score and :math:`R^2` score.</pre> <div class="fragment"><div class="line"><span class="lineno">  617</span>):</div>
<div class="line"><span class="lineno">  618</span>    <span class="stringliteral">&quot;&quot;&quot;Common part used by explained variance score and :math:`R^2` score.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  619</span> </div>
<div class="line"><span class="lineno">  620</span>    nonzero_denominator = denominator != 0</div>
<div class="line"><span class="lineno">  621</span> </div>
<div class="line"><span class="lineno">  622</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> force_finite:</div>
<div class="line"><span class="lineno">  623</span>        <span class="comment"># Standard formula, that may lead to NaN or -Inf</span></div>
<div class="line"><span class="lineno">  624</span>        output_scores = 1 - (numerator / denominator)</div>
<div class="line"><span class="lineno">  625</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  626</span>        nonzero_numerator = numerator != 0</div>
<div class="line"><span class="lineno">  627</span>        <span class="comment"># Default = Zero Numerator = perfect predictions. Set to 1.0</span></div>
<div class="line"><span class="lineno">  628</span>        <span class="comment"># (note: even if denominator is zero, thus avoiding NaN scores)</span></div>
<div class="line"><span class="lineno">  629</span>        output_scores = np.ones([n_outputs])</div>
<div class="line"><span class="lineno">  630</span>        <span class="comment"># Non-zero Numerator and Non-zero Denominator: use the formula</span></div>
<div class="line"><span class="lineno">  631</span>        valid_score = nonzero_denominator &amp; nonzero_numerator</div>
<div class="line"><span class="lineno">  632</span>        output_scores[valid_score] = 1 - (</div>
<div class="line"><span class="lineno">  633</span>            numerator[valid_score] / denominator[valid_score]</div>
<div class="line"><span class="lineno">  634</span>        )</div>
<div class="line"><span class="lineno">  635</span>        <span class="comment"># Non-zero Numerator and Zero Denominator:</span></div>
<div class="line"><span class="lineno">  636</span>        <span class="comment"># arbitrary set to 0.0 to avoid -inf scores</span></div>
<div class="line"><span class="lineno">  637</span>        output_scores[nonzero_numerator &amp; ~nonzero_denominator] = 0.0</div>
<div class="line"><span class="lineno">  638</span> </div>
<div class="line"><span class="lineno">  639</span>    <span class="keywordflow">if</span> isinstance(multioutput, str):</div>
<div class="line"><span class="lineno">  640</span>        <span class="keywordflow">if</span> multioutput == <span class="stringliteral">&quot;raw_values&quot;</span>:</div>
<div class="line"><span class="lineno">  641</span>            <span class="comment"># return scores individually</span></div>
<div class="line"><span class="lineno">  642</span>            <span class="keywordflow">return</span> output_scores</div>
<div class="line"><span class="lineno">  643</span>        <span class="keywordflow">elif</span> multioutput == <span class="stringliteral">&quot;uniform_average&quot;</span>:</div>
<div class="line"><span class="lineno">  644</span>            <span class="comment"># Passing None as weights to np.average results is uniform mean</span></div>
<div class="line"><span class="lineno">  645</span>            avg_weights = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  646</span>        <span class="keywordflow">elif</span> multioutput == <span class="stringliteral">&quot;variance_weighted&quot;</span>:</div>
<div class="line"><span class="lineno">  647</span>            avg_weights = denominator</div>
<div class="line"><span class="lineno">  648</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.any(nonzero_denominator):</div>
<div class="line"><span class="lineno">  649</span>                <span class="comment"># All weights are zero, np.average would raise a ZeroDiv error.</span></div>
<div class="line"><span class="lineno">  650</span>                <span class="comment"># This only happens when all y are constant (or 1-element long)</span></div>
<div class="line"><span class="lineno">  651</span>                <span class="comment"># Since weights are all equal, fall back to uniform weights.</span></div>
<div class="line"><span class="lineno">  652</span>                avg_weights = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  653</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  654</span>        avg_weights = multioutput</div>
<div class="line"><span class="lineno">  655</span> </div>
<div class="line"><span class="lineno">  656</span>    <span class="keywordflow">return</span> np.average(output_scores, weights=avg_weights)</div>
<div class="line"><span class="lineno">  657</span> </div>
<div class="line"><span class="lineno">  658</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab147e495adbcc8967a3d976ee6f9e8f9" name="ab147e495adbcc8967a3d976ee6f9e8f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab147e495adbcc8967a3d976ee6f9e8f9">&#9670;&#160;</a></span>_check_reg_targets()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression._check_reg_targets </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em> = <code>&quot;numeric&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Check that y_true and y_pred belong to the same regression task.

Parameters
----------
y_true : array-like

y_pred : array-like

multioutput : array-like or string in ['raw_values', uniform_average',
    'variance_weighted'] or None
    None is accepted due to backward compatibility of r2_score().

dtype : str or list, default="numeric"
    the dtype argument passed to check_array.

Returns
-------
type_true : one of {'continuous', continuous-multioutput'}
    The type of the true target data, as output by
    'utils.multiclass.type_of_target'.

y_true : array-like of shape (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples, n_outputs)
    Estimated target values.

multioutput : array-like of shape (n_outputs) or string in ['raw_values',
    uniform_average', 'variance_weighted'] or None
    Custom output weights if ``multioutput`` is array-like or
    just the corresponding argument if ``multioutput`` is a
    correct keyword.
</pre> <div class="fragment"><div class="line"><span class="lineno">   66</span><span class="keyword">def </span>_check_reg_targets(y_true, y_pred, multioutput, dtype=&quot;numeric&quot;):</div>
<div class="line"><span class="lineno">   67</span>    <span class="stringliteral">&quot;&quot;&quot;Check that y_true and y_pred belong to the same regression task.</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">    y_true : array-like</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">    y_pred : array-like</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">    multioutput : array-like or string in [&#39;raw_values&#39;, uniform_average&#39;,</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">        &#39;variance_weighted&#39;] or None</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">        None is accepted due to backward compatibility of r2_score().</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">    dtype : str or list, default=&quot;numeric&quot;</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">        the dtype argument passed to check_array.</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral">    type_true : one of {&#39;continuous&#39;, continuous-multioutput&#39;}</span></div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">        The type of the true target data, as output by</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">        &#39;utils.multiclass.type_of_target&#39;.</span></div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">    y_true : array-like of shape (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">    y_pred : array-like of shape (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral">    multioutput : array-like of shape (n_outputs) or string in [&#39;raw_values&#39;,</span></div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral">        uniform_average&#39;, &#39;variance_weighted&#39;] or None</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral">        Custom output weights if ``multioutput`` is array-like or</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral">        just the corresponding argument if ``multioutput`` is a</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">        correct keyword.</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  100</span>    check_consistent_length(y_true, y_pred)</div>
<div class="line"><span class="lineno">  101</span>    y_true = check_array(y_true, ensure_2d=<span class="keyword">False</span>, dtype=dtype)</div>
<div class="line"><span class="lineno">  102</span>    y_pred = check_array(y_pred, ensure_2d=<span class="keyword">False</span>, dtype=dtype)</div>
<div class="line"><span class="lineno">  103</span> </div>
<div class="line"><span class="lineno">  104</span>    <span class="keywordflow">if</span> y_true.ndim == 1:</div>
<div class="line"><span class="lineno">  105</span>        y_true = y_true.reshape((-1, 1))</div>
<div class="line"><span class="lineno">  106</span> </div>
<div class="line"><span class="lineno">  107</span>    <span class="keywordflow">if</span> y_pred.ndim == 1:</div>
<div class="line"><span class="lineno">  108</span>        y_pred = y_pred.reshape((-1, 1))</div>
<div class="line"><span class="lineno">  109</span> </div>
<div class="line"><span class="lineno">  110</span>    <span class="keywordflow">if</span> y_true.shape[1] != y_pred.shape[1]:</div>
<div class="line"><span class="lineno">  111</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  112</span>            <span class="stringliteral">&quot;y_true and y_pred have different number of output ({0}!={1})&quot;</span>.format(</div>
<div class="line"><span class="lineno">  113</span>                y_true.shape[1], y_pred.shape[1]</div>
<div class="line"><span class="lineno">  114</span>            )</div>
<div class="line"><span class="lineno">  115</span>        )</div>
<div class="line"><span class="lineno">  116</span> </div>
<div class="line"><span class="lineno">  117</span>    n_outputs = y_true.shape[1]</div>
<div class="line"><span class="lineno">  118</span>    allowed_multioutput_str = (<span class="stringliteral">&quot;raw_values&quot;</span>, <span class="stringliteral">&quot;uniform_average&quot;</span>, <span class="stringliteral">&quot;variance_weighted&quot;</span>)</div>
<div class="line"><span class="lineno">  119</span>    <span class="keywordflow">if</span> isinstance(multioutput, str):</div>
<div class="line"><span class="lineno">  120</span>        <span class="keywordflow">if</span> multioutput <span class="keywordflow">not</span> <span class="keywordflow">in</span> allowed_multioutput_str:</div>
<div class="line"><span class="lineno">  121</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  122</span>                <span class="stringliteral">&quot;Allowed &#39;multioutput&#39; string values are {}. &quot;</span></div>
<div class="line"><span class="lineno">  123</span>                <span class="stringliteral">&quot;You provided multioutput={!r}&quot;</span>.format(</div>
<div class="line"><span class="lineno">  124</span>                    allowed_multioutput_str, multioutput</div>
<div class="line"><span class="lineno">  125</span>                )</div>
<div class="line"><span class="lineno">  126</span>            )</div>
<div class="line"><span class="lineno">  127</span>    <span class="keywordflow">elif</span> multioutput <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  128</span>        multioutput = check_array(multioutput, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  129</span>        <span class="keywordflow">if</span> n_outputs == 1:</div>
<div class="line"><span class="lineno">  130</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Custom weights are useful only in multi-output cases.&quot;</span>)</div>
<div class="line"><span class="lineno">  131</span>        <span class="keywordflow">elif</span> n_outputs != len(multioutput):</div>
<div class="line"><span class="lineno">  132</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  133</span>                <span class="stringliteral">&quot;There must be equally many custom weights (%d) as outputs (%d).&quot;</span></div>
<div class="line"><span class="lineno">  134</span>                % (len(multioutput), n_outputs)</div>
<div class="line"><span class="lineno">  135</span>            )</div>
<div class="line"><span class="lineno">  136</span>    y_type = <span class="stringliteral">&quot;continuous&quot;</span> <span class="keywordflow">if</span> n_outputs == 1 <span class="keywordflow">else</span> <span class="stringliteral">&quot;continuous-multioutput&quot;</span></div>
<div class="line"><span class="lineno">  137</span> </div>
<div class="line"><span class="lineno">  138</span>    <span class="keywordflow">return</span> y_type, y_true, y_pred, multioutput</div>
<div class="line"><span class="lineno">  139</span> </div>
<div class="line"><span class="lineno">  140</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a04b1ea8f3154a641738e0cfe021622df" name="a04b1ea8f3154a641738e0cfe021622df"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a04b1ea8f3154a641738e0cfe021622df">&#9670;&#160;</a></span>_mean_tweedie_deviance()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression._mean_tweedie_deviance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>power</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Mean Tweedie deviance regression loss.</pre> <div class="fragment"><div class="line"><span class="lineno">  974</span><span class="keyword">def </span>_mean_tweedie_deviance(y_true, y_pred, sample_weight, power):</div>
<div class="line"><span class="lineno">  975</span>    <span class="stringliteral">&quot;&quot;&quot;Mean Tweedie deviance regression loss.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  976</span>    p = power</div>
<div class="line"><span class="lineno">  977</span>    <span class="keywordflow">if</span> p &lt; 0:</div>
<div class="line"><span class="lineno">  978</span>        <span class="comment"># &#39;Extreme stable&#39;, y any real number, y_pred &gt; 0</span></div>
<div class="line"><span class="lineno">  979</span>        dev = 2 * (</div>
<div class="line"><span class="lineno">  980</span>            np.power(np.maximum(y_true, 0), 2 - p) / ((1 - p) * (2 - p))</div>
<div class="line"><span class="lineno">  981</span>            - y_true * np.power(y_pred, 1 - p) / (1 - p)</div>
<div class="line"><span class="lineno">  982</span>            + np.power(y_pred, 2 - p) / (2 - p)</div>
<div class="line"><span class="lineno">  983</span>        )</div>
<div class="line"><span class="lineno">  984</span>    <span class="keywordflow">elif</span> p == 0:</div>
<div class="line"><span class="lineno">  985</span>        <span class="comment"># Normal distribution, y and y_pred any real number</span></div>
<div class="line"><span class="lineno">  986</span>        dev = (y_true - y_pred) ** 2</div>
<div class="line"><span class="lineno">  987</span>    <span class="keywordflow">elif</span> p == 1:</div>
<div class="line"><span class="lineno">  988</span>        <span class="comment"># Poisson distribution</span></div>
<div class="line"><span class="lineno">  989</span>        dev = 2 * (xlogy(y_true, y_true / y_pred) - y_true + y_pred)</div>
<div class="line"><span class="lineno">  990</span>    <span class="keywordflow">elif</span> p == 2:</div>
<div class="line"><span class="lineno">  991</span>        <span class="comment"># Gamma distribution</span></div>
<div class="line"><span class="lineno">  992</span>        dev = 2 * (np.log(y_pred / y_true) + y_true / y_pred - 1)</div>
<div class="line"><span class="lineno">  993</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  994</span>        dev = 2 * (</div>
<div class="line"><span class="lineno">  995</span>            np.power(y_true, 2 - p) / ((1 - p) * (2 - p))</div>
<div class="line"><span class="lineno">  996</span>            - y_true * np.power(y_pred, 1 - p) / (1 - p)</div>
<div class="line"><span class="lineno">  997</span>            + np.power(y_pred, 2 - p) / (2 - p)</div>
<div class="line"><span class="lineno">  998</span>        )</div>
<div class="line"><span class="lineno">  999</span> </div>
<div class="line"><span class="lineno"> 1000</span>    <span class="keywordflow">return</span> np.average(dev, weights=sample_weight)</div>
<div class="line"><span class="lineno"> 1001</span> </div>
<div class="line"><span class="lineno"> 1002</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1902af78bdbf846320c8f58e89151e8f" name="a1902af78bdbf846320c8f58e89151e8f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1902af78bdbf846320c8f58e89151e8f">&#9670;&#160;</a></span>d2_absolute_error_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.d2_absolute_error_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em> = <code>&quot;uniform_average&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">:math:`D^2` regression score function, \
fraction of absolute error explained.

Best possible score is 1.0 and it can be negative (because the model can be
arbitrarily worse). A model that always uses the empirical median of `y_true`
as constant prediction, disregarding the input features,
gets a :math:`D^2` score of 0.0.

Read more in the :ref:`User Guide &lt;d2_score&gt;`.

.. versionadded:: 1.1

Parameters
----------
y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), optional
    Sample weights.

multioutput : {'raw_values', 'uniform_average'} or array-like of shape \
        (n_outputs,), default='uniform_average'
    Defines aggregating of multiple output values.
    Array-like value defines weights used to average scores.

    'raw_values' :
        Returns a full set of errors in case of multioutput input.

    'uniform_average' :
        Scores of all outputs are averaged with uniform weight.

Returns
-------
score : float or ndarray of floats
    The :math:`D^2` score with an absolute error deviance
    or ndarray of scores if 'multioutput' is 'raw_values'.

Notes
-----
Like :math:`R^2`, :math:`D^2` score may be negative
(it need not actually be the square of a quantity D).

This metric is not well-defined for single samples and will return a NaN
value if n_samples is less than two.

 References
----------
.. [1] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.
       Wainwright. "Statistical Learning with Sparsity: The Lasso and
       Generalizations." (2015). https://hastie.su.domains/StatLearnSparsity/

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import d2_absolute_error_score
&gt;&gt;&gt; y_true = [3, -0.5, 2, 7]
&gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]
&gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred)
0.764...
&gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]
&gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]
&gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred, multioutput='uniform_average')
0.691...
&gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred, multioutput='raw_values')
array([0.8125    , 0.57142857])
&gt;&gt;&gt; y_true = [1, 2, 3]
&gt;&gt;&gt; y_pred = [1, 2, 3]
&gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred)
1.0
&gt;&gt;&gt; y_true = [1, 2, 3]
&gt;&gt;&gt; y_pred = [2, 2, 2]
&gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred)
0.0
&gt;&gt;&gt; y_true = [1, 2, 3]
&gt;&gt;&gt; y_pred = [3, 2, 1]
&gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred)
-1.0
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1413</span>):</div>
<div class="line"><span class="lineno"> 1414</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1415</span><span class="stringliteral">    :math:`D^2` regression score function, \</span></div>
<div class="line"><span class="lineno"> 1416</span><span class="stringliteral">    fraction of absolute error explained.</span></div>
<div class="line"><span class="lineno"> 1417</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1418</span><span class="stringliteral">    Best possible score is 1.0 and it can be negative (because the model can be</span></div>
<div class="line"><span class="lineno"> 1419</span><span class="stringliteral">    arbitrarily worse). A model that always uses the empirical median of `y_true`</span></div>
<div class="line"><span class="lineno"> 1420</span><span class="stringliteral">    as constant prediction, disregarding the input features,</span></div>
<div class="line"><span class="lineno"> 1421</span><span class="stringliteral">    gets a :math:`D^2` score of 0.0.</span></div>
<div class="line"><span class="lineno"> 1422</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1423</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;d2_score&gt;`.</span></div>
<div class="line"><span class="lineno"> 1424</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1425</span><span class="stringliteral">    .. versionadded:: 1.1</span></div>
<div class="line"><span class="lineno"> 1426</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1427</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1428</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1429</span><span class="stringliteral">    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno"> 1430</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 1431</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1432</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno"> 1433</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno"> 1434</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1435</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), optional</span></div>
<div class="line"><span class="lineno"> 1436</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1437</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1438</span><span class="stringliteral">    multioutput : {&#39;raw_values&#39;, &#39;uniform_average&#39;} or array-like of shape \</span></div>
<div class="line"><span class="lineno"> 1439</span><span class="stringliteral">            (n_outputs,), default=&#39;uniform_average&#39;</span></div>
<div class="line"><span class="lineno"> 1440</span><span class="stringliteral">        Defines aggregating of multiple output values.</span></div>
<div class="line"><span class="lineno"> 1441</span><span class="stringliteral">        Array-like value defines weights used to average scores.</span></div>
<div class="line"><span class="lineno"> 1442</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1443</span><span class="stringliteral">        &#39;raw_values&#39; :</span></div>
<div class="line"><span class="lineno"> 1444</span><span class="stringliteral">            Returns a full set of errors in case of multioutput input.</span></div>
<div class="line"><span class="lineno"> 1445</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1446</span><span class="stringliteral">        &#39;uniform_average&#39; :</span></div>
<div class="line"><span class="lineno"> 1447</span><span class="stringliteral">            Scores of all outputs are averaged with uniform weight.</span></div>
<div class="line"><span class="lineno"> 1448</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1449</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1450</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1451</span><span class="stringliteral">    score : float or ndarray of floats</span></div>
<div class="line"><span class="lineno"> 1452</span><span class="stringliteral">        The :math:`D^2` score with an absolute error deviance</span></div>
<div class="line"><span class="lineno"> 1453</span><span class="stringliteral">        or ndarray of scores if &#39;multioutput&#39; is &#39;raw_values&#39;.</span></div>
<div class="line"><span class="lineno"> 1454</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1455</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1456</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1457</span><span class="stringliteral">    Like :math:`R^2`, :math:`D^2` score may be negative</span></div>
<div class="line"><span class="lineno"> 1458</span><span class="stringliteral">    (it need not actually be the square of a quantity D).</span></div>
<div class="line"><span class="lineno"> 1459</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1460</span><span class="stringliteral">    This metric is not well-defined for single samples and will return a NaN</span></div>
<div class="line"><span class="lineno"> 1461</span><span class="stringliteral">    value if n_samples is less than two.</span></div>
<div class="line"><span class="lineno"> 1462</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1463</span><span class="stringliteral">     References</span></div>
<div class="line"><span class="lineno"> 1464</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1465</span><span class="stringliteral">    .. [1] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.</span></div>
<div class="line"><span class="lineno"> 1466</span><span class="stringliteral">           Wainwright. &quot;Statistical Learning with Sparsity: The Lasso and</span></div>
<div class="line"><span class="lineno"> 1467</span><span class="stringliteral">           Generalizations.&quot; (2015). https://hastie.su.domains/StatLearnSparsity/</span></div>
<div class="line"><span class="lineno"> 1468</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1469</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1470</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1471</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import d2_absolute_error_score</span></div>
<div class="line"><span class="lineno"> 1472</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [3, -0.5, 2, 7]</span></div>
<div class="line"><span class="lineno"> 1473</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]</span></div>
<div class="line"><span class="lineno"> 1474</span><span class="stringliteral">    &gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 1475</span><span class="stringliteral">    0.764...</span></div>
<div class="line"><span class="lineno"> 1476</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]</span></div>
<div class="line"><span class="lineno"> 1477</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]</span></div>
<div class="line"><span class="lineno"> 1478</span><span class="stringliteral">    &gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred, multioutput=&#39;uniform_average&#39;)</span></div>
<div class="line"><span class="lineno"> 1479</span><span class="stringliteral">    0.691...</span></div>
<div class="line"><span class="lineno"> 1480</span><span class="stringliteral">    &gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred, multioutput=&#39;raw_values&#39;)</span></div>
<div class="line"><span class="lineno"> 1481</span><span class="stringliteral">    array([0.8125    , 0.57142857])</span></div>
<div class="line"><span class="lineno"> 1482</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [1, 2, 3]</span></div>
<div class="line"><span class="lineno"> 1483</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [1, 2, 3]</span></div>
<div class="line"><span class="lineno"> 1484</span><span class="stringliteral">    &gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 1485</span><span class="stringliteral">    1.0</span></div>
<div class="line"><span class="lineno"> 1486</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [1, 2, 3]</span></div>
<div class="line"><span class="lineno"> 1487</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2, 2, 2]</span></div>
<div class="line"><span class="lineno"> 1488</span><span class="stringliteral">    &gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 1489</span><span class="stringliteral">    0.0</span></div>
<div class="line"><span class="lineno"> 1490</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [1, 2, 3]</span></div>
<div class="line"><span class="lineno"> 1491</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [3, 2, 1]</span></div>
<div class="line"><span class="lineno"> 1492</span><span class="stringliteral">    &gt;&gt;&gt; d2_absolute_error_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 1493</span><span class="stringliteral">    -1.0</span></div>
<div class="line"><span class="lineno"> 1494</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1495</span>    <span class="keywordflow">return</span> d2_pinball_score(</div>
<div class="line"><span class="lineno"> 1496</span>        y_true, y_pred, sample_weight=sample_weight, alpha=0.5, multioutput=multioutput</div>
<div class="line"><span class="lineno"> 1497</span>    )</div>
</div><!-- fragment -->
</div>
</div>
<a id="a0bd2df6b40b70224d2dd36734cfdeba4" name="a0bd2df6b40b70224d2dd36734cfdeba4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0bd2df6b40b70224d2dd36734cfdeba4">&#9670;&#160;</a></span>d2_pinball_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.d2_pinball_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em> = <code>&quot;uniform_average&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">:math:`D^2` regression score function, fraction of pinball loss explained.

Best possible score is 1.0 and it can be negative (because the model can be
arbitrarily worse). A model that always uses the empirical alpha-quantile of
`y_true` as constant prediction, disregarding the input features,
gets a :math:`D^2` score of 0.0.

Read more in the :ref:`User Guide &lt;d2_score&gt;`.

.. versionadded:: 1.1

Parameters
----------
y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), optional
    Sample weights.

alpha : float, default=0.5
    Slope of the pinball deviance. It determines the quantile level alpha
    for which the pinball deviance and also D2 are optimal.
    The default `alpha=0.5` is equivalent to `d2_absolute_error_score`.

multioutput : {'raw_values', 'uniform_average'} or array-like of shape \
        (n_outputs,), default='uniform_average'
    Defines aggregating of multiple output values.
    Array-like value defines weights used to average scores.

    'raw_values' :
        Returns a full set of errors in case of multioutput input.

    'uniform_average' :
        Scores of all outputs are averaged with uniform weight.

Returns
-------
score : float or ndarray of floats
    The :math:`D^2` score with a pinball deviance
    or ndarray of scores if `multioutput='raw_values'`.

Notes
-----
Like :math:`R^2`, :math:`D^2` score may be negative
(it need not actually be the square of a quantity D).

This metric is not well-defined for a single point and will return a NaN
value if n_samples is less than two.

 References
----------
.. [1] Eq. (7) of `Koenker, Roger; Machado, José A. F. (1999).
       "Goodness of Fit and Related Inference Processes for Quantile Regression"
       &lt;http://dx.doi.org/10.1080/01621459.1999.10473882&gt;`_
.. [2] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.
       Wainwright. "Statistical Learning with Sparsity: The Lasso and
       Generalizations." (2015). https://hastie.su.domains/StatLearnSparsity/

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import d2_pinball_score
&gt;&gt;&gt; y_true = [1, 2, 3]
&gt;&gt;&gt; y_pred = [1, 3, 3]
&gt;&gt;&gt; d2_pinball_score(y_true, y_pred)
0.5
&gt;&gt;&gt; d2_pinball_score(y_true, y_pred, alpha=0.9)
0.772...
&gt;&gt;&gt; d2_pinball_score(y_true, y_pred, alpha=0.1)
-1.045...
&gt;&gt;&gt; d2_pinball_score(y_true, y_true, alpha=0.1)
1.0
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1268</span>):</div>
<div class="line"><span class="lineno"> 1269</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1270</span><span class="stringliteral">    :math:`D^2` regression score function, fraction of pinball loss explained.</span></div>
<div class="line"><span class="lineno"> 1271</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1272</span><span class="stringliteral">    Best possible score is 1.0 and it can be negative (because the model can be</span></div>
<div class="line"><span class="lineno"> 1273</span><span class="stringliteral">    arbitrarily worse). A model that always uses the empirical alpha-quantile of</span></div>
<div class="line"><span class="lineno"> 1274</span><span class="stringliteral">    `y_true` as constant prediction, disregarding the input features,</span></div>
<div class="line"><span class="lineno"> 1275</span><span class="stringliteral">    gets a :math:`D^2` score of 0.0.</span></div>
<div class="line"><span class="lineno"> 1276</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1277</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;d2_score&gt;`.</span></div>
<div class="line"><span class="lineno"> 1278</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1279</span><span class="stringliteral">    .. versionadded:: 1.1</span></div>
<div class="line"><span class="lineno"> 1280</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1281</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1282</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1283</span><span class="stringliteral">    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno"> 1284</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 1285</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1286</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno"> 1287</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno"> 1288</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1289</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), optional</span></div>
<div class="line"><span class="lineno"> 1290</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1291</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1292</span><span class="stringliteral">    alpha : float, default=0.5</span></div>
<div class="line"><span class="lineno"> 1293</span><span class="stringliteral">        Slope of the pinball deviance. It determines the quantile level alpha</span></div>
<div class="line"><span class="lineno"> 1294</span><span class="stringliteral">        for which the pinball deviance and also D2 are optimal.</span></div>
<div class="line"><span class="lineno"> 1295</span><span class="stringliteral">        The default `alpha=0.5` is equivalent to `d2_absolute_error_score`.</span></div>
<div class="line"><span class="lineno"> 1296</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1297</span><span class="stringliteral">    multioutput : {&#39;raw_values&#39;, &#39;uniform_average&#39;} or array-like of shape \</span></div>
<div class="line"><span class="lineno"> 1298</span><span class="stringliteral">            (n_outputs,), default=&#39;uniform_average&#39;</span></div>
<div class="line"><span class="lineno"> 1299</span><span class="stringliteral">        Defines aggregating of multiple output values.</span></div>
<div class="line"><span class="lineno"> 1300</span><span class="stringliteral">        Array-like value defines weights used to average scores.</span></div>
<div class="line"><span class="lineno"> 1301</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1302</span><span class="stringliteral">        &#39;raw_values&#39; :</span></div>
<div class="line"><span class="lineno"> 1303</span><span class="stringliteral">            Returns a full set of errors in case of multioutput input.</span></div>
<div class="line"><span class="lineno"> 1304</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1305</span><span class="stringliteral">        &#39;uniform_average&#39; :</span></div>
<div class="line"><span class="lineno"> 1306</span><span class="stringliteral">            Scores of all outputs are averaged with uniform weight.</span></div>
<div class="line"><span class="lineno"> 1307</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1308</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1309</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1310</span><span class="stringliteral">    score : float or ndarray of floats</span></div>
<div class="line"><span class="lineno"> 1311</span><span class="stringliteral">        The :math:`D^2` score with a pinball deviance</span></div>
<div class="line"><span class="lineno"> 1312</span><span class="stringliteral">        or ndarray of scores if `multioutput=&#39;raw_values&#39;`.</span></div>
<div class="line"><span class="lineno"> 1313</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1314</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1315</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1316</span><span class="stringliteral">    Like :math:`R^2`, :math:`D^2` score may be negative</span></div>
<div class="line"><span class="lineno"> 1317</span><span class="stringliteral">    (it need not actually be the square of a quantity D).</span></div>
<div class="line"><span class="lineno"> 1318</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1319</span><span class="stringliteral">    This metric is not well-defined for a single point and will return a NaN</span></div>
<div class="line"><span class="lineno"> 1320</span><span class="stringliteral">    value if n_samples is less than two.</span></div>
<div class="line"><span class="lineno"> 1321</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1322</span><span class="stringliteral">     References</span></div>
<div class="line"><span class="lineno"> 1323</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1324</span><span class="stringliteral">    .. [1] Eq. (7) of `Koenker, Roger; Machado, José A. F. (1999).</span></div>
<div class="line"><span class="lineno"> 1325</span><span class="stringliteral">           &quot;Goodness of Fit and Related Inference Processes for Quantile Regression&quot;</span></div>
<div class="line"><span class="lineno"> 1326</span><span class="stringliteral">           &lt;http://dx.doi.org/10.1080/01621459.1999.10473882&gt;`_</span></div>
<div class="line"><span class="lineno"> 1327</span><span class="stringliteral">    .. [2] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.</span></div>
<div class="line"><span class="lineno"> 1328</span><span class="stringliteral">           Wainwright. &quot;Statistical Learning with Sparsity: The Lasso and</span></div>
<div class="line"><span class="lineno"> 1329</span><span class="stringliteral">           Generalizations.&quot; (2015). https://hastie.su.domains/StatLearnSparsity/</span></div>
<div class="line"><span class="lineno"> 1330</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1331</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1332</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1333</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import d2_pinball_score</span></div>
<div class="line"><span class="lineno"> 1334</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [1, 2, 3]</span></div>
<div class="line"><span class="lineno"> 1335</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [1, 3, 3]</span></div>
<div class="line"><span class="lineno"> 1336</span><span class="stringliteral">    &gt;&gt;&gt; d2_pinball_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 1337</span><span class="stringliteral">    0.5</span></div>
<div class="line"><span class="lineno"> 1338</span><span class="stringliteral">    &gt;&gt;&gt; d2_pinball_score(y_true, y_pred, alpha=0.9)</span></div>
<div class="line"><span class="lineno"> 1339</span><span class="stringliteral">    0.772...</span></div>
<div class="line"><span class="lineno"> 1340</span><span class="stringliteral">    &gt;&gt;&gt; d2_pinball_score(y_true, y_pred, alpha=0.1)</span></div>
<div class="line"><span class="lineno"> 1341</span><span class="stringliteral">    -1.045...</span></div>
<div class="line"><span class="lineno"> 1342</span><span class="stringliteral">    &gt;&gt;&gt; d2_pinball_score(y_true, y_true, alpha=0.1)</span></div>
<div class="line"><span class="lineno"> 1343</span><span class="stringliteral">    1.0</span></div>
<div class="line"><span class="lineno"> 1344</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1345</span>    y_type, y_true, y_pred, multioutput = _check_reg_targets(</div>
<div class="line"><span class="lineno"> 1346</span>        y_true, y_pred, multioutput</div>
<div class="line"><span class="lineno"> 1347</span>    )</div>
<div class="line"><span class="lineno"> 1348</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno"> 1349</span> </div>
<div class="line"><span class="lineno"> 1350</span>    <span class="keywordflow">if</span> _num_samples(y_pred) &lt; 2:</div>
<div class="line"><span class="lineno"> 1351</span>        msg = <span class="stringliteral">&quot;D^2 score is not well-defined with less than two samples.&quot;</span></div>
<div class="line"><span class="lineno"> 1352</span>        warnings.warn(msg, UndefinedMetricWarning)</div>
<div class="line"><span class="lineno"> 1353</span>        <span class="keywordflow">return</span> float(<span class="stringliteral">&quot;nan&quot;</span>)</div>
<div class="line"><span class="lineno"> 1354</span> </div>
<div class="line"><span class="lineno"> 1355</span>    numerator = mean_pinball_loss(</div>
<div class="line"><span class="lineno"> 1356</span>        y_true,</div>
<div class="line"><span class="lineno"> 1357</span>        y_pred,</div>
<div class="line"><span class="lineno"> 1358</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno"> 1359</span>        alpha=alpha,</div>
<div class="line"><span class="lineno"> 1360</span>        multioutput=<span class="stringliteral">&quot;raw_values&quot;</span>,</div>
<div class="line"><span class="lineno"> 1361</span>    )</div>
<div class="line"><span class="lineno"> 1362</span> </div>
<div class="line"><span class="lineno"> 1363</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1364</span>        y_quantile = np.tile(</div>
<div class="line"><span class="lineno"> 1365</span>            np.percentile(y_true, q=alpha * 100, axis=0), (len(y_true), 1)</div>
<div class="line"><span class="lineno"> 1366</span>        )</div>
<div class="line"><span class="lineno"> 1367</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1368</span>        sample_weight = _check_sample_weight(sample_weight, y_true)</div>
<div class="line"><span class="lineno"> 1369</span>        y_quantile = np.tile(</div>
<div class="line"><span class="lineno"> 1370</span>            _weighted_percentile(</div>
<div class="line"><span class="lineno"> 1371</span>                y_true, sample_weight=sample_weight, percentile=alpha * 100</div>
<div class="line"><span class="lineno"> 1372</span>            ),</div>
<div class="line"><span class="lineno"> 1373</span>            (len(y_true), 1),</div>
<div class="line"><span class="lineno"> 1374</span>        )</div>
<div class="line"><span class="lineno"> 1375</span> </div>
<div class="line"><span class="lineno"> 1376</span>    denominator = mean_pinball_loss(</div>
<div class="line"><span class="lineno"> 1377</span>        y_true,</div>
<div class="line"><span class="lineno"> 1378</span>        y_quantile,</div>
<div class="line"><span class="lineno"> 1379</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno"> 1380</span>        alpha=alpha,</div>
<div class="line"><span class="lineno"> 1381</span>        multioutput=<span class="stringliteral">&quot;raw_values&quot;</span>,</div>
<div class="line"><span class="lineno"> 1382</span>    )</div>
<div class="line"><span class="lineno"> 1383</span> </div>
<div class="line"><span class="lineno"> 1384</span>    nonzero_numerator = numerator != 0</div>
<div class="line"><span class="lineno"> 1385</span>    nonzero_denominator = denominator != 0</div>
<div class="line"><span class="lineno"> 1386</span>    valid_score = nonzero_numerator &amp; nonzero_denominator</div>
<div class="line"><span class="lineno"> 1387</span>    output_scores = np.ones(y_true.shape[1])</div>
<div class="line"><span class="lineno"> 1388</span> </div>
<div class="line"><span class="lineno"> 1389</span>    output_scores[valid_score] = 1 - (numerator[valid_score] / denominator[valid_score])</div>
<div class="line"><span class="lineno"> 1390</span>    output_scores[nonzero_numerator &amp; ~nonzero_denominator] = 0.0</div>
<div class="line"><span class="lineno"> 1391</span> </div>
<div class="line"><span class="lineno"> 1392</span>    <span class="keywordflow">if</span> isinstance(multioutput, str):</div>
<div class="line"><span class="lineno"> 1393</span>        <span class="keywordflow">if</span> multioutput == <span class="stringliteral">&quot;raw_values&quot;</span>:</div>
<div class="line"><span class="lineno"> 1394</span>            <span class="comment"># return scores individually</span></div>
<div class="line"><span class="lineno"> 1395</span>            <span class="keywordflow">return</span> output_scores</div>
<div class="line"><span class="lineno"> 1396</span>        <span class="keywordflow">elif</span> multioutput == <span class="stringliteral">&quot;uniform_average&quot;</span>:</div>
<div class="line"><span class="lineno"> 1397</span>            <span class="comment"># passing None as weights to np.average results in uniform mean</span></div>
<div class="line"><span class="lineno"> 1398</span>            avg_weights = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1399</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1400</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1401</span>                <span class="stringliteral">&quot;multioutput is expected to be &#39;raw_values&#39; &quot;</span></div>
<div class="line"><span class="lineno"> 1402</span>                <span class="stringliteral">&quot;or &#39;uniform_average&#39; but we got %r&quot;</span></div>
<div class="line"><span class="lineno"> 1403</span>                <span class="stringliteral">&quot; instead.&quot;</span> % multioutput</div>
<div class="line"><span class="lineno"> 1404</span>            )</div>
<div class="line"><span class="lineno"> 1405</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1406</span>        avg_weights = multioutput</div>
<div class="line"><span class="lineno"> 1407</span> </div>
<div class="line"><span class="lineno"> 1408</span>    <span class="keywordflow">return</span> np.average(output_scores, weights=avg_weights)</div>
<div class="line"><span class="lineno"> 1409</span> </div>
<div class="line"><span class="lineno"> 1410</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abdde527ffcb35166f371a5ceb850a3eb" name="abdde527ffcb35166f371a5ceb850a3eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abdde527ffcb35166f371a5ceb850a3eb">&#9670;&#160;</a></span>d2_tweedie_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.d2_tweedie_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>power</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">D^2 regression score function, fraction of Tweedie deviance explained.

Best possible score is 1.0 and it can be negative (because the model can be
arbitrarily worse). A model that always uses the empirical mean of `y_true` as
constant prediction, disregarding the input features, gets a D^2 score of 0.0.

Read more in the :ref:`User Guide &lt;d2_score&gt;`.

.. versionadded:: 1.0

Parameters
----------
y_true : array-like of shape (n_samples,)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), optional
    Sample weights.

power : float, default=0
    Tweedie power parameter. Either power &lt;= 0 or power &gt;= 1.

    The higher `p` the less weight is given to extreme
    deviations between true and predicted targets.

    - power &lt; 0: Extreme stable distribution. Requires: y_pred &gt; 0.
    - power = 0 : Normal distribution, output corresponds to r2_score.
      y_true and y_pred can be any real numbers.
    - power = 1 : Poisson distribution. Requires: y_true &gt;= 0 and
      y_pred &gt; 0.
    - 1 &lt; p &lt; 2 : Compound Poisson distribution. Requires: y_true &gt;= 0
      and y_pred &gt; 0.
    - power = 2 : Gamma distribution. Requires: y_true &gt; 0 and y_pred &gt; 0.
    - power = 3 : Inverse Gaussian distribution. Requires: y_true &gt; 0
      and y_pred &gt; 0.
    - otherwise : Positive stable distribution. Requires: y_true &gt; 0
      and y_pred &gt; 0.

Returns
-------
z : float or ndarray of floats
    The D^2 score.

Notes
-----
This is not a symmetric function.

Like R^2, D^2 score may be negative (it need not actually be the square of
a quantity D).

This metric is not well-defined for single samples and will return a NaN
value if n_samples is less than two.

References
----------
.. [1] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.
       Wainwright. "Statistical Learning with Sparsity: The Lasso and
       Generalizations." (2015). https://hastie.su.domains/StatLearnSparsity/

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import d2_tweedie_score
&gt;&gt;&gt; y_true = [0.5, 1, 2.5, 7]
&gt;&gt;&gt; y_pred = [1, 1, 5, 3.5]
&gt;&gt;&gt; d2_tweedie_score(y_true, y_pred)
0.285...
&gt;&gt;&gt; d2_tweedie_score(y_true, y_pred, power=1)
0.487...
&gt;&gt;&gt; d2_tweedie_score(y_true, y_pred, power=2)
0.630...
&gt;&gt;&gt; d2_tweedie_score(y_true, y_true, power=2)
1.0
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1166</span><span class="keyword">def </span>d2_tweedie_score(y_true, y_pred, *, sample_weight=None, power=0):</div>
<div class="line"><span class="lineno"> 1167</span>    <span class="stringliteral">&quot;&quot;&quot;D^2 regression score function, fraction of Tweedie deviance explained.</span></div>
<div class="line"><span class="lineno"> 1168</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1169</span><span class="stringliteral">    Best possible score is 1.0 and it can be negative (because the model can be</span></div>
<div class="line"><span class="lineno"> 1170</span><span class="stringliteral">    arbitrarily worse). A model that always uses the empirical mean of `y_true` as</span></div>
<div class="line"><span class="lineno"> 1171</span><span class="stringliteral">    constant prediction, disregarding the input features, gets a D^2 score of 0.0.</span></div>
<div class="line"><span class="lineno"> 1172</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1173</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;d2_score&gt;`.</span></div>
<div class="line"><span class="lineno"> 1174</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1175</span><span class="stringliteral">    .. versionadded:: 1.0</span></div>
<div class="line"><span class="lineno"> 1176</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1177</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1178</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1179</span><span class="stringliteral">    y_true : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1180</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 1181</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1182</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1183</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno"> 1184</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1185</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), optional</span></div>
<div class="line"><span class="lineno"> 1186</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1187</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1188</span><span class="stringliteral">    power : float, default=0</span></div>
<div class="line"><span class="lineno"> 1189</span><span class="stringliteral">        Tweedie power parameter. Either power &lt;= 0 or power &gt;= 1.</span></div>
<div class="line"><span class="lineno"> 1190</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1191</span><span class="stringliteral">        The higher `p` the less weight is given to extreme</span></div>
<div class="line"><span class="lineno"> 1192</span><span class="stringliteral">        deviations between true and predicted targets.</span></div>
<div class="line"><span class="lineno"> 1193</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1194</span><span class="stringliteral">        - power &lt; 0: Extreme stable distribution. Requires: y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1195</span><span class="stringliteral">        - power = 0 : Normal distribution, output corresponds to r2_score.</span></div>
<div class="line"><span class="lineno"> 1196</span><span class="stringliteral">          y_true and y_pred can be any real numbers.</span></div>
<div class="line"><span class="lineno"> 1197</span><span class="stringliteral">        - power = 1 : Poisson distribution. Requires: y_true &gt;= 0 and</span></div>
<div class="line"><span class="lineno"> 1198</span><span class="stringliteral">          y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1199</span><span class="stringliteral">        - 1 &lt; p &lt; 2 : Compound Poisson distribution. Requires: y_true &gt;= 0</span></div>
<div class="line"><span class="lineno"> 1200</span><span class="stringliteral">          and y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1201</span><span class="stringliteral">        - power = 2 : Gamma distribution. Requires: y_true &gt; 0 and y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1202</span><span class="stringliteral">        - power = 3 : Inverse Gaussian distribution. Requires: y_true &gt; 0</span></div>
<div class="line"><span class="lineno"> 1203</span><span class="stringliteral">          and y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1204</span><span class="stringliteral">        - otherwise : Positive stable distribution. Requires: y_true &gt; 0</span></div>
<div class="line"><span class="lineno"> 1205</span><span class="stringliteral">          and y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1206</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1207</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1208</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1209</span><span class="stringliteral">    z : float or ndarray of floats</span></div>
<div class="line"><span class="lineno"> 1210</span><span class="stringliteral">        The D^2 score.</span></div>
<div class="line"><span class="lineno"> 1211</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1212</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1213</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1214</span><span class="stringliteral">    This is not a symmetric function.</span></div>
<div class="line"><span class="lineno"> 1215</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1216</span><span class="stringliteral">    Like R^2, D^2 score may be negative (it need not actually be the square of</span></div>
<div class="line"><span class="lineno"> 1217</span><span class="stringliteral">    a quantity D).</span></div>
<div class="line"><span class="lineno"> 1218</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1219</span><span class="stringliteral">    This metric is not well-defined for single samples and will return a NaN</span></div>
<div class="line"><span class="lineno"> 1220</span><span class="stringliteral">    value if n_samples is less than two.</span></div>
<div class="line"><span class="lineno"> 1221</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1222</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1223</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1224</span><span class="stringliteral">    .. [1] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.</span></div>
<div class="line"><span class="lineno"> 1225</span><span class="stringliteral">           Wainwright. &quot;Statistical Learning with Sparsity: The Lasso and</span></div>
<div class="line"><span class="lineno"> 1226</span><span class="stringliteral">           Generalizations.&quot; (2015). https://hastie.su.domains/StatLearnSparsity/</span></div>
<div class="line"><span class="lineno"> 1227</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1228</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1229</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1230</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import d2_tweedie_score</span></div>
<div class="line"><span class="lineno"> 1231</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0.5, 1, 2.5, 7]</span></div>
<div class="line"><span class="lineno"> 1232</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [1, 1, 5, 3.5]</span></div>
<div class="line"><span class="lineno"> 1233</span><span class="stringliteral">    &gt;&gt;&gt; d2_tweedie_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 1234</span><span class="stringliteral">    0.285...</span></div>
<div class="line"><span class="lineno"> 1235</span><span class="stringliteral">    &gt;&gt;&gt; d2_tweedie_score(y_true, y_pred, power=1)</span></div>
<div class="line"><span class="lineno"> 1236</span><span class="stringliteral">    0.487...</span></div>
<div class="line"><span class="lineno"> 1237</span><span class="stringliteral">    &gt;&gt;&gt; d2_tweedie_score(y_true, y_pred, power=2)</span></div>
<div class="line"><span class="lineno"> 1238</span><span class="stringliteral">    0.630...</span></div>
<div class="line"><span class="lineno"> 1239</span><span class="stringliteral">    &gt;&gt;&gt; d2_tweedie_score(y_true, y_true, power=2)</span></div>
<div class="line"><span class="lineno"> 1240</span><span class="stringliteral">    1.0</span></div>
<div class="line"><span class="lineno"> 1241</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1242</span>    y_type, y_true, y_pred, _ = _check_reg_targets(</div>
<div class="line"><span class="lineno"> 1243</span>        y_true, y_pred, <span class="keywordtype">None</span>, dtype=[np.float64, np.float32]</div>
<div class="line"><span class="lineno"> 1244</span>    )</div>
<div class="line"><span class="lineno"> 1245</span>    <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;continuous-multioutput&quot;</span>:</div>
<div class="line"><span class="lineno"> 1246</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Multioutput not supported in d2_tweedie_score&quot;</span>)</div>
<div class="line"><span class="lineno"> 1247</span> </div>
<div class="line"><span class="lineno"> 1248</span>    <span class="keywordflow">if</span> _num_samples(y_pred) &lt; 2:</div>
<div class="line"><span class="lineno"> 1249</span>        msg = <span class="stringliteral">&quot;D^2 score is not well-defined with less than two samples.&quot;</span></div>
<div class="line"><span class="lineno"> 1250</span>        warnings.warn(msg, UndefinedMetricWarning)</div>
<div class="line"><span class="lineno"> 1251</span>        <span class="keywordflow">return</span> float(<span class="stringliteral">&quot;nan&quot;</span>)</div>
<div class="line"><span class="lineno"> 1252</span> </div>
<div class="line"><span class="lineno"> 1253</span>    y_true, y_pred = np.squeeze(y_true), np.squeeze(y_pred)</div>
<div class="line"><span class="lineno"> 1254</span>    numerator = mean_tweedie_deviance(</div>
<div class="line"><span class="lineno"> 1255</span>        y_true, y_pred, sample_weight=sample_weight, power=power</div>
<div class="line"><span class="lineno"> 1256</span>    )</div>
<div class="line"><span class="lineno"> 1257</span> </div>
<div class="line"><span class="lineno"> 1258</span>    y_avg = np.average(y_true, weights=sample_weight)</div>
<div class="line"><span class="lineno"> 1259</span>    denominator = _mean_tweedie_deviance(</div>
<div class="line"><span class="lineno"> 1260</span>        y_true, y_avg, sample_weight=sample_weight, power=power</div>
<div class="line"><span class="lineno"> 1261</span>    )</div>
<div class="line"><span class="lineno"> 1262</span> </div>
<div class="line"><span class="lineno"> 1263</span>    <span class="keywordflow">return</span> 1 - numerator / denominator</div>
<div class="line"><span class="lineno"> 1264</span> </div>
<div class="line"><span class="lineno"> 1265</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abe2e1ed196a96739ce70ef7a20db9372" name="abe2e1ed196a96739ce70ef7a20db9372"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe2e1ed196a96739ce70ef7a20db9372">&#9670;&#160;</a></span>explained_variance_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.explained_variance_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em> = <code>&quot;uniform_average&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>force_finite</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Explained variance regression score function.

Best possible score is 1.0, lower values are worse.

In the particular case when ``y_true`` is constant, the explained variance
score is not finite: it is either ``NaN`` (perfect predictions) or
``-Inf`` (imperfect predictions). To prevent such non-finite numbers to
pollute higher-level experiments such as a grid search cross-validation,
by default these cases are replaced with 1.0 (perfect predictions) or 0.0
(imperfect predictions) respectively. If ``force_finite``
is set to ``False``, this score falls back on the original :math:`R^2`
definition.

.. note::
   The Explained Variance score is similar to the
   :func:`R^2 score &lt;r2_score&gt;`, with the notable difference that it
   does not account for systematic offsets in the prediction. Most often
   the :func:`R^2 score &lt;r2_score&gt;` should be preferred.

Read more in the :ref:`User Guide &lt;explained_variance_score&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

multioutput : {'raw_values', 'uniform_average', 'variance_weighted'} or \
        array-like of shape (n_outputs,), default='uniform_average'
    Defines aggregating of multiple output scores.
    Array-like value defines weights used to average scores.

    'raw_values' :
        Returns a full set of scores in case of multioutput input.

    'uniform_average' :
        Scores of all outputs are averaged with uniform weight.

    'variance_weighted' :
        Scores of all outputs are averaged, weighted by the variances
        of each individual output.

force_finite : bool, default=True
    Flag indicating if ``NaN`` and ``-Inf`` scores resulting from constant
    data should be replaced with real numbers (``1.0`` if prediction is
    perfect, ``0.0`` otherwise). Default is ``True``, a convenient setting
    for hyperparameters' search procedures (e.g. grid search
    cross-validation).

    .. versionadded:: 1.1

Returns
-------
score : float or ndarray of floats
    The explained variance or ndarray if 'multioutput' is 'raw_values'.

See Also
--------
r2_score :
    Similar metric, but accounting for systematic offsets in
    prediction.

Notes
-----
This is not a symmetric function.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import explained_variance_score
&gt;&gt;&gt; y_true = [3, -0.5, 2, 7]
&gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]
&gt;&gt;&gt; explained_variance_score(y_true, y_pred)
0.957...
&gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]
&gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]
&gt;&gt;&gt; explained_variance_score(y_true, y_pred, multioutput='uniform_average')
0.983...
&gt;&gt;&gt; y_true = [-2, -2, -2]
&gt;&gt;&gt; y_pred = [-2, -2, -2]
&gt;&gt;&gt; explained_variance_score(y_true, y_pred)
1.0
&gt;&gt;&gt; explained_variance_score(y_true, y_pred, force_finite=False)
nan
&gt;&gt;&gt; y_true = [-2, -2, -2]
&gt;&gt;&gt; y_pred = [-2, -2, -2 + 1e-8]
&gt;&gt;&gt; explained_variance_score(y_true, y_pred)
0.0
&gt;&gt;&gt; explained_variance_score(y_true, y_pred, force_finite=False)
-inf
</pre> <div class="fragment"><div class="line"><span class="lineno">  666</span>):</div>
<div class="line"><span class="lineno">  667</span>    <span class="stringliteral">&quot;&quot;&quot;Explained variance regression score function.</span></div>
<div class="line"><span class="lineno">  668</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  669</span><span class="stringliteral">    Best possible score is 1.0, lower values are worse.</span></div>
<div class="line"><span class="lineno">  670</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  671</span><span class="stringliteral">    In the particular case when ``y_true`` is constant, the explained variance</span></div>
<div class="line"><span class="lineno">  672</span><span class="stringliteral">    score is not finite: it is either ``NaN`` (perfect predictions) or</span></div>
<div class="line"><span class="lineno">  673</span><span class="stringliteral">    ``-Inf`` (imperfect predictions). To prevent such non-finite numbers to</span></div>
<div class="line"><span class="lineno">  674</span><span class="stringliteral">    pollute higher-level experiments such as a grid search cross-validation,</span></div>
<div class="line"><span class="lineno">  675</span><span class="stringliteral">    by default these cases are replaced with 1.0 (perfect predictions) or 0.0</span></div>
<div class="line"><span class="lineno">  676</span><span class="stringliteral">    (imperfect predictions) respectively. If ``force_finite``</span></div>
<div class="line"><span class="lineno">  677</span><span class="stringliteral">    is set to ``False``, this score falls back on the original :math:`R^2`</span></div>
<div class="line"><span class="lineno">  678</span><span class="stringliteral">    definition.</span></div>
<div class="line"><span class="lineno">  679</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  680</span><span class="stringliteral">    .. note::</span></div>
<div class="line"><span class="lineno">  681</span><span class="stringliteral">       The Explained Variance score is similar to the</span></div>
<div class="line"><span class="lineno">  682</span><span class="stringliteral">       :func:`R^2 score &lt;r2_score&gt;`, with the notable difference that it</span></div>
<div class="line"><span class="lineno">  683</span><span class="stringliteral">       does not account for systematic offsets in the prediction. Most often</span></div>
<div class="line"><span class="lineno">  684</span><span class="stringliteral">       the :func:`R^2 score &lt;r2_score&gt;` should be preferred.</span></div>
<div class="line"><span class="lineno">  685</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  686</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;explained_variance_score&gt;`.</span></div>
<div class="line"><span class="lineno">  687</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  688</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  689</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  690</span><span class="stringliteral">    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  691</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  692</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  693</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  694</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno">  695</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  696</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  697</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  698</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  699</span><span class="stringliteral">    multioutput : {&#39;raw_values&#39;, &#39;uniform_average&#39;, &#39;variance_weighted&#39;} or \</span></div>
<div class="line"><span class="lineno">  700</span><span class="stringliteral">            array-like of shape (n_outputs,), default=&#39;uniform_average&#39;</span></div>
<div class="line"><span class="lineno">  701</span><span class="stringliteral">        Defines aggregating of multiple output scores.</span></div>
<div class="line"><span class="lineno">  702</span><span class="stringliteral">        Array-like value defines weights used to average scores.</span></div>
<div class="line"><span class="lineno">  703</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  704</span><span class="stringliteral">        &#39;raw_values&#39; :</span></div>
<div class="line"><span class="lineno">  705</span><span class="stringliteral">            Returns a full set of scores in case of multioutput input.</span></div>
<div class="line"><span class="lineno">  706</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  707</span><span class="stringliteral">        &#39;uniform_average&#39; :</span></div>
<div class="line"><span class="lineno">  708</span><span class="stringliteral">            Scores of all outputs are averaged with uniform weight.</span></div>
<div class="line"><span class="lineno">  709</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  710</span><span class="stringliteral">        &#39;variance_weighted&#39; :</span></div>
<div class="line"><span class="lineno">  711</span><span class="stringliteral">            Scores of all outputs are averaged, weighted by the variances</span></div>
<div class="line"><span class="lineno">  712</span><span class="stringliteral">            of each individual output.</span></div>
<div class="line"><span class="lineno">  713</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  714</span><span class="stringliteral">    force_finite : bool, default=True</span></div>
<div class="line"><span class="lineno">  715</span><span class="stringliteral">        Flag indicating if ``NaN`` and ``-Inf`` scores resulting from constant</span></div>
<div class="line"><span class="lineno">  716</span><span class="stringliteral">        data should be replaced with real numbers (``1.0`` if prediction is</span></div>
<div class="line"><span class="lineno">  717</span><span class="stringliteral">        perfect, ``0.0`` otherwise). Default is ``True``, a convenient setting</span></div>
<div class="line"><span class="lineno">  718</span><span class="stringliteral">        for hyperparameters&#39; search procedures (e.g. grid search</span></div>
<div class="line"><span class="lineno">  719</span><span class="stringliteral">        cross-validation).</span></div>
<div class="line"><span class="lineno">  720</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  721</span><span class="stringliteral">        .. versionadded:: 1.1</span></div>
<div class="line"><span class="lineno">  722</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  723</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  724</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  725</span><span class="stringliteral">    score : float or ndarray of floats</span></div>
<div class="line"><span class="lineno">  726</span><span class="stringliteral">        The explained variance or ndarray if &#39;multioutput&#39; is &#39;raw_values&#39;.</span></div>
<div class="line"><span class="lineno">  727</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  728</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  729</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  730</span><span class="stringliteral">    r2_score :</span></div>
<div class="line"><span class="lineno">  731</span><span class="stringliteral">        Similar metric, but accounting for systematic offsets in</span></div>
<div class="line"><span class="lineno">  732</span><span class="stringliteral">        prediction.</span></div>
<div class="line"><span class="lineno">  733</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  734</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  735</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  736</span><span class="stringliteral">    This is not a symmetric function.</span></div>
<div class="line"><span class="lineno">  737</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  738</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  739</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  740</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import explained_variance_score</span></div>
<div class="line"><span class="lineno">  741</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [3, -0.5, 2, 7]</span></div>
<div class="line"><span class="lineno">  742</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]</span></div>
<div class="line"><span class="lineno">  743</span><span class="stringliteral">    &gt;&gt;&gt; explained_variance_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  744</span><span class="stringliteral">    0.957...</span></div>
<div class="line"><span class="lineno">  745</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]</span></div>
<div class="line"><span class="lineno">  746</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]</span></div>
<div class="line"><span class="lineno">  747</span><span class="stringliteral">    &gt;&gt;&gt; explained_variance_score(y_true, y_pred, multioutput=&#39;uniform_average&#39;)</span></div>
<div class="line"><span class="lineno">  748</span><span class="stringliteral">    0.983...</span></div>
<div class="line"><span class="lineno">  749</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [-2, -2, -2]</span></div>
<div class="line"><span class="lineno">  750</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [-2, -2, -2]</span></div>
<div class="line"><span class="lineno">  751</span><span class="stringliteral">    &gt;&gt;&gt; explained_variance_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  752</span><span class="stringliteral">    1.0</span></div>
<div class="line"><span class="lineno">  753</span><span class="stringliteral">    &gt;&gt;&gt; explained_variance_score(y_true, y_pred, force_finite=False)</span></div>
<div class="line"><span class="lineno">  754</span><span class="stringliteral">    nan</span></div>
<div class="line"><span class="lineno">  755</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [-2, -2, -2]</span></div>
<div class="line"><span class="lineno">  756</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [-2, -2, -2 + 1e-8]</span></div>
<div class="line"><span class="lineno">  757</span><span class="stringliteral">    &gt;&gt;&gt; explained_variance_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  758</span><span class="stringliteral">    0.0</span></div>
<div class="line"><span class="lineno">  759</span><span class="stringliteral">    &gt;&gt;&gt; explained_variance_score(y_true, y_pred, force_finite=False)</span></div>
<div class="line"><span class="lineno">  760</span><span class="stringliteral">    -inf</span></div>
<div class="line"><span class="lineno">  761</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  762</span>    y_type, y_true, y_pred, multioutput = _check_reg_targets(</div>
<div class="line"><span class="lineno">  763</span>        y_true, y_pred, multioutput</div>
<div class="line"><span class="lineno">  764</span>    )</div>
<div class="line"><span class="lineno">  765</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  766</span> </div>
<div class="line"><span class="lineno">  767</span>    y_diff_avg = np.average(y_true - y_pred, weights=sample_weight, axis=0)</div>
<div class="line"><span class="lineno">  768</span>    numerator = np.average(</div>
<div class="line"><span class="lineno">  769</span>        (y_true - y_pred - y_diff_avg) ** 2, weights=sample_weight, axis=0</div>
<div class="line"><span class="lineno">  770</span>    )</div>
<div class="line"><span class="lineno">  771</span> </div>
<div class="line"><span class="lineno">  772</span>    y_true_avg = np.average(y_true, weights=sample_weight, axis=0)</div>
<div class="line"><span class="lineno">  773</span>    denominator = np.average((y_true - y_true_avg) ** 2, weights=sample_weight, axis=0)</div>
<div class="line"><span class="lineno">  774</span> </div>
<div class="line"><span class="lineno">  775</span>    <span class="keywordflow">return</span> _assemble_r2_explained_variance(</div>
<div class="line"><span class="lineno">  776</span>        numerator=numerator,</div>
<div class="line"><span class="lineno">  777</span>        denominator=denominator,</div>
<div class="line"><span class="lineno">  778</span>        n_outputs=y_true.shape[1],</div>
<div class="line"><span class="lineno">  779</span>        multioutput=multioutput,</div>
<div class="line"><span class="lineno">  780</span>        force_finite=force_finite,</div>
<div class="line"><span class="lineno">  781</span>    )</div>
<div class="line"><span class="lineno">  782</span> </div>
<div class="line"><span class="lineno">  783</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9193a97a2feef27a89742321e496da3b" name="a9193a97a2feef27a89742321e496da3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9193a97a2feef27a89742321e496da3b">&#9670;&#160;</a></span>max_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.max_error </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">The max_error metric calculates the maximum residual error.

Read more in the :ref:`User Guide &lt;max_error&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,)
    Estimated target values.

Returns
-------
max_error : float
    A positive floating point value (the best value is 0.0).

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import max_error
&gt;&gt;&gt; y_true = [3, 2, 7, 1]
&gt;&gt;&gt; y_pred = [4, 2, 7, 1]
&gt;&gt;&gt; max_error(y_true, y_pred)
1
</pre> <div class="fragment"><div class="line"><span class="lineno">  941</span><span class="keyword">def </span>max_error(y_true, y_pred):</div>
<div class="line"><span class="lineno">  942</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  943</span><span class="stringliteral">    The max_error metric calculates the maximum residual error.</span></div>
<div class="line"><span class="lineno">  944</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  945</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;max_error&gt;`.</span></div>
<div class="line"><span class="lineno">  946</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  947</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  948</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  949</span><span class="stringliteral">    y_true : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  950</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  951</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  952</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  953</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno">  954</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  955</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  956</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  957</span><span class="stringliteral">    max_error : float</span></div>
<div class="line"><span class="lineno">  958</span><span class="stringliteral">        A positive floating point value (the best value is 0.0).</span></div>
<div class="line"><span class="lineno">  959</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  960</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  961</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  962</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import max_error</span></div>
<div class="line"><span class="lineno">  963</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [3, 2, 7, 1]</span></div>
<div class="line"><span class="lineno">  964</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [4, 2, 7, 1]</span></div>
<div class="line"><span class="lineno">  965</span><span class="stringliteral">    &gt;&gt;&gt; max_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  966</span><span class="stringliteral">    1</span></div>
<div class="line"><span class="lineno">  967</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  968</span>    y_type, y_true, y_pred, _ = _check_reg_targets(y_true, y_pred, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  969</span>    <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;continuous-multioutput&quot;</span>:</div>
<div class="line"><span class="lineno">  970</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Multioutput not supported in max_error&quot;</span>)</div>
<div class="line"><span class="lineno">  971</span>    <span class="keywordflow">return</span> np.max(np.abs(y_true - y_pred))</div>
<div class="line"><span class="lineno">  972</span> </div>
<div class="line"><span class="lineno">  973</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a31dc70f5bfc4e47761f2c427e1601c27" name="a31dc70f5bfc4e47761f2c427e1601c27"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a31dc70f5bfc4e47761f2c427e1601c27">&#9670;&#160;</a></span>mean_absolute_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.mean_absolute_error </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em> = <code>&quot;uniform_average&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Mean absolute error regression loss.

Read more in the :ref:`User Guide &lt;mean_absolute_error&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

multioutput : {'raw_values', 'uniform_average'}  or array-like of shape \
        (n_outputs,), default='uniform_average'
    Defines aggregating of multiple output values.
    Array-like value defines weights used to average errors.

    'raw_values' :
        Returns a full set of errors in case of multioutput input.

    'uniform_average' :
        Errors of all outputs are averaged with uniform weight.

Returns
-------
loss : float or ndarray of floats
    If multioutput is 'raw_values', then mean absolute error is returned
    for each output separately.
    If multioutput is 'uniform_average' or an ndarray of weights, then the
    weighted average of all output errors is returned.

    MAE output is non-negative floating point. The best value is 0.0.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import mean_absolute_error
&gt;&gt;&gt; y_true = [3, -0.5, 2, 7]
&gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]
&gt;&gt;&gt; mean_absolute_error(y_true, y_pred)
0.5
&gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]
&gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]
&gt;&gt;&gt; mean_absolute_error(y_true, y_pred)
0.75
&gt;&gt;&gt; mean_absolute_error(y_true, y_pred, multioutput='raw_values')
array([0.5, 1. ])
&gt;&gt;&gt; mean_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])
0.85...
</pre> <div class="fragment"><div class="line"><span class="lineno">  143</span>):</div>
<div class="line"><span class="lineno">  144</span>    <span class="stringliteral">&quot;&quot;&quot;Mean absolute error regression loss.</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;mean_absolute_error&gt;`.</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">    multioutput : {&#39;raw_values&#39;, &#39;uniform_average&#39;}  or array-like of shape \</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">            (n_outputs,), default=&#39;uniform_average&#39;</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">        Defines aggregating of multiple output values.</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">        Array-like value defines weights used to average errors.</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        &#39;raw_values&#39; :</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">            Returns a full set of errors in case of multioutput input.</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">        &#39;uniform_average&#39; :</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">            Errors of all outputs are averaged with uniform weight.</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral">    loss : float or ndarray of floats</span></div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">        If multioutput is &#39;raw_values&#39;, then mean absolute error is returned</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">        for each output separately.</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">        If multioutput is &#39;uniform_average&#39; or an ndarray of weights, then the</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">        weighted average of all output errors is returned.</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral">        MAE output is non-negative floating point. The best value is 0.0.</span></div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import mean_absolute_error</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [3, -0.5, 2, 7]</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">    &gt;&gt;&gt; mean_absolute_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">    0.5</span></div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]</span></div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">    &gt;&gt;&gt; mean_absolute_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral">    0.75</span></div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral">    &gt;&gt;&gt; mean_absolute_error(y_true, y_pred, multioutput=&#39;raw_values&#39;)</span></div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">    array([0.5, 1. ])</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral">    &gt;&gt;&gt; mean_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])</span></div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">    0.85...</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  196</span>    y_type, y_true, y_pred, multioutput = _check_reg_targets(</div>
<div class="line"><span class="lineno">  197</span>        y_true, y_pred, multioutput</div>
<div class="line"><span class="lineno">  198</span>    )</div>
<div class="line"><span class="lineno">  199</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  200</span>    output_errors = np.average(np.abs(y_pred - y_true), weights=sample_weight, axis=0)</div>
<div class="line"><span class="lineno">  201</span>    <span class="keywordflow">if</span> isinstance(multioutput, str):</div>
<div class="line"><span class="lineno">  202</span>        <span class="keywordflow">if</span> multioutput == <span class="stringliteral">&quot;raw_values&quot;</span>:</div>
<div class="line"><span class="lineno">  203</span>            <span class="keywordflow">return</span> output_errors</div>
<div class="line"><span class="lineno">  204</span>        <span class="keywordflow">elif</span> multioutput == <span class="stringliteral">&quot;uniform_average&quot;</span>:</div>
<div class="line"><span class="lineno">  205</span>            <span class="comment"># pass None as weights to np.average: uniform mean</span></div>
<div class="line"><span class="lineno">  206</span>            multioutput = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  207</span> </div>
<div class="line"><span class="lineno">  208</span>    <span class="keywordflow">return</span> np.average(output_errors, weights=multioutput)</div>
<div class="line"><span class="lineno">  209</span> </div>
<div class="line"><span class="lineno">  210</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8e09f27b963f5e2514e260b3a327beae" name="a8e09f27b963f5e2514e260b3a327beae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e09f27b963f5e2514e260b3a327beae">&#9670;&#160;</a></span>mean_absolute_percentage_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.mean_absolute_percentage_error </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em> = <code>&quot;uniform_average&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Mean absolute percentage error (MAPE) regression loss.

Note here that the output is not a percentage in the range [0, 100]
and a value of 100 does not mean 100% but 1e2. Furthermore, the output
can be arbitrarily high when `y_true` is small (which is specific to the
metric) or when `abs(y_true - y_pred)` is large (which is common for most
regression metrics). Read more in the
:ref:`User Guide &lt;mean_absolute_percentage_error&gt;`.

.. versionadded:: 0.24

Parameters
----------
y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

multioutput : {'raw_values', 'uniform_average'} or array-like
    Defines aggregating of multiple output values.
    Array-like value defines weights used to average errors.
    If input is list then the shape must be (n_outputs,).

    'raw_values' :
        Returns a full set of errors in case of multioutput input.

    'uniform_average' :
        Errors of all outputs are averaged with uniform weight.

Returns
-------
loss : float or ndarray of floats
    If multioutput is 'raw_values', then mean absolute percentage error
    is returned for each output separately.
    If multioutput is 'uniform_average' or an ndarray of weights, then the
    weighted average of all output errors is returned.

    MAPE output is non-negative floating point. The best value is 0.0.
    But note that bad predictions can lead to arbitrarily large
    MAPE values, especially if some `y_true` values are very close to zero.
    Note that we return a large value instead of `inf` when `y_true` is zero.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import mean_absolute_percentage_error
&gt;&gt;&gt; y_true = [3, -0.5, 2, 7]
&gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]
&gt;&gt;&gt; mean_absolute_percentage_error(y_true, y_pred)
0.3273...
&gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]
&gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]
&gt;&gt;&gt; mean_absolute_percentage_error(y_true, y_pred)
0.5515...
&gt;&gt;&gt; mean_absolute_percentage_error(y_true, y_pred, multioutput=[0.3, 0.7])
0.6198...
&gt;&gt;&gt; # the value when some element of the y_true is zero is arbitrarily high because
&gt;&gt;&gt; # of the division by epsilon
&gt;&gt;&gt; y_true = [1., 0., 2.4, 7.]
&gt;&gt;&gt; y_pred = [1.2, 0.1, 2.4, 8.]
&gt;&gt;&gt; mean_absolute_percentage_error(y_true, y_pred)
112589990684262.48
</pre> <div class="fragment"><div class="line"><span class="lineno">  298</span>):</div>
<div class="line"><span class="lineno">  299</span>    <span class="stringliteral">&quot;&quot;&quot;Mean absolute percentage error (MAPE) regression loss.</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">    Note here that the output is not a percentage in the range [0, 100]</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">    and a value of 100 does not mean 100% but 1e2. Furthermore, the output</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">    can be arbitrarily high when `y_true` is small (which is specific to the</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">    metric) or when `abs(y_true - y_pred)` is large (which is common for most</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    regression metrics). Read more in the</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    :ref:`User Guide &lt;mean_absolute_percentage_error&gt;`.</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">    .. versionadded:: 0.24</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  318</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  319</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  320</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  321</span><span class="stringliteral">    multioutput : {&#39;raw_values&#39;, &#39;uniform_average&#39;} or array-like</span></div>
<div class="line"><span class="lineno">  322</span><span class="stringliteral">        Defines aggregating of multiple output values.</span></div>
<div class="line"><span class="lineno">  323</span><span class="stringliteral">        Array-like value defines weights used to average errors.</span></div>
<div class="line"><span class="lineno">  324</span><span class="stringliteral">        If input is list then the shape must be (n_outputs,).</span></div>
<div class="line"><span class="lineno">  325</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  326</span><span class="stringliteral">        &#39;raw_values&#39; :</span></div>
<div class="line"><span class="lineno">  327</span><span class="stringliteral">            Returns a full set of errors in case of multioutput input.</span></div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">        &#39;uniform_average&#39; :</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">            Errors of all outputs are averaged with uniform weight.</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral">    loss : float or ndarray of floats</span></div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">        If multioutput is &#39;raw_values&#39;, then mean absolute percentage error</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral">        is returned for each output separately.</span></div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral">        If multioutput is &#39;uniform_average&#39; or an ndarray of weights, then the</span></div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral">        weighted average of all output errors is returned.</span></div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">        MAPE output is non-negative floating point. The best value is 0.0.</span></div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral">        But note that bad predictions can lead to arbitrarily large</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral">        MAPE values, especially if some `y_true` values are very close to zero.</span></div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral">        Note that we return a large value instead of `inf` when `y_true` is zero.</span></div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import mean_absolute_percentage_error</span></div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [3, -0.5, 2, 7]</span></div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">    &gt;&gt;&gt; mean_absolute_percentage_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">    0.3273...</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]</span></div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]</span></div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">    &gt;&gt;&gt; mean_absolute_percentage_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">    0.5515...</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral">    &gt;&gt;&gt; mean_absolute_percentage_error(y_true, y_pred, multioutput=[0.3, 0.7])</span></div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">    0.6198...</span></div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral">    &gt;&gt;&gt; # the value when some element of the y_true is zero is arbitrarily high because</span></div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral">    &gt;&gt;&gt; # of the division by epsilon</span></div>
<div class="line"><span class="lineno">  360</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [1., 0., 2.4, 7.]</span></div>
<div class="line"><span class="lineno">  361</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [1.2, 0.1, 2.4, 8.]</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral">    &gt;&gt;&gt; mean_absolute_percentage_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  363</span><span class="stringliteral">    112589990684262.48</span></div>
<div class="line"><span class="lineno">  364</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  365</span>    y_type, y_true, y_pred, multioutput = _check_reg_targets(</div>
<div class="line"><span class="lineno">  366</span>        y_true, y_pred, multioutput</div>
<div class="line"><span class="lineno">  367</span>    )</div>
<div class="line"><span class="lineno">  368</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  369</span>    epsilon = np.finfo(np.float64).eps</div>
<div class="line"><span class="lineno">  370</span>    mape = np.abs(y_pred - y_true) / np.maximum(np.abs(y_true), epsilon)</div>
<div class="line"><span class="lineno">  371</span>    output_errors = np.average(mape, weights=sample_weight, axis=0)</div>
<div class="line"><span class="lineno">  372</span>    <span class="keywordflow">if</span> isinstance(multioutput, str):</div>
<div class="line"><span class="lineno">  373</span>        <span class="keywordflow">if</span> multioutput == <span class="stringliteral">&quot;raw_values&quot;</span>:</div>
<div class="line"><span class="lineno">  374</span>            <span class="keywordflow">return</span> output_errors</div>
<div class="line"><span class="lineno">  375</span>        <span class="keywordflow">elif</span> multioutput == <span class="stringliteral">&quot;uniform_average&quot;</span>:</div>
<div class="line"><span class="lineno">  376</span>            <span class="comment"># pass None as weights to np.average: uniform mean</span></div>
<div class="line"><span class="lineno">  377</span>            multioutput = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  378</span> </div>
<div class="line"><span class="lineno">  379</span>    <span class="keywordflow">return</span> np.average(output_errors, weights=multioutput)</div>
<div class="line"><span class="lineno">  380</span> </div>
<div class="line"><span class="lineno">  381</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a301d775644c0c902122f98aafcf9dbd0" name="a301d775644c0c902122f98aafcf9dbd0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a301d775644c0c902122f98aafcf9dbd0">&#9670;&#160;</a></span>mean_gamma_deviance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.mean_gamma_deviance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Mean Gamma deviance regression loss.

Gamma deviance is equivalent to the Tweedie deviance with
the power parameter `power=2`. It is invariant to scaling of
the target variable, and measures relative errors.

Read more in the :ref:`User Guide &lt;mean_tweedie_deviance&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,)
    Ground truth (correct) target values. Requires y_true &gt; 0.

y_pred : array-like of shape (n_samples,)
    Estimated target values. Requires y_pred &gt; 0.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
loss : float
    A non-negative floating point value (the best value is 0.0).

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import mean_gamma_deviance
&gt;&gt;&gt; y_true = [2, 0.5, 1, 4]
&gt;&gt;&gt; y_pred = [0.5, 0.5, 2., 2.]
&gt;&gt;&gt; mean_gamma_deviance(y_true, y_pred)
1.0568...
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1130</span><span class="keyword">def </span>mean_gamma_deviance(y_true, y_pred, *, sample_weight=None):</div>
<div class="line"><span class="lineno"> 1131</span>    <span class="stringliteral">&quot;&quot;&quot;Mean Gamma deviance regression loss.</span></div>
<div class="line"><span class="lineno"> 1132</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1133</span><span class="stringliteral">    Gamma deviance is equivalent to the Tweedie deviance with</span></div>
<div class="line"><span class="lineno"> 1134</span><span class="stringliteral">    the power parameter `power=2`. It is invariant to scaling of</span></div>
<div class="line"><span class="lineno"> 1135</span><span class="stringliteral">    the target variable, and measures relative errors.</span></div>
<div class="line"><span class="lineno"> 1136</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1137</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;mean_tweedie_deviance&gt;`.</span></div>
<div class="line"><span class="lineno"> 1138</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1139</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1140</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1141</span><span class="stringliteral">    y_true : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1142</span><span class="stringliteral">        Ground truth (correct) target values. Requires y_true &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1143</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1144</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1145</span><span class="stringliteral">        Estimated target values. Requires y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1146</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1147</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1148</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1149</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1150</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1151</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1152</span><span class="stringliteral">    loss : float</span></div>
<div class="line"><span class="lineno"> 1153</span><span class="stringliteral">        A non-negative floating point value (the best value is 0.0).</span></div>
<div class="line"><span class="lineno"> 1154</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1155</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1156</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1157</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import mean_gamma_deviance</span></div>
<div class="line"><span class="lineno"> 1158</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [2, 0.5, 1, 4]</span></div>
<div class="line"><span class="lineno"> 1159</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0.5, 0.5, 2., 2.]</span></div>
<div class="line"><span class="lineno"> 1160</span><span class="stringliteral">    &gt;&gt;&gt; mean_gamma_deviance(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 1161</span><span class="stringliteral">    1.0568...</span></div>
<div class="line"><span class="lineno"> 1162</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1163</span>    <span class="keywordflow">return</span> mean_tweedie_deviance(y_true, y_pred, sample_weight=sample_weight, power=2)</div>
<div class="line"><span class="lineno"> 1164</span> </div>
<div class="line"><span class="lineno"> 1165</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af07e96e2ec72f6820aa3d243740bad76" name="af07e96e2ec72f6820aa3d243740bad76"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af07e96e2ec72f6820aa3d243740bad76">&#9670;&#160;</a></span>mean_pinball_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.mean_pinball_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em> = <code>&quot;uniform_average&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pinball loss for quantile regression.

Read more in the :ref:`User Guide &lt;pinball_loss&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

alpha : float, slope of the pinball loss, default=0.5,
    This loss is equivalent to :ref:`mean_absolute_error` when `alpha=0.5`,
    `alpha=0.95` is minimized by estimators of the 95th percentile.

multioutput : {'raw_values', 'uniform_average'}  or array-like of shape \
        (n_outputs,), default='uniform_average'
    Defines aggregating of multiple output values.
    Array-like value defines weights used to average errors.

    'raw_values' :
        Returns a full set of errors in case of multioutput input.

    'uniform_average' :
        Errors of all outputs are averaged with uniform weight.

Returns
-------
loss : float or ndarray of floats
    If multioutput is 'raw_values', then mean absolute error is returned
    for each output separately.
    If multioutput is 'uniform_average' or an ndarray of weights, then the
    weighted average of all output errors is returned.

    The pinball loss output is a non-negative floating point. The best
    value is 0.0.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import mean_pinball_loss
&gt;&gt;&gt; y_true = [1, 2, 3]
&gt;&gt;&gt; mean_pinball_loss(y_true, [0, 2, 3], alpha=0.1)
0.03...
&gt;&gt;&gt; mean_pinball_loss(y_true, [1, 2, 4], alpha=0.1)
0.3...
&gt;&gt;&gt; mean_pinball_loss(y_true, [0, 2, 3], alpha=0.9)
0.3...
&gt;&gt;&gt; mean_pinball_loss(y_true, [1, 2, 4], alpha=0.9)
0.03...
&gt;&gt;&gt; mean_pinball_loss(y_true, y_true, alpha=0.1)
0.0
&gt;&gt;&gt; mean_pinball_loss(y_true, y_true, alpha=0.9)
0.0
</pre> <div class="fragment"><div class="line"><span class="lineno">  213</span>):</div>
<div class="line"><span class="lineno">  214</span>    <span class="stringliteral">&quot;&quot;&quot;Pinball loss for quantile regression.</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;pinball_loss&gt;`.</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">    alpha : float, slope of the pinball loss, default=0.5,</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">        This loss is equivalent to :ref:`mean_absolute_error` when `alpha=0.5`,</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">        `alpha=0.95` is minimized by estimators of the 95th percentile.</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">    multioutput : {&#39;raw_values&#39;, &#39;uniform_average&#39;}  or array-like of shape \</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">            (n_outputs,), default=&#39;uniform_average&#39;</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">        Defines aggregating of multiple output values.</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">        Array-like value defines weights used to average errors.</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">        &#39;raw_values&#39; :</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">            Returns a full set of errors in case of multioutput input.</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">        &#39;uniform_average&#39; :</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">            Errors of all outputs are averaged with uniform weight.</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">    loss : float or ndarray of floats</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">        If multioutput is &#39;raw_values&#39;, then mean absolute error is returned</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">        for each output separately.</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">        If multioutput is &#39;uniform_average&#39; or an ndarray of weights, then the</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">        weighted average of all output errors is returned.</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">        The pinball loss output is a non-negative floating point. The best</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">        value is 0.0.</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import mean_pinball_loss</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [1, 2, 3]</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">    &gt;&gt;&gt; mean_pinball_loss(y_true, [0, 2, 3], alpha=0.1)</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">    0.03...</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">    &gt;&gt;&gt; mean_pinball_loss(y_true, [1, 2, 4], alpha=0.1)</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">    0.3...</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">    &gt;&gt;&gt; mean_pinball_loss(y_true, [0, 2, 3], alpha=0.9)</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">    0.3...</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">    &gt;&gt;&gt; mean_pinball_loss(y_true, [1, 2, 4], alpha=0.9)</span></div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">    0.03...</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">    &gt;&gt;&gt; mean_pinball_loss(y_true, y_true, alpha=0.1)</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">    0.0</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral">    &gt;&gt;&gt; mean_pinball_loss(y_true, y_true, alpha=0.9)</span></div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">    0.0</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  272</span>    y_type, y_true, y_pred, multioutput = _check_reg_targets(</div>
<div class="line"><span class="lineno">  273</span>        y_true, y_pred, multioutput</div>
<div class="line"><span class="lineno">  274</span>    )</div>
<div class="line"><span class="lineno">  275</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  276</span>    diff = y_true - y_pred</div>
<div class="line"><span class="lineno">  277</span>    sign = (diff &gt;= 0).astype(diff.dtype)</div>
<div class="line"><span class="lineno">  278</span>    loss = alpha * sign * diff - (1 - alpha) * (1 - sign) * diff</div>
<div class="line"><span class="lineno">  279</span>    output_errors = np.average(loss, weights=sample_weight, axis=0)</div>
<div class="line"><span class="lineno">  280</span>    <span class="keywordflow">if</span> isinstance(multioutput, str):</div>
<div class="line"><span class="lineno">  281</span>        <span class="keywordflow">if</span> multioutput == <span class="stringliteral">&quot;raw_values&quot;</span>:</div>
<div class="line"><span class="lineno">  282</span>            <span class="keywordflow">return</span> output_errors</div>
<div class="line"><span class="lineno">  283</span>        <span class="keywordflow">elif</span> multioutput == <span class="stringliteral">&quot;uniform_average&quot;</span>:</div>
<div class="line"><span class="lineno">  284</span>            <span class="comment"># pass None as weights to np.average: uniform mean</span></div>
<div class="line"><span class="lineno">  285</span>            multioutput = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  286</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  287</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  288</span>                <span class="stringliteral">&quot;multioutput is expected to be &#39;raw_values&#39; &quot;</span></div>
<div class="line"><span class="lineno">  289</span>                <span class="stringliteral">&quot;or &#39;uniform_average&#39; but we got %r&quot;</span></div>
<div class="line"><span class="lineno">  290</span>                <span class="stringliteral">&quot; instead.&quot;</span> % multioutput</div>
<div class="line"><span class="lineno">  291</span>            )</div>
<div class="line"><span class="lineno">  292</span> </div>
<div class="line"><span class="lineno">  293</span>    <span class="keywordflow">return</span> np.average(output_errors, weights=multioutput)</div>
<div class="line"><span class="lineno">  294</span> </div>
<div class="line"><span class="lineno">  295</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aaf6b648d7fcfd09ff1e19ae5ac71d033" name="aaf6b648d7fcfd09ff1e19ae5ac71d033"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf6b648d7fcfd09ff1e19ae5ac71d033">&#9670;&#160;</a></span>mean_poisson_deviance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.mean_poisson_deviance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Mean Poisson deviance regression loss.

Poisson deviance is equivalent to the Tweedie deviance with
the power parameter `power=1`.

Read more in the :ref:`User Guide &lt;mean_tweedie_deviance&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,)
    Ground truth (correct) target values. Requires y_true &gt;= 0.

y_pred : array-like of shape (n_samples,)
    Estimated target values. Requires y_pred &gt; 0.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
loss : float
    A non-negative floating point value (the best value is 0.0).

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import mean_poisson_deviance
&gt;&gt;&gt; y_true = [2, 0, 1, 4]
&gt;&gt;&gt; y_pred = [0.5, 0.5, 2., 2.]
&gt;&gt;&gt; mean_poisson_deviance(y_true, y_pred)
1.4260...
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1095</span><span class="keyword">def </span>mean_poisson_deviance(y_true, y_pred, *, sample_weight=None):</div>
<div class="line"><span class="lineno"> 1096</span>    <span class="stringliteral">&quot;&quot;&quot;Mean Poisson deviance regression loss.</span></div>
<div class="line"><span class="lineno"> 1097</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1098</span><span class="stringliteral">    Poisson deviance is equivalent to the Tweedie deviance with</span></div>
<div class="line"><span class="lineno"> 1099</span><span class="stringliteral">    the power parameter `power=1`.</span></div>
<div class="line"><span class="lineno"> 1100</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1101</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;mean_tweedie_deviance&gt;`.</span></div>
<div class="line"><span class="lineno"> 1102</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1103</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1104</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1105</span><span class="stringliteral">    y_true : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1106</span><span class="stringliteral">        Ground truth (correct) target values. Requires y_true &gt;= 0.</span></div>
<div class="line"><span class="lineno"> 1107</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1108</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1109</span><span class="stringliteral">        Estimated target values. Requires y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1110</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1111</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1112</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1113</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1114</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1115</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1116</span><span class="stringliteral">    loss : float</span></div>
<div class="line"><span class="lineno"> 1117</span><span class="stringliteral">        A non-negative floating point value (the best value is 0.0).</span></div>
<div class="line"><span class="lineno"> 1118</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1119</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1120</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1121</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import mean_poisson_deviance</span></div>
<div class="line"><span class="lineno"> 1122</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [2, 0, 1, 4]</span></div>
<div class="line"><span class="lineno"> 1123</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0.5, 0.5, 2., 2.]</span></div>
<div class="line"><span class="lineno"> 1124</span><span class="stringliteral">    &gt;&gt;&gt; mean_poisson_deviance(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 1125</span><span class="stringliteral">    1.4260...</span></div>
<div class="line"><span class="lineno"> 1126</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1127</span>    <span class="keywordflow">return</span> mean_tweedie_deviance(y_true, y_pred, sample_weight=sample_weight, power=1)</div>
<div class="line"><span class="lineno"> 1128</span> </div>
<div class="line"><span class="lineno"> 1129</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9bb0aafe224fde57660c7be34331677d" name="a9bb0aafe224fde57660c7be34331677d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9bb0aafe224fde57660c7be34331677d">&#9670;&#160;</a></span>mean_squared_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.mean_squared_error </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em> = <code>&quot;uniform_average&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>squared</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Mean squared error regression loss.

Read more in the :ref:`User Guide &lt;mean_squared_error&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

multioutput : {'raw_values', 'uniform_average'} or array-like of shape \
        (n_outputs,), default='uniform_average'
    Defines aggregating of multiple output values.
    Array-like value defines weights used to average errors.

    'raw_values' :
        Returns a full set of errors in case of multioutput input.

    'uniform_average' :
        Errors of all outputs are averaged with uniform weight.

squared : bool, default=True
    If True returns MSE value, if False returns RMSE value.

Returns
-------
loss : float or ndarray of floats
    A non-negative floating point value (the best value is 0.0), or an
    array of floating point values, one for each individual target.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import mean_squared_error
&gt;&gt;&gt; y_true = [3, -0.5, 2, 7]
&gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]
&gt;&gt;&gt; mean_squared_error(y_true, y_pred)
0.375
&gt;&gt;&gt; y_true = [3, -0.5, 2, 7]
&gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]
&gt;&gt;&gt; mean_squared_error(y_true, y_pred, squared=False)
0.612...
&gt;&gt;&gt; y_true = [[0.5, 1],[-1, 1],[7, -6]]
&gt;&gt;&gt; y_pred = [[0, 2],[-1, 2],[8, -5]]
&gt;&gt;&gt; mean_squared_error(y_true, y_pred)
0.708...
&gt;&gt;&gt; mean_squared_error(y_true, y_pred, squared=False)
0.822...
&gt;&gt;&gt; mean_squared_error(y_true, y_pred, multioutput='raw_values')
array([0.41666667, 1.        ])
&gt;&gt;&gt; mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])
0.825...
</pre> <div class="fragment"><div class="line"><span class="lineno">  384</span>):</div>
<div class="line"><span class="lineno">  385</span>    <span class="stringliteral">&quot;&quot;&quot;Mean squared error regression loss.</span></div>
<div class="line"><span class="lineno">  386</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  387</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;mean_squared_error&gt;`.</span></div>
<div class="line"><span class="lineno">  388</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  389</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  390</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  391</span><span class="stringliteral">    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  392</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  393</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  394</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  395</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno">  396</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  397</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  398</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  399</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  400</span><span class="stringliteral">    multioutput : {&#39;raw_values&#39;, &#39;uniform_average&#39;} or array-like of shape \</span></div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral">            (n_outputs,), default=&#39;uniform_average&#39;</span></div>
<div class="line"><span class="lineno">  402</span><span class="stringliteral">        Defines aggregating of multiple output values.</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral">        Array-like value defines weights used to average errors.</span></div>
<div class="line"><span class="lineno">  404</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral">        &#39;raw_values&#39; :</span></div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">            Returns a full set of errors in case of multioutput input.</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral">        &#39;uniform_average&#39; :</span></div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral">            Errors of all outputs are averaged with uniform weight.</span></div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral">    squared : bool, default=True</span></div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral">        If True returns MSE value, if False returns RMSE value.</span></div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  414</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  415</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral">    loss : float or ndarray of floats</span></div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral">        A non-negative floating point value (the best value is 0.0), or an</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">        array of floating point values, one for each individual target.</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  421</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  422</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import mean_squared_error</span></div>
<div class="line"><span class="lineno">  423</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [3, -0.5, 2, 7]</span></div>
<div class="line"><span class="lineno">  424</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]</span></div>
<div class="line"><span class="lineno">  425</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  426</span><span class="stringliteral">    0.375</span></div>
<div class="line"><span class="lineno">  427</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [3, -0.5, 2, 7]</span></div>
<div class="line"><span class="lineno">  428</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]</span></div>
<div class="line"><span class="lineno">  429</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_error(y_true, y_pred, squared=False)</span></div>
<div class="line"><span class="lineno">  430</span><span class="stringliteral">    0.612...</span></div>
<div class="line"><span class="lineno">  431</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0.5, 1],[-1, 1],[7, -6]]</span></div>
<div class="line"><span class="lineno">  432</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0, 2],[-1, 2],[8, -5]]</span></div>
<div class="line"><span class="lineno">  433</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  434</span><span class="stringliteral">    0.708...</span></div>
<div class="line"><span class="lineno">  435</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_error(y_true, y_pred, squared=False)</span></div>
<div class="line"><span class="lineno">  436</span><span class="stringliteral">    0.822...</span></div>
<div class="line"><span class="lineno">  437</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_error(y_true, y_pred, multioutput=&#39;raw_values&#39;)</span></div>
<div class="line"><span class="lineno">  438</span><span class="stringliteral">    array([0.41666667, 1.        ])</span></div>
<div class="line"><span class="lineno">  439</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])</span></div>
<div class="line"><span class="lineno">  440</span><span class="stringliteral">    0.825...</span></div>
<div class="line"><span class="lineno">  441</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  442</span>    y_type, y_true, y_pred, multioutput = _check_reg_targets(</div>
<div class="line"><span class="lineno">  443</span>        y_true, y_pred, multioutput</div>
<div class="line"><span class="lineno">  444</span>    )</div>
<div class="line"><span class="lineno">  445</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  446</span>    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)</div>
<div class="line"><span class="lineno">  447</span> </div>
<div class="line"><span class="lineno">  448</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> squared:</div>
<div class="line"><span class="lineno">  449</span>        output_errors = np.sqrt(output_errors)</div>
<div class="line"><span class="lineno">  450</span> </div>
<div class="line"><span class="lineno">  451</span>    <span class="keywordflow">if</span> isinstance(multioutput, str):</div>
<div class="line"><span class="lineno">  452</span>        <span class="keywordflow">if</span> multioutput == <span class="stringliteral">&quot;raw_values&quot;</span>:</div>
<div class="line"><span class="lineno">  453</span>            <span class="keywordflow">return</span> output_errors</div>
<div class="line"><span class="lineno">  454</span>        <span class="keywordflow">elif</span> multioutput == <span class="stringliteral">&quot;uniform_average&quot;</span>:</div>
<div class="line"><span class="lineno">  455</span>            <span class="comment"># pass None as weights to np.average: uniform mean</span></div>
<div class="line"><span class="lineno">  456</span>            multioutput = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  457</span> </div>
<div class="line"><span class="lineno">  458</span>    <span class="keywordflow">return</span> np.average(output_errors, weights=multioutput)</div>
<div class="line"><span class="lineno">  459</span> </div>
<div class="line"><span class="lineno">  460</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a371dc0c75bbb46518b2780f44c9e8090" name="a371dc0c75bbb46518b2780f44c9e8090"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a371dc0c75bbb46518b2780f44c9e8090">&#9670;&#160;</a></span>mean_squared_log_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.mean_squared_log_error </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em> = <code>&quot;uniform_average&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>squared</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Mean squared logarithmic error regression loss.

Read more in the :ref:`User Guide &lt;mean_squared_log_error&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

multioutput : {'raw_values', 'uniform_average'} or array-like of shape \
        (n_outputs,), default='uniform_average'

    Defines aggregating of multiple output values.
    Array-like value defines weights used to average errors.

    'raw_values' :
        Returns a full set of errors when the input is of multioutput
        format.

    'uniform_average' :
        Errors of all outputs are averaged with uniform weight.
squared : bool, default=True
    If True returns MSLE (mean squared log error) value.
    If False returns RMSLE (root mean squared log error) value.

Returns
-------
loss : float or ndarray of floats
    A non-negative floating point value (the best value is 0.0), or an
    array of floating point values, one for each individual target.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import mean_squared_log_error
&gt;&gt;&gt; y_true = [3, 5, 2.5, 7]
&gt;&gt;&gt; y_pred = [2.5, 5, 4, 8]
&gt;&gt;&gt; mean_squared_log_error(y_true, y_pred)
0.039...
&gt;&gt;&gt; mean_squared_log_error(y_true, y_pred, squared=False)
0.199...
&gt;&gt;&gt; y_true = [[0.5, 1], [1, 2], [7, 6]]
&gt;&gt;&gt; y_pred = [[0.5, 2], [1, 2.5], [8, 8]]
&gt;&gt;&gt; mean_squared_log_error(y_true, y_pred)
0.044...
&gt;&gt;&gt; mean_squared_log_error(y_true, y_pred, multioutput='raw_values')
array([0.00462428, 0.08377444])
&gt;&gt;&gt; mean_squared_log_error(y_true, y_pred, multioutput=[0.3, 0.7])
0.060...
</pre> <div class="fragment"><div class="line"><span class="lineno">  463</span>):</div>
<div class="line"><span class="lineno">  464</span>    <span class="stringliteral">&quot;&quot;&quot;Mean squared logarithmic error regression loss.</span></div>
<div class="line"><span class="lineno">  465</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  466</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;mean_squared_log_error&gt;`.</span></div>
<div class="line"><span class="lineno">  467</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  468</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  469</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  470</span><span class="stringliteral">    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  471</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  472</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  473</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  474</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno">  475</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  476</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  477</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  478</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  479</span><span class="stringliteral">    multioutput : {&#39;raw_values&#39;, &#39;uniform_average&#39;} or array-like of shape \</span></div>
<div class="line"><span class="lineno">  480</span><span class="stringliteral">            (n_outputs,), default=&#39;uniform_average&#39;</span></div>
<div class="line"><span class="lineno">  481</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  482</span><span class="stringliteral">        Defines aggregating of multiple output values.</span></div>
<div class="line"><span class="lineno">  483</span><span class="stringliteral">        Array-like value defines weights used to average errors.</span></div>
<div class="line"><span class="lineno">  484</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  485</span><span class="stringliteral">        &#39;raw_values&#39; :</span></div>
<div class="line"><span class="lineno">  486</span><span class="stringliteral">            Returns a full set of errors when the input is of multioutput</span></div>
<div class="line"><span class="lineno">  487</span><span class="stringliteral">            format.</span></div>
<div class="line"><span class="lineno">  488</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  489</span><span class="stringliteral">        &#39;uniform_average&#39; :</span></div>
<div class="line"><span class="lineno">  490</span><span class="stringliteral">            Errors of all outputs are averaged with uniform weight.</span></div>
<div class="line"><span class="lineno">  491</span><span class="stringliteral">    squared : bool, default=True</span></div>
<div class="line"><span class="lineno">  492</span><span class="stringliteral">        If True returns MSLE (mean squared log error) value.</span></div>
<div class="line"><span class="lineno">  493</span><span class="stringliteral">        If False returns RMSLE (root mean squared log error) value.</span></div>
<div class="line"><span class="lineno">  494</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  495</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  496</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  497</span><span class="stringliteral">    loss : float or ndarray of floats</span></div>
<div class="line"><span class="lineno">  498</span><span class="stringliteral">        A non-negative floating point value (the best value is 0.0), or an</span></div>
<div class="line"><span class="lineno">  499</span><span class="stringliteral">        array of floating point values, one for each individual target.</span></div>
<div class="line"><span class="lineno">  500</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  501</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  502</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  503</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import mean_squared_log_error</span></div>
<div class="line"><span class="lineno">  504</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [3, 5, 2.5, 7]</span></div>
<div class="line"><span class="lineno">  505</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2.5, 5, 4, 8]</span></div>
<div class="line"><span class="lineno">  506</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_log_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  507</span><span class="stringliteral">    0.039...</span></div>
<div class="line"><span class="lineno">  508</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_log_error(y_true, y_pred, squared=False)</span></div>
<div class="line"><span class="lineno">  509</span><span class="stringliteral">    0.199...</span></div>
<div class="line"><span class="lineno">  510</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0.5, 1], [1, 2], [7, 6]]</span></div>
<div class="line"><span class="lineno">  511</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0.5, 2], [1, 2.5], [8, 8]]</span></div>
<div class="line"><span class="lineno">  512</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_log_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  513</span><span class="stringliteral">    0.044...</span></div>
<div class="line"><span class="lineno">  514</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_log_error(y_true, y_pred, multioutput=&#39;raw_values&#39;)</span></div>
<div class="line"><span class="lineno">  515</span><span class="stringliteral">    array([0.00462428, 0.08377444])</span></div>
<div class="line"><span class="lineno">  516</span><span class="stringliteral">    &gt;&gt;&gt; mean_squared_log_error(y_true, y_pred, multioutput=[0.3, 0.7])</span></div>
<div class="line"><span class="lineno">  517</span><span class="stringliteral">    0.060...</span></div>
<div class="line"><span class="lineno">  518</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  519</span>    y_type, y_true, y_pred, multioutput = _check_reg_targets(</div>
<div class="line"><span class="lineno">  520</span>        y_true, y_pred, multioutput</div>
<div class="line"><span class="lineno">  521</span>    )</div>
<div class="line"><span class="lineno">  522</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  523</span> </div>
<div class="line"><span class="lineno">  524</span>    <span class="keywordflow">if</span> (y_true &lt; 0).any() <span class="keywordflow">or</span> (y_pred &lt; 0).any():</div>
<div class="line"><span class="lineno">  525</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  526</span>            <span class="stringliteral">&quot;Mean Squared Logarithmic Error cannot be used when &quot;</span></div>
<div class="line"><span class="lineno">  527</span>            <span class="stringliteral">&quot;targets contain negative values.&quot;</span></div>
<div class="line"><span class="lineno">  528</span>        )</div>
<div class="line"><span class="lineno">  529</span> </div>
<div class="line"><span class="lineno">  530</span>    <span class="keywordflow">return</span> mean_squared_error(</div>
<div class="line"><span class="lineno">  531</span>        np.log1p(y_true),</div>
<div class="line"><span class="lineno">  532</span>        np.log1p(y_pred),</div>
<div class="line"><span class="lineno">  533</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  534</span>        multioutput=multioutput,</div>
<div class="line"><span class="lineno">  535</span>        squared=squared,</div>
<div class="line"><span class="lineno">  536</span>    )</div>
<div class="line"><span class="lineno">  537</span> </div>
<div class="line"><span class="lineno">  538</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8760cb469230339c89b3b62d8536dbdc" name="a8760cb469230339c89b3b62d8536dbdc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8760cb469230339c89b3b62d8536dbdc">&#9670;&#160;</a></span>mean_tweedie_deviance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.mean_tweedie_deviance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>power</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Mean Tweedie deviance regression loss.

Read more in the :ref:`User Guide &lt;mean_tweedie_deviance&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

power : float, default=0
    Tweedie power parameter. Either power &lt;= 0 or power &gt;= 1.

    The higher `p` the less weight is given to extreme
    deviations between true and predicted targets.

    - power &lt; 0: Extreme stable distribution. Requires: y_pred &gt; 0.
    - power = 0 : Normal distribution, output corresponds to
      mean_squared_error. y_true and y_pred can be any real numbers.
    - power = 1 : Poisson distribution. Requires: y_true &gt;= 0 and
      y_pred &gt; 0.
    - 1 &lt; p &lt; 2 : Compound Poisson distribution. Requires: y_true &gt;= 0
      and y_pred &gt; 0.
    - power = 2 : Gamma distribution. Requires: y_true &gt; 0 and y_pred &gt; 0.
    - power = 3 : Inverse Gaussian distribution. Requires: y_true &gt; 0
      and y_pred &gt; 0.
    - otherwise : Positive stable distribution. Requires: y_true &gt; 0
      and y_pred &gt; 0.

Returns
-------
loss : float
    A non-negative floating point value (the best value is 0.0).

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import mean_tweedie_deviance
&gt;&gt;&gt; y_true = [2, 0, 1, 4]
&gt;&gt;&gt; y_pred = [0.5, 0.5, 2., 2.]
&gt;&gt;&gt; mean_tweedie_deviance(y_true, y_pred, power=1)
1.4260...
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1003</span><span class="keyword">def </span>mean_tweedie_deviance(y_true, y_pred, *, sample_weight=None, power=0):</div>
<div class="line"><span class="lineno"> 1004</span>    <span class="stringliteral">&quot;&quot;&quot;Mean Tweedie deviance regression loss.</span></div>
<div class="line"><span class="lineno"> 1005</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1006</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;mean_tweedie_deviance&gt;`.</span></div>
<div class="line"><span class="lineno"> 1007</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1008</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1009</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1010</span><span class="stringliteral">    y_true : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1011</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 1012</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1013</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1014</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno"> 1015</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1016</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1017</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1018</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1019</span><span class="stringliteral">    power : float, default=0</span></div>
<div class="line"><span class="lineno"> 1020</span><span class="stringliteral">        Tweedie power parameter. Either power &lt;= 0 or power &gt;= 1.</span></div>
<div class="line"><span class="lineno"> 1021</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1022</span><span class="stringliteral">        The higher `p` the less weight is given to extreme</span></div>
<div class="line"><span class="lineno"> 1023</span><span class="stringliteral">        deviations between true and predicted targets.</span></div>
<div class="line"><span class="lineno"> 1024</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1025</span><span class="stringliteral">        - power &lt; 0: Extreme stable distribution. Requires: y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1026</span><span class="stringliteral">        - power = 0 : Normal distribution, output corresponds to</span></div>
<div class="line"><span class="lineno"> 1027</span><span class="stringliteral">          mean_squared_error. y_true and y_pred can be any real numbers.</span></div>
<div class="line"><span class="lineno"> 1028</span><span class="stringliteral">        - power = 1 : Poisson distribution. Requires: y_true &gt;= 0 and</span></div>
<div class="line"><span class="lineno"> 1029</span><span class="stringliteral">          y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1030</span><span class="stringliteral">        - 1 &lt; p &lt; 2 : Compound Poisson distribution. Requires: y_true &gt;= 0</span></div>
<div class="line"><span class="lineno"> 1031</span><span class="stringliteral">          and y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1032</span><span class="stringliteral">        - power = 2 : Gamma distribution. Requires: y_true &gt; 0 and y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1033</span><span class="stringliteral">        - power = 3 : Inverse Gaussian distribution. Requires: y_true &gt; 0</span></div>
<div class="line"><span class="lineno"> 1034</span><span class="stringliteral">          and y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1035</span><span class="stringliteral">        - otherwise : Positive stable distribution. Requires: y_true &gt; 0</span></div>
<div class="line"><span class="lineno"> 1036</span><span class="stringliteral">          and y_pred &gt; 0.</span></div>
<div class="line"><span class="lineno"> 1037</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1038</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1039</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1040</span><span class="stringliteral">    loss : float</span></div>
<div class="line"><span class="lineno"> 1041</span><span class="stringliteral">        A non-negative floating point value (the best value is 0.0).</span></div>
<div class="line"><span class="lineno"> 1042</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1043</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1044</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1045</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import mean_tweedie_deviance</span></div>
<div class="line"><span class="lineno"> 1046</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [2, 0, 1, 4]</span></div>
<div class="line"><span class="lineno"> 1047</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0.5, 0.5, 2., 2.]</span></div>
<div class="line"><span class="lineno"> 1048</span><span class="stringliteral">    &gt;&gt;&gt; mean_tweedie_deviance(y_true, y_pred, power=1)</span></div>
<div class="line"><span class="lineno"> 1049</span><span class="stringliteral">    1.4260...</span></div>
<div class="line"><span class="lineno"> 1050</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1051</span>    y_type, y_true, y_pred, _ = _check_reg_targets(</div>
<div class="line"><span class="lineno"> 1052</span>        y_true, y_pred, <span class="keywordtype">None</span>, dtype=[np.float64, np.float32]</div>
<div class="line"><span class="lineno"> 1053</span>    )</div>
<div class="line"><span class="lineno"> 1054</span>    <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;continuous-multioutput&quot;</span>:</div>
<div class="line"><span class="lineno"> 1055</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Multioutput not supported in mean_tweedie_deviance&quot;</span>)</div>
<div class="line"><span class="lineno"> 1056</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno"> 1057</span> </div>
<div class="line"><span class="lineno"> 1058</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1059</span>        sample_weight = column_or_1d(sample_weight)</div>
<div class="line"><span class="lineno"> 1060</span>        sample_weight = sample_weight[:, np.newaxis]</div>
<div class="line"><span class="lineno"> 1061</span> </div>
<div class="line"><span class="lineno"> 1062</span>    p = check_scalar(</div>
<div class="line"><span class="lineno"> 1063</span>        power,</div>
<div class="line"><span class="lineno"> 1064</span>        name=<span class="stringliteral">&quot;power&quot;</span>,</div>
<div class="line"><span class="lineno"> 1065</span>        target_type=numbers.Real,</div>
<div class="line"><span class="lineno"> 1066</span>    )</div>
<div class="line"><span class="lineno"> 1067</span> </div>
<div class="line"><span class="lineno"> 1068</span>    message = f<span class="stringliteral">&quot;Mean Tweedie deviance error with power={p} can only be used on &quot;</span></div>
<div class="line"><span class="lineno"> 1069</span>    <span class="keywordflow">if</span> p &lt; 0:</div>
<div class="line"><span class="lineno"> 1070</span>        <span class="comment"># &#39;Extreme stable&#39;, y any real number, y_pred &gt; 0</span></div>
<div class="line"><span class="lineno"> 1071</span>        <span class="keywordflow">if</span> (y_pred &lt;= 0).any():</div>
<div class="line"><span class="lineno"> 1072</span>            <span class="keywordflow">raise</span> ValueError(message + <span class="stringliteral">&quot;strictly positive y_pred.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1073</span>    <span class="keywordflow">elif</span> p == 0:</div>
<div class="line"><span class="lineno"> 1074</span>        <span class="comment"># Normal, y and y_pred can be any real number</span></div>
<div class="line"><span class="lineno"> 1075</span>        <span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno"> 1076</span>    <span class="keywordflow">elif</span> 0 &lt; p &lt; 1:</div>
<div class="line"><span class="lineno"> 1077</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Tweedie deviance is only defined for power&lt;=0 and power&gt;=1.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1078</span>    <span class="keywordflow">elif</span> 1 &lt;= p &lt; 2:</div>
<div class="line"><span class="lineno"> 1079</span>        <span class="comment"># Poisson and compound Poisson distribution, y &gt;= 0, y_pred &gt; 0</span></div>
<div class="line"><span class="lineno"> 1080</span>        <span class="keywordflow">if</span> (y_true &lt; 0).any() <span class="keywordflow">or</span> (y_pred &lt;= 0).any():</div>
<div class="line"><span class="lineno"> 1081</span>            <span class="keywordflow">raise</span> ValueError(message + <span class="stringliteral">&quot;non-negative y and strictly positive y_pred.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1082</span>    <span class="keywordflow">elif</span> p &gt;= 2:</div>
<div class="line"><span class="lineno"> 1083</span>        <span class="comment"># Gamma and Extreme stable distribution, y and y_pred &gt; 0</span></div>
<div class="line"><span class="lineno"> 1084</span>        <span class="keywordflow">if</span> (y_true &lt;= 0).any() <span class="keywordflow">or</span> (y_pred &lt;= 0).any():</div>
<div class="line"><span class="lineno"> 1085</span>            <span class="keywordflow">raise</span> ValueError(message + <span class="stringliteral">&quot;strictly positive y and y_pred.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1086</span>    <span class="keywordflow">else</span>:  <span class="comment"># pragma: nocover</span></div>
<div class="line"><span class="lineno"> 1087</span>        <span class="comment"># Unreachable statement</span></div>
<div class="line"><span class="lineno"> 1088</span>        <span class="keywordflow">raise</span> ValueError</div>
<div class="line"><span class="lineno"> 1089</span> </div>
<div class="line"><span class="lineno"> 1090</span>    <span class="keywordflow">return</span> _mean_tweedie_deviance(</div>
<div class="line"><span class="lineno"> 1091</span>        y_true, y_pred, sample_weight=sample_weight, power=power</div>
<div class="line"><span class="lineno"> 1092</span>    )</div>
<div class="line"><span class="lineno"> 1093</span> </div>
<div class="line"><span class="lineno"> 1094</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad20b0fabe18d48253a4e7804c8478b39" name="ad20b0fabe18d48253a4e7804c8478b39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad20b0fabe18d48253a4e7804c8478b39">&#9670;&#160;</a></span>median_absolute_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.median_absolute_error </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>multioutput</em> = <code>&quot;uniform_average&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Median absolute error regression loss.

Median absolute error output is non-negative floating point. The best value
is 0.0. Read more in the :ref:`User Guide &lt;median_absolute_error&gt;`.

Parameters
----------
y_true : array-like of shape = (n_samples) or (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)
    Estimated target values.

multioutput : {'raw_values', 'uniform_average'} or array-like of shape \
        (n_outputs,), default='uniform_average'
    Defines aggregating of multiple output values. Array-like value defines
    weights used to average errors.

    'raw_values' :
        Returns a full set of errors in case of multioutput input.

    'uniform_average' :
        Errors of all outputs are averaged with uniform weight.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

    .. versionadded:: 0.24

Returns
-------
loss : float or ndarray of floats
    If multioutput is 'raw_values', then mean absolute error is returned
    for each output separately.
    If multioutput is 'uniform_average' or an ndarray of weights, then the
    weighted average of all output errors is returned.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import median_absolute_error
&gt;&gt;&gt; y_true = [3, -0.5, 2, 7]
&gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]
&gt;&gt;&gt; median_absolute_error(y_true, y_pred)
0.5
&gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]
&gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]
&gt;&gt;&gt; median_absolute_error(y_true, y_pred)
0.75
&gt;&gt;&gt; median_absolute_error(y_true, y_pred, multioutput='raw_values')
array([0.5, 1. ])
&gt;&gt;&gt; median_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])
0.85
</pre> <div class="fragment"><div class="line"><span class="lineno">  541</span>):</div>
<div class="line"><span class="lineno">  542</span>    <span class="stringliteral">&quot;&quot;&quot;Median absolute error regression loss.</span></div>
<div class="line"><span class="lineno">  543</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  544</span><span class="stringliteral">    Median absolute error output is non-negative floating point. The best value</span></div>
<div class="line"><span class="lineno">  545</span><span class="stringliteral">    is 0.0. Read more in the :ref:`User Guide &lt;median_absolute_error&gt;`.</span></div>
<div class="line"><span class="lineno">  546</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  547</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  548</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  549</span><span class="stringliteral">    y_true : array-like of shape = (n_samples) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  550</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  551</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  552</span><span class="stringliteral">    y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  553</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno">  554</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  555</span><span class="stringliteral">    multioutput : {&#39;raw_values&#39;, &#39;uniform_average&#39;} or array-like of shape \</span></div>
<div class="line"><span class="lineno">  556</span><span class="stringliteral">            (n_outputs,), default=&#39;uniform_average&#39;</span></div>
<div class="line"><span class="lineno">  557</span><span class="stringliteral">        Defines aggregating of multiple output values. Array-like value defines</span></div>
<div class="line"><span class="lineno">  558</span><span class="stringliteral">        weights used to average errors.</span></div>
<div class="line"><span class="lineno">  559</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  560</span><span class="stringliteral">        &#39;raw_values&#39; :</span></div>
<div class="line"><span class="lineno">  561</span><span class="stringliteral">            Returns a full set of errors in case of multioutput input.</span></div>
<div class="line"><span class="lineno">  562</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  563</span><span class="stringliteral">        &#39;uniform_average&#39; :</span></div>
<div class="line"><span class="lineno">  564</span><span class="stringliteral">            Errors of all outputs are averaged with uniform weight.</span></div>
<div class="line"><span class="lineno">  565</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  566</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  567</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  568</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  569</span><span class="stringliteral">        .. versionadded:: 0.24</span></div>
<div class="line"><span class="lineno">  570</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  571</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  572</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  573</span><span class="stringliteral">    loss : float or ndarray of floats</span></div>
<div class="line"><span class="lineno">  574</span><span class="stringliteral">        If multioutput is &#39;raw_values&#39;, then mean absolute error is returned</span></div>
<div class="line"><span class="lineno">  575</span><span class="stringliteral">        for each output separately.</span></div>
<div class="line"><span class="lineno">  576</span><span class="stringliteral">        If multioutput is &#39;uniform_average&#39; or an ndarray of weights, then the</span></div>
<div class="line"><span class="lineno">  577</span><span class="stringliteral">        weighted average of all output errors is returned.</span></div>
<div class="line"><span class="lineno">  578</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  579</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  580</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  581</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import median_absolute_error</span></div>
<div class="line"><span class="lineno">  582</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [3, -0.5, 2, 7]</span></div>
<div class="line"><span class="lineno">  583</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]</span></div>
<div class="line"><span class="lineno">  584</span><span class="stringliteral">    &gt;&gt;&gt; median_absolute_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  585</span><span class="stringliteral">    0.5</span></div>
<div class="line"><span class="lineno">  586</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]</span></div>
<div class="line"><span class="lineno">  587</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]</span></div>
<div class="line"><span class="lineno">  588</span><span class="stringliteral">    &gt;&gt;&gt; median_absolute_error(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  589</span><span class="stringliteral">    0.75</span></div>
<div class="line"><span class="lineno">  590</span><span class="stringliteral">    &gt;&gt;&gt; median_absolute_error(y_true, y_pred, multioutput=&#39;raw_values&#39;)</span></div>
<div class="line"><span class="lineno">  591</span><span class="stringliteral">    array([0.5, 1. ])</span></div>
<div class="line"><span class="lineno">  592</span><span class="stringliteral">    &gt;&gt;&gt; median_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])</span></div>
<div class="line"><span class="lineno">  593</span><span class="stringliteral">    0.85</span></div>
<div class="line"><span class="lineno">  594</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  595</span>    y_type, y_true, y_pred, multioutput = _check_reg_targets(</div>
<div class="line"><span class="lineno">  596</span>        y_true, y_pred, multioutput</div>
<div class="line"><span class="lineno">  597</span>    )</div>
<div class="line"><span class="lineno">  598</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  599</span>        output_errors = np.median(np.abs(y_pred - y_true), axis=0)</div>
<div class="line"><span class="lineno">  600</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  601</span>        sample_weight = _check_sample_weight(sample_weight, y_pred)</div>
<div class="line"><span class="lineno">  602</span>        output_errors = _weighted_percentile(</div>
<div class="line"><span class="lineno">  603</span>            np.abs(y_pred - y_true), sample_weight=sample_weight</div>
<div class="line"><span class="lineno">  604</span>        )</div>
<div class="line"><span class="lineno">  605</span>    <span class="keywordflow">if</span> isinstance(multioutput, str):</div>
<div class="line"><span class="lineno">  606</span>        <span class="keywordflow">if</span> multioutput == <span class="stringliteral">&quot;raw_values&quot;</span>:</div>
<div class="line"><span class="lineno">  607</span>            <span class="keywordflow">return</span> output_errors</div>
<div class="line"><span class="lineno">  608</span>        <span class="keywordflow">elif</span> multioutput == <span class="stringliteral">&quot;uniform_average&quot;</span>:</div>
<div class="line"><span class="lineno">  609</span>            <span class="comment"># pass None as weights to np.average: uniform mean</span></div>
<div class="line"><span class="lineno">  610</span>            multioutput = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  611</span> </div>
<div class="line"><span class="lineno">  612</span>    <span class="keywordflow">return</span> np.average(output_errors, weights=multioutput)</div>
<div class="line"><span class="lineno">  613</span> </div>
<div class="line"><span class="lineno">  614</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a321756855a5b291846a1e738f9003bba" name="a321756855a5b291846a1e738f9003bba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a321756855a5b291846a1e738f9003bba">&#9670;&#160;</a></span>r2_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._regression.r2_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multioutput</em> = <code>&quot;uniform_average&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>force_finite</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">:math:`R^2` (coefficient of determination) regression score function.

Best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). In the general case when the true y is
non-constant, a constant model that always predicts the average y
disregarding the input features would get a :math:`R^2` score of 0.0.

In the particular case when ``y_true`` is constant, the :math:`R^2` score
is not finite: it is either ``NaN`` (perfect predictions) or ``-Inf``
(imperfect predictions). To prevent such non-finite numbers to pollute
higher-level experiments such as a grid search cross-validation, by default
these cases are replaced with 1.0 (perfect predictions) or 0.0 (imperfect
predictions) respectively. You can set ``force_finite`` to ``False`` to
prevent this fix from happening.

Note: when the prediction residuals have zero mean, the :math:`R^2` score
is identical to the
:func:`Explained Variance score &lt;explained_variance_score&gt;`.

Read more in the :ref:`User Guide &lt;r2_score&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)
    Estimated target values.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

multioutput : {'raw_values', 'uniform_average', 'variance_weighted'}, \
        array-like of shape (n_outputs,) or None, default='uniform_average'

    Defines aggregating of multiple output scores.
    Array-like value defines weights used to average scores.
    Default is "uniform_average".

    'raw_values' :
        Returns a full set of scores in case of multioutput input.

    'uniform_average' :
        Scores of all outputs are averaged with uniform weight.

    'variance_weighted' :
        Scores of all outputs are averaged, weighted by the variances
        of each individual output.

    .. versionchanged:: 0.19
        Default value of multioutput is 'uniform_average'.

force_finite : bool, default=True
    Flag indicating if ``NaN`` and ``-Inf`` scores resulting from constant
    data should be replaced with real numbers (``1.0`` if prediction is
    perfect, ``0.0`` otherwise). Default is ``True``, a convenient setting
    for hyperparameters' search procedures (e.g. grid search
    cross-validation).

    .. versionadded:: 1.1

Returns
-------
z : float or ndarray of floats
    The :math:`R^2` score or ndarray of scores if 'multioutput' is
    'raw_values'.

Notes
-----
This is not a symmetric function.

Unlike most other scores, :math:`R^2` score may be negative (it need not
actually be the square of a quantity R).

This metric is not well-defined for single samples and will return a NaN
value if n_samples is less than two.

References
----------
.. [1] `Wikipedia entry on the Coefficient of determination
        &lt;https://en.wikipedia.org/wiki/Coefficient_of_determination&gt;`_

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import r2_score
&gt;&gt;&gt; y_true = [3, -0.5, 2, 7]
&gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]
&gt;&gt;&gt; r2_score(y_true, y_pred)
0.948...
&gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]
&gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]
&gt;&gt;&gt; r2_score(y_true, y_pred,
...          multioutput='variance_weighted')
0.938...
&gt;&gt;&gt; y_true = [1, 2, 3]
&gt;&gt;&gt; y_pred = [1, 2, 3]
&gt;&gt;&gt; r2_score(y_true, y_pred)
1.0
&gt;&gt;&gt; y_true = [1, 2, 3]
&gt;&gt;&gt; y_pred = [2, 2, 2]
&gt;&gt;&gt; r2_score(y_true, y_pred)
0.0
&gt;&gt;&gt; y_true = [1, 2, 3]
&gt;&gt;&gt; y_pred = [3, 2, 1]
&gt;&gt;&gt; r2_score(y_true, y_pred)
-3.0
&gt;&gt;&gt; y_true = [-2, -2, -2]
&gt;&gt;&gt; y_pred = [-2, -2, -2]
&gt;&gt;&gt; r2_score(y_true, y_pred)
1.0
&gt;&gt;&gt; r2_score(y_true, y_pred, force_finite=False)
nan
&gt;&gt;&gt; y_true = [-2, -2, -2]
&gt;&gt;&gt; y_pred = [-2, -2, -2 + 1e-8]
&gt;&gt;&gt; r2_score(y_true, y_pred)
0.0
&gt;&gt;&gt; r2_score(y_true, y_pred, force_finite=False)
-inf
</pre> <div class="fragment"><div class="line"><span class="lineno">  791</span>):</div>
<div class="line"><span class="lineno">  792</span>    <span class="stringliteral">&quot;&quot;&quot;:math:`R^2` (coefficient of determination) regression score function.</span></div>
<div class="line"><span class="lineno">  793</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  794</span><span class="stringliteral">    Best possible score is 1.0 and it can be negative (because the</span></div>
<div class="line"><span class="lineno">  795</span><span class="stringliteral">    model can be arbitrarily worse). In the general case when the true y is</span></div>
<div class="line"><span class="lineno">  796</span><span class="stringliteral">    non-constant, a constant model that always predicts the average y</span></div>
<div class="line"><span class="lineno">  797</span><span class="stringliteral">    disregarding the input features would get a :math:`R^2` score of 0.0.</span></div>
<div class="line"><span class="lineno">  798</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  799</span><span class="stringliteral">    In the particular case when ``y_true`` is constant, the :math:`R^2` score</span></div>
<div class="line"><span class="lineno">  800</span><span class="stringliteral">    is not finite: it is either ``NaN`` (perfect predictions) or ``-Inf``</span></div>
<div class="line"><span class="lineno">  801</span><span class="stringliteral">    (imperfect predictions). To prevent such non-finite numbers to pollute</span></div>
<div class="line"><span class="lineno">  802</span><span class="stringliteral">    higher-level experiments such as a grid search cross-validation, by default</span></div>
<div class="line"><span class="lineno">  803</span><span class="stringliteral">    these cases are replaced with 1.0 (perfect predictions) or 0.0 (imperfect</span></div>
<div class="line"><span class="lineno">  804</span><span class="stringliteral">    predictions) respectively. You can set ``force_finite`` to ``False`` to</span></div>
<div class="line"><span class="lineno">  805</span><span class="stringliteral">    prevent this fix from happening.</span></div>
<div class="line"><span class="lineno">  806</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  807</span><span class="stringliteral">    Note: when the prediction residuals have zero mean, the :math:`R^2` score</span></div>
<div class="line"><span class="lineno">  808</span><span class="stringliteral">    is identical to the</span></div>
<div class="line"><span class="lineno">  809</span><span class="stringliteral">    :func:`Explained Variance score &lt;explained_variance_score&gt;`.</span></div>
<div class="line"><span class="lineno">  810</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  811</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;r2_score&gt;`.</span></div>
<div class="line"><span class="lineno">  812</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  813</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  814</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  815</span><span class="stringliteral">    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  816</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  817</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  818</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  819</span><span class="stringliteral">        Estimated target values.</span></div>
<div class="line"><span class="lineno">  820</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  821</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  822</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  823</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  824</span><span class="stringliteral">    multioutput : {&#39;raw_values&#39;, &#39;uniform_average&#39;, &#39;variance_weighted&#39;}, \</span></div>
<div class="line"><span class="lineno">  825</span><span class="stringliteral">            array-like of shape (n_outputs,) or None, default=&#39;uniform_average&#39;</span></div>
<div class="line"><span class="lineno">  826</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  827</span><span class="stringliteral">        Defines aggregating of multiple output scores.</span></div>
<div class="line"><span class="lineno">  828</span><span class="stringliteral">        Array-like value defines weights used to average scores.</span></div>
<div class="line"><span class="lineno">  829</span><span class="stringliteral">        Default is &quot;uniform_average&quot;.</span></div>
<div class="line"><span class="lineno">  830</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  831</span><span class="stringliteral">        &#39;raw_values&#39; :</span></div>
<div class="line"><span class="lineno">  832</span><span class="stringliteral">            Returns a full set of scores in case of multioutput input.</span></div>
<div class="line"><span class="lineno">  833</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  834</span><span class="stringliteral">        &#39;uniform_average&#39; :</span></div>
<div class="line"><span class="lineno">  835</span><span class="stringliteral">            Scores of all outputs are averaged with uniform weight.</span></div>
<div class="line"><span class="lineno">  836</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  837</span><span class="stringliteral">        &#39;variance_weighted&#39; :</span></div>
<div class="line"><span class="lineno">  838</span><span class="stringliteral">            Scores of all outputs are averaged, weighted by the variances</span></div>
<div class="line"><span class="lineno">  839</span><span class="stringliteral">            of each individual output.</span></div>
<div class="line"><span class="lineno">  840</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  841</span><span class="stringliteral">        .. versionchanged:: 0.19</span></div>
<div class="line"><span class="lineno">  842</span><span class="stringliteral">            Default value of multioutput is &#39;uniform_average&#39;.</span></div>
<div class="line"><span class="lineno">  843</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  844</span><span class="stringliteral">    force_finite : bool, default=True</span></div>
<div class="line"><span class="lineno">  845</span><span class="stringliteral">        Flag indicating if ``NaN`` and ``-Inf`` scores resulting from constant</span></div>
<div class="line"><span class="lineno">  846</span><span class="stringliteral">        data should be replaced with real numbers (``1.0`` if prediction is</span></div>
<div class="line"><span class="lineno">  847</span><span class="stringliteral">        perfect, ``0.0`` otherwise). Default is ``True``, a convenient setting</span></div>
<div class="line"><span class="lineno">  848</span><span class="stringliteral">        for hyperparameters&#39; search procedures (e.g. grid search</span></div>
<div class="line"><span class="lineno">  849</span><span class="stringliteral">        cross-validation).</span></div>
<div class="line"><span class="lineno">  850</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  851</span><span class="stringliteral">        .. versionadded:: 1.1</span></div>
<div class="line"><span class="lineno">  852</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  853</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  854</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  855</span><span class="stringliteral">    z : float or ndarray of floats</span></div>
<div class="line"><span class="lineno">  856</span><span class="stringliteral">        The :math:`R^2` score or ndarray of scores if &#39;multioutput&#39; is</span></div>
<div class="line"><span class="lineno">  857</span><span class="stringliteral">        &#39;raw_values&#39;.</span></div>
<div class="line"><span class="lineno">  858</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  859</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  860</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  861</span><span class="stringliteral">    This is not a symmetric function.</span></div>
<div class="line"><span class="lineno">  862</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  863</span><span class="stringliteral">    Unlike most other scores, :math:`R^2` score may be negative (it need not</span></div>
<div class="line"><span class="lineno">  864</span><span class="stringliteral">    actually be the square of a quantity R).</span></div>
<div class="line"><span class="lineno">  865</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  866</span><span class="stringliteral">    This metric is not well-defined for single samples and will return a NaN</span></div>
<div class="line"><span class="lineno">  867</span><span class="stringliteral">    value if n_samples is less than two.</span></div>
<div class="line"><span class="lineno">  868</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  869</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  870</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  871</span><span class="stringliteral">    .. [1] `Wikipedia entry on the Coefficient of determination</span></div>
<div class="line"><span class="lineno">  872</span><span class="stringliteral">            &lt;https://en.wikipedia.org/wiki/Coefficient_of_determination&gt;`_</span></div>
<div class="line"><span class="lineno">  873</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  874</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  875</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  876</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import r2_score</span></div>
<div class="line"><span class="lineno">  877</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [3, -0.5, 2, 7]</span></div>
<div class="line"><span class="lineno">  878</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2.5, 0.0, 2, 8]</span></div>
<div class="line"><span class="lineno">  879</span><span class="stringliteral">    &gt;&gt;&gt; r2_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  880</span><span class="stringliteral">    0.948...</span></div>
<div class="line"><span class="lineno">  881</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0.5, 1], [-1, 1], [7, -6]]</span></div>
<div class="line"><span class="lineno">  882</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0, 2], [-1, 2], [8, -5]]</span></div>
<div class="line"><span class="lineno">  883</span><span class="stringliteral">    &gt;&gt;&gt; r2_score(y_true, y_pred,</span></div>
<div class="line"><span class="lineno">  884</span><span class="stringliteral">    ...          multioutput=&#39;variance_weighted&#39;)</span></div>
<div class="line"><span class="lineno">  885</span><span class="stringliteral">    0.938...</span></div>
<div class="line"><span class="lineno">  886</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [1, 2, 3]</span></div>
<div class="line"><span class="lineno">  887</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [1, 2, 3]</span></div>
<div class="line"><span class="lineno">  888</span><span class="stringliteral">    &gt;&gt;&gt; r2_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  889</span><span class="stringliteral">    1.0</span></div>
<div class="line"><span class="lineno">  890</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [1, 2, 3]</span></div>
<div class="line"><span class="lineno">  891</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [2, 2, 2]</span></div>
<div class="line"><span class="lineno">  892</span><span class="stringliteral">    &gt;&gt;&gt; r2_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  893</span><span class="stringliteral">    0.0</span></div>
<div class="line"><span class="lineno">  894</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [1, 2, 3]</span></div>
<div class="line"><span class="lineno">  895</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [3, 2, 1]</span></div>
<div class="line"><span class="lineno">  896</span><span class="stringliteral">    &gt;&gt;&gt; r2_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  897</span><span class="stringliteral">    -3.0</span></div>
<div class="line"><span class="lineno">  898</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [-2, -2, -2]</span></div>
<div class="line"><span class="lineno">  899</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [-2, -2, -2]</span></div>
<div class="line"><span class="lineno">  900</span><span class="stringliteral">    &gt;&gt;&gt; r2_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  901</span><span class="stringliteral">    1.0</span></div>
<div class="line"><span class="lineno">  902</span><span class="stringliteral">    &gt;&gt;&gt; r2_score(y_true, y_pred, force_finite=False)</span></div>
<div class="line"><span class="lineno">  903</span><span class="stringliteral">    nan</span></div>
<div class="line"><span class="lineno">  904</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [-2, -2, -2]</span></div>
<div class="line"><span class="lineno">  905</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [-2, -2, -2 + 1e-8]</span></div>
<div class="line"><span class="lineno">  906</span><span class="stringliteral">    &gt;&gt;&gt; r2_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  907</span><span class="stringliteral">    0.0</span></div>
<div class="line"><span class="lineno">  908</span><span class="stringliteral">    &gt;&gt;&gt; r2_score(y_true, y_pred, force_finite=False)</span></div>
<div class="line"><span class="lineno">  909</span><span class="stringliteral">    -inf</span></div>
<div class="line"><span class="lineno">  910</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  911</span>    y_type, y_true, y_pred, multioutput = _check_reg_targets(</div>
<div class="line"><span class="lineno">  912</span>        y_true, y_pred, multioutput</div>
<div class="line"><span class="lineno">  913</span>    )</div>
<div class="line"><span class="lineno">  914</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  915</span> </div>
<div class="line"><span class="lineno">  916</span>    <span class="keywordflow">if</span> _num_samples(y_pred) &lt; 2:</div>
<div class="line"><span class="lineno">  917</span>        msg = <span class="stringliteral">&quot;R^2 score is not well-defined with less than two samples.&quot;</span></div>
<div class="line"><span class="lineno">  918</span>        warnings.warn(msg, UndefinedMetricWarning)</div>
<div class="line"><span class="lineno">  919</span>        <span class="keywordflow">return</span> float(<span class="stringliteral">&quot;nan&quot;</span>)</div>
<div class="line"><span class="lineno">  920</span> </div>
<div class="line"><span class="lineno">  921</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  922</span>        sample_weight = column_or_1d(sample_weight)</div>
<div class="line"><span class="lineno">  923</span>        weight = sample_weight[:, np.newaxis]</div>
<div class="line"><span class="lineno">  924</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  925</span>        weight = 1.0</div>
<div class="line"><span class="lineno">  926</span> </div>
<div class="line"><span class="lineno">  927</span>    numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)</div>
<div class="line"><span class="lineno">  928</span>    denominator = (</div>
<div class="line"><span class="lineno">  929</span>        weight * (y_true - np.average(y_true, axis=0, weights=sample_weight)) ** 2</div>
<div class="line"><span class="lineno">  930</span>    ).sum(axis=0, dtype=np.float64)</div>
<div class="line"><span class="lineno">  931</span> </div>
<div class="line"><span class="lineno">  932</span>    <span class="keywordflow">return</span> _assemble_r2_explained_variance(</div>
<div class="line"><span class="lineno">  933</span>        numerator=numerator,</div>
<div class="line"><span class="lineno">  934</span>        denominator=denominator,</div>
<div class="line"><span class="lineno">  935</span>        n_outputs=y_true.shape[1],</div>
<div class="line"><span class="lineno">  936</span>        multioutput=multioutput,</div>
<div class="line"><span class="lineno">  937</span>        force_finite=force_finite,</div>
<div class="line"><span class="lineno">  938</span>    )</div>
<div class="line"><span class="lineno">  939</span> </div>
<div class="line"><span class="lineno">  940</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
