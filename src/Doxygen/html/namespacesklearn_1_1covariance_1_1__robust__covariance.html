<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.covariance._robust_covariance Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1covariance.html">covariance</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1covariance_1_1__robust__covariance.html">_robust_covariance</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.covariance._robust_covariance Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1covariance_1_1__robust__covariance_1_1_min_cov_det.html">MinCovDet</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:aa2e54f478677261289bcf40c2693b24f" id="r_aa2e54f478677261289bcf40c2693b24f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1covariance_1_1__robust__covariance.html#aa2e54f478677261289bcf40c2693b24f">c_step</a> (X, n_support, remaining_iterations=30, initial_estimates=None, verbose=False, cov_computation_method=empirical_covariance, random_state=None)</td></tr>
<tr class="separator:aa2e54f478677261289bcf40c2693b24f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42dc65f873d6fd90471d5d58b2a2cf39" id="r_a42dc65f873d6fd90471d5d58b2a2cf39"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1covariance_1_1__robust__covariance.html#a42dc65f873d6fd90471d5d58b2a2cf39">_c_step</a> (X, n_support, random_state, remaining_iterations=30, initial_estimates=None, verbose=False, cov_computation_method=empirical_covariance)</td></tr>
<tr class="separator:a42dc65f873d6fd90471d5d58b2a2cf39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac23a32f73d65cd327ff1bb126f0cadfa" id="r_ac23a32f73d65cd327ff1bb126f0cadfa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1covariance_1_1__robust__covariance.html#ac23a32f73d65cd327ff1bb126f0cadfa">select_candidates</a> (X, n_support, n_trials, select=1, n_iter=30, verbose=False, cov_computation_method=empirical_covariance, random_state=None)</td></tr>
<tr class="separator:ac23a32f73d65cd327ff1bb126f0cadfa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92e74469768bec87dc8bc997e45840a2" id="r_a92e74469768bec87dc8bc997e45840a2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1covariance_1_1__robust__covariance.html#a92e74469768bec87dc8bc997e45840a2">fast_mcd</a> (X, support_fraction=None, cov_computation_method=empirical_covariance, random_state=None)</td></tr>
<tr class="separator:a92e74469768bec87dc8bc997e45840a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Robust location and covariance estimators.

Here are implemented estimators that are resistant to outliers.</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a42dc65f873d6fd90471d5d58b2a2cf39" name="a42dc65f873d6fd90471d5d58b2a2cf39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a42dc65f873d6fd90471d5d58b2a2cf39">&#9670;&#160;</a></span>_c_step()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.covariance._robust_covariance._c_step </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_support</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>remaining_iterations</em> = <code>30</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>initial_estimates</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cov_computation_method</em> = <code>empirical_covariance</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  116</span>):</div>
<div class="line"><span class="lineno">  117</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  118</span>    dist = np.inf</div>
<div class="line"><span class="lineno">  119</span> </div>
<div class="line"><span class="lineno">  120</span>    <span class="comment"># Initialisation</span></div>
<div class="line"><span class="lineno">  121</span>    support = np.zeros(n_samples, dtype=bool)</div>
<div class="line"><span class="lineno">  122</span>    <span class="keywordflow">if</span> initial_estimates <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  123</span>        <span class="comment"># compute initial robust estimates from a random subset</span></div>
<div class="line"><span class="lineno">  124</span>        support[random_state.permutation(n_samples)[:n_support]] = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  125</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  126</span>        <span class="comment"># get initial robust estimates from the function parameters</span></div>
<div class="line"><span class="lineno">  127</span>        location = initial_estimates[0]</div>
<div class="line"><span class="lineno">  128</span>        covariance = initial_estimates[1]</div>
<div class="line"><span class="lineno">  129</span>        <span class="comment"># run a special iteration for that case (to get an initial support)</span></div>
<div class="line"><span class="lineno">  130</span>        precision = linalg.pinvh(covariance)</div>
<div class="line"><span class="lineno">  131</span>        X_centered = X - location</div>
<div class="line"><span class="lineno">  132</span>        dist = (np.dot(X_centered, precision) * X_centered).sum(1)</div>
<div class="line"><span class="lineno">  133</span>        <span class="comment"># compute new estimates</span></div>
<div class="line"><span class="lineno">  134</span>        support[np.argsort(dist)[:n_support]] = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  135</span> </div>
<div class="line"><span class="lineno">  136</span>    X_support = X[support]</div>
<div class="line"><span class="lineno">  137</span>    location = X_support.mean(0)</div>
<div class="line"><span class="lineno">  138</span>    covariance = cov_computation_method(X_support)</div>
<div class="line"><span class="lineno">  139</span> </div>
<div class="line"><span class="lineno">  140</span>    <span class="comment"># Iterative procedure for Minimum Covariance Determinant computation</span></div>
<div class="line"><span class="lineno">  141</span>    det = fast_logdet(covariance)</div>
<div class="line"><span class="lineno">  142</span>    <span class="comment"># If the data already has singular covariance, calculate the precision,</span></div>
<div class="line"><span class="lineno">  143</span>    <span class="comment"># as the loop below will not be entered.</span></div>
<div class="line"><span class="lineno">  144</span>    <span class="keywordflow">if</span> np.isinf(det):</div>
<div class="line"><span class="lineno">  145</span>        precision = linalg.pinvh(covariance)</div>
<div class="line"><span class="lineno">  146</span> </div>
<div class="line"><span class="lineno">  147</span>    previous_det = np.inf</div>
<div class="line"><span class="lineno">  148</span>    <span class="keywordflow">while</span> det &lt; previous_det <span class="keywordflow">and</span> remaining_iterations &gt; 0 <span class="keywordflow">and</span> <span class="keywordflow">not</span> np.isinf(det):</div>
<div class="line"><span class="lineno">  149</span>        <span class="comment"># save old estimates values</span></div>
<div class="line"><span class="lineno">  150</span>        previous_location = location</div>
<div class="line"><span class="lineno">  151</span>        previous_covariance = covariance</div>
<div class="line"><span class="lineno">  152</span>        previous_det = det</div>
<div class="line"><span class="lineno">  153</span>        previous_support = support</div>
<div class="line"><span class="lineno">  154</span>        <span class="comment"># compute a new support from the full data set mahalanobis distances</span></div>
<div class="line"><span class="lineno">  155</span>        precision = linalg.pinvh(covariance)</div>
<div class="line"><span class="lineno">  156</span>        X_centered = X - location</div>
<div class="line"><span class="lineno">  157</span>        dist = (np.dot(X_centered, precision) * X_centered).sum(axis=1)</div>
<div class="line"><span class="lineno">  158</span>        <span class="comment"># compute new estimates</span></div>
<div class="line"><span class="lineno">  159</span>        support = np.zeros(n_samples, dtype=bool)</div>
<div class="line"><span class="lineno">  160</span>        support[np.argsort(dist)[:n_support]] = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  161</span>        X_support = X[support]</div>
<div class="line"><span class="lineno">  162</span>        location = X_support.mean(axis=0)</div>
<div class="line"><span class="lineno">  163</span>        covariance = cov_computation_method(X_support)</div>
<div class="line"><span class="lineno">  164</span>        det = fast_logdet(covariance)</div>
<div class="line"><span class="lineno">  165</span>        <span class="comment"># update remaining iterations for early stopping</span></div>
<div class="line"><span class="lineno">  166</span>        remaining_iterations -= 1</div>
<div class="line"><span class="lineno">  167</span> </div>
<div class="line"><span class="lineno">  168</span>    previous_dist = dist</div>
<div class="line"><span class="lineno">  169</span>    dist = (np.dot(X - location, precision) * (X - location)).sum(axis=1)</div>
<div class="line"><span class="lineno">  170</span>    <span class="comment"># Check if best fit already found (det =&gt; 0, logdet =&gt; -inf)</span></div>
<div class="line"><span class="lineno">  171</span>    <span class="keywordflow">if</span> np.isinf(det):</div>
<div class="line"><span class="lineno">  172</span>        results = location, covariance, det, support, dist</div>
<div class="line"><span class="lineno">  173</span>    <span class="comment"># Check convergence</span></div>
<div class="line"><span class="lineno">  174</span>    <span class="keywordflow">if</span> np.allclose(det, previous_det):</div>
<div class="line"><span class="lineno">  175</span>        <span class="comment"># c_step procedure converged</span></div>
<div class="line"><span class="lineno">  176</span>        <span class="keywordflow">if</span> verbose:</div>
<div class="line"><span class="lineno">  177</span>            print(</div>
<div class="line"><span class="lineno">  178</span>                <span class="stringliteral">&quot;Optimal couple (location, covariance) found before&quot;</span></div>
<div class="line"><span class="lineno">  179</span>                <span class="stringliteral">&quot; ending iterations (%d left)&quot;</span> % (remaining_iterations)</div>
<div class="line"><span class="lineno">  180</span>            )</div>
<div class="line"><span class="lineno">  181</span>        results = location, covariance, det, support, dist</div>
<div class="line"><span class="lineno">  182</span>    <span class="keywordflow">elif</span> det &gt; previous_det:</div>
<div class="line"><span class="lineno">  183</span>        <span class="comment"># determinant has increased (should not happen)</span></div>
<div class="line"><span class="lineno">  184</span>        warnings.warn(</div>
<div class="line"><span class="lineno">  185</span>            <span class="stringliteral">&quot;Determinant has increased; this should not happen: &quot;</span></div>
<div class="line"><span class="lineno">  186</span>            <span class="stringliteral">&quot;log(det) &gt; log(previous_det) (%.15f &gt; %.15f). &quot;</span></div>
<div class="line"><span class="lineno">  187</span>            <span class="stringliteral">&quot;You may want to try with a higher value of &quot;</span></div>
<div class="line"><span class="lineno">  188</span>            <span class="stringliteral">&quot;support_fraction (current value: %.3f).&quot;</span></div>
<div class="line"><span class="lineno">  189</span>            % (det, previous_det, n_support / n_samples),</div>
<div class="line"><span class="lineno">  190</span>            RuntimeWarning,</div>
<div class="line"><span class="lineno">  191</span>        )</div>
<div class="line"><span class="lineno">  192</span>        results = (</div>
<div class="line"><span class="lineno">  193</span>            previous_location,</div>
<div class="line"><span class="lineno">  194</span>            previous_covariance,</div>
<div class="line"><span class="lineno">  195</span>            previous_det,</div>
<div class="line"><span class="lineno">  196</span>            previous_support,</div>
<div class="line"><span class="lineno">  197</span>            previous_dist,</div>
<div class="line"><span class="lineno">  198</span>        )</div>
<div class="line"><span class="lineno">  199</span> </div>
<div class="line"><span class="lineno">  200</span>    <span class="comment"># Check early stopping</span></div>
<div class="line"><span class="lineno">  201</span>    <span class="keywordflow">if</span> remaining_iterations == 0:</div>
<div class="line"><span class="lineno">  202</span>        <span class="keywordflow">if</span> verbose:</div>
<div class="line"><span class="lineno">  203</span>            print(<span class="stringliteral">&quot;Maximum number of iterations reached&quot;</span>)</div>
<div class="line"><span class="lineno">  204</span>        results = location, covariance, det, support, dist</div>
<div class="line"><span class="lineno">  205</span> </div>
<div class="line"><span class="lineno">  206</span>    <span class="keywordflow">return</span> results</div>
<div class="line"><span class="lineno">  207</span> </div>
<div class="line"><span class="lineno">  208</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa2e54f478677261289bcf40c2693b24f" name="aa2e54f478677261289bcf40c2693b24f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa2e54f478677261289bcf40c2693b24f">&#9670;&#160;</a></span>c_step()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.covariance._robust_covariance.c_step </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_support</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>remaining_iterations</em> = <code>30</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>initial_estimates</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cov_computation_method</em> = <code>empirical_covariance</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">C_step procedure described in [Rouseeuw1984]_ aiming at computing MCD.

Parameters
----------
X : array-like of shape (n_samples, n_features)
    Data set in which we look for the n_support observations whose
    scatter matrix has minimum determinant.

n_support : int
    Number of observations to compute the robust estimates of location
    and covariance from. This parameter must be greater than
    `n_samples / 2`.

remaining_iterations : int, default=30
    Number of iterations to perform.
    According to [Rouseeuw1999]_, two iterations are sufficient to get
    close to the minimum, and we never need more than 30 to reach
    convergence.

initial_estimates : tuple of shape (2,), default=None
    Initial estimates of location and shape from which to run the c_step
    procedure:
    - initial_estimates[0]: an initial location estimate
    - initial_estimates[1]: an initial covariance estimate

verbose : bool, default=False
    Verbose mode.

cov_computation_method : callable, \
        default=:func:`sklearn.covariance.empirical_covariance`
    The function which will be used to compute the covariance.
    Must return array of shape (n_features, n_features).

random_state : int, RandomState instance or None, default=None
    Determines the pseudo random number generator for shuffling the data.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Returns
-------
location : ndarray of shape (n_features,)
    Robust location estimates.

covariance : ndarray of shape (n_features, n_features)
    Robust covariance estimates.

support : ndarray of shape (n_samples,)
    A mask for the `n_support` observations whose scatter matrix has
    minimum determinant.

References
----------
.. [Rouseeuw1999] A Fast Algorithm for the Minimum Covariance Determinant
    Estimator, 1999, American Statistical Association and the American
    Society for Quality, TECHNOMETRICS
</pre> <div class="fragment"><div class="line"><span class="lineno">   38</span>):</div>
<div class="line"><span class="lineno">   39</span>    <span class="stringliteral">&quot;&quot;&quot;C_step procedure described in [Rouseeuw1984]_ aiming at computing MCD.</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">    X : array-like of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">        Data set in which we look for the n_support observations whose</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">        scatter matrix has minimum determinant.</span></div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">    n_support : int</span></div>
<div class="line"><span class="lineno">   48</span><span class="stringliteral">        Number of observations to compute the robust estimates of location</span></div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral">        and covariance from. This parameter must be greater than</span></div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">        `n_samples / 2`.</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">    remaining_iterations : int, default=30</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">        Number of iterations to perform.</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral">        According to [Rouseeuw1999]_, two iterations are sufficient to get</span></div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">        close to the minimum, and we never need more than 30 to reach</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral">        convergence.</span></div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral">    initial_estimates : tuple of shape (2,), default=None</span></div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">        Initial estimates of location and shape from which to run the c_step</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">        procedure:</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral">        - initial_estimates[0]: an initial location estimate</span></div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">        - initial_estimates[1]: an initial covariance estimate</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    verbose : bool, default=False</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">        Verbose mode.</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    cov_computation_method : callable, \</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">            default=:func:`sklearn.covariance.empirical_covariance`</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral">        The function which will be used to compute the covariance.</span></div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">        Must return array of shape (n_features, n_features).</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">    random_state : int, RandomState instance or None, default=None</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">        Determines the pseudo random number generator for shuffling the data.</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">        Pass an int for reproducible results across multiple function calls.</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">    location : ndarray of shape (n_features,)</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">        Robust location estimates.</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">    covariance : ndarray of shape (n_features, n_features)</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">        Robust covariance estimates.</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">    support : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">        A mask for the `n_support` observations whose scatter matrix has</span></div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">        minimum determinant.</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">    .. [Rouseeuw1999] A Fast Algorithm for the Minimum Covariance Determinant</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral">        Estimator, 1999, American Statistical Association and the American</span></div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral">        Society for Quality, TECHNOMETRICS</span></div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   95</span>    X = np.asarray(X)</div>
<div class="line"><span class="lineno">   96</span>    random_state = check_random_state(random_state)</div>
<div class="line"><span class="lineno">   97</span>    <span class="keywordflow">return</span> _c_step(</div>
<div class="line"><span class="lineno">   98</span>        X,</div>
<div class="line"><span class="lineno">   99</span>        n_support,</div>
<div class="line"><span class="lineno">  100</span>        remaining_iterations=remaining_iterations,</div>
<div class="line"><span class="lineno">  101</span>        initial_estimates=initial_estimates,</div>
<div class="line"><span class="lineno">  102</span>        verbose=verbose,</div>
<div class="line"><span class="lineno">  103</span>        cov_computation_method=cov_computation_method,</div>
<div class="line"><span class="lineno">  104</span>        random_state=random_state,</div>
<div class="line"><span class="lineno">  105</span>    )</div>
<div class="line"><span class="lineno">  106</span> </div>
<div class="line"><span class="lineno">  107</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a92e74469768bec87dc8bc997e45840a2" name="a92e74469768bec87dc8bc997e45840a2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a92e74469768bec87dc8bc997e45840a2">&#9670;&#160;</a></span>fast_mcd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.covariance._robust_covariance.fast_mcd </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>support_fraction</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cov_computation_method</em> = <code>empirical_covariance</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Estimate the Minimum Covariance Determinant matrix.

Read more in the :ref:`User Guide &lt;robust_covariance&gt;`.

Parameters
----------
X : array-like of shape (n_samples, n_features)
    The data matrix, with p features and n samples.

support_fraction : float, default=None
    The proportion of points to be included in the support of the raw
    MCD estimate. Default is `None`, which implies that the minimum
    value of `support_fraction` will be used within the algorithm:
    `(n_sample + n_features + 1) / 2`. This parameter must be in the
    range (0, 1).

cov_computation_method : callable, \
        default=:func:`sklearn.covariance.empirical_covariance`
    The function which will be used to compute the covariance.
    Must return an array of shape (n_features, n_features).

random_state : int, RandomState instance or None, default=None
    Determines the pseudo random number generator for shuffling the data.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Returns
-------
location : ndarray of shape (n_features,)
    Robust location of the data.

covariance : ndarray of shape (n_features, n_features)
    Robust covariance of the features.

support : ndarray of shape (n_samples,), dtype=bool
    A mask of the observations that have been used to compute
    the robust location and covariance estimates of the data set.

Notes
-----
The FastMCD algorithm has been introduced by Rousseuw and Van Driessen
in "A Fast Algorithm for the Minimum Covariance Determinant Estimator,
1999, American Statistical Association and the American Society
for Quality, TECHNOMETRICS".
The principle is to compute robust estimates and random subsets before
pooling them into a larger subsets, and finally into the full data set.
Depending on the size of the initial sample, we have one, two or three
such computation levels.

Note that only raw estimates are returned. If one is interested in
the correction and reweighting steps described in [RouseeuwVan]_,
see the MinCovDet object.

References
----------

.. [RouseeuwVan] A Fast Algorithm for the Minimum Covariance
    Determinant Estimator, 1999, American Statistical Association
    and the American Society for Quality, TECHNOMETRICS

.. [Butler1993] R. W. Butler, P. L. Davies and M. Jhun,
    Asymptotics For The Minimum Covariance Determinant Estimator,
    The Annals of Statistics, 1993, Vol. 21, No. 3, 1385-1400
</pre> <div class="fragment"><div class="line"><span class="lineno">  360</span>):</div>
<div class="line"><span class="lineno">  361</span>    <span class="stringliteral">&quot;&quot;&quot;Estimate the Minimum Covariance Determinant matrix.</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  363</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;robust_covariance&gt;`.</span></div>
<div class="line"><span class="lineno">  364</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  365</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  366</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  367</span><span class="stringliteral">    X : array-like of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  368</span><span class="stringliteral">        The data matrix, with p features and n samples.</span></div>
<div class="line"><span class="lineno">  369</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  370</span><span class="stringliteral">    support_fraction : float, default=None</span></div>
<div class="line"><span class="lineno">  371</span><span class="stringliteral">        The proportion of points to be included in the support of the raw</span></div>
<div class="line"><span class="lineno">  372</span><span class="stringliteral">        MCD estimate. Default is `None`, which implies that the minimum</span></div>
<div class="line"><span class="lineno">  373</span><span class="stringliteral">        value of `support_fraction` will be used within the algorithm:</span></div>
<div class="line"><span class="lineno">  374</span><span class="stringliteral">        `(n_sample + n_features + 1) / 2`. This parameter must be in the</span></div>
<div class="line"><span class="lineno">  375</span><span class="stringliteral">        range (0, 1).</span></div>
<div class="line"><span class="lineno">  376</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  377</span><span class="stringliteral">    cov_computation_method : callable, \</span></div>
<div class="line"><span class="lineno">  378</span><span class="stringliteral">            default=:func:`sklearn.covariance.empirical_covariance`</span></div>
<div class="line"><span class="lineno">  379</span><span class="stringliteral">        The function which will be used to compute the covariance.</span></div>
<div class="line"><span class="lineno">  380</span><span class="stringliteral">        Must return an array of shape (n_features, n_features).</span></div>
<div class="line"><span class="lineno">  381</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  382</span><span class="stringliteral">    random_state : int, RandomState instance or None, default=None</span></div>
<div class="line"><span class="lineno">  383</span><span class="stringliteral">        Determines the pseudo random number generator for shuffling the data.</span></div>
<div class="line"><span class="lineno">  384</span><span class="stringliteral">        Pass an int for reproducible results across multiple function calls.</span></div>
<div class="line"><span class="lineno">  385</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  386</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  387</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  388</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  389</span><span class="stringliteral">    location : ndarray of shape (n_features,)</span></div>
<div class="line"><span class="lineno">  390</span><span class="stringliteral">        Robust location of the data.</span></div>
<div class="line"><span class="lineno">  391</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  392</span><span class="stringliteral">    covariance : ndarray of shape (n_features, n_features)</span></div>
<div class="line"><span class="lineno">  393</span><span class="stringliteral">        Robust covariance of the features.</span></div>
<div class="line"><span class="lineno">  394</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  395</span><span class="stringliteral">    support : ndarray of shape (n_samples,), dtype=bool</span></div>
<div class="line"><span class="lineno">  396</span><span class="stringliteral">        A mask of the observations that have been used to compute</span></div>
<div class="line"><span class="lineno">  397</span><span class="stringliteral">        the robust location and covariance estimates of the data set.</span></div>
<div class="line"><span class="lineno">  398</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  399</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  400</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral">    The FastMCD algorithm has been introduced by Rousseuw and Van Driessen</span></div>
<div class="line"><span class="lineno">  402</span><span class="stringliteral">    in &quot;A Fast Algorithm for the Minimum Covariance Determinant Estimator,</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral">    1999, American Statistical Association and the American Society</span></div>
<div class="line"><span class="lineno">  404</span><span class="stringliteral">    for Quality, TECHNOMETRICS&quot;.</span></div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral">    The principle is to compute robust estimates and random subsets before</span></div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">    pooling them into a larger subsets, and finally into the full data set.</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral">    Depending on the size of the initial sample, we have one, two or three</span></div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral">    such computation levels.</span></div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral">    Note that only raw estimates are returned. If one is interested in</span></div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral">    the correction and reweighting steps described in [RouseeuwVan]_,</span></div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral">    see the MinCovDet object.</span></div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  414</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  415</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral">    .. [RouseeuwVan] A Fast Algorithm for the Minimum Covariance</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">        Determinant Estimator, 1999, American Statistical Association</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">        and the American Society for Quality, TECHNOMETRICS</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  421</span><span class="stringliteral">    .. [Butler1993] R. W. Butler, P. L. Davies and M. Jhun,</span></div>
<div class="line"><span class="lineno">  422</span><span class="stringliteral">        Asymptotics For The Minimum Covariance Determinant Estimator,</span></div>
<div class="line"><span class="lineno">  423</span><span class="stringliteral">        The Annals of Statistics, 1993, Vol. 21, No. 3, 1385-1400</span></div>
<div class="line"><span class="lineno">  424</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  425</span>    random_state = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  426</span> </div>
<div class="line"><span class="lineno">  427</span>    X = check_array(X, ensure_min_samples=2, estimator=<span class="stringliteral">&quot;fast_mcd&quot;</span>)</div>
<div class="line"><span class="lineno">  428</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  429</span> </div>
<div class="line"><span class="lineno">  430</span>    <span class="comment"># minimum breakdown value</span></div>
<div class="line"><span class="lineno">  431</span>    <span class="keywordflow">if</span> support_fraction <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  432</span>        n_support = int(np.ceil(0.5 * (n_samples + n_features + 1)))</div>
<div class="line"><span class="lineno">  433</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  434</span>        n_support = int(support_fraction * n_samples)</div>
<div class="line"><span class="lineno">  435</span> </div>
<div class="line"><span class="lineno">  436</span>    <span class="comment"># 1-dimensional case quick computation</span></div>
<div class="line"><span class="lineno">  437</span>    <span class="comment"># (Rousseeuw, P. J. and Leroy, A. M. (2005) References, in Robust</span></div>
<div class="line"><span class="lineno">  438</span>    <span class="comment">#  Regression and Outlier Detection, John Wiley &amp; Sons, chapter 4)</span></div>
<div class="line"><span class="lineno">  439</span>    <span class="keywordflow">if</span> n_features == 1:</div>
<div class="line"><span class="lineno">  440</span>        <span class="keywordflow">if</span> n_support &lt; n_samples:</div>
<div class="line"><span class="lineno">  441</span>            <span class="comment"># find the sample shortest halves</span></div>
<div class="line"><span class="lineno">  442</span>            X_sorted = np.sort(np.ravel(X))</div>
<div class="line"><span class="lineno">  443</span>            diff = X_sorted[n_support:] - X_sorted[: (n_samples - n_support)]</div>
<div class="line"><span class="lineno">  444</span>            halves_start = np.where(diff == np.min(diff))[0]</div>
<div class="line"><span class="lineno">  445</span>            <span class="comment"># take the middle points&#39; mean to get the robust location estimate</span></div>
<div class="line"><span class="lineno">  446</span>            location = (</div>
<div class="line"><span class="lineno">  447</span>                0.5</div>
<div class="line"><span class="lineno">  448</span>                * (X_sorted[n_support + halves_start] + X_sorted[halves_start]).mean()</div>
<div class="line"><span class="lineno">  449</span>            )</div>
<div class="line"><span class="lineno">  450</span>            support = np.zeros(n_samples, dtype=bool)</div>
<div class="line"><span class="lineno">  451</span>            X_centered = X - location</div>
<div class="line"><span class="lineno">  452</span>            support[np.argsort(np.abs(X_centered), 0)[:n_support]] = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  453</span>            covariance = np.asarray([[np.var(X[support])]])</div>
<div class="line"><span class="lineno">  454</span>            location = np.array([location])</div>
<div class="line"><span class="lineno">  455</span>            <span class="comment"># get precision matrix in an optimized way</span></div>
<div class="line"><span class="lineno">  456</span>            precision = linalg.pinvh(covariance)</div>
<div class="line"><span class="lineno">  457</span>            dist = (np.dot(X_centered, precision) * (X_centered)).sum(axis=1)</div>
<div class="line"><span class="lineno">  458</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  459</span>            support = np.ones(n_samples, dtype=bool)</div>
<div class="line"><span class="lineno">  460</span>            covariance = np.asarray([[np.var(X)]])</div>
<div class="line"><span class="lineno">  461</span>            location = np.asarray([np.mean(X)])</div>
<div class="line"><span class="lineno">  462</span>            X_centered = X - location</div>
<div class="line"><span class="lineno">  463</span>            <span class="comment"># get precision matrix in an optimized way</span></div>
<div class="line"><span class="lineno">  464</span>            precision = linalg.pinvh(covariance)</div>
<div class="line"><span class="lineno">  465</span>            dist = (np.dot(X_centered, precision) * (X_centered)).sum(axis=1)</div>
<div class="line"><span class="lineno">  466</span>    <span class="comment"># Starting FastMCD algorithm for p-dimensional case</span></div>
<div class="line"><span class="lineno">  467</span>    <span class="keywordflow">if</span> (n_samples &gt; 500) <span class="keywordflow">and</span> (n_features &gt; 1):</div>
<div class="line"><span class="lineno">  468</span>        <span class="comment"># 1. Find candidate supports on subsets</span></div>
<div class="line"><span class="lineno">  469</span>        <span class="comment"># a. split the set in subsets of size ~ 300</span></div>
<div class="line"><span class="lineno">  470</span>        n_subsets = n_samples // 300</div>
<div class="line"><span class="lineno">  471</span>        n_samples_subsets = n_samples // n_subsets</div>
<div class="line"><span class="lineno">  472</span>        samples_shuffle = random_state.permutation(n_samples)</div>
<div class="line"><span class="lineno">  473</span>        h_subset = int(np.ceil(n_samples_subsets * (n_support / float(n_samples))))</div>
<div class="line"><span class="lineno">  474</span>        <span class="comment"># b. perform a total of 500 trials</span></div>
<div class="line"><span class="lineno">  475</span>        n_trials_tot = 500</div>
<div class="line"><span class="lineno">  476</span>        <span class="comment"># c. select 10 best (location, covariance) for each subset</span></div>
<div class="line"><span class="lineno">  477</span>        n_best_sub = 10</div>
<div class="line"><span class="lineno">  478</span>        n_trials = max(10, n_trials_tot // n_subsets)</div>
<div class="line"><span class="lineno">  479</span>        n_best_tot = n_subsets * n_best_sub</div>
<div class="line"><span class="lineno">  480</span>        all_best_locations = np.zeros((n_best_tot, n_features))</div>
<div class="line"><span class="lineno">  481</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  482</span>            all_best_covariances = np.zeros((n_best_tot, n_features, n_features))</div>
<div class="line"><span class="lineno">  483</span>        <span class="keywordflow">except</span> MemoryError:</div>
<div class="line"><span class="lineno">  484</span>            <span class="comment"># The above is too big. Let&#39;s try with something much small</span></div>
<div class="line"><span class="lineno">  485</span>            <span class="comment"># (and less optimal)</span></div>
<div class="line"><span class="lineno">  486</span>            n_best_tot = 10</div>
<div class="line"><span class="lineno">  487</span>            all_best_covariances = np.zeros((n_best_tot, n_features, n_features))</div>
<div class="line"><span class="lineno">  488</span>            n_best_sub = 2</div>
<div class="line"><span class="lineno">  489</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(n_subsets):</div>
<div class="line"><span class="lineno">  490</span>            low_bound = i * n_samples_subsets</div>
<div class="line"><span class="lineno">  491</span>            high_bound = low_bound + n_samples_subsets</div>
<div class="line"><span class="lineno">  492</span>            current_subset = X[samples_shuffle[low_bound:high_bound]]</div>
<div class="line"><span class="lineno">  493</span>            best_locations_sub, best_covariances_sub, _, _ = select_candidates(</div>
<div class="line"><span class="lineno">  494</span>                current_subset,</div>
<div class="line"><span class="lineno">  495</span>                h_subset,</div>
<div class="line"><span class="lineno">  496</span>                n_trials,</div>
<div class="line"><span class="lineno">  497</span>                select=n_best_sub,</div>
<div class="line"><span class="lineno">  498</span>                n_iter=2,</div>
<div class="line"><span class="lineno">  499</span>                cov_computation_method=cov_computation_method,</div>
<div class="line"><span class="lineno">  500</span>                random_state=random_state,</div>
<div class="line"><span class="lineno">  501</span>            )</div>
<div class="line"><span class="lineno">  502</span>            subset_slice = np.arange(i * n_best_sub, (i + 1) * n_best_sub)</div>
<div class="line"><span class="lineno">  503</span>            all_best_locations[subset_slice] = best_locations_sub</div>
<div class="line"><span class="lineno">  504</span>            all_best_covariances[subset_slice] = best_covariances_sub</div>
<div class="line"><span class="lineno">  505</span>        <span class="comment"># 2. Pool the candidate supports into a merged set</span></div>
<div class="line"><span class="lineno">  506</span>        <span class="comment"># (possibly the full dataset)</span></div>
<div class="line"><span class="lineno">  507</span>        n_samples_merged = min(1500, n_samples)</div>
<div class="line"><span class="lineno">  508</span>        h_merged = int(np.ceil(n_samples_merged * (n_support / float(n_samples))))</div>
<div class="line"><span class="lineno">  509</span>        <span class="keywordflow">if</span> n_samples &gt; 1500:</div>
<div class="line"><span class="lineno">  510</span>            n_best_merged = 10</div>
<div class="line"><span class="lineno">  511</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  512</span>            n_best_merged = 1</div>
<div class="line"><span class="lineno">  513</span>        <span class="comment"># find the best couples (location, covariance) on the merged set</span></div>
<div class="line"><span class="lineno">  514</span>        selection = random_state.permutation(n_samples)[:n_samples_merged]</div>
<div class="line"><span class="lineno">  515</span>        locations_merged, covariances_merged, supports_merged, d = select_candidates(</div>
<div class="line"><span class="lineno">  516</span>            X[selection],</div>
<div class="line"><span class="lineno">  517</span>            h_merged,</div>
<div class="line"><span class="lineno">  518</span>            n_trials=(all_best_locations, all_best_covariances),</div>
<div class="line"><span class="lineno">  519</span>            select=n_best_merged,</div>
<div class="line"><span class="lineno">  520</span>            cov_computation_method=cov_computation_method,</div>
<div class="line"><span class="lineno">  521</span>            random_state=random_state,</div>
<div class="line"><span class="lineno">  522</span>        )</div>
<div class="line"><span class="lineno">  523</span>        <span class="comment"># 3. Finally get the overall best (locations, covariance) couple</span></div>
<div class="line"><span class="lineno">  524</span>        <span class="keywordflow">if</span> n_samples &lt; 1500:</div>
<div class="line"><span class="lineno">  525</span>            <span class="comment"># directly get the best couple (location, covariance)</span></div>
<div class="line"><span class="lineno">  526</span>            location = locations_merged[0]</div>
<div class="line"><span class="lineno">  527</span>            covariance = covariances_merged[0]</div>
<div class="line"><span class="lineno">  528</span>            support = np.zeros(n_samples, dtype=bool)</div>
<div class="line"><span class="lineno">  529</span>            dist = np.zeros(n_samples)</div>
<div class="line"><span class="lineno">  530</span>            support[selection] = supports_merged[0]</div>
<div class="line"><span class="lineno">  531</span>            dist[selection] = d[0]</div>
<div class="line"><span class="lineno">  532</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  533</span>            <span class="comment"># select the best couple on the full dataset</span></div>
<div class="line"><span class="lineno">  534</span>            locations_full, covariances_full, supports_full, d = select_candidates(</div>
<div class="line"><span class="lineno">  535</span>                X,</div>
<div class="line"><span class="lineno">  536</span>                n_support,</div>
<div class="line"><span class="lineno">  537</span>                n_trials=(locations_merged, covariances_merged),</div>
<div class="line"><span class="lineno">  538</span>                select=1,</div>
<div class="line"><span class="lineno">  539</span>                cov_computation_method=cov_computation_method,</div>
<div class="line"><span class="lineno">  540</span>                random_state=random_state,</div>
<div class="line"><span class="lineno">  541</span>            )</div>
<div class="line"><span class="lineno">  542</span>            location = locations_full[0]</div>
<div class="line"><span class="lineno">  543</span>            covariance = covariances_full[0]</div>
<div class="line"><span class="lineno">  544</span>            support = supports_full[0]</div>
<div class="line"><span class="lineno">  545</span>            dist = d[0]</div>
<div class="line"><span class="lineno">  546</span>    <span class="keywordflow">elif</span> n_features &gt; 1:</div>
<div class="line"><span class="lineno">  547</span>        <span class="comment"># 1. Find the 10 best couples (location, covariance)</span></div>
<div class="line"><span class="lineno">  548</span>        <span class="comment"># considering two iterations</span></div>
<div class="line"><span class="lineno">  549</span>        n_trials = 30</div>
<div class="line"><span class="lineno">  550</span>        n_best = 10</div>
<div class="line"><span class="lineno">  551</span>        locations_best, covariances_best, _, _ = select_candidates(</div>
<div class="line"><span class="lineno">  552</span>            X,</div>
<div class="line"><span class="lineno">  553</span>            n_support,</div>
<div class="line"><span class="lineno">  554</span>            n_trials=n_trials,</div>
<div class="line"><span class="lineno">  555</span>            select=n_best,</div>
<div class="line"><span class="lineno">  556</span>            n_iter=2,</div>
<div class="line"><span class="lineno">  557</span>            cov_computation_method=cov_computation_method,</div>
<div class="line"><span class="lineno">  558</span>            random_state=random_state,</div>
<div class="line"><span class="lineno">  559</span>        )</div>
<div class="line"><span class="lineno">  560</span>        <span class="comment"># 2. Select the best couple on the full dataset amongst the 10</span></div>
<div class="line"><span class="lineno">  561</span>        locations_full, covariances_full, supports_full, d = select_candidates(</div>
<div class="line"><span class="lineno">  562</span>            X,</div>
<div class="line"><span class="lineno">  563</span>            n_support,</div>
<div class="line"><span class="lineno">  564</span>            n_trials=(locations_best, covariances_best),</div>
<div class="line"><span class="lineno">  565</span>            select=1,</div>
<div class="line"><span class="lineno">  566</span>            cov_computation_method=cov_computation_method,</div>
<div class="line"><span class="lineno">  567</span>            random_state=random_state,</div>
<div class="line"><span class="lineno">  568</span>        )</div>
<div class="line"><span class="lineno">  569</span>        location = locations_full[0]</div>
<div class="line"><span class="lineno">  570</span>        covariance = covariances_full[0]</div>
<div class="line"><span class="lineno">  571</span>        support = supports_full[0]</div>
<div class="line"><span class="lineno">  572</span>        dist = d[0]</div>
<div class="line"><span class="lineno">  573</span> </div>
<div class="line"><span class="lineno">  574</span>    <span class="keywordflow">return</span> location, covariance, support, dist</div>
<div class="line"><span class="lineno">  575</span> </div>
<div class="line"><span class="lineno">  576</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac23a32f73d65cd327ff1bb126f0cadfa" name="ac23a32f73d65cd327ff1bb126f0cadfa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac23a32f73d65cd327ff1bb126f0cadfa">&#9670;&#160;</a></span>select_candidates()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.covariance._robust_covariance.select_candidates </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_support</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_trials</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>select</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_iter</em> = <code>30</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cov_computation_method</em> = <code>empirical_covariance</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Finds the best pure subset of observations to compute MCD from it.

The purpose of this function is to find the best sets of n_support
observations with respect to a minimization of their covariance
matrix determinant. Equivalently, it removes n_samples-n_support
observations to construct what we call a pure data set (i.e. not
containing outliers). The list of the observations of the pure
data set is referred to as the `support`.

Starting from a random support, the pure data set is found by the
c_step procedure introduced by Rousseeuw and Van Driessen in
[RV]_.

Parameters
----------
X : array-like of shape (n_samples, n_features)
    Data (sub)set in which we look for the n_support purest observations.

n_support : int
    The number of samples the pure data set must contain.
    This parameter must be in the range `[(n + p + 1)/2] &lt; n_support &lt; n`.

n_trials : int or tuple of shape (2,)
    Number of different initial sets of observations from which to
    run the algorithm. This parameter should be a strictly positive
    integer.
    Instead of giving a number of trials to perform, one can provide a
    list of initial estimates that will be used to iteratively run
    c_step procedures. In this case:
    - n_trials[0]: array-like, shape (n_trials, n_features)
      is the list of `n_trials` initial location estimates
    - n_trials[1]: array-like, shape (n_trials, n_features, n_features)
      is the list of `n_trials` initial covariances estimates

select : int, default=1
    Number of best candidates results to return. This parameter must be
    a strictly positive integer.

n_iter : int, default=30
    Maximum number of iterations for the c_step procedure.
    (2 is enough to be close to the final solution. "Never" exceeds 20).
    This parameter must be a strictly positive integer.

verbose : bool, default=False
    Control the output verbosity.

cov_computation_method : callable, \
        default=:func:`sklearn.covariance.empirical_covariance`
    The function which will be used to compute the covariance.
    Must return an array of shape (n_features, n_features).

random_state : int, RandomState instance or None, default=None
    Determines the pseudo random number generator for shuffling the data.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

See Also
---------
c_step

Returns
-------
best_locations : ndarray of shape (select, n_features)
    The `select` location estimates computed from the `select` best
    supports found in the data set (`X`).

best_covariances : ndarray of shape (select, n_features, n_features)
    The `select` covariance estimates computed from the `select`
    best supports found in the data set (`X`).

best_supports : ndarray of shape (select, n_samples)
    The `select` best supports found in the data set (`X`).

References
----------
.. [RV] A Fast Algorithm for the Minimum Covariance Determinant
    Estimator, 1999, American Statistical Association and the American
    Society for Quality, TECHNOMETRICS
</pre> <div class="fragment"><div class="line"><span class="lineno">  218</span>):</div>
<div class="line"><span class="lineno">  219</span>    <span class="stringliteral">&quot;&quot;&quot;Finds the best pure subset of observations to compute MCD from it.</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">    The purpose of this function is to find the best sets of n_support</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">    observations with respect to a minimization of their covariance</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">    matrix determinant. Equivalently, it removes n_samples-n_support</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">    observations to construct what we call a pure data set (i.e. not</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">    containing outliers). The list of the observations of the pure</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">    data set is referred to as the `support`.</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">    Starting from a random support, the pure data set is found by the</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">    c_step procedure introduced by Rousseeuw and Van Driessen in</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">    [RV]_.</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">    X : array-like of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">        Data (sub)set in which we look for the n_support purest observations.</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">    n_support : int</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">        The number of samples the pure data set must contain.</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        This parameter must be in the range `[(n + p + 1)/2] &lt; n_support &lt; n`.</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">    n_trials : int or tuple of shape (2,)</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">        Number of different initial sets of observations from which to</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">        run the algorithm. This parameter should be a strictly positive</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">        integer.</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">        Instead of giving a number of trials to perform, one can provide a</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">        list of initial estimates that will be used to iteratively run</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">        c_step procedures. In this case:</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">        - n_trials[0]: array-like, shape (n_trials, n_features)</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">          is the list of `n_trials` initial location estimates</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">        - n_trials[1]: array-like, shape (n_trials, n_features, n_features)</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">          is the list of `n_trials` initial covariances estimates</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">    select : int, default=1</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">        Number of best candidates results to return. This parameter must be</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">        a strictly positive integer.</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">    n_iter : int, default=30</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">        Maximum number of iterations for the c_step procedure.</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">        (2 is enough to be close to the final solution. &quot;Never&quot; exceeds 20).</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">        This parameter must be a strictly positive integer.</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">    verbose : bool, default=False</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">        Control the output verbosity.</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">    cov_computation_method : callable, \</span></div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">            default=:func:`sklearn.covariance.empirical_covariance`</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">        The function which will be used to compute the covariance.</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">        Must return an array of shape (n_features, n_features).</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">    random_state : int, RandomState instance or None, default=None</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">        Determines the pseudo random number generator for shuffling the data.</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral">        Pass an int for reproducible results across multiple function calls.</span></div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">    ---------</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral">    c_step</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    best_locations : ndarray of shape (select, n_features)</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">        The `select` location estimates computed from the `select` best</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">        supports found in the data set (`X`).</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">    best_covariances : ndarray of shape (select, n_features, n_features)</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">        The `select` covariance estimates computed from the `select`</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">        best supports found in the data set (`X`).</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">    best_supports : ndarray of shape (select, n_samples)</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">        The `select` best supports found in the data set (`X`).</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">    .. [RV] A Fast Algorithm for the Minimum Covariance Determinant</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">        Estimator, 1999, American Statistical Association and the American</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">        Society for Quality, TECHNOMETRICS</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  298</span>    random_state = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  299</span> </div>
<div class="line"><span class="lineno">  300</span>    <span class="keywordflow">if</span> isinstance(n_trials, Integral):</div>
<div class="line"><span class="lineno">  301</span>        run_from_estimates = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  302</span>    <span class="keywordflow">elif</span> isinstance(n_trials, tuple):</div>
<div class="line"><span class="lineno">  303</span>        run_from_estimates = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  304</span>        estimates_list = n_trials</div>
<div class="line"><span class="lineno">  305</span>        n_trials = estimates_list[0].shape[0]</div>
<div class="line"><span class="lineno">  306</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  307</span>        <span class="keywordflow">raise</span> TypeError(</div>
<div class="line"><span class="lineno">  308</span>            <span class="stringliteral">&quot;Invalid &#39;n_trials&#39; parameter, expected tuple or  integer, got %s (%s)&quot;</span></div>
<div class="line"><span class="lineno">  309</span>            % (n_trials, type(n_trials))</div>
<div class="line"><span class="lineno">  310</span>        )</div>
<div class="line"><span class="lineno">  311</span> </div>
<div class="line"><span class="lineno">  312</span>    <span class="comment"># compute `n_trials` location and shape estimates candidates in the subset</span></div>
<div class="line"><span class="lineno">  313</span>    all_estimates = []</div>
<div class="line"><span class="lineno">  314</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> run_from_estimates:</div>
<div class="line"><span class="lineno">  315</span>        <span class="comment"># perform `n_trials` computations from random initial supports</span></div>
<div class="line"><span class="lineno">  316</span>        <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(n_trials):</div>
<div class="line"><span class="lineno">  317</span>            all_estimates.append(</div>
<div class="line"><span class="lineno">  318</span>                _c_step(</div>
<div class="line"><span class="lineno">  319</span>                    X,</div>
<div class="line"><span class="lineno">  320</span>                    n_support,</div>
<div class="line"><span class="lineno">  321</span>                    remaining_iterations=n_iter,</div>
<div class="line"><span class="lineno">  322</span>                    verbose=verbose,</div>
<div class="line"><span class="lineno">  323</span>                    cov_computation_method=cov_computation_method,</div>
<div class="line"><span class="lineno">  324</span>                    random_state=random_state,</div>
<div class="line"><span class="lineno">  325</span>                )</div>
<div class="line"><span class="lineno">  326</span>            )</div>
<div class="line"><span class="lineno">  327</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  328</span>        <span class="comment"># perform computations from every given initial estimates</span></div>
<div class="line"><span class="lineno">  329</span>        <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(n_trials):</div>
<div class="line"><span class="lineno">  330</span>            initial_estimates = (estimates_list[0][j], estimates_list[1][j])</div>
<div class="line"><span class="lineno">  331</span>            all_estimates.append(</div>
<div class="line"><span class="lineno">  332</span>                _c_step(</div>
<div class="line"><span class="lineno">  333</span>                    X,</div>
<div class="line"><span class="lineno">  334</span>                    n_support,</div>
<div class="line"><span class="lineno">  335</span>                    remaining_iterations=n_iter,</div>
<div class="line"><span class="lineno">  336</span>                    initial_estimates=initial_estimates,</div>
<div class="line"><span class="lineno">  337</span>                    verbose=verbose,</div>
<div class="line"><span class="lineno">  338</span>                    cov_computation_method=cov_computation_method,</div>
<div class="line"><span class="lineno">  339</span>                    random_state=random_state,</div>
<div class="line"><span class="lineno">  340</span>                )</div>
<div class="line"><span class="lineno">  341</span>            )</div>
<div class="line"><span class="lineno">  342</span>    all_locs_sub, all_covs_sub, all_dets_sub, all_supports_sub, all_ds_sub = zip(</div>
<div class="line"><span class="lineno">  343</span>        *all_estimates</div>
<div class="line"><span class="lineno">  344</span>    )</div>
<div class="line"><span class="lineno">  345</span>    <span class="comment"># find the `n_best` best results among the `n_trials` ones</span></div>
<div class="line"><span class="lineno">  346</span>    index_best = np.argsort(all_dets_sub)[:select]</div>
<div class="line"><span class="lineno">  347</span>    best_locations = np.asarray(all_locs_sub)[index_best]</div>
<div class="line"><span class="lineno">  348</span>    best_covariances = np.asarray(all_covs_sub)[index_best]</div>
<div class="line"><span class="lineno">  349</span>    best_supports = np.asarray(all_supports_sub)[index_best]</div>
<div class="line"><span class="lineno">  350</span>    best_ds = np.asarray(all_ds_sub)[index_best]</div>
<div class="line"><span class="lineno">  351</span> </div>
<div class="line"><span class="lineno">  352</span>    <span class="keywordflow">return</span> best_locations, best_covariances, best_supports, best_ds</div>
<div class="line"><span class="lineno">  353</span> </div>
<div class="line"><span class="lineno">  354</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
