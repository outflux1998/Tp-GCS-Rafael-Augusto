<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.linear_model._base Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model.html">linear_model</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model_1_1__base.html">_base</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.linear_model._base Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__base_1_1_linear_classifier_mixin.html">LinearClassifierMixin</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__base_1_1_linear_model.html">LinearModel</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__base_1_1_linear_regression.html">LinearRegression</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__base_1_1_sparse_coef_mixin.html">SparseCoefMixin</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ad3232000af0163df40a2acff69f316ff" id="r_ad3232000af0163df40a2acff69f316ff"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__base.html#ad3232000af0163df40a2acff69f316ff">_deprecate_normalize</a> (normalize, estimator_name)</td></tr>
<tr class="separator:ad3232000af0163df40a2acff69f316ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc94508f025e1cab4a1cc91a0bc64a11" id="r_abc94508f025e1cab4a1cc91a0bc64a11"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__base.html#abc94508f025e1cab4a1cc91a0bc64a11">make_dataset</a> (X, y, sample_weight, random_state=None)</td></tr>
<tr class="separator:abc94508f025e1cab4a1cc91a0bc64a11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4b9eb3d9bc4a6a892e01324db3cccb3" id="r_ae4b9eb3d9bc4a6a892e01324db3cccb3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__base.html#ae4b9eb3d9bc4a6a892e01324db3cccb3">_preprocess_data</a> (X, y, fit_intercept, normalize=False, copy=True, sample_weight=None, check_input=True)</td></tr>
<tr class="separator:ae4b9eb3d9bc4a6a892e01324db3cccb3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac831f308a59ecc27cd6c16f2c90b0a4f" id="r_ac831f308a59ecc27cd6c16f2c90b0a4f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__base.html#ac831f308a59ecc27cd6c16f2c90b0a4f">_rescale_data</a> (X, y, sample_weight)</td></tr>
<tr class="separator:ac831f308a59ecc27cd6c16f2c90b0a4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fd083594cbdcd35e3a5b15633bbd395" id="r_a7fd083594cbdcd35e3a5b15633bbd395"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__base.html#a7fd083594cbdcd35e3a5b15633bbd395">_check_precomputed_gram_matrix</a> (X, precompute, X_offset, X_scale, <a class="el" href="__lapack__subroutines_8h.html#aa4a017e91ee751f9803a1bdb6caf1c06">rtol</a>=None, atol=1e-5)</td></tr>
<tr class="separator:a7fd083594cbdcd35e3a5b15633bbd395"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad73033d93ae46098a1c2be701dfb2b65" id="r_ad73033d93ae46098a1c2be701dfb2b65"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__base.html#ad73033d93ae46098a1c2be701dfb2b65">_pre_fit</a> (X, y, Xy, precompute, normalize, fit_intercept, copy, check_input=True, sample_weight=None)</td></tr>
<tr class="separator:ad73033d93ae46098a1c2be701dfb2b65"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:aa160fd961899aaff36932501ec6610cb" id="r_aa160fd961899aaff36932501ec6610cb"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__base.html#aa160fd961899aaff36932501ec6610cb">SPARSE_INTERCEPT_DECAY</a> = 0.01</td></tr>
<tr class="separator:aa160fd961899aaff36932501ec6610cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Generalized Linear Models.
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a7fd083594cbdcd35e3a5b15633bbd395" name="a7fd083594cbdcd35e3a5b15633bbd395"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fd083594cbdcd35e3a5b15633bbd395">&#9670;&#160;</a></span>_check_precomputed_gram_matrix()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._base._check_precomputed_gram_matrix </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>precompute</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rtol</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>atol</em> = <code>1e-5</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Computes a single element of the gram matrix and compares it to
the corresponding element of the user supplied gram matrix.

If the values do not match a ValueError will be thrown.

Parameters
----------
X : ndarray of shape (n_samples, n_features)
    Data array.

precompute : array-like of shape (n_features, n_features)
    User-supplied gram matrix.

X_offset : ndarray of shape (n_features,)
    Array of feature means used to center design matrix.

X_scale : ndarray of shape (n_features,)
    Array of feature scale factors used to normalize design matrix.

rtol : float, default=None
    Relative tolerance; see numpy.allclose
    If None, it is set to 1e-4 for arrays of dtype numpy.float32 and 1e-7
    otherwise.

atol : float, default=1e-5
    absolute tolerance; see :func`numpy.allclose`. Note that the default
    here is more tolerant than the default for
    :func:`numpy.testing.assert_allclose`, where `atol=0`.

Raises
------
ValueError
    Raised when the provided Gram matrix is not consistent.
</pre> <div class="fragment"><div class="line"><span class="lineno">  711</span>):</div>
<div class="line"><span class="lineno">  712</span>    <span class="stringliteral">&quot;&quot;&quot;Computes a single element of the gram matrix and compares it to</span></div>
<div class="line"><span class="lineno">  713</span><span class="stringliteral">    the corresponding element of the user supplied gram matrix.</span></div>
<div class="line"><span class="lineno">  714</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  715</span><span class="stringliteral">    If the values do not match a ValueError will be thrown.</span></div>
<div class="line"><span class="lineno">  716</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  717</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  718</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  719</span><span class="stringliteral">    X : ndarray of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  720</span><span class="stringliteral">        Data array.</span></div>
<div class="line"><span class="lineno">  721</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  722</span><span class="stringliteral">    precompute : array-like of shape (n_features, n_features)</span></div>
<div class="line"><span class="lineno">  723</span><span class="stringliteral">        User-supplied gram matrix.</span></div>
<div class="line"><span class="lineno">  724</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  725</span><span class="stringliteral">    X_offset : ndarray of shape (n_features,)</span></div>
<div class="line"><span class="lineno">  726</span><span class="stringliteral">        Array of feature means used to center design matrix.</span></div>
<div class="line"><span class="lineno">  727</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  728</span><span class="stringliteral">    X_scale : ndarray of shape (n_features,)</span></div>
<div class="line"><span class="lineno">  729</span><span class="stringliteral">        Array of feature scale factors used to normalize design matrix.</span></div>
<div class="line"><span class="lineno">  730</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  731</span><span class="stringliteral">    rtol : float, default=None</span></div>
<div class="line"><span class="lineno">  732</span><span class="stringliteral">        Relative tolerance; see numpy.allclose</span></div>
<div class="line"><span class="lineno">  733</span><span class="stringliteral">        If None, it is set to 1e-4 for arrays of dtype numpy.float32 and 1e-7</span></div>
<div class="line"><span class="lineno">  734</span><span class="stringliteral">        otherwise.</span></div>
<div class="line"><span class="lineno">  735</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  736</span><span class="stringliteral">    atol : float, default=1e-5</span></div>
<div class="line"><span class="lineno">  737</span><span class="stringliteral">        absolute tolerance; see :func`numpy.allclose`. Note that the default</span></div>
<div class="line"><span class="lineno">  738</span><span class="stringliteral">        here is more tolerant than the default for</span></div>
<div class="line"><span class="lineno">  739</span><span class="stringliteral">        :func:`numpy.testing.assert_allclose`, where `atol=0`.</span></div>
<div class="line"><span class="lineno">  740</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  741</span><span class="stringliteral">    Raises</span></div>
<div class="line"><span class="lineno">  742</span><span class="stringliteral">    ------</span></div>
<div class="line"><span class="lineno">  743</span><span class="stringliteral">    ValueError</span></div>
<div class="line"><span class="lineno">  744</span><span class="stringliteral">        Raised when the provided Gram matrix is not consistent.</span></div>
<div class="line"><span class="lineno">  745</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  746</span> </div>
<div class="line"><span class="lineno">  747</span>    n_features = X.shape[1]</div>
<div class="line"><span class="lineno">  748</span>    f1 = n_features // 2</div>
<div class="line"><span class="lineno">  749</span>    f2 = min(f1 + 1, n_features - 1)</div>
<div class="line"><span class="lineno">  750</span> </div>
<div class="line"><span class="lineno">  751</span>    v1 = (X[:, f1] - X_offset[f1]) * X_scale[f1]</div>
<div class="line"><span class="lineno">  752</span>    v2 = (X[:, f2] - X_offset[f2]) * X_scale[f2]</div>
<div class="line"><span class="lineno">  753</span> </div>
<div class="line"><span class="lineno">  754</span>    expected = np.dot(v1, v2)</div>
<div class="line"><span class="lineno">  755</span>    actual = precompute[f1, f2]</div>
<div class="line"><span class="lineno">  756</span> </div>
<div class="line"><span class="lineno">  757</span>    dtypes = [precompute.dtype, expected.dtype]</div>
<div class="line"><span class="lineno">  758</span>    <span class="keywordflow">if</span> rtol <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  759</span>        rtols = [1e-4 <span class="keywordflow">if</span> dtype == np.float32 <span class="keywordflow">else</span> 1e-7 <span class="keywordflow">for</span> dtype <span class="keywordflow">in</span> dtypes]</div>
<div class="line"><span class="lineno">  760</span>        rtol = max(rtols)</div>
<div class="line"><span class="lineno">  761</span> </div>
<div class="line"><span class="lineno">  762</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.isclose(expected, actual, rtol=rtol, atol=atol):</div>
<div class="line"><span class="lineno">  763</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  764</span>            <span class="stringliteral">&quot;Gram matrix passed in via &#39;precompute&#39; parameter &quot;</span></div>
<div class="line"><span class="lineno">  765</span>            <span class="stringliteral">&quot;did not pass validation when a single element was &quot;</span></div>
<div class="line"><span class="lineno">  766</span>            <span class="stringliteral">&quot;checked - please check that it was computed &quot;</span></div>
<div class="line"><span class="lineno">  767</span>            f<span class="stringliteral">&quot;properly. For element ({f1},{f2}) we computed &quot;</span></div>
<div class="line"><span class="lineno">  768</span>            f<span class="stringliteral">&quot;{expected} but the user-supplied value was &quot;</span></div>
<div class="line"><span class="lineno">  769</span>            f<span class="stringliteral">&quot;{actual}.&quot;</span></div>
<div class="line"><span class="lineno">  770</span>        )</div>
<div class="line"><span class="lineno">  771</span> </div>
<div class="line"><span class="lineno">  772</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad3232000af0163df40a2acff69f316ff" name="ad3232000af0163df40a2acff69f316ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad3232000af0163df40a2acff69f316ff">&#9670;&#160;</a></span>_deprecate_normalize()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._base._deprecate_normalize </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>estimator_name</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Normalize is to be deprecated from linear models and a use of
a pipeline with a StandardScaler is to be recommended instead.
Here the appropriate message is selected to be displayed to the user
depending on the default normalize value (as it varies between the linear
models and normalize value selected by the user).

Parameters
----------
normalize : bool,
    normalize value passed by the user

estimator_name : str
    name of the linear estimator which calls this function.
    The name will be used for writing the deprecation warnings

Returns
-------
normalize : bool,
    normalize value which should further be used by the estimator at this
    stage of the depreciation process

Notes
-----
This function should be completely removed in 1.4.
</pre> <div class="fragment"><div class="line"><span class="lineno">   55</span><span class="keyword">def </span>_deprecate_normalize(normalize, estimator_name):</div>
<div class="line"><span class="lineno">   56</span>    <span class="stringliteral">&quot;&quot;&quot;Normalize is to be deprecated from linear models and a use of</span></div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral">    a pipeline with a StandardScaler is to be recommended instead.</span></div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral">    Here the appropriate message is selected to be displayed to the user</span></div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">    depending on the default normalize value (as it varies between the linear</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">    models and normalize value selected by the user).</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    normalize : bool,</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">        normalize value passed by the user</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    estimator_name : str</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">        name of the linear estimator which calls this function.</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral">        The name will be used for writing the deprecation warnings</span></div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">    normalize : bool,</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">        normalize value which should further be used by the estimator at this</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">        stage of the depreciation process</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">    This function should be completely removed in 1.4.</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   81</span> </div>
<div class="line"><span class="lineno">   82</span>    <span class="keywordflow">if</span> normalize <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="keyword">True</span>, <span class="keyword">False</span>, <span class="stringliteral">&quot;deprecated&quot;</span>]:</div>
<div class="line"><span class="lineno">   83</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">   84</span>            <span class="stringliteral">&quot;Leave &#39;normalize&#39; to its default value or set it to True or False&quot;</span></div>
<div class="line"><span class="lineno">   85</span>        )</div>
<div class="line"><span class="lineno">   86</span> </div>
<div class="line"><span class="lineno">   87</span>    <span class="keywordflow">if</span> normalize == <span class="stringliteral">&quot;deprecated&quot;</span>:</div>
<div class="line"><span class="lineno">   88</span>        _normalize = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">   89</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   90</span>        _normalize = normalize</div>
<div class="line"><span class="lineno">   91</span> </div>
<div class="line"><span class="lineno">   92</span>    pipeline_msg = (</div>
<div class="line"><span class="lineno">   93</span>        <span class="stringliteral">&quot;If you wish to scale the data, use Pipeline with a StandardScaler &quot;</span></div>
<div class="line"><span class="lineno">   94</span>        <span class="stringliteral">&quot;in a preprocessing stage. To reproduce the previous behavior:\n\n&quot;</span></div>
<div class="line"><span class="lineno">   95</span>        <span class="stringliteral">&quot;from sklearn.pipeline import make_pipeline\n\n&quot;</span></div>
<div class="line"><span class="lineno">   96</span>        <span class="stringliteral">&quot;model = make_pipeline(StandardScaler(with_mean=False), &quot;</span></div>
<div class="line"><span class="lineno">   97</span>        f<span class="stringliteral">&quot;{estimator_name}())\n\n&quot;</span></div>
<div class="line"><span class="lineno">   98</span>        <span class="stringliteral">&quot;If you wish to pass a sample_weight parameter, you need to pass it &quot;</span></div>
<div class="line"><span class="lineno">   99</span>        <span class="stringliteral">&quot;as a fit parameter to each step of the pipeline as follows:\n\n&quot;</span></div>
<div class="line"><span class="lineno">  100</span>        <span class="stringliteral">&quot;kwargs = {s[0] + &#39;__sample_weight&#39;: sample_weight for s &quot;</span></div>
<div class="line"><span class="lineno">  101</span>        <span class="stringliteral">&quot;in model.steps}\n&quot;</span></div>
<div class="line"><span class="lineno">  102</span>        <span class="stringliteral">&quot;model.fit(X, y, **kwargs)\n\n&quot;</span></div>
<div class="line"><span class="lineno">  103</span>    )</div>
<div class="line"><span class="lineno">  104</span> </div>
<div class="line"><span class="lineno">  105</span>    alpha_msg = <span class="stringliteral">&quot;&quot;</span></div>
<div class="line"><span class="lineno">  106</span>    <span class="keywordflow">if</span> <span class="stringliteral">&quot;LassoLars&quot;</span> <span class="keywordflow">in</span> estimator_name:</div>
<div class="line"><span class="lineno">  107</span>        alpha_msg = <span class="stringliteral">&quot;Set parameter alpha to: original_alpha * np.sqrt(n_samples). &quot;</span></div>
<div class="line"><span class="lineno">  108</span> </div>
<div class="line"><span class="lineno">  109</span>    <span class="keywordflow">if</span> normalize != <span class="stringliteral">&quot;deprecated&quot;</span> <span class="keywordflow">and</span> normalize:</div>
<div class="line"><span class="lineno">  110</span>        warnings.warn(</div>
<div class="line"><span class="lineno">  111</span>            <span class="stringliteral">&quot;&#39;normalize&#39; was deprecated in version 1.2 and will be removed in 1.4.\n&quot;</span></div>
<div class="line"><span class="lineno">  112</span>            + pipeline_msg</div>
<div class="line"><span class="lineno">  113</span>            + alpha_msg,</div>
<div class="line"><span class="lineno">  114</span>            FutureWarning,</div>
<div class="line"><span class="lineno">  115</span>        )</div>
<div class="line"><span class="lineno">  116</span>    <span class="keywordflow">elif</span> <span class="keywordflow">not</span> normalize:</div>
<div class="line"><span class="lineno">  117</span>        warnings.warn(</div>
<div class="line"><span class="lineno">  118</span>            <span class="stringliteral">&quot;&#39;normalize&#39; was deprecated in version 1.2 and will be &quot;</span></div>
<div class="line"><span class="lineno">  119</span>            <span class="stringliteral">&quot;removed in 1.4. &quot;</span></div>
<div class="line"><span class="lineno">  120</span>            <span class="stringliteral">&quot;Please leave the normalize parameter to its default value to &quot;</span></div>
<div class="line"><span class="lineno">  121</span>            <span class="stringliteral">&quot;silence this warning. The default behavior of this estimator &quot;</span></div>
<div class="line"><span class="lineno">  122</span>            <span class="stringliteral">&quot;is to not do any normalization. If normalization is needed &quot;</span></div>
<div class="line"><span class="lineno">  123</span>            <span class="stringliteral">&quot;please use sklearn.preprocessing.StandardScaler instead.&quot;</span>,</div>
<div class="line"><span class="lineno">  124</span>            FutureWarning,</div>
<div class="line"><span class="lineno">  125</span>        )</div>
<div class="line"><span class="lineno">  126</span> </div>
<div class="line"><span class="lineno">  127</span>    <span class="keywordflow">return</span> _normalize</div>
<div class="line"><span class="lineno">  128</span> </div>
<div class="line"><span class="lineno">  129</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad73033d93ae46098a1c2be701dfb2b65" name="ad73033d93ae46098a1c2be701dfb2b65"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad73033d93ae46098a1c2be701dfb2b65">&#9670;&#160;</a></span>_pre_fit()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._base._pre_fit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Xy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>precompute</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>copy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>check_input</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Function used at beginning of fit in linear models with L1 or L0 penalty.

This function applies _preprocess_data and additionally computes the gram matrix
`precompute` as needed as well as `Xy`.
</pre> <div class="fragment"><div class="line"><span class="lineno">  783</span>):</div>
<div class="line"><span class="lineno">  784</span>    <span class="stringliteral">&quot;&quot;&quot;Function used at beginning of fit in linear models with L1 or L0 penalty.</span></div>
<div class="line"><span class="lineno">  785</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  786</span><span class="stringliteral">    This function applies _preprocess_data and additionally computes the gram matrix</span></div>
<div class="line"><span class="lineno">  787</span><span class="stringliteral">    `precompute` as needed as well as `Xy`.</span></div>
<div class="line"><span class="lineno">  788</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  789</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  790</span> </div>
<div class="line"><span class="lineno">  791</span>    <span class="keywordflow">if</span> sparse.isspmatrix(X):</div>
<div class="line"><span class="lineno">  792</span>        <span class="comment"># copy is not needed here as X is not modified inplace when X is sparse</span></div>
<div class="line"><span class="lineno">  793</span>        precompute = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  794</span>        X, y, X_offset, y_offset, X_scale = _preprocess_data(</div>
<div class="line"><span class="lineno">  795</span>            X,</div>
<div class="line"><span class="lineno">  796</span>            y,</div>
<div class="line"><span class="lineno">  797</span>            fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  798</span>            normalize=normalize,</div>
<div class="line"><span class="lineno">  799</span>            copy=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  800</span>            check_input=check_input,</div>
<div class="line"><span class="lineno">  801</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  802</span>        )</div>
<div class="line"><span class="lineno">  803</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  804</span>        <span class="comment"># copy was done in fit if necessary</span></div>
<div class="line"><span class="lineno">  805</span>        X, y, X_offset, y_offset, X_scale = _preprocess_data(</div>
<div class="line"><span class="lineno">  806</span>            X,</div>
<div class="line"><span class="lineno">  807</span>            y,</div>
<div class="line"><span class="lineno">  808</span>            fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  809</span>            normalize=normalize,</div>
<div class="line"><span class="lineno">  810</span>            copy=copy,</div>
<div class="line"><span class="lineno">  811</span>            check_input=check_input,</div>
<div class="line"><span class="lineno">  812</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  813</span>        )</div>
<div class="line"><span class="lineno">  814</span>        <span class="comment"># Rescale only in dense case. Sparse cd solver directly deals with</span></div>
<div class="line"><span class="lineno">  815</span>        <span class="comment"># sample_weight.</span></div>
<div class="line"><span class="lineno">  816</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  817</span>            <span class="comment"># This triggers copies anyway.</span></div>
<div class="line"><span class="lineno">  818</span>            X, y, _ = _rescale_data(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  819</span> </div>
<div class="line"><span class="lineno">  820</span>    <span class="comment"># FIXME: &#39;normalize&#39; to be removed in 1.4</span></div>
<div class="line"><span class="lineno">  821</span>    <span class="keywordflow">if</span> hasattr(precompute, <span class="stringliteral">&quot;__array__&quot;</span>):</div>
<div class="line"><span class="lineno">  822</span>        <span class="keywordflow">if</span> (</div>
<div class="line"><span class="lineno">  823</span>            fit_intercept</div>
<div class="line"><span class="lineno">  824</span>            <span class="keywordflow">and</span> <span class="keywordflow">not</span> np.allclose(X_offset, np.zeros(n_features))</div>
<div class="line"><span class="lineno">  825</span>            <span class="keywordflow">or</span> normalize</div>
<div class="line"><span class="lineno">  826</span>            <span class="keywordflow">and</span> <span class="keywordflow">not</span> np.allclose(X_scale, np.ones(n_features))</div>
<div class="line"><span class="lineno">  827</span>        ):</div>
<div class="line"><span class="lineno">  828</span>            warnings.warn(</div>
<div class="line"><span class="lineno">  829</span>                <span class="stringliteral">&quot;Gram matrix was provided but X was centered to fit &quot;</span></div>
<div class="line"><span class="lineno">  830</span>                <span class="stringliteral">&quot;intercept, or X was normalized : recomputing Gram matrix.&quot;</span>,</div>
<div class="line"><span class="lineno">  831</span>                UserWarning,</div>
<div class="line"><span class="lineno">  832</span>            )</div>
<div class="line"><span class="lineno">  833</span>            <span class="comment"># recompute Gram</span></div>
<div class="line"><span class="lineno">  834</span>            precompute = <span class="stringliteral">&quot;auto&quot;</span></div>
<div class="line"><span class="lineno">  835</span>            Xy = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  836</span>        <span class="keywordflow">elif</span> check_input:</div>
<div class="line"><span class="lineno">  837</span>            <span class="comment"># If we&#39;re going to use the user&#39;s precomputed gram matrix, we</span></div>
<div class="line"><span class="lineno">  838</span>            <span class="comment"># do a quick check to make sure its not totally bogus.</span></div>
<div class="line"><span class="lineno">  839</span>            _check_precomputed_gram_matrix(X, precompute, X_offset, X_scale)</div>
<div class="line"><span class="lineno">  840</span> </div>
<div class="line"><span class="lineno">  841</span>    <span class="comment"># precompute if n_samples &gt; n_features</span></div>
<div class="line"><span class="lineno">  842</span>    <span class="keywordflow">if</span> isinstance(precompute, str) <span class="keywordflow">and</span> precompute == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  843</span>        precompute = n_samples &gt; n_features</div>
<div class="line"><span class="lineno">  844</span> </div>
<div class="line"><span class="lineno">  845</span>    <span class="keywordflow">if</span> precompute <span class="keywordflow">is</span> <span class="keyword">True</span>:</div>
<div class="line"><span class="lineno">  846</span>        <span class="comment"># make sure that the &#39;precompute&#39; array is contiguous.</span></div>
<div class="line"><span class="lineno">  847</span>        precompute = np.empty(shape=(n_features, n_features), dtype=X.dtype, order=<span class="stringliteral">&quot;C&quot;</span>)</div>
<div class="line"><span class="lineno">  848</span>        np.dot(X.T, X, out=precompute)</div>
<div class="line"><span class="lineno">  849</span> </div>
<div class="line"><span class="lineno">  850</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(precompute, <span class="stringliteral">&quot;__array__&quot;</span>):</div>
<div class="line"><span class="lineno">  851</span>        Xy = <span class="keywordtype">None</span>  <span class="comment"># cannot use Xy if precompute is not Gram</span></div>
<div class="line"><span class="lineno">  852</span> </div>
<div class="line"><span class="lineno">  853</span>    <span class="keywordflow">if</span> hasattr(precompute, <span class="stringliteral">&quot;__array__&quot;</span>) <span class="keywordflow">and</span> Xy <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  854</span>        common_dtype = np.result_type(X.dtype, y.dtype)</div>
<div class="line"><span class="lineno">  855</span>        <span class="keywordflow">if</span> y.ndim == 1:</div>
<div class="line"><span class="lineno">  856</span>            <span class="comment"># Xy is 1d, make sure it is contiguous.</span></div>
<div class="line"><span class="lineno">  857</span>            Xy = np.empty(shape=n_features, dtype=common_dtype, order=<span class="stringliteral">&quot;C&quot;</span>)</div>
<div class="line"><span class="lineno">  858</span>            np.dot(X.T, y, out=Xy)</div>
<div class="line"><span class="lineno">  859</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  860</span>            <span class="comment"># Make sure that Xy is always F contiguous even if X or y are not</span></div>
<div class="line"><span class="lineno">  861</span>            <span class="comment"># contiguous: the goal is to make it fast to extract the data for a</span></div>
<div class="line"><span class="lineno">  862</span>            <span class="comment"># specific target.</span></div>
<div class="line"><span class="lineno">  863</span>            n_targets = y.shape[1]</div>
<div class="line"><span class="lineno">  864</span>            Xy = np.empty(shape=(n_features, n_targets), dtype=common_dtype, order=<span class="stringliteral">&quot;F&quot;</span>)</div>
<div class="line"><span class="lineno">  865</span>            np.dot(y.T, X, out=Xy.T)</div>
<div class="line"><span class="lineno">  866</span> </div>
<div class="line"><span class="lineno">  867</span>    <span class="keywordflow">return</span> X, y, X_offset, y_offset, X_scale, precompute, Xy</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae4b9eb3d9bc4a6a892e01324db3cccb3" name="ae4b9eb3d9bc4a6a892e01324db3cccb3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4b9eb3d9bc4a6a892e01324db3cccb3">&#9670;&#160;</a></span>_preprocess_data()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._base._preprocess_data </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>copy</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>check_input</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Center and scale data.

Centers data to have mean zero along axis 0. If fit_intercept=False or if
the X is a sparse matrix, no centering is done, but normalization can still
be applied. The function returns the statistics necessary to reconstruct
the input data, which are X_offset, y_offset, X_scale, such that the output

    X = (X - X_offset) / X_scale

X_scale is the L2 norm of X - X_offset. If sample_weight is not None,
then the weighted mean of X and y is zero, and not the mean itself. If
fit_intercept=True, the mean, eventually weighted, is returned, independently
of whether X was centered (option used for optimization with sparse data in
coordinate_descend).

This is here because nearly all linear models will want their data to be
centered. This function also systematically makes y consistent with X.dtype

Returns
-------
X_out : {ndarray, sparse matrix} of shape (n_samples, n_features)
    If copy=True a copy of the input X is triggered, otherwise operations are
    inplace.
    If input X is dense, then X_out is centered.
    If normalize is True, then X_out is rescaled (dense and sparse case)
y_out : {ndarray, sparse matrix} of shape (n_samples,) or (n_samples, n_targets)
    Centered version of y. Likely performed inplace on input y.
X_offset : ndarray of shape (n_features,)
    The mean per column of input X.
y_offset : float or ndarray of shape (n_features,)
X_scale : ndarray of shape (n_features,)
    The standard deviation per column of input X.
</pre> <div class="fragment"><div class="line"><span class="lineno">  191</span>):</div>
<div class="line"><span class="lineno">  192</span>    <span class="stringliteral">&quot;&quot;&quot;Center and scale data.</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">    Centers data to have mean zero along axis 0. If fit_intercept=False or if</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">    the X is a sparse matrix, no centering is done, but normalization can still</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral">    be applied. The function returns the statistics necessary to reconstruct</span></div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral">    the input data, which are X_offset, y_offset, X_scale, such that the output</span></div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">        X = (X - X_offset) / X_scale</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral">    X_scale is the L2 norm of X - X_offset. If sample_weight is not None,</span></div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral">    then the weighted mean of X and y is zero, and not the mean itself. If</span></div>
<div class="line"><span class="lineno">  203</span><span class="stringliteral">    fit_intercept=True, the mean, eventually weighted, is returned, independently</span></div>
<div class="line"><span class="lineno">  204</span><span class="stringliteral">    of whether X was centered (option used for optimization with sparse data in</span></div>
<div class="line"><span class="lineno">  205</span><span class="stringliteral">    coordinate_descend).</span></div>
<div class="line"><span class="lineno">  206</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral">    This is here because nearly all linear models will want their data to be</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">    centered. This function also systematically makes y consistent with X.dtype</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">    X_out : {ndarray, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral">        If copy=True a copy of the input X is triggered, otherwise operations are</span></div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">        inplace.</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">        If input X is dense, then X_out is centered.</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">        If normalize is True, then X_out is rescaled (dense and sparse case)</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">    y_out : {ndarray, sparse matrix} of shape (n_samples,) or (n_samples, n_targets)</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">        Centered version of y. Likely performed inplace on input y.</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">    X_offset : ndarray of shape (n_features,)</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">        The mean per column of input X.</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">    y_offset : float or ndarray of shape (n_features,)</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">    X_scale : ndarray of shape (n_features,)</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">        The standard deviation per column of input X.</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  225</span>    <span class="keywordflow">if</span> isinstance(sample_weight, numbers.Number):</div>
<div class="line"><span class="lineno">  226</span>        sample_weight = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  227</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  228</span>        sample_weight = np.asarray(sample_weight)</div>
<div class="line"><span class="lineno">  229</span> </div>
<div class="line"><span class="lineno">  230</span>    <span class="keywordflow">if</span> check_input:</div>
<div class="line"><span class="lineno">  231</span>        X = check_array(X, copy=copy, accept_sparse=[<span class="stringliteral">&quot;csr&quot;</span>, <span class="stringliteral">&quot;csc&quot;</span>], dtype=FLOAT_DTYPES)</div>
<div class="line"><span class="lineno">  232</span>    <span class="keywordflow">elif</span> copy:</div>
<div class="line"><span class="lineno">  233</span>        <span class="keywordflow">if</span> sp.issparse(X):</div>
<div class="line"><span class="lineno">  234</span>            X = X.copy()</div>
<div class="line"><span class="lineno">  235</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  236</span>            X = X.copy(order=<span class="stringliteral">&quot;K&quot;</span>)</div>
<div class="line"><span class="lineno">  237</span> </div>
<div class="line"><span class="lineno">  238</span>    y = np.asarray(y, dtype=X.dtype)</div>
<div class="line"><span class="lineno">  239</span> </div>
<div class="line"><span class="lineno">  240</span>    <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno">  241</span>        <span class="keywordflow">if</span> sp.issparse(X):</div>
<div class="line"><span class="lineno">  242</span>            X_offset, X_var = mean_variance_axis(X, axis=0, weights=sample_weight)</div>
<div class="line"><span class="lineno">  243</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  244</span>            <span class="keywordflow">if</span> normalize:</div>
<div class="line"><span class="lineno">  245</span>                X_offset, X_var, _ = _incremental_mean_and_var(</div>
<div class="line"><span class="lineno">  246</span>                    X,</div>
<div class="line"><span class="lineno">  247</span>                    last_mean=0.0,</div>
<div class="line"><span class="lineno">  248</span>                    last_variance=0.0,</div>
<div class="line"><span class="lineno">  249</span>                    last_sample_count=0.0,</div>
<div class="line"><span class="lineno">  250</span>                    sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  251</span>                )</div>
<div class="line"><span class="lineno">  252</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  253</span>                X_offset = np.average(X, axis=0, weights=sample_weight)</div>
<div class="line"><span class="lineno">  254</span> </div>
<div class="line"><span class="lineno">  255</span>            X_offset = X_offset.astype(X.dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  256</span>            X -= X_offset</div>
<div class="line"><span class="lineno">  257</span> </div>
<div class="line"><span class="lineno">  258</span>        <span class="keywordflow">if</span> normalize:</div>
<div class="line"><span class="lineno">  259</span>            X_var = X_var.astype(X.dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  260</span>            <span class="comment"># Detect constant features on the computed variance, before taking</span></div>
<div class="line"><span class="lineno">  261</span>            <span class="comment"># the np.sqrt. Otherwise constant features cannot be detected with</span></div>
<div class="line"><span class="lineno">  262</span>            <span class="comment"># sample weights.</span></div>
<div class="line"><span class="lineno">  263</span>            constant_mask = _is_constant_feature(X_var, X_offset, X.shape[0])</div>
<div class="line"><span class="lineno">  264</span>            <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  265</span>                X_var *= X.shape[0]</div>
<div class="line"><span class="lineno">  266</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  267</span>                X_var *= sample_weight.sum()</div>
<div class="line"><span class="lineno">  268</span>            X_scale = np.sqrt(X_var, out=X_var)</div>
<div class="line"><span class="lineno">  269</span>            X_scale[constant_mask] = 1.0</div>
<div class="line"><span class="lineno">  270</span>            <span class="keywordflow">if</span> sp.issparse(X):</div>
<div class="line"><span class="lineno">  271</span>                inplace_column_scale(X, 1.0 / X_scale)</div>
<div class="line"><span class="lineno">  272</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  273</span>                X /= X_scale</div>
<div class="line"><span class="lineno">  274</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  275</span>            X_scale = np.ones(X.shape[1], dtype=X.dtype)</div>
<div class="line"><span class="lineno">  276</span> </div>
<div class="line"><span class="lineno">  277</span>        y_offset = np.average(y, axis=0, weights=sample_weight)</div>
<div class="line"><span class="lineno">  278</span>        y = y - y_offset</div>
<div class="line"><span class="lineno">  279</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  280</span>        X_offset = np.zeros(X.shape[1], dtype=X.dtype)</div>
<div class="line"><span class="lineno">  281</span>        X_scale = np.ones(X.shape[1], dtype=X.dtype)</div>
<div class="line"><span class="lineno">  282</span>        <span class="keywordflow">if</span> y.ndim == 1:</div>
<div class="line"><span class="lineno">  283</span>            y_offset = X.dtype.type(0)</div>
<div class="line"><span class="lineno">  284</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  285</span>            y_offset = np.zeros(y.shape[1], dtype=X.dtype)</div>
<div class="line"><span class="lineno">  286</span> </div>
<div class="line"><span class="lineno">  287</span>    <span class="keywordflow">return</span> X, y, X_offset, y_offset, X_scale</div>
<div class="line"><span class="lineno">  288</span> </div>
<div class="line"><span class="lineno">  289</span> </div>
<div class="line"><span class="lineno">  290</span><span class="comment"># TODO: _rescale_data should be factored into _preprocess_data.</span></div>
<div class="line"><span class="lineno">  291</span><span class="comment"># Currently, the fact that sag implements its own way to deal with</span></div>
<div class="line"><span class="lineno">  292</span><span class="comment"># sample_weight makes the refactoring tricky.</span></div>
<div class="line"><span class="lineno">  293</span> </div>
<div class="line"><span class="lineno">  294</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac831f308a59ecc27cd6c16f2c90b0a4f" name="ac831f308a59ecc27cd6c16f2c90b0a4f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac831f308a59ecc27cd6c16f2c90b0a4f">&#9670;&#160;</a></span>_rescale_data()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._base._rescale_data </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Rescale data sample-wise by square root of sample_weight.

For many linear models, this enables easy support for sample_weight because

    (y - X w)' S (y - X w)

with S = diag(sample_weight) becomes

    ||y_rescaled - X_rescaled w||_2^2

when setting

    y_rescaled = sqrt(S) y
    X_rescaled = sqrt(S) X

Returns
-------
X_rescaled : {array-like, sparse matrix}

y_rescaled : {array-like, sparse matrix}
</pre> <div class="fragment"><div class="line"><span class="lineno">  295</span><span class="keyword">def </span>_rescale_data(X, y, sample_weight):</div>
<div class="line"><span class="lineno">  296</span>    <span class="stringliteral">&quot;&quot;&quot;Rescale data sample-wise by square root of sample_weight.</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">    For many linear models, this enables easy support for sample_weight because</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">        (y - X w)&#39; S (y - X w)</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">    with S = diag(sample_weight) becomes</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">        ||y_rescaled - X_rescaled w||_2^2</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    when setting</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">        y_rescaled = sqrt(S) y</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">        X_rescaled = sqrt(S) X</span></div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">    X_rescaled : {array-like, sparse matrix}</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">    y_rescaled : {array-like, sparse matrix}</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  317</span>    n_samples = X.shape[0]</div>
<div class="line"><span class="lineno">  318</span>    sample_weight = np.asarray(sample_weight)</div>
<div class="line"><span class="lineno">  319</span>    <span class="keywordflow">if</span> sample_weight.ndim == 0:</div>
<div class="line"><span class="lineno">  320</span>        sample_weight = np.full(n_samples, sample_weight, dtype=sample_weight.dtype)</div>
<div class="line"><span class="lineno">  321</span>    sample_weight_sqrt = np.sqrt(sample_weight)</div>
<div class="line"><span class="lineno">  322</span>    sw_matrix = sparse.dia_matrix((sample_weight_sqrt, 0), shape=(n_samples, n_samples))</div>
<div class="line"><span class="lineno">  323</span>    X = safe_sparse_dot(sw_matrix, X)</div>
<div class="line"><span class="lineno">  324</span>    y = safe_sparse_dot(sw_matrix, y)</div>
<div class="line"><span class="lineno">  325</span>    <span class="keywordflow">return</span> X, y, sample_weight_sqrt</div>
<div class="line"><span class="lineno">  326</span> </div>
<div class="line"><span class="lineno">  327</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abc94508f025e1cab4a1cc91a0bc64a11" name="abc94508f025e1cab4a1cc91a0bc64a11"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abc94508f025e1cab4a1cc91a0bc64a11">&#9670;&#160;</a></span>make_dataset()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._base.make_dataset </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Create ``Dataset`` abstraction for sparse and dense inputs.

This also returns the ``intercept_decay`` which is different
for sparse datasets.

Parameters
----------
X : array-like, shape (n_samples, n_features)
    Training data

y : array-like, shape (n_samples, )
    Target values.

sample_weight : numpy array of shape (n_samples,)
    The weight of each sample

random_state : int, RandomState instance or None (default)
    Determines random number generation for dataset random sampling. It is not
    used for dataset shuffling.
    Pass an int for reproducible output across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Returns
-------
dataset
    The ``Dataset`` abstraction
intercept_decay
    The intercept decay
</pre> <div class="fragment"><div class="line"><span class="lineno">  130</span><span class="keyword">def </span>make_dataset(X, y, sample_weight, random_state=None):</div>
<div class="line"><span class="lineno">  131</span>    <span class="stringliteral">&quot;&quot;&quot;Create ``Dataset`` abstraction for sparse and dense inputs.</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">    This also returns the ``intercept_decay`` which is different</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">    for sparse datasets.</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">    X : array-like, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral">        Training data</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">    y : array-like, shape (n_samples, )</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">        Target values.</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">    sample_weight : numpy array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">        The weight of each sample</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">    random_state : int, RandomState instance or None (default)</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">        Determines random number generation for dataset random sampling. It is not</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">        used for dataset shuffling.</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">        Pass an int for reproducible output across multiple function calls.</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">    dataset</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">        The ``Dataset`` abstraction</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">    intercept_decay</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">        The intercept decay</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  160</span> </div>
<div class="line"><span class="lineno">  161</span>    rng = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  162</span>    <span class="comment"># seed should never be 0 in SequentialDataset64</span></div>
<div class="line"><span class="lineno">  163</span>    seed = rng.randint(1, np.iinfo(np.int32).max)</div>
<div class="line"><span class="lineno">  164</span> </div>
<div class="line"><span class="lineno">  165</span>    <span class="keywordflow">if</span> X.dtype == np.float32:</div>
<div class="line"><span class="lineno">  166</span>        CSRData = CSRDataset32</div>
<div class="line"><span class="lineno">  167</span>        ArrayData = ArrayDataset32</div>
<div class="line"><span class="lineno">  168</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  169</span>        CSRData = CSRDataset64</div>
<div class="line"><span class="lineno">  170</span>        ArrayData = ArrayDataset64</div>
<div class="line"><span class="lineno">  171</span> </div>
<div class="line"><span class="lineno">  172</span>    <span class="keywordflow">if</span> sp.issparse(X):</div>
<div class="line"><span class="lineno">  173</span>        dataset = CSRData(X.data, X.indptr, X.indices, y, sample_weight, seed=seed)</div>
<div class="line"><span class="lineno">  174</span>        intercept_decay = SPARSE_INTERCEPT_DECAY</div>
<div class="line"><span class="lineno">  175</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  176</span>        X = np.ascontiguousarray(X)</div>
<div class="line"><span class="lineno">  177</span>        dataset = ArrayData(X, y, sample_weight, seed=seed)</div>
<div class="line"><span class="lineno">  178</span>        intercept_decay = 1.0</div>
<div class="line"><span class="lineno">  179</span> </div>
<div class="line"><span class="lineno">  180</span>    <span class="keywordflow">return</span> dataset, intercept_decay</div>
<div class="line"><span class="lineno">  181</span> </div>
<div class="line"><span class="lineno">  182</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="aa160fd961899aaff36932501ec6610cb" name="aa160fd961899aaff36932501ec6610cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa160fd961899aaff36932501ec6610cb">&#9670;&#160;</a></span>SPARSE_INTERCEPT_DECAY</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float sklearn.linear_model._base.SPARSE_INTERCEPT_DECAY = 0.01</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
