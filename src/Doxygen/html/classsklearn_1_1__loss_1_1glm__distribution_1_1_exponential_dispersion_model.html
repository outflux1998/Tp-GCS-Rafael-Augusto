<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn._loss.glm_distribution.ExponentialDispersionModel Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1__loss.html">_loss</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1__loss_1_1glm__distribution.html">glm_distribution</a></li><li class="navelem"><a class="el" href="classsklearn_1_1__loss_1_1glm__distribution_1_1_exponential_dispersion_model.html">ExponentialDispersionModel</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classsklearn_1_1__loss_1_1glm__distribution_1_1_exponential_dispersion_model-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">sklearn._loss.glm_distribution.ExponentialDispersionModel Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for sklearn._loss.glm_distribution.ExponentialDispersionModel:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classsklearn_1_1__loss_1_1glm__distribution_1_1_exponential_dispersion_model.png" usemap="#sklearn._5Floss.glm_5Fdistribution.ExponentialDispersionModel_map" alt=""/>
  <map id="sklearn._5Floss.glm_5Fdistribution.ExponentialDispersionModel_map" name="sklearn._5Floss.glm_5Fdistribution.ExponentialDispersionModel_map">
<area href="classsklearn_1_1__loss_1_1glm__distribution_1_1_tweedie_distribution.html" alt="sklearn._loss.glm_distribution.TweedieDistribution" shape="rect" coords="526,112,867,136"/>
<area href="classsklearn_1_1__loss_1_1glm__distribution_1_1_gamma_distribution.html" alt="sklearn._loss.glm_distribution.GammaDistribution" shape="rect" coords="0,168,341,192"/>
<area href="classsklearn_1_1__loss_1_1glm__distribution_1_1_inverse_gaussian_distribution.html" alt="sklearn._loss.glm_distribution.InverseGaussianDistribution" shape="rect" coords="351,168,692,192"/>
<area href="classsklearn_1_1__loss_1_1glm__distribution_1_1_normal_distribution.html" alt="sklearn._loss.glm_distribution.NormalDistribution" shape="rect" coords="702,168,1043,192"/>
<area href="classsklearn_1_1__loss_1_1glm__distribution_1_1_poisson_distribution.html" alt="sklearn._loss.glm_distribution.PoissonDistribution" shape="rect" coords="1053,168,1394,192"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a68ea329a7abbf088162595173e3fcf3b" id="r_a68ea329a7abbf088162595173e3fcf3b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1glm__distribution_1_1_exponential_dispersion_model.html#a68ea329a7abbf088162595173e3fcf3b">in_y_range</a> (self, y)</td></tr>
<tr class="separator:a68ea329a7abbf088162595173e3fcf3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af147485172659d390296db18b42ba20a" id="r_af147485172659d390296db18b42ba20a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1glm__distribution_1_1_exponential_dispersion_model.html#af147485172659d390296db18b42ba20a">unit_variance</a> (self, y_pred)</td></tr>
<tr class="separator:af147485172659d390296db18b42ba20a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a714e07052ec4d24b2cfb9155aa7fe416" id="r_a714e07052ec4d24b2cfb9155aa7fe416"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1glm__distribution_1_1_exponential_dispersion_model.html#a714e07052ec4d24b2cfb9155aa7fe416">unit_deviance</a> (self, y, y_pred, check_input=False)</td></tr>
<tr class="separator:a714e07052ec4d24b2cfb9155aa7fe416"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43bdb5847fb054ca312321d3ff8185cd" id="r_a43bdb5847fb054ca312321d3ff8185cd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1glm__distribution_1_1_exponential_dispersion_model.html#a43bdb5847fb054ca312321d3ff8185cd">unit_deviance_derivative</a> (self, y, y_pred)</td></tr>
<tr class="separator:a43bdb5847fb054ca312321d3ff8185cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2264ba61371889beda787b28a06978a" id="r_af2264ba61371889beda787b28a06978a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1glm__distribution_1_1_exponential_dispersion_model.html#af2264ba61371889beda787b28a06978a">deviance</a> (self, y, y_pred, weights=1)</td></tr>
<tr class="separator:af2264ba61371889beda787b28a06978a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a847d961ccdb992396e50d31e26ce2e" id="r_a5a847d961ccdb992396e50d31e26ce2e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1glm__distribution_1_1_exponential_dispersion_model.html#a5a847d961ccdb992396e50d31e26ce2e">deviance_derivative</a> (self, y, y_pred, weights=1)</td></tr>
<tr class="separator:a5a847d961ccdb992396e50d31e26ce2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-attribs" name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:aaef6dc9001da8082bbe55e96997306e2" id="r_aaef6dc9001da8082bbe55e96997306e2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1glm__distribution_1_1_exponential_dispersion_model.html#aaef6dc9001da8082bbe55e96997306e2">_lower_bound</a></td></tr>
<tr class="separator:aaef6dc9001da8082bbe55e96997306e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Base class for reproductive Exponential Dispersion Models (EDM).

The pdf of :math:`Y\sim \mathrm{EDM}(y_\textrm{pred}, \phi)` is given by

.. math:: p(y| \theta, \phi) = c(y, \phi)
    \exp\left(\frac{\theta y-A(\theta)}{\phi}\right)
    = \tilde{c}(y, \phi)
        \exp\left(-\frac{d(y, y_\textrm{pred})}{2\phi}\right)

with mean :math:`\mathrm{E}[Y] = A'(\theta) = y_\textrm{pred}`,
variance :math:`\mathrm{Var}[Y] = \phi \cdot v(y_\textrm{pred})`,
unit variance :math:`v(y_\textrm{pred})` and
unit deviance :math:`d(y,y_\textrm{pred})`.

Methods
-------
deviance
deviance_derivative
in_y_range
unit_deviance
unit_deviance_derivative
unit_variance

References
----------
https://en.wikipedia.org/wiki/Exponential_dispersion_model.
</pre> </div><h2 class="groupheader">Member Function Documentation</h2>
<a id="af2264ba61371889beda787b28a06978a" name="af2264ba61371889beda787b28a06978a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af2264ba61371889beda787b28a06978a">&#9670;&#160;</a></span>deviance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.glm_distribution.ExponentialDispersionModel.deviance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>weights</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the deviance.

    The deviance is a weighted sum of the per sample unit deviances,
    :math:`D = \sum_i s_i \cdot d(y_i, y_\textrm{pred}_i)`
    with weights :math:`s_i` and unit deviance
    :math:`d(y,y_\textrm{pred})`.
    In terms of the log-likelihood it is :math:`D = -2\phi\cdot
    \left(loglike(y,y_\textrm{pred},\frac{phi}{s})
    - loglike(y,y,\frac{phi}{s})\right)`.

    Parameters
    ----------
    y : array of shape (n_samples,)
        Target values.

    y_pred : array of shape (n_samples,)
        Predicted mean.

    weights : {int, array of shape (n_samples,)}, default=1
        Weights or exposure to which variance is inverse proportional.</pre> <div class="fragment"><div class="line"><span class="lineno">  138</span>    <span class="keyword">def </span>deviance(self, y, y_pred, weights=1):</div>
<div class="line"><span class="lineno">  139</span>        <span class="stringliteral">r&quot;&quot;&quot;Compute the deviance.</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">        The deviance is a weighted sum of the per sample unit deviances,</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">        :math:`D = \sum_i s_i \cdot d(y_i, y_\textrm{pred}_i)`</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">        with weights :math:`s_i` and unit deviance</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">        :math:`d(y,y_\textrm{pred})`.</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">        In terms of the log-likelihood it is :math:`D = -2\phi\cdot</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">        \left(loglike(y,y_\textrm{pred},\frac{phi}{s})</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">        - loglike(y,y,\frac{phi}{s})\right)`.</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">        y : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">            Target values.</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">        y_pred : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">            Predicted mean.</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">        weights : {int, array of shape (n_samples,)}, default=1</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">            Weights or exposure to which variance is inverse proportional.</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  160</span>        <span class="keywordflow">return</span> np.sum(weights * self.unit_deviance(y, y_pred))</div>
<div class="line"><span class="lineno">  161</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5a847d961ccdb992396e50d31e26ce2e" name="a5a847d961ccdb992396e50d31e26ce2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5a847d961ccdb992396e50d31e26ce2e">&#9670;&#160;</a></span>deviance_derivative()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.glm_distribution.ExponentialDispersionModel.deviance_derivative </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>weights</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the derivative of the deviance w.r.t. y_pred.

    It gives :math:`\frac{\partial}{\partial y_\textrm{pred}}
    D(y, \y_\textrm{pred}; weights)`.

    Parameters
    ----------
    y : array, shape (n_samples,)
        Target values.

    y_pred : array, shape (n_samples,)
        Predicted mean.

    weights : {int, array of shape (n_samples,)}, default=1
        Weights or exposure to which variance is inverse proportional.</pre> <div class="fragment"><div class="line"><span class="lineno">  162</span>    <span class="keyword">def </span>deviance_derivative(self, y, y_pred, weights=1):</div>
<div class="line"><span class="lineno">  163</span>        <span class="stringliteral">r&quot;&quot;&quot;Compute the derivative of the deviance w.r.t. y_pred.</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">        It gives :math:`\frac{\partial}{\partial y_\textrm{pred}}</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">        D(y, \y_\textrm{pred}; weights)`.</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">        y : array, shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">            Target values.</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">        y_pred : array, shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">            Predicted mean.</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">        weights : {int, array of shape (n_samples,)}, default=1</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">            Weights or exposure to which variance is inverse proportional.</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  179</span>        <span class="keywordflow">return</span> weights * self.unit_deviance_derivative(y, y_pred)</div>
<div class="line"><span class="lineno">  180</span> </div>
<div class="line"><span class="lineno">  181</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a68ea329a7abbf088162595173e3fcf3b" name="a68ea329a7abbf088162595173e3fcf3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68ea329a7abbf088162595173e3fcf3b">&#9670;&#160;</a></span>in_y_range()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.glm_distribution.ExponentialDispersionModel.in_y_range </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns ``True`` if y is in the valid range of Y~EDM.

Parameters
----------
y : array of shape (n_samples,)
    Target values.
</pre> <div class="fragment"><div class="line"><span class="lineno">   52</span>    <span class="keyword">def </span>in_y_range(self, y):</div>
<div class="line"><span class="lineno">   53</span>        <span class="stringliteral">&quot;&quot;&quot;Returns ``True`` if y is in the valid range of Y~EDM.</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral">        y : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral">            Target values.</span></div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   60</span>        <span class="comment"># Note that currently supported distributions have +inf upper bound</span></div>
<div class="line"><span class="lineno">   61</span> </div>
<div class="line"><span class="lineno">   62</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(self._lower_bound, DistributionBoundary):</div>
<div class="line"><span class="lineno">   63</span>            <span class="keywordflow">raise</span> TypeError(</div>
<div class="line"><span class="lineno">   64</span>                <span class="stringliteral">&quot;_lower_bound attribute must be of type DistributionBoundary&quot;</span></div>
<div class="line"><span class="lineno">   65</span>            )</div>
<div class="line"><span class="lineno">   66</span> </div>
<div class="line"><span class="lineno">   67</span>        <span class="keywordflow">if</span> self._lower_bound.inclusive:</div>
<div class="line"><span class="lineno">   68</span>            <span class="keywordflow">return</span> np.greater_equal(y, self._lower_bound.value)</div>
<div class="line"><span class="lineno">   69</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   70</span>            <span class="keywordflow">return</span> np.greater(y, self._lower_bound.value)</div>
<div class="line"><span class="lineno">   71</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a714e07052ec4d24b2cfb9155aa7fe416" name="a714e07052ec4d24b2cfb9155aa7fe416"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a714e07052ec4d24b2cfb9155aa7fe416">&#9670;&#160;</a></span>unit_deviance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.glm_distribution.ExponentialDispersionModel.unit_deviance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>check_input</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the unit deviance.

    The unit_deviance :math:`d(y,y_\textrm{pred})` can be defined by the
    log-likelihood as
    :math:`d(y,y_\textrm{pred}) = -2\phi\cdot
    \left(loglike(y,y_\textrm{pred},\phi) - loglike(y,y,\phi)\right).`

    Parameters
    ----------
    y : array of shape (n_samples,)
        Target values.

    y_pred : array of shape (n_samples,)
        Predicted mean.

    check_input : bool, default=False
        If True raise an exception on invalid y or y_pred values, otherwise
        they will be propagated as NaN.
    Returns
    -------
    deviance: array of shape (n_samples,)
        Computed deviance</pre> 
<p>Reimplemented in <a class="el" href="classsklearn_1_1__loss_1_1glm__distribution_1_1_tweedie_distribution.html#ad5e13e137e0f5d4124af708b25227b0d">sklearn._loss.glm_distribution.TweedieDistribution</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   95</span>    <span class="keyword">def </span>unit_deviance(self, y, y_pred, check_input=False):</div>
<div class="line"><span class="lineno">   96</span>        <span class="stringliteral">r&quot;&quot;&quot;Compute the unit deviance.</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">        The unit_deviance :math:`d(y,y_\textrm{pred})` can be defined by the</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">        log-likelihood as</span></div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">        :math:`d(y,y_\textrm{pred}) = -2\phi\cdot</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">        \left(loglike(y,y_\textrm{pred},\phi) - loglike(y,y,\phi)\right).`</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral">        y : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral">            Target values.</span></div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">        y_pred : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">            Predicted mean.</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral">        check_input : bool, default=False</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral">            If True raise an exception on invalid y or y_pred values, otherwise</span></div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral">            they will be propagated as NaN.</span></div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral">        deviance: array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">            Computed deviance</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  119</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a43bdb5847fb054ca312321d3ff8185cd" name="a43bdb5847fb054ca312321d3ff8185cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a43bdb5847fb054ca312321d3ff8185cd">&#9670;&#160;</a></span>unit_deviance_derivative()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.glm_distribution.ExponentialDispersionModel.unit_deviance_derivative </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the derivative of the unit deviance w.r.t. y_pred.

    The derivative of the unit deviance is given by
    :math:`\frac{\partial}{\partialy_\textrm{pred}}d(y,y_\textrm{pred})
         = -2\frac{y-y_\textrm{pred}}{v(y_\textrm{pred})}`
    with unit variance :math:`v(y_\textrm{pred})`.

    Parameters
    ----------
    y : array of shape (n_samples,)
        Target values.

    y_pred : array of shape (n_samples,)
        Predicted mean.</pre> <div class="fragment"><div class="line"><span class="lineno">  120</span>    <span class="keyword">def </span>unit_deviance_derivative(self, y, y_pred):</div>
<div class="line"><span class="lineno">  121</span>        <span class="stringliteral">r&quot;&quot;&quot;Compute the derivative of the unit deviance w.r.t. y_pred.</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">        The derivative of the unit deviance is given by</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">        :math:`\frac{\partial}{\partialy_\textrm{pred}}d(y,y_\textrm{pred})</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral">             = -2\frac{y-y_\textrm{pred}}{v(y_\textrm{pred})}`</span></div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral">        with unit variance :math:`v(y_\textrm{pred})`.</span></div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral">        y : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">            Target values.</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">        y_pred : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">            Predicted mean.</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  136</span>        <span class="keywordflow">return</span> -2 * (y - y_pred) / self.unit_variance(y_pred)</div>
<div class="line"><span class="lineno">  137</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af147485172659d390296db18b42ba20a" name="af147485172659d390296db18b42ba20a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af147485172659d390296db18b42ba20a">&#9670;&#160;</a></span>unit_variance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.glm_distribution.ExponentialDispersionModel.unit_variance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the unit variance function.

    The unit variance :math:`v(y_\textrm{pred})` determines the variance as
    a function of the mean :math:`y_\textrm{pred}` by
    :math:`\mathrm{Var}[Y_i] = \phi/s_i*v(y_\textrm{pred}_i)`.
    It can also be derived from the unit deviance
    :math:`d(y,y_\textrm{pred})` as

    .. math:: v(y_\textrm{pred}) = \frac{2}{
        \frac{\partial^2 d(y,y_\textrm{pred})}{
        \partialy_\textrm{pred}^2}}\big|_{y=y_\textrm{pred}}

    See also :func:`variance`.

    Parameters
    ----------
    y_pred : array of shape (n_samples,)
        Predicted mean.</pre> 
<p>Reimplemented in <a class="el" href="classsklearn_1_1__loss_1_1glm__distribution_1_1_tweedie_distribution.html#a917c31fac208ea0ddf4a7abf5b15d30f">sklearn._loss.glm_distribution.TweedieDistribution</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   73</span>    <span class="keyword">def </span>unit_variance(self, y_pred):</div>
<div class="line"><span class="lineno">   74</span>        <span class="stringliteral">r&quot;&quot;&quot;Compute the unit variance function.</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">        The unit variance :math:`v(y_\textrm{pred})` determines the variance as</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">        a function of the mean :math:`y_\textrm{pred}` by</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">        :math:`\mathrm{Var}[Y_i] = \phi/s_i*v(y_\textrm{pred}_i)`.</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">        It can also be derived from the unit deviance</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">        :math:`d(y,y_\textrm{pred})` as</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">        .. math:: v(y_\textrm{pred}) = \frac{2}{</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">            \frac{\partial^2 d(y,y_\textrm{pred})}{</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral">            \partialy_\textrm{pred}^2}}\big|_{y=y_\textrm{pred}}</span></div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">        See also :func:`variance`.</span></div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">        y_pred : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">            Predicted mean.</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   93</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="aaef6dc9001da8082bbe55e96997306e2" name="aaef6dc9001da8082bbe55e96997306e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaef6dc9001da8082bbe55e96997306e2">&#9670;&#160;</a></span>_lower_bound</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.glm_distribution.ExponentialDispersionModel._lower_bound</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/rafael/Documents/GitHub/PUC-GCES-PY/Tp-GCS-Rafael-Augusto/venv/lib/python3.9/site-packages/sklearn/_loss/<a class="el" href="glm__distribution_8py.html">glm_distribution.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
