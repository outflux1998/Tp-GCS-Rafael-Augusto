<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.decomposition._fastica Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1decomposition.html">decomposition</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1decomposition_1_1__fastica.html">_fastica</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.decomposition._fastica Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1decomposition_1_1__fastica_1_1_fast_i_c_a.html">FastICA</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:aeba62014ab40e082044d2022296ff430" id="r_aeba62014ab40e082044d2022296ff430"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1decomposition_1_1__fastica.html#aeba62014ab40e082044d2022296ff430">_gs_decorrelation</a> (<a class="el" href="__lapack__subroutines_8h.html#a817b85d82af73ef273fafbec623bb90b">w</a>, W, <a class="el" href="__lapack__subroutines_8h.html#a7a2934b0e050f997202d3f47a979d888">j</a>)</td></tr>
<tr class="separator:aeba62014ab40e082044d2022296ff430"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a633a2f03b59b1af32078df1020f9e25e" id="r_a633a2f03b59b1af32078df1020f9e25e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1decomposition_1_1__fastica.html#a633a2f03b59b1af32078df1020f9e25e">_sym_decorrelation</a> (W)</td></tr>
<tr class="separator:a633a2f03b59b1af32078df1020f9e25e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aebd4cfe9cbe517d97d769aa5273d7f3b" id="r_aebd4cfe9cbe517d97d769aa5273d7f3b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1decomposition_1_1__fastica.html#aebd4cfe9cbe517d97d769aa5273d7f3b">_ica_def</a> (X, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>, <a class="el" href="__lapack__subroutines_8h.html#aeb0d2dd2a2609d5775607acf542b2161">g</a>, fun_args, max_iter, w_init)</td></tr>
<tr class="separator:aebd4cfe9cbe517d97d769aa5273d7f3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b727515f60c5eac985701caed6269ec" id="r_a5b727515f60c5eac985701caed6269ec"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1decomposition_1_1__fastica.html#a5b727515f60c5eac985701caed6269ec">_ica_par</a> (X, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>, <a class="el" href="__lapack__subroutines_8h.html#aeb0d2dd2a2609d5775607acf542b2161">g</a>, fun_args, max_iter, w_init)</td></tr>
<tr class="separator:a5b727515f60c5eac985701caed6269ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad991976119fb309e5a54db7838840f7b" id="r_ad991976119fb309e5a54db7838840f7b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1decomposition_1_1__fastica.html#ad991976119fb309e5a54db7838840f7b">_logcosh</a> (x, fun_args=None)</td></tr>
<tr class="separator:ad991976119fb309e5a54db7838840f7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a5d4d6dad5bbb115a23a63908572441" id="r_a9a5d4d6dad5bbb115a23a63908572441"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1decomposition_1_1__fastica.html#a9a5d4d6dad5bbb115a23a63908572441">_exp</a> (x, fun_args)</td></tr>
<tr class="separator:a9a5d4d6dad5bbb115a23a63908572441"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b1c21eff504c2701e5f32e7f4f0fe48" id="r_a7b1c21eff504c2701e5f32e7f4f0fe48"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1decomposition_1_1__fastica.html#a7b1c21eff504c2701e5f32e7f4f0fe48">_cube</a> (x, fun_args)</td></tr>
<tr class="separator:a7b1c21eff504c2701e5f32e7f4f0fe48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaafb25f18c1156b87d7b0359e611effc" id="r_aaafb25f18c1156b87d7b0359e611effc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1decomposition_1_1__fastica.html#aaafb25f18c1156b87d7b0359e611effc">fastica</a> (X, n_components=None, *algorithm=&quot;parallel&quot;, whiten=&quot;warn&quot;, fun=&quot;logcosh&quot;, fun_args=None, max_iter=200, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-04, w_init=None, whiten_solver=&quot;svd&quot;, random_state=None, return_X_mean=False, compute_sources=True, return_n_iter=False)</td></tr>
<tr class="separator:aaafb25f18c1156b87d7b0359e611effc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Python implementation of the fast ICA algorithms.

Reference: Tables 8.3 and 8.4 page 196 in the book:
Independent Component Analysis, by  Hyvarinen et al.
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a7b1c21eff504c2701e5f32e7f4f0fe48" name="a7b1c21eff504c2701e5f32e7f4f0fe48"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b1c21eff504c2701e5f32e7f4f0fe48">&#9670;&#160;</a></span>_cube()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.decomposition._fastica._cube </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun_args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  153</span><span class="keyword">def </span>_cube(x, fun_args):</div>
<div class="line"><span class="lineno">  154</span>    <span class="keywordflow">return</span> x**3, (3 * x**2).mean(axis=-1)</div>
<div class="line"><span class="lineno">  155</span> </div>
<div class="line"><span class="lineno">  156</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9a5d4d6dad5bbb115a23a63908572441" name="a9a5d4d6dad5bbb115a23a63908572441"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a5d4d6dad5bbb115a23a63908572441">&#9670;&#160;</a></span>_exp()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.decomposition._fastica._exp </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun_args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  146</span><span class="keyword">def </span>_exp(x, fun_args):</div>
<div class="line"><span class="lineno">  147</span>    exp = np.exp(-(x**2) / 2)</div>
<div class="line"><span class="lineno">  148</span>    gx = x * exp</div>
<div class="line"><span class="lineno">  149</span>    g_x = (1 - x**2) * exp</div>
<div class="line"><span class="lineno">  150</span>    <span class="keywordflow">return</span> gx, g_x.mean(axis=-1)</div>
<div class="line"><span class="lineno">  151</span> </div>
<div class="line"><span class="lineno">  152</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aeba62014ab40e082044d2022296ff430" name="aeba62014ab40e082044d2022296ff430"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeba62014ab40e082044d2022296ff430">&#9670;&#160;</a></span>_gs_decorrelation()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.decomposition._fastica._gs_decorrelation </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>j</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Orthonormalize w wrt the first j rows of W.

Parameters
----------
w : ndarray of shape (n,)
    Array to be orthogonalized

W : ndarray of shape (p, n)
    Null space definition

j : int &lt; p
    The no of (from the first) rows of Null space W wrt which w is
    orthogonalized.

Notes
-----
Assumes that W is orthogonal
w changed in place
</pre> <div class="fragment"><div class="line"><span class="lineno">   27</span><span class="keyword">def </span>_gs_decorrelation(w, W, j):</div>
<div class="line"><span class="lineno">   28</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">    Orthonormalize w wrt the first j rows of W.</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">    w : ndarray of shape (n,)</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">        Array to be orthogonalized</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">    W : ndarray of shape (p, n)</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral">        Null space definition</span></div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">    j : int &lt; p</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">        The no of (from the first) rows of Null space W wrt which w is</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">        orthogonalized.</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">    Assumes that W is orthogonal</span></div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">    w changed in place</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   48</span>    w -= np.linalg.multi_dot([w, W[:j].T, W[:j]])</div>
<div class="line"><span class="lineno">   49</span>    <span class="keywordflow">return</span> w</div>
<div class="line"><span class="lineno">   50</span> </div>
<div class="line"><span class="lineno">   51</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aebd4cfe9cbe517d97d769aa5273d7f3b" name="aebd4cfe9cbe517d97d769aa5273d7f3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aebd4cfe9cbe517d97d769aa5273d7f3b">&#9670;&#160;</a></span>_ica_def()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.decomposition._fastica._ica_def </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>g</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun_args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w_init</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Deflationary FastICA using fun approx to neg-entropy function

Used internally by FastICA.
</pre> <div class="fragment"><div class="line"><span class="lineno">   67</span><span class="keyword">def </span>_ica_def(X, tol, g, fun_args, max_iter, w_init):</div>
<div class="line"><span class="lineno">   68</span>    <span class="stringliteral">&quot;&quot;&quot;Deflationary FastICA using fun approx to neg-entropy function</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    Used internally by FastICA.</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   72</span> </div>
<div class="line"><span class="lineno">   73</span>    n_components = w_init.shape[0]</div>
<div class="line"><span class="lineno">   74</span>    W = np.zeros((n_components, n_components), dtype=X.dtype)</div>
<div class="line"><span class="lineno">   75</span>    n_iter = []</div>
<div class="line"><span class="lineno">   76</span> </div>
<div class="line"><span class="lineno">   77</span>    <span class="comment"># j is the index of the extracted component</span></div>
<div class="line"><span class="lineno">   78</span>    <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(n_components):</div>
<div class="line"><span class="lineno">   79</span>        w = w_init[j, :].copy()</div>
<div class="line"><span class="lineno">   80</span>        w /= np.sqrt((w**2).sum())</div>
<div class="line"><span class="lineno">   81</span> </div>
<div class="line"><span class="lineno">   82</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(max_iter):</div>
<div class="line"><span class="lineno">   83</span>            gwtx, g_wtx = <a class="code hl_variable" href="__lapack__subroutines_8h.html#aeb0d2dd2a2609d5775607acf542b2161">g</a>(np.dot(w.T, X), fun_args)</div>
<div class="line"><span class="lineno">   84</span> </div>
<div class="line"><span class="lineno">   85</span>            w1 = (X * gwtx).mean(axis=1) - g_wtx.mean() * w</div>
<div class="line"><span class="lineno">   86</span> </div>
<div class="line"><span class="lineno">   87</span>            _gs_decorrelation(w1, W, j)</div>
<div class="line"><span class="lineno">   88</span> </div>
<div class="line"><span class="lineno">   89</span>            w1 /= np.sqrt((w1**2).sum())</div>
<div class="line"><span class="lineno">   90</span> </div>
<div class="line"><span class="lineno">   91</span>            lim = np.abs(np.abs((w1 * w).sum()) - 1)</div>
<div class="line"><span class="lineno">   92</span>            w = w1</div>
<div class="line"><span class="lineno">   93</span>            <span class="keywordflow">if</span> lim &lt; tol:</div>
<div class="line"><span class="lineno">   94</span>                <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">   95</span> </div>
<div class="line"><span class="lineno">   96</span>        n_iter.append(i + 1)</div>
<div class="line"><span class="lineno">   97</span>        W[j, :] = w</div>
<div class="line"><span class="lineno">   98</span> </div>
<div class="line"><span class="lineno">   99</span>    <span class="keywordflow">return</span> W, max(n_iter)</div>
<div class="line"><span class="lineno">  100</span> </div>
<div class="line"><span class="lineno">  101</span> </div>
<div class="ttc" id="a__lapack__subroutines_8h_html_aeb0d2dd2a2609d5775607acf542b2161"><div class="ttname"><a href="__lapack__subroutines_8h.html#aeb0d2dd2a2609d5775607acf542b2161">g</a></div><div class="ttdeci">void npy_complex64 * g</div><div class="ttdef"><b>Definition</b> _lapack_subroutines.h:284</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a5b727515f60c5eac985701caed6269ec" name="a5b727515f60c5eac985701caed6269ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5b727515f60c5eac985701caed6269ec">&#9670;&#160;</a></span>_ica_par()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.decomposition._fastica._ica_par </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>g</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun_args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w_init</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Parallel FastICA.

Used internally by FastICA --main loop</pre> <div class="fragment"><div class="line"><span class="lineno">  102</span><span class="keyword">def </span>_ica_par(X, tol, g, fun_args, max_iter, w_init):</div>
<div class="line"><span class="lineno">  103</span>    <span class="stringliteral">&quot;&quot;&quot;Parallel FastICA.</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral">    Used internally by FastICA --main loop</span></div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  108</span>    W = _sym_decorrelation(w_init)</div>
<div class="line"><span class="lineno">  109</span>    del w_init</div>
<div class="line"><span class="lineno">  110</span>    p_ = float(X.shape[1])</div>
<div class="line"><span class="lineno">  111</span>    <span class="keywordflow">for</span> ii <span class="keywordflow">in</span> range(max_iter):</div>
<div class="line"><span class="lineno">  112</span>        gwtx, g_wtx = <a class="code hl_variable" href="__lapack__subroutines_8h.html#aeb0d2dd2a2609d5775607acf542b2161">g</a>(np.dot(W, X), fun_args)</div>
<div class="line"><span class="lineno">  113</span>        W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)</div>
<div class="line"><span class="lineno">  114</span>        del gwtx, g_wtx</div>
<div class="line"><span class="lineno">  115</span>        <span class="comment"># builtin max, abs are faster than numpy counter parts.</span></div>
<div class="line"><span class="lineno">  116</span>        <span class="comment"># np.einsum allows having the lowest memory footprint.</span></div>
<div class="line"><span class="lineno">  117</span>        <span class="comment"># It is faster than np.diag(np.dot(W1, W.T)).</span></div>
<div class="line"><span class="lineno">  118</span>        lim = max(abs(abs(np.einsum(<span class="stringliteral">&quot;ij,ij-&gt;i&quot;</span>, W1, W)) - 1))</div>
<div class="line"><span class="lineno">  119</span>        W = W1</div>
<div class="line"><span class="lineno">  120</span>        <span class="keywordflow">if</span> lim &lt; tol:</div>
<div class="line"><span class="lineno">  121</span>            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  122</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  123</span>        warnings.warn(</div>
<div class="line"><span class="lineno">  124</span>            <span class="stringliteral">&quot;FastICA did not converge. Consider increasing &quot;</span></div>
<div class="line"><span class="lineno">  125</span>            <span class="stringliteral">&quot;tolerance or the maximum number of iterations.&quot;</span>,</div>
<div class="line"><span class="lineno">  126</span>            ConvergenceWarning,</div>
<div class="line"><span class="lineno">  127</span>        )</div>
<div class="line"><span class="lineno">  128</span> </div>
<div class="line"><span class="lineno">  129</span>    <span class="keywordflow">return</span> W, ii + 1</div>
<div class="line"><span class="lineno">  130</span> </div>
<div class="line"><span class="lineno">  131</span> </div>
<div class="line"><span class="lineno">  132</span><span class="comment"># Some standard non-linear functions.</span></div>
<div class="line"><span class="lineno">  133</span><span class="comment"># XXX: these should be optimized, as they can be a bottleneck.</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ad991976119fb309e5a54db7838840f7b" name="ad991976119fb309e5a54db7838840f7b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad991976119fb309e5a54db7838840f7b">&#9670;&#160;</a></span>_logcosh()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.decomposition._fastica._logcosh </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun_args</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  134</span><span class="keyword">def </span>_logcosh(x, fun_args=None):</div>
<div class="line"><span class="lineno">  135</span>    alpha = fun_args.get(<span class="stringliteral">&quot;alpha&quot;</span>, 1.0)  <span class="comment"># comment it out?</span></div>
<div class="line"><span class="lineno">  136</span> </div>
<div class="line"><span class="lineno">  137</span>    x *= alpha</div>
<div class="line"><span class="lineno">  138</span>    gx = np.tanh(x, x)  <span class="comment"># apply the tanh inplace</span></div>
<div class="line"><span class="lineno">  139</span>    g_x = np.empty(x.shape[0], dtype=x.dtype)</div>
<div class="line"><span class="lineno">  140</span>    <span class="comment"># XXX compute in chunks to avoid extra allocation</span></div>
<div class="line"><span class="lineno">  141</span>    <span class="keywordflow">for</span> i, gx_i <span class="keywordflow">in</span> enumerate(gx):  <span class="comment"># please don&#39;t vectorize.</span></div>
<div class="line"><span class="lineno">  142</span>        g_x[i] = (alpha * (1 - gx_i**2)).mean()</div>
<div class="line"><span class="lineno">  143</span>    <span class="keywordflow">return</span> gx, g_x</div>
<div class="line"><span class="lineno">  144</span> </div>
<div class="line"><span class="lineno">  145</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a633a2f03b59b1af32078df1020f9e25e" name="a633a2f03b59b1af32078df1020f9e25e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a633a2f03b59b1af32078df1020f9e25e">&#9670;&#160;</a></span>_sym_decorrelation()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.decomposition._fastica._sym_decorrelation </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>W</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Symmetric decorrelation
i.e. W &lt;- (W * W.T) ^{-1/2} * W
</pre> <div class="fragment"><div class="line"><span class="lineno">   52</span><span class="keyword">def </span>_sym_decorrelation(W):</div>
<div class="line"><span class="lineno">   53</span>    <span class="stringliteral">&quot;&quot;&quot;Symmetric decorrelation</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral">    i.e. W &lt;- (W * W.T) ^{-1/2} * W</span></div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   56</span>    s, u = linalg.eigh(np.dot(W, W.T))</div>
<div class="line"><span class="lineno">   57</span>    <span class="comment"># Avoid sqrt of negative values because of rounding errors. Note that</span></div>
<div class="line"><span class="lineno">   58</span>    <span class="comment"># np.sqrt(tiny) is larger than tiny and therefore this clipping also</span></div>
<div class="line"><span class="lineno">   59</span>    <span class="comment"># prevents division by zero in the next step.</span></div>
<div class="line"><span class="lineno">   60</span>    s = np.clip(s, a_min=np.finfo(W.dtype).tiny, a_max=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">   61</span> </div>
<div class="line"><span class="lineno">   62</span>    <span class="comment"># u (resp. s) contains the eigenvectors (resp. square roots of</span></div>
<div class="line"><span class="lineno">   63</span>    <span class="comment"># the eigenvalues) of W * W.T</span></div>
<div class="line"><span class="lineno">   64</span>    <span class="keywordflow">return</span> np.linalg.multi_dot([u * (1.0 / np.sqrt(s)), u.T, W])</div>
<div class="line"><span class="lineno">   65</span> </div>
<div class="line"><span class="lineno">   66</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aaafb25f18c1156b87d7b0359e611effc" name="aaafb25f18c1156b87d7b0359e611effc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaafb25f18c1156b87d7b0359e611effc">&#9670;&#160;</a></span>fastica()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.decomposition._fastica.fastica </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_components</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>algorithm</em> = <code>&quot;parallel&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>whiten</em> = <code>&quot;warn&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun</em> = <code>&quot;logcosh&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun_args</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>200</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-04</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w_init</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>whiten_solver</em> = <code>&quot;svd&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_X_mean</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>compute_sources</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_n_iter</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Perform Fast Independent Component Analysis.

The implementation is based on [1]_.

Read more in the :ref:`User Guide &lt;ICA&gt;`.

Parameters
----------
X : array-like of shape (n_samples, n_features)
    Training vector, where `n_samples` is the number of samples and
    `n_features` is the number of features.

n_components : int, default=None
    Number of components to use. If None is passed, all are used.

algorithm : {'parallel', 'deflation'}, default='parallel'
    Specify which algorithm to use for FastICA.

whiten : str or bool, default="warn"
    Specify the whitening strategy to use.

    - If 'arbitrary-variance' (default), a whitening with variance
      arbitrary is used.
    - If 'unit-variance', the whitening matrix is rescaled to ensure that
      each recovered source has unit variance.
    - If False, the data is already considered to be whitened, and no
      whitening is performed.

    .. deprecated:: 1.1
        Starting in v1.3, `whiten='unit-variance'` will be used by default.
        `whiten=True` is deprecated from 1.1 and will raise ValueError in 1.3.
        Use `whiten=arbitrary-variance` instead.

fun : {'logcosh', 'exp', 'cube'} or callable, default='logcosh'
    The functional form of the G function used in the
    approximation to neg-entropy. Could be either 'logcosh', 'exp',
    or 'cube'.
    You can also provide your own function. It should return a tuple
    containing the value of the function, and of its derivative, in the
    point. The derivative should be averaged along its last dimension.
    Example::

        def my_g(x):
            return x ** 3, (3 * x ** 2).mean(axis=-1)

fun_args : dict, default=None
    Arguments to send to the functional form.
    If empty or None and if fun='logcosh', fun_args will take value
    {'alpha' : 1.0}.

max_iter : int, default=200
    Maximum number of iterations to perform.

tol : float, default=1e-4
    A positive scalar giving the tolerance at which the
    un-mixing matrix is considered to have converged.

w_init : ndarray of shape (n_components, n_components), default=None
    Initial un-mixing array. If `w_init=None`, then an array of values
    drawn from a normal distribution is used.

whiten_solver : {"eigh", "svd"}, default="svd"
    The solver to use for whitening.

    - "svd" is more stable numerically if the problem is degenerate, and
      often faster when `n_samples &lt;= n_features`.

    - "eigh" is generally more memory efficient when
      `n_samples &gt;= n_features`, and can be faster when
      `n_samples &gt;= 50 * n_features`.

    .. versionadded:: 1.2

random_state : int, RandomState instance or None, default=None
    Used to initialize ``w_init`` when not specified, with a
    normal distribution. Pass an int, for reproducible results
    across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

return_X_mean : bool, default=False
    If True, X_mean is returned too.

compute_sources : bool, default=True
    If False, sources are not computed, but only the rotation matrix.
    This can save memory when working with big data. Defaults to True.

return_n_iter : bool, default=False
    Whether or not to return the number of iterations.

Returns
-------
K : ndarray of shape (n_components, n_features) or None
    If whiten is 'True', K is the pre-whitening matrix that projects data
    onto the first n_components principal components. If whiten is 'False',
    K is 'None'.

W : ndarray of shape (n_components, n_components)
    The square matrix that unmixes the data after whitening.
    The mixing matrix is the pseudo-inverse of matrix ``W K``
    if K is not None, else it is the inverse of W.

S : ndarray of shape (n_samples, n_components) or None
    Estimated source matrix.

X_mean : ndarray of shape (n_features,)
    The mean over features. Returned only if return_X_mean is True.

n_iter : int
    If the algorithm is "deflation", n_iter is the
    maximum number of iterations run across all components. Else
    they are just the number of iterations taken to converge. This is
    returned only when return_n_iter is set to `True`.

Notes
-----
The data matrix X is considered to be a linear combination of
non-Gaussian (independent) components i.e. X = AS where columns of S
contain the independent components and A is a linear mixing
matrix. In short ICA attempts to `un-mix' the data by estimating an
un-mixing matrix W where ``S = W K X.``
While FastICA was proposed to estimate as many sources
as features, it is possible to estimate less by setting
n_components &lt; n_features. It this case K is not a square matrix
and the estimated A is the pseudo-inverse of ``W K``.

This implementation was originally made for data of shape
[n_features, n_samples]. Now the input is transposed
before the algorithm is applied. This makes it slightly
faster for Fortran-ordered input.

References
----------
.. [1] A. Hyvarinen and E. Oja, "Fast Independent Component Analysis",
       Algorithms and Applications, Neural Networks, 13(4-5), 2000,
       pp. 411-430.
</pre> <div class="fragment"><div class="line"><span class="lineno">  173</span>):</div>
<div class="line"><span class="lineno">  174</span>    <span class="stringliteral">&quot;&quot;&quot;Perform Fast Independent Component Analysis.</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">    The implementation is based on [1]_.</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;ICA&gt;`.</span></div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">    X : array-like of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">        Training vector, where `n_samples` is the number of samples and</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral">        `n_features` is the number of features.</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">    n_components : int, default=None</span></div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">        Number of components to use. If None is passed, all are used.</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">    algorithm : {&#39;parallel&#39;, &#39;deflation&#39;}, default=&#39;parallel&#39;</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral">        Specify which algorithm to use for FastICA.</span></div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">    whiten : str or bool, default=&quot;warn&quot;</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral">        Specify the whitening strategy to use.</span></div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">        - If &#39;arbitrary-variance&#39; (default), a whitening with variance</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral">          arbitrary is used.</span></div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral">        - If &#39;unit-variance&#39;, the whitening matrix is rescaled to ensure that</span></div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral">          each recovered source has unit variance.</span></div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">        - If False, the data is already considered to be whitened, and no</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral">          whitening is performed.</span></div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral">        .. deprecated:: 1.1</span></div>
<div class="line"><span class="lineno">  203</span><span class="stringliteral">            Starting in v1.3, `whiten=&#39;unit-variance&#39;` will be used by default.</span></div>
<div class="line"><span class="lineno">  204</span><span class="stringliteral">            `whiten=True` is deprecated from 1.1 and will raise ValueError in 1.3.</span></div>
<div class="line"><span class="lineno">  205</span><span class="stringliteral">            Use `whiten=arbitrary-variance` instead.</span></div>
<div class="line"><span class="lineno">  206</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral">    fun : {&#39;logcosh&#39;, &#39;exp&#39;, &#39;cube&#39;} or callable, default=&#39;logcosh&#39;</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">        The functional form of the G function used in the</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">        approximation to neg-entropy. Could be either &#39;logcosh&#39;, &#39;exp&#39;,</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">        or &#39;cube&#39;.</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">        You can also provide your own function. It should return a tuple</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">        containing the value of the function, and of its derivative, in the</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral">        point. The derivative should be averaged along its last dimension.</span></div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">        Example::</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">            def my_g(x):</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">                return x ** 3, (3 * x ** 2).mean(axis=-1)</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">    fun_args : dict, default=None</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">        Arguments to send to the functional form.</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">        If empty or None and if fun=&#39;logcosh&#39;, fun_args will take value</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">        {&#39;alpha&#39; : 1.0}.</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">    max_iter : int, default=200</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">        Maximum number of iterations to perform.</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">    tol : float, default=1e-4</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">        A positive scalar giving the tolerance at which the</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">        un-mixing matrix is considered to have converged.</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">    w_init : ndarray of shape (n_components, n_components), default=None</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">        Initial un-mixing array. If `w_init=None`, then an array of values</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">        drawn from a normal distribution is used.</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">    whiten_solver : {&quot;eigh&quot;, &quot;svd&quot;}, default=&quot;svd&quot;</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">        The solver to use for whitening.</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">        - &quot;svd&quot; is more stable numerically if the problem is degenerate, and</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">          often faster when `n_samples &lt;= n_features`.</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">        - &quot;eigh&quot; is generally more memory efficient when</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">          `n_samples &gt;= n_features`, and can be faster when</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">          `n_samples &gt;= 50 * n_features`.</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">        .. versionadded:: 1.2</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">    random_state : int, RandomState instance or None, default=None</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">        Used to initialize ``w_init`` when not specified, with a</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">        normal distribution. Pass an int, for reproducible results</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">        across multiple function calls.</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">    return_X_mean : bool, default=False</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">        If True, X_mean is returned too.</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">    compute_sources : bool, default=True</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">        If False, sources are not computed, but only the rotation matrix.</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">        This can save memory when working with big data. Defaults to True.</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">    return_n_iter : bool, default=False</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">        Whether or not to return the number of iterations.</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">    K : ndarray of shape (n_components, n_features) or None</span></div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">        If whiten is &#39;True&#39;, K is the pre-whitening matrix that projects data</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">        onto the first n_components principal components. If whiten is &#39;False&#39;,</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">        K is &#39;None&#39;.</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">    W : ndarray of shape (n_components, n_components)</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">        The square matrix that unmixes the data after whitening.</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral">        The mixing matrix is the pseudo-inverse of matrix ``W K``</span></div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">        if K is not None, else it is the inverse of W.</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">    S : ndarray of shape (n_samples, n_components) or None</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">        Estimated source matrix.</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">    X_mean : ndarray of shape (n_features,)</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">        The mean over features. Returned only if return_X_mean is True.</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    n_iter : int</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">        If the algorithm is &quot;deflation&quot;, n_iter is the</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">        maximum number of iterations run across all components. Else</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">        they are just the number of iterations taken to converge. This is</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">        returned only when return_n_iter is set to `True`.</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">    The data matrix X is considered to be a linear combination of</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">    non-Gaussian (independent) components i.e. X = AS where columns of S</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">    contain the independent components and A is a linear mixing</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">    matrix. In short ICA attempts to `un-mix&#39; the data by estimating an</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">    un-mixing matrix W where ``S = W K X.``</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">    While FastICA was proposed to estimate as many sources</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">    as features, it is possible to estimate less by setting</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">    n_components &lt; n_features. It this case K is not a square matrix</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">    and the estimated A is the pseudo-inverse of ``W K``.</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">    This implementation was originally made for data of shape</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">    [n_features, n_samples]. Now the input is transposed</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">    before the algorithm is applied. This makes it slightly</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">    faster for Fortran-ordered input.</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    .. [1] A. Hyvarinen and E. Oja, &quot;Fast Independent Component Analysis&quot;,</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">           Algorithms and Applications, Neural Networks, 13(4-5), 2000,</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">           pp. 411-430.</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  310</span>    est = FastICA(</div>
<div class="line"><span class="lineno">  311</span>        n_components=n_components,</div>
<div class="line"><span class="lineno">  312</span>        algorithm=algorithm,</div>
<div class="line"><span class="lineno">  313</span>        whiten=whiten,</div>
<div class="line"><span class="lineno">  314</span>        fun=fun,</div>
<div class="line"><span class="lineno">  315</span>        fun_args=fun_args,</div>
<div class="line"><span class="lineno">  316</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  317</span>        tol=tol,</div>
<div class="line"><span class="lineno">  318</span>        w_init=w_init,</div>
<div class="line"><span class="lineno">  319</span>        whiten_solver=whiten_solver,</div>
<div class="line"><span class="lineno">  320</span>        random_state=random_state,</div>
<div class="line"><span class="lineno">  321</span>    )</div>
<div class="line"><span class="lineno">  322</span>    S = est._fit_transform(X, compute_sources=compute_sources)</div>
<div class="line"><span class="lineno">  323</span> </div>
<div class="line"><span class="lineno">  324</span>    <span class="keywordflow">if</span> est._whiten <span class="keywordflow">in</span> [<span class="stringliteral">&quot;unit-variance&quot;</span>, <span class="stringliteral">&quot;arbitrary-variance&quot;</span>]:</div>
<div class="line"><span class="lineno">  325</span>        K = est.whitening_</div>
<div class="line"><span class="lineno">  326</span>        X_mean = est.mean_</div>
<div class="line"><span class="lineno">  327</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  328</span>        K = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  329</span>        X_mean = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  330</span> </div>
<div class="line"><span class="lineno">  331</span>    returned_values = [K, est._unmixing, S]</div>
<div class="line"><span class="lineno">  332</span>    <span class="keywordflow">if</span> return_X_mean:</div>
<div class="line"><span class="lineno">  333</span>        returned_values.append(X_mean)</div>
<div class="line"><span class="lineno">  334</span>    <span class="keywordflow">if</span> return_n_iter:</div>
<div class="line"><span class="lineno">  335</span>        returned_values.append(est.n_iter_)</div>
<div class="line"><span class="lineno">  336</span> </div>
<div class="line"><span class="lineno">  337</span>    <span class="keywordflow">return</span> returned_values</div>
<div class="line"><span class="lineno">  338</span> </div>
<div class="line"><span class="lineno">  339</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
