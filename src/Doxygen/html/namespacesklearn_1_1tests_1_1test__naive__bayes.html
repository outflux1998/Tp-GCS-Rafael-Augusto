<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.tests.test_naive_bayes Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html">test_naive_bayes</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.tests.test_naive_bayes Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a10f722aede94044416c7cdd4e3cf7b2f" id="r_a10f722aede94044416c7cdd4e3cf7b2f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a10f722aede94044416c7cdd4e3cf7b2f">test_gnb</a> ()</td></tr>
<tr class="separator:a10f722aede94044416c7cdd4e3cf7b2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1595e0a53e81a04a44df2d97ac251589" id="r_a1595e0a53e81a04a44df2d97ac251589"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a1595e0a53e81a04a44df2d97ac251589">test_gnb_prior</a> ()</td></tr>
<tr class="separator:a1595e0a53e81a04a44df2d97ac251589"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08fb05d56b221cc96f5bf0306c8fa08d" id="r_a08fb05d56b221cc96f5bf0306c8fa08d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a08fb05d56b221cc96f5bf0306c8fa08d">test_gnb_sample_weight</a> ()</td></tr>
<tr class="separator:a08fb05d56b221cc96f5bf0306c8fa08d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24f28303585c3d70aacc4adcf97307ea" id="r_a24f28303585c3d70aacc4adcf97307ea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a24f28303585c3d70aacc4adcf97307ea">test_gnb_neg_priors</a> ()</td></tr>
<tr class="separator:a24f28303585c3d70aacc4adcf97307ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a593edb7ebb05a84b93e4ed98d8064af4" id="r_a593edb7ebb05a84b93e4ed98d8064af4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a593edb7ebb05a84b93e4ed98d8064af4">test_gnb_priors</a> ()</td></tr>
<tr class="separator:a593edb7ebb05a84b93e4ed98d8064af4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed95c6e9135463debcf139a3923962b0" id="r_aed95c6e9135463debcf139a3923962b0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#aed95c6e9135463debcf139a3923962b0">test_gnb_priors_sum_isclose</a> ()</td></tr>
<tr class="separator:aed95c6e9135463debcf139a3923962b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af854e2f16e8ba8fec0292f6134ed93b2" id="r_af854e2f16e8ba8fec0292f6134ed93b2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#af854e2f16e8ba8fec0292f6134ed93b2">test_gnb_wrong_nb_priors</a> ()</td></tr>
<tr class="separator:af854e2f16e8ba8fec0292f6134ed93b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fe35ef9f827aef2b0a9a81aeed167b6" id="r_a5fe35ef9f827aef2b0a9a81aeed167b6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a5fe35ef9f827aef2b0a9a81aeed167b6">test_gnb_prior_greater_one</a> ()</td></tr>
<tr class="separator:a5fe35ef9f827aef2b0a9a81aeed167b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98e7ea888345d76e7ba0d3e76b2aef2a" id="r_a98e7ea888345d76e7ba0d3e76b2aef2a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a98e7ea888345d76e7ba0d3e76b2aef2a">test_gnb_prior_large_bias</a> ()</td></tr>
<tr class="separator:a98e7ea888345d76e7ba0d3e76b2aef2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0af02e03e40b1fc19cdd4756bd75e62a" id="r_a0af02e03e40b1fc19cdd4756bd75e62a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a0af02e03e40b1fc19cdd4756bd75e62a">test_gnb_check_update_with_no_data</a> ()</td></tr>
<tr class="separator:a0af02e03e40b1fc19cdd4756bd75e62a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59129051ec35ecad52b5675db81dd683" id="r_a59129051ec35ecad52b5675db81dd683"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a59129051ec35ecad52b5675db81dd683">test_gnb_partial_fit</a> ()</td></tr>
<tr class="separator:a59129051ec35ecad52b5675db81dd683"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a484722e8fb10577aa40661a1dc4a7c91" id="r_a484722e8fb10577aa40661a1dc4a7c91"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a484722e8fb10577aa40661a1dc4a7c91">test_gnb_naive_bayes_scale_invariance</a> ()</td></tr>
<tr class="separator:a484722e8fb10577aa40661a1dc4a7c91"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06cc638a18fa4ea249ea52023ee41069" id="r_a06cc638a18fa4ea249ea52023ee41069"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a06cc638a18fa4ea249ea52023ee41069">test_discretenb_prior</a> (DiscreteNaiveBayes)</td></tr>
<tr class="separator:a06cc638a18fa4ea249ea52023ee41069"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad24e2e895150360b59135d15a07bbe34" id="r_ad24e2e895150360b59135d15a07bbe34"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#ad24e2e895150360b59135d15a07bbe34">test_discretenb_partial_fit</a> (DiscreteNaiveBayes)</td></tr>
<tr class="separator:ad24e2e895150360b59135d15a07bbe34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af267455721e4bd81d241229c85a15cb8" id="r_af267455721e4bd81d241229c85a15cb8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#af267455721e4bd81d241229c85a15cb8">test_NB_partial_fit_no_first_classes</a> (NaiveBayes)</td></tr>
<tr class="separator:af267455721e4bd81d241229c85a15cb8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a450bed24d9a2fb5f35261c4dbdc611a7" id="r_a450bed24d9a2fb5f35261c4dbdc611a7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a450bed24d9a2fb5f35261c4dbdc611a7">test_discretenb_predict_proba</a> ()</td></tr>
<tr class="separator:a450bed24d9a2fb5f35261c4dbdc611a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a749d2395c201b8d559871c428240dde4" id="r_a749d2395c201b8d559871c428240dde4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a749d2395c201b8d559871c428240dde4">test_discretenb_uniform_prior</a> (DiscreteNaiveBayes)</td></tr>
<tr class="separator:a749d2395c201b8d559871c428240dde4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a469620e3cf5c36240d804f3eb48eb697" id="r_a469620e3cf5c36240d804f3eb48eb697"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a469620e3cf5c36240d804f3eb48eb697">test_discretenb_provide_prior</a> (DiscreteNaiveBayes)</td></tr>
<tr class="separator:a469620e3cf5c36240d804f3eb48eb697"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0059bf50c507f6852fa5ff7bfc694afc" id="r_a0059bf50c507f6852fa5ff7bfc694afc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a0059bf50c507f6852fa5ff7bfc694afc">test_discretenb_provide_prior_with_partial_fit</a> (DiscreteNaiveBayes)</td></tr>
<tr class="separator:a0059bf50c507f6852fa5ff7bfc694afc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aceda898446067ce780ce330eb65a4926" id="r_aceda898446067ce780ce330eb65a4926"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#aceda898446067ce780ce330eb65a4926">test_discretenb_sample_weight_multiclass</a> (DiscreteNaiveBayes)</td></tr>
<tr class="separator:aceda898446067ce780ce330eb65a4926"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade8900eb812925718c0ca8a6baffa293" id="r_ade8900eb812925718c0ca8a6baffa293"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#ade8900eb812925718c0ca8a6baffa293">test_discretenb_degenerate_one_class_case</a> (DiscreteNaiveBayes, use_partial_fit, train_on_single_class_y)</td></tr>
<tr class="separator:ade8900eb812925718c0ca8a6baffa293"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5f3e58251ade169125e660e16a636f6" id="r_af5f3e58251ade169125e660e16a636f6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#af5f3e58251ade169125e660e16a636f6">test_mnnb</a> (kind)</td></tr>
<tr class="separator:af5f3e58251ade169125e660e16a636f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8e89adf0e49608f80c6291200372230" id="r_aa8e89adf0e49608f80c6291200372230"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#aa8e89adf0e49608f80c6291200372230">test_mnb_prior_unobserved_targets</a> ()</td></tr>
<tr class="separator:aa8e89adf0e49608f80c6291200372230"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40369ac0efdffa181e75201e32e86489" id="r_a40369ac0efdffa181e75201e32e86489"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a40369ac0efdffa181e75201e32e86489">test_bnb</a> ()</td></tr>
<tr class="separator:a40369ac0efdffa181e75201e32e86489"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb4183b1daa342598ed7e1531a924a3f" id="r_afb4183b1daa342598ed7e1531a924a3f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#afb4183b1daa342598ed7e1531a924a3f">test_bnb_feature_log_prob</a> ()</td></tr>
<tr class="separator:afb4183b1daa342598ed7e1531a924a3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08a5a9cc8086b1fab516de6b832281be" id="r_a08a5a9cc8086b1fab516de6b832281be"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a08a5a9cc8086b1fab516de6b832281be">test_cnb</a> ()</td></tr>
<tr class="separator:a08a5a9cc8086b1fab516de6b832281be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a778da87caeded9faf3b89580826bd37f" id="r_a778da87caeded9faf3b89580826bd37f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a778da87caeded9faf3b89580826bd37f">test_categoricalnb</a> ()</td></tr>
<tr class="separator:a778da87caeded9faf3b89580826bd37f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa5dfc60c00fddfb7b30e70e1c696dbb" id="r_aaa5dfc60c00fddfb7b30e70e1c696dbb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#aaa5dfc60c00fddfb7b30e70e1c696dbb">test_categoricalnb_with_min_categories</a> (min_categories, exp_X1_count, exp_X2_count, new_X, exp_n_categories_)</td></tr>
<tr class="separator:aaa5dfc60c00fddfb7b30e70e1c696dbb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad03ed1e7ba8e0d8bcf5e49f9cfe2e3bd" id="r_ad03ed1e7ba8e0d8bcf5e49f9cfe2e3bd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#ad03ed1e7ba8e0d8bcf5e49f9cfe2e3bd">test_categoricalnb_min_categories_errors</a> (min_categories, error_msg)</td></tr>
<tr class="separator:ad03ed1e7ba8e0d8bcf5e49f9cfe2e3bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38bb7428e4d6ec59cbe1856b9c183c02" id="r_a38bb7428e4d6ec59cbe1856b9c183c02"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a38bb7428e4d6ec59cbe1856b9c183c02">test_alpha</a> ()</td></tr>
<tr class="separator:a38bb7428e4d6ec59cbe1856b9c183c02"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a428c394083017207c0a3bfea972e2df6" id="r_a428c394083017207c0a3bfea972e2df6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a428c394083017207c0a3bfea972e2df6">test_alpha_vector</a> ()</td></tr>
<tr class="separator:a428c394083017207c0a3bfea972e2df6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92f1fc88ce81e9764e8bb217d8c218d1" id="r_a92f1fc88ce81e9764e8bb217d8c218d1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a92f1fc88ce81e9764e8bb217d8c218d1">test_check_accuracy_on_digits</a> ()</td></tr>
<tr class="separator:a92f1fc88ce81e9764e8bb217d8c218d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7461afcd8f2b46bc08d6dc92c6595ff8" id="r_a7461afcd8f2b46bc08d6dc92c6595ff8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a7461afcd8f2b46bc08d6dc92c6595ff8">test_force_alpha_deprecation</a> (Estimator, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>)</td></tr>
<tr class="separator:a7461afcd8f2b46bc08d6dc92c6595ff8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adfec673f12b3d0ed01519e4b527ee684" id="r_adfec673f12b3d0ed01519e4b527ee684"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#adfec673f12b3d0ed01519e4b527ee684">test_check_alpha</a> ()</td></tr>
<tr class="separator:adfec673f12b3d0ed01519e4b527ee684"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28d2614f7d38235055f8388a8a3c6af4" id="r_a28d2614f7d38235055f8388a8a3c6af4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a28d2614f7d38235055f8388a8a3c6af4">test_predict_joint_proba</a> (Estimator)</td></tr>
<tr class="separator:a28d2614f7d38235055f8388a8a3c6af4"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a46f773bb00225ae439c4338e45142c86" id="r_a46f773bb00225ae439c4338e45142c86"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a46f773bb00225ae439c4338e45142c86">DISCRETE_NAIVE_BAYES_CLASSES</a> = [<a class="el" href="classsklearn_1_1naive__bayes_1_1_bernoulli_n_b.html">BernoulliNB</a>, <a class="el" href="classsklearn_1_1naive__bayes_1_1_categorical_n_b.html">CategoricalNB</a>, <a class="el" href="classsklearn_1_1naive__bayes_1_1_complement_n_b.html">ComplementNB</a>, <a class="el" href="classsklearn_1_1naive__bayes_1_1_multinomial_n_b.html">MultinomialNB</a>]</td></tr>
<tr class="separator:a46f773bb00225ae439c4338e45142c86"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac90db191e1ecbcec2171fb5a09f6e39a" id="r_ac90db191e1ecbcec2171fb5a09f6e39a"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#ac90db191e1ecbcec2171fb5a09f6e39a">ALL_NAIVE_BAYES_CLASSES</a> = <a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a46f773bb00225ae439c4338e45142c86">DISCRETE_NAIVE_BAYES_CLASSES</a> + [<a class="el" href="classsklearn_1_1naive__bayes_1_1_gaussian_n_b.html">GaussianNB</a>]</td></tr>
<tr class="separator:ac90db191e1ecbcec2171fb5a09f6e39a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e7ce65cbf15b02a1ba65565126783be" id="r_a3e7ce65cbf15b02a1ba65565126783be"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a3e7ce65cbf15b02a1ba65565126783be">msg</a> = &quot;The default value for `force_alpha` will change&quot;</td></tr>
<tr class="separator:a3e7ce65cbf15b02a1ba65565126783be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6374da7293667fd46a8e75c00d5fdd3" id="r_ab6374da7293667fd46a8e75c00d5fdd3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#ab6374da7293667fd46a8e75c00d5fdd3">pytestmark</a> = pytest.mark.filterwarnings(f&quot;ignore:{<a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a3e7ce65cbf15b02a1ba65565126783be">msg</a>}:FutureWarning&quot;)</td></tr>
<tr class="separator:ab6374da7293667fd46a8e75c00d5fdd3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aadbfd25e902ceed3b6877d17eefb313b" id="r_aadbfd25e902ceed3b6877d17eefb313b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#aadbfd25e902ceed3b6877d17eefb313b">X</a> = np.array([[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]])</td></tr>
<tr class="separator:aadbfd25e902ceed3b6877d17eefb313b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07a5c033abe5c93f1ecf29bc235c3795" id="r_a07a5c033abe5c93f1ecf29bc235c3795"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a07a5c033abe5c93f1ecf29bc235c3795">y</a> = np.array([1, 1, 1, 2, 2, 2])</td></tr>
<tr class="separator:a07a5c033abe5c93f1ecf29bc235c3795"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade2cf23d6f0539a259159dc58e1203ce" id="r_ade2cf23d6f0539a259159dc58e1203ce"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#ade2cf23d6f0539a259159dc58e1203ce">rng</a> = np.random.RandomState(0)</td></tr>
<tr class="separator:ade2cf23d6f0539a259159dc58e1203ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4955b6a8fd5acecdf1abccf6a9ef5076" id="r_a4955b6a8fd5acecdf1abccf6a9ef5076"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a4955b6a8fd5acecdf1abccf6a9ef5076">X1</a> = rng.normal(size=(10, 3))</td></tr>
<tr class="separator:a4955b6a8fd5acecdf1abccf6a9ef5076"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e5175c6e48adb67716497c9c163d8b0" id="r_a9e5175c6e48adb67716497c9c163d8b0"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a9e5175c6e48adb67716497c9c163d8b0">y1</a> = (rng.normal(size=(10)) &gt; 0).astype(int)</td></tr>
<tr class="separator:a9e5175c6e48adb67716497c9c163d8b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08a522c98c3606bbaebf9371d66624dd" id="r_a08a522c98c3606bbaebf9371d66624dd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a08a522c98c3606bbaebf9371d66624dd">X2</a> = rng.randint(5, size=(6, 100))</td></tr>
<tr class="separator:a08a522c98c3606bbaebf9371d66624dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa50840ed50270563ae3b37eb6c950c5" id="r_afa50840ed50270563ae3b37eb6c950c5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#afa50840ed50270563ae3b37eb6c950c5">y2</a> = np.array([1, 1, 2, 2, 3, 3])</td></tr>
<tr class="separator:afa50840ed50270563ae3b37eb6c950c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a38bb7428e4d6ec59cbe1856b9c183c02" name="a38bb7428e4d6ec59cbe1856b9c183c02"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38bb7428e4d6ec59cbe1856b9c183c02">&#9670;&#160;</a></span>test_alpha()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_alpha </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  791</span><span class="keyword">def </span>test_alpha():</div>
<div class="line"><span class="lineno">  792</span>    <span class="comment"># Setting alpha=0 should not output nan results when p(x_i|y_j)=0 is a case</span></div>
<div class="line"><span class="lineno">  793</span>    X = np.array([[1, 0], [1, 1]])</div>
<div class="line"><span class="lineno">  794</span>    y = np.array([0, 1])</div>
<div class="line"><span class="lineno">  795</span>    nb = BernoulliNB(alpha=0.0)</div>
<div class="line"><span class="lineno">  796</span>    msg = <span class="stringliteral">&quot;alpha too small will result in numeric errors, setting alpha = 1.0e-10&quot;</span></div>
<div class="line"><span class="lineno">  797</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno">  798</span>        nb.partial_fit(X, y, classes=[0, 1])</div>
<div class="line"><span class="lineno">  799</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno">  800</span>        nb.fit(X, y)</div>
<div class="line"><span class="lineno">  801</span>    prob = np.array([[1, 0], [0, 1]])</div>
<div class="line"><span class="lineno">  802</span>    assert_array_almost_equal(nb.predict_proba(X), prob)</div>
<div class="line"><span class="lineno">  803</span> </div>
<div class="line"><span class="lineno">  804</span>    nb = MultinomialNB(alpha=0.0)</div>
<div class="line"><span class="lineno">  805</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno">  806</span>        nb.partial_fit(X, y, classes=[0, 1])</div>
<div class="line"><span class="lineno">  807</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno">  808</span>        nb.fit(X, y)</div>
<div class="line"><span class="lineno">  809</span>    prob = np.array([[2.0 / 3, 1.0 / 3], [0, 1]])</div>
<div class="line"><span class="lineno">  810</span>    assert_array_almost_equal(nb.predict_proba(X), prob)</div>
<div class="line"><span class="lineno">  811</span> </div>
<div class="line"><span class="lineno">  812</span>    nb = CategoricalNB(alpha=0.0)</div>
<div class="line"><span class="lineno">  813</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno">  814</span>        nb.fit(X, y)</div>
<div class="line"><span class="lineno">  815</span>    prob = np.array([[1.0, 0.0], [0.0, 1.0]])</div>
<div class="line"><span class="lineno">  816</span>    assert_array_almost_equal(nb.predict_proba(X), prob)</div>
<div class="line"><span class="lineno">  817</span> </div>
<div class="line"><span class="lineno">  818</span>    <span class="comment"># Test sparse X</span></div>
<div class="line"><span class="lineno">  819</span>    X = <a class="code hl_class" href="classscipy_1_1sparse_1_1__csr_1_1csr__matrix.html">scipy.sparse.csr_matrix</a>(X)</div>
<div class="line"><span class="lineno">  820</span>    nb = BernoulliNB(alpha=0.0)</div>
<div class="line"><span class="lineno">  821</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno">  822</span>        nb.fit(X, y)</div>
<div class="line"><span class="lineno">  823</span>    prob = np.array([[1, 0], [0, 1]])</div>
<div class="line"><span class="lineno">  824</span>    assert_array_almost_equal(nb.predict_proba(X), prob)</div>
<div class="line"><span class="lineno">  825</span> </div>
<div class="line"><span class="lineno">  826</span>    nb = MultinomialNB(alpha=0.0)</div>
<div class="line"><span class="lineno">  827</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno">  828</span>        nb.fit(X, y)</div>
<div class="line"><span class="lineno">  829</span>    prob = np.array([[2.0 / 3, 1.0 / 3], [0, 1]])</div>
<div class="line"><span class="lineno">  830</span>    assert_array_almost_equal(nb.predict_proba(X), prob)</div>
<div class="line"><span class="lineno">  831</span> </div>
<div class="line"><span class="lineno">  832</span> </div>
<div class="ttc" id="aclassscipy_1_1sparse_1_1__csr_1_1csr__matrix_html"><div class="ttname"><a href="classscipy_1_1sparse_1_1__csr_1_1csr__matrix.html">scipy.sparse._csr.csr_matrix</a></div><div class="ttdef"><b>Definition</b> _csr.py:17</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a428c394083017207c0a3bfea972e2df6" name="a428c394083017207c0a3bfea972e2df6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a428c394083017207c0a3bfea972e2df6">&#9670;&#160;</a></span>test_alpha_vector()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_alpha_vector </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  833</span><span class="keyword">def </span>test_alpha_vector():</div>
<div class="line"><span class="lineno">  834</span>    X = np.array([[1, 0], [1, 1]])</div>
<div class="line"><span class="lineno">  835</span>    y = np.array([0, 1])</div>
<div class="line"><span class="lineno">  836</span> </div>
<div class="line"><span class="lineno">  837</span>    <span class="comment"># Setting alpha=np.array with same length</span></div>
<div class="line"><span class="lineno">  838</span>    <span class="comment"># as number of features should be fine</span></div>
<div class="line"><span class="lineno">  839</span>    alpha = np.array([1, 2])</div>
<div class="line"><span class="lineno">  840</span>    nb = MultinomialNB(alpha=alpha)</div>
<div class="line"><span class="lineno">  841</span>    nb.partial_fit(X, y, classes=[0, 1])</div>
<div class="line"><span class="lineno">  842</span> </div>
<div class="line"><span class="lineno">  843</span>    <span class="comment"># Test feature probabilities uses pseudo-counts (alpha)</span></div>
<div class="line"><span class="lineno">  844</span>    feature_prob = np.array([[1 / 2, 1 / 2], [2 / 5, 3 / 5]])</div>
<div class="line"><span class="lineno">  845</span>    assert_array_almost_equal(nb.feature_log_prob_, np.log(feature_prob))</div>
<div class="line"><span class="lineno">  846</span> </div>
<div class="line"><span class="lineno">  847</span>    <span class="comment"># Test predictions</span></div>
<div class="line"><span class="lineno">  848</span>    prob = np.array([[5 / 9, 4 / 9], [25 / 49, 24 / 49]])</div>
<div class="line"><span class="lineno">  849</span>    assert_array_almost_equal(nb.predict_proba(X), prob)</div>
<div class="line"><span class="lineno">  850</span> </div>
<div class="line"><span class="lineno">  851</span>    <span class="comment"># Test alpha non-negative</span></div>
<div class="line"><span class="lineno">  852</span>    alpha = np.array([1.0, -0.1])</div>
<div class="line"><span class="lineno">  853</span>    m_nb = MultinomialNB(alpha=alpha)</div>
<div class="line"><span class="lineno">  854</span>    expected_msg = <span class="stringliteral">&quot;All values in alpha must be greater than 0.&quot;</span></div>
<div class="line"><span class="lineno">  855</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=expected_msg):</div>
<div class="line"><span class="lineno">  856</span>        m_nb.fit(X, y)</div>
<div class="line"><span class="lineno">  857</span> </div>
<div class="line"><span class="lineno">  858</span>    <span class="comment"># Test that too small pseudo-counts are replaced</span></div>
<div class="line"><span class="lineno">  859</span>    ALPHA_MIN = 1e-10</div>
<div class="line"><span class="lineno">  860</span>    alpha = np.array([ALPHA_MIN / 2, 0.5])</div>
<div class="line"><span class="lineno">  861</span>    m_nb = MultinomialNB(alpha=alpha)</div>
<div class="line"><span class="lineno">  862</span>    m_nb.partial_fit(X, y, classes=[0, 1])</div>
<div class="line"><span class="lineno">  863</span>    assert_array_almost_equal(m_nb._check_alpha(), [ALPHA_MIN, 0.5], decimal=12)</div>
<div class="line"><span class="lineno">  864</span> </div>
<div class="line"><span class="lineno">  865</span>    <span class="comment"># Test correct dimensions</span></div>
<div class="line"><span class="lineno">  866</span>    alpha = np.array([1.0, 2.0, 3.0])</div>
<div class="line"><span class="lineno">  867</span>    m_nb = MultinomialNB(alpha=alpha)</div>
<div class="line"><span class="lineno">  868</span>    expected_msg = <span class="stringliteral">&quot;When alpha is an array, it should contains `n_features`&quot;</span></div>
<div class="line"><span class="lineno">  869</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=expected_msg):</div>
<div class="line"><span class="lineno">  870</span>        m_nb.fit(X, y)</div>
<div class="line"><span class="lineno">  871</span> </div>
<div class="line"><span class="lineno">  872</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a40369ac0efdffa181e75201e32e86489" name="a40369ac0efdffa181e75201e32e86489"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40369ac0efdffa181e75201e32e86489">&#9670;&#160;</a></span>test_bnb()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_bnb </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  533</span><span class="keyword">def </span>test_bnb():</div>
<div class="line"><span class="lineno">  534</span>    <span class="comment"># Tests that BernoulliNB when alpha=1.0 gives the same values as</span></div>
<div class="line"><span class="lineno">  535</span>    <span class="comment"># those given for the toy example in Manning, Raghavan, and</span></div>
<div class="line"><span class="lineno">  536</span>    <span class="comment"># Schuetze&#39;s &quot;Introduction to Information Retrieval&quot; book:</span></div>
<div class="line"><span class="lineno">  537</span>    <span class="comment"># https://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html</span></div>
<div class="line"><span class="lineno">  538</span> </div>
<div class="line"><span class="lineno">  539</span>    <span class="comment"># Training data points are:</span></div>
<div class="line"><span class="lineno">  540</span>    <span class="comment"># Chinese Beijing Chinese (class: China)</span></div>
<div class="line"><span class="lineno">  541</span>    <span class="comment"># Chinese Chinese Shanghai (class: China)</span></div>
<div class="line"><span class="lineno">  542</span>    <span class="comment"># Chinese Macao (class: China)</span></div>
<div class="line"><span class="lineno">  543</span>    <span class="comment"># Tokyo Japan Chinese (class: Japan)</span></div>
<div class="line"><span class="lineno">  544</span> </div>
<div class="line"><span class="lineno">  545</span>    <span class="comment"># Features are Beijing, Chinese, Japan, Macao, Shanghai, and Tokyo</span></div>
<div class="line"><span class="lineno">  546</span>    X = np.array(</div>
<div class="line"><span class="lineno">  547</span>        [[1, 1, 0, 0, 0, 0], [0, 1, 0, 0, 1, 0], [0, 1, 0, 1, 0, 0], [0, 1, 1, 0, 0, 1]]</div>
<div class="line"><span class="lineno">  548</span>    )</div>
<div class="line"><span class="lineno">  549</span> </div>
<div class="line"><span class="lineno">  550</span>    <span class="comment"># Classes are China (0), Japan (1)</span></div>
<div class="line"><span class="lineno">  551</span>    Y = np.array([0, 0, 0, 1])</div>
<div class="line"><span class="lineno">  552</span> </div>
<div class="line"><span class="lineno">  553</span>    <span class="comment"># Fit BernoulliBN w/ alpha = 1.0</span></div>
<div class="line"><span class="lineno">  554</span>    clf = BernoulliNB(alpha=1.0)</div>
<div class="line"><span class="lineno">  555</span>    clf.fit(X, Y)</div>
<div class="line"><span class="lineno">  556</span> </div>
<div class="line"><span class="lineno">  557</span>    <span class="comment"># Check the class prior is correct</span></div>
<div class="line"><span class="lineno">  558</span>    class_prior = np.array([0.75, 0.25])</div>
<div class="line"><span class="lineno">  559</span>    assert_array_almost_equal(np.exp(clf.class_log_prior_), class_prior)</div>
<div class="line"><span class="lineno">  560</span> </div>
<div class="line"><span class="lineno">  561</span>    <span class="comment"># Check the feature probabilities are correct</span></div>
<div class="line"><span class="lineno">  562</span>    feature_prob = np.array(</div>
<div class="line"><span class="lineno">  563</span>        [</div>
<div class="line"><span class="lineno">  564</span>            [0.4, 0.8, 0.2, 0.4, 0.4, 0.2],</div>
<div class="line"><span class="lineno">  565</span>            [1 / 3.0, 2 / 3.0, 2 / 3.0, 1 / 3.0, 1 / 3.0, 2 / 3.0],</div>
<div class="line"><span class="lineno">  566</span>        ]</div>
<div class="line"><span class="lineno">  567</span>    )</div>
<div class="line"><span class="lineno">  568</span>    assert_array_almost_equal(np.exp(clf.feature_log_prob_), feature_prob)</div>
<div class="line"><span class="lineno">  569</span> </div>
<div class="line"><span class="lineno">  570</span>    <span class="comment"># Testing data point is:</span></div>
<div class="line"><span class="lineno">  571</span>    <span class="comment"># Chinese Chinese Chinese Tokyo Japan</span></div>
<div class="line"><span class="lineno">  572</span>    X_test = np.array([[0, 1, 1, 0, 0, 1]])</div>
<div class="line"><span class="lineno">  573</span> </div>
<div class="line"><span class="lineno">  574</span>    <span class="comment"># Check the predictive probabilities are correct</span></div>
<div class="line"><span class="lineno">  575</span>    unnorm_predict_proba = np.array([[0.005183999999999999, 0.02194787379972565]])</div>
<div class="line"><span class="lineno">  576</span>    predict_proba = unnorm_predict_proba / np.sum(unnorm_predict_proba)</div>
<div class="line"><span class="lineno">  577</span>    assert_array_almost_equal(clf.predict_proba(X_test), predict_proba)</div>
<div class="line"><span class="lineno">  578</span> </div>
<div class="line"><span class="lineno">  579</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afb4183b1daa342598ed7e1531a924a3f" name="afb4183b1daa342598ed7e1531a924a3f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afb4183b1daa342598ed7e1531a924a3f">&#9670;&#160;</a></span>test_bnb_feature_log_prob()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_bnb_feature_log_prob </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  580</span><span class="keyword">def </span>test_bnb_feature_log_prob():</div>
<div class="line"><span class="lineno">  581</span>    <span class="comment"># Test for issue #4268.</span></div>
<div class="line"><span class="lineno">  582</span>    <span class="comment"># Tests that the feature log prob value computed by BernoulliNB when</span></div>
<div class="line"><span class="lineno">  583</span>    <span class="comment"># alpha=1.0 is equal to the expression given in Manning, Raghavan,</span></div>
<div class="line"><span class="lineno">  584</span>    <span class="comment"># and Schuetze&#39;s &quot;Introduction to Information Retrieval&quot; book:</span></div>
<div class="line"><span class="lineno">  585</span>    <span class="comment"># http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html</span></div>
<div class="line"><span class="lineno">  586</span> </div>
<div class="line"><span class="lineno">  587</span>    X = np.array([[0, 0, 0], [1, 1, 0], [0, 1, 0], [1, 0, 1], [0, 1, 0]])</div>
<div class="line"><span class="lineno">  588</span>    Y = np.array([0, 0, 1, 2, 2])</div>
<div class="line"><span class="lineno">  589</span> </div>
<div class="line"><span class="lineno">  590</span>    <span class="comment"># Fit Bernoulli NB w/ alpha = 1.0</span></div>
<div class="line"><span class="lineno">  591</span>    clf = BernoulliNB(alpha=1.0)</div>
<div class="line"><span class="lineno">  592</span>    clf.fit(X, Y)</div>
<div class="line"><span class="lineno">  593</span> </div>
<div class="line"><span class="lineno">  594</span>    <span class="comment"># Manually form the (log) numerator and denominator that</span></div>
<div class="line"><span class="lineno">  595</span>    <span class="comment"># constitute P(feature presence | class)</span></div>
<div class="line"><span class="lineno">  596</span>    num = np.log(clf.feature_count_ + 1.0)</div>
<div class="line"><span class="lineno">  597</span>    denom = np.tile(np.log(clf.class_count_ + 2.0), (X.shape[1], 1)).T</div>
<div class="line"><span class="lineno">  598</span> </div>
<div class="line"><span class="lineno">  599</span>    <span class="comment"># Check manual estimate matches</span></div>
<div class="line"><span class="lineno">  600</span>    assert_array_almost_equal(clf.feature_log_prob_, (num - denom))</div>
<div class="line"><span class="lineno">  601</span> </div>
<div class="line"><span class="lineno">  602</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a778da87caeded9faf3b89580826bd37f" name="a778da87caeded9faf3b89580826bd37f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a778da87caeded9faf3b89580826bd37f">&#9670;&#160;</a></span>test_categoricalnb()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_categoricalnb </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  674</span><span class="keyword">def </span>test_categoricalnb():</div>
<div class="line"><span class="lineno">  675</span>    <span class="comment"># Check the ability to predict the training set.</span></div>
<div class="line"><span class="lineno">  676</span>    clf = CategoricalNB()</div>
<div class="line"><span class="lineno">  677</span>    y_pred = clf.fit(X2, y2).predict(X2)</div>
<div class="line"><span class="lineno">  678</span>    assert_array_equal(y_pred, y2)</div>
<div class="line"><span class="lineno">  679</span> </div>
<div class="line"><span class="lineno">  680</span>    X3 = np.array([[1, 4], [2, 5]])</div>
<div class="line"><span class="lineno">  681</span>    y3 = np.array([1, 2])</div>
<div class="line"><span class="lineno">  682</span>    clf = CategoricalNB(alpha=1, fit_prior=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  683</span> </div>
<div class="line"><span class="lineno">  684</span>    clf.fit(X3, y3)</div>
<div class="line"><span class="lineno">  685</span>    assert_array_equal(clf.n_categories_, np.array([3, 6]))</div>
<div class="line"><span class="lineno">  686</span> </div>
<div class="line"><span class="lineno">  687</span>    <span class="comment"># Check error is raised for X with negative entries</span></div>
<div class="line"><span class="lineno">  688</span>    X = np.array([[0, -1]])</div>
<div class="line"><span class="lineno">  689</span>    y = np.array([1])</div>
<div class="line"><span class="lineno">  690</span>    error_msg = re.escape(<span class="stringliteral">&quot;Negative values in data passed to CategoricalNB (input X)&quot;</span>)</div>
<div class="line"><span class="lineno">  691</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=error_msg):</div>
<div class="line"><span class="lineno">  692</span>        clf.predict(X)</div>
<div class="line"><span class="lineno">  693</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=error_msg):</div>
<div class="line"><span class="lineno">  694</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  695</span> </div>
<div class="line"><span class="lineno">  696</span>    <span class="comment"># Test alpha</span></div>
<div class="line"><span class="lineno">  697</span>    X3_test = np.array([[2, 5]])</div>
<div class="line"><span class="lineno">  698</span>    <span class="comment"># alpha=1 increases the count of all categories by one so the final</span></div>
<div class="line"><span class="lineno">  699</span>    <span class="comment"># probability for each category is not 50/50 but 1/3 to 2/3</span></div>
<div class="line"><span class="lineno">  700</span>    bayes_numerator = np.array([[1 / 3 * 1 / 3, 2 / 3 * 2 / 3]])</div>
<div class="line"><span class="lineno">  701</span>    bayes_denominator = bayes_numerator.sum()</div>
<div class="line"><span class="lineno">  702</span>    assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  703</span>        clf.predict_proba(X3_test), bayes_numerator / bayes_denominator</div>
<div class="line"><span class="lineno">  704</span>    )</div>
<div class="line"><span class="lineno">  705</span> </div>
<div class="line"><span class="lineno">  706</span>    <span class="comment"># Assert category_count has counted all features</span></div>
<div class="line"><span class="lineno">  707</span>    <span class="keyword">assert</span> len(clf.category_count_) == X3.shape[1]</div>
<div class="line"><span class="lineno">  708</span> </div>
<div class="line"><span class="lineno">  709</span>    <span class="comment"># Check sample_weight</span></div>
<div class="line"><span class="lineno">  710</span>    X = np.array([[0, 0], [0, 1], [0, 0], [1, 1]])</div>
<div class="line"><span class="lineno">  711</span>    y = np.array([1, 1, 2, 2])</div>
<div class="line"><span class="lineno">  712</span>    clf = CategoricalNB(alpha=1, fit_prior=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  713</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  714</span>    assert_array_equal(clf.predict(np.array([[0, 0]])), np.array([1]))</div>
<div class="line"><span class="lineno">  715</span>    assert_array_equal(clf.n_categories_, np.array([2, 2]))</div>
<div class="line"><span class="lineno">  716</span> </div>
<div class="line"><span class="lineno">  717</span>    <span class="keywordflow">for</span> factor <span class="keywordflow">in</span> [1.0, 0.3, 5, 0.0001]:</div>
<div class="line"><span class="lineno">  718</span>        X = np.array([[0, 0], [0, 1], [0, 0], [1, 1]])</div>
<div class="line"><span class="lineno">  719</span>        y = np.array([1, 1, 2, 2])</div>
<div class="line"><span class="lineno">  720</span>        sample_weight = np.array([1, 1, 10, 0.1]) * factor</div>
<div class="line"><span class="lineno">  721</span>        clf = CategoricalNB(alpha=1, fit_prior=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  722</span>        clf.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  723</span>        assert_array_equal(clf.predict(np.array([[0, 0]])), np.array([2]))</div>
<div class="line"><span class="lineno">  724</span>        assert_array_equal(clf.n_categories_, np.array([2, 2]))</div>
<div class="line"><span class="lineno">  725</span> </div>
<div class="line"><span class="lineno">  726</span> </div>
<div class="line"><span class="lineno">  727</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  728</span>    <span class="stringliteral">&quot;min_categories, exp_X1_count, exp_X2_count, new_X, exp_n_categories_&quot;</span>,</div>
<div class="line"><span class="lineno">  729</span>    [</div>
<div class="line"><span class="lineno">  730</span>        <span class="comment"># check min_categories with int &gt; observed categories</span></div>
<div class="line"><span class="lineno">  731</span>        (</div>
<div class="line"><span class="lineno">  732</span>            3,</div>
<div class="line"><span class="lineno">  733</span>            np.array([[2, 0, 0], [1, 1, 0]]),</div>
<div class="line"><span class="lineno">  734</span>            np.array([[1, 1, 0], [1, 1, 0]]),</div>
<div class="line"><span class="lineno">  735</span>            np.array([[0, 2]]),</div>
<div class="line"><span class="lineno">  736</span>            np.array([3, 3]),</div>
<div class="line"><span class="lineno">  737</span>        ),</div>
<div class="line"><span class="lineno">  738</span>        <span class="comment"># check with list input</span></div>
<div class="line"><span class="lineno">  739</span>        (</div>
<div class="line"><span class="lineno">  740</span>            [3, 4],</div>
<div class="line"><span class="lineno">  741</span>            np.array([[2, 0, 0], [1, 1, 0]]),</div>
<div class="line"><span class="lineno">  742</span>            np.array([[1, 1, 0, 0], [1, 1, 0, 0]]),</div>
<div class="line"><span class="lineno">  743</span>            np.array([[0, 3]]),</div>
<div class="line"><span class="lineno">  744</span>            np.array([3, 4]),</div>
<div class="line"><span class="lineno">  745</span>        ),</div>
<div class="line"><span class="lineno">  746</span>        <span class="comment"># check min_categories with min less than actual</span></div>
<div class="line"><span class="lineno">  747</span>        (</div>
<div class="line"><span class="lineno">  748</span>            [</div>
<div class="line"><span class="lineno">  749</span>                1,</div>
<div class="line"><span class="lineno">  750</span>                np.array([[2, 0], [1, 1]]),</div>
<div class="line"><span class="lineno">  751</span>                np.array([[1, 1], [1, 1]]),</div>
<div class="line"><span class="lineno">  752</span>                np.array([[0, 1]]),</div>
<div class="line"><span class="lineno">  753</span>                np.array([2, 2]),</div>
<div class="line"><span class="lineno">  754</span>            ]</div>
<div class="line"><span class="lineno">  755</span>        ),</div>
<div class="line"><span class="lineno">  756</span>    ],</div>
<div class="line"><span class="lineno">  757</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ad03ed1e7ba8e0d8bcf5e49f9cfe2e3bd" name="ad03ed1e7ba8e0d8bcf5e49f9cfe2e3bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad03ed1e7ba8e0d8bcf5e49f9cfe2e3bd">&#9670;&#160;</a></span>test_categoricalnb_min_categories_errors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_categoricalnb_min_categories_errors </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_categories</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>error_msg</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  781</span><span class="keyword">def </span>test_categoricalnb_min_categories_errors(min_categories, error_msg):</div>
<div class="line"><span class="lineno">  782</span> </div>
<div class="line"><span class="lineno">  783</span>    X = np.array([[0, 0], [0, 1], [0, 0], [1, 1]])</div>
<div class="line"><span class="lineno">  784</span>    y = np.array([1, 1, 2, 2])</div>
<div class="line"><span class="lineno">  785</span> </div>
<div class="line"><span class="lineno">  786</span>    clf = CategoricalNB(alpha=1, fit_prior=<span class="keyword">False</span>, min_categories=min_categories)</div>
<div class="line"><span class="lineno">  787</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=error_msg):</div>
<div class="line"><span class="lineno">  788</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  789</span> </div>
<div class="line"><span class="lineno">  790</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aaa5dfc60c00fddfb7b30e70e1c696dbb" name="aaa5dfc60c00fddfb7b30e70e1c696dbb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaa5dfc60c00fddfb7b30e70e1c696dbb">&#9670;&#160;</a></span>test_categoricalnb_with_min_categories()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_categoricalnb_with_min_categories </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_categories</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>exp_X1_count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>exp_X2_count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>new_X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>exp_n_categories_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  760</span>):</div>
<div class="line"><span class="lineno">  761</span>    X_n_categories = np.array([[0, 0], [0, 1], [0, 0], [1, 1]])</div>
<div class="line"><span class="lineno">  762</span>    y_n_categories = np.array([1, 1, 2, 2])</div>
<div class="line"><span class="lineno">  763</span>    expected_prediction = np.array([1])</div>
<div class="line"><span class="lineno">  764</span> </div>
<div class="line"><span class="lineno">  765</span>    clf = CategoricalNB(alpha=1, fit_prior=<span class="keyword">False</span>, min_categories=min_categories)</div>
<div class="line"><span class="lineno">  766</span>    clf.fit(X_n_categories, y_n_categories)</div>
<div class="line"><span class="lineno">  767</span>    X1_count, X2_count = clf.category_count_</div>
<div class="line"><span class="lineno">  768</span>    assert_array_equal(X1_count, exp_X1_count)</div>
<div class="line"><span class="lineno">  769</span>    assert_array_equal(X2_count, exp_X2_count)</div>
<div class="line"><span class="lineno">  770</span>    predictions = clf.predict(new_X)</div>
<div class="line"><span class="lineno">  771</span>    assert_array_equal(predictions, expected_prediction)</div>
<div class="line"><span class="lineno">  772</span>    assert_array_equal(clf.n_categories_, exp_n_categories_)</div>
<div class="line"><span class="lineno">  773</span> </div>
<div class="line"><span class="lineno">  774</span> </div>
<div class="line"><span class="lineno">  775</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  776</span>    <span class="stringliteral">&quot;min_categories, error_msg&quot;</span>,</div>
<div class="line"><span class="lineno">  777</span>    [</div>
<div class="line"><span class="lineno">  778</span>        ([[3, 2], [2, 4]], <span class="stringliteral">&quot;&#39;min_categories&#39; should have shape&quot;</span>),</div>
<div class="line"><span class="lineno">  779</span>    ],</div>
<div class="line"><span class="lineno">  780</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a92f1fc88ce81e9764e8bb217d8c218d1" name="a92f1fc88ce81e9764e8bb217d8c218d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a92f1fc88ce81e9764e8bb217d8c218d1">&#9670;&#160;</a></span>test_check_accuracy_on_digits()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_check_accuracy_on_digits </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  873</span><span class="keyword">def </span>test_check_accuracy_on_digits():</div>
<div class="line"><span class="lineno">  874</span>    <span class="comment"># Non regression test to make sure that any further refactoring / optim</span></div>
<div class="line"><span class="lineno">  875</span>    <span class="comment"># of the NB models do not harm the performance on a slightly non-linearly</span></div>
<div class="line"><span class="lineno">  876</span>    <span class="comment"># separable dataset</span></div>
<div class="line"><span class="lineno">  877</span>    X, y = load_digits(return_X_y=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  878</span>    binary_3v8 = np.logical_or(y == 3, y == 8)</div>
<div class="line"><span class="lineno">  879</span>    X_3v8, y_3v8 = X[binary_3v8], y[binary_3v8]</div>
<div class="line"><span class="lineno">  880</span> </div>
<div class="line"><span class="lineno">  881</span>    <span class="comment"># Multinomial NB</span></div>
<div class="line"><span class="lineno">  882</span>    scores = cross_val_score(MultinomialNB(alpha=10), X, y, cv=10)</div>
<div class="line"><span class="lineno">  883</span>    <span class="keyword">assert</span> scores.mean() &gt; 0.86</div>
<div class="line"><span class="lineno">  884</span> </div>
<div class="line"><span class="lineno">  885</span>    scores = cross_val_score(MultinomialNB(alpha=10), X_3v8, y_3v8, cv=10)</div>
<div class="line"><span class="lineno">  886</span>    <span class="keyword">assert</span> scores.mean() &gt; 0.94</div>
<div class="line"><span class="lineno">  887</span> </div>
<div class="line"><span class="lineno">  888</span>    <span class="comment"># Bernoulli NB</span></div>
<div class="line"><span class="lineno">  889</span>    scores = cross_val_score(BernoulliNB(alpha=10), X &gt; 4, y, cv=10)</div>
<div class="line"><span class="lineno">  890</span>    <span class="keyword">assert</span> scores.mean() &gt; 0.83</div>
<div class="line"><span class="lineno">  891</span> </div>
<div class="line"><span class="lineno">  892</span>    scores = cross_val_score(BernoulliNB(alpha=10), X_3v8 &gt; 4, y_3v8, cv=10)</div>
<div class="line"><span class="lineno">  893</span>    <span class="keyword">assert</span> scores.mean() &gt; 0.92</div>
<div class="line"><span class="lineno">  894</span> </div>
<div class="line"><span class="lineno">  895</span>    <span class="comment"># Gaussian NB</span></div>
<div class="line"><span class="lineno">  896</span>    scores = cross_val_score(GaussianNB(), X, y, cv=10)</div>
<div class="line"><span class="lineno">  897</span>    <span class="keyword">assert</span> scores.mean() &gt; 0.77</div>
<div class="line"><span class="lineno">  898</span> </div>
<div class="line"><span class="lineno">  899</span>    scores = cross_val_score(GaussianNB(var_smoothing=0.1), X, y, cv=10)</div>
<div class="line"><span class="lineno">  900</span>    <span class="keyword">assert</span> scores.mean() &gt; 0.89</div>
<div class="line"><span class="lineno">  901</span> </div>
<div class="line"><span class="lineno">  902</span>    scores = cross_val_score(GaussianNB(), X_3v8, y_3v8, cv=10)</div>
<div class="line"><span class="lineno">  903</span>    <span class="keyword">assert</span> scores.mean() &gt; 0.86</div>
<div class="line"><span class="lineno">  904</span> </div>
<div class="line"><span class="lineno">  905</span> </div>
<div class="line"><span class="lineno">  906</span><span class="comment"># TODO(1.4): Remove</span></div>
<div class="line"><span class="lineno">  907</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Estimator&quot;, DISCRETE_NAIVE_BAYES_CLASSES)</span></div>
<div class="line"><span class="lineno">  908</span><span class="preprocessor">@pytest.mark.parametrize(&quot;alpha&quot;, [1, [0.1, 1e-11], 1e-12])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="adfec673f12b3d0ed01519e4b527ee684" name="adfec673f12b3d0ed01519e4b527ee684"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adfec673f12b3d0ed01519e4b527ee684">&#9670;&#160;</a></span>test_check_alpha()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_check_alpha </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">The provided value for alpha must only be
used if alpha &lt; _ALPHA_MIN and force_alpha is True.

Non-regression test for:
https://github.com/scikit-learn/scikit-learn/issues/10772
</pre> <div class="fragment"><div class="line"><span class="lineno">  926</span><span class="keyword">def </span>test_check_alpha():</div>
<div class="line"><span class="lineno">  927</span>    <span class="stringliteral">&quot;&quot;&quot;The provided value for alpha must only be</span></div>
<div class="line"><span class="lineno">  928</span><span class="stringliteral">    used if alpha &lt; _ALPHA_MIN and force_alpha is True.</span></div>
<div class="line"><span class="lineno">  929</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  930</span><span class="stringliteral">    Non-regression test for:</span></div>
<div class="line"><span class="lineno">  931</span><span class="stringliteral">    https://github.com/scikit-learn/scikit-learn/issues/10772</span></div>
<div class="line"><span class="lineno">  932</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  933</span>    _ALPHA_MIN = 1e-10</div>
<div class="line"><span class="lineno">  934</span>    b = BernoulliNB(alpha=0, force_alpha=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  935</span>    <span class="keyword">assert</span> b._check_alpha() == 0</div>
<div class="line"><span class="lineno">  936</span> </div>
<div class="line"><span class="lineno">  937</span>    alphas = np.array([0.0, 1.0])</div>
<div class="line"><span class="lineno">  938</span> </div>
<div class="line"><span class="lineno">  939</span>    b = BernoulliNB(alpha=alphas, force_alpha=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  940</span>    <span class="comment"># We manually set `n_features_in_` not to have `_check_alpha` err</span></div>
<div class="line"><span class="lineno">  941</span>    b.n_features_in_ = alphas.shape[0]</div>
<div class="line"><span class="lineno">  942</span>    assert_array_equal(b._check_alpha(), alphas)</div>
<div class="line"><span class="lineno">  943</span> </div>
<div class="line"><span class="lineno">  944</span>    msg = (</div>
<div class="line"><span class="lineno">  945</span>        <span class="stringliteral">&quot;alpha too small will result in numeric errors, setting alpha = %.1e&quot;</span></div>
<div class="line"><span class="lineno">  946</span>        % _ALPHA_MIN</div>
<div class="line"><span class="lineno">  947</span>    )</div>
<div class="line"><span class="lineno">  948</span>    b = BernoulliNB(alpha=0, force_alpha=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  949</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno">  950</span>        <span class="keyword">assert</span> b._check_alpha() == _ALPHA_MIN</div>
<div class="line"><span class="lineno">  951</span> </div>
<div class="line"><span class="lineno">  952</span>    b = BernoulliNB(alpha=0)</div>
<div class="line"><span class="lineno">  953</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno">  954</span>        <span class="keyword">assert</span> b._check_alpha() == _ALPHA_MIN</div>
<div class="line"><span class="lineno">  955</span> </div>
<div class="line"><span class="lineno">  956</span>    b = BernoulliNB(alpha=alphas, force_alpha=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  957</span>    <span class="comment"># We manually set `n_features_in_` not to have `_check_alpha` err</span></div>
<div class="line"><span class="lineno">  958</span>    b.n_features_in_ = alphas.shape[0]</div>
<div class="line"><span class="lineno">  959</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=msg):</div>
<div class="line"><span class="lineno">  960</span>        assert_array_equal(b._check_alpha(), np.array([_ALPHA_MIN, 1.0]))</div>
<div class="line"><span class="lineno">  961</span> </div>
<div class="line"><span class="lineno">  962</span> </div>
<div class="line"><span class="lineno">  963</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Estimator&quot;, ALL_NAIVE_BAYES_CLASSES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a08a5a9cc8086b1fab516de6b832281be" name="a08a5a9cc8086b1fab516de6b832281be"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a08a5a9cc8086b1fab516de6b832281be">&#9670;&#160;</a></span>test_cnb()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_cnb </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  603</span><span class="keyword">def </span>test_cnb():</div>
<div class="line"><span class="lineno">  604</span>    <span class="comment"># Tests ComplementNB when alpha=1.0 for the toy example in Manning,</span></div>
<div class="line"><span class="lineno">  605</span>    <span class="comment"># Raghavan, and Schuetze&#39;s &quot;Introduction to Information Retrieval&quot; book:</span></div>
<div class="line"><span class="lineno">  606</span>    <span class="comment"># https://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html</span></div>
<div class="line"><span class="lineno">  607</span> </div>
<div class="line"><span class="lineno">  608</span>    <span class="comment"># Training data points are:</span></div>
<div class="line"><span class="lineno">  609</span>    <span class="comment"># Chinese Beijing Chinese (class: China)</span></div>
<div class="line"><span class="lineno">  610</span>    <span class="comment"># Chinese Chinese Shanghai (class: China)</span></div>
<div class="line"><span class="lineno">  611</span>    <span class="comment"># Chinese Macao (class: China)</span></div>
<div class="line"><span class="lineno">  612</span>    <span class="comment"># Tokyo Japan Chinese (class: Japan)</span></div>
<div class="line"><span class="lineno">  613</span> </div>
<div class="line"><span class="lineno">  614</span>    <span class="comment"># Features are Beijing, Chinese, Japan, Macao, Shanghai, and Tokyo.</span></div>
<div class="line"><span class="lineno">  615</span>    X = np.array(</div>
<div class="line"><span class="lineno">  616</span>        [[1, 1, 0, 0, 0, 0], [0, 1, 0, 0, 1, 0], [0, 1, 0, 1, 0, 0], [0, 1, 1, 0, 0, 1]]</div>
<div class="line"><span class="lineno">  617</span>    )</div>
<div class="line"><span class="lineno">  618</span> </div>
<div class="line"><span class="lineno">  619</span>    <span class="comment"># Classes are China (0), Japan (1).</span></div>
<div class="line"><span class="lineno">  620</span>    Y = np.array([0, 0, 0, 1])</div>
<div class="line"><span class="lineno">  621</span> </div>
<div class="line"><span class="lineno">  622</span>    <span class="comment"># Check that weights are correct. See steps 4-6 in Table 4 of</span></div>
<div class="line"><span class="lineno">  623</span>    <span class="comment"># Rennie et al. (2003).</span></div>
<div class="line"><span class="lineno">  624</span>    theta = np.array(</div>
<div class="line"><span class="lineno">  625</span>        [</div>
<div class="line"><span class="lineno">  626</span>            [</div>
<div class="line"><span class="lineno">  627</span>                (0 + 1) / (3 + 6),</div>
<div class="line"><span class="lineno">  628</span>                (1 + 1) / (3 + 6),</div>
<div class="line"><span class="lineno">  629</span>                (1 + 1) / (3 + 6),</div>
<div class="line"><span class="lineno">  630</span>                (0 + 1) / (3 + 6),</div>
<div class="line"><span class="lineno">  631</span>                (0 + 1) / (3 + 6),</div>
<div class="line"><span class="lineno">  632</span>                (1 + 1) / (3 + 6),</div>
<div class="line"><span class="lineno">  633</span>            ],</div>
<div class="line"><span class="lineno">  634</span>            [</div>
<div class="line"><span class="lineno">  635</span>                (1 + 1) / (6 + 6),</div>
<div class="line"><span class="lineno">  636</span>                (3 + 1) / (6 + 6),</div>
<div class="line"><span class="lineno">  637</span>                (0 + 1) / (6 + 6),</div>
<div class="line"><span class="lineno">  638</span>                (1 + 1) / (6 + 6),</div>
<div class="line"><span class="lineno">  639</span>                (1 + 1) / (6 + 6),</div>
<div class="line"><span class="lineno">  640</span>                (0 + 1) / (6 + 6),</div>
<div class="line"><span class="lineno">  641</span>            ],</div>
<div class="line"><span class="lineno">  642</span>        ]</div>
<div class="line"><span class="lineno">  643</span>    )</div>
<div class="line"><span class="lineno">  644</span> </div>
<div class="line"><span class="lineno">  645</span>    weights = np.zeros(theta.shape)</div>
<div class="line"><span class="lineno">  646</span>    normed_weights = np.zeros(theta.shape)</div>
<div class="line"><span class="lineno">  647</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(2):</div>
<div class="line"><span class="lineno">  648</span>        weights[i] = -np.log(theta[i])</div>
<div class="line"><span class="lineno">  649</span>        normed_weights[i] = weights[i] / weights[i].sum()</div>
<div class="line"><span class="lineno">  650</span> </div>
<div class="line"><span class="lineno">  651</span>    <span class="comment"># Verify inputs are nonnegative.</span></div>
<div class="line"><span class="lineno">  652</span>    clf = ComplementNB(alpha=1.0)</div>
<div class="line"><span class="lineno">  653</span> </div>
<div class="line"><span class="lineno">  654</span>    msg = re.escape(<span class="stringliteral">&quot;Negative values in data passed to ComplementNB (input X)&quot;</span>)</div>
<div class="line"><span class="lineno">  655</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  656</span>        clf.fit(-X, Y)</div>
<div class="line"><span class="lineno">  657</span> </div>
<div class="line"><span class="lineno">  658</span>    clf.fit(X, Y)</div>
<div class="line"><span class="lineno">  659</span> </div>
<div class="line"><span class="lineno">  660</span>    <span class="comment"># Check that counts/weights are correct.</span></div>
<div class="line"><span class="lineno">  661</span>    feature_count = np.array([[1, 3, 0, 1, 1, 0], [0, 1, 1, 0, 0, 1]])</div>
<div class="line"><span class="lineno">  662</span>    assert_array_equal(clf.feature_count_, feature_count)</div>
<div class="line"><span class="lineno">  663</span>    class_count = np.array([3, 1])</div>
<div class="line"><span class="lineno">  664</span>    assert_array_equal(clf.class_count_, class_count)</div>
<div class="line"><span class="lineno">  665</span>    feature_all = np.array([1, 4, 1, 1, 1, 1])</div>
<div class="line"><span class="lineno">  666</span>    assert_array_equal(clf.feature_all_, feature_all)</div>
<div class="line"><span class="lineno">  667</span>    assert_array_almost_equal(clf.feature_log_prob_, weights)</div>
<div class="line"><span class="lineno">  668</span> </div>
<div class="line"><span class="lineno">  669</span>    clf = ComplementNB(alpha=1.0, norm=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  670</span>    clf.fit(X, Y)</div>
<div class="line"><span class="lineno">  671</span>    assert_array_almost_equal(clf.feature_log_prob_, normed_weights)</div>
<div class="line"><span class="lineno">  672</span> </div>
<div class="line"><span class="lineno">  673</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ade8900eb812925718c0ca8a6baffa293" name="ade8900eb812925718c0ca8a6baffa293"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade8900eb812925718c0ca8a6baffa293">&#9670;&#160;</a></span>test_discretenb_degenerate_one_class_case()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_discretenb_degenerate_one_class_case </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>DiscreteNaiveBayes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>use_partial_fit</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>train_on_single_class_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  403</span>):</div>
<div class="line"><span class="lineno">  404</span>    <span class="comment"># Most array attributes of a discrete naive Bayes classifier should have a</span></div>
<div class="line"><span class="lineno">  405</span>    <span class="comment"># first-axis length equal to the number of classes. Exceptions include:</span></div>
<div class="line"><span class="lineno">  406</span>    <span class="comment"># ComplementNB.feature_all_, CategoricalNB.n_categories_.</span></div>
<div class="line"><span class="lineno">  407</span>    <span class="comment"># Confirm that this is the case for binary problems and the degenerate</span></div>
<div class="line"><span class="lineno">  408</span>    <span class="comment"># case of a single class in the training set, when fitting with `fit` or</span></div>
<div class="line"><span class="lineno">  409</span>    <span class="comment"># `partial_fit`.</span></div>
<div class="line"><span class="lineno">  410</span>    <span class="comment"># Non-regression test for handling degenerate one-class case:</span></div>
<div class="line"><span class="lineno">  411</span>    <span class="comment"># https://github.com/scikit-learn/scikit-learn/issues/18974</span></div>
<div class="line"><span class="lineno">  412</span> </div>
<div class="line"><span class="lineno">  413</span>    X = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]</div>
<div class="line"><span class="lineno">  414</span>    y = [1, 1, 2]</div>
<div class="line"><span class="lineno">  415</span>    <span class="keywordflow">if</span> train_on_single_class_y:</div>
<div class="line"><span class="lineno">  416</span>        X = X[:-1]</div>
<div class="line"><span class="lineno">  417</span>        y = y[:-1]</div>
<div class="line"><span class="lineno">  418</span>    classes = sorted(list(set(y)))</div>
<div class="line"><span class="lineno">  419</span>    num_classes = len(classes)</div>
<div class="line"><span class="lineno">  420</span> </div>
<div class="line"><span class="lineno">  421</span>    clf = DiscreteNaiveBayes()</div>
<div class="line"><span class="lineno">  422</span>    <span class="keywordflow">if</span> use_partial_fit:</div>
<div class="line"><span class="lineno">  423</span>        clf.partial_fit(X, y, classes=classes)</div>
<div class="line"><span class="lineno">  424</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  425</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  426</span>    <span class="keyword">assert</span> clf.predict(X[:1]) == y[0]</div>
<div class="line"><span class="lineno">  427</span> </div>
<div class="line"><span class="lineno">  428</span>    <span class="comment"># Check that attributes have expected first-axis lengths</span></div>
<div class="line"><span class="lineno">  429</span>    attribute_names = [</div>
<div class="line"><span class="lineno">  430</span>        <span class="stringliteral">&quot;classes_&quot;</span>,</div>
<div class="line"><span class="lineno">  431</span>        <span class="stringliteral">&quot;class_count_&quot;</span>,</div>
<div class="line"><span class="lineno">  432</span>        <span class="stringliteral">&quot;class_log_prior_&quot;</span>,</div>
<div class="line"><span class="lineno">  433</span>        <span class="stringliteral">&quot;feature_count_&quot;</span>,</div>
<div class="line"><span class="lineno">  434</span>        <span class="stringliteral">&quot;feature_log_prob_&quot;</span>,</div>
<div class="line"><span class="lineno">  435</span>    ]</div>
<div class="line"><span class="lineno">  436</span>    <span class="keywordflow">for</span> attribute_name <span class="keywordflow">in</span> attribute_names:</div>
<div class="line"><span class="lineno">  437</span>        attribute = getattr(clf, attribute_name, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  438</span>        <span class="keywordflow">if</span> attribute <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  439</span>            <span class="comment"># CategoricalNB has no feature_count_ attribute</span></div>
<div class="line"><span class="lineno">  440</span>            <span class="keywordflow">continue</span></div>
<div class="line"><span class="lineno">  441</span>        <span class="keywordflow">if</span> isinstance(attribute, np.ndarray):</div>
<div class="line"><span class="lineno">  442</span>            <span class="keyword">assert</span> attribute.shape[0] == num_classes</div>
<div class="line"><span class="lineno">  443</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  444</span>            <span class="comment"># CategoricalNB.feature_log_prob_ is a list of arrays</span></div>
<div class="line"><span class="lineno">  445</span>            <span class="keywordflow">for</span> element <span class="keywordflow">in</span> attribute:</div>
<div class="line"><span class="lineno">  446</span>                <span class="keyword">assert</span> element.shape[0] == num_classes</div>
<div class="line"><span class="lineno">  447</span> </div>
<div class="line"><span class="lineno">  448</span> </div>
<div class="line"><span class="lineno">  449</span><span class="preprocessor">@pytest.mark.parametrize(&quot;kind&quot;, (&quot;dense&quot;, &quot;sparse&quot;)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ad24e2e895150360b59135d15a07bbe34" name="ad24e2e895150360b59135d15a07bbe34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad24e2e895150360b59135d15a07bbe34">&#9670;&#160;</a></span>test_discretenb_partial_fit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_discretenb_partial_fit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>DiscreteNaiveBayes</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  222</span><span class="keyword">def </span>test_discretenb_partial_fit(DiscreteNaiveBayes):</div>
<div class="line"><span class="lineno">  223</span>    clf1 = DiscreteNaiveBayes()</div>
<div class="line"><span class="lineno">  224</span>    clf1.fit([[0, 1], [1, 0], [1, 1]], [0, 1, 1])</div>
<div class="line"><span class="lineno">  225</span> </div>
<div class="line"><span class="lineno">  226</span>    clf2 = DiscreteNaiveBayes()</div>
<div class="line"><span class="lineno">  227</span>    clf2.partial_fit([[0, 1], [1, 0], [1, 1]], [0, 1, 1], classes=[0, 1])</div>
<div class="line"><span class="lineno">  228</span>    assert_array_equal(clf1.class_count_, clf2.class_count_)</div>
<div class="line"><span class="lineno">  229</span>    <span class="keywordflow">if</span> DiscreteNaiveBayes <span class="keywordflow">is</span> CategoricalNB:</div>
<div class="line"><span class="lineno">  230</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(clf1.category_count_)):</div>
<div class="line"><span class="lineno">  231</span>            assert_array_equal(clf1.category_count_[i], clf2.category_count_[i])</div>
<div class="line"><span class="lineno">  232</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  233</span>        assert_array_equal(clf1.feature_count_, clf2.feature_count_)</div>
<div class="line"><span class="lineno">  234</span> </div>
<div class="line"><span class="lineno">  235</span>    clf3 = DiscreteNaiveBayes()</div>
<div class="line"><span class="lineno">  236</span>    <span class="comment"># all categories have to appear in the first partial fit</span></div>
<div class="line"><span class="lineno">  237</span>    clf3.partial_fit([[0, 1]], [0], classes=[0, 1])</div>
<div class="line"><span class="lineno">  238</span>    clf3.partial_fit([[1, 0]], [1])</div>
<div class="line"><span class="lineno">  239</span>    clf3.partial_fit([[1, 1]], [1])</div>
<div class="line"><span class="lineno">  240</span>    assert_array_equal(clf1.class_count_, clf3.class_count_)</div>
<div class="line"><span class="lineno">  241</span>    <span class="keywordflow">if</span> DiscreteNaiveBayes <span class="keywordflow">is</span> CategoricalNB:</div>
<div class="line"><span class="lineno">  242</span>        <span class="comment"># the categories for each feature of CategoricalNB are mapped to an</span></div>
<div class="line"><span class="lineno">  243</span>        <span class="comment"># index chronologically with each call of partial fit and therefore</span></div>
<div class="line"><span class="lineno">  244</span>        <span class="comment"># the category_count matrices cannot be compared for equality</span></div>
<div class="line"><span class="lineno">  245</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(clf1.category_count_)):</div>
<div class="line"><span class="lineno">  246</span>            assert_array_equal(</div>
<div class="line"><span class="lineno">  247</span>                clf1.category_count_[i].shape, clf3.category_count_[i].shape</div>
<div class="line"><span class="lineno">  248</span>            )</div>
<div class="line"><span class="lineno">  249</span>            assert_array_equal(</div>
<div class="line"><span class="lineno">  250</span>                np.sum(clf1.category_count_[i], axis=1),</div>
<div class="line"><span class="lineno">  251</span>                np.sum(clf3.category_count_[i], axis=1),</div>
<div class="line"><span class="lineno">  252</span>            )</div>
<div class="line"><span class="lineno">  253</span> </div>
<div class="line"><span class="lineno">  254</span>        <span class="comment"># assert category 0 occurs 1x in the first class and 0x in the 2nd</span></div>
<div class="line"><span class="lineno">  255</span>        <span class="comment"># class</span></div>
<div class="line"><span class="lineno">  256</span>        assert_array_equal(clf1.category_count_[0][0], np.array([1, 0]))</div>
<div class="line"><span class="lineno">  257</span>        <span class="comment"># assert category 1 occurs 0x in the first class and 2x in the 2nd</span></div>
<div class="line"><span class="lineno">  258</span>        <span class="comment"># class</span></div>
<div class="line"><span class="lineno">  259</span>        assert_array_equal(clf1.category_count_[0][1], np.array([0, 2]))</div>
<div class="line"><span class="lineno">  260</span> </div>
<div class="line"><span class="lineno">  261</span>        <span class="comment"># assert category 0 occurs 0x in the first class and 1x in the 2nd</span></div>
<div class="line"><span class="lineno">  262</span>        <span class="comment"># class</span></div>
<div class="line"><span class="lineno">  263</span>        assert_array_equal(clf1.category_count_[1][0], np.array([0, 1]))</div>
<div class="line"><span class="lineno">  264</span>        <span class="comment"># assert category 1 occurs 1x in the first class and 1x in the 2nd</span></div>
<div class="line"><span class="lineno">  265</span>        <span class="comment"># class</span></div>
<div class="line"><span class="lineno">  266</span>        assert_array_equal(clf1.category_count_[1][1], np.array([1, 1]))</div>
<div class="line"><span class="lineno">  267</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  268</span>        assert_array_equal(clf1.feature_count_, clf3.feature_count_)</div>
<div class="line"><span class="lineno">  269</span> </div>
<div class="line"><span class="lineno">  270</span> </div>
<div class="line"><span class="lineno">  271</span><span class="preprocessor">@pytest.mark.parametrize(&quot;NaiveBayes&quot;, ALL_NAIVE_BAYES_CLASSES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a450bed24d9a2fb5f35261c4dbdc611a7" name="a450bed24d9a2fb5f35261c4dbdc611a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a450bed24d9a2fb5f35261c4dbdc611a7">&#9670;&#160;</a></span>test_discretenb_predict_proba()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_discretenb_predict_proba </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  288</span><span class="keyword">def </span>test_discretenb_predict_proba():</div>
<div class="line"><span class="lineno">  289</span>    <span class="comment"># Test discrete NB classes&#39; probability scores</span></div>
<div class="line"><span class="lineno">  290</span> </div>
<div class="line"><span class="lineno">  291</span>    <span class="comment"># The 100s below distinguish Bernoulli from multinomial.</span></div>
<div class="line"><span class="lineno">  292</span>    <span class="comment"># FIXME: write a test to show this.</span></div>
<div class="line"><span class="lineno">  293</span>    X_bernoulli = [[1, 100, 0], [0, 1, 0], [0, 100, 1]]</div>
<div class="line"><span class="lineno">  294</span>    X_multinomial = [[0, 1], [1, 3], [4, 0]]</div>
<div class="line"><span class="lineno">  295</span> </div>
<div class="line"><span class="lineno">  296</span>    <span class="comment"># test binary case (1-d output)</span></div>
<div class="line"><span class="lineno">  297</span>    y = [0, 0, 2]  <span class="comment"># 2 is regression test for binary case, 02e673</span></div>
<div class="line"><span class="lineno">  298</span>    <span class="keywordflow">for</span> DiscreteNaiveBayes, X <span class="keywordflow">in</span> zip(</div>
<div class="line"><span class="lineno">  299</span>        [BernoulliNB, MultinomialNB], [X_bernoulli, X_multinomial]</div>
<div class="line"><span class="lineno">  300</span>    ):</div>
<div class="line"><span class="lineno">  301</span>        clf = DiscreteNaiveBayes().fit(X, y)</div>
<div class="line"><span class="lineno">  302</span>        <span class="keyword">assert</span> clf.predict(X[-1:]) == 2</div>
<div class="line"><span class="lineno">  303</span>        <span class="keyword">assert</span> clf.predict_proba([X[0]]).shape == (1, 2)</div>
<div class="line"><span class="lineno">  304</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  305</span>            clf.predict_proba(X[:2]).sum(axis=1), np.array([1.0, 1.0]), 6</div>
<div class="line"><span class="lineno">  306</span>        )</div>
<div class="line"><span class="lineno">  307</span> </div>
<div class="line"><span class="lineno">  308</span>    <span class="comment"># test multiclass case (2-d output, must sum to one)</span></div>
<div class="line"><span class="lineno">  309</span>    y = [0, 1, 2]</div>
<div class="line"><span class="lineno">  310</span>    <span class="keywordflow">for</span> DiscreteNaiveBayes, X <span class="keywordflow">in</span> zip(</div>
<div class="line"><span class="lineno">  311</span>        [BernoulliNB, MultinomialNB], [X_bernoulli, X_multinomial]</div>
<div class="line"><span class="lineno">  312</span>    ):</div>
<div class="line"><span class="lineno">  313</span>        clf = DiscreteNaiveBayes().fit(X, y)</div>
<div class="line"><span class="lineno">  314</span>        <span class="keyword">assert</span> clf.predict_proba(X[0:1]).shape == (1, 3)</div>
<div class="line"><span class="lineno">  315</span>        <span class="keyword">assert</span> clf.predict_proba(X[:2]).shape == (2, 3)</div>
<div class="line"><span class="lineno">  316</span>        assert_almost_equal(np.sum(clf.predict_proba([X[1]])), 1)</div>
<div class="line"><span class="lineno">  317</span>        assert_almost_equal(np.sum(clf.predict_proba([X[-1]])), 1)</div>
<div class="line"><span class="lineno">  318</span>        assert_almost_equal(np.sum(np.exp(clf.class_log_prior_)), 1)</div>
<div class="line"><span class="lineno">  319</span> </div>
<div class="line"><span class="lineno">  320</span> </div>
<div class="line"><span class="lineno">  321</span><span class="preprocessor">@pytest.mark.parametrize(&quot;DiscreteNaiveBayes&quot;, DISCRETE_NAIVE_BAYES_CLASSES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a06cc638a18fa4ea249ea52023ee41069" name="a06cc638a18fa4ea249ea52023ee41069"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06cc638a18fa4ea249ea52023ee41069">&#9670;&#160;</a></span>test_discretenb_prior()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_discretenb_prior </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>DiscreteNaiveBayes</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  213</span><span class="keyword">def </span>test_discretenb_prior(DiscreteNaiveBayes):</div>
<div class="line"><span class="lineno">  214</span>    <span class="comment"># Test whether class priors are properly set.</span></div>
<div class="line"><span class="lineno">  215</span>    clf = DiscreteNaiveBayes().fit(X2, y2)</div>
<div class="line"><span class="lineno">  216</span>    assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  217</span>        np.log(np.array([2, 2, 2]) / 6.0), clf.class_log_prior_, 8</div>
<div class="line"><span class="lineno">  218</span>    )</div>
<div class="line"><span class="lineno">  219</span> </div>
<div class="line"><span class="lineno">  220</span> </div>
<div class="line"><span class="lineno">  221</span><span class="preprocessor">@pytest.mark.parametrize(&quot;DiscreteNaiveBayes&quot;, DISCRETE_NAIVE_BAYES_CLASSES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a469620e3cf5c36240d804f3eb48eb697" name="a469620e3cf5c36240d804f3eb48eb697"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a469620e3cf5c36240d804f3eb48eb697">&#9670;&#160;</a></span>test_discretenb_provide_prior()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_discretenb_provide_prior </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>DiscreteNaiveBayes</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  334</span><span class="keyword">def </span>test_discretenb_provide_prior(DiscreteNaiveBayes):</div>
<div class="line"><span class="lineno">  335</span>    <span class="comment"># Test whether discrete NB classes use provided prior</span></div>
<div class="line"><span class="lineno">  336</span> </div>
<div class="line"><span class="lineno">  337</span>    clf = DiscreteNaiveBayes(class_prior=[0.5, 0.5])</div>
<div class="line"><span class="lineno">  338</span>    clf.fit([[0], [0], [1]], [0, 0, 1])</div>
<div class="line"><span class="lineno">  339</span>    prior = np.exp(clf.class_log_prior_)</div>
<div class="line"><span class="lineno">  340</span>    assert_array_almost_equal(prior, np.array([0.5, 0.5]))</div>
<div class="line"><span class="lineno">  341</span> </div>
<div class="line"><span class="lineno">  342</span>    <span class="comment"># Inconsistent number of classes with prior</span></div>
<div class="line"><span class="lineno">  343</span>    msg = <span class="stringliteral">&quot;Number of priors must match number of classes&quot;</span></div>
<div class="line"><span class="lineno">  344</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  345</span>        clf.fit([[0], [1], [2]], [0, 1, 2])</div>
<div class="line"><span class="lineno">  346</span> </div>
<div class="line"><span class="lineno">  347</span>    msg = <span class="stringliteral">&quot;is not the same as on last call to partial_fit&quot;</span></div>
<div class="line"><span class="lineno">  348</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  349</span>        clf.partial_fit([[0], [1]], [0, 1], classes=[0, 1, 1])</div>
<div class="line"><span class="lineno">  350</span> </div>
<div class="line"><span class="lineno">  351</span> </div>
<div class="line"><span class="lineno">  352</span><span class="preprocessor">@pytest.mark.parametrize(&quot;DiscreteNaiveBayes&quot;, DISCRETE_NAIVE_BAYES_CLASSES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a0059bf50c507f6852fa5ff7bfc694afc" name="a0059bf50c507f6852fa5ff7bfc694afc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0059bf50c507f6852fa5ff7bfc694afc">&#9670;&#160;</a></span>test_discretenb_provide_prior_with_partial_fit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_discretenb_provide_prior_with_partial_fit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>DiscreteNaiveBayes</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  353</span><span class="keyword">def </span>test_discretenb_provide_prior_with_partial_fit(DiscreteNaiveBayes):</div>
<div class="line"><span class="lineno">  354</span>    <span class="comment"># Test whether discrete NB classes use provided prior</span></div>
<div class="line"><span class="lineno">  355</span>    <span class="comment"># when using partial_fit</span></div>
<div class="line"><span class="lineno">  356</span> </div>
<div class="line"><span class="lineno">  357</span>    iris = load_iris()</div>
<div class="line"><span class="lineno">  358</span>    iris_data1, iris_data2, iris_target1, iris_target2 = train_test_split(</div>
<div class="line"><span class="lineno">  359</span>        iris.data, iris.target, test_size=0.4, random_state=415</div>
<div class="line"><span class="lineno">  360</span>    )</div>
<div class="line"><span class="lineno">  361</span> </div>
<div class="line"><span class="lineno">  362</span>    <span class="keywordflow">for</span> prior <span class="keywordflow">in</span> [<span class="keywordtype">None</span>, [0.3, 0.3, 0.4]]:</div>
<div class="line"><span class="lineno">  363</span>        clf_full = DiscreteNaiveBayes(class_prior=prior)</div>
<div class="line"><span class="lineno">  364</span>        clf_full.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  365</span>        clf_partial = DiscreteNaiveBayes(class_prior=prior)</div>
<div class="line"><span class="lineno">  366</span>        clf_partial.partial_fit(iris_data1, iris_target1, classes=[0, 1, 2])</div>
<div class="line"><span class="lineno">  367</span>        clf_partial.partial_fit(iris_data2, iris_target2)</div>
<div class="line"><span class="lineno">  368</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  369</span>            clf_full.class_log_prior_, clf_partial.class_log_prior_</div>
<div class="line"><span class="lineno">  370</span>        )</div>
<div class="line"><span class="lineno">  371</span> </div>
<div class="line"><span class="lineno">  372</span> </div>
<div class="line"><span class="lineno">  373</span><span class="preprocessor">@pytest.mark.parametrize(&quot;DiscreteNaiveBayes&quot;, DISCRETE_NAIVE_BAYES_CLASSES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aceda898446067ce780ce330eb65a4926" name="aceda898446067ce780ce330eb65a4926"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aceda898446067ce780ce330eb65a4926">&#9670;&#160;</a></span>test_discretenb_sample_weight_multiclass()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_discretenb_sample_weight_multiclass </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>DiscreteNaiveBayes</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  374</span><span class="keyword">def </span>test_discretenb_sample_weight_multiclass(DiscreteNaiveBayes):</div>
<div class="line"><span class="lineno">  375</span>    <span class="comment"># check shape consistency for number of samples at fit time</span></div>
<div class="line"><span class="lineno">  376</span>    X = [</div>
<div class="line"><span class="lineno">  377</span>        [0, 0, 1],</div>
<div class="line"><span class="lineno">  378</span>        [0, 1, 1],</div>
<div class="line"><span class="lineno">  379</span>        [0, 1, 1],</div>
<div class="line"><span class="lineno">  380</span>        [1, 0, 0],</div>
<div class="line"><span class="lineno">  381</span>    ]</div>
<div class="line"><span class="lineno">  382</span>    y = [0, 0, 1, 2]</div>
<div class="line"><span class="lineno">  383</span>    sample_weight = np.array([1, 1, 2, 2], dtype=np.float64)</div>
<div class="line"><span class="lineno">  384</span>    sample_weight /= sample_weight.sum()</div>
<div class="line"><span class="lineno">  385</span>    clf = DiscreteNaiveBayes().fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  386</span>    assert_array_equal(clf.predict(X), [0, 1, 1, 2])</div>
<div class="line"><span class="lineno">  387</span> </div>
<div class="line"><span class="lineno">  388</span>    <span class="comment"># Check sample weight using the partial_fit method</span></div>
<div class="line"><span class="lineno">  389</span>    clf = DiscreteNaiveBayes()</div>
<div class="line"><span class="lineno">  390</span>    clf.partial_fit(X[:2], y[:2], classes=[0, 1, 2], sample_weight=sample_weight[:2])</div>
<div class="line"><span class="lineno">  391</span>    clf.partial_fit(X[2:3], y[2:3], sample_weight=sample_weight[2:3])</div>
<div class="line"><span class="lineno">  392</span>    clf.partial_fit(X[3:], y[3:], sample_weight=sample_weight[3:])</div>
<div class="line"><span class="lineno">  393</span>    assert_array_equal(clf.predict(X), [0, 1, 1, 2])</div>
<div class="line"><span class="lineno">  394</span> </div>
<div class="line"><span class="lineno">  395</span> </div>
<div class="line"><span class="lineno">  396</span><span class="preprocessor">@pytest.mark.parametrize(&quot;DiscreteNaiveBayes&quot;, DISCRETE_NAIVE_BAYES_CLASSES)</span></div>
<div class="line"><span class="lineno">  397</span><span class="preprocessor">@pytest.mark.parametrize(&quot;use_partial_fit&quot;, [False, True])</span></div>
<div class="line"><span class="lineno">  398</span><span class="preprocessor">@pytest.mark.parametrize(&quot;train_on_single_class_y&quot;, [False, True])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a749d2395c201b8d559871c428240dde4" name="a749d2395c201b8d559871c428240dde4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a749d2395c201b8d559871c428240dde4">&#9670;&#160;</a></span>test_discretenb_uniform_prior()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_discretenb_uniform_prior </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>DiscreteNaiveBayes</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  322</span><span class="keyword">def </span>test_discretenb_uniform_prior(DiscreteNaiveBayes):</div>
<div class="line"><span class="lineno">  323</span>    <span class="comment"># Test whether discrete NB classes fit a uniform prior</span></div>
<div class="line"><span class="lineno">  324</span>    <span class="comment"># when fit_prior=False and class_prior=None</span></div>
<div class="line"><span class="lineno">  325</span> </div>
<div class="line"><span class="lineno">  326</span>    clf = DiscreteNaiveBayes()</div>
<div class="line"><span class="lineno">  327</span>    clf.set_params(fit_prior=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  328</span>    clf.fit([[0], [0], [1]], [0, 0, 1])</div>
<div class="line"><span class="lineno">  329</span>    prior = np.exp(clf.class_log_prior_)</div>
<div class="line"><span class="lineno">  330</span>    assert_array_almost_equal(prior, np.array([0.5, 0.5]))</div>
<div class="line"><span class="lineno">  331</span> </div>
<div class="line"><span class="lineno">  332</span> </div>
<div class="line"><span class="lineno">  333</span><span class="preprocessor">@pytest.mark.parametrize(&quot;DiscreteNaiveBayes&quot;, DISCRETE_NAIVE_BAYES_CLASSES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a7461afcd8f2b46bc08d6dc92c6595ff8" name="a7461afcd8f2b46bc08d6dc92c6595ff8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7461afcd8f2b46bc08d6dc92c6595ff8">&#9670;&#160;</a></span>test_force_alpha_deprecation()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_force_alpha_deprecation </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Estimator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  909</span><span class="keyword">def </span>test_force_alpha_deprecation(Estimator, alpha):</div>
<div class="line"><span class="lineno">  910</span>    <span class="keywordflow">if</span> Estimator <span class="keywordflow">is</span> CategoricalNB <span class="keywordflow">and</span> isinstance(alpha, list):</div>
<div class="line"><span class="lineno">  911</span>        pytest.skip(<span class="stringliteral">&quot;CategoricalNB does not support array-like alpha values.&quot;</span>)</div>
<div class="line"><span class="lineno">  912</span>    X = np.array([[1, 2], [3, 4]])</div>
<div class="line"><span class="lineno">  913</span>    y = np.array([1, 0])</div>
<div class="line"><span class="lineno">  914</span>    alpha_min = 1e-10</div>
<div class="line"><span class="lineno">  915</span>    msg = <span class="stringliteral">&quot;The default value for `force_alpha` will change to `True`&quot;</span></div>
<div class="line"><span class="lineno">  916</span>    est = Estimator(alpha=alpha)</div>
<div class="line"><span class="lineno">  917</span>    est_force = Estimator(alpha=alpha, force_alpha=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  918</span>    <span class="keywordflow">if</span> np.min(alpha) &lt; alpha_min:</div>
<div class="line"><span class="lineno">  919</span>        <span class="keyword">with</span> pytest.warns(FutureWarning, match=msg):</div>
<div class="line"><span class="lineno">  920</span>            est.fit(X, y)</div>
<div class="line"><span class="lineno">  921</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  922</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno">  923</span>    est_force.fit(X, y)</div>
<div class="line"><span class="lineno">  924</span> </div>
<div class="line"><span class="lineno">  925</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a10f722aede94044416c7cdd4e3cf7b2f" name="a10f722aede94044416c7cdd4e3cf7b2f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a10f722aede94044416c7cdd4e3cf7b2f">&#9670;&#160;</a></span>test_gnb()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   45</span><span class="keyword">def </span>test_gnb():</div>
<div class="line"><span class="lineno">   46</span>    <span class="comment"># Gaussian Naive Bayes classification.</span></div>
<div class="line"><span class="lineno">   47</span>    <span class="comment"># This checks that GaussianNB implements fit and predict and returns</span></div>
<div class="line"><span class="lineno">   48</span>    <span class="comment"># correct values for a simple toy dataset.</span></div>
<div class="line"><span class="lineno">   49</span> </div>
<div class="line"><span class="lineno">   50</span>    clf = GaussianNB()</div>
<div class="line"><span class="lineno">   51</span>    y_pred = clf.fit(X, y).predict(X)</div>
<div class="line"><span class="lineno">   52</span>    assert_array_equal(y_pred, y)</div>
<div class="line"><span class="lineno">   53</span> </div>
<div class="line"><span class="lineno">   54</span>    y_pred_proba = clf.predict_proba(X)</div>
<div class="line"><span class="lineno">   55</span>    y_pred_log_proba = clf.predict_log_proba(X)</div>
<div class="line"><span class="lineno">   56</span>    assert_array_almost_equal(np.log(y_pred_proba), y_pred_log_proba, 8)</div>
<div class="line"><span class="lineno">   57</span> </div>
<div class="line"><span class="lineno">   58</span>    <span class="comment"># Test whether label mismatch between target y and classes raises</span></div>
<div class="line"><span class="lineno">   59</span>    <span class="comment"># an Error</span></div>
<div class="line"><span class="lineno">   60</span>    <span class="comment"># FIXME Remove this test once the more general partial_fit tests are merged</span></div>
<div class="line"><span class="lineno">   61</span>    <span class="keyword">with</span> pytest.raises(</div>
<div class="line"><span class="lineno">   62</span>        ValueError, match=<span class="stringliteral">&quot;The target label.* in y do not exist in the initial classes&quot;</span></div>
<div class="line"><span class="lineno">   63</span>    ):</div>
<div class="line"><span class="lineno">   64</span>        GaussianNB().partial_fit(X, y, classes=[0, 1])</div>
<div class="line"><span class="lineno">   65</span> </div>
<div class="line"><span class="lineno">   66</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0af02e03e40b1fc19cdd4756bd75e62a" name="a0af02e03e40b1fc19cdd4756bd75e62a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0af02e03e40b1fc19cdd4756bd75e62a">&#9670;&#160;</a></span>test_gnb_check_update_with_no_data()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_check_update_with_no_data </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test when the partial fit is called without any data</pre> <div class="fragment"><div class="line"><span class="lineno">  177</span><span class="keyword">def </span>test_gnb_check_update_with_no_data():</div>
<div class="line"><span class="lineno">  178</span>    <span class="stringliteral">&quot;&quot;&quot;Test when the partial fit is called without any data&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  179</span>    <span class="comment"># Create an empty array</span></div>
<div class="line"><span class="lineno">  180</span>    prev_points = 100</div>
<div class="line"><span class="lineno">  181</span>    mean = 0.0</div>
<div class="line"><span class="lineno">  182</span>    var = 1.0</div>
<div class="line"><span class="lineno">  183</span>    x_empty = np.empty((0, X.shape[1]))</div>
<div class="line"><span class="lineno">  184</span>    tmean, tvar = GaussianNB._update_mean_variance(prev_points, mean, var, x_empty)</div>
<div class="line"><span class="lineno">  185</span>    <span class="keyword">assert</span> tmean == mean</div>
<div class="line"><span class="lineno">  186</span>    <span class="keyword">assert</span> tvar == var</div>
<div class="line"><span class="lineno">  187</span> </div>
<div class="line"><span class="lineno">  188</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a484722e8fb10577aa40661a1dc4a7c91" name="a484722e8fb10577aa40661a1dc4a7c91"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a484722e8fb10577aa40661a1dc4a7c91">&#9670;&#160;</a></span>test_gnb_naive_bayes_scale_invariance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_naive_bayes_scale_invariance </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  203</span><span class="keyword">def </span>test_gnb_naive_bayes_scale_invariance():</div>
<div class="line"><span class="lineno">  204</span>    <span class="comment"># Scaling the data should not change the prediction results</span></div>
<div class="line"><span class="lineno">  205</span>    iris = load_iris()</div>
<div class="line"><span class="lineno">  206</span>    X, y = iris.data, iris.target</div>
<div class="line"><span class="lineno">  207</span>    labels = [GaussianNB().fit(f * X, y).predict(f * X) <span class="keywordflow">for</span> f <span class="keywordflow">in</span> [1e-10, 1, 1e10]]</div>
<div class="line"><span class="lineno">  208</span>    assert_array_equal(labels[0], labels[1])</div>
<div class="line"><span class="lineno">  209</span>    assert_array_equal(labels[1], labels[2])</div>
<div class="line"><span class="lineno">  210</span> </div>
<div class="line"><span class="lineno">  211</span> </div>
<div class="line"><span class="lineno">  212</span><span class="preprocessor">@pytest.mark.parametrize(&quot;DiscreteNaiveBayes&quot;, DISCRETE_NAIVE_BAYES_CLASSES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a24f28303585c3d70aacc4adcf97307ea" name="a24f28303585c3d70aacc4adcf97307ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24f28303585c3d70aacc4adcf97307ea">&#9670;&#160;</a></span>test_gnb_neg_priors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_neg_priors </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test whether an error is raised in case of negative priors</pre> <div class="fragment"><div class="line"><span class="lineno">  108</span><span class="keyword">def </span>test_gnb_neg_priors():</div>
<div class="line"><span class="lineno">  109</span>    <span class="stringliteral">&quot;&quot;&quot;Test whether an error is raised in case of negative priors&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  110</span>    clf = GaussianNB(priors=np.array([-1.0, 2.0]))</div>
<div class="line"><span class="lineno">  111</span> </div>
<div class="line"><span class="lineno">  112</span>    msg = <span class="stringliteral">&quot;Priors must be non-negative&quot;</span></div>
<div class="line"><span class="lineno">  113</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  114</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  115</span> </div>
<div class="line"><span class="lineno">  116</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a59129051ec35ecad52b5675db81dd683" name="a59129051ec35ecad52b5675db81dd683"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59129051ec35ecad52b5675db81dd683">&#9670;&#160;</a></span>test_gnb_partial_fit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_partial_fit </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  189</span><span class="keyword">def </span>test_gnb_partial_fit():</div>
<div class="line"><span class="lineno">  190</span>    clf = GaussianNB().fit(X, y)</div>
<div class="line"><span class="lineno">  191</span>    clf_pf = GaussianNB().partial_fit(X, y, np.unique(y))</div>
<div class="line"><span class="lineno">  192</span>    assert_array_almost_equal(clf.theta_, clf_pf.theta_)</div>
<div class="line"><span class="lineno">  193</span>    assert_array_almost_equal(clf.var_, clf_pf.var_)</div>
<div class="line"><span class="lineno">  194</span>    assert_array_almost_equal(clf.class_prior_, clf_pf.class_prior_)</div>
<div class="line"><span class="lineno">  195</span> </div>
<div class="line"><span class="lineno">  196</span>    clf_pf2 = GaussianNB().partial_fit(X[0::2, :], y[0::2], np.unique(y))</div>
<div class="line"><span class="lineno">  197</span>    clf_pf2.partial_fit(X[1::2], y[1::2])</div>
<div class="line"><span class="lineno">  198</span>    assert_array_almost_equal(clf.theta_, clf_pf2.theta_)</div>
<div class="line"><span class="lineno">  199</span>    assert_array_almost_equal(clf.var_, clf_pf2.var_)</div>
<div class="line"><span class="lineno">  200</span>    assert_array_almost_equal(clf.class_prior_, clf_pf2.class_prior_)</div>
<div class="line"><span class="lineno">  201</span> </div>
<div class="line"><span class="lineno">  202</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1595e0a53e81a04a44df2d97ac251589" name="a1595e0a53e81a04a44df2d97ac251589"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1595e0a53e81a04a44df2d97ac251589">&#9670;&#160;</a></span>test_gnb_prior()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_prior </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   67</span><span class="keyword">def </span>test_gnb_prior():</div>
<div class="line"><span class="lineno">   68</span>    <span class="comment"># Test whether class priors are properly set.</span></div>
<div class="line"><span class="lineno">   69</span>    clf = GaussianNB().fit(X, y)</div>
<div class="line"><span class="lineno">   70</span>    assert_array_almost_equal(np.array([3, 3]) / 6.0, clf.class_prior_, 8)</div>
<div class="line"><span class="lineno">   71</span>    clf = GaussianNB().fit(X1, y1)</div>
<div class="line"><span class="lineno">   72</span>    <span class="comment"># Check that the class priors sum to 1</span></div>
<div class="line"><span class="lineno">   73</span>    assert_array_almost_equal(clf.class_prior_.sum(), 1)</div>
<div class="line"><span class="lineno">   74</span> </div>
<div class="line"><span class="lineno">   75</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5fe35ef9f827aef2b0a9a81aeed167b6" name="a5fe35ef9f827aef2b0a9a81aeed167b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5fe35ef9f827aef2b0a9a81aeed167b6">&#9670;&#160;</a></span>test_gnb_prior_greater_one()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_prior_greater_one </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test if an error is raised if the sum of prior greater than one</pre> <div class="fragment"><div class="line"><span class="lineno">  161</span><span class="keyword">def </span>test_gnb_prior_greater_one():</div>
<div class="line"><span class="lineno">  162</span>    <span class="stringliteral">&quot;&quot;&quot;Test if an error is raised if the sum of prior greater than one&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  163</span>    clf = GaussianNB(priors=np.array([2.0, 1.0]))</div>
<div class="line"><span class="lineno">  164</span> </div>
<div class="line"><span class="lineno">  165</span>    msg = <span class="stringliteral">&quot;The sum of the priors should be 1&quot;</span></div>
<div class="line"><span class="lineno">  166</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  167</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  168</span> </div>
<div class="line"><span class="lineno">  169</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a98e7ea888345d76e7ba0d3e76b2aef2a" name="a98e7ea888345d76e7ba0d3e76b2aef2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a98e7ea888345d76e7ba0d3e76b2aef2a">&#9670;&#160;</a></span>test_gnb_prior_large_bias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_prior_large_bias </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test if good prediction when class prior favor largely one class</pre> <div class="fragment"><div class="line"><span class="lineno">  170</span><span class="keyword">def </span>test_gnb_prior_large_bias():</div>
<div class="line"><span class="lineno">  171</span>    <span class="stringliteral">&quot;&quot;&quot;Test if good prediction when class prior favor largely one class&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  172</span>    clf = GaussianNB(priors=np.array([0.01, 0.99]))</div>
<div class="line"><span class="lineno">  173</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  174</span>    <span class="keyword">assert</span> clf.predict([[-0.1, -0.1]]) == np.array([2])</div>
<div class="line"><span class="lineno">  175</span> </div>
<div class="line"><span class="lineno">  176</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a593edb7ebb05a84b93e4ed98d8064af4" name="a593edb7ebb05a84b93e4ed98d8064af4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a593edb7ebb05a84b93e4ed98d8064af4">&#9670;&#160;</a></span>test_gnb_priors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_priors </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test whether the class prior override is properly used</pre> <div class="fragment"><div class="line"><span class="lineno">  117</span><span class="keyword">def </span>test_gnb_priors():</div>
<div class="line"><span class="lineno">  118</span>    <span class="stringliteral">&quot;&quot;&quot;Test whether the class prior override is properly used&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  119</span>    clf = GaussianNB(priors=np.array([0.3, 0.7])).fit(X, y)</div>
<div class="line"><span class="lineno">  120</span>    assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  121</span>        clf.predict_proba([[-0.1, -0.1]]),</div>
<div class="line"><span class="lineno">  122</span>        np.array([[0.825303662161683, 0.174696337838317]]),</div>
<div class="line"><span class="lineno">  123</span>        8,</div>
<div class="line"><span class="lineno">  124</span>    )</div>
<div class="line"><span class="lineno">  125</span>    assert_array_almost_equal(clf.class_prior_, np.array([0.3, 0.7]))</div>
<div class="line"><span class="lineno">  126</span> </div>
<div class="line"><span class="lineno">  127</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aed95c6e9135463debcf139a3923962b0" name="aed95c6e9135463debcf139a3923962b0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aed95c6e9135463debcf139a3923962b0">&#9670;&#160;</a></span>test_gnb_priors_sum_isclose()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_priors_sum_isclose </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  128</span><span class="keyword">def </span>test_gnb_priors_sum_isclose():</div>
<div class="line"><span class="lineno">  129</span>    <span class="comment"># test whether the class prior sum is properly tested&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  130</span>    X = np.array(</div>
<div class="line"><span class="lineno">  131</span>        [</div>
<div class="line"><span class="lineno">  132</span>            [-1, -1],</div>
<div class="line"><span class="lineno">  133</span>            [-2, -1],</div>
<div class="line"><span class="lineno">  134</span>            [-3, -2],</div>
<div class="line"><span class="lineno">  135</span>            [-4, -5],</div>
<div class="line"><span class="lineno">  136</span>            [-5, -4],</div>
<div class="line"><span class="lineno">  137</span>            [1, 1],</div>
<div class="line"><span class="lineno">  138</span>            [2, 1],</div>
<div class="line"><span class="lineno">  139</span>            [3, 2],</div>
<div class="line"><span class="lineno">  140</span>            [4, 4],</div>
<div class="line"><span class="lineno">  141</span>            [5, 5],</div>
<div class="line"><span class="lineno">  142</span>        ]</div>
<div class="line"><span class="lineno">  143</span>    )</div>
<div class="line"><span class="lineno">  144</span>    priors = np.array([0.08, 0.14, 0.03, 0.16, 0.11, 0.16, 0.07, 0.14, 0.11, 0.0])</div>
<div class="line"><span class="lineno">  145</span>    Y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])</div>
<div class="line"><span class="lineno">  146</span>    clf = GaussianNB(priors=priors)</div>
<div class="line"><span class="lineno">  147</span>    <span class="comment"># smoke test for issue #9633</span></div>
<div class="line"><span class="lineno">  148</span>    clf.fit(X, Y)</div>
<div class="line"><span class="lineno">  149</span> </div>
<div class="line"><span class="lineno">  150</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a08fb05d56b221cc96f5bf0306c8fa08d" name="a08fb05d56b221cc96f5bf0306c8fa08d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a08fb05d56b221cc96f5bf0306c8fa08d">&#9670;&#160;</a></span>test_gnb_sample_weight()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_sample_weight </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test whether sample weights are properly used in GNB.</pre> <div class="fragment"><div class="line"><span class="lineno">   76</span><span class="keyword">def </span>test_gnb_sample_weight():</div>
<div class="line"><span class="lineno">   77</span>    <span class="stringliteral">&quot;&quot;&quot;Test whether sample weights are properly used in GNB.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   78</span>    <span class="comment"># Sample weights all being 1 should not change results</span></div>
<div class="line"><span class="lineno">   79</span>    sw = np.ones(6)</div>
<div class="line"><span class="lineno">   80</span>    clf = GaussianNB().fit(X, y)</div>
<div class="line"><span class="lineno">   81</span>    clf_sw = GaussianNB().fit(X, y, sw)</div>
<div class="line"><span class="lineno">   82</span> </div>
<div class="line"><span class="lineno">   83</span>    assert_array_almost_equal(clf.theta_, clf_sw.theta_)</div>
<div class="line"><span class="lineno">   84</span>    assert_array_almost_equal(clf.var_, clf_sw.var_)</div>
<div class="line"><span class="lineno">   85</span> </div>
<div class="line"><span class="lineno">   86</span>    <span class="comment"># Fitting twice with half sample-weights should result</span></div>
<div class="line"><span class="lineno">   87</span>    <span class="comment"># in same result as fitting once with full weights</span></div>
<div class="line"><span class="lineno">   88</span>    sw = rng.rand(y.shape[0])</div>
<div class="line"><span class="lineno">   89</span>    clf1 = GaussianNB().fit(X, y, sample_weight=sw)</div>
<div class="line"><span class="lineno">   90</span>    clf2 = GaussianNB().partial_fit(X, y, classes=[1, 2], sample_weight=sw / 2)</div>
<div class="line"><span class="lineno">   91</span>    clf2.partial_fit(X, y, sample_weight=sw / 2)</div>
<div class="line"><span class="lineno">   92</span> </div>
<div class="line"><span class="lineno">   93</span>    assert_array_almost_equal(clf1.theta_, clf2.theta_)</div>
<div class="line"><span class="lineno">   94</span>    assert_array_almost_equal(clf1.var_, clf2.var_)</div>
<div class="line"><span class="lineno">   95</span> </div>
<div class="line"><span class="lineno">   96</span>    <span class="comment"># Check that duplicate entries and correspondingly increased sample</span></div>
<div class="line"><span class="lineno">   97</span>    <span class="comment"># weights yield the same result</span></div>
<div class="line"><span class="lineno">   98</span>    ind = rng.randint(0, X.shape[0], 20)</div>
<div class="line"><span class="lineno">   99</span>    sample_weight = np.bincount(ind, minlength=X.shape[0])</div>
<div class="line"><span class="lineno">  100</span> </div>
<div class="line"><span class="lineno">  101</span>    clf_dupl = GaussianNB().fit(X[ind], y[ind])</div>
<div class="line"><span class="lineno">  102</span>    clf_sw = GaussianNB().fit(X, y, sample_weight)</div>
<div class="line"><span class="lineno">  103</span> </div>
<div class="line"><span class="lineno">  104</span>    assert_array_almost_equal(clf_dupl.theta_, clf_sw.theta_)</div>
<div class="line"><span class="lineno">  105</span>    assert_array_almost_equal(clf_dupl.var_, clf_sw.var_)</div>
<div class="line"><span class="lineno">  106</span> </div>
<div class="line"><span class="lineno">  107</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af854e2f16e8ba8fec0292f6134ed93b2" name="af854e2f16e8ba8fec0292f6134ed93b2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af854e2f16e8ba8fec0292f6134ed93b2">&#9670;&#160;</a></span>test_gnb_wrong_nb_priors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_gnb_wrong_nb_priors </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test whether an error is raised if the number of prior is different
from the number of class</pre> <div class="fragment"><div class="line"><span class="lineno">  151</span><span class="keyword">def </span>test_gnb_wrong_nb_priors():</div>
<div class="line"><span class="lineno">  152</span>    <span class="stringliteral">&quot;&quot;&quot;Test whether an error is raised if the number of prior is different</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">    from the number of class&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  154</span>    clf = GaussianNB(priors=np.array([0.25, 0.25, 0.25, 0.25]))</div>
<div class="line"><span class="lineno">  155</span> </div>
<div class="line"><span class="lineno">  156</span>    msg = <span class="stringliteral">&quot;Number of priors must match number of classes&quot;</span></div>
<div class="line"><span class="lineno">  157</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  158</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  159</span> </div>
<div class="line"><span class="lineno">  160</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa8e89adf0e49608f80c6291200372230" name="aa8e89adf0e49608f80c6291200372230"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa8e89adf0e49608f80c6291200372230">&#9670;&#160;</a></span>test_mnb_prior_unobserved_targets()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_mnb_prior_unobserved_targets </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  504</span><span class="keyword">def </span>test_mnb_prior_unobserved_targets():</div>
<div class="line"><span class="lineno">  505</span>    <span class="comment"># test smoothing of prior for yet unobserved targets</span></div>
<div class="line"><span class="lineno">  506</span> </div>
<div class="line"><span class="lineno">  507</span>    <span class="comment"># Create toy training data</span></div>
<div class="line"><span class="lineno">  508</span>    X = np.array([[0, 1], [1, 0]])</div>
<div class="line"><span class="lineno">  509</span>    y = np.array([0, 1])</div>
<div class="line"><span class="lineno">  510</span> </div>
<div class="line"><span class="lineno">  511</span>    clf = MultinomialNB()</div>
<div class="line"><span class="lineno">  512</span> </div>
<div class="line"><span class="lineno">  513</span>    <span class="keyword">with</span> warnings.catch_warnings():</div>
<div class="line"><span class="lineno">  514</span>        warnings.simplefilter(<span class="stringliteral">&quot;error&quot;</span>, RuntimeWarning)</div>
<div class="line"><span class="lineno">  515</span> </div>
<div class="line"><span class="lineno">  516</span>        clf.partial_fit(X, y, classes=[0, 1, 2])</div>
<div class="line"><span class="lineno">  517</span> </div>
<div class="line"><span class="lineno">  518</span>    <span class="keyword">assert</span> clf.predict([[0, 1]]) == 0</div>
<div class="line"><span class="lineno">  519</span>    <span class="keyword">assert</span> clf.predict([[1, 0]]) == 1</div>
<div class="line"><span class="lineno">  520</span>    <span class="keyword">assert</span> clf.predict([[1, 1]]) == 0</div>
<div class="line"><span class="lineno">  521</span> </div>
<div class="line"><span class="lineno">  522</span>    <span class="comment"># add a training example with previously unobserved class</span></div>
<div class="line"><span class="lineno">  523</span>    <span class="keyword">with</span> warnings.catch_warnings():</div>
<div class="line"><span class="lineno">  524</span>        warnings.simplefilter(<span class="stringliteral">&quot;error&quot;</span>, RuntimeWarning)</div>
<div class="line"><span class="lineno">  525</span> </div>
<div class="line"><span class="lineno">  526</span>        clf.partial_fit([[1, 1]], [2])</div>
<div class="line"><span class="lineno">  527</span> </div>
<div class="line"><span class="lineno">  528</span>    <span class="keyword">assert</span> clf.predict([[0, 1]]) == 0</div>
<div class="line"><span class="lineno">  529</span>    <span class="keyword">assert</span> clf.predict([[1, 0]]) == 1</div>
<div class="line"><span class="lineno">  530</span>    <span class="keyword">assert</span> clf.predict([[1, 1]]) == 2</div>
<div class="line"><span class="lineno">  531</span> </div>
<div class="line"><span class="lineno">  532</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af5f3e58251ade169125e660e16a636f6" name="af5f3e58251ade169125e660e16a636f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5f3e58251ade169125e660e16a636f6">&#9670;&#160;</a></span>test_mnnb()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_mnnb </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>kind</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  450</span><span class="keyword">def </span>test_mnnb(kind):</div>
<div class="line"><span class="lineno">  451</span>    <span class="comment"># Test Multinomial Naive Bayes classification.</span></div>
<div class="line"><span class="lineno">  452</span>    <span class="comment"># This checks that MultinomialNB implements fit and predict and returns</span></div>
<div class="line"><span class="lineno">  453</span>    <span class="comment"># correct values for a simple toy dataset.</span></div>
<div class="line"><span class="lineno">  454</span> </div>
<div class="line"><span class="lineno">  455</span>    <span class="keywordflow">if</span> kind == <span class="stringliteral">&quot;dense&quot;</span>:</div>
<div class="line"><span class="lineno">  456</span>        X = X2</div>
<div class="line"><span class="lineno">  457</span>    <span class="keywordflow">elif</span> kind == <span class="stringliteral">&quot;sparse&quot;</span>:</div>
<div class="line"><span class="lineno">  458</span>        X = <a class="code hl_class" href="classscipy_1_1sparse_1_1__csr_1_1csr__matrix.html">scipy.sparse.csr_matrix</a>(X2)</div>
<div class="line"><span class="lineno">  459</span> </div>
<div class="line"><span class="lineno">  460</span>    <span class="comment"># Check the ability to predict the learning set.</span></div>
<div class="line"><span class="lineno">  461</span>    clf = MultinomialNB()</div>
<div class="line"><span class="lineno">  462</span> </div>
<div class="line"><span class="lineno">  463</span>    msg = <span class="stringliteral">&quot;Negative values in data passed to&quot;</span></div>
<div class="line"><span class="lineno">  464</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  465</span>        clf.fit(-X, y2)</div>
<div class="line"><span class="lineno">  466</span>    y_pred = clf.fit(X, y2).predict(X)</div>
<div class="line"><span class="lineno">  467</span> </div>
<div class="line"><span class="lineno">  468</span>    assert_array_equal(y_pred, y2)</div>
<div class="line"><span class="lineno">  469</span> </div>
<div class="line"><span class="lineno">  470</span>    <span class="comment"># Verify that np.log(clf.predict_proba(X)) gives the same results as</span></div>
<div class="line"><span class="lineno">  471</span>    <span class="comment"># clf.predict_log_proba(X)</span></div>
<div class="line"><span class="lineno">  472</span>    y_pred_proba = clf.predict_proba(X)</div>
<div class="line"><span class="lineno">  473</span>    y_pred_log_proba = clf.predict_log_proba(X)</div>
<div class="line"><span class="lineno">  474</span>    assert_array_almost_equal(np.log(y_pred_proba), y_pred_log_proba, 8)</div>
<div class="line"><span class="lineno">  475</span> </div>
<div class="line"><span class="lineno">  476</span>    <span class="comment"># Check that incremental fitting yields the same results</span></div>
<div class="line"><span class="lineno">  477</span>    clf2 = MultinomialNB()</div>
<div class="line"><span class="lineno">  478</span>    clf2.partial_fit(X[:2], y2[:2], classes=np.unique(y2))</div>
<div class="line"><span class="lineno">  479</span>    clf2.partial_fit(X[2:5], y2[2:5])</div>
<div class="line"><span class="lineno">  480</span>    clf2.partial_fit(X[5:], y2[5:])</div>
<div class="line"><span class="lineno">  481</span> </div>
<div class="line"><span class="lineno">  482</span>    y_pred2 = clf2.predict(X)</div>
<div class="line"><span class="lineno">  483</span>    assert_array_equal(y_pred2, y2)</div>
<div class="line"><span class="lineno">  484</span> </div>
<div class="line"><span class="lineno">  485</span>    y_pred_proba2 = clf2.predict_proba(X)</div>
<div class="line"><span class="lineno">  486</span>    y_pred_log_proba2 = clf2.predict_log_proba(X)</div>
<div class="line"><span class="lineno">  487</span>    assert_array_almost_equal(np.log(y_pred_proba2), y_pred_log_proba2, 8)</div>
<div class="line"><span class="lineno">  488</span>    assert_array_almost_equal(y_pred_proba2, y_pred_proba)</div>
<div class="line"><span class="lineno">  489</span>    assert_array_almost_equal(y_pred_log_proba2, y_pred_log_proba)</div>
<div class="line"><span class="lineno">  490</span> </div>
<div class="line"><span class="lineno">  491</span>    <span class="comment"># Partial fit on the whole data at once should be the same as fit too</span></div>
<div class="line"><span class="lineno">  492</span>    clf3 = MultinomialNB()</div>
<div class="line"><span class="lineno">  493</span>    clf3.partial_fit(X, y2, classes=np.unique(y2))</div>
<div class="line"><span class="lineno">  494</span> </div>
<div class="line"><span class="lineno">  495</span>    y_pred3 = clf3.predict(X)</div>
<div class="line"><span class="lineno">  496</span>    assert_array_equal(y_pred3, y2)</div>
<div class="line"><span class="lineno">  497</span>    y_pred_proba3 = clf3.predict_proba(X)</div>
<div class="line"><span class="lineno">  498</span>    y_pred_log_proba3 = clf3.predict_log_proba(X)</div>
<div class="line"><span class="lineno">  499</span>    assert_array_almost_equal(np.log(y_pred_proba3), y_pred_log_proba3, 8)</div>
<div class="line"><span class="lineno">  500</span>    assert_array_almost_equal(y_pred_proba3, y_pred_proba)</div>
<div class="line"><span class="lineno">  501</span>    assert_array_almost_equal(y_pred_log_proba3, y_pred_log_proba)</div>
<div class="line"><span class="lineno">  502</span> </div>
<div class="line"><span class="lineno">  503</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af267455721e4bd81d241229c85a15cb8" name="af267455721e4bd81d241229c85a15cb8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af267455721e4bd81d241229c85a15cb8">&#9670;&#160;</a></span>test_NB_partial_fit_no_first_classes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_NB_partial_fit_no_first_classes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>NaiveBayes</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  272</span><span class="keyword">def </span>test_NB_partial_fit_no_first_classes(NaiveBayes):</div>
<div class="line"><span class="lineno">  273</span>    <span class="comment"># classes is required for first call to partial fit</span></div>
<div class="line"><span class="lineno">  274</span>    <span class="keyword">with</span> pytest.raises(</div>
<div class="line"><span class="lineno">  275</span>        ValueError, match=<span class="stringliteral">&quot;classes must be passed on the first call to partial_fit.&quot;</span></div>
<div class="line"><span class="lineno">  276</span>    ):</div>
<div class="line"><span class="lineno">  277</span>        NaiveBayes().partial_fit(X2, y2)</div>
<div class="line"><span class="lineno">  278</span> </div>
<div class="line"><span class="lineno">  279</span>    <span class="comment"># check consistency of consecutive classes values</span></div>
<div class="line"><span class="lineno">  280</span>    clf = NaiveBayes()</div>
<div class="line"><span class="lineno">  281</span>    clf.partial_fit(X2, y2, classes=np.unique(y2))</div>
<div class="line"><span class="lineno">  282</span>    <span class="keyword">with</span> pytest.raises(</div>
<div class="line"><span class="lineno">  283</span>        ValueError, match=<span class="stringliteral">&quot;is not the same as on last call to partial_fit&quot;</span></div>
<div class="line"><span class="lineno">  284</span>    ):</div>
<div class="line"><span class="lineno">  285</span>        clf.partial_fit(X2, y2, classes=np.arange(42))</div>
<div class="line"><span class="lineno">  286</span> </div>
<div class="line"><span class="lineno">  287</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a28d2614f7d38235055f8388a8a3c6af4" name="a28d2614f7d38235055f8388a8a3c6af4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a28d2614f7d38235055f8388a8a3c6af4">&#9670;&#160;</a></span>test_predict_joint_proba()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.test_predict_joint_proba </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Estimator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  964</span><span class="keyword">def </span>test_predict_joint_proba(Estimator):</div>
<div class="line"><span class="lineno">  965</span>    est = Estimator().fit(X2, y2)</div>
<div class="line"><span class="lineno">  966</span>    jll = est.predict_joint_log_proba(X2)</div>
<div class="line"><span class="lineno">  967</span>    log_prob_x = logsumexp(jll, axis=1)</div>
<div class="line"><span class="lineno">  968</span>    log_prob_x_y = jll - np.atleast_2d(log_prob_x).T</div>
<div class="line"><span class="lineno">  969</span>    assert_allclose(est.predict_log_proba(X2), log_prob_x_y)</div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="ac90db191e1ecbcec2171fb5a09f6e39a" name="ac90db191e1ecbcec2171fb5a09f6e39a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac90db191e1ecbcec2171fb5a09f6e39a">&#9670;&#160;</a></span>ALL_NAIVE_BAYES_CLASSES</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.tests.test_naive_bayes.ALL_NAIVE_BAYES_CLASSES = <a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a46f773bb00225ae439c4338e45142c86">DISCRETE_NAIVE_BAYES_CLASSES</a> + [<a class="el" href="classsklearn_1_1naive__bayes_1_1_gaussian_n_b.html">GaussianNB</a>]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a46f773bb00225ae439c4338e45142c86" name="a46f773bb00225ae439c4338e45142c86"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46f773bb00225ae439c4338e45142c86">&#9670;&#160;</a></span>DISCRETE_NAIVE_BAYES_CLASSES</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.tests.test_naive_bayes.DISCRETE_NAIVE_BAYES_CLASSES = [<a class="el" href="classsklearn_1_1naive__bayes_1_1_bernoulli_n_b.html">BernoulliNB</a>, <a class="el" href="classsklearn_1_1naive__bayes_1_1_categorical_n_b.html">CategoricalNB</a>, <a class="el" href="classsklearn_1_1naive__bayes_1_1_complement_n_b.html">ComplementNB</a>, <a class="el" href="classsklearn_1_1naive__bayes_1_1_multinomial_n_b.html">MultinomialNB</a>]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3e7ce65cbf15b02a1ba65565126783be" name="a3e7ce65cbf15b02a1ba65565126783be"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3e7ce65cbf15b02a1ba65565126783be">&#9670;&#160;</a></span>msg</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">str sklearn.tests.test_naive_bayes.msg = &quot;The default value for `force_alpha` will change&quot;</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab6374da7293667fd46a8e75c00d5fdd3" name="ab6374da7293667fd46a8e75c00d5fdd3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab6374da7293667fd46a8e75c00d5fdd3">&#9670;&#160;</a></span>pytestmark</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.pytestmark = pytest.mark.filterwarnings(f&quot;ignore:{<a class="el" href="namespacesklearn_1_1tests_1_1test__naive__bayes.html#a3e7ce65cbf15b02a1ba65565126783be">msg</a>}:FutureWarning&quot;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ade2cf23d6f0539a259159dc58e1203ce" name="ade2cf23d6f0539a259159dc58e1203ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade2cf23d6f0539a259159dc58e1203ce">&#9670;&#160;</a></span>rng</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.rng = np.random.RandomState(0)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aadbfd25e902ceed3b6877d17eefb313b" name="aadbfd25e902ceed3b6877d17eefb313b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aadbfd25e902ceed3b6877d17eefb313b">&#9670;&#160;</a></span>X</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.X = np.array([[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]])</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4955b6a8fd5acecdf1abccf6a9ef5076" name="a4955b6a8fd5acecdf1abccf6a9ef5076"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4955b6a8fd5acecdf1abccf6a9ef5076">&#9670;&#160;</a></span>X1</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.X1 = rng.normal(size=(10, 3))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a08a522c98c3606bbaebf9371d66624dd" name="a08a522c98c3606bbaebf9371d66624dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a08a522c98c3606bbaebf9371d66624dd">&#9670;&#160;</a></span>X2</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.X2 = rng.randint(5, size=(6, 100))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a07a5c033abe5c93f1ecf29bc235c3795" name="a07a5c033abe5c93f1ecf29bc235c3795"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07a5c033abe5c93f1ecf29bc235c3795">&#9670;&#160;</a></span>y</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.y = np.array([1, 1, 1, 2, 2, 2])</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9e5175c6e48adb67716497c9c163d8b0" name="a9e5175c6e48adb67716497c9c163d8b0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e5175c6e48adb67716497c9c163d8b0">&#9670;&#160;</a></span>y1</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple sklearn.tests.test_naive_bayes.y1 = (rng.normal(size=(10)) &gt; 0).astype(int)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afa50840ed50270563ae3b37eb6c950c5" name="afa50840ed50270563ae3b37eb6c950c5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afa50840ed50270563ae3b37eb6c950c5">&#9670;&#160;</a></span>y2</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tests.test_naive_bayes.y2 = np.array([1, 1, 2, 2, 3, 3])</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
