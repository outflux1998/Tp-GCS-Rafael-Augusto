<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.svm._base Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1svm.html">svm</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1svm_1_1__base.html">_base</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.svm._base Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1svm_1_1__base_1_1_base_lib_s_v_m.html">BaseLibSVM</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1svm_1_1__base_1_1_base_s_v_c.html">BaseSVC</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:aa06fd7aa93a7c1c101edce53218d69a9" id="r_aa06fd7aa93a7c1c101edce53218d69a9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1svm_1_1__base.html#aa06fd7aa93a7c1c101edce53218d69a9">_one_vs_one_coef</a> (dual_coef, n_support, support_vectors)</td></tr>
<tr class="separator:aa06fd7aa93a7c1c101edce53218d69a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a744f8c0d87a44ff5827c8e9d0b451acd" id="r_a744f8c0d87a44ff5827c8e9d0b451acd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1svm_1_1__base.html#a744f8c0d87a44ff5827c8e9d0b451acd">_get_liblinear_solver_type</a> (multi_class, penalty, loss, dual)</td></tr>
<tr class="separator:a744f8c0d87a44ff5827c8e9d0b451acd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8528bba3e87685ee2351da306eca528" id="r_ab8528bba3e87685ee2351da306eca528"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1svm_1_1__base.html#ab8528bba3e87685ee2351da306eca528">_fit_liblinear</a> (X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>, random_state=None, multi_class=&quot;ovr&quot;, loss=&quot;logistic_regression&quot;, epsilon=0.1, sample_weight=None)</td></tr>
<tr class="separator:ab8528bba3e87685ee2351da306eca528"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a0b80d7c5e324f912550f18fd5fa74608" id="r_a0b80d7c5e324f912550f18fd5fa74608"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1svm_1_1__base.html#a0b80d7c5e324f912550f18fd5fa74608">LIBSVM_IMPL</a> = [&quot;c_svc&quot;, &quot;nu_svc&quot;, &quot;one_class&quot;, &quot;epsilon_svr&quot;, &quot;nu_svr&quot;]</td></tr>
<tr class="separator:a0b80d7c5e324f912550f18fd5fa74608"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="ab8528bba3e87685ee2351da306eca528" name="ab8528bba3e87685ee2351da306eca528"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab8528bba3e87685ee2351da306eca528">&#9670;&#160;</a></span>_fit_liblinear()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.svm._base._fit_liblinear </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>intercept_scaling</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>class_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>penalty</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dual</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em> = <code>&quot;ovr&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss</em> = <code>&quot;logistic_regression&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>epsilon</em> = <code>0.1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Used by Logistic Regression (and CV) and LinearSVC/LinearSVR.

Preprocessing is done in this function before supplying it to liblinear.

Parameters
----------
X : {array-like, sparse matrix} of shape (n_samples, n_features)
    Training vector, where `n_samples` is the number of samples and
    `n_features` is the number of features.

y : array-like of shape (n_samples,)
    Target vector relative to X

C : float
    Inverse of cross-validation parameter. Lower the C, the more
    the penalization.

fit_intercept : bool
    Whether or not to fit the intercept, that is to add a intercept
    term to the decision function.

intercept_scaling : float
    LibLinear internally penalizes the intercept and this term is subject
    to regularization just like the other terms of the feature vector.
    In order to avoid this, one should increase the intercept_scaling.
    such that the feature vector becomes [x, intercept_scaling].

class_weight : dict or 'balanced', default=None
    Weights associated with classes in the form ``{class_label: weight}``.
    If not given, all classes are supposed to have weight one. For
    multi-output problems, a list of dicts can be provided in the same
    order as the columns of y.

    The "balanced" mode uses the values of y to automatically adjust
    weights inversely proportional to class frequencies in the input data
    as ``n_samples / (n_classes * np.bincount(y))``

penalty : {'l1', 'l2'}
    The norm of the penalty used in regularization.

dual : bool
    Dual or primal formulation,

verbose : int
    Set verbose to any positive number for verbosity.

max_iter : int
    Number of iterations.

tol : float
    Stopping condition.

random_state : int, RandomState instance or None, default=None
    Controls the pseudo random number generation for shuffling the data.
    Pass an int for reproducible output across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

multi_class : {'ovr', 'crammer_singer'}, default='ovr'
    `ovr` trains n_classes one-vs-rest classifiers, while `crammer_singer`
    optimizes a joint objective over all classes.
    While `crammer_singer` is interesting from an theoretical perspective
    as it is consistent it is seldom used in practice and rarely leads to
    better accuracy and is more expensive to compute.
    If `crammer_singer` is chosen, the options loss, penalty and dual will
    be ignored.

loss : {'logistic_regression', 'hinge', 'squared_hinge', \
        'epsilon_insensitive', 'squared_epsilon_insensitive}, \
        default='logistic_regression'
    The loss function used to fit the model.

epsilon : float, default=0.1
    Epsilon parameter in the epsilon-insensitive loss function. Note
    that the value of this parameter depends on the scale of the target
    variable y. If unsure, set epsilon=0.

sample_weight : array-like of shape (n_samples,), default=None
    Weights assigned to each sample.

Returns
-------
coef_ : ndarray of shape (n_features, n_features + 1)
    The coefficient vector got by minimizing the objective function.

intercept_ : float
    The intercept term added to the vector.

n_iter_ : array of int
    Number of iterations run across for each class.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1085</span>):</div>
<div class="line"><span class="lineno"> 1086</span>    <span class="stringliteral">&quot;&quot;&quot;Used by Logistic Regression (and CV) and LinearSVC/LinearSVR.</span></div>
<div class="line"><span class="lineno"> 1087</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1088</span><span class="stringliteral">    Preprocessing is done in this function before supplying it to liblinear.</span></div>
<div class="line"><span class="lineno"> 1089</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1090</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1091</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1092</span><span class="stringliteral">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno"> 1093</span><span class="stringliteral">        Training vector, where `n_samples` is the number of samples and</span></div>
<div class="line"><span class="lineno"> 1094</span><span class="stringliteral">        `n_features` is the number of features.</span></div>
<div class="line"><span class="lineno"> 1095</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1096</span><span class="stringliteral">    y : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1097</span><span class="stringliteral">        Target vector relative to X</span></div>
<div class="line"><span class="lineno"> 1098</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1099</span><span class="stringliteral">    C : float</span></div>
<div class="line"><span class="lineno"> 1100</span><span class="stringliteral">        Inverse of cross-validation parameter. Lower the C, the more</span></div>
<div class="line"><span class="lineno"> 1101</span><span class="stringliteral">        the penalization.</span></div>
<div class="line"><span class="lineno"> 1102</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1103</span><span class="stringliteral">    fit_intercept : bool</span></div>
<div class="line"><span class="lineno"> 1104</span><span class="stringliteral">        Whether or not to fit the intercept, that is to add a intercept</span></div>
<div class="line"><span class="lineno"> 1105</span><span class="stringliteral">        term to the decision function.</span></div>
<div class="line"><span class="lineno"> 1106</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1107</span><span class="stringliteral">    intercept_scaling : float</span></div>
<div class="line"><span class="lineno"> 1108</span><span class="stringliteral">        LibLinear internally penalizes the intercept and this term is subject</span></div>
<div class="line"><span class="lineno"> 1109</span><span class="stringliteral">        to regularization just like the other terms of the feature vector.</span></div>
<div class="line"><span class="lineno"> 1110</span><span class="stringliteral">        In order to avoid this, one should increase the intercept_scaling.</span></div>
<div class="line"><span class="lineno"> 1111</span><span class="stringliteral">        such that the feature vector becomes [x, intercept_scaling].</span></div>
<div class="line"><span class="lineno"> 1112</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1113</span><span class="stringliteral">    class_weight : dict or &#39;balanced&#39;, default=None</span></div>
<div class="line"><span class="lineno"> 1114</span><span class="stringliteral">        Weights associated with classes in the form ``{class_label: weight}``.</span></div>
<div class="line"><span class="lineno"> 1115</span><span class="stringliteral">        If not given, all classes are supposed to have weight one. For</span></div>
<div class="line"><span class="lineno"> 1116</span><span class="stringliteral">        multi-output problems, a list of dicts can be provided in the same</span></div>
<div class="line"><span class="lineno"> 1117</span><span class="stringliteral">        order as the columns of y.</span></div>
<div class="line"><span class="lineno"> 1118</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1119</span><span class="stringliteral">        The &quot;balanced&quot; mode uses the values of y to automatically adjust</span></div>
<div class="line"><span class="lineno"> 1120</span><span class="stringliteral">        weights inversely proportional to class frequencies in the input data</span></div>
<div class="line"><span class="lineno"> 1121</span><span class="stringliteral">        as ``n_samples / (n_classes * np.bincount(y))``</span></div>
<div class="line"><span class="lineno"> 1122</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1123</span><span class="stringliteral">    penalty : {&#39;l1&#39;, &#39;l2&#39;}</span></div>
<div class="line"><span class="lineno"> 1124</span><span class="stringliteral">        The norm of the penalty used in regularization.</span></div>
<div class="line"><span class="lineno"> 1125</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1126</span><span class="stringliteral">    dual : bool</span></div>
<div class="line"><span class="lineno"> 1127</span><span class="stringliteral">        Dual or primal formulation,</span></div>
<div class="line"><span class="lineno"> 1128</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1129</span><span class="stringliteral">    verbose : int</span></div>
<div class="line"><span class="lineno"> 1130</span><span class="stringliteral">        Set verbose to any positive number for verbosity.</span></div>
<div class="line"><span class="lineno"> 1131</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1132</span><span class="stringliteral">    max_iter : int</span></div>
<div class="line"><span class="lineno"> 1133</span><span class="stringliteral">        Number of iterations.</span></div>
<div class="line"><span class="lineno"> 1134</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1135</span><span class="stringliteral">    tol : float</span></div>
<div class="line"><span class="lineno"> 1136</span><span class="stringliteral">        Stopping condition.</span></div>
<div class="line"><span class="lineno"> 1137</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1138</span><span class="stringliteral">    random_state : int, RandomState instance or None, default=None</span></div>
<div class="line"><span class="lineno"> 1139</span><span class="stringliteral">        Controls the pseudo random number generation for shuffling the data.</span></div>
<div class="line"><span class="lineno"> 1140</span><span class="stringliteral">        Pass an int for reproducible output across multiple function calls.</span></div>
<div class="line"><span class="lineno"> 1141</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno"> 1142</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1143</span><span class="stringliteral">    multi_class : {&#39;ovr&#39;, &#39;crammer_singer&#39;}, default=&#39;ovr&#39;</span></div>
<div class="line"><span class="lineno"> 1144</span><span class="stringliteral">        `ovr` trains n_classes one-vs-rest classifiers, while `crammer_singer`</span></div>
<div class="line"><span class="lineno"> 1145</span><span class="stringliteral">        optimizes a joint objective over all classes.</span></div>
<div class="line"><span class="lineno"> 1146</span><span class="stringliteral">        While `crammer_singer` is interesting from an theoretical perspective</span></div>
<div class="line"><span class="lineno"> 1147</span><span class="stringliteral">        as it is consistent it is seldom used in practice and rarely leads to</span></div>
<div class="line"><span class="lineno"> 1148</span><span class="stringliteral">        better accuracy and is more expensive to compute.</span></div>
<div class="line"><span class="lineno"> 1149</span><span class="stringliteral">        If `crammer_singer` is chosen, the options loss, penalty and dual will</span></div>
<div class="line"><span class="lineno"> 1150</span><span class="stringliteral">        be ignored.</span></div>
<div class="line"><span class="lineno"> 1151</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1152</span><span class="stringliteral">    loss : {&#39;logistic_regression&#39;, &#39;hinge&#39;, &#39;squared_hinge&#39;, \</span></div>
<div class="line"><span class="lineno"> 1153</span><span class="stringliteral">            &#39;epsilon_insensitive&#39;, &#39;squared_epsilon_insensitive}, \</span></div>
<div class="line"><span class="lineno"> 1154</span><span class="stringliteral">            default=&#39;logistic_regression&#39;</span></div>
<div class="line"><span class="lineno"> 1155</span><span class="stringliteral">        The loss function used to fit the model.</span></div>
<div class="line"><span class="lineno"> 1156</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1157</span><span class="stringliteral">    epsilon : float, default=0.1</span></div>
<div class="line"><span class="lineno"> 1158</span><span class="stringliteral">        Epsilon parameter in the epsilon-insensitive loss function. Note</span></div>
<div class="line"><span class="lineno"> 1159</span><span class="stringliteral">        that the value of this parameter depends on the scale of the target</span></div>
<div class="line"><span class="lineno"> 1160</span><span class="stringliteral">        variable y. If unsure, set epsilon=0.</span></div>
<div class="line"><span class="lineno"> 1161</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1162</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1163</span><span class="stringliteral">        Weights assigned to each sample.</span></div>
<div class="line"><span class="lineno"> 1164</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1165</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1166</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1167</span><span class="stringliteral">    coef_ : ndarray of shape (n_features, n_features + 1)</span></div>
<div class="line"><span class="lineno"> 1168</span><span class="stringliteral">        The coefficient vector got by minimizing the objective function.</span></div>
<div class="line"><span class="lineno"> 1169</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1170</span><span class="stringliteral">    intercept_ : float</span></div>
<div class="line"><span class="lineno"> 1171</span><span class="stringliteral">        The intercept term added to the vector.</span></div>
<div class="line"><span class="lineno"> 1172</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1173</span><span class="stringliteral">    n_iter_ : array of int</span></div>
<div class="line"><span class="lineno"> 1174</span><span class="stringliteral">        Number of iterations run across for each class.</span></div>
<div class="line"><span class="lineno"> 1175</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1176</span>    <span class="keywordflow">if</span> loss <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&quot;epsilon_insensitive&quot;</span>, <span class="stringliteral">&quot;squared_epsilon_insensitive&quot;</span>]:</div>
<div class="line"><span class="lineno"> 1177</span>        enc = LabelEncoder()</div>
<div class="line"><span class="lineno"> 1178</span>        y_ind = enc.fit_transform(y)</div>
<div class="line"><span class="lineno"> 1179</span>        classes_ = enc.classes_</div>
<div class="line"><span class="lineno"> 1180</span>        <span class="keywordflow">if</span> len(classes_) &lt; 2:</div>
<div class="line"><span class="lineno"> 1181</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1182</span>                <span class="stringliteral">&quot;This solver needs samples of at least 2 classes&quot;</span></div>
<div class="line"><span class="lineno"> 1183</span>                <span class="stringliteral">&quot; in the data, but the data contains only one&quot;</span></div>
<div class="line"><span class="lineno"> 1184</span>                <span class="stringliteral">&quot; class: %r&quot;</span></div>
<div class="line"><span class="lineno"> 1185</span>                % classes_[0]</div>
<div class="line"><span class="lineno"> 1186</span>            )</div>
<div class="line"><span class="lineno"> 1187</span> </div>
<div class="line"><span class="lineno"> 1188</span>        class_weight_ = compute_class_weight(class_weight, classes=classes_, y=y)</div>
<div class="line"><span class="lineno"> 1189</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1190</span>        class_weight_ = np.empty(0, dtype=np.float64)</div>
<div class="line"><span class="lineno"> 1191</span>        y_ind = y</div>
<div class="line"><span class="lineno"> 1192</span>    liblinear.set_verbosity_wrap(verbose)</div>
<div class="line"><span class="lineno"> 1193</span>    rnd = check_random_state(random_state)</div>
<div class="line"><span class="lineno"> 1194</span>    <span class="keywordflow">if</span> verbose:</div>
<div class="line"><span class="lineno"> 1195</span>        print(<span class="stringliteral">&quot;[LibLinear]&quot;</span>, end=<span class="stringliteral">&quot;&quot;</span>)</div>
<div class="line"><span class="lineno"> 1196</span> </div>
<div class="line"><span class="lineno"> 1197</span>    <span class="comment"># LinearSVC breaks when intercept_scaling is &lt;= 0</span></div>
<div class="line"><span class="lineno"> 1198</span>    bias = -1.0</div>
<div class="line"><span class="lineno"> 1199</span>    <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno"> 1200</span>        <span class="keywordflow">if</span> intercept_scaling &lt;= 0:</div>
<div class="line"><span class="lineno"> 1201</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1202</span>                <span class="stringliteral">&quot;Intercept scaling is %r but needs to be greater &quot;</span></div>
<div class="line"><span class="lineno"> 1203</span>                <span class="stringliteral">&quot;than 0. To disable fitting an intercept,&quot;</span></div>
<div class="line"><span class="lineno"> 1204</span>                <span class="stringliteral">&quot; set fit_intercept=False.&quot;</span> % intercept_scaling</div>
<div class="line"><span class="lineno"> 1205</span>            )</div>
<div class="line"><span class="lineno"> 1206</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1207</span>            bias = intercept_scaling</div>
<div class="line"><span class="lineno"> 1208</span> </div>
<div class="line"><span class="lineno"> 1209</span>    libsvm.set_verbosity_wrap(verbose)</div>
<div class="line"><span class="lineno"> 1210</span>    libsvm_sparse.set_verbosity_wrap(verbose)</div>
<div class="line"><span class="lineno"> 1211</span>    liblinear.set_verbosity_wrap(verbose)</div>
<div class="line"><span class="lineno"> 1212</span> </div>
<div class="line"><span class="lineno"> 1213</span>    <span class="comment"># Liblinear doesn&#39;t support 64bit sparse matrix indices yet</span></div>
<div class="line"><span class="lineno"> 1214</span>    <span class="keywordflow">if</span> sp.issparse(X):</div>
<div class="line"><span class="lineno"> 1215</span>        _check_large_sparse(X)</div>
<div class="line"><span class="lineno"> 1216</span> </div>
<div class="line"><span class="lineno"> 1217</span>    <span class="comment"># LibLinear wants targets as doubles, even for classification</span></div>
<div class="line"><span class="lineno"> 1218</span>    y_ind = np.asarray(y_ind, dtype=np.float64).ravel()</div>
<div class="line"><span class="lineno"> 1219</span>    y_ind = np.require(y_ind, requirements=<span class="stringliteral">&quot;W&quot;</span>)</div>
<div class="line"><span class="lineno"> 1220</span> </div>
<div class="line"><span class="lineno"> 1221</span>    sample_weight = _check_sample_weight(sample_weight, X, dtype=np.float64)</div>
<div class="line"><span class="lineno"> 1222</span> </div>
<div class="line"><span class="lineno"> 1223</span>    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)</div>
<div class="line"><span class="lineno"> 1224</span>    raw_coef_, n_iter_ = liblinear.train_wrap(</div>
<div class="line"><span class="lineno"> 1225</span>        X,</div>
<div class="line"><span class="lineno"> 1226</span>        y_ind,</div>
<div class="line"><span class="lineno"> 1227</span>        sp.isspmatrix(X),</div>
<div class="line"><span class="lineno"> 1228</span>        solver_type,</div>
<div class="line"><span class="lineno"> 1229</span>        tol,</div>
<div class="line"><span class="lineno"> 1230</span>        bias,</div>
<div class="line"><span class="lineno"> 1231</span>        C,</div>
<div class="line"><span class="lineno"> 1232</span>        class_weight_,</div>
<div class="line"><span class="lineno"> 1233</span>        max_iter,</div>
<div class="line"><span class="lineno"> 1234</span>        rnd.randint(np.iinfo(<span class="stringliteral">&quot;i&quot;</span>).max),</div>
<div class="line"><span class="lineno"> 1235</span>        epsilon,</div>
<div class="line"><span class="lineno"> 1236</span>        sample_weight,</div>
<div class="line"><span class="lineno"> 1237</span>    )</div>
<div class="line"><span class="lineno"> 1238</span>    <span class="comment"># Regarding rnd.randint(..) in the above signature:</span></div>
<div class="line"><span class="lineno"> 1239</span>    <span class="comment"># seed for srand in range [0..INT_MAX); due to limitations in Numpy</span></div>
<div class="line"><span class="lineno"> 1240</span>    <span class="comment"># on 32-bit platforms, we can&#39;t get to the UINT_MAX limit that</span></div>
<div class="line"><span class="lineno"> 1241</span>    <span class="comment"># srand supports</span></div>
<div class="line"><span class="lineno"> 1242</span>    n_iter_max = max(n_iter_)</div>
<div class="line"><span class="lineno"> 1243</span>    <span class="keywordflow">if</span> n_iter_max &gt;= max_iter:</div>
<div class="line"><span class="lineno"> 1244</span>        warnings.warn(</div>
<div class="line"><span class="lineno"> 1245</span>            <span class="stringliteral">&quot;Liblinear failed to converge, increase the number of iterations.&quot;</span>,</div>
<div class="line"><span class="lineno"> 1246</span>            ConvergenceWarning,</div>
<div class="line"><span class="lineno"> 1247</span>        )</div>
<div class="line"><span class="lineno"> 1248</span> </div>
<div class="line"><span class="lineno"> 1249</span>    <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno"> 1250</span>        coef_ = raw_coef_[:, :-1]</div>
<div class="line"><span class="lineno"> 1251</span>        intercept_ = intercept_scaling * raw_coef_[:, -1]</div>
<div class="line"><span class="lineno"> 1252</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1253</span>        coef_ = raw_coef_</div>
<div class="line"><span class="lineno"> 1254</span>        intercept_ = 0.0</div>
<div class="line"><span class="lineno"> 1255</span> </div>
<div class="line"><span class="lineno"> 1256</span>    <span class="keywordflow">return</span> coef_, intercept_, n_iter_</div>
</div><!-- fragment -->
</div>
</div>
<a id="a744f8c0d87a44ff5827c8e9d0b451acd" name="a744f8c0d87a44ff5827c8e9d0b451acd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a744f8c0d87a44ff5827c8e9d0b451acd">&#9670;&#160;</a></span>_get_liblinear_solver_type()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.svm._base._get_liblinear_solver_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>penalty</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dual</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Find the liblinear magic number for the solver.

This number depends on the values of the following attributes:
  - multi_class
  - penalty
  - loss
  - dual

The same number is also internally used by LibLinear to determine
which solver to use.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1011</span><span class="keyword">def </span>_get_liblinear_solver_type(multi_class, penalty, loss, dual):</div>
<div class="line"><span class="lineno"> 1012</span>    <span class="stringliteral">&quot;&quot;&quot;Find the liblinear magic number for the solver.</span></div>
<div class="line"><span class="lineno"> 1013</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1014</span><span class="stringliteral">    This number depends on the values of the following attributes:</span></div>
<div class="line"><span class="lineno"> 1015</span><span class="stringliteral">      - multi_class</span></div>
<div class="line"><span class="lineno"> 1016</span><span class="stringliteral">      - penalty</span></div>
<div class="line"><span class="lineno"> 1017</span><span class="stringliteral">      - loss</span></div>
<div class="line"><span class="lineno"> 1018</span><span class="stringliteral">      - dual</span></div>
<div class="line"><span class="lineno"> 1019</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1020</span><span class="stringliteral">    The same number is also internally used by LibLinear to determine</span></div>
<div class="line"><span class="lineno"> 1021</span><span class="stringliteral">    which solver to use.</span></div>
<div class="line"><span class="lineno"> 1022</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1023</span>    <span class="comment"># nested dicts containing level 1: available loss functions,</span></div>
<div class="line"><span class="lineno"> 1024</span>    <span class="comment"># level2: available penalties for the given loss function,</span></div>
<div class="line"><span class="lineno"> 1025</span>    <span class="comment"># level3: whether the dual solver is available for the specified</span></div>
<div class="line"><span class="lineno"> 1026</span>    <span class="comment"># combination of loss function and penalty</span></div>
<div class="line"><span class="lineno"> 1027</span>    _solver_type_dict = {</div>
<div class="line"><span class="lineno"> 1028</span>        <span class="stringliteral">&quot;logistic_regression&quot;</span>: {<span class="stringliteral">&quot;l1&quot;</span>: {<span class="keyword">False</span>: 6}, <span class="stringliteral">&quot;l2&quot;</span>: {<span class="keyword">False</span>: 0, <span class="keyword">True</span>: 7}},</div>
<div class="line"><span class="lineno"> 1029</span>        <span class="stringliteral">&quot;hinge&quot;</span>: {<span class="stringliteral">&quot;l2&quot;</span>: {<span class="keyword">True</span>: 3}},</div>
<div class="line"><span class="lineno"> 1030</span>        <span class="stringliteral">&quot;squared_hinge&quot;</span>: {<span class="stringliteral">&quot;l1&quot;</span>: {<span class="keyword">False</span>: 5}, <span class="stringliteral">&quot;l2&quot;</span>: {<span class="keyword">False</span>: 2, <span class="keyword">True</span>: 1}},</div>
<div class="line"><span class="lineno"> 1031</span>        <span class="stringliteral">&quot;epsilon_insensitive&quot;</span>: {<span class="stringliteral">&quot;l2&quot;</span>: {<span class="keyword">True</span>: 13}},</div>
<div class="line"><span class="lineno"> 1032</span>        <span class="stringliteral">&quot;squared_epsilon_insensitive&quot;</span>: {<span class="stringliteral">&quot;l2&quot;</span>: {<span class="keyword">False</span>: 11, <span class="keyword">True</span>: 12}},</div>
<div class="line"><span class="lineno"> 1033</span>        <span class="stringliteral">&quot;crammer_singer&quot;</span>: 4,</div>
<div class="line"><span class="lineno"> 1034</span>    }</div>
<div class="line"><span class="lineno"> 1035</span> </div>
<div class="line"><span class="lineno"> 1036</span>    <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;crammer_singer&quot;</span>:</div>
<div class="line"><span class="lineno"> 1037</span>        <span class="keywordflow">return</span> _solver_type_dict[multi_class]</div>
<div class="line"><span class="lineno"> 1038</span>    <span class="keywordflow">elif</span> multi_class != <span class="stringliteral">&quot;ovr&quot;</span>:</div>
<div class="line"><span class="lineno"> 1039</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1040</span>            <span class="stringliteral">&quot;`multi_class` must be one of `ovr`, `crammer_singer`, got %r&quot;</span> % multi_class</div>
<div class="line"><span class="lineno"> 1041</span>        )</div>
<div class="line"><span class="lineno"> 1042</span> </div>
<div class="line"><span class="lineno"> 1043</span>    _solver_pen = _solver_type_dict.get(loss, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno"> 1044</span>    <span class="keywordflow">if</span> _solver_pen <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1045</span>        error_string = <span class="stringliteral">&quot;loss=&#39;%s&#39; is not supported&quot;</span> % loss</div>
<div class="line"><span class="lineno"> 1046</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1047</span>        _solver_dual = _solver_pen.get(penalty, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno"> 1048</span>        <span class="keywordflow">if</span> _solver_dual <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1049</span>            error_string = (</div>
<div class="line"><span class="lineno"> 1050</span>                <span class="stringliteral">&quot;The combination of penalty=&#39;%s&#39; and loss=&#39;%s&#39; is not supported&quot;</span></div>
<div class="line"><span class="lineno"> 1051</span>                % (penalty, loss)</div>
<div class="line"><span class="lineno"> 1052</span>            )</div>
<div class="line"><span class="lineno"> 1053</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1054</span>            solver_num = _solver_dual.get(dual, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno"> 1055</span>            <span class="keywordflow">if</span> solver_num <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1056</span>                error_string = (</div>
<div class="line"><span class="lineno"> 1057</span>                    <span class="stringliteral">&quot;The combination of penalty=&#39;%s&#39; and &quot;</span></div>
<div class="line"><span class="lineno"> 1058</span>                    <span class="stringliteral">&quot;loss=&#39;%s&#39; are not supported when dual=%s&quot;</span> % (penalty, loss, dual)</div>
<div class="line"><span class="lineno"> 1059</span>                )</div>
<div class="line"><span class="lineno"> 1060</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1061</span>                <span class="keywordflow">return</span> solver_num</div>
<div class="line"><span class="lineno"> 1062</span>    <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1063</span>        <span class="stringliteral">&quot;Unsupported set of arguments: %s, Parameters: penalty=%r, loss=%r, dual=%r&quot;</span></div>
<div class="line"><span class="lineno"> 1064</span>        % (error_string, penalty, loss, dual)</div>
<div class="line"><span class="lineno"> 1065</span>    )</div>
<div class="line"><span class="lineno"> 1066</span> </div>
<div class="line"><span class="lineno"> 1067</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa06fd7aa93a7c1c101edce53218d69a9" name="aa06fd7aa93a7c1c101edce53218d69a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa06fd7aa93a7c1c101edce53218d69a9">&#9670;&#160;</a></span>_one_vs_one_coef()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.svm._base._one_vs_one_coef </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dual_coef</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_support</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>support_vectors</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate primal coefficients from dual coefficients
for the one-vs-one multi class LibSVM in the case
of a linear kernel.</pre> <div class="fragment"><div class="line"><span class="lineno">   33</span><span class="keyword">def </span>_one_vs_one_coef(dual_coef, n_support, support_vectors):</div>
<div class="line"><span class="lineno">   34</span>    <span class="stringliteral">&quot;&quot;&quot;Generate primal coefficients from dual coefficients</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">    for the one-vs-one multi class LibSVM in the case</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">    of a linear kernel.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   37</span> </div>
<div class="line"><span class="lineno">   38</span>    <span class="comment"># get 1vs1 weights for all n*(n-1) classifiers.</span></div>
<div class="line"><span class="lineno">   39</span>    <span class="comment"># this is somewhat messy.</span></div>
<div class="line"><span class="lineno">   40</span>    <span class="comment"># shape of dual_coef_ is nSV * (n_classes -1)</span></div>
<div class="line"><span class="lineno">   41</span>    <span class="comment"># see docs for details</span></div>
<div class="line"><span class="lineno">   42</span>    n_class = dual_coef.shape[0] + 1</div>
<div class="line"><span class="lineno">   43</span> </div>
<div class="line"><span class="lineno">   44</span>    <span class="comment"># XXX we could do preallocation of coef but</span></div>
<div class="line"><span class="lineno">   45</span>    <span class="comment"># would have to take care in the sparse case</span></div>
<div class="line"><span class="lineno">   46</span>    coef = []</div>
<div class="line"><span class="lineno">   47</span>    sv_locs = np.cumsum(np.hstack([[0], n_support]))</div>
<div class="line"><span class="lineno">   48</span>    <span class="keywordflow">for</span> class1 <span class="keywordflow">in</span> range(n_class):</div>
<div class="line"><span class="lineno">   49</span>        <span class="comment"># SVs for class1:</span></div>
<div class="line"><span class="lineno">   50</span>        sv1 = support_vectors[sv_locs[class1] : sv_locs[class1 + 1], :]</div>
<div class="line"><span class="lineno">   51</span>        <span class="keywordflow">for</span> class2 <span class="keywordflow">in</span> range(class1 + 1, n_class):</div>
<div class="line"><span class="lineno">   52</span>            <span class="comment"># SVs for class1:</span></div>
<div class="line"><span class="lineno">   53</span>            sv2 = support_vectors[sv_locs[class2] : sv_locs[class2 + 1], :]</div>
<div class="line"><span class="lineno">   54</span> </div>
<div class="line"><span class="lineno">   55</span>            <span class="comment"># dual coef for class1 SVs:</span></div>
<div class="line"><span class="lineno">   56</span>            alpha1 = dual_coef[class2 - 1, sv_locs[class1] : sv_locs[class1 + 1]]</div>
<div class="line"><span class="lineno">   57</span>            <span class="comment"># dual coef for class2 SVs:</span></div>
<div class="line"><span class="lineno">   58</span>            alpha2 = dual_coef[class1, sv_locs[class2] : sv_locs[class2 + 1]]</div>
<div class="line"><span class="lineno">   59</span>            <span class="comment"># build weight for class1 vs class2</span></div>
<div class="line"><span class="lineno">   60</span> </div>
<div class="line"><span class="lineno">   61</span>            coef.append(safe_sparse_dot(alpha1, sv1) + safe_sparse_dot(alpha2, sv2))</div>
<div class="line"><span class="lineno">   62</span>    <span class="keywordflow">return</span> coef</div>
<div class="line"><span class="lineno">   63</span> </div>
<div class="line"><span class="lineno">   64</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a0b80d7c5e324f912550f18fd5fa74608" name="a0b80d7c5e324f912550f18fd5fa74608"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b80d7c5e324f912550f18fd5fa74608">&#9670;&#160;</a></span>LIBSVM_IMPL</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.svm._base.LIBSVM_IMPL = [&quot;c_svc&quot;, &quot;nu_svc&quot;, &quot;one_class&quot;, &quot;epsilon_svr&quot;, &quot;nu_svr&quot;]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
