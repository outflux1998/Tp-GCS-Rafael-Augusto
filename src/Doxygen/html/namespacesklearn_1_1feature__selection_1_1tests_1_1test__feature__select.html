<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.feature_selection.tests.test_feature_select Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1feature__selection.html">feature_selection</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html">test_feature_select</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.feature_selection.tests.test_feature_select Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a1afff2202f504b2f302db8d234a14602" id="r_a1afff2202f504b2f302db8d234a14602"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a1afff2202f504b2f302db8d234a14602">test_f_oneway_vs_scipy_stats</a> ()</td></tr>
<tr class="memdesc:a1afff2202f504b2f302db8d234a14602"><td class="mdescLeft">&#160;</td><td class="mdescRight">Test the score functions.  <br /></td></tr>
<tr class="separator:a1afff2202f504b2f302db8d234a14602"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a192c256b7babe47a449da10790dcb5e0" id="r_a192c256b7babe47a449da10790dcb5e0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a192c256b7babe47a449da10790dcb5e0">test_f_oneway_ints</a> ()</td></tr>
<tr class="separator:a192c256b7babe47a449da10790dcb5e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6dda98ec6687e9d66f5622458b50c0f" id="r_ae6dda98ec6687e9d66f5622458b50c0f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#ae6dda98ec6687e9d66f5622458b50c0f">test_f_classif</a> ()</td></tr>
<tr class="separator:ae6dda98ec6687e9d66f5622458b50c0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18581b623e1c6ce8978b9f3c63b75465" id="r_a18581b623e1c6ce8978b9f3c63b75465"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a18581b623e1c6ce8978b9f3c63b75465">test_r_regression</a> (center)</td></tr>
<tr class="separator:a18581b623e1c6ce8978b9f3c63b75465"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae51b21df002a98c19b8a59710be2e889" id="r_ae51b21df002a98c19b8a59710be2e889"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#ae51b21df002a98c19b8a59710be2e889">test_f_regression</a> ()</td></tr>
<tr class="separator:ae51b21df002a98c19b8a59710be2e889"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5191107fea957d563aab83f5da333092" id="r_a5191107fea957d563aab83f5da333092"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a5191107fea957d563aab83f5da333092">test_f_regression_input_dtype</a> ()</td></tr>
<tr class="separator:a5191107fea957d563aab83f5da333092"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f393a2d61da596a89e4855f6659f946" id="r_a1f393a2d61da596a89e4855f6659f946"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a1f393a2d61da596a89e4855f6659f946">test_f_regression_center</a> ()</td></tr>
<tr class="separator:a1f393a2d61da596a89e4855f6659f946"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fbed6e23050bbc8f1355fb992ea8d19" id="r_a7fbed6e23050bbc8f1355fb992ea8d19"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a7fbed6e23050bbc8f1355fb992ea8d19">test_r_regression_force_finite</a> (X, y, expected_corr_coef, force_finite)</td></tr>
<tr class="separator:a7fbed6e23050bbc8f1355fb992ea8d19"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1cd76592d1674eaa6a603646a1c1c0b1" id="r_a1cd76592d1674eaa6a603646a1c1c0b1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a1cd76592d1674eaa6a603646a1c1c0b1">test_f_regression_corner_case</a> (X, y, expected_f_statistic, expected_p_values, force_finite)</td></tr>
<tr class="separator:a1cd76592d1674eaa6a603646a1c1c0b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f8b7d634489bfef0119f7c8c5ff3678" id="r_a1f8b7d634489bfef0119f7c8c5ff3678"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a1f8b7d634489bfef0119f7c8c5ff3678">test_f_classif_multi_class</a> ()</td></tr>
<tr class="separator:a1f8b7d634489bfef0119f7c8c5ff3678"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88c4cee60a1ac91549cbffa1f5ba9a86" id="r_a88c4cee60a1ac91549cbffa1f5ba9a86"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a88c4cee60a1ac91549cbffa1f5ba9a86">test_select_percentile_classif</a> ()</td></tr>
<tr class="separator:a88c4cee60a1ac91549cbffa1f5ba9a86"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1968567e414a32bda6058785da33e2f4" id="r_a1968567e414a32bda6058785da33e2f4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a1968567e414a32bda6058785da33e2f4">test_select_percentile_classif_sparse</a> ()</td></tr>
<tr class="separator:a1968567e414a32bda6058785da33e2f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaca5262182fd2ebe5c60a90cf27a54e8" id="r_aaca5262182fd2ebe5c60a90cf27a54e8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#aaca5262182fd2ebe5c60a90cf27a54e8">test_select_kbest_classif</a> ()</td></tr>
<tr class="memdesc:aaca5262182fd2ebe5c60a90cf27a54e8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Test univariate selection in classification settings.  <br /></td></tr>
<tr class="separator:aaca5262182fd2ebe5c60a90cf27a54e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86e6d5afedf3aaf65829f471cd77828b" id="r_a86e6d5afedf3aaf65829f471cd77828b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a86e6d5afedf3aaf65829f471cd77828b">test_select_kbest_all</a> ()</td></tr>
<tr class="separator:a86e6d5afedf3aaf65829f471cd77828b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a0868d97f4410d22b49ad700b97f8ee" id="r_a8a0868d97f4410d22b49ad700b97f8ee"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a8a0868d97f4410d22b49ad700b97f8ee">test_select_kbest_zero</a> (dtype_in)</td></tr>
<tr class="separator:a8a0868d97f4410d22b49ad700b97f8ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22614034700c590bd9f3993eb83bf020" id="r_a22614034700c590bd9f3993eb83bf020"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a22614034700c590bd9f3993eb83bf020">test_select_heuristics_classif</a> ()</td></tr>
<tr class="separator:a22614034700c590bd9f3993eb83bf020"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b5b4457a240c02a7b8b0b6983ff0f13" id="r_a3b5b4457a240c02a7b8b0b6983ff0f13"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a3b5b4457a240c02a7b8b0b6983ff0f13">assert_best_scores_kept</a> (score_filter)</td></tr>
<tr class="memdesc:a3b5b4457a240c02a7b8b0b6983ff0f13"><td class="mdescLeft">&#160;</td><td class="mdescRight">Test univariate selection in regression settings.  <br /></td></tr>
<tr class="separator:a3b5b4457a240c02a7b8b0b6983ff0f13"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab7575abfe119fbe9059044ff0b71d95" id="r_aab7575abfe119fbe9059044ff0b71d95"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#aab7575abfe119fbe9059044ff0b71d95">test_select_percentile_regression</a> ()</td></tr>
<tr class="separator:aab7575abfe119fbe9059044ff0b71d95"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18991433d6be7ea06b23c056dcc3ba2a" id="r_a18991433d6be7ea06b23c056dcc3ba2a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a18991433d6be7ea06b23c056dcc3ba2a">test_select_percentile_regression_full</a> ()</td></tr>
<tr class="separator:a18991433d6be7ea06b23c056dcc3ba2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b92cd7a388d88e9c36ca781a22186f7" id="r_a5b92cd7a388d88e9c36ca781a22186f7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a5b92cd7a388d88e9c36ca781a22186f7">test_select_kbest_regression</a> ()</td></tr>
<tr class="separator:a5b92cd7a388d88e9c36ca781a22186f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6c010a0eb0e6bb254a70b6d24dec11f" id="r_ac6c010a0eb0e6bb254a70b6d24dec11f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#ac6c010a0eb0e6bb254a70b6d24dec11f">test_select_heuristics_regression</a> ()</td></tr>
<tr class="separator:ac6c010a0eb0e6bb254a70b6d24dec11f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26e7c90f884f815a61efaaee962ac70f" id="r_a26e7c90f884f815a61efaaee962ac70f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a26e7c90f884f815a61efaaee962ac70f">test_boundary_case_ch2</a> ()</td></tr>
<tr class="separator:a26e7c90f884f815a61efaaee962ac70f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a705e9a13c822ea231c8899a5db5a0e74" id="r_a705e9a13c822ea231c8899a5db5a0e74"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a705e9a13c822ea231c8899a5db5a0e74">test_select_fdr_regression</a> (<a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, n_informative)</td></tr>
<tr class="separator:a705e9a13c822ea231c8899a5db5a0e74"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9131f57b799cc14f8aeb70bbe6d2f735" id="r_a9131f57b799cc14f8aeb70bbe6d2f735"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a9131f57b799cc14f8aeb70bbe6d2f735">test_select_fwe_regression</a> ()</td></tr>
<tr class="separator:a9131f57b799cc14f8aeb70bbe6d2f735"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af68d82d0959c21ba0dae32efe48e3728" id="r_af68d82d0959c21ba0dae32efe48e3728"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#af68d82d0959c21ba0dae32efe48e3728">test_selectkbest_tiebreaking</a> ()</td></tr>
<tr class="separator:af68d82d0959c21ba0dae32efe48e3728"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a452b4e0abef71f0d7edfeb41ecba25ff" id="r_a452b4e0abef71f0d7edfeb41ecba25ff"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a452b4e0abef71f0d7edfeb41ecba25ff">test_selectpercentile_tiebreaking</a> ()</td></tr>
<tr class="separator:a452b4e0abef71f0d7edfeb41ecba25ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac68982fada2a221801b307de54b3ba66" id="r_ac68982fada2a221801b307de54b3ba66"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#ac68982fada2a221801b307de54b3ba66">test_tied_pvalues</a> ()</td></tr>
<tr class="separator:ac68982fada2a221801b307de54b3ba66"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae31da764c47ed3db972bedc4fbcab61" id="r_aae31da764c47ed3db972bedc4fbcab61"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#aae31da764c47ed3db972bedc4fbcab61">test_scorefunc_multilabel</a> ()</td></tr>
<tr class="separator:aae31da764c47ed3db972bedc4fbcab61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9df067c1e957c1b110abc3d3a2f582e3" id="r_a9df067c1e957c1b110abc3d3a2f582e3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a9df067c1e957c1b110abc3d3a2f582e3">test_tied_scores</a> ()</td></tr>
<tr class="separator:a9df067c1e957c1b110abc3d3a2f582e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4994e613da0338a2f6db9b8d2028ceb5" id="r_a4994e613da0338a2f6db9b8d2028ceb5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a4994e613da0338a2f6db9b8d2028ceb5">test_nans</a> ()</td></tr>
<tr class="separator:a4994e613da0338a2f6db9b8d2028ceb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a913ce0c0a72b0efc38f5232499d0f0dc" id="r_a913ce0c0a72b0efc38f5232499d0f0dc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a913ce0c0a72b0efc38f5232499d0f0dc">test_invalid_k</a> ()</td></tr>
<tr class="separator:a913ce0c0a72b0efc38f5232499d0f0dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a376230dfbdf9e1a7706c0b767eaf1ae9" id="r_a376230dfbdf9e1a7706c0b767eaf1ae9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a376230dfbdf9e1a7706c0b767eaf1ae9">test_f_classif_constant_feature</a> ()</td></tr>
<tr class="separator:a376230dfbdf9e1a7706c0b767eaf1ae9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f8bc2a3c06aaf4c4b861e3ad8945251" id="r_a5f8bc2a3c06aaf4c4b861e3ad8945251"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a5f8bc2a3c06aaf4c4b861e3ad8945251">test_no_feature_selected</a> ()</td></tr>
<tr class="separator:a5f8bc2a3c06aaf4c4b861e3ad8945251"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29c178c4ce4290fed8388f985345f145" id="r_a29c178c4ce4290fed8388f985345f145"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#a29c178c4ce4290fed8388f985345f145">test_mutual_info_classif</a> ()</td></tr>
<tr class="separator:a29c178c4ce4290fed8388f985345f145"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1f32b9254e087d9dcf2df8edfcfc5cc" id="r_ae1f32b9254e087d9dcf2df8edfcfc5cc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1tests_1_1test__feature__select.html#ae1f32b9254e087d9dcf2df8edfcfc5cc">test_mutual_info_regression</a> ()</td></tr>
<tr class="separator:ae1f32b9254e087d9dcf2df8edfcfc5cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Todo: cross-check the F-value with stats model
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a3b5b4457a240c02a7b8b0b6983ff0f13" name="a3b5b4457a240c02a7b8b0b6983ff0f13"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3b5b4457a240c02a7b8b0b6983ff0f13">&#9670;&#160;</a></span>assert_best_scores_kept()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.assert_best_scores_kept </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>score_filter</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Test univariate selection in regression settings. </p>
<div class="fragment"><div class="line"><span class="lineno">  509</span><span class="keyword">def </span>assert_best_scores_kept(score_filter):</div>
<div class="line"><span class="lineno">  510</span>    scores = score_filter.scores_</div>
<div class="line"><span class="lineno">  511</span>    support = score_filter.get_support()</div>
<div class="line"><span class="lineno">  512</span>    assert_allclose(np.sort(scores[support]), np.sort(scores)[-support.sum() :])</div>
<div class="line"><span class="lineno">  513</span> </div>
<div class="line"><span class="lineno">  514</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a26e7c90f884f815a61efaaee962ac70f" name="a26e7c90f884f815a61efaaee962ac70f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a26e7c90f884f815a61efaaee962ac70f">&#9670;&#160;</a></span>test_boundary_case_ch2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_boundary_case_ch2 </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  623</span><span class="keyword">def </span>test_boundary_case_ch2():</div>
<div class="line"><span class="lineno">  624</span>    <span class="comment"># Test boundary case, and always aim to select 1 feature.</span></div>
<div class="line"><span class="lineno">  625</span>    X = np.array([[10, 20], [20, 20], [20, 30]])</div>
<div class="line"><span class="lineno">  626</span>    y = np.array([[1], [0], [0]])</div>
<div class="line"><span class="lineno">  627</span>    scores, pvalues = chi2(X, y)</div>
<div class="line"><span class="lineno">  628</span>    assert_array_almost_equal(scores, np.array([4.0, 0.71428571]))</div>
<div class="line"><span class="lineno">  629</span>    assert_array_almost_equal(pvalues, np.array([0.04550026, 0.39802472]))</div>
<div class="line"><span class="lineno">  630</span> </div>
<div class="line"><span class="lineno">  631</span>    filter_fdr = SelectFdr(chi2, alpha=0.1)</div>
<div class="line"><span class="lineno">  632</span>    filter_fdr.fit(X, y)</div>
<div class="line"><span class="lineno">  633</span>    support_fdr = filter_fdr.get_support()</div>
<div class="line"><span class="lineno">  634</span>    assert_array_equal(support_fdr, np.array([<span class="keyword">True</span>, <span class="keyword">False</span>]))</div>
<div class="line"><span class="lineno">  635</span> </div>
<div class="line"><span class="lineno">  636</span>    filter_kbest = SelectKBest(chi2, k=1)</div>
<div class="line"><span class="lineno">  637</span>    filter_kbest.fit(X, y)</div>
<div class="line"><span class="lineno">  638</span>    support_kbest = filter_kbest.get_support()</div>
<div class="line"><span class="lineno">  639</span>    assert_array_equal(support_kbest, np.array([<span class="keyword">True</span>, <span class="keyword">False</span>]))</div>
<div class="line"><span class="lineno">  640</span> </div>
<div class="line"><span class="lineno">  641</span>    filter_percentile = SelectPercentile(chi2, percentile=50)</div>
<div class="line"><span class="lineno">  642</span>    filter_percentile.fit(X, y)</div>
<div class="line"><span class="lineno">  643</span>    support_percentile = filter_percentile.get_support()</div>
<div class="line"><span class="lineno">  644</span>    assert_array_equal(support_percentile, np.array([<span class="keyword">True</span>, <span class="keyword">False</span>]))</div>
<div class="line"><span class="lineno">  645</span> </div>
<div class="line"><span class="lineno">  646</span>    filter_fpr = SelectFpr(chi2, alpha=0.1)</div>
<div class="line"><span class="lineno">  647</span>    filter_fpr.fit(X, y)</div>
<div class="line"><span class="lineno">  648</span>    support_fpr = filter_fpr.get_support()</div>
<div class="line"><span class="lineno">  649</span>    assert_array_equal(support_fpr, np.array([<span class="keyword">True</span>, <span class="keyword">False</span>]))</div>
<div class="line"><span class="lineno">  650</span> </div>
<div class="line"><span class="lineno">  651</span>    filter_fwe = SelectFwe(chi2, alpha=0.1)</div>
<div class="line"><span class="lineno">  652</span>    filter_fwe.fit(X, y)</div>
<div class="line"><span class="lineno">  653</span>    support_fwe = filter_fwe.get_support()</div>
<div class="line"><span class="lineno">  654</span>    assert_array_equal(support_fwe, np.array([<span class="keyword">True</span>, <span class="keyword">False</span>]))</div>
<div class="line"><span class="lineno">  655</span> </div>
<div class="line"><span class="lineno">  656</span> </div>
<div class="line"><span class="lineno">  657</span><span class="preprocessor">@pytest.mark.parametrize(&quot;alpha&quot;, [0.001, 0.01, 0.1])</span></div>
<div class="line"><span class="lineno">  658</span><span class="preprocessor">@pytest.mark.parametrize(&quot;n_informative&quot;, [1, 5, 10])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ae6dda98ec6687e9d66f5622458b50c0f" name="ae6dda98ec6687e9d66f5622458b50c0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6dda98ec6687e9d66f5622458b50c0f">&#9670;&#160;</a></span>test_f_classif()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_f_classif </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   65</span><span class="keyword">def </span>test_f_classif():</div>
<div class="line"><span class="lineno">   66</span>    <span class="comment"># Test whether the F test yields meaningful results</span></div>
<div class="line"><span class="lineno">   67</span>    <span class="comment"># on a simple simulated classification problem</span></div>
<div class="line"><span class="lineno">   68</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">   69</span>        n_samples=200,</div>
<div class="line"><span class="lineno">   70</span>        n_features=20,</div>
<div class="line"><span class="lineno">   71</span>        n_informative=3,</div>
<div class="line"><span class="lineno">   72</span>        n_redundant=2,</div>
<div class="line"><span class="lineno">   73</span>        n_repeated=0,</div>
<div class="line"><span class="lineno">   74</span>        n_classes=8,</div>
<div class="line"><span class="lineno">   75</span>        n_clusters_per_class=1,</div>
<div class="line"><span class="lineno">   76</span>        flip_y=0.0,</div>
<div class="line"><span class="lineno">   77</span>        class_sep=10,</div>
<div class="line"><span class="lineno">   78</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">   79</span>        random_state=0,</div>
<div class="line"><span class="lineno">   80</span>    )</div>
<div class="line"><span class="lineno">   81</span> </div>
<div class="line"><span class="lineno">   82</span>    F, pv = f_classif(X, y)</div>
<div class="line"><span class="lineno">   83</span>    F_sparse, pv_sparse = f_classif(sparse.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">   84</span>    <span class="keyword">assert</span> (F &gt; 0).all()</div>
<div class="line"><span class="lineno">   85</span>    <span class="keyword">assert</span> (pv &gt; 0).all()</div>
<div class="line"><span class="lineno">   86</span>    <span class="keyword">assert</span> (pv &lt; 1).all()</div>
<div class="line"><span class="lineno">   87</span>    <span class="keyword">assert</span> (pv[:5] &lt; 0.05).all()</div>
<div class="line"><span class="lineno">   88</span>    <span class="keyword">assert</span> (pv[5:] &gt; 1.0e-4).all()</div>
<div class="line"><span class="lineno">   89</span>    assert_array_almost_equal(F_sparse, F)</div>
<div class="line"><span class="lineno">   90</span>    assert_array_almost_equal(pv_sparse, pv)</div>
<div class="line"><span class="lineno">   91</span> </div>
<div class="line"><span class="lineno">   92</span> </div>
<div class="line"><span class="lineno">   93</span><span class="preprocessor">@pytest.mark.parametrize(&quot;center&quot;, [True, False])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a376230dfbdf9e1a7706c0b767eaf1ae9" name="a376230dfbdf9e1a7706c0b767eaf1ae9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a376230dfbdf9e1a7706c0b767eaf1ae9">&#9670;&#160;</a></span>test_f_classif_constant_feature()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_f_classif_constant_feature </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  835</span><span class="keyword">def </span>test_f_classif_constant_feature():</div>
<div class="line"><span class="lineno">  836</span>    <span class="comment"># Test that f_classif warns if a feature is constant throughout.</span></div>
<div class="line"><span class="lineno">  837</span> </div>
<div class="line"><span class="lineno">  838</span>    X, y = make_classification(n_samples=10, n_features=5)</div>
<div class="line"><span class="lineno">  839</span>    X[:, 0] = 2.0</div>
<div class="line"><span class="lineno">  840</span>    <span class="keyword">with</span> pytest.warns(UserWarning):</div>
<div class="line"><span class="lineno">  841</span>        f_classif(X, y)</div>
<div class="line"><span class="lineno">  842</span> </div>
<div class="line"><span class="lineno">  843</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1f8b7d634489bfef0119f7c8c5ff3678" name="a1f8b7d634489bfef0119f7c8c5ff3678"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f8b7d634489bfef0119f7c8c5ff3678">&#9670;&#160;</a></span>test_f_classif_multi_class()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_f_classif_multi_class </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  301</span><span class="keyword">def </span>test_f_classif_multi_class():</div>
<div class="line"><span class="lineno">  302</span>    <span class="comment"># Test whether the F test yields meaningful results</span></div>
<div class="line"><span class="lineno">  303</span>    <span class="comment"># on a simple simulated classification problem</span></div>
<div class="line"><span class="lineno">  304</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  305</span>        n_samples=200,</div>
<div class="line"><span class="lineno">  306</span>        n_features=20,</div>
<div class="line"><span class="lineno">  307</span>        n_informative=3,</div>
<div class="line"><span class="lineno">  308</span>        n_redundant=2,</div>
<div class="line"><span class="lineno">  309</span>        n_repeated=0,</div>
<div class="line"><span class="lineno">  310</span>        n_classes=8,</div>
<div class="line"><span class="lineno">  311</span>        n_clusters_per_class=1,</div>
<div class="line"><span class="lineno">  312</span>        flip_y=0.0,</div>
<div class="line"><span class="lineno">  313</span>        class_sep=10,</div>
<div class="line"><span class="lineno">  314</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  315</span>        random_state=0,</div>
<div class="line"><span class="lineno">  316</span>    )</div>
<div class="line"><span class="lineno">  317</span> </div>
<div class="line"><span class="lineno">  318</span>    F, pv = f_classif(X, y)</div>
<div class="line"><span class="lineno">  319</span>    <span class="keyword">assert</span> (F &gt; 0).all()</div>
<div class="line"><span class="lineno">  320</span>    <span class="keyword">assert</span> (pv &gt; 0).all()</div>
<div class="line"><span class="lineno">  321</span>    <span class="keyword">assert</span> (pv &lt; 1).all()</div>
<div class="line"><span class="lineno">  322</span>    <span class="keyword">assert</span> (pv[:5] &lt; 0.05).all()</div>
<div class="line"><span class="lineno">  323</span>    <span class="keyword">assert</span> (pv[5:] &gt; 1.0e-4).all()</div>
<div class="line"><span class="lineno">  324</span> </div>
<div class="line"><span class="lineno">  325</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a192c256b7babe47a449da10790dcb5e0" name="a192c256b7babe47a449da10790dcb5e0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a192c256b7babe47a449da10790dcb5e0">&#9670;&#160;</a></span>test_f_oneway_ints()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_f_oneway_ints </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   51</span><span class="keyword">def </span>test_f_oneway_ints():</div>
<div class="line"><span class="lineno">   52</span>    <span class="comment"># Smoke test f_oneway on integers: that it does raise casting errors</span></div>
<div class="line"><span class="lineno">   53</span>    <span class="comment"># with recent numpys</span></div>
<div class="line"><span class="lineno">   54</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">   55</span>    X = rng.randint(10, size=(10, 10))</div>
<div class="line"><span class="lineno">   56</span>    y = np.arange(10)</div>
<div class="line"><span class="lineno">   57</span>    fint, pint = f_oneway(X, y)</div>
<div class="line"><span class="lineno">   58</span> </div>
<div class="line"><span class="lineno">   59</span>    <span class="comment"># test that is gives the same result as with float</span></div>
<div class="line"><span class="lineno">   60</span>    f, p = f_oneway(X.astype(float), y)</div>
<div class="line"><span class="lineno">   61</span>    assert_array_almost_equal(f, fint, decimal=4)</div>
<div class="line"><span class="lineno">   62</span>    assert_array_almost_equal(p, pint, decimal=4)</div>
<div class="line"><span class="lineno">   63</span> </div>
<div class="line"><span class="lineno">   64</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1afff2202f504b2f302db8d234a14602" name="a1afff2202f504b2f302db8d234a14602"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1afff2202f504b2f302db8d234a14602">&#9670;&#160;</a></span>test_f_oneway_vs_scipy_stats()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_f_oneway_vs_scipy_stats </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Test the score functions. </p>
<div class="fragment"><div class="line"><span class="lineno">   40</span><span class="keyword">def </span>test_f_oneway_vs_scipy_stats():</div>
<div class="line"><span class="lineno">   41</span>    <span class="comment"># Test that our f_oneway gives the same result as scipy.stats</span></div>
<div class="line"><span class="lineno">   42</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">   43</span>    X1 = rng.randn(10, 3)</div>
<div class="line"><span class="lineno">   44</span>    X2 = 1 + rng.randn(10, 3)</div>
<div class="line"><span class="lineno">   45</span>    f, pv = stats.f_oneway(X1, X2)</div>
<div class="line"><span class="lineno">   46</span>    f2, pv2 = f_oneway(X1, X2)</div>
<div class="line"><span class="lineno">   47</span>    <span class="keyword">assert</span> np.allclose(f, f2)</div>
<div class="line"><span class="lineno">   48</span>    <span class="keyword">assert</span> np.allclose(pv, pv2)</div>
<div class="line"><span class="lineno">   49</span> </div>
<div class="line"><span class="lineno">   50</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae51b21df002a98c19b8a59710be2e889" name="ae51b21df002a98c19b8a59710be2e889"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae51b21df002a98c19b8a59710be2e889">&#9670;&#160;</a></span>test_f_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_f_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  115</span><span class="keyword">def </span>test_f_regression():</div>
<div class="line"><span class="lineno">  116</span>    <span class="comment"># Test whether the F test yields meaningful results</span></div>
<div class="line"><span class="lineno">  117</span>    <span class="comment"># on a simple simulated regression problem</span></div>
<div class="line"><span class="lineno">  118</span>    X, y = make_regression(</div>
<div class="line"><span class="lineno">  119</span>        n_samples=200, n_features=20, n_informative=5, shuffle=<span class="keyword">False</span>, random_state=0</div>
<div class="line"><span class="lineno">  120</span>    )</div>
<div class="line"><span class="lineno">  121</span> </div>
<div class="line"><span class="lineno">  122</span>    F, pv = f_regression(X, y)</div>
<div class="line"><span class="lineno">  123</span>    <span class="keyword">assert</span> (F &gt; 0).all()</div>
<div class="line"><span class="lineno">  124</span>    <span class="keyword">assert</span> (pv &gt; 0).all()</div>
<div class="line"><span class="lineno">  125</span>    <span class="keyword">assert</span> (pv &lt; 1).all()</div>
<div class="line"><span class="lineno">  126</span>    <span class="keyword">assert</span> (pv[:5] &lt; 0.05).all()</div>
<div class="line"><span class="lineno">  127</span>    <span class="keyword">assert</span> (pv[5:] &gt; 1.0e-4).all()</div>
<div class="line"><span class="lineno">  128</span> </div>
<div class="line"><span class="lineno">  129</span>    <span class="comment"># with centering, compare with sparse</span></div>
<div class="line"><span class="lineno">  130</span>    F, pv = f_regression(X, y, center=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  131</span>    F_sparse, pv_sparse = f_regression(sparse.csr_matrix(X), y, center=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  132</span>    assert_allclose(F_sparse, F)</div>
<div class="line"><span class="lineno">  133</span>    assert_allclose(pv_sparse, pv)</div>
<div class="line"><span class="lineno">  134</span> </div>
<div class="line"><span class="lineno">  135</span>    <span class="comment"># again without centering, compare with sparse</span></div>
<div class="line"><span class="lineno">  136</span>    F, pv = f_regression(X, y, center=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  137</span>    F_sparse, pv_sparse = f_regression(sparse.csr_matrix(X), y, center=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  138</span>    assert_allclose(F_sparse, F)</div>
<div class="line"><span class="lineno">  139</span>    assert_allclose(pv_sparse, pv)</div>
<div class="line"><span class="lineno">  140</span> </div>
<div class="line"><span class="lineno">  141</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1f393a2d61da596a89e4855f6659f946" name="a1f393a2d61da596a89e4855f6659f946"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f393a2d61da596a89e4855f6659f946">&#9670;&#160;</a></span>test_f_regression_center()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_f_regression_center </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  155</span><span class="keyword">def </span>test_f_regression_center():</div>
<div class="line"><span class="lineno">  156</span>    <span class="comment"># Test whether f_regression preserves dof according to &#39;center&#39; argument</span></div>
<div class="line"><span class="lineno">  157</span>    <span class="comment"># We use two centered variates so we have a simple relationship between</span></div>
<div class="line"><span class="lineno">  158</span>    <span class="comment"># F-score with variates centering and F-score without variates centering.</span></div>
<div class="line"><span class="lineno">  159</span>    <span class="comment"># Create toy example</span></div>
<div class="line"><span class="lineno">  160</span>    X = np.arange(-5, 6).reshape(-1, 1)  <span class="comment"># X has zero mean</span></div>
<div class="line"><span class="lineno">  161</span>    n_samples = X.size</div>
<div class="line"><span class="lineno">  162</span>    Y = np.ones(n_samples)</div>
<div class="line"><span class="lineno">  163</span>    Y[::2] *= -1.0</div>
<div class="line"><span class="lineno">  164</span>    Y[0] = 0.0  <span class="comment"># have Y mean being null</span></div>
<div class="line"><span class="lineno">  165</span> </div>
<div class="line"><span class="lineno">  166</span>    F1, _ = f_regression(X, Y, center=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  167</span>    F2, _ = f_regression(X, Y, center=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  168</span>    assert_allclose(F1 * (n_samples - 1.0) / (n_samples - 2.0), F2)</div>
<div class="line"><span class="lineno">  169</span>    assert_almost_equal(F2[0], 0.232558139)  <span class="comment"># value from statsmodels OLS</span></div>
<div class="line"><span class="lineno">  170</span> </div>
<div class="line"><span class="lineno">  171</span> </div>
<div class="line"><span class="lineno">  172</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  173</span>    <span class="stringliteral">&quot;X, y, expected_corr_coef, force_finite&quot;</span>,</div>
<div class="line"><span class="lineno">  174</span>    [</div>
<div class="line"><span class="lineno">  175</span>        (</div>
<div class="line"><span class="lineno">  176</span>            <span class="comment"># A feature in X is constant - forcing finite</span></div>
<div class="line"><span class="lineno">  177</span>            np.array([[2, 1], [2, 0], [2, 10], [2, 4]]),</div>
<div class="line"><span class="lineno">  178</span>            np.array([0, 1, 1, 0]),</div>
<div class="line"><span class="lineno">  179</span>            np.array([0.0, 0.32075]),</div>
<div class="line"><span class="lineno">  180</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  181</span>        ),</div>
<div class="line"><span class="lineno">  182</span>        (</div>
<div class="line"><span class="lineno">  183</span>            <span class="comment"># The target y is constant - forcing finite</span></div>
<div class="line"><span class="lineno">  184</span>            np.array([[5, 1], [3, 0], [2, 10], [8, 4]]),</div>
<div class="line"><span class="lineno">  185</span>            np.array([0, 0, 0, 0]),</div>
<div class="line"><span class="lineno">  186</span>            np.array([0.0, 0.0]),</div>
<div class="line"><span class="lineno">  187</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  188</span>        ),</div>
<div class="line"><span class="lineno">  189</span>        (</div>
<div class="line"><span class="lineno">  190</span>            <span class="comment"># A feature in X is constant - not forcing finite</span></div>
<div class="line"><span class="lineno">  191</span>            np.array([[2, 1], [2, 0], [2, 10], [2, 4]]),</div>
<div class="line"><span class="lineno">  192</span>            np.array([0, 1, 1, 0]),</div>
<div class="line"><span class="lineno">  193</span>            np.array([np.nan, 0.32075]),</div>
<div class="line"><span class="lineno">  194</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  195</span>        ),</div>
<div class="line"><span class="lineno">  196</span>        (</div>
<div class="line"><span class="lineno">  197</span>            <span class="comment"># The target y is constant - not forcing finite</span></div>
<div class="line"><span class="lineno">  198</span>            np.array([[5, 1], [3, 0], [2, 10], [8, 4]]),</div>
<div class="line"><span class="lineno">  199</span>            np.array([0, 0, 0, 0]),</div>
<div class="line"><span class="lineno">  200</span>            np.array([np.nan, np.nan]),</div>
<div class="line"><span class="lineno">  201</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  202</span>        ),</div>
<div class="line"><span class="lineno">  203</span>    ],</div>
<div class="line"><span class="lineno">  204</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a1cd76592d1674eaa6a603646a1c1c0b1" name="a1cd76592d1674eaa6a603646a1c1c0b1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1cd76592d1674eaa6a603646a1c1c0b1">&#9670;&#160;</a></span>test_f_regression_corner_case()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_f_regression_corner_case </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>expected_f_statistic</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>expected_p_values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>force_finite</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check the behaviour of `force_finite` for some corner cases with `f_regression`.

Non-regression test for:
https://github.com/scikit-learn/scikit-learn/issues/15672
</pre> <div class="fragment"><div class="line"><span class="lineno">  288</span>):</div>
<div class="line"><span class="lineno">  289</span>    <span class="stringliteral">&quot;&quot;&quot;Check the behaviour of `force_finite` for some corner cases with `f_regression`.</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">    Non-regression test for:</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">    https://github.com/scikit-learn/scikit-learn/issues/15672</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  294</span>    <span class="keyword">with</span> warnings.catch_warnings():</div>
<div class="line"><span class="lineno">  295</span>        warnings.simplefilter(<span class="stringliteral">&quot;error&quot;</span>, RuntimeWarning)</div>
<div class="line"><span class="lineno">  296</span>        f_statistic, p_values = f_regression(X, y, force_finite=force_finite)</div>
<div class="line"><span class="lineno">  297</span>    np.testing.assert_array_almost_equal(f_statistic, expected_f_statistic)</div>
<div class="line"><span class="lineno">  298</span>    np.testing.assert_array_almost_equal(p_values, expected_p_values)</div>
<div class="line"><span class="lineno">  299</span> </div>
<div class="line"><span class="lineno">  300</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5191107fea957d563aab83f5da333092" name="a5191107fea957d563aab83f5da333092"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5191107fea957d563aab83f5da333092">&#9670;&#160;</a></span>test_f_regression_input_dtype()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_f_regression_input_dtype </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  142</span><span class="keyword">def </span>test_f_regression_input_dtype():</div>
<div class="line"><span class="lineno">  143</span>    <span class="comment"># Test whether f_regression returns the same value</span></div>
<div class="line"><span class="lineno">  144</span>    <span class="comment"># for any numeric data_type</span></div>
<div class="line"><span class="lineno">  145</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  146</span>    X = rng.rand(10, 20)</div>
<div class="line"><span class="lineno">  147</span>    y = np.arange(10).astype(int)</div>
<div class="line"><span class="lineno">  148</span> </div>
<div class="line"><span class="lineno">  149</span>    F1, pv1 = f_regression(X, y)</div>
<div class="line"><span class="lineno">  150</span>    F2, pv2 = f_regression(X, y.astype(float))</div>
<div class="line"><span class="lineno">  151</span>    assert_allclose(F1, F2, 5)</div>
<div class="line"><span class="lineno">  152</span>    assert_allclose(pv1, pv2, 5)</div>
<div class="line"><span class="lineno">  153</span> </div>
<div class="line"><span class="lineno">  154</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a913ce0c0a72b0efc38f5232499d0f0dc" name="a913ce0c0a72b0efc38f5232499d0f0dc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a913ce0c0a72b0efc38f5232499d0f0dc">&#9670;&#160;</a></span>test_invalid_k()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_invalid_k </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  825</span><span class="keyword">def </span>test_invalid_k():</div>
<div class="line"><span class="lineno">  826</span>    X = [[0, 1, 0], [0, -1, -1], [0, 0.5, 0.5]]</div>
<div class="line"><span class="lineno">  827</span>    y = [1, 0, 1]</div>
<div class="line"><span class="lineno">  828</span> </div>
<div class="line"><span class="lineno">  829</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  830</span>        SelectKBest(k=4).fit(X, y)</div>
<div class="line"><span class="lineno">  831</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  832</span>        GenericUnivariateSelect(mode=<span class="stringliteral">&quot;k_best&quot;</span>, param=4).fit(X, y)</div>
<div class="line"><span class="lineno">  833</span> </div>
<div class="line"><span class="lineno">  834</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a29c178c4ce4290fed8388f985345f145" name="a29c178c4ce4290fed8388f985345f145"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a29c178c4ce4290fed8388f985345f145">&#9670;&#160;</a></span>test_mutual_info_classif()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_mutual_info_classif </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  865</span><span class="keyword">def </span>test_mutual_info_classif():</div>
<div class="line"><span class="lineno">  866</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  867</span>        n_samples=100,</div>
<div class="line"><span class="lineno">  868</span>        n_features=5,</div>
<div class="line"><span class="lineno">  869</span>        n_informative=1,</div>
<div class="line"><span class="lineno">  870</span>        n_redundant=1,</div>
<div class="line"><span class="lineno">  871</span>        n_repeated=0,</div>
<div class="line"><span class="lineno">  872</span>        n_classes=2,</div>
<div class="line"><span class="lineno">  873</span>        n_clusters_per_class=1,</div>
<div class="line"><span class="lineno">  874</span>        flip_y=0.0,</div>
<div class="line"><span class="lineno">  875</span>        class_sep=10,</div>
<div class="line"><span class="lineno">  876</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  877</span>        random_state=0,</div>
<div class="line"><span class="lineno">  878</span>    )</div>
<div class="line"><span class="lineno">  879</span> </div>
<div class="line"><span class="lineno">  880</span>    <span class="comment"># Test in KBest mode.</span></div>
<div class="line"><span class="lineno">  881</span>    univariate_filter = SelectKBest(mutual_info_classif, k=2)</div>
<div class="line"><span class="lineno">  882</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  883</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  884</span>        GenericUnivariateSelect(mutual_info_classif, mode=<span class="stringliteral">&quot;k_best&quot;</span>, param=2)</div>
<div class="line"><span class="lineno">  885</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  886</span>        .transform(X)</div>
<div class="line"><span class="lineno">  887</span>    )</div>
<div class="line"><span class="lineno">  888</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  889</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  890</span>    gtruth = np.zeros(5)</div>
<div class="line"><span class="lineno">  891</span>    gtruth[:2] = 1</div>
<div class="line"><span class="lineno">  892</span>    assert_array_equal(support, gtruth)</div>
<div class="line"><span class="lineno">  893</span> </div>
<div class="line"><span class="lineno">  894</span>    <span class="comment"># Test in Percentile mode.</span></div>
<div class="line"><span class="lineno">  895</span>    univariate_filter = SelectPercentile(mutual_info_classif, percentile=40)</div>
<div class="line"><span class="lineno">  896</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  897</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  898</span>        GenericUnivariateSelect(mutual_info_classif, mode=<span class="stringliteral">&quot;percentile&quot;</span>, param=40)</div>
<div class="line"><span class="lineno">  899</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  900</span>        .transform(X)</div>
<div class="line"><span class="lineno">  901</span>    )</div>
<div class="line"><span class="lineno">  902</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  903</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  904</span>    gtruth = np.zeros(5)</div>
<div class="line"><span class="lineno">  905</span>    gtruth[:2] = 1</div>
<div class="line"><span class="lineno">  906</span>    assert_array_equal(support, gtruth)</div>
<div class="line"><span class="lineno">  907</span> </div>
<div class="line"><span class="lineno">  908</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae1f32b9254e087d9dcf2df8edfcfc5cc" name="ae1f32b9254e087d9dcf2df8edfcfc5cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1f32b9254e087d9dcf2df8edfcfc5cc">&#9670;&#160;</a></span>test_mutual_info_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_mutual_info_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  909</span><span class="keyword">def </span>test_mutual_info_regression():</div>
<div class="line"><span class="lineno">  910</span>    X, y = make_regression(</div>
<div class="line"><span class="lineno">  911</span>        n_samples=100,</div>
<div class="line"><span class="lineno">  912</span>        n_features=10,</div>
<div class="line"><span class="lineno">  913</span>        n_informative=2,</div>
<div class="line"><span class="lineno">  914</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  915</span>        random_state=0,</div>
<div class="line"><span class="lineno">  916</span>        noise=10,</div>
<div class="line"><span class="lineno">  917</span>    )</div>
<div class="line"><span class="lineno">  918</span> </div>
<div class="line"><span class="lineno">  919</span>    <span class="comment"># Test in KBest mode.</span></div>
<div class="line"><span class="lineno">  920</span>    univariate_filter = SelectKBest(mutual_info_regression, k=2)</div>
<div class="line"><span class="lineno">  921</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  922</span>    assert_best_scores_kept(univariate_filter)</div>
<div class="line"><span class="lineno">  923</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  924</span>        GenericUnivariateSelect(mutual_info_regression, mode=<span class="stringliteral">&quot;k_best&quot;</span>, param=2)</div>
<div class="line"><span class="lineno">  925</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  926</span>        .transform(X)</div>
<div class="line"><span class="lineno">  927</span>    )</div>
<div class="line"><span class="lineno">  928</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  929</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  930</span>    gtruth = np.zeros(10)</div>
<div class="line"><span class="lineno">  931</span>    gtruth[:2] = 1</div>
<div class="line"><span class="lineno">  932</span>    assert_array_equal(support, gtruth)</div>
<div class="line"><span class="lineno">  933</span> </div>
<div class="line"><span class="lineno">  934</span>    <span class="comment"># Test in Percentile mode.</span></div>
<div class="line"><span class="lineno">  935</span>    univariate_filter = SelectPercentile(mutual_info_regression, percentile=20)</div>
<div class="line"><span class="lineno">  936</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  937</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  938</span>        GenericUnivariateSelect(mutual_info_regression, mode=<span class="stringliteral">&quot;percentile&quot;</span>, param=20)</div>
<div class="line"><span class="lineno">  939</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  940</span>        .transform(X)</div>
<div class="line"><span class="lineno">  941</span>    )</div>
<div class="line"><span class="lineno">  942</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  943</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  944</span>    gtruth = np.zeros(10)</div>
<div class="line"><span class="lineno">  945</span>    gtruth[:2] = 1</div>
<div class="line"><span class="lineno">  946</span>    assert_array_equal(support, gtruth)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a4994e613da0338a2f6db9b8d2028ceb5" name="a4994e613da0338a2f6db9b8d2028ceb5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4994e613da0338a2f6db9b8d2028ceb5">&#9670;&#160;</a></span>test_nans()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_nans </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  810</span><span class="keyword">def </span>test_nans():</div>
<div class="line"><span class="lineno">  811</span>    <span class="comment"># Assert that SelectKBest and SelectPercentile can handle NaNs.</span></div>
<div class="line"><span class="lineno">  812</span>    <span class="comment"># First feature has zero variance to confuse f_classif (ANOVA) and</span></div>
<div class="line"><span class="lineno">  813</span>    <span class="comment"># make it return a NaN.</span></div>
<div class="line"><span class="lineno">  814</span>    X = [[0, 1, 0], [0, -1, -1], [0, 0.5, 0.5]]</div>
<div class="line"><span class="lineno">  815</span>    y = [1, 0, 1]</div>
<div class="line"><span class="lineno">  816</span> </div>
<div class="line"><span class="lineno">  817</span>    <span class="keywordflow">for</span> select <span class="keywordflow">in</span> (</div>
<div class="line"><span class="lineno">  818</span>        SelectKBest(f_classif, k=2),</div>
<div class="line"><span class="lineno">  819</span>        SelectPercentile(f_classif, percentile=67),</div>
<div class="line"><span class="lineno">  820</span>    ):</div>
<div class="line"><span class="lineno">  821</span>        ignore_warnings(select.fit)(X, y)</div>
<div class="line"><span class="lineno">  822</span>        assert_array_equal(select.get_support(indices=<span class="keyword">True</span>), np.array([1, 2]))</div>
<div class="line"><span class="lineno">  823</span> </div>
<div class="line"><span class="lineno">  824</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5f8bc2a3c06aaf4c4b861e3ad8945251" name="a5f8bc2a3c06aaf4c4b861e3ad8945251"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f8bc2a3c06aaf4c4b861e3ad8945251">&#9670;&#160;</a></span>test_no_feature_selected()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_no_feature_selected </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  844</span><span class="keyword">def </span>test_no_feature_selected():</div>
<div class="line"><span class="lineno">  845</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  846</span> </div>
<div class="line"><span class="lineno">  847</span>    <span class="comment"># Generate random uncorrelated data: a strict univariate test should</span></div>
<div class="line"><span class="lineno">  848</span>    <span class="comment"># rejects all the features</span></div>
<div class="line"><span class="lineno">  849</span>    X = rng.rand(40, 10)</div>
<div class="line"><span class="lineno">  850</span>    y = rng.randint(0, 4, size=40)</div>
<div class="line"><span class="lineno">  851</span>    strict_selectors = [</div>
<div class="line"><span class="lineno">  852</span>        SelectFwe(alpha=0.01).fit(X, y),</div>
<div class="line"><span class="lineno">  853</span>        SelectFdr(alpha=0.01).fit(X, y),</div>
<div class="line"><span class="lineno">  854</span>        SelectFpr(alpha=0.01).fit(X, y),</div>
<div class="line"><span class="lineno">  855</span>        SelectPercentile(percentile=0).fit(X, y),</div>
<div class="line"><span class="lineno">  856</span>        SelectKBest(k=0).fit(X, y),</div>
<div class="line"><span class="lineno">  857</span>    ]</div>
<div class="line"><span class="lineno">  858</span>    <span class="keywordflow">for</span> selector <span class="keywordflow">in</span> strict_selectors:</div>
<div class="line"><span class="lineno">  859</span>        assert_array_equal(selector.get_support(), np.zeros(10))</div>
<div class="line"><span class="lineno">  860</span>        <span class="keyword">with</span> pytest.warns(UserWarning, match=<span class="stringliteral">&quot;No features were selected&quot;</span>):</div>
<div class="line"><span class="lineno">  861</span>            X_selected = selector.transform(X)</div>
<div class="line"><span class="lineno">  862</span>        <span class="keyword">assert</span> X_selected.shape == (40, 0)</div>
<div class="line"><span class="lineno">  863</span> </div>
<div class="line"><span class="lineno">  864</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a18581b623e1c6ce8978b9f3c63b75465" name="a18581b623e1c6ce8978b9f3c63b75465"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18581b623e1c6ce8978b9f3c63b75465">&#9670;&#160;</a></span>test_r_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_r_regression </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>center</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   94</span><span class="keyword">def </span>test_r_regression(center):</div>
<div class="line"><span class="lineno">   95</span>    X, y = make_regression(</div>
<div class="line"><span class="lineno">   96</span>        n_samples=2000, n_features=20, n_informative=5, shuffle=<span class="keyword">False</span>, random_state=0</div>
<div class="line"><span class="lineno">   97</span>    )</div>
<div class="line"><span class="lineno">   98</span> </div>
<div class="line"><span class="lineno">   99</span>    corr_coeffs = r_regression(X, y, center=center)</div>
<div class="line"><span class="lineno">  100</span>    <span class="keyword">assert</span> (-1 &lt; corr_coeffs).all()</div>
<div class="line"><span class="lineno">  101</span>    <span class="keyword">assert</span> (corr_coeffs &lt; 1).all()</div>
<div class="line"><span class="lineno">  102</span> </div>
<div class="line"><span class="lineno">  103</span>    sparse_X = _convert_container(X, <span class="stringliteral">&quot;sparse&quot;</span>)</div>
<div class="line"><span class="lineno">  104</span> </div>
<div class="line"><span class="lineno">  105</span>    sparse_corr_coeffs = r_regression(sparse_X, y, center=center)</div>
<div class="line"><span class="lineno">  106</span>    assert_allclose(sparse_corr_coeffs, corr_coeffs)</div>
<div class="line"><span class="lineno">  107</span> </div>
<div class="line"><span class="lineno">  108</span>    <span class="comment"># Testing against numpy for reference</span></div>
<div class="line"><span class="lineno">  109</span>    Z = np.hstack((X, y[:, np.newaxis]))</div>
<div class="line"><span class="lineno">  110</span>    correlation_matrix = np.corrcoef(Z, rowvar=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  111</span>    np_corr_coeffs = correlation_matrix[:-1, -1]</div>
<div class="line"><span class="lineno">  112</span>    assert_array_almost_equal(np_corr_coeffs, corr_coeffs, decimal=3)</div>
<div class="line"><span class="lineno">  113</span> </div>
<div class="line"><span class="lineno">  114</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7fbed6e23050bbc8f1355fb992ea8d19" name="a7fbed6e23050bbc8f1355fb992ea8d19"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fbed6e23050bbc8f1355fb992ea8d19">&#9670;&#160;</a></span>test_r_regression_force_finite()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_r_regression_force_finite </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>expected_corr_coef</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>force_finite</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check the behaviour of `force_finite` for some corner cases with `r_regression`.

Non-regression test for:
https://github.com/scikit-learn/scikit-learn/issues/15672
</pre> <div class="fragment"><div class="line"><span class="lineno">  205</span><span class="keyword">def </span>test_r_regression_force_finite(X, y, expected_corr_coef, force_finite):</div>
<div class="line"><span class="lineno">  206</span>    <span class="stringliteral">&quot;&quot;&quot;Check the behaviour of `force_finite` for some corner cases with `r_regression`.</span></div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">    Non-regression test for:</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">    https://github.com/scikit-learn/scikit-learn/issues/15672</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  211</span>    <span class="keyword">with</span> warnings.catch_warnings():</div>
<div class="line"><span class="lineno">  212</span>        warnings.simplefilter(<span class="stringliteral">&quot;error&quot;</span>, RuntimeWarning)</div>
<div class="line"><span class="lineno">  213</span>        corr_coef = r_regression(X, y, force_finite=force_finite)</div>
<div class="line"><span class="lineno">  214</span>    np.testing.assert_array_almost_equal(corr_coef, expected_corr_coef)</div>
<div class="line"><span class="lineno">  215</span> </div>
<div class="line"><span class="lineno">  216</span> </div>
<div class="line"><span class="lineno">  217</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  218</span>    <span class="stringliteral">&quot;X, y, expected_f_statistic, expected_p_values, force_finite&quot;</span>,</div>
<div class="line"><span class="lineno">  219</span>    [</div>
<div class="line"><span class="lineno">  220</span>        (</div>
<div class="line"><span class="lineno">  221</span>            <span class="comment"># A feature in X is constant - forcing finite</span></div>
<div class="line"><span class="lineno">  222</span>            np.array([[2, 1], [2, 0], [2, 10], [2, 4]]),</div>
<div class="line"><span class="lineno">  223</span>            np.array([0, 1, 1, 0]),</div>
<div class="line"><span class="lineno">  224</span>            np.array([0.0, 0.2293578]),</div>
<div class="line"><span class="lineno">  225</span>            np.array([1.0, 0.67924985]),</div>
<div class="line"><span class="lineno">  226</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  227</span>        ),</div>
<div class="line"><span class="lineno">  228</span>        (</div>
<div class="line"><span class="lineno">  229</span>            <span class="comment"># The target y is constant - forcing finite</span></div>
<div class="line"><span class="lineno">  230</span>            np.array([[5, 1], [3, 0], [2, 10], [8, 4]]),</div>
<div class="line"><span class="lineno">  231</span>            np.array([0, 0, 0, 0]),</div>
<div class="line"><span class="lineno">  232</span>            np.array([0.0, 0.0]),</div>
<div class="line"><span class="lineno">  233</span>            np.array([1.0, 1.0]),</div>
<div class="line"><span class="lineno">  234</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  235</span>        ),</div>
<div class="line"><span class="lineno">  236</span>        (</div>
<div class="line"><span class="lineno">  237</span>            <span class="comment"># Feature in X correlated with y - forcing finite</span></div>
<div class="line"><span class="lineno">  238</span>            np.array([[0, 1], [1, 0], [2, 10], [3, 4]]),</div>
<div class="line"><span class="lineno">  239</span>            np.array([0, 1, 2, 3]),</div>
<div class="line"><span class="lineno">  240</span>            np.array([np.finfo(np.float64).max, 0.845433]),</div>
<div class="line"><span class="lineno">  241</span>            np.array([0.0, 0.454913]),</div>
<div class="line"><span class="lineno">  242</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  243</span>        ),</div>
<div class="line"><span class="lineno">  244</span>        (</div>
<div class="line"><span class="lineno">  245</span>            <span class="comment"># Feature in X anti-correlated with y - forcing finite</span></div>
<div class="line"><span class="lineno">  246</span>            np.array([[3, 1], [2, 0], [1, 10], [0, 4]]),</div>
<div class="line"><span class="lineno">  247</span>            np.array([0, 1, 2, 3]),</div>
<div class="line"><span class="lineno">  248</span>            np.array([np.finfo(np.float64).max, 0.845433]),</div>
<div class="line"><span class="lineno">  249</span>            np.array([0.0, 0.454913]),</div>
<div class="line"><span class="lineno">  250</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  251</span>        ),</div>
<div class="line"><span class="lineno">  252</span>        (</div>
<div class="line"><span class="lineno">  253</span>            <span class="comment"># A feature in X is constant - not forcing finite</span></div>
<div class="line"><span class="lineno">  254</span>            np.array([[2, 1], [2, 0], [2, 10], [2, 4]]),</div>
<div class="line"><span class="lineno">  255</span>            np.array([0, 1, 1, 0]),</div>
<div class="line"><span class="lineno">  256</span>            np.array([np.nan, 0.2293578]),</div>
<div class="line"><span class="lineno">  257</span>            np.array([np.nan, 0.67924985]),</div>
<div class="line"><span class="lineno">  258</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  259</span>        ),</div>
<div class="line"><span class="lineno">  260</span>        (</div>
<div class="line"><span class="lineno">  261</span>            <span class="comment"># The target y is constant - not forcing finite</span></div>
<div class="line"><span class="lineno">  262</span>            np.array([[5, 1], [3, 0], [2, 10], [8, 4]]),</div>
<div class="line"><span class="lineno">  263</span>            np.array([0, 0, 0, 0]),</div>
<div class="line"><span class="lineno">  264</span>            np.array([np.nan, np.nan]),</div>
<div class="line"><span class="lineno">  265</span>            np.array([np.nan, np.nan]),</div>
<div class="line"><span class="lineno">  266</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  267</span>        ),</div>
<div class="line"><span class="lineno">  268</span>        (</div>
<div class="line"><span class="lineno">  269</span>            <span class="comment"># Feature in X correlated with y - not forcing finite</span></div>
<div class="line"><span class="lineno">  270</span>            np.array([[0, 1], [1, 0], [2, 10], [3, 4]]),</div>
<div class="line"><span class="lineno">  271</span>            np.array([0, 1, 2, 3]),</div>
<div class="line"><span class="lineno">  272</span>            np.array([np.inf, 0.845433]),</div>
<div class="line"><span class="lineno">  273</span>            np.array([0.0, 0.454913]),</div>
<div class="line"><span class="lineno">  274</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  275</span>        ),</div>
<div class="line"><span class="lineno">  276</span>        (</div>
<div class="line"><span class="lineno">  277</span>            <span class="comment"># Feature in X anti-correlated with y - not forcing finite</span></div>
<div class="line"><span class="lineno">  278</span>            np.array([[3, 1], [2, 0], [1, 10], [0, 4]]),</div>
<div class="line"><span class="lineno">  279</span>            np.array([0, 1, 2, 3]),</div>
<div class="line"><span class="lineno">  280</span>            np.array([np.inf, 0.845433]),</div>
<div class="line"><span class="lineno">  281</span>            np.array([0.0, 0.454913]),</div>
<div class="line"><span class="lineno">  282</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  283</span>        ),</div>
<div class="line"><span class="lineno">  284</span>    ],</div>
<div class="line"><span class="lineno">  285</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="aae31da764c47ed3db972bedc4fbcab61" name="aae31da764c47ed3db972bedc4fbcab61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae31da764c47ed3db972bedc4fbcab61">&#9670;&#160;</a></span>test_scorefunc_multilabel()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_scorefunc_multilabel </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  784</span><span class="keyword">def </span>test_scorefunc_multilabel():</div>
<div class="line"><span class="lineno">  785</span>    <span class="comment"># Test whether k-best and percentiles works with multilabels with chi2.</span></div>
<div class="line"><span class="lineno">  786</span> </div>
<div class="line"><span class="lineno">  787</span>    X = np.array([[10000, 9999, 0], [100, 9999, 0], [1000, 99, 0]])</div>
<div class="line"><span class="lineno">  788</span>    y = [[1, 1], [0, 1], [1, 0]]</div>
<div class="line"><span class="lineno">  789</span> </div>
<div class="line"><span class="lineno">  790</span>    Xt = SelectKBest(chi2, k=2).fit_transform(X, y)</div>
<div class="line"><span class="lineno">  791</span>    <span class="keyword">assert</span> Xt.shape == (3, 2)</div>
<div class="line"><span class="lineno">  792</span>    <span class="keyword">assert</span> 0 <span class="keywordflow">not</span> <span class="keywordflow">in</span> Xt</div>
<div class="line"><span class="lineno">  793</span> </div>
<div class="line"><span class="lineno">  794</span>    Xt = SelectPercentile(chi2, percentile=67).fit_transform(X, y)</div>
<div class="line"><span class="lineno">  795</span>    <span class="keyword">assert</span> Xt.shape == (3, 2)</div>
<div class="line"><span class="lineno">  796</span>    <span class="keyword">assert</span> 0 <span class="keywordflow">not</span> <span class="keywordflow">in</span> Xt</div>
<div class="line"><span class="lineno">  797</span> </div>
<div class="line"><span class="lineno">  798</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a705e9a13c822ea231c8899a5db5a0e74" name="a705e9a13c822ea231c8899a5db5a0e74"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a705e9a13c822ea231c8899a5db5a0e74">&#9670;&#160;</a></span>test_select_fdr_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_fdr_regression </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_informative</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  659</span><span class="keyword">def </span>test_select_fdr_regression(alpha, n_informative):</div>
<div class="line"><span class="lineno">  660</span>    <span class="comment"># Test that fdr heuristic actually has low FDR.</span></div>
<div class="line"><span class="lineno">  661</span>    <span class="keyword">def </span>single_fdr(alpha, n_informative, random_state):</div>
<div class="line"><span class="lineno">  662</span>        X, y = make_regression(</div>
<div class="line"><span class="lineno">  663</span>            n_samples=150,</div>
<div class="line"><span class="lineno">  664</span>            n_features=20,</div>
<div class="line"><span class="lineno">  665</span>            n_informative=n_informative,</div>
<div class="line"><span class="lineno">  666</span>            shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  667</span>            random_state=random_state,</div>
<div class="line"><span class="lineno">  668</span>            noise=10,</div>
<div class="line"><span class="lineno">  669</span>        )</div>
<div class="line"><span class="lineno">  670</span> </div>
<div class="line"><span class="lineno">  671</span>        <span class="keyword">with</span> warnings.catch_warnings(record=<span class="keyword">True</span>):</div>
<div class="line"><span class="lineno">  672</span>            <span class="comment"># Warnings can be raised when no features are selected</span></div>
<div class="line"><span class="lineno">  673</span>            <span class="comment"># (low alpha or very noisy data)</span></div>
<div class="line"><span class="lineno">  674</span>            univariate_filter = SelectFdr(f_regression, alpha=alpha)</div>
<div class="line"><span class="lineno">  675</span>            X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  676</span>            X_r2 = (</div>
<div class="line"><span class="lineno">  677</span>                GenericUnivariateSelect(f_regression, mode=<span class="stringliteral">&quot;fdr&quot;</span>, param=alpha)</div>
<div class="line"><span class="lineno">  678</span>                .fit(X, y)</div>
<div class="line"><span class="lineno">  679</span>                .transform(X)</div>
<div class="line"><span class="lineno">  680</span>            )</div>
<div class="line"><span class="lineno">  681</span> </div>
<div class="line"><span class="lineno">  682</span>        assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  683</span>        support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  684</span>        num_false_positives = np.sum(support[n_informative:] == 1)</div>
<div class="line"><span class="lineno">  685</span>        num_true_positives = np.sum(support[:n_informative] == 1)</div>
<div class="line"><span class="lineno">  686</span> </div>
<div class="line"><span class="lineno">  687</span>        <span class="keywordflow">if</span> num_false_positives == 0:</div>
<div class="line"><span class="lineno">  688</span>            <span class="keywordflow">return</span> 0.0</div>
<div class="line"><span class="lineno">  689</span>        false_discovery_rate = num_false_positives / (</div>
<div class="line"><span class="lineno">  690</span>            num_true_positives + num_false_positives</div>
<div class="line"><span class="lineno">  691</span>        )</div>
<div class="line"><span class="lineno">  692</span>        <span class="keywordflow">return</span> false_discovery_rate</div>
<div class="line"><span class="lineno">  693</span> </div>
<div class="line"><span class="lineno">  694</span>    <span class="comment"># As per Benjamini-Hochberg, the expected false discovery rate</span></div>
<div class="line"><span class="lineno">  695</span>    <span class="comment"># should be lower than alpha:</span></div>
<div class="line"><span class="lineno">  696</span>    <span class="comment"># FDR = E(FP / (TP + FP)) &lt;= alpha</span></div>
<div class="line"><span class="lineno">  697</span>    false_discovery_rate = np.mean(</div>
<div class="line"><span class="lineno">  698</span>        [single_fdr(alpha, n_informative, random_state) <span class="keywordflow">for</span> random_state <span class="keywordflow">in</span> range(100)]</div>
<div class="line"><span class="lineno">  699</span>    )</div>
<div class="line"><span class="lineno">  700</span>    <span class="keyword">assert</span> alpha &gt;= false_discovery_rate</div>
<div class="line"><span class="lineno">  701</span> </div>
<div class="line"><span class="lineno">  702</span>    <span class="comment"># Make sure that the empirical false discovery rate increases</span></div>
<div class="line"><span class="lineno">  703</span>    <span class="comment"># with alpha:</span></div>
<div class="line"><span class="lineno">  704</span>    <span class="keywordflow">if</span> false_discovery_rate != 0:</div>
<div class="line"><span class="lineno">  705</span>        <span class="keyword">assert</span> false_discovery_rate &gt; alpha / 10</div>
<div class="line"><span class="lineno">  706</span> </div>
<div class="line"><span class="lineno">  707</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9131f57b799cc14f8aeb70bbe6d2f735" name="a9131f57b799cc14f8aeb70bbe6d2f735"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9131f57b799cc14f8aeb70bbe6d2f735">&#9670;&#160;</a></span>test_select_fwe_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_fwe_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  708</span><span class="keyword">def </span>test_select_fwe_regression():</div>
<div class="line"><span class="lineno">  709</span>    <span class="comment"># Test whether the relative univariate feature selection</span></div>
<div class="line"><span class="lineno">  710</span>    <span class="comment"># gets the correct items in a simple regression problem</span></div>
<div class="line"><span class="lineno">  711</span>    <span class="comment"># with the fwe heuristic</span></div>
<div class="line"><span class="lineno">  712</span>    X, y = make_regression(</div>
<div class="line"><span class="lineno">  713</span>        n_samples=200, n_features=20, n_informative=5, shuffle=<span class="keyword">False</span>, random_state=0</div>
<div class="line"><span class="lineno">  714</span>    )</div>
<div class="line"><span class="lineno">  715</span> </div>
<div class="line"><span class="lineno">  716</span>    univariate_filter = SelectFwe(f_regression, alpha=0.01)</div>
<div class="line"><span class="lineno">  717</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  718</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  719</span>        GenericUnivariateSelect(f_regression, mode=<span class="stringliteral">&quot;fwe&quot;</span>, param=0.01)</div>
<div class="line"><span class="lineno">  720</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  721</span>        .transform(X)</div>
<div class="line"><span class="lineno">  722</span>    )</div>
<div class="line"><span class="lineno">  723</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  724</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  725</span>    gtruth = np.zeros(20)</div>
<div class="line"><span class="lineno">  726</span>    gtruth[:5] = 1</div>
<div class="line"><span class="lineno">  727</span>    assert_array_equal(support[:5], np.ones((5,), dtype=bool))</div>
<div class="line"><span class="lineno">  728</span>    <span class="keyword">assert</span> np.sum(support[5:] == 1) &lt; 2</div>
<div class="line"><span class="lineno">  729</span> </div>
<div class="line"><span class="lineno">  730</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a22614034700c590bd9f3993eb83bf020" name="a22614034700c590bd9f3993eb83bf020"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a22614034700c590bd9f3993eb83bf020">&#9670;&#160;</a></span>test_select_heuristics_classif()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_heuristics_classif </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  472</span><span class="keyword">def </span>test_select_heuristics_classif():</div>
<div class="line"><span class="lineno">  473</span>    <span class="comment"># Test whether the relative univariate feature selection</span></div>
<div class="line"><span class="lineno">  474</span>    <span class="comment"># gets the correct items in a simple classification problem</span></div>
<div class="line"><span class="lineno">  475</span>    <span class="comment"># with the fdr, fwe and fpr heuristics</span></div>
<div class="line"><span class="lineno">  476</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  477</span>        n_samples=200,</div>
<div class="line"><span class="lineno">  478</span>        n_features=20,</div>
<div class="line"><span class="lineno">  479</span>        n_informative=3,</div>
<div class="line"><span class="lineno">  480</span>        n_redundant=2,</div>
<div class="line"><span class="lineno">  481</span>        n_repeated=0,</div>
<div class="line"><span class="lineno">  482</span>        n_classes=8,</div>
<div class="line"><span class="lineno">  483</span>        n_clusters_per_class=1,</div>
<div class="line"><span class="lineno">  484</span>        flip_y=0.0,</div>
<div class="line"><span class="lineno">  485</span>        class_sep=10,</div>
<div class="line"><span class="lineno">  486</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  487</span>        random_state=0,</div>
<div class="line"><span class="lineno">  488</span>    )</div>
<div class="line"><span class="lineno">  489</span> </div>
<div class="line"><span class="lineno">  490</span>    univariate_filter = SelectFwe(f_classif, alpha=0.01)</div>
<div class="line"><span class="lineno">  491</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  492</span>    gtruth = np.zeros(20)</div>
<div class="line"><span class="lineno">  493</span>    gtruth[:5] = 1</div>
<div class="line"><span class="lineno">  494</span>    <span class="keywordflow">for</span> mode <span class="keywordflow">in</span> [<span class="stringliteral">&quot;fdr&quot;</span>, <span class="stringliteral">&quot;fpr&quot;</span>, <span class="stringliteral">&quot;fwe&quot;</span>]:</div>
<div class="line"><span class="lineno">  495</span>        X_r2 = (</div>
<div class="line"><span class="lineno">  496</span>            GenericUnivariateSelect(f_classif, mode=mode, param=0.01)</div>
<div class="line"><span class="lineno">  497</span>            .fit(X, y)</div>
<div class="line"><span class="lineno">  498</span>            .transform(X)</div>
<div class="line"><span class="lineno">  499</span>        )</div>
<div class="line"><span class="lineno">  500</span>        assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  501</span>        support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  502</span>        assert_allclose(support, gtruth)</div>
<div class="line"><span class="lineno">  503</span> </div>
<div class="line"><span class="lineno">  504</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac6c010a0eb0e6bb254a70b6d24dec11f" name="ac6c010a0eb0e6bb254a70b6d24dec11f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac6c010a0eb0e6bb254a70b6d24dec11f">&#9670;&#160;</a></span>test_select_heuristics_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_heuristics_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  594</span><span class="keyword">def </span>test_select_heuristics_regression():</div>
<div class="line"><span class="lineno">  595</span>    <span class="comment"># Test whether the relative univariate feature selection</span></div>
<div class="line"><span class="lineno">  596</span>    <span class="comment"># gets the correct items in a simple regression problem</span></div>
<div class="line"><span class="lineno">  597</span>    <span class="comment"># with the fpr, fdr or fwe heuristics</span></div>
<div class="line"><span class="lineno">  598</span>    X, y = make_regression(</div>
<div class="line"><span class="lineno">  599</span>        n_samples=200,</div>
<div class="line"><span class="lineno">  600</span>        n_features=20,</div>
<div class="line"><span class="lineno">  601</span>        n_informative=5,</div>
<div class="line"><span class="lineno">  602</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  603</span>        random_state=0,</div>
<div class="line"><span class="lineno">  604</span>        noise=10,</div>
<div class="line"><span class="lineno">  605</span>    )</div>
<div class="line"><span class="lineno">  606</span> </div>
<div class="line"><span class="lineno">  607</span>    univariate_filter = SelectFpr(f_regression, alpha=0.01)</div>
<div class="line"><span class="lineno">  608</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  609</span>    gtruth = np.zeros(20)</div>
<div class="line"><span class="lineno">  610</span>    gtruth[:5] = 1</div>
<div class="line"><span class="lineno">  611</span>    <span class="keywordflow">for</span> mode <span class="keywordflow">in</span> [<span class="stringliteral">&quot;fdr&quot;</span>, <span class="stringliteral">&quot;fpr&quot;</span>, <span class="stringliteral">&quot;fwe&quot;</span>]:</div>
<div class="line"><span class="lineno">  612</span>        X_r2 = (</div>
<div class="line"><span class="lineno">  613</span>            GenericUnivariateSelect(f_regression, mode=mode, param=0.01)</div>
<div class="line"><span class="lineno">  614</span>            .fit(X, y)</div>
<div class="line"><span class="lineno">  615</span>            .transform(X)</div>
<div class="line"><span class="lineno">  616</span>        )</div>
<div class="line"><span class="lineno">  617</span>        assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  618</span>        support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  619</span>        assert_array_equal(support[:5], np.ones((5,), dtype=bool))</div>
<div class="line"><span class="lineno">  620</span>        <span class="keyword">assert</span> np.sum(support[5:] == 1) &lt; 3</div>
<div class="line"><span class="lineno">  621</span> </div>
<div class="line"><span class="lineno">  622</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a86e6d5afedf3aaf65829f471cd77828b" name="a86e6d5afedf3aaf65829f471cd77828b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a86e6d5afedf3aaf65829f471cd77828b">&#9670;&#160;</a></span>test_select_kbest_all()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_kbest_all </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  434</span><span class="keyword">def </span>test_select_kbest_all():</div>
<div class="line"><span class="lineno">  435</span>    <span class="comment"># Test whether k=&quot;all&quot; correctly returns all features.</span></div>
<div class="line"><span class="lineno">  436</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  437</span>        n_samples=20, n_features=10, shuffle=<span class="keyword">False</span>, random_state=0</div>
<div class="line"><span class="lineno">  438</span>    )</div>
<div class="line"><span class="lineno">  439</span> </div>
<div class="line"><span class="lineno">  440</span>    univariate_filter = SelectKBest(f_classif, k=<span class="stringliteral">&quot;all&quot;</span>)</div>
<div class="line"><span class="lineno">  441</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  442</span>    assert_array_equal(X, X_r)</div>
<div class="line"><span class="lineno">  443</span>    <span class="comment"># Non-regression test for:</span></div>
<div class="line"><span class="lineno">  444</span>    <span class="comment"># https://github.com/scikit-learn/scikit-learn/issues/24949</span></div>
<div class="line"><span class="lineno">  445</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  446</span>        GenericUnivariateSelect(f_classif, mode=<span class="stringliteral">&quot;k_best&quot;</span>, param=<span class="stringliteral">&quot;all&quot;</span>)</div>
<div class="line"><span class="lineno">  447</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  448</span>        .transform(X)</div>
<div class="line"><span class="lineno">  449</span>    )</div>
<div class="line"><span class="lineno">  450</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  451</span> </div>
<div class="line"><span class="lineno">  452</span> </div>
<div class="line"><span class="lineno">  453</span><span class="preprocessor">@pytest.mark.parametrize(&quot;dtype_in&quot;, [np.float32, np.float64])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aaca5262182fd2ebe5c60a90cf27a54e8" name="aaca5262182fd2ebe5c60a90cf27a54e8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaca5262182fd2ebe5c60a90cf27a54e8">&#9670;&#160;</a></span>test_select_kbest_classif()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_kbest_classif </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Test univariate selection in classification settings. </p>
<div class="fragment"><div class="line"><span class="lineno">  402</span><span class="keyword">def </span>test_select_kbest_classif():</div>
<div class="line"><span class="lineno">  403</span>    <span class="comment"># Test whether the relative univariate feature selection</span></div>
<div class="line"><span class="lineno">  404</span>    <span class="comment"># gets the correct items in a simple classification problem</span></div>
<div class="line"><span class="lineno">  405</span>    <span class="comment"># with the k best heuristic</span></div>
<div class="line"><span class="lineno">  406</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  407</span>        n_samples=200,</div>
<div class="line"><span class="lineno">  408</span>        n_features=20,</div>
<div class="line"><span class="lineno">  409</span>        n_informative=3,</div>
<div class="line"><span class="lineno">  410</span>        n_redundant=2,</div>
<div class="line"><span class="lineno">  411</span>        n_repeated=0,</div>
<div class="line"><span class="lineno">  412</span>        n_classes=8,</div>
<div class="line"><span class="lineno">  413</span>        n_clusters_per_class=1,</div>
<div class="line"><span class="lineno">  414</span>        flip_y=0.0,</div>
<div class="line"><span class="lineno">  415</span>        class_sep=10,</div>
<div class="line"><span class="lineno">  416</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  417</span>        random_state=0,</div>
<div class="line"><span class="lineno">  418</span>    )</div>
<div class="line"><span class="lineno">  419</span> </div>
<div class="line"><span class="lineno">  420</span>    univariate_filter = SelectKBest(f_classif, k=5)</div>
<div class="line"><span class="lineno">  421</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  422</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  423</span>        GenericUnivariateSelect(f_classif, mode=<span class="stringliteral">&quot;k_best&quot;</span>, param=5)</div>
<div class="line"><span class="lineno">  424</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  425</span>        .transform(X)</div>
<div class="line"><span class="lineno">  426</span>    )</div>
<div class="line"><span class="lineno">  427</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  428</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  429</span>    gtruth = np.zeros(20)</div>
<div class="line"><span class="lineno">  430</span>    gtruth[:5] = 1</div>
<div class="line"><span class="lineno">  431</span>    assert_array_equal(support, gtruth)</div>
<div class="line"><span class="lineno">  432</span> </div>
<div class="line"><span class="lineno">  433</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5b92cd7a388d88e9c36ca781a22186f7" name="a5b92cd7a388d88e9c36ca781a22186f7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5b92cd7a388d88e9c36ca781a22186f7">&#9670;&#160;</a></span>test_select_kbest_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_kbest_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  566</span><span class="keyword">def </span>test_select_kbest_regression():</div>
<div class="line"><span class="lineno">  567</span>    <span class="comment"># Test whether the relative univariate feature selection</span></div>
<div class="line"><span class="lineno">  568</span>    <span class="comment"># gets the correct items in a simple regression problem</span></div>
<div class="line"><span class="lineno">  569</span>    <span class="comment"># with the k best heuristic</span></div>
<div class="line"><span class="lineno">  570</span>    X, y = make_regression(</div>
<div class="line"><span class="lineno">  571</span>        n_samples=200,</div>
<div class="line"><span class="lineno">  572</span>        n_features=20,</div>
<div class="line"><span class="lineno">  573</span>        n_informative=5,</div>
<div class="line"><span class="lineno">  574</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  575</span>        random_state=0,</div>
<div class="line"><span class="lineno">  576</span>        noise=10,</div>
<div class="line"><span class="lineno">  577</span>    )</div>
<div class="line"><span class="lineno">  578</span> </div>
<div class="line"><span class="lineno">  579</span>    univariate_filter = SelectKBest(f_regression, k=5)</div>
<div class="line"><span class="lineno">  580</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  581</span>    assert_best_scores_kept(univariate_filter)</div>
<div class="line"><span class="lineno">  582</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  583</span>        GenericUnivariateSelect(f_regression, mode=<span class="stringliteral">&quot;k_best&quot;</span>, param=5)</div>
<div class="line"><span class="lineno">  584</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  585</span>        .transform(X)</div>
<div class="line"><span class="lineno">  586</span>    )</div>
<div class="line"><span class="lineno">  587</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  588</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  589</span>    gtruth = np.zeros(20)</div>
<div class="line"><span class="lineno">  590</span>    gtruth[:5] = 1</div>
<div class="line"><span class="lineno">  591</span>    assert_array_equal(support, gtruth)</div>
<div class="line"><span class="lineno">  592</span> </div>
<div class="line"><span class="lineno">  593</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8a0868d97f4410d22b49ad700b97f8ee" name="a8a0868d97f4410d22b49ad700b97f8ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a0868d97f4410d22b49ad700b97f8ee">&#9670;&#160;</a></span>test_select_kbest_zero()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_kbest_zero </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype_in</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  454</span><span class="keyword">def </span>test_select_kbest_zero(dtype_in):</div>
<div class="line"><span class="lineno">  455</span>    <span class="comment"># Test whether k=0 correctly returns no features.</span></div>
<div class="line"><span class="lineno">  456</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  457</span>        n_samples=20, n_features=10, shuffle=<span class="keyword">False</span>, random_state=0</div>
<div class="line"><span class="lineno">  458</span>    )</div>
<div class="line"><span class="lineno">  459</span>    X = X.astype(dtype_in)</div>
<div class="line"><span class="lineno">  460</span> </div>
<div class="line"><span class="lineno">  461</span>    univariate_filter = SelectKBest(f_classif, k=0)</div>
<div class="line"><span class="lineno">  462</span>    univariate_filter.fit(X, y)</div>
<div class="line"><span class="lineno">  463</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  464</span>    gtruth = np.zeros(10, dtype=bool)</div>
<div class="line"><span class="lineno">  465</span>    assert_array_equal(support, gtruth)</div>
<div class="line"><span class="lineno">  466</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=<span class="stringliteral">&quot;No features were selected&quot;</span>):</div>
<div class="line"><span class="lineno">  467</span>        X_selected = univariate_filter.transform(X)</div>
<div class="line"><span class="lineno">  468</span>    <span class="keyword">assert</span> X_selected.shape == (20, 0)</div>
<div class="line"><span class="lineno">  469</span>    <span class="keyword">assert</span> X_selected.dtype == dtype_in</div>
<div class="line"><span class="lineno">  470</span> </div>
<div class="line"><span class="lineno">  471</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a88c4cee60a1ac91549cbffa1f5ba9a86" name="a88c4cee60a1ac91549cbffa1f5ba9a86"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a88c4cee60a1ac91549cbffa1f5ba9a86">&#9670;&#160;</a></span>test_select_percentile_classif()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_percentile_classif </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  326</span><span class="keyword">def </span>test_select_percentile_classif():</div>
<div class="line"><span class="lineno">  327</span>    <span class="comment"># Test whether the relative univariate feature selection</span></div>
<div class="line"><span class="lineno">  328</span>    <span class="comment"># gets the correct items in a simple classification problem</span></div>
<div class="line"><span class="lineno">  329</span>    <span class="comment"># with the percentile heuristic</span></div>
<div class="line"><span class="lineno">  330</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  331</span>        n_samples=200,</div>
<div class="line"><span class="lineno">  332</span>        n_features=20,</div>
<div class="line"><span class="lineno">  333</span>        n_informative=3,</div>
<div class="line"><span class="lineno">  334</span>        n_redundant=2,</div>
<div class="line"><span class="lineno">  335</span>        n_repeated=0,</div>
<div class="line"><span class="lineno">  336</span>        n_classes=8,</div>
<div class="line"><span class="lineno">  337</span>        n_clusters_per_class=1,</div>
<div class="line"><span class="lineno">  338</span>        flip_y=0.0,</div>
<div class="line"><span class="lineno">  339</span>        class_sep=10,</div>
<div class="line"><span class="lineno">  340</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  341</span>        random_state=0,</div>
<div class="line"><span class="lineno">  342</span>    )</div>
<div class="line"><span class="lineno">  343</span> </div>
<div class="line"><span class="lineno">  344</span>    univariate_filter = SelectPercentile(f_classif, percentile=25)</div>
<div class="line"><span class="lineno">  345</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  346</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  347</span>        GenericUnivariateSelect(f_classif, mode=<span class="stringliteral">&quot;percentile&quot;</span>, param=25)</div>
<div class="line"><span class="lineno">  348</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  349</span>        .transform(X)</div>
<div class="line"><span class="lineno">  350</span>    )</div>
<div class="line"><span class="lineno">  351</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  352</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  353</span>    gtruth = np.zeros(20)</div>
<div class="line"><span class="lineno">  354</span>    gtruth[:5] = 1</div>
<div class="line"><span class="lineno">  355</span>    assert_array_equal(support, gtruth)</div>
<div class="line"><span class="lineno">  356</span> </div>
<div class="line"><span class="lineno">  357</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1968567e414a32bda6058785da33e2f4" name="a1968567e414a32bda6058785da33e2f4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1968567e414a32bda6058785da33e2f4">&#9670;&#160;</a></span>test_select_percentile_classif_sparse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_percentile_classif_sparse </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  358</span><span class="keyword">def </span>test_select_percentile_classif_sparse():</div>
<div class="line"><span class="lineno">  359</span>    <span class="comment"># Test whether the relative univariate feature selection</span></div>
<div class="line"><span class="lineno">  360</span>    <span class="comment"># gets the correct items in a simple classification problem</span></div>
<div class="line"><span class="lineno">  361</span>    <span class="comment"># with the percentile heuristic</span></div>
<div class="line"><span class="lineno">  362</span>    X, y = make_classification(</div>
<div class="line"><span class="lineno">  363</span>        n_samples=200,</div>
<div class="line"><span class="lineno">  364</span>        n_features=20,</div>
<div class="line"><span class="lineno">  365</span>        n_informative=3,</div>
<div class="line"><span class="lineno">  366</span>        n_redundant=2,</div>
<div class="line"><span class="lineno">  367</span>        n_repeated=0,</div>
<div class="line"><span class="lineno">  368</span>        n_classes=8,</div>
<div class="line"><span class="lineno">  369</span>        n_clusters_per_class=1,</div>
<div class="line"><span class="lineno">  370</span>        flip_y=0.0,</div>
<div class="line"><span class="lineno">  371</span>        class_sep=10,</div>
<div class="line"><span class="lineno">  372</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  373</span>        random_state=0,</div>
<div class="line"><span class="lineno">  374</span>    )</div>
<div class="line"><span class="lineno">  375</span>    X = sparse.csr_matrix(X)</div>
<div class="line"><span class="lineno">  376</span>    univariate_filter = SelectPercentile(f_classif, percentile=25)</div>
<div class="line"><span class="lineno">  377</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  378</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  379</span>        GenericUnivariateSelect(f_classif, mode=<span class="stringliteral">&quot;percentile&quot;</span>, param=25)</div>
<div class="line"><span class="lineno">  380</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  381</span>        .transform(X)</div>
<div class="line"><span class="lineno">  382</span>    )</div>
<div class="line"><span class="lineno">  383</span>    assert_array_equal(X_r.toarray(), X_r2.toarray())</div>
<div class="line"><span class="lineno">  384</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  385</span>    gtruth = np.zeros(20)</div>
<div class="line"><span class="lineno">  386</span>    gtruth[:5] = 1</div>
<div class="line"><span class="lineno">  387</span>    assert_array_equal(support, gtruth)</div>
<div class="line"><span class="lineno">  388</span> </div>
<div class="line"><span class="lineno">  389</span>    X_r2inv = univariate_filter.inverse_transform(X_r2)</div>
<div class="line"><span class="lineno">  390</span>    <span class="keyword">assert</span> sparse.issparse(X_r2inv)</div>
<div class="line"><span class="lineno">  391</span>    support_mask = safe_mask(X_r2inv, support)</div>
<div class="line"><span class="lineno">  392</span>    <span class="keyword">assert</span> X_r2inv.shape == X.shape</div>
<div class="line"><span class="lineno">  393</span>    assert_array_equal(X_r2inv[:, support_mask].toarray(), X_r.toarray())</div>
<div class="line"><span class="lineno">  394</span>    <span class="comment"># Check other columns are empty</span></div>
<div class="line"><span class="lineno">  395</span>    <span class="keyword">assert</span> X_r2inv.getnnz() == X_r.getnnz()</div>
<div class="line"><span class="lineno">  396</span> </div>
<div class="line"><span class="lineno">  397</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aab7575abfe119fbe9059044ff0b71d95" name="aab7575abfe119fbe9059044ff0b71d95"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab7575abfe119fbe9059044ff0b71d95">&#9670;&#160;</a></span>test_select_percentile_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_percentile_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  515</span><span class="keyword">def </span>test_select_percentile_regression():</div>
<div class="line"><span class="lineno">  516</span>    <span class="comment"># Test whether the relative univariate feature selection</span></div>
<div class="line"><span class="lineno">  517</span>    <span class="comment"># gets the correct items in a simple regression problem</span></div>
<div class="line"><span class="lineno">  518</span>    <span class="comment"># with the percentile heuristic</span></div>
<div class="line"><span class="lineno">  519</span>    X, y = make_regression(</div>
<div class="line"><span class="lineno">  520</span>        n_samples=200, n_features=20, n_informative=5, shuffle=<span class="keyword">False</span>, random_state=0</div>
<div class="line"><span class="lineno">  521</span>    )</div>
<div class="line"><span class="lineno">  522</span> </div>
<div class="line"><span class="lineno">  523</span>    univariate_filter = SelectPercentile(f_regression, percentile=25)</div>
<div class="line"><span class="lineno">  524</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  525</span>    assert_best_scores_kept(univariate_filter)</div>
<div class="line"><span class="lineno">  526</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  527</span>        GenericUnivariateSelect(f_regression, mode=<span class="stringliteral">&quot;percentile&quot;</span>, param=25)</div>
<div class="line"><span class="lineno">  528</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  529</span>        .transform(X)</div>
<div class="line"><span class="lineno">  530</span>    )</div>
<div class="line"><span class="lineno">  531</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  532</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  533</span>    gtruth = np.zeros(20)</div>
<div class="line"><span class="lineno">  534</span>    gtruth[:5] = 1</div>
<div class="line"><span class="lineno">  535</span>    assert_array_equal(support, gtruth)</div>
<div class="line"><span class="lineno">  536</span>    X_2 = X.copy()</div>
<div class="line"><span class="lineno">  537</span>    X_2[:, np.logical_not(support)] = 0</div>
<div class="line"><span class="lineno">  538</span>    assert_array_equal(X_2, univariate_filter.inverse_transform(X_r))</div>
<div class="line"><span class="lineno">  539</span>    <span class="comment"># Check inverse_transform respects dtype</span></div>
<div class="line"><span class="lineno">  540</span>    assert_array_equal(</div>
<div class="line"><span class="lineno">  541</span>        X_2.astype(bool), univariate_filter.inverse_transform(X_r.astype(bool))</div>
<div class="line"><span class="lineno">  542</span>    )</div>
<div class="line"><span class="lineno">  543</span> </div>
<div class="line"><span class="lineno">  544</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a18991433d6be7ea06b23c056dcc3ba2a" name="a18991433d6be7ea06b23c056dcc3ba2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18991433d6be7ea06b23c056dcc3ba2a">&#9670;&#160;</a></span>test_select_percentile_regression_full()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_select_percentile_regression_full </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  545</span><span class="keyword">def </span>test_select_percentile_regression_full():</div>
<div class="line"><span class="lineno">  546</span>    <span class="comment"># Test whether the relative univariate feature selection</span></div>
<div class="line"><span class="lineno">  547</span>    <span class="comment"># selects all features when &#39;100%&#39; is asked.</span></div>
<div class="line"><span class="lineno">  548</span>    X, y = make_regression(</div>
<div class="line"><span class="lineno">  549</span>        n_samples=200, n_features=20, n_informative=5, shuffle=<span class="keyword">False</span>, random_state=0</div>
<div class="line"><span class="lineno">  550</span>    )</div>
<div class="line"><span class="lineno">  551</span> </div>
<div class="line"><span class="lineno">  552</span>    univariate_filter = SelectPercentile(f_regression, percentile=100)</div>
<div class="line"><span class="lineno">  553</span>    X_r = univariate_filter.fit(X, y).transform(X)</div>
<div class="line"><span class="lineno">  554</span>    assert_best_scores_kept(univariate_filter)</div>
<div class="line"><span class="lineno">  555</span>    X_r2 = (</div>
<div class="line"><span class="lineno">  556</span>        GenericUnivariateSelect(f_regression, mode=<span class="stringliteral">&quot;percentile&quot;</span>, param=100)</div>
<div class="line"><span class="lineno">  557</span>        .fit(X, y)</div>
<div class="line"><span class="lineno">  558</span>        .transform(X)</div>
<div class="line"><span class="lineno">  559</span>    )</div>
<div class="line"><span class="lineno">  560</span>    assert_array_equal(X_r, X_r2)</div>
<div class="line"><span class="lineno">  561</span>    support = univariate_filter.get_support()</div>
<div class="line"><span class="lineno">  562</span>    gtruth = np.ones(20)</div>
<div class="line"><span class="lineno">  563</span>    assert_array_equal(support, gtruth)</div>
<div class="line"><span class="lineno">  564</span> </div>
<div class="line"><span class="lineno">  565</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af68d82d0959c21ba0dae32efe48e3728" name="af68d82d0959c21ba0dae32efe48e3728"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af68d82d0959c21ba0dae32efe48e3728">&#9670;&#160;</a></span>test_selectkbest_tiebreaking()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_selectkbest_tiebreaking </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  731</span><span class="keyword">def </span>test_selectkbest_tiebreaking():</div>
<div class="line"><span class="lineno">  732</span>    <span class="comment"># Test whether SelectKBest actually selects k features in case of ties.</span></div>
<div class="line"><span class="lineno">  733</span>    <span class="comment"># Prior to 0.11, SelectKBest would return more features than requested.</span></div>
<div class="line"><span class="lineno">  734</span>    Xs = [[0, 1, 1], [0, 0, 1], [1, 0, 0], [1, 1, 0]]</div>
<div class="line"><span class="lineno">  735</span>    y = [1]</div>
<div class="line"><span class="lineno">  736</span>    dummy_score = <span class="keyword">lambda</span> X, y: (X[0], X[0])</div>
<div class="line"><span class="lineno">  737</span>    <span class="keywordflow">for</span> X <span class="keywordflow">in</span> Xs:</div>
<div class="line"><span class="lineno">  738</span>        sel = SelectKBest(dummy_score, k=1)</div>
<div class="line"><span class="lineno">  739</span>        X1 = ignore_warnings(sel.fit_transform)([X], y)</div>
<div class="line"><span class="lineno">  740</span>        <span class="keyword">assert</span> X1.shape[1] == 1</div>
<div class="line"><span class="lineno">  741</span>        assert_best_scores_kept(sel)</div>
<div class="line"><span class="lineno">  742</span> </div>
<div class="line"><span class="lineno">  743</span>        sel = SelectKBest(dummy_score, k=2)</div>
<div class="line"><span class="lineno">  744</span>        X2 = ignore_warnings(sel.fit_transform)([X], y)</div>
<div class="line"><span class="lineno">  745</span>        <span class="keyword">assert</span> X2.shape[1] == 2</div>
<div class="line"><span class="lineno">  746</span>        assert_best_scores_kept(sel)</div>
<div class="line"><span class="lineno">  747</span> </div>
<div class="line"><span class="lineno">  748</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a452b4e0abef71f0d7edfeb41ecba25ff" name="a452b4e0abef71f0d7edfeb41ecba25ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a452b4e0abef71f0d7edfeb41ecba25ff">&#9670;&#160;</a></span>test_selectpercentile_tiebreaking()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_selectpercentile_tiebreaking </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  749</span><span class="keyword">def </span>test_selectpercentile_tiebreaking():</div>
<div class="line"><span class="lineno">  750</span>    <span class="comment"># Test if SelectPercentile selects the right n_features in case of ties.</span></div>
<div class="line"><span class="lineno">  751</span>    Xs = [[0, 1, 1], [0, 0, 1], [1, 0, 0], [1, 1, 0]]</div>
<div class="line"><span class="lineno">  752</span>    y = [1]</div>
<div class="line"><span class="lineno">  753</span>    dummy_score = <span class="keyword">lambda</span> X, y: (X[0], X[0])</div>
<div class="line"><span class="lineno">  754</span>    <span class="keywordflow">for</span> X <span class="keywordflow">in</span> Xs:</div>
<div class="line"><span class="lineno">  755</span>        sel = SelectPercentile(dummy_score, percentile=34)</div>
<div class="line"><span class="lineno">  756</span>        X1 = ignore_warnings(sel.fit_transform)([X], y)</div>
<div class="line"><span class="lineno">  757</span>        <span class="keyword">assert</span> X1.shape[1] == 1</div>
<div class="line"><span class="lineno">  758</span>        assert_best_scores_kept(sel)</div>
<div class="line"><span class="lineno">  759</span> </div>
<div class="line"><span class="lineno">  760</span>        sel = SelectPercentile(dummy_score, percentile=67)</div>
<div class="line"><span class="lineno">  761</span>        X2 = ignore_warnings(sel.fit_transform)([X], y)</div>
<div class="line"><span class="lineno">  762</span>        <span class="keyword">assert</span> X2.shape[1] == 2</div>
<div class="line"><span class="lineno">  763</span>        assert_best_scores_kept(sel)</div>
<div class="line"><span class="lineno">  764</span> </div>
<div class="line"><span class="lineno">  765</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac68982fada2a221801b307de54b3ba66" name="ac68982fada2a221801b307de54b3ba66"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac68982fada2a221801b307de54b3ba66">&#9670;&#160;</a></span>test_tied_pvalues()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_tied_pvalues </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  766</span><span class="keyword">def </span>test_tied_pvalues():</div>
<div class="line"><span class="lineno">  767</span>    <span class="comment"># Test whether k-best and percentiles work with tied pvalues from chi2.</span></div>
<div class="line"><span class="lineno">  768</span>    <span class="comment"># chi2 will return the same p-values for the following features, but it</span></div>
<div class="line"><span class="lineno">  769</span>    <span class="comment"># will return different scores.</span></div>
<div class="line"><span class="lineno">  770</span>    X0 = np.array([[10000, 9999, 9998], [1, 1, 1]])</div>
<div class="line"><span class="lineno">  771</span>    y = [0, 1]</div>
<div class="line"><span class="lineno">  772</span> </div>
<div class="line"><span class="lineno">  773</span>    <span class="keywordflow">for</span> perm <span class="keywordflow">in</span> itertools.permutations((0, 1, 2)):</div>
<div class="line"><span class="lineno">  774</span>        X = X0[:, perm]</div>
<div class="line"><span class="lineno">  775</span>        Xt = SelectKBest(chi2, k=2).fit_transform(X, y)</div>
<div class="line"><span class="lineno">  776</span>        <span class="keyword">assert</span> Xt.shape == (2, 2)</div>
<div class="line"><span class="lineno">  777</span>        <span class="keyword">assert</span> 9998 <span class="keywordflow">not</span> <span class="keywordflow">in</span> Xt</div>
<div class="line"><span class="lineno">  778</span> </div>
<div class="line"><span class="lineno">  779</span>        Xt = SelectPercentile(chi2, percentile=67).fit_transform(X, y)</div>
<div class="line"><span class="lineno">  780</span>        <span class="keyword">assert</span> Xt.shape == (2, 2)</div>
<div class="line"><span class="lineno">  781</span>        <span class="keyword">assert</span> 9998 <span class="keywordflow">not</span> <span class="keywordflow">in</span> Xt</div>
<div class="line"><span class="lineno">  782</span> </div>
<div class="line"><span class="lineno">  783</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9df067c1e957c1b110abc3d3a2f582e3" name="a9df067c1e957c1b110abc3d3a2f582e3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9df067c1e957c1b110abc3d3a2f582e3">&#9670;&#160;</a></span>test_tied_scores()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection.tests.test_feature_select.test_tied_scores </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  799</span><span class="keyword">def </span>test_tied_scores():</div>
<div class="line"><span class="lineno">  800</span>    <span class="comment"># Test for stable sorting in k-best with tied scores.</span></div>
<div class="line"><span class="lineno">  801</span>    X_train = np.array([[0, 0, 0], [1, 1, 1]])</div>
<div class="line"><span class="lineno">  802</span>    y_train = [0, 1]</div>
<div class="line"><span class="lineno">  803</span> </div>
<div class="line"><span class="lineno">  804</span>    <span class="keywordflow">for</span> n_features <span class="keywordflow">in</span> [1, 2, 3]:</div>
<div class="line"><span class="lineno">  805</span>        sel = SelectKBest(chi2, k=n_features).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  806</span>        X_test = sel.transform([[0, 1, 2]])</div>
<div class="line"><span class="lineno">  807</span>        assert_array_equal(X_test[0], np.arange(3)[-n_features:])</div>
<div class="line"><span class="lineno">  808</span> </div>
<div class="line"><span class="lineno">  809</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
