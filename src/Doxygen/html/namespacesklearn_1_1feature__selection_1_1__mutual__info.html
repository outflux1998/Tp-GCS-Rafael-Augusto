<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.feature_selection._mutual_info Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1feature__selection.html">feature_selection</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1feature__selection_1_1__mutual__info.html">_mutual_info</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.feature_selection._mutual_info Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ac49db445ee6667fff290cbf8dd8064dd" id="r_ac49db445ee6667fff290cbf8dd8064dd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1__mutual__info.html#ac49db445ee6667fff290cbf8dd8064dd">_compute_mi_cc</a> (x, y, n_neighbors)</td></tr>
<tr class="separator:ac49db445ee6667fff290cbf8dd8064dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afdc6bada0efceac33737bb24a53372dc" id="r_afdc6bada0efceac33737bb24a53372dc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1__mutual__info.html#afdc6bada0efceac33737bb24a53372dc">_compute_mi_cd</a> (c, <a class="el" href="__lapack__subroutines_8h.html#a4c293bae27b15a76659be28378992185">d</a>, n_neighbors)</td></tr>
<tr class="separator:afdc6bada0efceac33737bb24a53372dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e69d7fc9b9e2deea6ff28e1d290f51b" id="r_a9e69d7fc9b9e2deea6ff28e1d290f51b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1__mutual__info.html#a9e69d7fc9b9e2deea6ff28e1d290f51b">_compute_mi</a> (x, y, x_discrete, y_discrete, n_neighbors=3)</td></tr>
<tr class="separator:a9e69d7fc9b9e2deea6ff28e1d290f51b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c1ae1b37d124e11e30aed8ebed389de" id="r_a0c1ae1b37d124e11e30aed8ebed389de"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1__mutual__info.html#a0c1ae1b37d124e11e30aed8ebed389de">_iterate_columns</a> (X, columns=None)</td></tr>
<tr class="separator:a0c1ae1b37d124e11e30aed8ebed389de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a72daf080d6b58db9f077eba05bc63f" id="r_a8a72daf080d6b58db9f077eba05bc63f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1__mutual__info.html#a8a72daf080d6b58db9f077eba05bc63f">_estimate_mi</a> (X, y, discrete_features=&quot;auto&quot;, discrete_target=False, n_neighbors=3, copy=True, random_state=None)</td></tr>
<tr class="separator:a8a72daf080d6b58db9f077eba05bc63f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a15a1dc1bfa2bdd07e4bf901dd8275758" id="r_a15a1dc1bfa2bdd07e4bf901dd8275758"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1__mutual__info.html#a15a1dc1bfa2bdd07e4bf901dd8275758">mutual_info_regression</a> (X, y, *discrete_features=&quot;auto&quot;, n_neighbors=3, copy=True, random_state=None)</td></tr>
<tr class="separator:a15a1dc1bfa2bdd07e4bf901dd8275758"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5446c2b8f3f48cd50046173db566f34d" id="r_a5446c2b8f3f48cd50046173db566f34d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1feature__selection_1_1__mutual__info.html#a5446c2b8f3f48cd50046173db566f34d">mutual_info_classif</a> (X, y, *discrete_features=&quot;auto&quot;, n_neighbors=3, copy=True, random_state=None)</td></tr>
<tr class="separator:a5446c2b8f3f48cd50046173db566f34d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a9e69d7fc9b9e2deea6ff28e1d290f51b" name="a9e69d7fc9b9e2deea6ff28e1d290f51b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e69d7fc9b9e2deea6ff28e1d290f51b">&#9670;&#160;</a></span>_compute_mi()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection._mutual_info._compute_mi </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x_discrete</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_discrete</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_neighbors</em> = <code>3</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute mutual information between two variables.

This is a simple wrapper which selects a proper function to call based on
whether `x` and `y` are discrete or not.
</pre> <div class="fragment"><div class="line"><span class="lineno">  152</span><span class="keyword">def </span>_compute_mi(x, y, x_discrete, y_discrete, n_neighbors=3):</div>
<div class="line"><span class="lineno">  153</span>    <span class="stringliteral">&quot;&quot;&quot;Compute mutual information between two variables.</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">    This is a simple wrapper which selects a proper function to call based on</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">    whether `x` and `y` are discrete or not.</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  158</span>    <span class="keywordflow">if</span> x_discrete <span class="keywordflow">and</span> y_discrete:</div>
<div class="line"><span class="lineno">  159</span>        <span class="keywordflow">return</span> mutual_info_score(x, y)</div>
<div class="line"><span class="lineno">  160</span>    <span class="keywordflow">elif</span> x_discrete <span class="keywordflow">and</span> <span class="keywordflow">not</span> y_discrete:</div>
<div class="line"><span class="lineno">  161</span>        <span class="keywordflow">return</span> _compute_mi_cd(y, x, n_neighbors)</div>
<div class="line"><span class="lineno">  162</span>    <span class="keywordflow">elif</span> <span class="keywordflow">not</span> x_discrete <span class="keywordflow">and</span> y_discrete:</div>
<div class="line"><span class="lineno">  163</span>        <span class="keywordflow">return</span> _compute_mi_cd(x, y, n_neighbors)</div>
<div class="line"><span class="lineno">  164</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  165</span>        <span class="keywordflow">return</span> _compute_mi_cc(x, y, n_neighbors)</div>
<div class="line"><span class="lineno">  166</span> </div>
<div class="line"><span class="lineno">  167</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac49db445ee6667fff290cbf8dd8064dd" name="ac49db445ee6667fff290cbf8dd8064dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac49db445ee6667fff290cbf8dd8064dd">&#9670;&#160;</a></span>_compute_mi_cc()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection._mutual_info._compute_mi_cc </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_neighbors</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute mutual information between two continuous variables.

Parameters
----------
x, y : ndarray, shape (n_samples,)
    Samples of two continuous random variables, must have an identical
    shape.

n_neighbors : int
    Number of nearest neighbors to search for each point, see [1]_.

Returns
-------
mi : float
    Estimated mutual information. If it turned out to be negative it is
    replace by 0.

Notes
-----
True mutual information can't be negative. If its estimate by a numerical
method is negative, it means (providing the method is adequate) that the
mutual information is close to 0 and replacing it by 0 is a reasonable
strategy.

References
----------
.. [1] A. Kraskov, H. Stogbauer and P. Grassberger, "Estimating mutual
       information". Phys. Rev. E 69, 2004.
</pre> <div class="fragment"><div class="line"><span class="lineno">   16</span><span class="keyword">def </span>_compute_mi_cc(x, y, n_neighbors):</div>
<div class="line"><span class="lineno">   17</span>    <span class="stringliteral">&quot;&quot;&quot;Compute mutual information between two continuous variables.</span></div>
<div class="line"><span class="lineno">   18</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   19</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   20</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   21</span><span class="stringliteral">    x, y : ndarray, shape (n_samples,)</span></div>
<div class="line"><span class="lineno">   22</span><span class="stringliteral">        Samples of two continuous random variables, must have an identical</span></div>
<div class="line"><span class="lineno">   23</span><span class="stringliteral">        shape.</span></div>
<div class="line"><span class="lineno">   24</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   25</span><span class="stringliteral">    n_neighbors : int</span></div>
<div class="line"><span class="lineno">   26</span><span class="stringliteral">        Number of nearest neighbors to search for each point, see [1]_.</span></div>
<div class="line"><span class="lineno">   27</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   28</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral">    mi : float</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral">        Estimated mutual information. If it turned out to be negative it is</span></div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">        replace by 0.</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">    True mutual information can&#39;t be negative. If its estimate by a numerical</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral">    method is negative, it means (providing the method is adequate) that the</span></div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral">    mutual information is close to 0 and replacing it by 0 is a reasonable</span></div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">    strategy.</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">    .. [1] A. Kraskov, H. Stogbauer and P. Grassberger, &quot;Estimating mutual</span></div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">           information&quot;. Phys. Rev. E 69, 2004.</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   46</span>    n_samples = x.size</div>
<div class="line"><span class="lineno">   47</span> </div>
<div class="line"><span class="lineno">   48</span>    x = x.reshape((-1, 1))</div>
<div class="line"><span class="lineno">   49</span>    y = y.reshape((-1, 1))</div>
<div class="line"><span class="lineno">   50</span>    xy = np.hstack((x, y))</div>
<div class="line"><span class="lineno">   51</span> </div>
<div class="line"><span class="lineno">   52</span>    <span class="comment"># Here we rely on NearestNeighbors to select the fastest algorithm.</span></div>
<div class="line"><span class="lineno">   53</span>    nn = NearestNeighbors(metric=<span class="stringliteral">&quot;chebyshev&quot;</span>, n_neighbors=n_neighbors)</div>
<div class="line"><span class="lineno">   54</span> </div>
<div class="line"><span class="lineno">   55</span>    nn.fit(xy)</div>
<div class="line"><span class="lineno">   56</span>    radius = nn.kneighbors()[0]</div>
<div class="line"><span class="lineno">   57</span>    radius = np.nextafter(radius[:, -1], 0)</div>
<div class="line"><span class="lineno">   58</span> </div>
<div class="line"><span class="lineno">   59</span>    <span class="comment"># KDTree is explicitly fit to allow for the querying of number of</span></div>
<div class="line"><span class="lineno">   60</span>    <span class="comment"># neighbors within a specified radius</span></div>
<div class="line"><span class="lineno">   61</span>    kd = KDTree(x, metric=<span class="stringliteral">&quot;chebyshev&quot;</span>)</div>
<div class="line"><span class="lineno">   62</span>    nx = kd.query_radius(x, radius, count_only=<span class="keyword">True</span>, return_distance=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">   63</span>    nx = np.array(nx) - 1.0</div>
<div class="line"><span class="lineno">   64</span> </div>
<div class="line"><span class="lineno">   65</span>    kd = KDTree(y, metric=<span class="stringliteral">&quot;chebyshev&quot;</span>)</div>
<div class="line"><span class="lineno">   66</span>    ny = kd.query_radius(y, radius, count_only=<span class="keyword">True</span>, return_distance=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">   67</span>    ny = np.array(ny) - 1.0</div>
<div class="line"><span class="lineno">   68</span> </div>
<div class="line"><span class="lineno">   69</span>    mi = (</div>
<div class="line"><span class="lineno">   70</span>        digamma(n_samples)</div>
<div class="line"><span class="lineno">   71</span>        + digamma(n_neighbors)</div>
<div class="line"><span class="lineno">   72</span>        - np.mean(digamma(nx + 1))</div>
<div class="line"><span class="lineno">   73</span>        - np.mean(digamma(ny + 1))</div>
<div class="line"><span class="lineno">   74</span>    )</div>
<div class="line"><span class="lineno">   75</span> </div>
<div class="line"><span class="lineno">   76</span>    <span class="keywordflow">return</span> max(0, mi)</div>
<div class="line"><span class="lineno">   77</span> </div>
<div class="line"><span class="lineno">   78</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afdc6bada0efceac33737bb24a53372dc" name="afdc6bada0efceac33737bb24a53372dc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afdc6bada0efceac33737bb24a53372dc">&#9670;&#160;</a></span>_compute_mi_cd()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection._mutual_info._compute_mi_cd </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>c</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>d</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_neighbors</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute mutual information between continuous and discrete variables.

Parameters
----------
c : ndarray, shape (n_samples,)
    Samples of a continuous random variable.

d : ndarray, shape (n_samples,)
    Samples of a discrete random variable.

n_neighbors : int
    Number of nearest neighbors to search for each point, see [1]_.

Returns
-------
mi : float
    Estimated mutual information. If it turned out to be negative it is
    replace by 0.

Notes
-----
True mutual information can't be negative. If its estimate by a numerical
method is negative, it means (providing the method is adequate) that the
mutual information is close to 0 and replacing it by 0 is a reasonable
strategy.

References
----------
.. [1] B. C. Ross "Mutual Information between Discrete and Continuous
   Data Sets". PLoS ONE 9(2), 2014.
</pre> <div class="fragment"><div class="line"><span class="lineno">   79</span><span class="keyword">def </span>_compute_mi_cd(c, d, n_neighbors):</div>
<div class="line"><span class="lineno">   80</span>    <span class="stringliteral">&quot;&quot;&quot;Compute mutual information between continuous and discrete variables.</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral">    c : ndarray, shape (n_samples,)</span></div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">        Samples of a continuous random variable.</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">    d : ndarray, shape (n_samples,)</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">        Samples of a discrete random variable.</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">    n_neighbors : int</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">        Number of nearest neighbors to search for each point, see [1]_.</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral">    mi : float</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral">        Estimated mutual information. If it turned out to be negative it is</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral">        replace by 0.</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">    True mutual information can&#39;t be negative. If its estimate by a numerical</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral">    method is negative, it means (providing the method is adequate) that the</span></div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">    mutual information is close to 0 and replacing it by 0 is a reasonable</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">    strategy.</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">    .. [1] B. C. Ross &quot;Mutual Information between Discrete and Continuous</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">       Data Sets&quot;. PLoS ONE 9(2), 2014.</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  111</span>    n_samples = c.shape[0]</div>
<div class="line"><span class="lineno">  112</span>    c = c.reshape((-1, 1))</div>
<div class="line"><span class="lineno">  113</span> </div>
<div class="line"><span class="lineno">  114</span>    radius = np.empty(n_samples)</div>
<div class="line"><span class="lineno">  115</span>    label_counts = np.empty(n_samples)</div>
<div class="line"><span class="lineno">  116</span>    k_all = np.empty(n_samples)</div>
<div class="line"><span class="lineno">  117</span>    nn = NearestNeighbors()</div>
<div class="line"><span class="lineno">  118</span>    <span class="keywordflow">for</span> label <span class="keywordflow">in</span> np.unique(d):</div>
<div class="line"><span class="lineno">  119</span>        mask = d == label</div>
<div class="line"><span class="lineno">  120</span>        count = np.sum(mask)</div>
<div class="line"><span class="lineno">  121</span>        <span class="keywordflow">if</span> count &gt; 1:</div>
<div class="line"><span class="lineno">  122</span>            k = min(n_neighbors, count - 1)</div>
<div class="line"><span class="lineno">  123</span>            nn.set_params(n_neighbors=k)</div>
<div class="line"><span class="lineno">  124</span>            nn.fit(c[mask])</div>
<div class="line"><span class="lineno">  125</span>            r = nn.kneighbors()[0]</div>
<div class="line"><span class="lineno">  126</span>            radius[mask] = np.nextafter(r[:, -1], 0)</div>
<div class="line"><span class="lineno">  127</span>            k_all[mask] = k</div>
<div class="line"><span class="lineno">  128</span>        label_counts[mask] = count</div>
<div class="line"><span class="lineno">  129</span> </div>
<div class="line"><span class="lineno">  130</span>    <span class="comment"># Ignore points with unique labels.</span></div>
<div class="line"><span class="lineno">  131</span>    mask = label_counts &gt; 1</div>
<div class="line"><span class="lineno">  132</span>    n_samples = np.sum(mask)</div>
<div class="line"><span class="lineno">  133</span>    label_counts = label_counts[mask]</div>
<div class="line"><span class="lineno">  134</span>    k_all = k_all[mask]</div>
<div class="line"><span class="lineno">  135</span>    c = c[mask]</div>
<div class="line"><span class="lineno">  136</span>    radius = radius[mask]</div>
<div class="line"><span class="lineno">  137</span> </div>
<div class="line"><span class="lineno">  138</span>    kd = KDTree(c)</div>
<div class="line"><span class="lineno">  139</span>    m_all = kd.query_radius(c, radius, count_only=<span class="keyword">True</span>, return_distance=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  140</span>    m_all = np.array(m_all)</div>
<div class="line"><span class="lineno">  141</span> </div>
<div class="line"><span class="lineno">  142</span>    mi = (</div>
<div class="line"><span class="lineno">  143</span>        digamma(n_samples)</div>
<div class="line"><span class="lineno">  144</span>        + np.mean(digamma(k_all))</div>
<div class="line"><span class="lineno">  145</span>        - np.mean(digamma(label_counts))</div>
<div class="line"><span class="lineno">  146</span>        - np.mean(digamma(m_all))</div>
<div class="line"><span class="lineno">  147</span>    )</div>
<div class="line"><span class="lineno">  148</span> </div>
<div class="line"><span class="lineno">  149</span>    <span class="keywordflow">return</span> max(0, mi)</div>
<div class="line"><span class="lineno">  150</span> </div>
<div class="line"><span class="lineno">  151</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8a72daf080d6b58db9f077eba05bc63f" name="a8a72daf080d6b58db9f077eba05bc63f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a72daf080d6b58db9f077eba05bc63f">&#9670;&#160;</a></span>_estimate_mi()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection._mutual_info._estimate_mi </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>discrete_features</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>discrete_target</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_neighbors</em> = <code>3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>copy</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Estimate mutual information between the features and the target.

Parameters
----------
X : array-like or sparse matrix, shape (n_samples, n_features)
    Feature matrix.

y : array-like of shape (n_samples,)
    Target vector.

discrete_features : {'auto', bool, array-like}, default='auto'
    If bool, then determines whether to consider all features discrete
    or continuous. If array, then it should be either a boolean mask
    with shape (n_features,) or array with indices of discrete features.
    If 'auto', it is assigned to False for dense `X` and to True for
    sparse `X`.

discrete_target : bool, default=False
    Whether to consider `y` as a discrete variable.

n_neighbors : int, default=3
    Number of neighbors to use for MI estimation for continuous variables,
    see [1]_ and [2]_. Higher values reduce variance of the estimation, but
    could introduce a bias.

copy : bool, default=True
    Whether to make a copy of the given data. If set to False, the initial
    data will be overwritten.

random_state : int, RandomState instance or None, default=None
    Determines random number generation for adding small noise to
    continuous variables in order to remove repeated values.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Returns
-------
mi : ndarray, shape (n_features,)
    Estimated mutual information between each feature and the target.
    A negative value will be replaced by 0.

References
----------
.. [1] A. Kraskov, H. Stogbauer and P. Grassberger, "Estimating mutual
       information". Phys. Rev. E 69, 2004.
.. [2] B. C. Ross "Mutual Information between Discrete and Continuous
       Data Sets". PLoS ONE 9(2), 2014.
</pre> <div class="fragment"><div class="line"><span class="lineno">  206</span>):</div>
<div class="line"><span class="lineno">  207</span>    <span class="stringliteral">&quot;&quot;&quot;Estimate mutual information between the features and the target.</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">    X : array-like or sparse matrix, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">        Feature matrix.</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">    y : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">        Target vector.</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">    discrete_features : {&#39;auto&#39;, bool, array-like}, default=&#39;auto&#39;</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">        If bool, then determines whether to consider all features discrete</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">        or continuous. If array, then it should be either a boolean mask</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">        with shape (n_features,) or array with indices of discrete features.</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">        If &#39;auto&#39;, it is assigned to False for dense `X` and to True for</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">        sparse `X`.</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">    discrete_target : bool, default=False</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">        Whether to consider `y` as a discrete variable.</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">    n_neighbors : int, default=3</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">        Number of neighbors to use for MI estimation for continuous variables,</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">        see [1]_ and [2]_. Higher values reduce variance of the estimation, but</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">        could introduce a bias.</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">    copy : bool, default=True</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">        Whether to make a copy of the given data. If set to False, the initial</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">        data will be overwritten.</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">    random_state : int, RandomState instance or None, default=None</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">        Determines random number generation for adding small noise to</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">        continuous variables in order to remove repeated values.</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        Pass an int for reproducible results across multiple function calls.</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">    mi : ndarray, shape (n_features,)</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">        Estimated mutual information between each feature and the target.</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">        A negative value will be replaced by 0.</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">    .. [1] A. Kraskov, H. Stogbauer and P. Grassberger, &quot;Estimating mutual</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">           information&quot;. Phys. Rev. E 69, 2004.</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">    .. [2] B. C. Ross &quot;Mutual Information between Discrete and Continuous</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">           Data Sets&quot;. PLoS ONE 9(2), 2014.</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  255</span>    X, y = check_X_y(X, y, accept_sparse=<span class="stringliteral">&quot;csc&quot;</span>, y_numeric=<span class="keywordflow">not</span> discrete_target)</div>
<div class="line"><span class="lineno">  256</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  257</span> </div>
<div class="line"><span class="lineno">  258</span>    <span class="keywordflow">if</span> isinstance(discrete_features, (str, bool)):</div>
<div class="line"><span class="lineno">  259</span>        <span class="keywordflow">if</span> isinstance(discrete_features, str):</div>
<div class="line"><span class="lineno">  260</span>            <span class="keywordflow">if</span> discrete_features == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  261</span>                discrete_features = issparse(X)</div>
<div class="line"><span class="lineno">  262</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  263</span>                <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Invalid string value for discrete_features.&quot;</span>)</div>
<div class="line"><span class="lineno">  264</span>        discrete_mask = np.empty(n_features, dtype=bool)</div>
<div class="line"><span class="lineno">  265</span>        discrete_mask.fill(discrete_features)</div>
<div class="line"><span class="lineno">  266</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  267</span>        discrete_features = check_array(discrete_features, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  268</span>        <span class="keywordflow">if</span> discrete_features.dtype != <span class="stringliteral">&quot;bool&quot;</span>:</div>
<div class="line"><span class="lineno">  269</span>            discrete_mask = np.zeros(n_features, dtype=bool)</div>
<div class="line"><span class="lineno">  270</span>            discrete_mask[discrete_features] = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  271</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  272</span>            discrete_mask = discrete_features</div>
<div class="line"><span class="lineno">  273</span> </div>
<div class="line"><span class="lineno">  274</span>    continuous_mask = ~discrete_mask</div>
<div class="line"><span class="lineno">  275</span>    <span class="keywordflow">if</span> np.any(continuous_mask) <span class="keywordflow">and</span> issparse(X):</div>
<div class="line"><span class="lineno">  276</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Sparse matrix `X` can&#39;t have continuous features.&quot;</span>)</div>
<div class="line"><span class="lineno">  277</span> </div>
<div class="line"><span class="lineno">  278</span>    rng = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  279</span>    <span class="keywordflow">if</span> np.any(continuous_mask):</div>
<div class="line"><span class="lineno">  280</span>        <span class="keywordflow">if</span> copy:</div>
<div class="line"><span class="lineno">  281</span>            X = X.copy()</div>
<div class="line"><span class="lineno">  282</span> </div>
<div class="line"><span class="lineno">  283</span>        X[:, continuous_mask] = scale(</div>
<div class="line"><span class="lineno">  284</span>            X[:, continuous_mask], with_mean=<span class="keyword">False</span>, copy=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  285</span>        )</div>
<div class="line"><span class="lineno">  286</span> </div>
<div class="line"><span class="lineno">  287</span>        <span class="comment"># Add small noise to continuous features as advised in Kraskov et. al.</span></div>
<div class="line"><span class="lineno">  288</span>        X = X.astype(np.float64, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  289</span>        means = np.maximum(1, np.mean(np.abs(X[:, continuous_mask]), axis=0))</div>
<div class="line"><span class="lineno">  290</span>        X[:, continuous_mask] += (</div>
<div class="line"><span class="lineno">  291</span>            1e-10</div>
<div class="line"><span class="lineno">  292</span>            * means</div>
<div class="line"><span class="lineno">  293</span>            * rng.standard_normal(size=(n_samples, np.sum(continuous_mask)))</div>
<div class="line"><span class="lineno">  294</span>        )</div>
<div class="line"><span class="lineno">  295</span> </div>
<div class="line"><span class="lineno">  296</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> discrete_target:</div>
<div class="line"><span class="lineno">  297</span>        y = scale(y, with_mean=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  298</span>        y += (</div>
<div class="line"><span class="lineno">  299</span>            1e-10</div>
<div class="line"><span class="lineno">  300</span>            * np.maximum(1, np.mean(np.abs(y)))</div>
<div class="line"><span class="lineno">  301</span>            * rng.standard_normal(size=n_samples)</div>
<div class="line"><span class="lineno">  302</span>        )</div>
<div class="line"><span class="lineno">  303</span> </div>
<div class="line"><span class="lineno">  304</span>    mi = [</div>
<div class="line"><span class="lineno">  305</span>        _compute_mi(x, y, discrete_feature, discrete_target, n_neighbors)</div>
<div class="line"><span class="lineno">  306</span>        <span class="keywordflow">for</span> x, discrete_feature <span class="keywordflow">in</span> zip(_iterate_columns(X), discrete_mask)</div>
<div class="line"><span class="lineno">  307</span>    ]</div>
<div class="line"><span class="lineno">  308</span> </div>
<div class="line"><span class="lineno">  309</span>    <span class="keywordflow">return</span> np.array(mi)</div>
<div class="line"><span class="lineno">  310</span> </div>
<div class="line"><span class="lineno">  311</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0c1ae1b37d124e11e30aed8ebed389de" name="a0c1ae1b37d124e11e30aed8ebed389de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c1ae1b37d124e11e30aed8ebed389de">&#9670;&#160;</a></span>_iterate_columns()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection._mutual_info._iterate_columns </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>columns</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Iterate over columns of a matrix.

Parameters
----------
X : ndarray or csc_matrix, shape (n_samples, n_features)
    Matrix over which to iterate.

columns : iterable or None, default=None
    Indices of columns to iterate over. If None, iterate over all columns.

Yields
------
x : ndarray, shape (n_samples,)
    Columns of `X` in dense format.
</pre> <div class="fragment"><div class="line"><span class="lineno">  168</span><span class="keyword">def </span>_iterate_columns(X, columns=None):</div>
<div class="line"><span class="lineno">  169</span>    <span class="stringliteral">&quot;&quot;&quot;Iterate over columns of a matrix.</span></div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">    X : ndarray or csc_matrix, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">        Matrix over which to iterate.</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">    columns : iterable or None, default=None</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">        Indices of columns to iterate over. If None, iterate over all columns.</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">    Yields</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">    ------</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">    x : ndarray, shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">        Columns of `X` in dense format.</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  184</span>    <span class="keywordflow">if</span> columns <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  185</span>        columns = range(X.shape[1])</div>
<div class="line"><span class="lineno">  186</span> </div>
<div class="line"><span class="lineno">  187</span>    <span class="keywordflow">if</span> issparse(X):</div>
<div class="line"><span class="lineno">  188</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> columns:</div>
<div class="line"><span class="lineno">  189</span>            x = np.zeros(X.shape[0])</div>
<div class="line"><span class="lineno">  190</span>            start_ptr, end_ptr = X.indptr[i], X.indptr[i + 1]</div>
<div class="line"><span class="lineno">  191</span>            x[X.indices[start_ptr:end_ptr]] = X.data[start_ptr:end_ptr]</div>
<div class="line"><span class="lineno">  192</span>            <span class="keywordflow">yield</span> x</div>
<div class="line"><span class="lineno">  193</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  194</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> columns:</div>
<div class="line"><span class="lineno">  195</span>            <span class="keywordflow">yield</span> X[:, i]</div>
<div class="line"><span class="lineno">  196</span> </div>
<div class="line"><span class="lineno">  197</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5446c2b8f3f48cd50046173db566f34d" name="a5446c2b8f3f48cd50046173db566f34d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5446c2b8f3f48cd50046173db566f34d">&#9670;&#160;</a></span>mutual_info_classif()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection._mutual_info.mutual_info_classif </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>discrete_features</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_neighbors</em> = <code>3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>copy</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Estimate mutual information for a discrete target variable.

Mutual information (MI) [1]_ between two random variables is a non-negative
value, which measures the dependency between the variables. It is equal
to zero if and only if two random variables are independent, and higher
values mean higher dependency.

The function relies on nonparametric methods based on entropy estimation
from k-nearest neighbors distances as described in [2]_ and [3]_. Both
methods are based on the idea originally proposed in [4]_.

It can be used for univariate features selection, read more in the
:ref:`User Guide &lt;univariate_feature_selection&gt;`.

Parameters
----------
X : array-like or sparse matrix, shape (n_samples, n_features)
    Feature matrix.

y : array-like of shape (n_samples,)
    Target vector.

discrete_features : {'auto', bool, array-like}, default='auto'
    If bool, then determines whether to consider all features discrete
    or continuous. If array, then it should be either a boolean mask
    with shape (n_features,) or array with indices of discrete features.
    If 'auto', it is assigned to False for dense `X` and to True for
    sparse `X`.

n_neighbors : int, default=3
    Number of neighbors to use for MI estimation for continuous variables,
    see [2]_ and [3]_. Higher values reduce variance of the estimation, but
    could introduce a bias.

copy : bool, default=True
    Whether to make a copy of the given data. If set to False, the initial
    data will be overwritten.

random_state : int, RandomState instance or None, default=None
    Determines random number generation for adding small noise to
    continuous variables in order to remove repeated values.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Returns
-------
mi : ndarray, shape (n_features,)
    Estimated mutual information between each feature and the target.

Notes
-----
1. The term "discrete features" is used instead of naming them
   "categorical", because it describes the essence more accurately.
   For example, pixel intensities of an image are discrete features
   (but hardly categorical) and you will get better results if mark them
   as such. Also note, that treating a continuous variable as discrete and
   vice versa will usually give incorrect results, so be attentive about
   that.
2. True mutual information can't be negative. If its estimate turns out
   to be negative, it is replaced by zero.

References
----------
.. [1] `Mutual Information
       &lt;https://en.wikipedia.org/wiki/Mutual_information&gt;`_
       on Wikipedia.
.. [2] A. Kraskov, H. Stogbauer and P. Grassberger, "Estimating mutual
       information". Phys. Rev. E 69, 2004.
.. [3] B. C. Ross "Mutual Information between Discrete and Continuous
       Data Sets". PLoS ONE 9(2), 2014.
.. [4] L. F. Kozachenko, N. N. Leonenko, "Sample Estimate of the Entropy
       of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16
</pre> <div class="fragment"><div class="line"><span class="lineno">  393</span>):</div>
<div class="line"><span class="lineno">  394</span>    <span class="stringliteral">&quot;&quot;&quot;Estimate mutual information for a discrete target variable.</span></div>
<div class="line"><span class="lineno">  395</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  396</span><span class="stringliteral">    Mutual information (MI) [1]_ between two random variables is a non-negative</span></div>
<div class="line"><span class="lineno">  397</span><span class="stringliteral">    value, which measures the dependency between the variables. It is equal</span></div>
<div class="line"><span class="lineno">  398</span><span class="stringliteral">    to zero if and only if two random variables are independent, and higher</span></div>
<div class="line"><span class="lineno">  399</span><span class="stringliteral">    values mean higher dependency.</span></div>
<div class="line"><span class="lineno">  400</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral">    The function relies on nonparametric methods based on entropy estimation</span></div>
<div class="line"><span class="lineno">  402</span><span class="stringliteral">    from k-nearest neighbors distances as described in [2]_ and [3]_. Both</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral">    methods are based on the idea originally proposed in [4]_.</span></div>
<div class="line"><span class="lineno">  404</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral">    It can be used for univariate features selection, read more in the</span></div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">    :ref:`User Guide &lt;univariate_feature_selection&gt;`.</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral">    X : array-like or sparse matrix, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral">        Feature matrix.</span></div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral">    y : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  414</span><span class="stringliteral">        Target vector.</span></div>
<div class="line"><span class="lineno">  415</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral">    discrete_features : {&#39;auto&#39;, bool, array-like}, default=&#39;auto&#39;</span></div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral">        If bool, then determines whether to consider all features discrete</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">        or continuous. If array, then it should be either a boolean mask</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">        with shape (n_features,) or array with indices of discrete features.</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral">        If &#39;auto&#39;, it is assigned to False for dense `X` and to True for</span></div>
<div class="line"><span class="lineno">  421</span><span class="stringliteral">        sparse `X`.</span></div>
<div class="line"><span class="lineno">  422</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  423</span><span class="stringliteral">    n_neighbors : int, default=3</span></div>
<div class="line"><span class="lineno">  424</span><span class="stringliteral">        Number of neighbors to use for MI estimation for continuous variables,</span></div>
<div class="line"><span class="lineno">  425</span><span class="stringliteral">        see [2]_ and [3]_. Higher values reduce variance of the estimation, but</span></div>
<div class="line"><span class="lineno">  426</span><span class="stringliteral">        could introduce a bias.</span></div>
<div class="line"><span class="lineno">  427</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  428</span><span class="stringliteral">    copy : bool, default=True</span></div>
<div class="line"><span class="lineno">  429</span><span class="stringliteral">        Whether to make a copy of the given data. If set to False, the initial</span></div>
<div class="line"><span class="lineno">  430</span><span class="stringliteral">        data will be overwritten.</span></div>
<div class="line"><span class="lineno">  431</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  432</span><span class="stringliteral">    random_state : int, RandomState instance or None, default=None</span></div>
<div class="line"><span class="lineno">  433</span><span class="stringliteral">        Determines random number generation for adding small noise to</span></div>
<div class="line"><span class="lineno">  434</span><span class="stringliteral">        continuous variables in order to remove repeated values.</span></div>
<div class="line"><span class="lineno">  435</span><span class="stringliteral">        Pass an int for reproducible results across multiple function calls.</span></div>
<div class="line"><span class="lineno">  436</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  437</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  438</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  439</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  440</span><span class="stringliteral">    mi : ndarray, shape (n_features,)</span></div>
<div class="line"><span class="lineno">  441</span><span class="stringliteral">        Estimated mutual information between each feature and the target.</span></div>
<div class="line"><span class="lineno">  442</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  443</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  444</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  445</span><span class="stringliteral">    1. The term &quot;discrete features&quot; is used instead of naming them</span></div>
<div class="line"><span class="lineno">  446</span><span class="stringliteral">       &quot;categorical&quot;, because it describes the essence more accurately.</span></div>
<div class="line"><span class="lineno">  447</span><span class="stringliteral">       For example, pixel intensities of an image are discrete features</span></div>
<div class="line"><span class="lineno">  448</span><span class="stringliteral">       (but hardly categorical) and you will get better results if mark them</span></div>
<div class="line"><span class="lineno">  449</span><span class="stringliteral">       as such. Also note, that treating a continuous variable as discrete and</span></div>
<div class="line"><span class="lineno">  450</span><span class="stringliteral">       vice versa will usually give incorrect results, so be attentive about</span></div>
<div class="line"><span class="lineno">  451</span><span class="stringliteral">       that.</span></div>
<div class="line"><span class="lineno">  452</span><span class="stringliteral">    2. True mutual information can&#39;t be negative. If its estimate turns out</span></div>
<div class="line"><span class="lineno">  453</span><span class="stringliteral">       to be negative, it is replaced by zero.</span></div>
<div class="line"><span class="lineno">  454</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  455</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  456</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  457</span><span class="stringliteral">    .. [1] `Mutual Information</span></div>
<div class="line"><span class="lineno">  458</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/Mutual_information&gt;`_</span></div>
<div class="line"><span class="lineno">  459</span><span class="stringliteral">           on Wikipedia.</span></div>
<div class="line"><span class="lineno">  460</span><span class="stringliteral">    .. [2] A. Kraskov, H. Stogbauer and P. Grassberger, &quot;Estimating mutual</span></div>
<div class="line"><span class="lineno">  461</span><span class="stringliteral">           information&quot;. Phys. Rev. E 69, 2004.</span></div>
<div class="line"><span class="lineno">  462</span><span class="stringliteral">    .. [3] B. C. Ross &quot;Mutual Information between Discrete and Continuous</span></div>
<div class="line"><span class="lineno">  463</span><span class="stringliteral">           Data Sets&quot;. PLoS ONE 9(2), 2014.</span></div>
<div class="line"><span class="lineno">  464</span><span class="stringliteral">    .. [4] L. F. Kozachenko, N. N. Leonenko, &quot;Sample Estimate of the Entropy</span></div>
<div class="line"><span class="lineno">  465</span><span class="stringliteral">           of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16</span></div>
<div class="line"><span class="lineno">  466</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  467</span>    check_classification_targets(y)</div>
<div class="line"><span class="lineno">  468</span>    <span class="keywordflow">return</span> _estimate_mi(X, y, discrete_features, <span class="keyword">True</span>, n_neighbors, copy, random_state)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a15a1dc1bfa2bdd07e4bf901dd8275758" name="a15a1dc1bfa2bdd07e4bf901dd8275758"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a15a1dc1bfa2bdd07e4bf901dd8275758">&#9670;&#160;</a></span>mutual_info_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.feature_selection._mutual_info.mutual_info_regression </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>discrete_features</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_neighbors</em> = <code>3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>copy</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Estimate mutual information for a continuous target variable.

Mutual information (MI) [1]_ between two random variables is a non-negative
value, which measures the dependency between the variables. It is equal
to zero if and only if two random variables are independent, and higher
values mean higher dependency.

The function relies on nonparametric methods based on entropy estimation
from k-nearest neighbors distances as described in [2]_ and [3]_. Both
methods are based on the idea originally proposed in [4]_.

It can be used for univariate features selection, read more in the
:ref:`User Guide &lt;univariate_feature_selection&gt;`.

Parameters
----------
X : array-like or sparse matrix, shape (n_samples, n_features)
    Feature matrix.

y : array-like of shape (n_samples,)
    Target vector.

discrete_features : {'auto', bool, array-like}, default='auto'
    If bool, then determines whether to consider all features discrete
    or continuous. If array, then it should be either a boolean mask
    with shape (n_features,) or array with indices of discrete features.
    If 'auto', it is assigned to False for dense `X` and to True for
    sparse `X`.

n_neighbors : int, default=3
    Number of neighbors to use for MI estimation for continuous variables,
    see [2]_ and [3]_. Higher values reduce variance of the estimation, but
    could introduce a bias.

copy : bool, default=True
    Whether to make a copy of the given data. If set to False, the initial
    data will be overwritten.

random_state : int, RandomState instance or None, default=None
    Determines random number generation for adding small noise to
    continuous variables in order to remove repeated values.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Returns
-------
mi : ndarray, shape (n_features,)
    Estimated mutual information between each feature and the target.

Notes
-----
1. The term "discrete features" is used instead of naming them
   "categorical", because it describes the essence more accurately.
   For example, pixel intensities of an image are discrete features
   (but hardly categorical) and you will get better results if mark them
   as such. Also note, that treating a continuous variable as discrete and
   vice versa will usually give incorrect results, so be attentive about
   that.
2. True mutual information can't be negative. If its estimate turns out
   to be negative, it is replaced by zero.

References
----------
.. [1] `Mutual Information
       &lt;https://en.wikipedia.org/wiki/Mutual_information&gt;`_
       on Wikipedia.
.. [2] A. Kraskov, H. Stogbauer and P. Grassberger, "Estimating mutual
       information". Phys. Rev. E 69, 2004.
.. [3] B. C. Ross "Mutual Information between Discrete and Continuous
       Data Sets". PLoS ONE 9(2), 2014.
.. [4] L. F. Kozachenko, N. N. Leonenko, "Sample Estimate of the Entropy
       of a Random Vector", Probl. Peredachi Inf., 23:2 (1987), 9-16
</pre> <div class="fragment"><div class="line"><span class="lineno">  314</span>):</div>
<div class="line"><span class="lineno">  315</span>    <span class="stringliteral">&quot;&quot;&quot;Estimate mutual information for a continuous target variable.</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral">    Mutual information (MI) [1]_ between two random variables is a non-negative</span></div>
<div class="line"><span class="lineno">  318</span><span class="stringliteral">    value, which measures the dependency between the variables. It is equal</span></div>
<div class="line"><span class="lineno">  319</span><span class="stringliteral">    to zero if and only if two random variables are independent, and higher</span></div>
<div class="line"><span class="lineno">  320</span><span class="stringliteral">    values mean higher dependency.</span></div>
<div class="line"><span class="lineno">  321</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  322</span><span class="stringliteral">    The function relies on nonparametric methods based on entropy estimation</span></div>
<div class="line"><span class="lineno">  323</span><span class="stringliteral">    from k-nearest neighbors distances as described in [2]_ and [3]_. Both</span></div>
<div class="line"><span class="lineno">  324</span><span class="stringliteral">    methods are based on the idea originally proposed in [4]_.</span></div>
<div class="line"><span class="lineno">  325</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  326</span><span class="stringliteral">    It can be used for univariate features selection, read more in the</span></div>
<div class="line"><span class="lineno">  327</span><span class="stringliteral">    :ref:`User Guide &lt;univariate_feature_selection&gt;`.</span></div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral">    X : array-like or sparse matrix, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">        Feature matrix.</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral">    y : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">        Target vector.</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral">    discrete_features : {&#39;auto&#39;, bool, array-like}, default=&#39;auto&#39;</span></div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral">        If bool, then determines whether to consider all features discrete</span></div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral">        or continuous. If array, then it should be either a boolean mask</span></div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">        with shape (n_features,) or array with indices of discrete features.</span></div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral">        If &#39;auto&#39;, it is assigned to False for dense `X` and to True for</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral">        sparse `X`.</span></div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">    n_neighbors : int, default=3</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral">        Number of neighbors to use for MI estimation for continuous variables,</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">        see [2]_ and [3]_. Higher values reduce variance of the estimation, but</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">        could introduce a bias.</span></div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">    copy : bool, default=True</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">        Whether to make a copy of the given data. If set to False, the initial</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">        data will be overwritten.</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral">    random_state : int, RandomState instance or None, default=None</span></div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">        Determines random number generation for adding small noise to</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">        continuous variables in order to remove repeated values.</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral">        Pass an int for reproducible results across multiple function calls.</span></div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  360</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  361</span><span class="stringliteral">    mi : ndarray, shape (n_features,)</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral">        Estimated mutual information between each feature and the target.</span></div>
<div class="line"><span class="lineno">  363</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  364</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  365</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  366</span><span class="stringliteral">    1. The term &quot;discrete features&quot; is used instead of naming them</span></div>
<div class="line"><span class="lineno">  367</span><span class="stringliteral">       &quot;categorical&quot;, because it describes the essence more accurately.</span></div>
<div class="line"><span class="lineno">  368</span><span class="stringliteral">       For example, pixel intensities of an image are discrete features</span></div>
<div class="line"><span class="lineno">  369</span><span class="stringliteral">       (but hardly categorical) and you will get better results if mark them</span></div>
<div class="line"><span class="lineno">  370</span><span class="stringliteral">       as such. Also note, that treating a continuous variable as discrete and</span></div>
<div class="line"><span class="lineno">  371</span><span class="stringliteral">       vice versa will usually give incorrect results, so be attentive about</span></div>
<div class="line"><span class="lineno">  372</span><span class="stringliteral">       that.</span></div>
<div class="line"><span class="lineno">  373</span><span class="stringliteral">    2. True mutual information can&#39;t be negative. If its estimate turns out</span></div>
<div class="line"><span class="lineno">  374</span><span class="stringliteral">       to be negative, it is replaced by zero.</span></div>
<div class="line"><span class="lineno">  375</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  376</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  377</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  378</span><span class="stringliteral">    .. [1] `Mutual Information</span></div>
<div class="line"><span class="lineno">  379</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/Mutual_information&gt;`_</span></div>
<div class="line"><span class="lineno">  380</span><span class="stringliteral">           on Wikipedia.</span></div>
<div class="line"><span class="lineno">  381</span><span class="stringliteral">    .. [2] A. Kraskov, H. Stogbauer and P. Grassberger, &quot;Estimating mutual</span></div>
<div class="line"><span class="lineno">  382</span><span class="stringliteral">           information&quot;. Phys. Rev. E 69, 2004.</span></div>
<div class="line"><span class="lineno">  383</span><span class="stringliteral">    .. [3] B. C. Ross &quot;Mutual Information between Discrete and Continuous</span></div>
<div class="line"><span class="lineno">  384</span><span class="stringliteral">           Data Sets&quot;. PLoS ONE 9(2), 2014.</span></div>
<div class="line"><span class="lineno">  385</span><span class="stringliteral">    .. [4] L. F. Kozachenko, N. N. Leonenko, &quot;Sample Estimate of the Entropy</span></div>
<div class="line"><span class="lineno">  386</span><span class="stringliteral">           of a Random Vector&quot;, Probl. Peredachi Inf., 23:2 (1987), 9-16</span></div>
<div class="line"><span class="lineno">  387</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  388</span>    <span class="keywordflow">return</span> _estimate_mi(X, y, discrete_features, <span class="keyword">False</span>, n_neighbors, copy, random_state)</div>
<div class="line"><span class="lineno">  389</span> </div>
<div class="line"><span class="lineno">  390</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
