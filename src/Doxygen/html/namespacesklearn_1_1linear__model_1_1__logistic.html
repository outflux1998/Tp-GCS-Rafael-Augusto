<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.linear_model._logistic Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model.html">linear_model</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model_1_1__logistic.html">_logistic</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.linear_model._logistic Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__logistic_1_1_logistic_regression.html">LogisticRegression</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1linear__model_1_1__logistic_1_1_logistic_regression_c_v.html">LogisticRegressionCV</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a8d9119fe5a2852152893dd839028f15f" id="r_a8d9119fe5a2852152893dd839028f15f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__logistic.html#a8d9119fe5a2852152893dd839028f15f">_check_solver</a> (solver, penalty, dual)</td></tr>
<tr class="separator:a8d9119fe5a2852152893dd839028f15f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a345ab1f72da761ccf68e0bbec57f3c79" id="r_a345ab1f72da761ccf68e0bbec57f3c79"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__logistic.html#a345ab1f72da761ccf68e0bbec57f3c79">_check_multi_class</a> (multi_class, solver, n_classes)</td></tr>
<tr class="separator:a345ab1f72da761ccf68e0bbec57f3c79"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bcf185546ecc3dd3272b38aede3876f" id="r_a4bcf185546ecc3dd3272b38aede3876f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__logistic.html#a4bcf185546ecc3dd3272b38aede3876f">_logistic_regression_path</a> (X, y, pos_class=None, Cs=10, fit_intercept=True, max_iter=100, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-4, verbose=0, solver=&quot;lbfgs&quot;, coef=None, class_weight=None, dual=False, penalty=&quot;l2&quot;, intercept_scaling=1.0, multi_class=&quot;auto&quot;, random_state=None, check_input=True, max_squared_sum=None, sample_weight=None, l1_ratio=None, n_threads=1)</td></tr>
<tr class="separator:a4bcf185546ecc3dd3272b38aede3876f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e1a1e76b15f895b5368e7c20a93159b" id="r_a9e1a1e76b15f895b5368e7c20a93159b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__logistic.html#a9e1a1e76b15f895b5368e7c20a93159b">_log_reg_scoring_path</a> (X, y, train, test, pos_class=None, Cs=10, scoring=None, fit_intercept=False, max_iter=100, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-4, class_weight=None, verbose=0, solver=&quot;lbfgs&quot;, penalty=&quot;l2&quot;, dual=False, intercept_scaling=1.0, multi_class=&quot;auto&quot;, random_state=None, max_squared_sum=None, sample_weight=None, l1_ratio=None)</td></tr>
<tr class="separator:a9e1a1e76b15f895b5368e7c20a93159b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a59835dda5959e60841bcb83a1c6e452e" id="r_a59835dda5959e60841bcb83a1c6e452e"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1__logistic.html#a59835dda5959e60841bcb83a1c6e452e">_LOGISTIC_SOLVER_CONVERGENCE_MSG</a></td></tr>
<tr class="separator:a59835dda5959e60841bcb83a1c6e452e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Logistic Regression
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a345ab1f72da761ccf68e0bbec57f3c79" name="a345ab1f72da761ccf68e0bbec57f3c79"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a345ab1f72da761ccf68e0bbec57f3c79">&#9670;&#160;</a></span>_check_multi_class()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._logistic._check_multi_class </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_classes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Computes the multi class type, either "multinomial" or "ovr".

For `n_classes` &gt; 2 and a solver that supports it, returns "multinomial".
For all other cases, in particular binary classification, return "ovr".
</pre> <div class="fragment"><div class="line"><span class="lineno">   76</span><span class="keyword">def </span>_check_multi_class(multi_class, solver, n_classes):</div>
<div class="line"><span class="lineno">   77</span>    <span class="stringliteral">&quot;&quot;&quot;Computes the multi class type, either &quot;multinomial&quot; or &quot;ovr&quot;.</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">    For `n_classes` &gt; 2 and a solver that supports it, returns &quot;multinomial&quot;.</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">    For all other cases, in particular binary classification, return &quot;ovr&quot;.</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   82</span>    <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">   83</span>        <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> (<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>):</div>
<div class="line"><span class="lineno">   84</span>            multi_class = <span class="stringliteral">&quot;ovr&quot;</span></div>
<div class="line"><span class="lineno">   85</span>        <span class="keywordflow">elif</span> n_classes &gt; 2:</div>
<div class="line"><span class="lineno">   86</span>            multi_class = <span class="stringliteral">&quot;multinomial&quot;</span></div>
<div class="line"><span class="lineno">   87</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   88</span>            multi_class = <span class="stringliteral">&quot;ovr&quot;</span></div>
<div class="line"><span class="lineno">   89</span>    <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;multinomial&quot;</span> <span class="keywordflow">and</span> solver <span class="keywordflow">in</span> (<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>):</div>
<div class="line"><span class="lineno">   90</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Solver %s does not support a multinomial backend.&quot;</span> % solver)</div>
<div class="line"><span class="lineno">   91</span>    <span class="keywordflow">return</span> multi_class</div>
<div class="line"><span class="lineno">   92</span> </div>
<div class="line"><span class="lineno">   93</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8d9119fe5a2852152893dd839028f15f" name="a8d9119fe5a2852152893dd839028f15f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d9119fe5a2852152893dd839028f15f">&#9670;&#160;</a></span>_check_solver()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._logistic._check_solver </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>penalty</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dual</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   50</span><span class="keyword">def </span>_check_solver(solver, penalty, dual):</div>
<div class="line"><span class="lineno">   51</span> </div>
<div class="line"><span class="lineno">   52</span>    <span class="comment"># TODO(1.4): Remove &quot;none&quot; option</span></div>
<div class="line"><span class="lineno">   53</span>    <span class="keywordflow">if</span> solver <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>] <span class="keywordflow">and</span> penalty <span class="keywordflow">not</span> <span class="keywordflow">in</span> (<span class="stringliteral">&quot;l2&quot;</span>, <span class="stringliteral">&quot;none&quot;</span>, <span class="keywordtype">None</span>):</div>
<div class="line"><span class="lineno">   54</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">   55</span>            <span class="stringliteral">&quot;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, got %s penalty.&quot;</span></div>
<div class="line"><span class="lineno">   56</span>            % (solver, penalty)</div>
<div class="line"><span class="lineno">   57</span>        )</div>
<div class="line"><span class="lineno">   58</span>    <span class="keywordflow">if</span> solver != <span class="stringliteral">&quot;liblinear&quot;</span> <span class="keywordflow">and</span> dual:</div>
<div class="line"><span class="lineno">   59</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">   60</span>            <span class="stringliteral">&quot;Solver %s supports only dual=False, got dual=%s&quot;</span> % (solver, dual)</div>
<div class="line"><span class="lineno">   61</span>        )</div>
<div class="line"><span class="lineno">   62</span> </div>
<div class="line"><span class="lineno">   63</span>    <span class="keywordflow">if</span> penalty == <span class="stringliteral">&quot;elasticnet&quot;</span> <span class="keywordflow">and</span> solver != <span class="stringliteral">&quot;saga&quot;</span>:</div>
<div class="line"><span class="lineno">   64</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">   65</span>            <span class="stringliteral">&quot;Only &#39;saga&#39; solver supports elasticnet penalty, got solver={}.&quot;</span>.format(</div>
<div class="line"><span class="lineno">   66</span>                solver</div>
<div class="line"><span class="lineno">   67</span>            )</div>
<div class="line"><span class="lineno">   68</span>        )</div>
<div class="line"><span class="lineno">   69</span> </div>
<div class="line"><span class="lineno">   70</span>    <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;liblinear&quot;</span> <span class="keywordflow">and</span> penalty == <span class="stringliteral">&quot;none&quot;</span>:</div>
<div class="line"><span class="lineno">   71</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;penalty=&#39;none&#39; is not supported for the liblinear solver&quot;</span>)</div>
<div class="line"><span class="lineno">   72</span> </div>
<div class="line"><span class="lineno">   73</span>    <span class="keywordflow">return</span> solver</div>
<div class="line"><span class="lineno">   74</span> </div>
<div class="line"><span class="lineno">   75</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9e1a1e76b15f895b5368e7c20a93159b" name="a9e1a1e76b15f895b5368e7c20a93159b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e1a1e76b15f895b5368e7c20a93159b">&#9670;&#160;</a></span>_log_reg_scoring_path()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._logistic._log_reg_scoring_path </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>train</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>test</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_class</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cs</em> = <code>10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>scoring</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>class_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em> = <code>&quot;lbfgs&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>penalty</em> = <code>&quot;l2&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dual</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>intercept_scaling</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_squared_sum</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>l1_ratio</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Computes scores across logistic_regression_path

Parameters
----------
X : {array-like, sparse matrix} of shape (n_samples, n_features)
    Training data.

y : array-like of shape (n_samples,) or (n_samples, n_targets)
    Target labels.

train : list of indices
    The indices of the train set.

test : list of indices
    The indices of the test set.

pos_class : int, default=None
    The class with respect to which we perform a one-vs-all fit.
    If None, then it is assumed that the given problem is binary.

Cs : int or list of floats, default=10
    Each of the values in Cs describes the inverse of
    regularization strength. If Cs is as an int, then a grid of Cs
    values are chosen in a logarithmic scale between 1e-4 and 1e4.
    If not provided, then a fixed set of values for Cs are used.

scoring : callable, default=None
    A string (see model evaluation documentation) or
    a scorer callable object / function with signature
    ``scorer(estimator, X, y)``. For a list of scoring functions
    that can be used, look at :mod:`sklearn.metrics`. The
    default scoring option used is accuracy_score.

fit_intercept : bool, default=False
    If False, then the bias term is set to zero. Else the last
    term of each coef_ gives us the intercept.

max_iter : int, default=100
    Maximum number of iterations for the solver.

tol : float, default=1e-4
    Tolerance for stopping criteria.

class_weight : dict or 'balanced', default=None
    Weights associated with classes in the form ``{class_label: weight}``.
    If not given, all classes are supposed to have weight one.

    The "balanced" mode uses the values of y to automatically adjust
    weights inversely proportional to class frequencies in the input data
    as ``n_samples / (n_classes * np.bincount(y))``

    Note that these weights will be multiplied with sample_weight (passed
    through the fit method) if sample_weight is specified.

verbose : int, default=0
    For the liblinear and lbfgs solvers set verbose to any positive
    number for verbosity.

solver : {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'}, \
        default='lbfgs'
    Decides which solver to use.

penalty : {'l1', 'l2', 'elasticnet'}, default='l2'
    Used to specify the norm used in the penalization. The 'newton-cg',
    'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is
    only supported by the 'saga' solver.

dual : bool, default=False
    Dual or primal formulation. Dual formulation is only implemented for
    l2 penalty with liblinear solver. Prefer dual=False when
    n_samples &gt; n_features.

intercept_scaling : float, default=1.
    Useful only when the solver 'liblinear' is used
    and self.fit_intercept is set to True. In this case, x becomes
    [x, self.intercept_scaling],
    i.e. a "synthetic" feature with constant value equals to
    intercept_scaling is appended to the instance vector.
    The intercept becomes intercept_scaling * synthetic feature weight
    Note! the synthetic feature weight is subject to l1/l2 regularization
    as all other features.
    To lessen the effect of regularization on synthetic feature weight
    (and therefore on the intercept) intercept_scaling has to be increased.

multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'
    If the option chosen is 'ovr', then a binary problem is fit for each
    label. For 'multinomial' the loss minimised is the multinomial loss fit
    across the entire probability distribution, *even when the data is
    binary*. 'multinomial' is unavailable when solver='liblinear'.

random_state : int, RandomState instance, default=None
    Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the
    data. See :term:`Glossary &lt;random_state&gt;` for details.

max_squared_sum : float, default=None
    Maximum squared sum of X over samples. Used only in SAG solver.
    If None, it will be computed, going through all the samples.
    The value should be precomputed to speed up cross validation.

sample_weight : array-like of shape(n_samples,), default=None
    Array of weights that are assigned to individual samples.
    If not provided, then each sample is given unit weight.

l1_ratio : float, default=None
    The Elastic-Net mixing parameter, with ``0 &lt;= l1_ratio &lt;= 1``. Only
    used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent
    to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent
    to using ``penalty='l1'``. For ``0 &lt; l1_ratio &lt;1``, the penalty is a
    combination of L1 and L2.

Returns
-------
coefs : ndarray of shape (n_cs, n_features) or (n_cs, n_features + 1)
    List of coefficients for the Logistic Regression model. If
    fit_intercept is set to True then the second dimension will be
    n_features + 1, where the last item represents the intercept.

Cs : ndarray
    Grid of Cs used for cross-validation.

scores : ndarray of shape (n_cs,)
    Scores obtained for each Cs.

n_iter : ndarray of shape(n_cs,)
    Actual number of iteration for each Cs.
</pre> <div class="fragment"><div class="line"><span class="lineno">  587</span>):</div>
<div class="line"><span class="lineno">  588</span>    <span class="stringliteral">&quot;&quot;&quot;Computes scores across logistic_regression_path</span></div>
<div class="line"><span class="lineno">  589</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  590</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  591</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  592</span><span class="stringliteral">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  593</span><span class="stringliteral">        Training data.</span></div>
<div class="line"><span class="lineno">  594</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  595</span><span class="stringliteral">    y : array-like of shape (n_samples,) or (n_samples, n_targets)</span></div>
<div class="line"><span class="lineno">  596</span><span class="stringliteral">        Target labels.</span></div>
<div class="line"><span class="lineno">  597</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  598</span><span class="stringliteral">    train : list of indices</span></div>
<div class="line"><span class="lineno">  599</span><span class="stringliteral">        The indices of the train set.</span></div>
<div class="line"><span class="lineno">  600</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  601</span><span class="stringliteral">    test : list of indices</span></div>
<div class="line"><span class="lineno">  602</span><span class="stringliteral">        The indices of the test set.</span></div>
<div class="line"><span class="lineno">  603</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  604</span><span class="stringliteral">    pos_class : int, default=None</span></div>
<div class="line"><span class="lineno">  605</span><span class="stringliteral">        The class with respect to which we perform a one-vs-all fit.</span></div>
<div class="line"><span class="lineno">  606</span><span class="stringliteral">        If None, then it is assumed that the given problem is binary.</span></div>
<div class="line"><span class="lineno">  607</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  608</span><span class="stringliteral">    Cs : int or list of floats, default=10</span></div>
<div class="line"><span class="lineno">  609</span><span class="stringliteral">        Each of the values in Cs describes the inverse of</span></div>
<div class="line"><span class="lineno">  610</span><span class="stringliteral">        regularization strength. If Cs is as an int, then a grid of Cs</span></div>
<div class="line"><span class="lineno">  611</span><span class="stringliteral">        values are chosen in a logarithmic scale between 1e-4 and 1e4.</span></div>
<div class="line"><span class="lineno">  612</span><span class="stringliteral">        If not provided, then a fixed set of values for Cs are used.</span></div>
<div class="line"><span class="lineno">  613</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  614</span><span class="stringliteral">    scoring : callable, default=None</span></div>
<div class="line"><span class="lineno">  615</span><span class="stringliteral">        A string (see model evaluation documentation) or</span></div>
<div class="line"><span class="lineno">  616</span><span class="stringliteral">        a scorer callable object / function with signature</span></div>
<div class="line"><span class="lineno">  617</span><span class="stringliteral">        ``scorer(estimator, X, y)``. For a list of scoring functions</span></div>
<div class="line"><span class="lineno">  618</span><span class="stringliteral">        that can be used, look at :mod:`sklearn.metrics`. The</span></div>
<div class="line"><span class="lineno">  619</span><span class="stringliteral">        default scoring option used is accuracy_score.</span></div>
<div class="line"><span class="lineno">  620</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  621</span><span class="stringliteral">    fit_intercept : bool, default=False</span></div>
<div class="line"><span class="lineno">  622</span><span class="stringliteral">        If False, then the bias term is set to zero. Else the last</span></div>
<div class="line"><span class="lineno">  623</span><span class="stringliteral">        term of each coef_ gives us the intercept.</span></div>
<div class="line"><span class="lineno">  624</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  625</span><span class="stringliteral">    max_iter : int, default=100</span></div>
<div class="line"><span class="lineno">  626</span><span class="stringliteral">        Maximum number of iterations for the solver.</span></div>
<div class="line"><span class="lineno">  627</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  628</span><span class="stringliteral">    tol : float, default=1e-4</span></div>
<div class="line"><span class="lineno">  629</span><span class="stringliteral">        Tolerance for stopping criteria.</span></div>
<div class="line"><span class="lineno">  630</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  631</span><span class="stringliteral">    class_weight : dict or &#39;balanced&#39;, default=None</span></div>
<div class="line"><span class="lineno">  632</span><span class="stringliteral">        Weights associated with classes in the form ``{class_label: weight}``.</span></div>
<div class="line"><span class="lineno">  633</span><span class="stringliteral">        If not given, all classes are supposed to have weight one.</span></div>
<div class="line"><span class="lineno">  634</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  635</span><span class="stringliteral">        The &quot;balanced&quot; mode uses the values of y to automatically adjust</span></div>
<div class="line"><span class="lineno">  636</span><span class="stringliteral">        weights inversely proportional to class frequencies in the input data</span></div>
<div class="line"><span class="lineno">  637</span><span class="stringliteral">        as ``n_samples / (n_classes * np.bincount(y))``</span></div>
<div class="line"><span class="lineno">  638</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  639</span><span class="stringliteral">        Note that these weights will be multiplied with sample_weight (passed</span></div>
<div class="line"><span class="lineno">  640</span><span class="stringliteral">        through the fit method) if sample_weight is specified.</span></div>
<div class="line"><span class="lineno">  641</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  642</span><span class="stringliteral">    verbose : int, default=0</span></div>
<div class="line"><span class="lineno">  643</span><span class="stringliteral">        For the liblinear and lbfgs solvers set verbose to any positive</span></div>
<div class="line"><span class="lineno">  644</span><span class="stringliteral">        number for verbosity.</span></div>
<div class="line"><span class="lineno">  645</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  646</span><span class="stringliteral">    solver : {&#39;lbfgs&#39;, &#39;liblinear&#39;, &#39;newton-cg&#39;, &#39;newton-cholesky&#39;, &#39;sag&#39;, &#39;saga&#39;}, \</span></div>
<div class="line"><span class="lineno">  647</span><span class="stringliteral">            default=&#39;lbfgs&#39;</span></div>
<div class="line"><span class="lineno">  648</span><span class="stringliteral">        Decides which solver to use.</span></div>
<div class="line"><span class="lineno">  649</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  650</span><span class="stringliteral">    penalty : {&#39;l1&#39;, &#39;l2&#39;, &#39;elasticnet&#39;}, default=&#39;l2&#39;</span></div>
<div class="line"><span class="lineno">  651</span><span class="stringliteral">        Used to specify the norm used in the penalization. The &#39;newton-cg&#39;,</span></div>
<div class="line"><span class="lineno">  652</span><span class="stringliteral">        &#39;sag&#39; and &#39;lbfgs&#39; solvers support only l2 penalties. &#39;elasticnet&#39; is</span></div>
<div class="line"><span class="lineno">  653</span><span class="stringliteral">        only supported by the &#39;saga&#39; solver.</span></div>
<div class="line"><span class="lineno">  654</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  655</span><span class="stringliteral">    dual : bool, default=False</span></div>
<div class="line"><span class="lineno">  656</span><span class="stringliteral">        Dual or primal formulation. Dual formulation is only implemented for</span></div>
<div class="line"><span class="lineno">  657</span><span class="stringliteral">        l2 penalty with liblinear solver. Prefer dual=False when</span></div>
<div class="line"><span class="lineno">  658</span><span class="stringliteral">        n_samples &gt; n_features.</span></div>
<div class="line"><span class="lineno">  659</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  660</span><span class="stringliteral">    intercept_scaling : float, default=1.</span></div>
<div class="line"><span class="lineno">  661</span><span class="stringliteral">        Useful only when the solver &#39;liblinear&#39; is used</span></div>
<div class="line"><span class="lineno">  662</span><span class="stringliteral">        and self.fit_intercept is set to True. In this case, x becomes</span></div>
<div class="line"><span class="lineno">  663</span><span class="stringliteral">        [x, self.intercept_scaling],</span></div>
<div class="line"><span class="lineno">  664</span><span class="stringliteral">        i.e. a &quot;synthetic&quot; feature with constant value equals to</span></div>
<div class="line"><span class="lineno">  665</span><span class="stringliteral">        intercept_scaling is appended to the instance vector.</span></div>
<div class="line"><span class="lineno">  666</span><span class="stringliteral">        The intercept becomes intercept_scaling * synthetic feature weight</span></div>
<div class="line"><span class="lineno">  667</span><span class="stringliteral">        Note! the synthetic feature weight is subject to l1/l2 regularization</span></div>
<div class="line"><span class="lineno">  668</span><span class="stringliteral">        as all other features.</span></div>
<div class="line"><span class="lineno">  669</span><span class="stringliteral">        To lessen the effect of regularization on synthetic feature weight</span></div>
<div class="line"><span class="lineno">  670</span><span class="stringliteral">        (and therefore on the intercept) intercept_scaling has to be increased.</span></div>
<div class="line"><span class="lineno">  671</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  672</span><span class="stringliteral">    multi_class : {&#39;auto&#39;, &#39;ovr&#39;, &#39;multinomial&#39;}, default=&#39;auto&#39;</span></div>
<div class="line"><span class="lineno">  673</span><span class="stringliteral">        If the option chosen is &#39;ovr&#39;, then a binary problem is fit for each</span></div>
<div class="line"><span class="lineno">  674</span><span class="stringliteral">        label. For &#39;multinomial&#39; the loss minimised is the multinomial loss fit</span></div>
<div class="line"><span class="lineno">  675</span><span class="stringliteral">        across the entire probability distribution, *even when the data is</span></div>
<div class="line"><span class="lineno">  676</span><span class="stringliteral">        binary*. &#39;multinomial&#39; is unavailable when solver=&#39;liblinear&#39;.</span></div>
<div class="line"><span class="lineno">  677</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  678</span><span class="stringliteral">    random_state : int, RandomState instance, default=None</span></div>
<div class="line"><span class="lineno">  679</span><span class="stringliteral">        Used when ``solver`` == &#39;sag&#39;, &#39;saga&#39; or &#39;liblinear&#39; to shuffle the</span></div>
<div class="line"><span class="lineno">  680</span><span class="stringliteral">        data. See :term:`Glossary &lt;random_state&gt;` for details.</span></div>
<div class="line"><span class="lineno">  681</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  682</span><span class="stringliteral">    max_squared_sum : float, default=None</span></div>
<div class="line"><span class="lineno">  683</span><span class="stringliteral">        Maximum squared sum of X over samples. Used only in SAG solver.</span></div>
<div class="line"><span class="lineno">  684</span><span class="stringliteral">        If None, it will be computed, going through all the samples.</span></div>
<div class="line"><span class="lineno">  685</span><span class="stringliteral">        The value should be precomputed to speed up cross validation.</span></div>
<div class="line"><span class="lineno">  686</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  687</span><span class="stringliteral">    sample_weight : array-like of shape(n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  688</span><span class="stringliteral">        Array of weights that are assigned to individual samples.</span></div>
<div class="line"><span class="lineno">  689</span><span class="stringliteral">        If not provided, then each sample is given unit weight.</span></div>
<div class="line"><span class="lineno">  690</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  691</span><span class="stringliteral">    l1_ratio : float, default=None</span></div>
<div class="line"><span class="lineno">  692</span><span class="stringliteral">        The Elastic-Net mixing parameter, with ``0 &lt;= l1_ratio &lt;= 1``. Only</span></div>
<div class="line"><span class="lineno">  693</span><span class="stringliteral">        used if ``penalty=&#39;elasticnet&#39;``. Setting ``l1_ratio=0`` is equivalent</span></div>
<div class="line"><span class="lineno">  694</span><span class="stringliteral">        to using ``penalty=&#39;l2&#39;``, while setting ``l1_ratio=1`` is equivalent</span></div>
<div class="line"><span class="lineno">  695</span><span class="stringliteral">        to using ``penalty=&#39;l1&#39;``. For ``0 &lt; l1_ratio &lt;1``, the penalty is a</span></div>
<div class="line"><span class="lineno">  696</span><span class="stringliteral">        combination of L1 and L2.</span></div>
<div class="line"><span class="lineno">  697</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  698</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  699</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  700</span><span class="stringliteral">    coefs : ndarray of shape (n_cs, n_features) or (n_cs, n_features + 1)</span></div>
<div class="line"><span class="lineno">  701</span><span class="stringliteral">        List of coefficients for the Logistic Regression model. If</span></div>
<div class="line"><span class="lineno">  702</span><span class="stringliteral">        fit_intercept is set to True then the second dimension will be</span></div>
<div class="line"><span class="lineno">  703</span><span class="stringliteral">        n_features + 1, where the last item represents the intercept.</span></div>
<div class="line"><span class="lineno">  704</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  705</span><span class="stringliteral">    Cs : ndarray</span></div>
<div class="line"><span class="lineno">  706</span><span class="stringliteral">        Grid of Cs used for cross-validation.</span></div>
<div class="line"><span class="lineno">  707</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  708</span><span class="stringliteral">    scores : ndarray of shape (n_cs,)</span></div>
<div class="line"><span class="lineno">  709</span><span class="stringliteral">        Scores obtained for each Cs.</span></div>
<div class="line"><span class="lineno">  710</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  711</span><span class="stringliteral">    n_iter : ndarray of shape(n_cs,)</span></div>
<div class="line"><span class="lineno">  712</span><span class="stringliteral">        Actual number of iteration for each Cs.</span></div>
<div class="line"><span class="lineno">  713</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  714</span>    X_train = X[train]</div>
<div class="line"><span class="lineno">  715</span>    X_test = X[test]</div>
<div class="line"><span class="lineno">  716</span>    y_train = y[train]</div>
<div class="line"><span class="lineno">  717</span>    y_test = y[test]</div>
<div class="line"><span class="lineno">  718</span> </div>
<div class="line"><span class="lineno">  719</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  720</span>        sample_weight = _check_sample_weight(sample_weight, X)</div>
<div class="line"><span class="lineno">  721</span>        sample_weight = sample_weight[train]</div>
<div class="line"><span class="lineno">  722</span> </div>
<div class="line"><span class="lineno">  723</span>    coefs, Cs, n_iter = _logistic_regression_path(</div>
<div class="line"><span class="lineno">  724</span>        X_train,</div>
<div class="line"><span class="lineno">  725</span>        y_train,</div>
<div class="line"><span class="lineno">  726</span>        Cs=Cs,</div>
<div class="line"><span class="lineno">  727</span>        l1_ratio=l1_ratio,</div>
<div class="line"><span class="lineno">  728</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  729</span>        solver=solver,</div>
<div class="line"><span class="lineno">  730</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  731</span>        class_weight=class_weight,</div>
<div class="line"><span class="lineno">  732</span>        pos_class=pos_class,</div>
<div class="line"><span class="lineno">  733</span>        multi_class=multi_class,</div>
<div class="line"><span class="lineno">  734</span>        tol=tol,</div>
<div class="line"><span class="lineno">  735</span>        verbose=verbose,</div>
<div class="line"><span class="lineno">  736</span>        dual=dual,</div>
<div class="line"><span class="lineno">  737</span>        penalty=penalty,</div>
<div class="line"><span class="lineno">  738</span>        intercept_scaling=intercept_scaling,</div>
<div class="line"><span class="lineno">  739</span>        random_state=random_state,</div>
<div class="line"><span class="lineno">  740</span>        check_input=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  741</span>        max_squared_sum=max_squared_sum,</div>
<div class="line"><span class="lineno">  742</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  743</span>    )</div>
<div class="line"><span class="lineno">  744</span> </div>
<div class="line"><span class="lineno">  745</span>    log_reg = LogisticRegression(solver=solver, multi_class=multi_class)</div>
<div class="line"><span class="lineno">  746</span> </div>
<div class="line"><span class="lineno">  747</span>    <span class="comment"># The score method of Logistic Regression has a classes_ attribute.</span></div>
<div class="line"><span class="lineno">  748</span>    <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;ovr&quot;</span>:</div>
<div class="line"><span class="lineno">  749</span>        log_reg.classes_ = np.array([-1, 1])</div>
<div class="line"><span class="lineno">  750</span>    <span class="keywordflow">elif</span> multi_class == <span class="stringliteral">&quot;multinomial&quot;</span>:</div>
<div class="line"><span class="lineno">  751</span>        log_reg.classes_ = np.unique(y_train)</div>
<div class="line"><span class="lineno">  752</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  753</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  754</span>            <span class="stringliteral">&quot;multi_class should be either multinomial or ovr, got %d&quot;</span> % multi_class</div>
<div class="line"><span class="lineno">  755</span>        )</div>
<div class="line"><span class="lineno">  756</span> </div>
<div class="line"><span class="lineno">  757</span>    <span class="keywordflow">if</span> pos_class <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  758</span>        mask = y_test == pos_class</div>
<div class="line"><span class="lineno">  759</span>        y_test = np.ones(y_test.shape, dtype=np.float64)</div>
<div class="line"><span class="lineno">  760</span>        y_test[~mask] = -1.0</div>
<div class="line"><span class="lineno">  761</span> </div>
<div class="line"><span class="lineno">  762</span>    scores = list()</div>
<div class="line"><span class="lineno">  763</span> </div>
<div class="line"><span class="lineno">  764</span>    scoring = get_scorer(scoring)</div>
<div class="line"><span class="lineno">  765</span>    <span class="keywordflow">for</span> w <span class="keywordflow">in</span> coefs:</div>
<div class="line"><span class="lineno">  766</span>        <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;ovr&quot;</span>:</div>
<div class="line"><span class="lineno">  767</span>            w = w[np.newaxis, :]</div>
<div class="line"><span class="lineno">  768</span>        <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno">  769</span>            log_reg.coef_ = w[:, :-1]</div>
<div class="line"><span class="lineno">  770</span>            log_reg.intercept_ = w[:, -1]</div>
<div class="line"><span class="lineno">  771</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  772</span>            log_reg.coef_ = w</div>
<div class="line"><span class="lineno">  773</span>            log_reg.intercept_ = 0.0</div>
<div class="line"><span class="lineno">  774</span> </div>
<div class="line"><span class="lineno">  775</span>        <span class="keywordflow">if</span> scoring <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  776</span>            scores.append(log_reg.score(X_test, y_test))</div>
<div class="line"><span class="lineno">  777</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  778</span>            scores.append(scoring(log_reg, X_test, y_test))</div>
<div class="line"><span class="lineno">  779</span> </div>
<div class="line"><span class="lineno">  780</span>    <span class="keywordflow">return</span> coefs, Cs, np.array(scores), n_iter</div>
<div class="line"><span class="lineno">  781</span> </div>
<div class="line"><span class="lineno">  782</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4bcf185546ecc3dd3272b38aede3876f" name="a4bcf185546ecc3dd3272b38aede3876f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4bcf185546ecc3dd3272b38aede3876f">&#9670;&#160;</a></span>_logistic_regression_path()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model._logistic._logistic_regression_path </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_class</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cs</em> = <code>10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em> = <code>&quot;lbfgs&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>coef</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>class_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dual</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>penalty</em> = <code>&quot;l2&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>intercept_scaling</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>check_input</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_squared_sum</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>l1_ratio</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_threads</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute a Logistic Regression model for a list of regularization
parameters.

This is an implementation that uses the result of the previous model
to speed up computations along the set of solutions, making it faster
than sequentially calling LogisticRegression for the different parameters.
Note that there will be no speedup with liblinear solver, since it does
not handle warm-starting.

Read more in the :ref:`User Guide &lt;logistic_regression&gt;`.

Parameters
----------
X : {array-like, sparse matrix} of shape (n_samples, n_features)
    Input data.

y : array-like of shape (n_samples,) or (n_samples, n_targets)
    Input data, target values.

pos_class : int, default=None
    The class with respect to which we perform a one-vs-all fit.
    If None, then it is assumed that the given problem is binary.

Cs : int or array-like of shape (n_cs,), default=10
    List of values for the regularization parameter or integer specifying
    the number of regularization parameters that should be used. In this
    case, the parameters will be chosen in a logarithmic scale between
    1e-4 and 1e4.

fit_intercept : bool, default=True
    Whether to fit an intercept for the model. In this case the shape of
    the returned array is (n_cs, n_features + 1).

max_iter : int, default=100
    Maximum number of iterations for the solver.

tol : float, default=1e-4
    Stopping criterion. For the newton-cg and lbfgs solvers, the iteration
    will stop when ``max{|g_i | i = 1, ..., n} &lt;= tol``
    where ``g_i`` is the i-th component of the gradient.

verbose : int, default=0
    For the liblinear and lbfgs solvers set verbose to any positive
    number for verbosity.

solver : {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'}, \
        default='lbfgs'
    Numerical solver to use.

coef : array-like of shape (n_features,), default=None
    Initialization value for coefficients of logistic regression.
    Useless for liblinear solver.

class_weight : dict or 'balanced', default=None
    Weights associated with classes in the form ``{class_label: weight}``.
    If not given, all classes are supposed to have weight one.

    The "balanced" mode uses the values of y to automatically adjust
    weights inversely proportional to class frequencies in the input data
    as ``n_samples / (n_classes * np.bincount(y))``.

    Note that these weights will be multiplied with sample_weight (passed
    through the fit method) if sample_weight is specified.

dual : bool, default=False
    Dual or primal formulation. Dual formulation is only implemented for
    l2 penalty with liblinear solver. Prefer dual=False when
    n_samples &gt; n_features.

penalty : {'l1', 'l2', 'elasticnet'}, default='l2'
    Used to specify the norm used in the penalization. The 'newton-cg',
    'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is
    only supported by the 'saga' solver.

intercept_scaling : float, default=1.
    Useful only when the solver 'liblinear' is used
    and self.fit_intercept is set to True. In this case, x becomes
    [x, self.intercept_scaling],
    i.e. a "synthetic" feature with constant value equal to
    intercept_scaling is appended to the instance vector.
    The intercept becomes ``intercept_scaling * synthetic_feature_weight``.

    Note! the synthetic feature weight is subject to l1/l2 regularization
    as all other features.
    To lessen the effect of regularization on synthetic feature weight
    (and therefore on the intercept) intercept_scaling has to be increased.

multi_class : {'ovr', 'multinomial', 'auto'}, default='auto'
    If the option chosen is 'ovr', then a binary problem is fit for each
    label. For 'multinomial' the loss minimised is the multinomial loss fit
    across the entire probability distribution, *even when the data is
    binary*. 'multinomial' is unavailable when solver='liblinear'.
    'auto' selects 'ovr' if the data is binary, or if solver='liblinear',
    and otherwise selects 'multinomial'.

    .. versionadded:: 0.18
       Stochastic Average Gradient descent solver for 'multinomial' case.
    .. versionchanged:: 0.22
        Default changed from 'ovr' to 'auto' in 0.22.

random_state : int, RandomState instance, default=None
    Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the
    data. See :term:`Glossary &lt;random_state&gt;` for details.

check_input : bool, default=True
    If False, the input arrays X and y will not be checked.

max_squared_sum : float, default=None
    Maximum squared sum of X over samples. Used only in SAG solver.
    If None, it will be computed, going through all the samples.
    The value should be precomputed to speed up cross validation.

sample_weight : array-like of shape(n_samples,), default=None
    Array of weights that are assigned to individual samples.
    If not provided, then each sample is given unit weight.

l1_ratio : float, default=None
    The Elastic-Net mixing parameter, with ``0 &lt;= l1_ratio &lt;= 1``. Only
    used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent
    to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent
    to using ``penalty='l1'``. For ``0 &lt; l1_ratio &lt;1``, the penalty is a
    combination of L1 and L2.

n_threads : int, default=1
   Number of OpenMP threads to use.

Returns
-------
coefs : ndarray of shape (n_cs, n_features) or (n_cs, n_features + 1)
    List of coefficients for the Logistic Regression model. If
    fit_intercept is set to True then the second dimension will be
    n_features + 1, where the last item represents the intercept. For
    ``multiclass='multinomial'``, the shape is (n_classes, n_cs,
    n_features) or (n_classes, n_cs, n_features + 1).

Cs : ndarray
    Grid of Cs used for cross-validation.

n_iter : array of shape (n_cs,)
    Actual number of iteration for each Cs.

Notes
-----
You might get slightly different results with the solver liblinear than
with the others since this uses LIBLINEAR which penalizes the intercept.

.. versionchanged:: 0.19
    The "copy" parameter was removed.
</pre> <div class="fragment"><div class="line"><span class="lineno">  116</span>):</div>
<div class="line"><span class="lineno">  117</span>    <span class="stringliteral">&quot;&quot;&quot;Compute a Logistic Regression model for a list of regularization</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">    parameters.</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral">    This is an implementation that uses the result of the previous model</span></div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral">    to speed up computations along the set of solutions, making it faster</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">    than sequentially calling LogisticRegression for the different parameters.</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">    Note that there will be no speedup with liblinear solver, since it does</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">    not handle warm-starting.</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;logistic_regression&gt;`.</span></div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">        Input data.</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">    y : array-like of shape (n_samples,) or (n_samples, n_targets)</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">        Input data, target values.</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">    pos_class : int, default=None</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">        The class with respect to which we perform a one-vs-all fit.</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">        If None, then it is assumed that the given problem is binary.</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">    Cs : int or array-like of shape (n_cs,), default=10</span></div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">        List of values for the regularization parameter or integer specifying</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">        the number of regularization parameters that should be used. In this</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">        case, the parameters will be chosen in a logarithmic scale between</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">        1e-4 and 1e4.</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">    fit_intercept : bool, default=True</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">        Whether to fit an intercept for the model. In this case the shape of</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">        the returned array is (n_cs, n_features + 1).</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">    max_iter : int, default=100</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">        Maximum number of iterations for the solver.</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">    tol : float, default=1e-4</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">        Stopping criterion. For the newton-cg and lbfgs solvers, the iteration</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">        will stop when ``max{|g_i | i = 1, ..., n} &lt;= tol``</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">        where ``g_i`` is the i-th component of the gradient.</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">    verbose : int, default=0</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">        For the liblinear and lbfgs solvers set verbose to any positive</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">        number for verbosity.</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">    solver : {&#39;lbfgs&#39;, &#39;liblinear&#39;, &#39;newton-cg&#39;, &#39;newton-cholesky&#39;, &#39;sag&#39;, &#39;saga&#39;}, \</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">            default=&#39;lbfgs&#39;</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        Numerical solver to use.</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">    coef : array-like of shape (n_features,), default=None</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">        Initialization value for coefficients of logistic regression.</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">        Useless for liblinear solver.</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">    class_weight : dict or &#39;balanced&#39;, default=None</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">        Weights associated with classes in the form ``{class_label: weight}``.</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral">        If not given, all classes are supposed to have weight one.</span></div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">        The &quot;balanced&quot; mode uses the values of y to automatically adjust</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">        weights inversely proportional to class frequencies in the input data</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">        as ``n_samples / (n_classes * np.bincount(y))``.</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral">        Note that these weights will be multiplied with sample_weight (passed</span></div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">        through the fit method) if sample_weight is specified.</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">    dual : bool, default=False</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">        Dual or primal formulation. Dual formulation is only implemented for</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">        l2 penalty with liblinear solver. Prefer dual=False when</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral">        n_samples &gt; n_features.</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">    penalty : {&#39;l1&#39;, &#39;l2&#39;, &#39;elasticnet&#39;}, default=&#39;l2&#39;</span></div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">        Used to specify the norm used in the penalization. The &#39;newton-cg&#39;,</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral">        &#39;sag&#39; and &#39;lbfgs&#39; solvers support only l2 penalties. &#39;elasticnet&#39; is</span></div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">        only supported by the &#39;saga&#39; solver.</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral">    intercept_scaling : float, default=1.</span></div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">        Useful only when the solver &#39;liblinear&#39; is used</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral">        and self.fit_intercept is set to True. In this case, x becomes</span></div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">        [x, self.intercept_scaling],</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">        i.e. a &quot;synthetic&quot; feature with constant value equal to</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral">        intercept_scaling is appended to the instance vector.</span></div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral">        The intercept becomes ``intercept_scaling * synthetic_feature_weight``.</span></div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">        Note! the synthetic feature weight is subject to l1/l2 regularization</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral">        as all other features.</span></div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral">        To lessen the effect of regularization on synthetic feature weight</span></div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral">        (and therefore on the intercept) intercept_scaling has to be increased.</span></div>
<div class="line"><span class="lineno">  203</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  204</span><span class="stringliteral">    multi_class : {&#39;ovr&#39;, &#39;multinomial&#39;, &#39;auto&#39;}, default=&#39;auto&#39;</span></div>
<div class="line"><span class="lineno">  205</span><span class="stringliteral">        If the option chosen is &#39;ovr&#39;, then a binary problem is fit for each</span></div>
<div class="line"><span class="lineno">  206</span><span class="stringliteral">        label. For &#39;multinomial&#39; the loss minimised is the multinomial loss fit</span></div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral">        across the entire probability distribution, *even when the data is</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">        binary*. &#39;multinomial&#39; is unavailable when solver=&#39;liblinear&#39;.</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">        &#39;auto&#39; selects &#39;ovr&#39; if the data is binary, or if solver=&#39;liblinear&#39;,</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">        and otherwise selects &#39;multinomial&#39;.</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">        .. versionadded:: 0.18</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral">           Stochastic Average Gradient descent solver for &#39;multinomial&#39; case.</span></div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">        .. versionchanged:: 0.22</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">            Default changed from &#39;ovr&#39; to &#39;auto&#39; in 0.22.</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">    random_state : int, RandomState instance, default=None</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">        Used when ``solver`` == &#39;sag&#39;, &#39;saga&#39; or &#39;liblinear&#39; to shuffle the</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">        data. See :term:`Glossary &lt;random_state&gt;` for details.</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">    check_input : bool, default=True</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">        If False, the input arrays X and y will not be checked.</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">    max_squared_sum : float, default=None</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">        Maximum squared sum of X over samples. Used only in SAG solver.</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">        If None, it will be computed, going through all the samples.</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">        The value should be precomputed to speed up cross validation.</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">    sample_weight : array-like of shape(n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">        Array of weights that are assigned to individual samples.</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">        If not provided, then each sample is given unit weight.</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">    l1_ratio : float, default=None</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">        The Elastic-Net mixing parameter, with ``0 &lt;= l1_ratio &lt;= 1``. Only</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">        used if ``penalty=&#39;elasticnet&#39;``. Setting ``l1_ratio=0`` is equivalent</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">        to using ``penalty=&#39;l2&#39;``, while setting ``l1_ratio=1`` is equivalent</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">        to using ``penalty=&#39;l1&#39;``. For ``0 &lt; l1_ratio &lt;1``, the penalty is a</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">        combination of L1 and L2.</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">    n_threads : int, default=1</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">       Number of OpenMP threads to use.</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">    coefs : ndarray of shape (n_cs, n_features) or (n_cs, n_features + 1)</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">        List of coefficients for the Logistic Regression model. If</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">        fit_intercept is set to True then the second dimension will be</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">        n_features + 1, where the last item represents the intercept. For</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">        ``multiclass=&#39;multinomial&#39;``, the shape is (n_classes, n_cs,</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">        n_features) or (n_classes, n_cs, n_features + 1).</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">    Cs : ndarray</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">        Grid of Cs used for cross-validation.</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">    n_iter : array of shape (n_cs,)</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">        Actual number of iteration for each Cs.</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">    You might get slightly different results with the solver liblinear than</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">    with the others since this uses LIBLINEAR which penalizes the intercept.</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">    .. versionchanged:: 0.19</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">        The &quot;copy&quot; parameter was removed.</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  266</span>    <span class="keywordflow">if</span> isinstance(Cs, numbers.Integral):</div>
<div class="line"><span class="lineno">  267</span>        Cs = np.logspace(-4, 4, Cs)</div>
<div class="line"><span class="lineno">  268</span> </div>
<div class="line"><span class="lineno">  269</span>    solver = _check_solver(solver, penalty, dual)</div>
<div class="line"><span class="lineno">  270</span> </div>
<div class="line"><span class="lineno">  271</span>    <span class="comment"># Preprocessing.</span></div>
<div class="line"><span class="lineno">  272</span>    <span class="keywordflow">if</span> check_input:</div>
<div class="line"><span class="lineno">  273</span>        X = check_array(</div>
<div class="line"><span class="lineno">  274</span>            X,</div>
<div class="line"><span class="lineno">  275</span>            accept_sparse=<span class="stringliteral">&quot;csr&quot;</span>,</div>
<div class="line"><span class="lineno">  276</span>            dtype=np.float64,</div>
<div class="line"><span class="lineno">  277</span>            accept_large_sparse=solver <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&quot;liblinear&quot;</span>, <span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>],</div>
<div class="line"><span class="lineno">  278</span>        )</div>
<div class="line"><span class="lineno">  279</span>        y = check_array(y, ensure_2d=<span class="keyword">False</span>, dtype=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  280</span>        check_consistent_length(X, y)</div>
<div class="line"><span class="lineno">  281</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  282</span> </div>
<div class="line"><span class="lineno">  283</span>    classes = np.unique(y)</div>
<div class="line"><span class="lineno">  284</span>    random_state = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  285</span> </div>
<div class="line"><span class="lineno">  286</span>    multi_class = _check_multi_class(multi_class, solver, len(classes))</div>
<div class="line"><span class="lineno">  287</span>    <span class="keywordflow">if</span> pos_class <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> multi_class != <span class="stringliteral">&quot;multinomial&quot;</span>:</div>
<div class="line"><span class="lineno">  288</span>        <span class="keywordflow">if</span> classes.size &gt; 2:</div>
<div class="line"><span class="lineno">  289</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;To fit OvR, use the pos_class argument&quot;</span>)</div>
<div class="line"><span class="lineno">  290</span>        <span class="comment"># np.unique(y) gives labels in sorted order.</span></div>
<div class="line"><span class="lineno">  291</span>        pos_class = classes[1]</div>
<div class="line"><span class="lineno">  292</span> </div>
<div class="line"><span class="lineno">  293</span>    <span class="comment"># If sample weights exist, convert them to array (support for lists)</span></div>
<div class="line"><span class="lineno">  294</span>    <span class="comment"># and check length</span></div>
<div class="line"><span class="lineno">  295</span>    <span class="comment"># Otherwise set them to 1 for all examples</span></div>
<div class="line"><span class="lineno">  296</span>    sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype, copy=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  297</span> </div>
<div class="line"><span class="lineno">  298</span>    <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;newton-cholesky&quot;</span>:</div>
<div class="line"><span class="lineno">  299</span>        <span class="comment"># IMPORTANT NOTE: Rescaling of sample_weight:</span></div>
<div class="line"><span class="lineno">  300</span>        <span class="comment"># Same as in _GeneralizedLinearRegressor.fit().</span></div>
<div class="line"><span class="lineno">  301</span>        <span class="comment"># We want to minimize</span></div>
<div class="line"><span class="lineno">  302</span>        <span class="comment">#     obj = 1/(2*sum(sample_weight)) * sum(sample_weight * deviance)</span></div>
<div class="line"><span class="lineno">  303</span>        <span class="comment">#         + 1/2 * alpha * L2,</span></div>
<div class="line"><span class="lineno">  304</span>        <span class="comment"># with</span></div>
<div class="line"><span class="lineno">  305</span>        <span class="comment">#     deviance = 2 * log_loss.</span></div>
<div class="line"><span class="lineno">  306</span>        <span class="comment"># The objective is invariant to multiplying sample_weight by a constant. We</span></div>
<div class="line"><span class="lineno">  307</span>        <span class="comment"># choose this constant such that sum(sample_weight) = 1. Thus, we end up with</span></div>
<div class="line"><span class="lineno">  308</span>        <span class="comment">#     obj = sum(sample_weight * loss) + 1/2 * alpha * L2.</span></div>
<div class="line"><span class="lineno">  309</span>        <span class="comment"># Note that LinearModelLoss.loss() computes sum(sample_weight * loss).</span></div>
<div class="line"><span class="lineno">  310</span>        <span class="comment">#</span></div>
<div class="line"><span class="lineno">  311</span>        <span class="comment"># This rescaling has to be done before multiplying by class_weights.</span></div>
<div class="line"><span class="lineno">  312</span>        sw_sum = sample_weight.sum()  <span class="comment"># needed to rescale penalty, nasty matter!</span></div>
<div class="line"><span class="lineno">  313</span>        sample_weight = sample_weight / sw_sum</div>
<div class="line"><span class="lineno">  314</span> </div>
<div class="line"><span class="lineno">  315</span>    <span class="comment"># If class_weights is a dict (provided by the user), the weights</span></div>
<div class="line"><span class="lineno">  316</span>    <span class="comment"># are assigned to the original labels. If it is &quot;balanced&quot;, then</span></div>
<div class="line"><span class="lineno">  317</span>    <span class="comment"># the class_weights are assigned after masking the labels with a OvR.</span></div>
<div class="line"><span class="lineno">  318</span>    le = LabelEncoder()</div>
<div class="line"><span class="lineno">  319</span>    <span class="keywordflow">if</span> isinstance(class_weight, dict) <span class="keywordflow">or</span> multi_class == <span class="stringliteral">&quot;multinomial&quot;</span>:</div>
<div class="line"><span class="lineno">  320</span>        class_weight_ = compute_class_weight(class_weight, classes=classes, y=y)</div>
<div class="line"><span class="lineno">  321</span>        sample_weight *= class_weight_[le.fit_transform(y)]</div>
<div class="line"><span class="lineno">  322</span> </div>
<div class="line"><span class="lineno">  323</span>    <span class="comment"># For doing a ovr, we need to mask the labels first. For the</span></div>
<div class="line"><span class="lineno">  324</span>    <span class="comment"># multinomial case this is not necessary.</span></div>
<div class="line"><span class="lineno">  325</span>    <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;ovr&quot;</span>:</div>
<div class="line"><span class="lineno">  326</span>        w0 = np.zeros(n_features + int(fit_intercept), dtype=X.dtype)</div>
<div class="line"><span class="lineno">  327</span>        mask = y == pos_class</div>
<div class="line"><span class="lineno">  328</span>        y_bin = np.ones(y.shape, dtype=X.dtype)</div>
<div class="line"><span class="lineno">  329</span>        <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>, <span class="stringliteral">&quot;newton-cholesky&quot;</span>]:</div>
<div class="line"><span class="lineno">  330</span>            <span class="comment"># HalfBinomialLoss, used for those solvers, represents y in [0, 1] instead</span></div>
<div class="line"><span class="lineno">  331</span>            <span class="comment"># of in [-1, 1].</span></div>
<div class="line"><span class="lineno">  332</span>            mask_classes = np.array([0, 1])</div>
<div class="line"><span class="lineno">  333</span>            y_bin[~mask] = 0.0</div>
<div class="line"><span class="lineno">  334</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  335</span>            mask_classes = np.array([-1, 1])</div>
<div class="line"><span class="lineno">  336</span>            y_bin[~mask] = -1.0</div>
<div class="line"><span class="lineno">  337</span> </div>
<div class="line"><span class="lineno">  338</span>        <span class="comment"># for compute_class_weight</span></div>
<div class="line"><span class="lineno">  339</span>        <span class="keywordflow">if</span> class_weight == <span class="stringliteral">&quot;balanced&quot;</span>:</div>
<div class="line"><span class="lineno">  340</span>            class_weight_ = compute_class_weight(</div>
<div class="line"><span class="lineno">  341</span>                class_weight, classes=mask_classes, y=y_bin</div>
<div class="line"><span class="lineno">  342</span>            )</div>
<div class="line"><span class="lineno">  343</span>            sample_weight *= class_weight_[le.fit_transform(y_bin)]</div>
<div class="line"><span class="lineno">  344</span> </div>
<div class="line"><span class="lineno">  345</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  346</span>        <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>, <span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>]:</div>
<div class="line"><span class="lineno">  347</span>            <span class="comment"># SAG, lbfgs and newton-cg multinomial solvers need LabelEncoder,</span></div>
<div class="line"><span class="lineno">  348</span>            <span class="comment"># not LabelBinarizer, i.e. y as a 1d-array of integers.</span></div>
<div class="line"><span class="lineno">  349</span>            <span class="comment"># LabelEncoder also saves memory compared to LabelBinarizer, especially</span></div>
<div class="line"><span class="lineno">  350</span>            <span class="comment"># when n_classes is large.</span></div>
<div class="line"><span class="lineno">  351</span>            le = LabelEncoder()</div>
<div class="line"><span class="lineno">  352</span>            Y_multi = le.fit_transform(y).astype(X.dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  353</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  354</span>            <span class="comment"># For liblinear solver, apply LabelBinarizer, i.e. y is one-hot encoded.</span></div>
<div class="line"><span class="lineno">  355</span>            lbin = LabelBinarizer()</div>
<div class="line"><span class="lineno">  356</span>            Y_multi = lbin.fit_transform(y)</div>
<div class="line"><span class="lineno">  357</span>            <span class="keywordflow">if</span> Y_multi.shape[1] == 1:</div>
<div class="line"><span class="lineno">  358</span>                Y_multi = np.hstack([1 - Y_multi, Y_multi])</div>
<div class="line"><span class="lineno">  359</span> </div>
<div class="line"><span class="lineno">  360</span>        w0 = np.zeros(</div>
<div class="line"><span class="lineno">  361</span>            (classes.size, n_features + int(fit_intercept)), order=<span class="stringliteral">&quot;F&quot;</span>, dtype=X.dtype</div>
<div class="line"><span class="lineno">  362</span>        )</div>
<div class="line"><span class="lineno">  363</span> </div>
<div class="line"><span class="lineno">  364</span>    <span class="keywordflow">if</span> coef <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  365</span>        <span class="comment"># it must work both giving the bias term and not</span></div>
<div class="line"><span class="lineno">  366</span>        <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;ovr&quot;</span>:</div>
<div class="line"><span class="lineno">  367</span>            <span class="keywordflow">if</span> coef.size <span class="keywordflow">not</span> <span class="keywordflow">in</span> (n_features, w0.size):</div>
<div class="line"><span class="lineno">  368</span>                <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  369</span>                    <span class="stringliteral">&quot;Initialization coef is of shape %d, expected shape %d or %d&quot;</span></div>
<div class="line"><span class="lineno">  370</span>                    % (coef.size, n_features, w0.size)</div>
<div class="line"><span class="lineno">  371</span>                )</div>
<div class="line"><span class="lineno">  372</span>            w0[: coef.size] = coef</div>
<div class="line"><span class="lineno">  373</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  374</span>            <span class="comment"># For binary problems coef.shape[0] should be 1, otherwise it</span></div>
<div class="line"><span class="lineno">  375</span>            <span class="comment"># should be classes.size.</span></div>
<div class="line"><span class="lineno">  376</span>            n_classes = classes.size</div>
<div class="line"><span class="lineno">  377</span>            <span class="keywordflow">if</span> n_classes == 2:</div>
<div class="line"><span class="lineno">  378</span>                n_classes = 1</div>
<div class="line"><span class="lineno">  379</span> </div>
<div class="line"><span class="lineno">  380</span>            <span class="keywordflow">if</span> coef.shape[0] != n_classes <span class="keywordflow">or</span> coef.shape[1] <span class="keywordflow">not</span> <span class="keywordflow">in</span> (</div>
<div class="line"><span class="lineno">  381</span>                n_features,</div>
<div class="line"><span class="lineno">  382</span>                n_features + 1,</div>
<div class="line"><span class="lineno">  383</span>            ):</div>
<div class="line"><span class="lineno">  384</span>                <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  385</span>                    <span class="stringliteral">&quot;Initialization coef is of shape (%d, %d), expected &quot;</span></div>
<div class="line"><span class="lineno">  386</span>                    <span class="stringliteral">&quot;shape (%d, %d) or (%d, %d)&quot;</span></div>
<div class="line"><span class="lineno">  387</span>                    % (</div>
<div class="line"><span class="lineno">  388</span>                        coef.shape[0],</div>
<div class="line"><span class="lineno">  389</span>                        coef.shape[1],</div>
<div class="line"><span class="lineno">  390</span>                        classes.size,</div>
<div class="line"><span class="lineno">  391</span>                        n_features,</div>
<div class="line"><span class="lineno">  392</span>                        classes.size,</div>
<div class="line"><span class="lineno">  393</span>                        n_features + 1,</div>
<div class="line"><span class="lineno">  394</span>                    )</div>
<div class="line"><span class="lineno">  395</span>                )</div>
<div class="line"><span class="lineno">  396</span> </div>
<div class="line"><span class="lineno">  397</span>            <span class="keywordflow">if</span> n_classes == 1:</div>
<div class="line"><span class="lineno">  398</span>                w0[0, : coef.shape[1]] = -coef</div>
<div class="line"><span class="lineno">  399</span>                w0[1, : coef.shape[1]] = coef</div>
<div class="line"><span class="lineno">  400</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  401</span>                w0[:, : coef.shape[1]] = coef</div>
<div class="line"><span class="lineno">  402</span> </div>
<div class="line"><span class="lineno">  403</span>    <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;multinomial&quot;</span>:</div>
<div class="line"><span class="lineno">  404</span>        <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>]:</div>
<div class="line"><span class="lineno">  405</span>            <span class="comment"># scipy.optimize.minimize and newton-cg accept only ravelled parameters,</span></div>
<div class="line"><span class="lineno">  406</span>            <span class="comment"># i.e. 1d-arrays. LinearModelLoss expects classes to be contiguous and</span></div>
<div class="line"><span class="lineno">  407</span>            <span class="comment"># reconstructs the 2d-array via w0.reshape((n_classes, -1), order=&quot;F&quot;).</span></div>
<div class="line"><span class="lineno">  408</span>            <span class="comment"># As w0 is F-contiguous, ravel(order=&quot;F&quot;) also avoids a copy.</span></div>
<div class="line"><span class="lineno">  409</span>            w0 = w0.ravel(order=<span class="stringliteral">&quot;F&quot;</span>)</div>
<div class="line"><span class="lineno">  410</span>            loss = LinearModelLoss(</div>
<div class="line"><span class="lineno">  411</span>                base_loss=HalfMultinomialLoss(n_classes=classes.size),</div>
<div class="line"><span class="lineno">  412</span>                fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  413</span>            )</div>
<div class="line"><span class="lineno">  414</span>        target = Y_multi</div>
<div class="line"><span class="lineno">  415</span>        <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> <span class="stringliteral">&quot;lbfgs&quot;</span>:</div>
<div class="line"><span class="lineno">  416</span>            func = loss.loss_gradient</div>
<div class="line"><span class="lineno">  417</span>        <span class="keywordflow">elif</span> solver == <span class="stringliteral">&quot;newton-cg&quot;</span>:</div>
<div class="line"><span class="lineno">  418</span>            func = loss.loss</div>
<div class="line"><span class="lineno">  419</span>            grad = loss.gradient</div>
<div class="line"><span class="lineno">  420</span>            hess = loss.gradient_hessian_product  <span class="comment"># hess = [gradient, hessp]</span></div>
<div class="line"><span class="lineno">  421</span>        warm_start_sag = {<span class="stringliteral">&quot;coef&quot;</span>: w0.T}</div>
<div class="line"><span class="lineno">  422</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  423</span>        target = y_bin</div>
<div class="line"><span class="lineno">  424</span>        <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;lbfgs&quot;</span>:</div>
<div class="line"><span class="lineno">  425</span>            loss = LinearModelLoss(</div>
<div class="line"><span class="lineno">  426</span>                base_loss=HalfBinomialLoss(), fit_intercept=fit_intercept</div>
<div class="line"><span class="lineno">  427</span>            )</div>
<div class="line"><span class="lineno">  428</span>            func = loss.loss_gradient</div>
<div class="line"><span class="lineno">  429</span>        <span class="keywordflow">elif</span> solver == <span class="stringliteral">&quot;newton-cg&quot;</span>:</div>
<div class="line"><span class="lineno">  430</span>            loss = LinearModelLoss(</div>
<div class="line"><span class="lineno">  431</span>                base_loss=HalfBinomialLoss(), fit_intercept=fit_intercept</div>
<div class="line"><span class="lineno">  432</span>            )</div>
<div class="line"><span class="lineno">  433</span>            func = loss.loss</div>
<div class="line"><span class="lineno">  434</span>            grad = loss.gradient</div>
<div class="line"><span class="lineno">  435</span>            hess = loss.gradient_hessian_product  <span class="comment"># hess = [gradient, hessp]</span></div>
<div class="line"><span class="lineno">  436</span>        <span class="keywordflow">elif</span> solver == <span class="stringliteral">&quot;newton-cholesky&quot;</span>:</div>
<div class="line"><span class="lineno">  437</span>            loss = LinearModelLoss(</div>
<div class="line"><span class="lineno">  438</span>                base_loss=HalfBinomialLoss(), fit_intercept=fit_intercept</div>
<div class="line"><span class="lineno">  439</span>            )</div>
<div class="line"><span class="lineno">  440</span>        warm_start_sag = {<span class="stringliteral">&quot;coef&quot;</span>: np.expand_dims(w0, axis=1)}</div>
<div class="line"><span class="lineno">  441</span> </div>
<div class="line"><span class="lineno">  442</span>    coefs = list()</div>
<div class="line"><span class="lineno">  443</span>    n_iter = np.zeros(len(Cs), dtype=np.int32)</div>
<div class="line"><span class="lineno">  444</span>    <span class="keywordflow">for</span> i, C <span class="keywordflow">in</span> enumerate(Cs):</div>
<div class="line"><span class="lineno">  445</span>        <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;lbfgs&quot;</span>:</div>
<div class="line"><span class="lineno">  446</span>            l2_reg_strength = 1.0 / C</div>
<div class="line"><span class="lineno">  447</span>            iprint = [-1, 50, 1, 100, 101][</div>
<div class="line"><span class="lineno">  448</span>                np.searchsorted(np.array([0, 1, 2, 3]), verbose)</div>
<div class="line"><span class="lineno">  449</span>            ]</div>
<div class="line"><span class="lineno">  450</span>            opt_res = optimize.minimize(</div>
<div class="line"><span class="lineno">  451</span>                func,</div>
<div class="line"><span class="lineno">  452</span>                w0,</div>
<div class="line"><span class="lineno">  453</span>                method=<span class="stringliteral">&quot;L-BFGS-B&quot;</span>,</div>
<div class="line"><span class="lineno">  454</span>                jac=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  455</span>                args=(X, target, sample_weight, l2_reg_strength, n_threads),</div>
<div class="line"><span class="lineno">  456</span>                options={<span class="stringliteral">&quot;iprint&quot;</span>: iprint, <span class="stringliteral">&quot;gtol&quot;</span>: tol, <span class="stringliteral">&quot;maxiter&quot;</span>: max_iter},</div>
<div class="line"><span class="lineno">  457</span>            )</div>
<div class="line"><span class="lineno">  458</span>            n_iter_i = _check_optimize_result(</div>
<div class="line"><span class="lineno">  459</span>                solver,</div>
<div class="line"><span class="lineno">  460</span>                opt_res,</div>
<div class="line"><span class="lineno">  461</span>                max_iter,</div>
<div class="line"><span class="lineno">  462</span>                extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,</div>
<div class="line"><span class="lineno">  463</span>            )</div>
<div class="line"><span class="lineno">  464</span>            w0, loss = opt_res.x, opt_res.fun</div>
<div class="line"><span class="lineno">  465</span>        <span class="keywordflow">elif</span> solver == <span class="stringliteral">&quot;newton-cg&quot;</span>:</div>
<div class="line"><span class="lineno">  466</span>            l2_reg_strength = 1.0 / C</div>
<div class="line"><span class="lineno">  467</span>            args = (X, target, sample_weight, l2_reg_strength, n_threads)</div>
<div class="line"><span class="lineno">  468</span>            w0, n_iter_i = _newton_cg(</div>
<div class="line"><span class="lineno">  469</span>                hess, func, grad, w0, args=args, maxiter=max_iter, tol=tol</div>
<div class="line"><span class="lineno">  470</span>            )</div>
<div class="line"><span class="lineno">  471</span>        <span class="keywordflow">elif</span> solver == <span class="stringliteral">&quot;newton-cholesky&quot;</span>:</div>
<div class="line"><span class="lineno">  472</span>            <span class="comment"># The division by sw_sum is a consequence of the rescaling of</span></div>
<div class="line"><span class="lineno">  473</span>            <span class="comment"># sample_weight, see comment above.</span></div>
<div class="line"><span class="lineno">  474</span>            l2_reg_strength = 1.0 / C / sw_sum</div>
<div class="line"><span class="lineno">  475</span>            sol = NewtonCholeskySolver(</div>
<div class="line"><span class="lineno">  476</span>                coef=w0,</div>
<div class="line"><span class="lineno">  477</span>                linear_loss=loss,</div>
<div class="line"><span class="lineno">  478</span>                l2_reg_strength=l2_reg_strength,</div>
<div class="line"><span class="lineno">  479</span>                tol=tol,</div>
<div class="line"><span class="lineno">  480</span>                max_iter=max_iter,</div>
<div class="line"><span class="lineno">  481</span>                n_threads=n_threads,</div>
<div class="line"><span class="lineno">  482</span>                verbose=verbose,</div>
<div class="line"><span class="lineno">  483</span>            )</div>
<div class="line"><span class="lineno">  484</span>            w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  485</span>            n_iter_i = sol.iteration</div>
<div class="line"><span class="lineno">  486</span>        <span class="keywordflow">elif</span> solver == <span class="stringliteral">&quot;liblinear&quot;</span>:</div>
<div class="line"><span class="lineno">  487</span>            coef_, intercept_, n_iter_i, = _fit_liblinear(</div>
<div class="line"><span class="lineno">  488</span>                X,</div>
<div class="line"><span class="lineno">  489</span>                target,</div>
<div class="line"><span class="lineno">  490</span>                C,</div>
<div class="line"><span class="lineno">  491</span>                fit_intercept,</div>
<div class="line"><span class="lineno">  492</span>                intercept_scaling,</div>
<div class="line"><span class="lineno">  493</span>                <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  494</span>                penalty,</div>
<div class="line"><span class="lineno">  495</span>                dual,</div>
<div class="line"><span class="lineno">  496</span>                verbose,</div>
<div class="line"><span class="lineno">  497</span>                max_iter,</div>
<div class="line"><span class="lineno">  498</span>                tol,</div>
<div class="line"><span class="lineno">  499</span>                random_state,</div>
<div class="line"><span class="lineno">  500</span>                sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  501</span>            )</div>
<div class="line"><span class="lineno">  502</span>            <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno">  503</span>                w0 = np.concatenate([coef_.ravel(), intercept_])</div>
<div class="line"><span class="lineno">  504</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  505</span>                w0 = coef_.ravel()</div>
<div class="line"><span class="lineno">  506</span> </div>
<div class="line"><span class="lineno">  507</span>        <span class="keywordflow">elif</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]:</div>
<div class="line"><span class="lineno">  508</span>            <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;multinomial&quot;</span>:</div>
<div class="line"><span class="lineno">  509</span>                target = target.astype(X.dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  510</span>                loss = <span class="stringliteral">&quot;multinomial&quot;</span></div>
<div class="line"><span class="lineno">  511</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  512</span>                loss = <span class="stringliteral">&quot;log&quot;</span></div>
<div class="line"><span class="lineno">  513</span>            <span class="comment"># alpha is for L2-norm, beta is for L1-norm</span></div>
<div class="line"><span class="lineno">  514</span>            <span class="keywordflow">if</span> penalty == <span class="stringliteral">&quot;l1&quot;</span>:</div>
<div class="line"><span class="lineno">  515</span>                alpha = 0.0</div>
<div class="line"><span class="lineno">  516</span>                beta = 1.0 / C</div>
<div class="line"><span class="lineno">  517</span>            <span class="keywordflow">elif</span> penalty == <span class="stringliteral">&quot;l2&quot;</span>:</div>
<div class="line"><span class="lineno">  518</span>                alpha = 1.0 / C</div>
<div class="line"><span class="lineno">  519</span>                beta = 0.0</div>
<div class="line"><span class="lineno">  520</span>            <span class="keywordflow">else</span>:  <span class="comment"># Elastic-Net penalty</span></div>
<div class="line"><span class="lineno">  521</span>                alpha = (1.0 / C) * (1 - l1_ratio)</div>
<div class="line"><span class="lineno">  522</span>                beta = (1.0 / C) * l1_ratio</div>
<div class="line"><span class="lineno">  523</span> </div>
<div class="line"><span class="lineno">  524</span>            w0, n_iter_i, warm_start_sag = sag_solver(</div>
<div class="line"><span class="lineno">  525</span>                X,</div>
<div class="line"><span class="lineno">  526</span>                target,</div>
<div class="line"><span class="lineno">  527</span>                sample_weight,</div>
<div class="line"><span class="lineno">  528</span>                loss,</div>
<div class="line"><span class="lineno">  529</span>                alpha,</div>
<div class="line"><span class="lineno">  530</span>                beta,</div>
<div class="line"><span class="lineno">  531</span>                max_iter,</div>
<div class="line"><span class="lineno">  532</span>                tol,</div>
<div class="line"><span class="lineno">  533</span>                verbose,</div>
<div class="line"><span class="lineno">  534</span>                random_state,</div>
<div class="line"><span class="lineno">  535</span>                <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  536</span>                max_squared_sum,</div>
<div class="line"><span class="lineno">  537</span>                warm_start_sag,</div>
<div class="line"><span class="lineno">  538</span>                is_saga=(solver == <span class="stringliteral">&quot;saga&quot;</span>),</div>
<div class="line"><span class="lineno">  539</span>            )</div>
<div class="line"><span class="lineno">  540</span> </div>
<div class="line"><span class="lineno">  541</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  542</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  543</span>                <span class="stringliteral">&quot;solver must be one of {&#39;liblinear&#39;, &#39;lbfgs&#39;, &quot;</span></div>
<div class="line"><span class="lineno">  544</span>                <span class="stringliteral">&quot;&#39;newton-cg&#39;, &#39;sag&#39;}, got &#39;%s&#39; instead&quot;</span> % solver</div>
<div class="line"><span class="lineno">  545</span>            )</div>
<div class="line"><span class="lineno">  546</span> </div>
<div class="line"><span class="lineno">  547</span>        <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;multinomial&quot;</span>:</div>
<div class="line"><span class="lineno">  548</span>            n_classes = max(2, classes.size)</div>
<div class="line"><span class="lineno">  549</span>            <span class="keywordflow">if</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;newton-cg&quot;</span>]:</div>
<div class="line"><span class="lineno">  550</span>                multi_w0 = np.reshape(w0, (n_classes, -1), order=<span class="stringliteral">&quot;F&quot;</span>)</div>
<div class="line"><span class="lineno">  551</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  552</span>                multi_w0 = w0</div>
<div class="line"><span class="lineno">  553</span>            <span class="keywordflow">if</span> n_classes == 2:</div>
<div class="line"><span class="lineno">  554</span>                multi_w0 = multi_w0[1][np.newaxis, :]</div>
<div class="line"><span class="lineno">  555</span>            coefs.append(multi_w0.copy())</div>
<div class="line"><span class="lineno">  556</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  557</span>            coefs.append(w0.copy())</div>
<div class="line"><span class="lineno">  558</span> </div>
<div class="line"><span class="lineno">  559</span>        n_iter[i] = n_iter_i</div>
<div class="line"><span class="lineno">  560</span> </div>
<div class="line"><span class="lineno">  561</span>    <span class="keywordflow">return</span> np.array(coefs), np.array(Cs), n_iter</div>
<div class="line"><span class="lineno">  562</span> </div>
<div class="line"><span class="lineno">  563</span> </div>
<div class="line"><span class="lineno">  564</span><span class="comment"># helper function for LogisticCV</span></div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a59835dda5959e60841bcb83a1c6e452e" name="a59835dda5959e60841bcb83a1c6e452e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59835dda5959e60841bcb83a1c6e452e">&#9670;&#160;</a></span>_LOGISTIC_SOLVER_CONVERGENCE_MSG</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">tuple sklearn.linear_model._logistic._LOGISTIC_SOLVER_CONVERGENCE_MSG</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  (</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;Please also refer to the documentation for alternative solver options:\n&quot;</span></div>
<div class="line"><span class="lineno">    3</span>    <span class="stringliteral">&quot;    https://scikit-learn.org/stable/modules/linear_model.html&quot;</span></div>
<div class="line"><span class="lineno">    4</span>    <span class="stringliteral">&quot;#logistic-regression&quot;</span></div>
<div class="line"><span class="lineno">    5</span>)</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
