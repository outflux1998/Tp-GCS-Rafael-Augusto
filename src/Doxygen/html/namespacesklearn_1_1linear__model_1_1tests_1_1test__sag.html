<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.linear_model.tests.test_sag Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model.html">linear_model</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html">test_sag</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.linear_model.tests.test_sag Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a7b3394599aa3ec43b1fd642569dfec73" id="r_a7b3394599aa3ec43b1fd642569dfec73"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a7b3394599aa3ec43b1fd642569dfec73">log_dloss</a> (p, y)</td></tr>
<tr class="separator:a7b3394599aa3ec43b1fd642569dfec73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92f519f85b7a1851a5040cc39b7cdf9c" id="r_a92f519f85b7a1851a5040cc39b7cdf9c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a92f519f85b7a1851a5040cc39b7cdf9c">log_loss</a> (p, y)</td></tr>
<tr class="separator:a92f519f85b7a1851a5040cc39b7cdf9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9879a03e1d834409d68f9e871677f178" id="r_a9879a03e1d834409d68f9e871677f178"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a9879a03e1d834409d68f9e871677f178">squared_dloss</a> (p, y)</td></tr>
<tr class="separator:a9879a03e1d834409d68f9e871677f178"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59dab525fd7483146442f278ed300ecc" id="r_a59dab525fd7483146442f278ed300ecc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a59dab525fd7483146442f278ed300ecc">squared_loss</a> (p, y)</td></tr>
<tr class="separator:a59dab525fd7483146442f278ed300ecc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a1158f485c53f6ca8a224d0e0baf642" id="r_a0a1158f485c53f6ca8a224d0e0baf642"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a0a1158f485c53f6ca8a224d0e0baf642">get_pobj</a> (<a class="el" href="__lapack__subroutines_8h.html#a817b85d82af73ef273fafbec623bb90b">w</a>, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, myX, myy, loss)</td></tr>
<tr class="separator:a0a1158f485c53f6ca8a224d0e0baf642"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1049cbb73773d2f5ffb180b4ffd7b772" id="r_a1049cbb73773d2f5ffb180b4ffd7b772"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a1049cbb73773d2f5ffb180b4ffd7b772">sag</a> (X, y, step_size, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, n_iter=1, dloss=None, sparse=False, sample_weight=None, fit_intercept=True, saga=False)</td></tr>
<tr class="separator:a1049cbb73773d2f5ffb180b4ffd7b772"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a3b42c80c6a6af37ee953741718885b" id="r_a7a3b42c80c6a6af37ee953741718885b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a7a3b42c80c6a6af37ee953741718885b">sag_sparse</a> (X, y, step_size, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, n_iter=1, dloss=None, sample_weight=None, sparse=False, fit_intercept=True, saga=False, random_state=0)</td></tr>
<tr class="separator:a7a3b42c80c6a6af37ee953741718885b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe3fb0a9fd4a1244eb5954cd9078f3ea" id="r_abe3fb0a9fd4a1244eb5954cd9078f3ea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#abe3fb0a9fd4a1244eb5954cd9078f3ea">get_step_size</a> (X, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, fit_intercept, classification=True)</td></tr>
<tr class="separator:abe3fb0a9fd4a1244eb5954cd9078f3ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84b1b9a0671c988a7f33c62a7d9e6950" id="r_a84b1b9a0671c988a7f33c62a7d9e6950"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a84b1b9a0671c988a7f33c62a7d9e6950">test_classifier_matching</a> ()</td></tr>
<tr class="separator:a84b1b9a0671c988a7f33c62a7d9e6950"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3b3d6a54cd7764253f8877b94f8d8a4" id="r_ab3b3d6a54cd7764253f8877b94f8d8a4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#ab3b3d6a54cd7764253f8877b94f8d8a4">test_regressor_matching</a> ()</td></tr>
<tr class="separator:ab3b3d6a54cd7764253f8877b94f8d8a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2b7a86c68348192a6ce24757c7cad54" id="r_ac2b7a86c68348192a6ce24757c7cad54"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#ac2b7a86c68348192a6ce24757c7cad54">test_sag_pobj_matches_logistic_regression</a> ()</td></tr>
<tr class="separator:ac2b7a86c68348192a6ce24757c7cad54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7f5714908782328471d0e434651b36b" id="r_ad7f5714908782328471d0e434651b36b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#ad7f5714908782328471d0e434651b36b">test_sag_pobj_matches_ridge_regression</a> ()</td></tr>
<tr class="separator:ad7f5714908782328471d0e434651b36b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab95a592c7ab3d2ddbf11e5329cc18bfe" id="r_ab95a592c7ab3d2ddbf11e5329cc18bfe"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#ab95a592c7ab3d2ddbf11e5329cc18bfe">test_sag_regressor_computed_correctly</a> ()</td></tr>
<tr class="separator:ab95a592c7ab3d2ddbf11e5329cc18bfe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada550e837676cd5df2816973d84be5fc" id="r_ada550e837676cd5df2816973d84be5fc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#ada550e837676cd5df2816973d84be5fc">test_get_auto_step_size</a> ()</td></tr>
<tr class="separator:ada550e837676cd5df2816973d84be5fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1437e57f76233b0fbd4a2c09026cf426" id="r_a1437e57f76233b0fbd4a2c09026cf426"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a1437e57f76233b0fbd4a2c09026cf426">test_sag_regressor</a> (seed)</td></tr>
<tr class="separator:a1437e57f76233b0fbd4a2c09026cf426"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afaffd4fa137e28a04e939653d546d3fe" id="r_afaffd4fa137e28a04e939653d546d3fe"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#afaffd4fa137e28a04e939653d546d3fe">test_sag_classifier_computed_correctly</a> ()</td></tr>
<tr class="separator:afaffd4fa137e28a04e939653d546d3fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d812bcd732ad9151fd8f583790331b5" id="r_a1d812bcd732ad9151fd8f583790331b5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a1d812bcd732ad9151fd8f583790331b5">test_sag_multiclass_computed_correctly</a> ()</td></tr>
<tr class="separator:a1d812bcd732ad9151fd8f583790331b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22e79647db994188cf5d621283c27d14" id="r_a22e79647db994188cf5d621283c27d14"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a22e79647db994188cf5d621283c27d14">test_classifier_results</a> ()</td></tr>
<tr class="separator:a22e79647db994188cf5d621283c27d14"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaab136c1bb858d7e75a229d8928002e9" id="r_aaab136c1bb858d7e75a229d8928002e9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#aaab136c1bb858d7e75a229d8928002e9">test_binary_classifier_class_weight</a> ()</td></tr>
<tr class="separator:aaab136c1bb858d7e75a229d8928002e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4419c1d85fa1635e11ed33c4dcb7729" id="r_aa4419c1d85fa1635e11ed33c4dcb7729"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#aa4419c1d85fa1635e11ed33c4dcb7729">test_multiclass_classifier_class_weight</a> ()</td></tr>
<tr class="separator:aa4419c1d85fa1635e11ed33c4dcb7729"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6dc7e22916ac14060c484eb012efebab" id="r_a6dc7e22916ac14060c484eb012efebab"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a6dc7e22916ac14060c484eb012efebab">test_classifier_single_class</a> ()</td></tr>
<tr class="separator:a6dc7e22916ac14060c484eb012efebab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23bfaca22a3cd68fb247e0554dcd74a0" id="r_a23bfaca22a3cd68fb247e0554dcd74a0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a23bfaca22a3cd68fb247e0554dcd74a0">test_step_size_alpha_error</a> ()</td></tr>
<tr class="separator:a23bfaca22a3cd68fb247e0554dcd74a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56ed6289e366107125c68928b3473e1f" id="r_a56ed6289e366107125c68928b3473e1f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a56ed6289e366107125c68928b3473e1f">test_multinomial_loss</a> ()</td></tr>
<tr class="separator:a56ed6289e366107125c68928b3473e1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2471c0278f591c9d5593a7bae252876b" id="r_a2471c0278f591c9d5593a7bae252876b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a2471c0278f591c9d5593a7bae252876b">test_multinomial_loss_ground_truth</a> ()</td></tr>
<tr class="separator:a2471c0278f591c9d5593a7bae252876b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05ad10f1fcf94c17237e9a47a00fd85e" id="r_a05ad10f1fcf94c17237e9a47a00fd85e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a05ad10f1fcf94c17237e9a47a00fd85e">test_sag_classifier_raises_error</a> (solver)</td></tr>
<tr class="separator:a05ad10f1fcf94c17237e9a47a00fd85e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a18f7a31c3b953db84cda4e2856075851" id="r_a18f7a31c3b953db84cda4e2856075851"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1linear__model_1_1tests_1_1test__sag.html#a18f7a31c3b953db84cda4e2856075851">iris</a> = load_iris()</td></tr>
<tr class="separator:a18f7a31c3b953db84cda4e2856075851"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a0a1158f485c53f6ca8a224d0e0baf642" name="a0a1158f485c53f6ca8a224d0e0baf642"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a1158f485c53f6ca8a224d0e0baf642">&#9670;&#160;</a></span>get_pobj()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.get_pobj </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>myX</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>myy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   58</span><span class="keyword">def </span>get_pobj(w, alpha, myX, myy, loss):</div>
<div class="line"><span class="lineno">   59</span>    w = w.ravel()</div>
<div class="line"><span class="lineno">   60</span>    pred = np.dot(myX, w)</div>
<div class="line"><span class="lineno">   61</span>    p = loss(pred, myy)</div>
<div class="line"><span class="lineno">   62</span>    p += alpha * w.dot(w) / 2.0</div>
<div class="line"><span class="lineno">   63</span>    <span class="keywordflow">return</span> p</div>
<div class="line"><span class="lineno">   64</span> </div>
<div class="line"><span class="lineno">   65</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abe3fb0a9fd4a1244eb5954cd9078f3ea" name="abe3fb0a9fd4a1244eb5954cd9078f3ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe3fb0a9fd4a1244eb5954cd9078f3ea">&#9670;&#160;</a></span>get_step_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.get_step_size </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>classification</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  247</span><span class="keyword">def </span>get_step_size(X, alpha, fit_intercept, classification=True):</div>
<div class="line"><span class="lineno">  248</span>    <span class="keywordflow">if</span> classification:</div>
<div class="line"><span class="lineno">  249</span>        <span class="keywordflow">return</span> 4.0 / (np.max(np.sum(X * X, axis=1)) + fit_intercept + 4.0 * alpha)</div>
<div class="line"><span class="lineno">  250</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  251</span>        <span class="keywordflow">return</span> 1.0 / (np.max(np.sum(X * X, axis=1)) + fit_intercept + alpha)</div>
<div class="line"><span class="lineno">  252</span> </div>
<div class="line"><span class="lineno">  253</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7b3394599aa3ec43b1fd642569dfec73" name="a7b3394599aa3ec43b1fd642569dfec73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b3394599aa3ec43b1fd642569dfec73">&#9670;&#160;</a></span>log_dloss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.log_dloss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>p</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   34</span><span class="keyword">def </span>log_dloss(p, y):</div>
<div class="line"><span class="lineno">   35</span>    z = p * y</div>
<div class="line"><span class="lineno">   36</span>    <span class="comment"># approximately equal and saves the computation of the log</span></div>
<div class="line"><span class="lineno">   37</span>    <span class="keywordflow">if</span> z &gt; 18.0:</div>
<div class="line"><span class="lineno">   38</span>        <span class="keywordflow">return</span> math.exp(-z) * -y</div>
<div class="line"><span class="lineno">   39</span>    <span class="keywordflow">if</span> z &lt; -18.0:</div>
<div class="line"><span class="lineno">   40</span>        <span class="keywordflow">return</span> -y</div>
<div class="line"><span class="lineno">   41</span>    <span class="keywordflow">return</span> -y / (math.exp(z) + 1.0)</div>
<div class="line"><span class="lineno">   42</span> </div>
<div class="line"><span class="lineno">   43</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a92f519f85b7a1851a5040cc39b7cdf9c" name="a92f519f85b7a1851a5040cc39b7cdf9c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a92f519f85b7a1851a5040cc39b7cdf9c">&#9670;&#160;</a></span>log_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.log_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>p</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   44</span><span class="keyword">def </span>log_loss(p, y):</div>
<div class="line"><span class="lineno">   45</span>    <span class="keywordflow">return</span> np.mean(np.log(1.0 + np.exp(-y * p)))</div>
<div class="line"><span class="lineno">   46</span> </div>
<div class="line"><span class="lineno">   47</span> </div>
<div class="line"><span class="lineno">   48</span><span class="comment"># this is used for sag regression</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a1049cbb73773d2f5ffb180b4ffd7b772" name="a1049cbb73773d2f5ffb180b4ffd7b772"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1049cbb73773d2f5ffb180b4ffd7b772">&#9670;&#160;</a></span>sag()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.sag </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>step_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_iter</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dloss</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sparse</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>saga</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   77</span>):</div>
<div class="line"><span class="lineno">   78</span>    n_samples, n_features = X.shape[0], X.shape[1]</div>
<div class="line"><span class="lineno">   79</span> </div>
<div class="line"><span class="lineno">   80</span>    weights = np.zeros(X.shape[1])</div>
<div class="line"><span class="lineno">   81</span>    sum_gradient = np.zeros(X.shape[1])</div>
<div class="line"><span class="lineno">   82</span>    gradient_memory = np.zeros((n_samples, n_features))</div>
<div class="line"><span class="lineno">   83</span> </div>
<div class="line"><span class="lineno">   84</span>    intercept = 0.0</div>
<div class="line"><span class="lineno">   85</span>    intercept_sum_gradient = 0.0</div>
<div class="line"><span class="lineno">   86</span>    intercept_gradient_memory = np.zeros(n_samples)</div>
<div class="line"><span class="lineno">   87</span> </div>
<div class="line"><span class="lineno">   88</span>    rng = np.random.RandomState(77)</div>
<div class="line"><span class="lineno">   89</span>    decay = 1.0</div>
<div class="line"><span class="lineno">   90</span>    seen = set()</div>
<div class="line"><span class="lineno">   91</span> </div>
<div class="line"><span class="lineno">   92</span>    <span class="comment"># sparse data has a fixed decay of .01</span></div>
<div class="line"><span class="lineno">   93</span>    <span class="keywordflow">if</span> sparse:</div>
<div class="line"><span class="lineno">   94</span>        decay = 0.01</div>
<div class="line"><span class="lineno">   95</span> </div>
<div class="line"><span class="lineno">   96</span>    <span class="keywordflow">for</span> epoch <span class="keywordflow">in</span> range(n_iter):</div>
<div class="line"><span class="lineno">   97</span>        <span class="keywordflow">for</span> k <span class="keywordflow">in</span> range(n_samples):</div>
<div class="line"><span class="lineno">   98</span>            idx = int(rng.rand(1) * n_samples)</div>
<div class="line"><span class="lineno">   99</span>            <span class="comment"># idx = k</span></div>
<div class="line"><span class="lineno">  100</span>            entry = X[idx]</div>
<div class="line"><span class="lineno">  101</span>            seen.add(idx)</div>
<div class="line"><span class="lineno">  102</span>            p = np.dot(entry, weights) + intercept</div>
<div class="line"><span class="lineno">  103</span>            gradient = dloss(p, y[idx])</div>
<div class="line"><span class="lineno">  104</span>            <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  105</span>                gradient *= sample_weight[idx]</div>
<div class="line"><span class="lineno">  106</span>            update = entry * gradient + alpha * weights</div>
<div class="line"><span class="lineno">  107</span>            gradient_correction = update - gradient_memory[idx]</div>
<div class="line"><span class="lineno">  108</span>            sum_gradient += gradient_correction</div>
<div class="line"><span class="lineno">  109</span>            gradient_memory[idx] = update</div>
<div class="line"><span class="lineno">  110</span>            <span class="keywordflow">if</span> saga:</div>
<div class="line"><span class="lineno">  111</span>                weights -= gradient_correction * step_size * (1 - 1.0 / len(seen))</div>
<div class="line"><span class="lineno">  112</span> </div>
<div class="line"><span class="lineno">  113</span>            <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno">  114</span>                gradient_correction = gradient - intercept_gradient_memory[idx]</div>
<div class="line"><span class="lineno">  115</span>                intercept_gradient_memory[idx] = gradient</div>
<div class="line"><span class="lineno">  116</span>                intercept_sum_gradient += gradient_correction</div>
<div class="line"><span class="lineno">  117</span>                gradient_correction *= step_size * (1.0 - 1.0 / len(seen))</div>
<div class="line"><span class="lineno">  118</span>                <span class="keywordflow">if</span> saga:</div>
<div class="line"><span class="lineno">  119</span>                    intercept -= (</div>
<div class="line"><span class="lineno">  120</span>                        step_size * intercept_sum_gradient / len(seen) * decay</div>
<div class="line"><span class="lineno">  121</span>                    ) + gradient_correction</div>
<div class="line"><span class="lineno">  122</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  123</span>                    intercept -= step_size * intercept_sum_gradient / len(seen) * decay</div>
<div class="line"><span class="lineno">  124</span> </div>
<div class="line"><span class="lineno">  125</span>            weights -= step_size * sum_gradient / len(seen)</div>
<div class="line"><span class="lineno">  126</span> </div>
<div class="line"><span class="lineno">  127</span>    <span class="keywordflow">return</span> weights, intercept</div>
<div class="line"><span class="lineno">  128</span> </div>
<div class="line"><span class="lineno">  129</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7a3b42c80c6a6af37ee953741718885b" name="a7a3b42c80c6a6af37ee953741718885b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7a3b42c80c6a6af37ee953741718885b">&#9670;&#160;</a></span>sag_sparse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.sag_sparse </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>step_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_iter</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dloss</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sparse</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fit_intercept</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>saga</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  142</span>):</div>
<div class="line"><span class="lineno">  143</span>    <span class="keywordflow">if</span> step_size * alpha == 1.0:</div>
<div class="line"><span class="lineno">  144</span>        <span class="keywordflow">raise</span> ZeroDivisionError(</div>
<div class="line"><span class="lineno">  145</span>            <span class="stringliteral">&quot;Sparse sag does not handle the case step_size * alpha == 1&quot;</span></div>
<div class="line"><span class="lineno">  146</span>        )</div>
<div class="line"><span class="lineno">  147</span>    n_samples, n_features = X.shape[0], X.shape[1]</div>
<div class="line"><span class="lineno">  148</span> </div>
<div class="line"><span class="lineno">  149</span>    weights = np.zeros(n_features)</div>
<div class="line"><span class="lineno">  150</span>    sum_gradient = np.zeros(n_features)</div>
<div class="line"><span class="lineno">  151</span>    last_updated = np.zeros(n_features, dtype=int)</div>
<div class="line"><span class="lineno">  152</span>    gradient_memory = np.zeros(n_samples)</div>
<div class="line"><span class="lineno">  153</span>    rng = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  154</span>    intercept = 0.0</div>
<div class="line"><span class="lineno">  155</span>    intercept_sum_gradient = 0.0</div>
<div class="line"><span class="lineno">  156</span>    wscale = 1.0</div>
<div class="line"><span class="lineno">  157</span>    decay = 1.0</div>
<div class="line"><span class="lineno">  158</span>    seen = set()</div>
<div class="line"><span class="lineno">  159</span> </div>
<div class="line"><span class="lineno">  160</span>    c_sum = np.zeros(n_iter * n_samples)</div>
<div class="line"><span class="lineno">  161</span> </div>
<div class="line"><span class="lineno">  162</span>    <span class="comment"># sparse data has a fixed decay of .01</span></div>
<div class="line"><span class="lineno">  163</span>    <span class="keywordflow">if</span> sparse:</div>
<div class="line"><span class="lineno">  164</span>        decay = 0.01</div>
<div class="line"><span class="lineno">  165</span> </div>
<div class="line"><span class="lineno">  166</span>    counter = 0</div>
<div class="line"><span class="lineno">  167</span>    <span class="keywordflow">for</span> epoch <span class="keywordflow">in</span> range(n_iter):</div>
<div class="line"><span class="lineno">  168</span>        <span class="keywordflow">for</span> k <span class="keywordflow">in</span> range(n_samples):</div>
<div class="line"><span class="lineno">  169</span>            <span class="comment"># idx = k</span></div>
<div class="line"><span class="lineno">  170</span>            idx = int(rng.rand(1) * n_samples)</div>
<div class="line"><span class="lineno">  171</span>            entry = X[idx]</div>
<div class="line"><span class="lineno">  172</span>            seen.add(idx)</div>
<div class="line"><span class="lineno">  173</span> </div>
<div class="line"><span class="lineno">  174</span>            <span class="keywordflow">if</span> counter &gt;= 1:</div>
<div class="line"><span class="lineno">  175</span>                <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(n_features):</div>
<div class="line"><span class="lineno">  176</span>                    <span class="keywordflow">if</span> last_updated[j] == 0:</div>
<div class="line"><span class="lineno">  177</span>                        weights[j] -= c_sum[counter - 1] * sum_gradient[j]</div>
<div class="line"><span class="lineno">  178</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  179</span>                        weights[j] -= (</div>
<div class="line"><span class="lineno">  180</span>                            c_sum[counter - 1] - c_sum[last_updated[j] - 1]</div>
<div class="line"><span class="lineno">  181</span>                        ) * sum_gradient[j]</div>
<div class="line"><span class="lineno">  182</span>                    last_updated[j] = counter</div>
<div class="line"><span class="lineno">  183</span> </div>
<div class="line"><span class="lineno">  184</span>            p = (wscale * np.dot(entry, weights)) + intercept</div>
<div class="line"><span class="lineno">  185</span>            gradient = dloss(p, y[idx])</div>
<div class="line"><span class="lineno">  186</span> </div>
<div class="line"><span class="lineno">  187</span>            <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  188</span>                gradient *= sample_weight[idx]</div>
<div class="line"><span class="lineno">  189</span> </div>
<div class="line"><span class="lineno">  190</span>            update = entry * gradient</div>
<div class="line"><span class="lineno">  191</span>            gradient_correction = update - (gradient_memory[idx] * entry)</div>
<div class="line"><span class="lineno">  192</span>            sum_gradient += gradient_correction</div>
<div class="line"><span class="lineno">  193</span>            <span class="keywordflow">if</span> saga:</div>
<div class="line"><span class="lineno">  194</span>                <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(n_features):</div>
<div class="line"><span class="lineno">  195</span>                    weights[j] -= (</div>
<div class="line"><span class="lineno">  196</span>                        gradient_correction[j]</div>
<div class="line"><span class="lineno">  197</span>                        * step_size</div>
<div class="line"><span class="lineno">  198</span>                        * (1 - 1.0 / len(seen))</div>
<div class="line"><span class="lineno">  199</span>                        / wscale</div>
<div class="line"><span class="lineno">  200</span>                    )</div>
<div class="line"><span class="lineno">  201</span> </div>
<div class="line"><span class="lineno">  202</span>            <span class="keywordflow">if</span> fit_intercept:</div>
<div class="line"><span class="lineno">  203</span>                gradient_correction = gradient - gradient_memory[idx]</div>
<div class="line"><span class="lineno">  204</span>                intercept_sum_gradient += gradient_correction</div>
<div class="line"><span class="lineno">  205</span>                gradient_correction *= step_size * (1.0 - 1.0 / len(seen))</div>
<div class="line"><span class="lineno">  206</span>                <span class="keywordflow">if</span> saga:</div>
<div class="line"><span class="lineno">  207</span>                    intercept -= (</div>
<div class="line"><span class="lineno">  208</span>                        step_size * intercept_sum_gradient / len(seen) * decay</div>
<div class="line"><span class="lineno">  209</span>                    ) + gradient_correction</div>
<div class="line"><span class="lineno">  210</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  211</span>                    intercept -= step_size * intercept_sum_gradient / len(seen) * decay</div>
<div class="line"><span class="lineno">  212</span> </div>
<div class="line"><span class="lineno">  213</span>            gradient_memory[idx] = gradient</div>
<div class="line"><span class="lineno">  214</span> </div>
<div class="line"><span class="lineno">  215</span>            wscale *= 1.0 - alpha * step_size</div>
<div class="line"><span class="lineno">  216</span>            <span class="keywordflow">if</span> counter == 0:</div>
<div class="line"><span class="lineno">  217</span>                c_sum[0] = step_size / (wscale * len(seen))</div>
<div class="line"><span class="lineno">  218</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  219</span>                c_sum[counter] = c_sum[counter - 1] + step_size / (wscale * len(seen))</div>
<div class="line"><span class="lineno">  220</span> </div>
<div class="line"><span class="lineno">  221</span>            <span class="keywordflow">if</span> counter &gt;= 1 <span class="keywordflow">and</span> wscale &lt; 1e-9:</div>
<div class="line"><span class="lineno">  222</span>                <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(n_features):</div>
<div class="line"><span class="lineno">  223</span>                    <span class="keywordflow">if</span> last_updated[j] == 0:</div>
<div class="line"><span class="lineno">  224</span>                        weights[j] -= c_sum[counter] * sum_gradient[j]</div>
<div class="line"><span class="lineno">  225</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  226</span>                        weights[j] -= (</div>
<div class="line"><span class="lineno">  227</span>                            c_sum[counter] - c_sum[last_updated[j] - 1]</div>
<div class="line"><span class="lineno">  228</span>                        ) * sum_gradient[j]</div>
<div class="line"><span class="lineno">  229</span>                    last_updated[j] = counter + 1</div>
<div class="line"><span class="lineno">  230</span>                c_sum[counter] = 0</div>
<div class="line"><span class="lineno">  231</span>                weights *= wscale</div>
<div class="line"><span class="lineno">  232</span>                wscale = 1.0</div>
<div class="line"><span class="lineno">  233</span> </div>
<div class="line"><span class="lineno">  234</span>            counter += 1</div>
<div class="line"><span class="lineno">  235</span> </div>
<div class="line"><span class="lineno">  236</span>    <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(n_features):</div>
<div class="line"><span class="lineno">  237</span>        <span class="keywordflow">if</span> last_updated[j] == 0:</div>
<div class="line"><span class="lineno">  238</span>            weights[j] -= c_sum[counter - 1] * sum_gradient[j]</div>
<div class="line"><span class="lineno">  239</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  240</span>            weights[j] -= (</div>
<div class="line"><span class="lineno">  241</span>                c_sum[counter - 1] - c_sum[last_updated[j] - 1]</div>
<div class="line"><span class="lineno">  242</span>            ) * sum_gradient[j]</div>
<div class="line"><span class="lineno">  243</span>    weights *= wscale</div>
<div class="line"><span class="lineno">  244</span>    <span class="keywordflow">return</span> weights, intercept</div>
<div class="line"><span class="lineno">  245</span> </div>
<div class="line"><span class="lineno">  246</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9879a03e1d834409d68f9e871677f178" name="a9879a03e1d834409d68f9e871677f178"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9879a03e1d834409d68f9e871677f178">&#9670;&#160;</a></span>squared_dloss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.squared_dloss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>p</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   49</span><span class="keyword">def </span>squared_dloss(p, y):</div>
<div class="line"><span class="lineno">   50</span>    <span class="keywordflow">return</span> p - y</div>
<div class="line"><span class="lineno">   51</span> </div>
<div class="line"><span class="lineno">   52</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a59dab525fd7483146442f278ed300ecc" name="a59dab525fd7483146442f278ed300ecc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59dab525fd7483146442f278ed300ecc">&#9670;&#160;</a></span>squared_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.squared_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>p</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   53</span><span class="keyword">def </span>squared_loss(p, y):</div>
<div class="line"><span class="lineno">   54</span>    <span class="keywordflow">return</span> np.mean(0.5 * (p - y) * (p - y))</div>
<div class="line"><span class="lineno">   55</span> </div>
<div class="line"><span class="lineno">   56</span> </div>
<div class="line"><span class="lineno">   57</span><span class="comment"># function for measuring the log loss</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aaab136c1bb858d7e75a229d8928002e9" name="aaab136c1bb858d7e75a229d8928002e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaab136c1bb858d7e75a229d8928002e9">&#9670;&#160;</a></span>test_binary_classifier_class_weight()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_binary_classifier_class_weight </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">tests binary classifier with classweights for each class</pre> <div class="fragment"><div class="line"><span class="lineno">  752</span><span class="keyword">def </span>test_binary_classifier_class_weight():</div>
<div class="line"><span class="lineno">  753</span>    <span class="stringliteral">&quot;&quot;&quot;tests binary classifier with classweights for each class&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  754</span>    alpha = 0.1</div>
<div class="line"><span class="lineno">  755</span>    n_samples = 50</div>
<div class="line"><span class="lineno">  756</span>    n_iter = 20</div>
<div class="line"><span class="lineno">  757</span>    tol = 0.00001</div>
<div class="line"><span class="lineno">  758</span>    fit_intercept = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  759</span>    X, y = make_blobs(n_samples=n_samples, centers=2, random_state=10, cluster_std=0.1)</div>
<div class="line"><span class="lineno">  760</span>    step_size = get_step_size(X, alpha, fit_intercept, classification=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  761</span>    classes = np.unique(y)</div>
<div class="line"><span class="lineno">  762</span>    y_tmp = np.ones(n_samples)</div>
<div class="line"><span class="lineno">  763</span>    y_tmp[y != classes[1]] = -1</div>
<div class="line"><span class="lineno">  764</span>    y = y_tmp</div>
<div class="line"><span class="lineno">  765</span> </div>
<div class="line"><span class="lineno">  766</span>    class_weight = {1: 0.45, -1: 0.55}</div>
<div class="line"><span class="lineno">  767</span>    clf1 = LogisticRegression(</div>
<div class="line"><span class="lineno">  768</span>        solver=<span class="stringliteral">&quot;sag&quot;</span>,</div>
<div class="line"><span class="lineno">  769</span>        C=1.0 / alpha / n_samples,</div>
<div class="line"><span class="lineno">  770</span>        max_iter=n_iter,</div>
<div class="line"><span class="lineno">  771</span>        tol=tol,</div>
<div class="line"><span class="lineno">  772</span>        random_state=77,</div>
<div class="line"><span class="lineno">  773</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  774</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  775</span>        class_weight=class_weight,</div>
<div class="line"><span class="lineno">  776</span>    )</div>
<div class="line"><span class="lineno">  777</span>    clf2 = clone(clf1)</div>
<div class="line"><span class="lineno">  778</span> </div>
<div class="line"><span class="lineno">  779</span>    clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  780</span>    clf2.fit(sp.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  781</span> </div>
<div class="line"><span class="lineno">  782</span>    le = LabelEncoder()</div>
<div class="line"><span class="lineno">  783</span>    class_weight_ = compute_class_weight(class_weight, classes=np.unique(y), y=y)</div>
<div class="line"><span class="lineno">  784</span>    sample_weight = class_weight_[le.fit_transform(y)]</div>
<div class="line"><span class="lineno">  785</span>    spweights, spintercept = sag_sparse(</div>
<div class="line"><span class="lineno">  786</span>        X,</div>
<div class="line"><span class="lineno">  787</span>        y,</div>
<div class="line"><span class="lineno">  788</span>        step_size,</div>
<div class="line"><span class="lineno">  789</span>        alpha,</div>
<div class="line"><span class="lineno">  790</span>        n_iter=n_iter,</div>
<div class="line"><span class="lineno">  791</span>        dloss=log_dloss,</div>
<div class="line"><span class="lineno">  792</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  793</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  794</span>    )</div>
<div class="line"><span class="lineno">  795</span>    spweights2, spintercept2 = sag_sparse(</div>
<div class="line"><span class="lineno">  796</span>        X,</div>
<div class="line"><span class="lineno">  797</span>        y,</div>
<div class="line"><span class="lineno">  798</span>        step_size,</div>
<div class="line"><span class="lineno">  799</span>        alpha,</div>
<div class="line"><span class="lineno">  800</span>        n_iter=n_iter,</div>
<div class="line"><span class="lineno">  801</span>        dloss=log_dloss,</div>
<div class="line"><span class="lineno">  802</span>        sparse=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  803</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  804</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  805</span>    )</div>
<div class="line"><span class="lineno">  806</span> </div>
<div class="line"><span class="lineno">  807</span>    assert_array_almost_equal(clf1.coef_.ravel(), spweights.ravel(), decimal=2)</div>
<div class="line"><span class="lineno">  808</span>    assert_almost_equal(clf1.intercept_, spintercept, decimal=1)</div>
<div class="line"><span class="lineno">  809</span> </div>
<div class="line"><span class="lineno">  810</span>    assert_array_almost_equal(clf2.coef_.ravel(), spweights2.ravel(), decimal=2)</div>
<div class="line"><span class="lineno">  811</span>    assert_almost_equal(clf2.intercept_, spintercept2, decimal=1)</div>
<div class="line"><span class="lineno">  812</span> </div>
<div class="line"><span class="lineno">  813</span> </div>
<div class="line"><span class="lineno">  814</span><span class="preprocessor">@pytest.mark.filterwarnings(&quot;ignore:The max_iter was reached&quot;)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a84b1b9a0671c988a7f33c62a7d9e6950" name="a84b1b9a0671c988a7f33c62a7d9e6950"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a84b1b9a0671c988a7f33c62a7d9e6950">&#9670;&#160;</a></span>test_classifier_matching()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_classifier_matching </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  254</span><span class="keyword">def </span>test_classifier_matching():</div>
<div class="line"><span class="lineno">  255</span>    n_samples = 20</div>
<div class="line"><span class="lineno">  256</span>    X, y = make_blobs(n_samples=n_samples, centers=2, random_state=0, cluster_std=0.1)</div>
<div class="line"><span class="lineno">  257</span>    y[y == 0] = -1</div>
<div class="line"><span class="lineno">  258</span>    alpha = 1.1</div>
<div class="line"><span class="lineno">  259</span>    fit_intercept = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  260</span>    step_size = get_step_size(X, alpha, fit_intercept)</div>
<div class="line"><span class="lineno">  261</span>    <span class="keywordflow">for</span> solver <span class="keywordflow">in</span> [<span class="stringliteral">&quot;sag&quot;</span>, <span class="stringliteral">&quot;saga&quot;</span>]:</div>
<div class="line"><span class="lineno">  262</span>        <span class="keywordflow">if</span> solver == <span class="stringliteral">&quot;sag&quot;</span>:</div>
<div class="line"><span class="lineno">  263</span>            n_iter = 80</div>
<div class="line"><span class="lineno">  264</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  265</span>            <span class="comment"># SAGA variance w.r.t. stream order is higher</span></div>
<div class="line"><span class="lineno">  266</span>            n_iter = 300</div>
<div class="line"><span class="lineno">  267</span>        clf = LogisticRegression(</div>
<div class="line"><span class="lineno">  268</span>            solver=solver,</div>
<div class="line"><span class="lineno">  269</span>            fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  270</span>            tol=1e-11,</div>
<div class="line"><span class="lineno">  271</span>            C=1.0 / alpha / n_samples,</div>
<div class="line"><span class="lineno">  272</span>            max_iter=n_iter,</div>
<div class="line"><span class="lineno">  273</span>            random_state=10,</div>
<div class="line"><span class="lineno">  274</span>            multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  275</span>        )</div>
<div class="line"><span class="lineno">  276</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  277</span> </div>
<div class="line"><span class="lineno">  278</span>        weights, intercept = sag_sparse(</div>
<div class="line"><span class="lineno">  279</span>            X,</div>
<div class="line"><span class="lineno">  280</span>            y,</div>
<div class="line"><span class="lineno">  281</span>            step_size,</div>
<div class="line"><span class="lineno">  282</span>            alpha,</div>
<div class="line"><span class="lineno">  283</span>            n_iter=n_iter,</div>
<div class="line"><span class="lineno">  284</span>            dloss=log_dloss,</div>
<div class="line"><span class="lineno">  285</span>            fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  286</span>            saga=solver == <span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno">  287</span>        )</div>
<div class="line"><span class="lineno">  288</span>        weights2, intercept2 = sag(</div>
<div class="line"><span class="lineno">  289</span>            X,</div>
<div class="line"><span class="lineno">  290</span>            y,</div>
<div class="line"><span class="lineno">  291</span>            step_size,</div>
<div class="line"><span class="lineno">  292</span>            alpha,</div>
<div class="line"><span class="lineno">  293</span>            n_iter=n_iter,</div>
<div class="line"><span class="lineno">  294</span>            dloss=log_dloss,</div>
<div class="line"><span class="lineno">  295</span>            fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  296</span>            saga=solver == <span class="stringliteral">&quot;saga&quot;</span>,</div>
<div class="line"><span class="lineno">  297</span>        )</div>
<div class="line"><span class="lineno">  298</span>        weights = np.atleast_2d(weights)</div>
<div class="line"><span class="lineno">  299</span>        intercept = np.atleast_1d(intercept)</div>
<div class="line"><span class="lineno">  300</span>        weights2 = np.atleast_2d(weights2)</div>
<div class="line"><span class="lineno">  301</span>        intercept2 = np.atleast_1d(intercept2)</div>
<div class="line"><span class="lineno">  302</span> </div>
<div class="line"><span class="lineno">  303</span>        assert_array_almost_equal(weights, clf.coef_, decimal=9)</div>
<div class="line"><span class="lineno">  304</span>        assert_array_almost_equal(intercept, clf.intercept_, decimal=9)</div>
<div class="line"><span class="lineno">  305</span>        assert_array_almost_equal(weights2, clf.coef_, decimal=9)</div>
<div class="line"><span class="lineno">  306</span>        assert_array_almost_equal(intercept2, clf.intercept_, decimal=9)</div>
<div class="line"><span class="lineno">  307</span> </div>
<div class="line"><span class="lineno">  308</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a22e79647db994188cf5d621283c27d14" name="a22e79647db994188cf5d621283c27d14"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a22e79647db994188cf5d621283c27d14">&#9670;&#160;</a></span>test_classifier_results()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_classifier_results </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">tests if classifier results match target</pre> <div class="fragment"><div class="line"><span class="lineno">  722</span><span class="keyword">def </span>test_classifier_results():</div>
<div class="line"><span class="lineno">  723</span>    <span class="stringliteral">&quot;&quot;&quot;tests if classifier results match target&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  724</span>    alpha = 0.1</div>
<div class="line"><span class="lineno">  725</span>    n_features = 20</div>
<div class="line"><span class="lineno">  726</span>    n_samples = 10</div>
<div class="line"><span class="lineno">  727</span>    tol = 0.01</div>
<div class="line"><span class="lineno">  728</span>    max_iter = 200</div>
<div class="line"><span class="lineno">  729</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  730</span>    X = rng.normal(size=(n_samples, n_features))</div>
<div class="line"><span class="lineno">  731</span>    w = rng.normal(size=n_features)</div>
<div class="line"><span class="lineno">  732</span>    y = np.dot(X, w)</div>
<div class="line"><span class="lineno">  733</span>    y = np.sign(y)</div>
<div class="line"><span class="lineno">  734</span>    clf1 = LogisticRegression(</div>
<div class="line"><span class="lineno">  735</span>        solver=<span class="stringliteral">&quot;sag&quot;</span>,</div>
<div class="line"><span class="lineno">  736</span>        C=1.0 / alpha / n_samples,</div>
<div class="line"><span class="lineno">  737</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  738</span>        tol=tol,</div>
<div class="line"><span class="lineno">  739</span>        random_state=77,</div>
<div class="line"><span class="lineno">  740</span>    )</div>
<div class="line"><span class="lineno">  741</span>    clf2 = clone(clf1)</div>
<div class="line"><span class="lineno">  742</span> </div>
<div class="line"><span class="lineno">  743</span>    clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  744</span>    clf2.fit(sp.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  745</span>    pred1 = clf1.predict(X)</div>
<div class="line"><span class="lineno">  746</span>    pred2 = clf2.predict(X)</div>
<div class="line"><span class="lineno">  747</span>    assert_almost_equal(pred1, y, decimal=12)</div>
<div class="line"><span class="lineno">  748</span>    assert_almost_equal(pred2, y, decimal=12)</div>
<div class="line"><span class="lineno">  749</span> </div>
<div class="line"><span class="lineno">  750</span> </div>
<div class="line"><span class="lineno">  751</span><span class="preprocessor">@pytest.mark.filterwarnings(&quot;ignore:The max_iter was reached&quot;)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a6dc7e22916ac14060c484eb012efebab" name="a6dc7e22916ac14060c484eb012efebab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6dc7e22916ac14060c484eb012efebab">&#9670;&#160;</a></span>test_classifier_single_class()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_classifier_single_class </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">tests if ValueError is thrown with only one class</pre> <div class="fragment"><div class="line"><span class="lineno">  890</span><span class="keyword">def </span>test_classifier_single_class():</div>
<div class="line"><span class="lineno">  891</span>    <span class="stringliteral">&quot;&quot;&quot;tests if ValueError is thrown with only one class&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  892</span>    X = [[1, 2], [3, 4]]</div>
<div class="line"><span class="lineno">  893</span>    y = [1, 1]</div>
<div class="line"><span class="lineno">  894</span> </div>
<div class="line"><span class="lineno">  895</span>    msg = <span class="stringliteral">&quot;This solver needs samples of at least 2 classes in the data&quot;</span></div>
<div class="line"><span class="lineno">  896</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  897</span>        LogisticRegression(solver=<span class="stringliteral">&quot;sag&quot;</span>).fit(X, y)</div>
<div class="line"><span class="lineno">  898</span> </div>
<div class="line"><span class="lineno">  899</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ada550e837676cd5df2816973d84be5fc" name="ada550e837676cd5df2816973d84be5fc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ada550e837676cd5df2816973d84be5fc">&#9670;&#160;</a></span>test_get_auto_step_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_get_auto_step_size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  502</span><span class="keyword">def </span>test_get_auto_step_size():</div>
<div class="line"><span class="lineno">  503</span>    X = np.array([[1, 2, 3], [2, 3, 4], [2, 3, 2]], dtype=np.float64)</div>
<div class="line"><span class="lineno">  504</span>    alpha = 1.2</div>
<div class="line"><span class="lineno">  505</span>    fit_intercept = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  506</span>    <span class="comment"># sum the squares of the second sample because that&#39;s the largest</span></div>
<div class="line"><span class="lineno">  507</span>    max_squared_sum = 4 + 9 + 16</div>
<div class="line"><span class="lineno">  508</span>    max_squared_sum_ = row_norms(X, squared=<span class="keyword">True</span>).max()</div>
<div class="line"><span class="lineno">  509</span>    n_samples = X.shape[0]</div>
<div class="line"><span class="lineno">  510</span>    assert_almost_equal(max_squared_sum, max_squared_sum_, decimal=4)</div>
<div class="line"><span class="lineno">  511</span> </div>
<div class="line"><span class="lineno">  512</span>    <span class="keywordflow">for</span> saga <span class="keywordflow">in</span> [<span class="keyword">True</span>, <span class="keyword">False</span>]:</div>
<div class="line"><span class="lineno">  513</span>        <span class="keywordflow">for</span> fit_intercept <span class="keywordflow">in</span> (<span class="keyword">True</span>, <span class="keyword">False</span>):</div>
<div class="line"><span class="lineno">  514</span>            <span class="keywordflow">if</span> saga:</div>
<div class="line"><span class="lineno">  515</span>                L_sqr = max_squared_sum + alpha + int(fit_intercept)</div>
<div class="line"><span class="lineno">  516</span>                L_log = (max_squared_sum + 4.0 * alpha + int(fit_intercept)) / 4.0</div>
<div class="line"><span class="lineno">  517</span>                mun_sqr = min(2 * n_samples * alpha, L_sqr)</div>
<div class="line"><span class="lineno">  518</span>                mun_log = min(2 * n_samples * alpha, L_log)</div>
<div class="line"><span class="lineno">  519</span>                step_size_sqr = 1 / (2 * L_sqr + mun_sqr)</div>
<div class="line"><span class="lineno">  520</span>                step_size_log = 1 / (2 * L_log + mun_log)</div>
<div class="line"><span class="lineno">  521</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  522</span>                step_size_sqr = 1.0 / (max_squared_sum + alpha + int(fit_intercept))</div>
<div class="line"><span class="lineno">  523</span>                step_size_log = 4.0 / (</div>
<div class="line"><span class="lineno">  524</span>                    max_squared_sum + 4.0 * alpha + int(fit_intercept)</div>
<div class="line"><span class="lineno">  525</span>                )</div>
<div class="line"><span class="lineno">  526</span> </div>
<div class="line"><span class="lineno">  527</span>            step_size_sqr_ = get_auto_step_size(</div>
<div class="line"><span class="lineno">  528</span>                max_squared_sum_,</div>
<div class="line"><span class="lineno">  529</span>                alpha,</div>
<div class="line"><span class="lineno">  530</span>                <span class="stringliteral">&quot;squared&quot;</span>,</div>
<div class="line"><span class="lineno">  531</span>                fit_intercept,</div>
<div class="line"><span class="lineno">  532</span>                n_samples=n_samples,</div>
<div class="line"><span class="lineno">  533</span>                is_saga=saga,</div>
<div class="line"><span class="lineno">  534</span>            )</div>
<div class="line"><span class="lineno">  535</span>            step_size_log_ = get_auto_step_size(</div>
<div class="line"><span class="lineno">  536</span>                max_squared_sum_,</div>
<div class="line"><span class="lineno">  537</span>                alpha,</div>
<div class="line"><span class="lineno">  538</span>                <span class="stringliteral">&quot;log&quot;</span>,</div>
<div class="line"><span class="lineno">  539</span>                fit_intercept,</div>
<div class="line"><span class="lineno">  540</span>                n_samples=n_samples,</div>
<div class="line"><span class="lineno">  541</span>                is_saga=saga,</div>
<div class="line"><span class="lineno">  542</span>            )</div>
<div class="line"><span class="lineno">  543</span> </div>
<div class="line"><span class="lineno">  544</span>            assert_almost_equal(step_size_sqr, step_size_sqr_, decimal=4)</div>
<div class="line"><span class="lineno">  545</span>            assert_almost_equal(step_size_log, step_size_log_, decimal=4)</div>
<div class="line"><span class="lineno">  546</span> </div>
<div class="line"><span class="lineno">  547</span>    msg = <span class="stringliteral">&quot;Unknown loss function for SAG solver, got wrong instead of&quot;</span></div>
<div class="line"><span class="lineno">  548</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  549</span>        get_auto_step_size(max_squared_sum_, alpha, <span class="stringliteral">&quot;wrong&quot;</span>, fit_intercept)</div>
<div class="line"><span class="lineno">  550</span> </div>
<div class="line"><span class="lineno">  551</span> </div>
<div class="line"><span class="lineno">  552</span><span class="preprocessor">@pytest.mark.parametrize(&quot;seed&quot;, range(3)</span>)  <span class="comment"># locally tested with 1000 seeds</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aa4419c1d85fa1635e11ed33c4dcb7729" name="aa4419c1d85fa1635e11ed33c4dcb7729"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa4419c1d85fa1635e11ed33c4dcb7729">&#9670;&#160;</a></span>test_multiclass_classifier_class_weight()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_multiclass_classifier_class_weight </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">tests multiclass with classweights for each class</pre> <div class="fragment"><div class="line"><span class="lineno">  815</span><span class="keyword">def </span>test_multiclass_classifier_class_weight():</div>
<div class="line"><span class="lineno">  816</span>    <span class="stringliteral">&quot;&quot;&quot;tests multiclass with classweights for each class&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  817</span>    alpha = 0.1</div>
<div class="line"><span class="lineno">  818</span>    n_samples = 20</div>
<div class="line"><span class="lineno">  819</span>    tol = 0.00001</div>
<div class="line"><span class="lineno">  820</span>    max_iter = 50</div>
<div class="line"><span class="lineno">  821</span>    class_weight = {0: 0.45, 1: 0.55, 2: 0.75}</div>
<div class="line"><span class="lineno">  822</span>    fit_intercept = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  823</span>    X, y = make_blobs(n_samples=n_samples, centers=3, random_state=0, cluster_std=0.1)</div>
<div class="line"><span class="lineno">  824</span>    step_size = get_step_size(X, alpha, fit_intercept, classification=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  825</span>    classes = np.unique(y)</div>
<div class="line"><span class="lineno">  826</span> </div>
<div class="line"><span class="lineno">  827</span>    clf1 = LogisticRegression(</div>
<div class="line"><span class="lineno">  828</span>        solver=<span class="stringliteral">&quot;sag&quot;</span>,</div>
<div class="line"><span class="lineno">  829</span>        C=1.0 / alpha / n_samples,</div>
<div class="line"><span class="lineno">  830</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  831</span>        tol=tol,</div>
<div class="line"><span class="lineno">  832</span>        random_state=77,</div>
<div class="line"><span class="lineno">  833</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  834</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  835</span>        class_weight=class_weight,</div>
<div class="line"><span class="lineno">  836</span>    )</div>
<div class="line"><span class="lineno">  837</span>    clf2 = clone(clf1)</div>
<div class="line"><span class="lineno">  838</span>    clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  839</span>    clf2.fit(sp.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  840</span> </div>
<div class="line"><span class="lineno">  841</span>    le = LabelEncoder()</div>
<div class="line"><span class="lineno">  842</span>    class_weight_ = compute_class_weight(class_weight, classes=np.unique(y), y=y)</div>
<div class="line"><span class="lineno">  843</span>    sample_weight = class_weight_[le.fit_transform(y)]</div>
<div class="line"><span class="lineno">  844</span> </div>
<div class="line"><span class="lineno">  845</span>    coef1 = []</div>
<div class="line"><span class="lineno">  846</span>    intercept1 = []</div>
<div class="line"><span class="lineno">  847</span>    coef2 = []</div>
<div class="line"><span class="lineno">  848</span>    intercept2 = []</div>
<div class="line"><span class="lineno">  849</span>    <span class="keywordflow">for</span> cl <span class="keywordflow">in</span> classes:</div>
<div class="line"><span class="lineno">  850</span>        y_encoded = np.ones(n_samples)</div>
<div class="line"><span class="lineno">  851</span>        y_encoded[y != cl] = -1</div>
<div class="line"><span class="lineno">  852</span> </div>
<div class="line"><span class="lineno">  853</span>        spweights1, spintercept1 = sag_sparse(</div>
<div class="line"><span class="lineno">  854</span>            X,</div>
<div class="line"><span class="lineno">  855</span>            y_encoded,</div>
<div class="line"><span class="lineno">  856</span>            step_size,</div>
<div class="line"><span class="lineno">  857</span>            alpha,</div>
<div class="line"><span class="lineno">  858</span>            n_iter=max_iter,</div>
<div class="line"><span class="lineno">  859</span>            dloss=log_dloss,</div>
<div class="line"><span class="lineno">  860</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  861</span>        )</div>
<div class="line"><span class="lineno">  862</span>        spweights2, spintercept2 = sag_sparse(</div>
<div class="line"><span class="lineno">  863</span>            X,</div>
<div class="line"><span class="lineno">  864</span>            y_encoded,</div>
<div class="line"><span class="lineno">  865</span>            step_size,</div>
<div class="line"><span class="lineno">  866</span>            alpha,</div>
<div class="line"><span class="lineno">  867</span>            n_iter=max_iter,</div>
<div class="line"><span class="lineno">  868</span>            dloss=log_dloss,</div>
<div class="line"><span class="lineno">  869</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  870</span>            sparse=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  871</span>        )</div>
<div class="line"><span class="lineno">  872</span>        coef1.append(spweights1)</div>
<div class="line"><span class="lineno">  873</span>        intercept1.append(spintercept1)</div>
<div class="line"><span class="lineno">  874</span>        coef2.append(spweights2)</div>
<div class="line"><span class="lineno">  875</span>        intercept2.append(spintercept2)</div>
<div class="line"><span class="lineno">  876</span> </div>
<div class="line"><span class="lineno">  877</span>    coef1 = np.vstack(coef1)</div>
<div class="line"><span class="lineno">  878</span>    intercept1 = np.array(intercept1)</div>
<div class="line"><span class="lineno">  879</span>    coef2 = np.vstack(coef2)</div>
<div class="line"><span class="lineno">  880</span>    intercept2 = np.array(intercept2)</div>
<div class="line"><span class="lineno">  881</span> </div>
<div class="line"><span class="lineno">  882</span>    <span class="keywordflow">for</span> i, cl <span class="keywordflow">in</span> enumerate(classes):</div>
<div class="line"><span class="lineno">  883</span>        assert_array_almost_equal(clf1.coef_[i].ravel(), coef1[i].ravel(), decimal=2)</div>
<div class="line"><span class="lineno">  884</span>        assert_almost_equal(clf1.intercept_[i], intercept1[i], decimal=1)</div>
<div class="line"><span class="lineno">  885</span> </div>
<div class="line"><span class="lineno">  886</span>        assert_array_almost_equal(clf2.coef_[i].ravel(), coef2[i].ravel(), decimal=2)</div>
<div class="line"><span class="lineno">  887</span>        assert_almost_equal(clf2.intercept_[i], intercept2[i], decimal=1)</div>
<div class="line"><span class="lineno">  888</span> </div>
<div class="line"><span class="lineno">  889</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a56ed6289e366107125c68928b3473e1f" name="a56ed6289e366107125c68928b3473e1f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56ed6289e366107125c68928b3473e1f">&#9670;&#160;</a></span>test_multinomial_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_multinomial_loss </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  919</span><span class="keyword">def </span>test_multinomial_loss():</div>
<div class="line"><span class="lineno">  920</span>    <span class="comment"># test if the multinomial loss and gradient computations are consistent</span></div>
<div class="line"><span class="lineno">  921</span>    X, y = iris.data, iris.target.astype(np.float64)</div>
<div class="line"><span class="lineno">  922</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  923</span>    n_classes = len(np.unique(y))</div>
<div class="line"><span class="lineno">  924</span> </div>
<div class="line"><span class="lineno">  925</span>    rng = check_random_state(42)</div>
<div class="line"><span class="lineno">  926</span>    weights = rng.randn(n_features, n_classes)</div>
<div class="line"><span class="lineno">  927</span>    intercept = rng.randn(n_classes)</div>
<div class="line"><span class="lineno">  928</span>    sample_weights = rng.randn(n_samples)</div>
<div class="line"><span class="lineno">  929</span>    np.abs(sample_weights, sample_weights)</div>
<div class="line"><span class="lineno">  930</span> </div>
<div class="line"><span class="lineno">  931</span>    <span class="comment"># compute loss and gradient like in multinomial SAG</span></div>
<div class="line"><span class="lineno">  932</span>    dataset, _ = make_dataset(X, y, sample_weights, random_state=42)</div>
<div class="line"><span class="lineno">  933</span>    loss_1, grad_1 = _multinomial_grad_loss_all_samples(</div>
<div class="line"><span class="lineno">  934</span>        dataset, weights, intercept, n_samples, n_features, n_classes</div>
<div class="line"><span class="lineno">  935</span>    )</div>
<div class="line"><span class="lineno">  936</span>    <span class="comment"># compute loss and gradient like in multinomial LogisticRegression</span></div>
<div class="line"><span class="lineno">  937</span>    loss = LinearModelLoss(</div>
<div class="line"><span class="lineno">  938</span>        base_loss=HalfMultinomialLoss(n_classes=n_classes),</div>
<div class="line"><span class="lineno">  939</span>        fit_intercept=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  940</span>    )</div>
<div class="line"><span class="lineno">  941</span>    weights_intercept = np.vstack((weights, intercept)).T</div>
<div class="line"><span class="lineno">  942</span>    loss_2, grad_2 = loss.loss_gradient(</div>
<div class="line"><span class="lineno">  943</span>        weights_intercept, X, y, l2_reg_strength=0.0, sample_weight=sample_weights</div>
<div class="line"><span class="lineno">  944</span>    )</div>
<div class="line"><span class="lineno">  945</span>    grad_2 = grad_2[:, :-1].T</div>
<div class="line"><span class="lineno">  946</span> </div>
<div class="line"><span class="lineno">  947</span>    <span class="comment"># comparison</span></div>
<div class="line"><span class="lineno">  948</span>    assert_array_almost_equal(grad_1, grad_2)</div>
<div class="line"><span class="lineno">  949</span>    assert_almost_equal(loss_1, loss_2)</div>
<div class="line"><span class="lineno">  950</span> </div>
<div class="line"><span class="lineno">  951</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2471c0278f591c9d5593a7bae252876b" name="a2471c0278f591c9d5593a7bae252876b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2471c0278f591c9d5593a7bae252876b">&#9670;&#160;</a></span>test_multinomial_loss_ground_truth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_multinomial_loss_ground_truth </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  952</span><span class="keyword">def </span>test_multinomial_loss_ground_truth():</div>
<div class="line"><span class="lineno">  953</span>    <span class="comment"># n_samples, n_features, n_classes = 4, 2, 3</span></div>
<div class="line"><span class="lineno">  954</span>    n_classes = 3</div>
<div class="line"><span class="lineno">  955</span>    X = np.array([[1.1, 2.2], [2.2, -4.4], [3.3, -2.2], [1.1, 1.1]])</div>
<div class="line"><span class="lineno">  956</span>    y = np.array([0, 1, 2, 0], dtype=np.float64)</div>
<div class="line"><span class="lineno">  957</span>    lbin = LabelBinarizer()</div>
<div class="line"><span class="lineno">  958</span>    Y_bin = lbin.fit_transform(y)</div>
<div class="line"><span class="lineno">  959</span> </div>
<div class="line"><span class="lineno">  960</span>    weights = np.array([[0.1, 0.2, 0.3], [1.1, 1.2, -1.3]])</div>
<div class="line"><span class="lineno">  961</span>    intercept = np.array([1.0, 0, -0.2])</div>
<div class="line"><span class="lineno">  962</span>    sample_weights = np.array([0.8, 1, 1, 0.8])</div>
<div class="line"><span class="lineno">  963</span> </div>
<div class="line"><span class="lineno">  964</span>    prediction = np.dot(X, weights) + intercept</div>
<div class="line"><span class="lineno">  965</span>    logsumexp_prediction = logsumexp(prediction, axis=1)</div>
<div class="line"><span class="lineno">  966</span>    p = prediction - logsumexp_prediction[:, np.newaxis]</div>
<div class="line"><span class="lineno">  967</span>    loss_1 = -(sample_weights[:, np.newaxis] * p * Y_bin).sum()</div>
<div class="line"><span class="lineno">  968</span>    diff = sample_weights[:, np.newaxis] * (np.exp(p) - Y_bin)</div>
<div class="line"><span class="lineno">  969</span>    grad_1 = np.dot(X.T, diff)</div>
<div class="line"><span class="lineno">  970</span> </div>
<div class="line"><span class="lineno">  971</span>    loss = LinearModelLoss(</div>
<div class="line"><span class="lineno">  972</span>        base_loss=HalfMultinomialLoss(n_classes=n_classes),</div>
<div class="line"><span class="lineno">  973</span>        fit_intercept=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  974</span>    )</div>
<div class="line"><span class="lineno">  975</span>    weights_intercept = np.vstack((weights, intercept)).T</div>
<div class="line"><span class="lineno">  976</span>    loss_2, grad_2 = loss.loss_gradient(</div>
<div class="line"><span class="lineno">  977</span>        weights_intercept, X, y, l2_reg_strength=0.0, sample_weight=sample_weights</div>
<div class="line"><span class="lineno">  978</span>    )</div>
<div class="line"><span class="lineno">  979</span>    grad_2 = grad_2[:, :-1].T</div>
<div class="line"><span class="lineno">  980</span> </div>
<div class="line"><span class="lineno">  981</span>    assert_almost_equal(loss_1, loss_2)</div>
<div class="line"><span class="lineno">  982</span>    assert_array_almost_equal(grad_1, grad_2)</div>
<div class="line"><span class="lineno">  983</span> </div>
<div class="line"><span class="lineno">  984</span>    <span class="comment"># ground truth</span></div>
<div class="line"><span class="lineno">  985</span>    loss_gt = 11.680360354325961</div>
<div class="line"><span class="lineno">  986</span>    grad_gt = np.array(</div>
<div class="line"><span class="lineno">  987</span>        [[-0.557487, -1.619151, +2.176638], [-0.903942, +5.258745, -4.354803]]</div>
<div class="line"><span class="lineno">  988</span>    )</div>
<div class="line"><span class="lineno">  989</span>    assert_almost_equal(loss_1, loss_gt)</div>
<div class="line"><span class="lineno">  990</span>    assert_array_almost_equal(grad_1, grad_gt)</div>
<div class="line"><span class="lineno">  991</span> </div>
<div class="line"><span class="lineno">  992</span> </div>
<div class="line"><span class="lineno">  993</span><span class="preprocessor">@pytest.mark.parametrize(&quot;solver&quot;, [&quot;sag&quot;, &quot;saga&quot;])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab3b3d6a54cd7764253f8877b94f8d8a4" name="ab3b3d6a54cd7764253f8877b94f8d8a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3b3d6a54cd7764253f8877b94f8d8a4">&#9670;&#160;</a></span>test_regressor_matching()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_regressor_matching </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  309</span><span class="keyword">def </span>test_regressor_matching():</div>
<div class="line"><span class="lineno">  310</span>    n_samples = 10</div>
<div class="line"><span class="lineno">  311</span>    n_features = 5</div>
<div class="line"><span class="lineno">  312</span> </div>
<div class="line"><span class="lineno">  313</span>    rng = np.random.RandomState(10)</div>
<div class="line"><span class="lineno">  314</span>    X = rng.normal(size=(n_samples, n_features))</div>
<div class="line"><span class="lineno">  315</span>    true_w = rng.normal(size=n_features)</div>
<div class="line"><span class="lineno">  316</span>    y = X.dot(true_w)</div>
<div class="line"><span class="lineno">  317</span> </div>
<div class="line"><span class="lineno">  318</span>    alpha = 1.0</div>
<div class="line"><span class="lineno">  319</span>    n_iter = 100</div>
<div class="line"><span class="lineno">  320</span>    fit_intercept = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  321</span> </div>
<div class="line"><span class="lineno">  322</span>    step_size = get_step_size(X, alpha, fit_intercept, classification=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  323</span>    clf = Ridge(</div>
<div class="line"><span class="lineno">  324</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  325</span>        tol=0.00000000001,</div>
<div class="line"><span class="lineno">  326</span>        solver=<span class="stringliteral">&quot;sag&quot;</span>,</div>
<div class="line"><span class="lineno">  327</span>        alpha=alpha * n_samples,</div>
<div class="line"><span class="lineno">  328</span>        max_iter=n_iter,</div>
<div class="line"><span class="lineno">  329</span>    )</div>
<div class="line"><span class="lineno">  330</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  331</span> </div>
<div class="line"><span class="lineno">  332</span>    weights1, intercept1 = sag_sparse(</div>
<div class="line"><span class="lineno">  333</span>        X,</div>
<div class="line"><span class="lineno">  334</span>        y,</div>
<div class="line"><span class="lineno">  335</span>        step_size,</div>
<div class="line"><span class="lineno">  336</span>        alpha,</div>
<div class="line"><span class="lineno">  337</span>        n_iter=n_iter,</div>
<div class="line"><span class="lineno">  338</span>        dloss=squared_dloss,</div>
<div class="line"><span class="lineno">  339</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  340</span>    )</div>
<div class="line"><span class="lineno">  341</span>    weights2, intercept2 = sag(</div>
<div class="line"><span class="lineno">  342</span>        X,</div>
<div class="line"><span class="lineno">  343</span>        y,</div>
<div class="line"><span class="lineno">  344</span>        step_size,</div>
<div class="line"><span class="lineno">  345</span>        alpha,</div>
<div class="line"><span class="lineno">  346</span>        n_iter=n_iter,</div>
<div class="line"><span class="lineno">  347</span>        dloss=squared_dloss,</div>
<div class="line"><span class="lineno">  348</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  349</span>    )</div>
<div class="line"><span class="lineno">  350</span> </div>
<div class="line"><span class="lineno">  351</span>    assert_allclose(weights1, clf.coef_)</div>
<div class="line"><span class="lineno">  352</span>    assert_allclose(intercept1, clf.intercept_)</div>
<div class="line"><span class="lineno">  353</span>    assert_allclose(weights2, clf.coef_)</div>
<div class="line"><span class="lineno">  354</span>    assert_allclose(intercept2, clf.intercept_)</div>
<div class="line"><span class="lineno">  355</span> </div>
<div class="line"><span class="lineno">  356</span> </div>
<div class="line"><span class="lineno">  357</span><span class="preprocessor">@pytest.mark.filterwarnings(&quot;ignore:The max_iter was reached&quot;)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="afaffd4fa137e28a04e939653d546d3fe" name="afaffd4fa137e28a04e939653d546d3fe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afaffd4fa137e28a04e939653d546d3fe">&#9670;&#160;</a></span>test_sag_classifier_computed_correctly()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_sag_classifier_computed_correctly </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">tests if the binary classifier is computed correctly</pre> <div class="fragment"><div class="line"><span class="lineno">  595</span><span class="keyword">def </span>test_sag_classifier_computed_correctly():</div>
<div class="line"><span class="lineno">  596</span>    <span class="stringliteral">&quot;&quot;&quot;tests if the binary classifier is computed correctly&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  597</span>    alpha = 0.1</div>
<div class="line"><span class="lineno">  598</span>    n_samples = 50</div>
<div class="line"><span class="lineno">  599</span>    n_iter = 50</div>
<div class="line"><span class="lineno">  600</span>    tol = 0.00001</div>
<div class="line"><span class="lineno">  601</span>    fit_intercept = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  602</span>    X, y = make_blobs(n_samples=n_samples, centers=2, random_state=0, cluster_std=0.1)</div>
<div class="line"><span class="lineno">  603</span>    step_size = get_step_size(X, alpha, fit_intercept, classification=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  604</span>    classes = np.unique(y)</div>
<div class="line"><span class="lineno">  605</span>    y_tmp = np.ones(n_samples)</div>
<div class="line"><span class="lineno">  606</span>    y_tmp[y != classes[1]] = -1</div>
<div class="line"><span class="lineno">  607</span>    y = y_tmp</div>
<div class="line"><span class="lineno">  608</span> </div>
<div class="line"><span class="lineno">  609</span>    clf1 = LogisticRegression(</div>
<div class="line"><span class="lineno">  610</span>        solver=<span class="stringliteral">&quot;sag&quot;</span>,</div>
<div class="line"><span class="lineno">  611</span>        C=1.0 / alpha / n_samples,</div>
<div class="line"><span class="lineno">  612</span>        max_iter=n_iter,</div>
<div class="line"><span class="lineno">  613</span>        tol=tol,</div>
<div class="line"><span class="lineno">  614</span>        random_state=77,</div>
<div class="line"><span class="lineno">  615</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  616</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  617</span>    )</div>
<div class="line"><span class="lineno">  618</span>    clf2 = clone(clf1)</div>
<div class="line"><span class="lineno">  619</span> </div>
<div class="line"><span class="lineno">  620</span>    clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  621</span>    clf2.fit(sp.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  622</span> </div>
<div class="line"><span class="lineno">  623</span>    spweights, spintercept = sag_sparse(</div>
<div class="line"><span class="lineno">  624</span>        X,</div>
<div class="line"><span class="lineno">  625</span>        y,</div>
<div class="line"><span class="lineno">  626</span>        step_size,</div>
<div class="line"><span class="lineno">  627</span>        alpha,</div>
<div class="line"><span class="lineno">  628</span>        n_iter=n_iter,</div>
<div class="line"><span class="lineno">  629</span>        dloss=log_dloss,</div>
<div class="line"><span class="lineno">  630</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  631</span>    )</div>
<div class="line"><span class="lineno">  632</span>    spweights2, spintercept2 = sag_sparse(</div>
<div class="line"><span class="lineno">  633</span>        X,</div>
<div class="line"><span class="lineno">  634</span>        y,</div>
<div class="line"><span class="lineno">  635</span>        step_size,</div>
<div class="line"><span class="lineno">  636</span>        alpha,</div>
<div class="line"><span class="lineno">  637</span>        n_iter=n_iter,</div>
<div class="line"><span class="lineno">  638</span>        dloss=log_dloss,</div>
<div class="line"><span class="lineno">  639</span>        sparse=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  640</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  641</span>    )</div>
<div class="line"><span class="lineno">  642</span> </div>
<div class="line"><span class="lineno">  643</span>    assert_array_almost_equal(clf1.coef_.ravel(), spweights.ravel(), decimal=2)</div>
<div class="line"><span class="lineno">  644</span>    assert_almost_equal(clf1.intercept_, spintercept, decimal=1)</div>
<div class="line"><span class="lineno">  645</span> </div>
<div class="line"><span class="lineno">  646</span>    assert_array_almost_equal(clf2.coef_.ravel(), spweights2.ravel(), decimal=2)</div>
<div class="line"><span class="lineno">  647</span>    assert_almost_equal(clf2.intercept_, spintercept2, decimal=1)</div>
<div class="line"><span class="lineno">  648</span> </div>
<div class="line"><span class="lineno">  649</span> </div>
<div class="line"><span class="lineno">  650</span><span class="preprocessor">@pytest.mark.filterwarnings(&quot;ignore:The max_iter was reached&quot;)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a05ad10f1fcf94c17237e9a47a00fd85e" name="a05ad10f1fcf94c17237e9a47a00fd85e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a05ad10f1fcf94c17237e9a47a00fd85e">&#9670;&#160;</a></span>test_sag_classifier_raises_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_sag_classifier_raises_error </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  994</span><span class="keyword">def </span>test_sag_classifier_raises_error(solver):</div>
<div class="line"><span class="lineno">  995</span>    <span class="comment"># Following #13316, the error handling behavior changed in cython sag. This</span></div>
<div class="line"><span class="lineno">  996</span>    <span class="comment"># is simply a non-regression test to make sure numerical errors are</span></div>
<div class="line"><span class="lineno">  997</span>    <span class="comment"># properly raised.</span></div>
<div class="line"><span class="lineno">  998</span> </div>
<div class="line"><span class="lineno">  999</span>    <span class="comment"># Train a classifier on a simple problem</span></div>
<div class="line"><span class="lineno"> 1000</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno"> 1001</span>    X, y = make_classification(random_state=rng)</div>
<div class="line"><span class="lineno"> 1002</span>    clf = LogisticRegression(solver=solver, random_state=rng, warm_start=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1003</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 1004</span> </div>
<div class="line"><span class="lineno"> 1005</span>    <span class="comment"># Trigger a numerical error by:</span></div>
<div class="line"><span class="lineno"> 1006</span>    <span class="comment"># - corrupting the fitted coefficients of the classifier</span></div>
<div class="line"><span class="lineno"> 1007</span>    <span class="comment"># - fit it again starting from its current state thanks to warm_start</span></div>
<div class="line"><span class="lineno"> 1008</span>    clf.coef_[:] = np.nan</div>
<div class="line"><span class="lineno"> 1009</span> </div>
<div class="line"><span class="lineno"> 1010</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;Floating-point under-/overflow&quot;</span>):</div>
<div class="line"><span class="lineno"> 1011</span>        clf.fit(X, y)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a1d812bcd732ad9151fd8f583790331b5" name="a1d812bcd732ad9151fd8f583790331b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d812bcd732ad9151fd8f583790331b5">&#9670;&#160;</a></span>test_sag_multiclass_computed_correctly()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_sag_multiclass_computed_correctly </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">tests if the multiclass classifier is computed correctly</pre> <div class="fragment"><div class="line"><span class="lineno">  651</span><span class="keyword">def </span>test_sag_multiclass_computed_correctly():</div>
<div class="line"><span class="lineno">  652</span>    <span class="stringliteral">&quot;&quot;&quot;tests if the multiclass classifier is computed correctly&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  653</span>    alpha = 0.1</div>
<div class="line"><span class="lineno">  654</span>    n_samples = 20</div>
<div class="line"><span class="lineno">  655</span>    tol = 0.00001</div>
<div class="line"><span class="lineno">  656</span>    max_iter = 40</div>
<div class="line"><span class="lineno">  657</span>    fit_intercept = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  658</span>    X, y = make_blobs(n_samples=n_samples, centers=3, random_state=0, cluster_std=0.1)</div>
<div class="line"><span class="lineno">  659</span>    step_size = get_step_size(X, alpha, fit_intercept, classification=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  660</span>    classes = np.unique(y)</div>
<div class="line"><span class="lineno">  661</span> </div>
<div class="line"><span class="lineno">  662</span>    clf1 = LogisticRegression(</div>
<div class="line"><span class="lineno">  663</span>        solver=<span class="stringliteral">&quot;sag&quot;</span>,</div>
<div class="line"><span class="lineno">  664</span>        C=1.0 / alpha / n_samples,</div>
<div class="line"><span class="lineno">  665</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  666</span>        tol=tol,</div>
<div class="line"><span class="lineno">  667</span>        random_state=77,</div>
<div class="line"><span class="lineno">  668</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  669</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  670</span>    )</div>
<div class="line"><span class="lineno">  671</span>    clf2 = clone(clf1)</div>
<div class="line"><span class="lineno">  672</span> </div>
<div class="line"><span class="lineno">  673</span>    clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  674</span>    clf2.fit(sp.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  675</span> </div>
<div class="line"><span class="lineno">  676</span>    coef1 = []</div>
<div class="line"><span class="lineno">  677</span>    intercept1 = []</div>
<div class="line"><span class="lineno">  678</span>    coef2 = []</div>
<div class="line"><span class="lineno">  679</span>    intercept2 = []</div>
<div class="line"><span class="lineno">  680</span>    <span class="keywordflow">for</span> cl <span class="keywordflow">in</span> classes:</div>
<div class="line"><span class="lineno">  681</span>        y_encoded = np.ones(n_samples)</div>
<div class="line"><span class="lineno">  682</span>        y_encoded[y != cl] = -1</div>
<div class="line"><span class="lineno">  683</span> </div>
<div class="line"><span class="lineno">  684</span>        spweights1, spintercept1 = sag_sparse(</div>
<div class="line"><span class="lineno">  685</span>            X,</div>
<div class="line"><span class="lineno">  686</span>            y_encoded,</div>
<div class="line"><span class="lineno">  687</span>            step_size,</div>
<div class="line"><span class="lineno">  688</span>            alpha,</div>
<div class="line"><span class="lineno">  689</span>            dloss=log_dloss,</div>
<div class="line"><span class="lineno">  690</span>            n_iter=max_iter,</div>
<div class="line"><span class="lineno">  691</span>            fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  692</span>        )</div>
<div class="line"><span class="lineno">  693</span>        spweights2, spintercept2 = sag_sparse(</div>
<div class="line"><span class="lineno">  694</span>            X,</div>
<div class="line"><span class="lineno">  695</span>            y_encoded,</div>
<div class="line"><span class="lineno">  696</span>            step_size,</div>
<div class="line"><span class="lineno">  697</span>            alpha,</div>
<div class="line"><span class="lineno">  698</span>            dloss=log_dloss,</div>
<div class="line"><span class="lineno">  699</span>            n_iter=max_iter,</div>
<div class="line"><span class="lineno">  700</span>            sparse=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  701</span>            fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  702</span>        )</div>
<div class="line"><span class="lineno">  703</span>        coef1.append(spweights1)</div>
<div class="line"><span class="lineno">  704</span>        intercept1.append(spintercept1)</div>
<div class="line"><span class="lineno">  705</span> </div>
<div class="line"><span class="lineno">  706</span>        coef2.append(spweights2)</div>
<div class="line"><span class="lineno">  707</span>        intercept2.append(spintercept2)</div>
<div class="line"><span class="lineno">  708</span> </div>
<div class="line"><span class="lineno">  709</span>    coef1 = np.vstack(coef1)</div>
<div class="line"><span class="lineno">  710</span>    intercept1 = np.array(intercept1)</div>
<div class="line"><span class="lineno">  711</span>    coef2 = np.vstack(coef2)</div>
<div class="line"><span class="lineno">  712</span>    intercept2 = np.array(intercept2)</div>
<div class="line"><span class="lineno">  713</span> </div>
<div class="line"><span class="lineno">  714</span>    <span class="keywordflow">for</span> i, cl <span class="keywordflow">in</span> enumerate(classes):</div>
<div class="line"><span class="lineno">  715</span>        assert_array_almost_equal(clf1.coef_[i].ravel(), coef1[i].ravel(), decimal=2)</div>
<div class="line"><span class="lineno">  716</span>        assert_almost_equal(clf1.intercept_[i], intercept1[i], decimal=1)</div>
<div class="line"><span class="lineno">  717</span> </div>
<div class="line"><span class="lineno">  718</span>        assert_array_almost_equal(clf2.coef_[i].ravel(), coef2[i].ravel(), decimal=2)</div>
<div class="line"><span class="lineno">  719</span>        assert_almost_equal(clf2.intercept_[i], intercept2[i], decimal=1)</div>
<div class="line"><span class="lineno">  720</span> </div>
<div class="line"><span class="lineno">  721</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac2b7a86c68348192a6ce24757c7cad54" name="ac2b7a86c68348192a6ce24757c7cad54"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac2b7a86c68348192a6ce24757c7cad54">&#9670;&#160;</a></span>test_sag_pobj_matches_logistic_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_sag_pobj_matches_logistic_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">tests if the sag pobj matches log reg</pre> <div class="fragment"><div class="line"><span class="lineno">  358</span><span class="keyword">def </span>test_sag_pobj_matches_logistic_regression():</div>
<div class="line"><span class="lineno">  359</span>    <span class="stringliteral">&quot;&quot;&quot;tests if the sag pobj matches log reg&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  360</span>    n_samples = 100</div>
<div class="line"><span class="lineno">  361</span>    alpha = 1.0</div>
<div class="line"><span class="lineno">  362</span>    max_iter = 20</div>
<div class="line"><span class="lineno">  363</span>    X, y = make_blobs(n_samples=n_samples, centers=2, random_state=0, cluster_std=0.1)</div>
<div class="line"><span class="lineno">  364</span> </div>
<div class="line"><span class="lineno">  365</span>    clf1 = LogisticRegression(</div>
<div class="line"><span class="lineno">  366</span>        solver=<span class="stringliteral">&quot;sag&quot;</span>,</div>
<div class="line"><span class="lineno">  367</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  368</span>        tol=0.0000001,</div>
<div class="line"><span class="lineno">  369</span>        C=1.0 / alpha / n_samples,</div>
<div class="line"><span class="lineno">  370</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  371</span>        random_state=10,</div>
<div class="line"><span class="lineno">  372</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  373</span>    )</div>
<div class="line"><span class="lineno">  374</span>    clf2 = clone(clf1)</div>
<div class="line"><span class="lineno">  375</span>    clf3 = LogisticRegression(</div>
<div class="line"><span class="lineno">  376</span>        fit_intercept=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  377</span>        tol=0.0000001,</div>
<div class="line"><span class="lineno">  378</span>        C=1.0 / alpha / n_samples,</div>
<div class="line"><span class="lineno">  379</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  380</span>        random_state=10,</div>
<div class="line"><span class="lineno">  381</span>        multi_class=<span class="stringliteral">&quot;ovr&quot;</span>,</div>
<div class="line"><span class="lineno">  382</span>    )</div>
<div class="line"><span class="lineno">  383</span> </div>
<div class="line"><span class="lineno">  384</span>    clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  385</span>    clf2.fit(sp.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  386</span>    clf3.fit(X, y)</div>
<div class="line"><span class="lineno">  387</span> </div>
<div class="line"><span class="lineno">  388</span>    pobj1 = get_pobj(clf1.coef_, alpha, X, y, log_loss)</div>
<div class="line"><span class="lineno">  389</span>    pobj2 = get_pobj(clf2.coef_, alpha, X, y, log_loss)</div>
<div class="line"><span class="lineno">  390</span>    pobj3 = get_pobj(clf3.coef_, alpha, X, y, log_loss)</div>
<div class="line"><span class="lineno">  391</span> </div>
<div class="line"><span class="lineno">  392</span>    assert_array_almost_equal(pobj1, pobj2, decimal=4)</div>
<div class="line"><span class="lineno">  393</span>    assert_array_almost_equal(pobj2, pobj3, decimal=4)</div>
<div class="line"><span class="lineno">  394</span>    assert_array_almost_equal(pobj3, pobj1, decimal=4)</div>
<div class="line"><span class="lineno">  395</span> </div>
<div class="line"><span class="lineno">  396</span> </div>
<div class="line"><span class="lineno">  397</span><span class="preprocessor">@pytest.mark.filterwarnings(&quot;ignore:The max_iter was reached&quot;)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ad7f5714908782328471d0e434651b36b" name="ad7f5714908782328471d0e434651b36b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad7f5714908782328471d0e434651b36b">&#9670;&#160;</a></span>test_sag_pobj_matches_ridge_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_sag_pobj_matches_ridge_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">tests if the sag pobj matches ridge reg</pre> <div class="fragment"><div class="line"><span class="lineno">  398</span><span class="keyword">def </span>test_sag_pobj_matches_ridge_regression():</div>
<div class="line"><span class="lineno">  399</span>    <span class="stringliteral">&quot;&quot;&quot;tests if the sag pobj matches ridge reg&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  400</span>    n_samples = 100</div>
<div class="line"><span class="lineno">  401</span>    n_features = 10</div>
<div class="line"><span class="lineno">  402</span>    alpha = 1.0</div>
<div class="line"><span class="lineno">  403</span>    n_iter = 100</div>
<div class="line"><span class="lineno">  404</span>    fit_intercept = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  405</span>    rng = np.random.RandomState(10)</div>
<div class="line"><span class="lineno">  406</span>    X = rng.normal(size=(n_samples, n_features))</div>
<div class="line"><span class="lineno">  407</span>    true_w = rng.normal(size=n_features)</div>
<div class="line"><span class="lineno">  408</span>    y = X.dot(true_w)</div>
<div class="line"><span class="lineno">  409</span> </div>
<div class="line"><span class="lineno">  410</span>    clf1 = Ridge(</div>
<div class="line"><span class="lineno">  411</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  412</span>        tol=0.00000000001,</div>
<div class="line"><span class="lineno">  413</span>        solver=<span class="stringliteral">&quot;sag&quot;</span>,</div>
<div class="line"><span class="lineno">  414</span>        alpha=alpha,</div>
<div class="line"><span class="lineno">  415</span>        max_iter=n_iter,</div>
<div class="line"><span class="lineno">  416</span>        random_state=42,</div>
<div class="line"><span class="lineno">  417</span>    )</div>
<div class="line"><span class="lineno">  418</span>    clf2 = clone(clf1)</div>
<div class="line"><span class="lineno">  419</span>    clf3 = Ridge(</div>
<div class="line"><span class="lineno">  420</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  421</span>        tol=0.00001,</div>
<div class="line"><span class="lineno">  422</span>        solver=<span class="stringliteral">&quot;lsqr&quot;</span>,</div>
<div class="line"><span class="lineno">  423</span>        alpha=alpha,</div>
<div class="line"><span class="lineno">  424</span>        max_iter=n_iter,</div>
<div class="line"><span class="lineno">  425</span>        random_state=42,</div>
<div class="line"><span class="lineno">  426</span>    )</div>
<div class="line"><span class="lineno">  427</span> </div>
<div class="line"><span class="lineno">  428</span>    clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  429</span>    clf2.fit(sp.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  430</span>    clf3.fit(X, y)</div>
<div class="line"><span class="lineno">  431</span> </div>
<div class="line"><span class="lineno">  432</span>    pobj1 = get_pobj(clf1.coef_, alpha, X, y, squared_loss)</div>
<div class="line"><span class="lineno">  433</span>    pobj2 = get_pobj(clf2.coef_, alpha, X, y, squared_loss)</div>
<div class="line"><span class="lineno">  434</span>    pobj3 = get_pobj(clf3.coef_, alpha, X, y, squared_loss)</div>
<div class="line"><span class="lineno">  435</span> </div>
<div class="line"><span class="lineno">  436</span>    assert_array_almost_equal(pobj1, pobj2, decimal=4)</div>
<div class="line"><span class="lineno">  437</span>    assert_array_almost_equal(pobj1, pobj3, decimal=4)</div>
<div class="line"><span class="lineno">  438</span>    assert_array_almost_equal(pobj3, pobj2, decimal=4)</div>
<div class="line"><span class="lineno">  439</span> </div>
<div class="line"><span class="lineno">  440</span> </div>
<div class="line"><span class="lineno">  441</span><span class="preprocessor">@pytest.mark.filterwarnings(&quot;ignore:The max_iter was reached&quot;)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a1437e57f76233b0fbd4a2c09026cf426" name="a1437e57f76233b0fbd4a2c09026cf426"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1437e57f76233b0fbd4a2c09026cf426">&#9670;&#160;</a></span>test_sag_regressor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_sag_regressor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>seed</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">tests if the sag regressor performs well</pre> <div class="fragment"><div class="line"><span class="lineno">  553</span><span class="keyword">def </span>test_sag_regressor(seed):</div>
<div class="line"><span class="lineno">  554</span>    <span class="stringliteral">&quot;&quot;&quot;tests if the sag regressor performs well&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  555</span>    xmin, xmax = -5, 5</div>
<div class="line"><span class="lineno">  556</span>    n_samples = 300</div>
<div class="line"><span class="lineno">  557</span>    tol = 0.001</div>
<div class="line"><span class="lineno">  558</span>    max_iter = 100</div>
<div class="line"><span class="lineno">  559</span>    alpha = 0.1</div>
<div class="line"><span class="lineno">  560</span>    rng = np.random.RandomState(seed)</div>
<div class="line"><span class="lineno">  561</span>    X = np.linspace(xmin, xmax, n_samples).reshape(n_samples, 1)</div>
<div class="line"><span class="lineno">  562</span> </div>
<div class="line"><span class="lineno">  563</span>    <span class="comment"># simple linear function without noise</span></div>
<div class="line"><span class="lineno">  564</span>    y = 0.5 * X.ravel()</div>
<div class="line"><span class="lineno">  565</span> </div>
<div class="line"><span class="lineno">  566</span>    clf1 = Ridge(</div>
<div class="line"><span class="lineno">  567</span>        tol=tol,</div>
<div class="line"><span class="lineno">  568</span>        solver=<span class="stringliteral">&quot;sag&quot;</span>,</div>
<div class="line"><span class="lineno">  569</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  570</span>        alpha=alpha * n_samples,</div>
<div class="line"><span class="lineno">  571</span>        random_state=rng,</div>
<div class="line"><span class="lineno">  572</span>    )</div>
<div class="line"><span class="lineno">  573</span>    clf2 = clone(clf1)</div>
<div class="line"><span class="lineno">  574</span>    clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  575</span>    clf2.fit(sp.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  576</span>    score1 = clf1.score(X, y)</div>
<div class="line"><span class="lineno">  577</span>    score2 = clf2.score(X, y)</div>
<div class="line"><span class="lineno">  578</span>    <span class="keyword">assert</span> score1 &gt; 0.98</div>
<div class="line"><span class="lineno">  579</span>    <span class="keyword">assert</span> score2 &gt; 0.98</div>
<div class="line"><span class="lineno">  580</span> </div>
<div class="line"><span class="lineno">  581</span>    <span class="comment"># simple linear function with noise</span></div>
<div class="line"><span class="lineno">  582</span>    y = 0.5 * X.ravel() + rng.randn(n_samples, 1).ravel()</div>
<div class="line"><span class="lineno">  583</span> </div>
<div class="line"><span class="lineno">  584</span>    clf1 = Ridge(tol=tol, solver=<span class="stringliteral">&quot;sag&quot;</span>, max_iter=max_iter, alpha=alpha * n_samples)</div>
<div class="line"><span class="lineno">  585</span>    clf2 = clone(clf1)</div>
<div class="line"><span class="lineno">  586</span>    clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  587</span>    clf2.fit(sp.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  588</span>    score1 = clf1.score(X, y)</div>
<div class="line"><span class="lineno">  589</span>    score2 = clf2.score(X, y)</div>
<div class="line"><span class="lineno">  590</span>    <span class="keyword">assert</span> score1 &gt; 0.45</div>
<div class="line"><span class="lineno">  591</span>    <span class="keyword">assert</span> score2 &gt; 0.45</div>
<div class="line"><span class="lineno">  592</span> </div>
<div class="line"><span class="lineno">  593</span> </div>
<div class="line"><span class="lineno">  594</span><span class="preprocessor">@pytest.mark.filterwarnings(&quot;ignore:The max_iter was reached&quot;)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab95a592c7ab3d2ddbf11e5329cc18bfe" name="ab95a592c7ab3d2ddbf11e5329cc18bfe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab95a592c7ab3d2ddbf11e5329cc18bfe">&#9670;&#160;</a></span>test_sag_regressor_computed_correctly()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_sag_regressor_computed_correctly </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">tests if the sag regressor is computed correctly</pre> <div class="fragment"><div class="line"><span class="lineno">  442</span><span class="keyword">def </span>test_sag_regressor_computed_correctly():</div>
<div class="line"><span class="lineno">  443</span>    <span class="stringliteral">&quot;&quot;&quot;tests if the sag regressor is computed correctly&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  444</span>    alpha = 0.1</div>
<div class="line"><span class="lineno">  445</span>    n_features = 10</div>
<div class="line"><span class="lineno">  446</span>    n_samples = 40</div>
<div class="line"><span class="lineno">  447</span>    max_iter = 100</div>
<div class="line"><span class="lineno">  448</span>    tol = 0.000001</div>
<div class="line"><span class="lineno">  449</span>    fit_intercept = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  450</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  451</span>    X = rng.normal(size=(n_samples, n_features))</div>
<div class="line"><span class="lineno">  452</span>    w = rng.normal(size=n_features)</div>
<div class="line"><span class="lineno">  453</span>    y = np.dot(X, w) + 2.0</div>
<div class="line"><span class="lineno">  454</span>    step_size = get_step_size(X, alpha, fit_intercept, classification=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  455</span> </div>
<div class="line"><span class="lineno">  456</span>    clf1 = Ridge(</div>
<div class="line"><span class="lineno">  457</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  458</span>        tol=tol,</div>
<div class="line"><span class="lineno">  459</span>        solver=<span class="stringliteral">&quot;sag&quot;</span>,</div>
<div class="line"><span class="lineno">  460</span>        alpha=alpha * n_samples,</div>
<div class="line"><span class="lineno">  461</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  462</span>        random_state=rng,</div>
<div class="line"><span class="lineno">  463</span>    )</div>
<div class="line"><span class="lineno">  464</span>    clf2 = clone(clf1)</div>
<div class="line"><span class="lineno">  465</span> </div>
<div class="line"><span class="lineno">  466</span>    clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  467</span>    clf2.fit(sp.csr_matrix(X), y)</div>
<div class="line"><span class="lineno">  468</span> </div>
<div class="line"><span class="lineno">  469</span>    spweights1, spintercept1 = sag_sparse(</div>
<div class="line"><span class="lineno">  470</span>        X,</div>
<div class="line"><span class="lineno">  471</span>        y,</div>
<div class="line"><span class="lineno">  472</span>        step_size,</div>
<div class="line"><span class="lineno">  473</span>        alpha,</div>
<div class="line"><span class="lineno">  474</span>        n_iter=max_iter,</div>
<div class="line"><span class="lineno">  475</span>        dloss=squared_dloss,</div>
<div class="line"><span class="lineno">  476</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  477</span>        random_state=rng,</div>
<div class="line"><span class="lineno">  478</span>    )</div>
<div class="line"><span class="lineno">  479</span> </div>
<div class="line"><span class="lineno">  480</span>    spweights2, spintercept2 = sag_sparse(</div>
<div class="line"><span class="lineno">  481</span>        X,</div>
<div class="line"><span class="lineno">  482</span>        y,</div>
<div class="line"><span class="lineno">  483</span>        step_size,</div>
<div class="line"><span class="lineno">  484</span>        alpha,</div>
<div class="line"><span class="lineno">  485</span>        n_iter=max_iter,</div>
<div class="line"><span class="lineno">  486</span>        dloss=squared_dloss,</div>
<div class="line"><span class="lineno">  487</span>        sparse=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  488</span>        fit_intercept=fit_intercept,</div>
<div class="line"><span class="lineno">  489</span>        random_state=rng,</div>
<div class="line"><span class="lineno">  490</span>    )</div>
<div class="line"><span class="lineno">  491</span> </div>
<div class="line"><span class="lineno">  492</span>    assert_array_almost_equal(clf1.coef_.ravel(), spweights1.ravel(), decimal=3)</div>
<div class="line"><span class="lineno">  493</span>    assert_almost_equal(clf1.intercept_, spintercept1, decimal=1)</div>
<div class="line"><span class="lineno">  494</span> </div>
<div class="line"><span class="lineno">  495</span>    <span class="comment"># TODO: uncomment when sparse Ridge with intercept will be fixed (#4710)</span></div>
<div class="line"><span class="lineno">  496</span>    <span class="comment"># assert_array_almost_equal(clf2.coef_.ravel(),</span></div>
<div class="line"><span class="lineno">  497</span>    <span class="comment">#                          spweights2.ravel(),</span></div>
<div class="line"><span class="lineno">  498</span>    <span class="comment">#                          decimal=3)</span></div>
<div class="line"><span class="lineno">  499</span>    <span class="comment"># assert_almost_equal(clf2.intercept_, spintercept2, decimal=1)&#39;&#39;&#39;</span></div>
<div class="line"><span class="lineno">  500</span> </div>
<div class="line"><span class="lineno">  501</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a23bfaca22a3cd68fb247e0554dcd74a0" name="a23bfaca22a3cd68fb247e0554dcd74a0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a23bfaca22a3cd68fb247e0554dcd74a0">&#9670;&#160;</a></span>test_step_size_alpha_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.test_step_size_alpha_error </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  900</span><span class="keyword">def </span>test_step_size_alpha_error():</div>
<div class="line"><span class="lineno">  901</span>    X = [[0, 0], [0, 0]]</div>
<div class="line"><span class="lineno">  902</span>    y = [1, -1]</div>
<div class="line"><span class="lineno">  903</span>    fit_intercept = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  904</span>    alpha = 1.0</div>
<div class="line"><span class="lineno">  905</span>    msg = re.escape(</div>
<div class="line"><span class="lineno">  906</span>        <span class="stringliteral">&quot;Current sag implementation does not handle the case&quot;</span></div>
<div class="line"><span class="lineno">  907</span>        <span class="stringliteral">&quot; step_size * alpha_scaled == 1&quot;</span></div>
<div class="line"><span class="lineno">  908</span>    )</div>
<div class="line"><span class="lineno">  909</span> </div>
<div class="line"><span class="lineno">  910</span>    clf1 = LogisticRegression(solver=<span class="stringliteral">&quot;sag&quot;</span>, C=1.0 / alpha, fit_intercept=fit_intercept)</div>
<div class="line"><span class="lineno">  911</span>    <span class="keyword">with</span> pytest.raises(ZeroDivisionError, match=msg):</div>
<div class="line"><span class="lineno">  912</span>        clf1.fit(X, y)</div>
<div class="line"><span class="lineno">  913</span> </div>
<div class="line"><span class="lineno">  914</span>    clf2 = Ridge(fit_intercept=fit_intercept, solver=<span class="stringliteral">&quot;sag&quot;</span>, alpha=alpha)</div>
<div class="line"><span class="lineno">  915</span>    <span class="keyword">with</span> pytest.raises(ZeroDivisionError, match=msg):</div>
<div class="line"><span class="lineno">  916</span>        clf2.fit(X, y)</div>
<div class="line"><span class="lineno">  917</span> </div>
<div class="line"><span class="lineno">  918</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a18f7a31c3b953db84cda4e2856075851" name="a18f7a31c3b953db84cda4e2856075851"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18f7a31c3b953db84cda4e2856075851">&#9670;&#160;</a></span>iris</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.linear_model.tests.test_sag.iris = load_iris()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
