<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.tree.tests.test_tree Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1tree.html">tree</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1tree_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html">test_tree</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.tree.tests.test_tree Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a3ec98097203a9148b89eb1808f0c4023" id="r_a3ec98097203a9148b89eb1808f0c4023"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a3ec98097203a9148b89eb1808f0c4023">assert_tree_equal</a> (<a class="el" href="__lapack__subroutines_8h.html#a4c293bae27b15a76659be28378992185">d</a>, s, message)</td></tr>
<tr class="separator:a3ec98097203a9148b89eb1808f0c4023"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9dc287bd0c6175372c12aeced8d4dd60" id="r_a9dc287bd0c6175372c12aeced8d4dd60"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a9dc287bd0c6175372c12aeced8d4dd60">test_classification_toy</a> ()</td></tr>
<tr class="separator:a9dc287bd0c6175372c12aeced8d4dd60"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aefbb6d1db4fa4591e1d4499bea35b020" id="r_aefbb6d1db4fa4591e1d4499bea35b020"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aefbb6d1db4fa4591e1d4499bea35b020">test_weighted_classification_toy</a> ()</td></tr>
<tr class="separator:aefbb6d1db4fa4591e1d4499bea35b020"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbae6d17bf807b5f4c8c4e60b0ade633" id="r_acbae6d17bf807b5f4c8c4e60b0ade633"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#acbae6d17bf807b5f4c8c4e60b0ade633">test_regression_toy</a> (Tree, criterion)</td></tr>
<tr class="separator:acbae6d17bf807b5f4c8c4e60b0ade633"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aedda82194fbccbc27a9690ec6885923d" id="r_aedda82194fbccbc27a9690ec6885923d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aedda82194fbccbc27a9690ec6885923d">test_xor</a> ()</td></tr>
<tr class="separator:aedda82194fbccbc27a9690ec6885923d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf247a125c58b5a6bb427efed77cf52d" id="r_abf247a125c58b5a6bb427efed77cf52d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#abf247a125c58b5a6bb427efed77cf52d">test_iris</a> ()</td></tr>
<tr class="separator:abf247a125c58b5a6bb427efed77cf52d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6967f02536bdad7574319c6b666b3ea5" id="r_a6967f02536bdad7574319c6b666b3ea5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a6967f02536bdad7574319c6b666b3ea5">test_diabetes_overfit</a> (name, Tree, criterion)</td></tr>
<tr class="separator:a6967f02536bdad7574319c6b666b3ea5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a906dc5fc348c26eb13f94a35a1ac4735" id="r_a906dc5fc348c26eb13f94a35a1ac4735"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a906dc5fc348c26eb13f94a35a1ac4735">test_diabetes_underfit</a> (name, Tree, criterion, max_depth, metric, max_loss)</td></tr>
<tr class="separator:a906dc5fc348c26eb13f94a35a1ac4735"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1cd1b8bbbefb63a84690f13899bba82f" id="r_a1cd1b8bbbefb63a84690f13899bba82f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a1cd1b8bbbefb63a84690f13899bba82f">test_probability</a> ()</td></tr>
<tr class="separator:a1cd1b8bbbefb63a84690f13899bba82f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d62b12850c2a4c0ed6c5b3933f83645" id="r_a5d62b12850c2a4c0ed6c5b3933f83645"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a5d62b12850c2a4c0ed6c5b3933f83645">test_arrayrepr</a> ()</td></tr>
<tr class="separator:a5d62b12850c2a4c0ed6c5b3933f83645"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87db168d8eb431d79a1e6ab566e7561b" id="r_a87db168d8eb431d79a1e6ab566e7561b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a87db168d8eb431d79a1e6ab566e7561b">test_pure_set</a> ()</td></tr>
<tr class="separator:a87db168d8eb431d79a1e6ab566e7561b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9769166ca81f2b05958fb558c0e9441a" id="r_a9769166ca81f2b05958fb558c0e9441a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a9769166ca81f2b05958fb558c0e9441a">test_numerical_stability</a> ()</td></tr>
<tr class="separator:a9769166ca81f2b05958fb558c0e9441a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77e0129331b09da880892265ff5741d0" id="r_a77e0129331b09da880892265ff5741d0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a77e0129331b09da880892265ff5741d0">test_importances</a> ()</td></tr>
<tr class="separator:a77e0129331b09da880892265ff5741d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a520375ba091f98a989dca7a84228f5c5" id="r_a520375ba091f98a989dca7a84228f5c5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a520375ba091f98a989dca7a84228f5c5">test_importances_raises</a> ()</td></tr>
<tr class="separator:a520375ba091f98a989dca7a84228f5c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02e99d9a24e8dd16528fbb6787e5c75f" id="r_a02e99d9a24e8dd16528fbb6787e5c75f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a02e99d9a24e8dd16528fbb6787e5c75f">test_importances_gini_equal_squared_error</a> ()</td></tr>
<tr class="separator:a02e99d9a24e8dd16528fbb6787e5c75f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80c1cbf836f4b0013ccb82d6a2455851" id="r_a80c1cbf836f4b0013ccb82d6a2455851"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a80c1cbf836f4b0013ccb82d6a2455851">test_max_features</a> ()</td></tr>
<tr class="separator:a80c1cbf836f4b0013ccb82d6a2455851"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5131e82712fb9a10246b47b8040fd082" id="r_a5131e82712fb9a10246b47b8040fd082"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a5131e82712fb9a10246b47b8040fd082">test_error</a> ()</td></tr>
<tr class="separator:a5131e82712fb9a10246b47b8040fd082"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a004c38aadbea45dd988b72d920858fbe" id="r_a004c38aadbea45dd988b72d920858fbe"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a004c38aadbea45dd988b72d920858fbe">test_min_samples_split</a> ()</td></tr>
<tr class="separator:a004c38aadbea45dd988b72d920858fbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2e7f854a04b501bec1d94317e23af41d" id="r_a2e7f854a04b501bec1d94317e23af41d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a2e7f854a04b501bec1d94317e23af41d">test_min_samples_leaf</a> ()</td></tr>
<tr class="separator:a2e7f854a04b501bec1d94317e23af41d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f8d6a2df67f8251595c8695bb1b4f1f" id="r_a4f8d6a2df67f8251595c8695bb1b4f1f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a4f8d6a2df67f8251595c8695bb1b4f1f">check_min_weight_fraction_leaf</a> (name, datasets, sparse=False)</td></tr>
<tr class="separator:a4f8d6a2df67f8251595c8695bb1b4f1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f6be513139b600c55e7debeaf81bcbc" id="r_a5f6be513139b600c55e7debeaf81bcbc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a5f6be513139b600c55e7debeaf81bcbc">test_min_weight_fraction_leaf_on_dense_input</a> (name)</td></tr>
<tr class="separator:a5f6be513139b600c55e7debeaf81bcbc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e376ebb5df06a71995ba8f86ccfa336" id="r_a3e376ebb5df06a71995ba8f86ccfa336"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a3e376ebb5df06a71995ba8f86ccfa336">test_min_weight_fraction_leaf_on_sparse_input</a> (name)</td></tr>
<tr class="separator:a3e376ebb5df06a71995ba8f86ccfa336"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5d6d483fcb17fa89efa1afe49f945d6" id="r_af5d6d483fcb17fa89efa1afe49f945d6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#af5d6d483fcb17fa89efa1afe49f945d6">check_min_weight_fraction_leaf_with_min_samples_leaf</a> (name, datasets, sparse=False)</td></tr>
<tr class="separator:af5d6d483fcb17fa89efa1afe49f945d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35b9c7562b8ed0fbdcfc4b5eb6f78b9a" id="r_a35b9c7562b8ed0fbdcfc4b5eb6f78b9a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a35b9c7562b8ed0fbdcfc4b5eb6f78b9a">test_min_weight_fraction_leaf_with_min_samples_leaf_on_dense_input</a> (name)</td></tr>
<tr class="separator:a35b9c7562b8ed0fbdcfc4b5eb6f78b9a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01c5a5e0c02013c6b6d91d5c91d6ce75" id="r_a01c5a5e0c02013c6b6d91d5c91d6ce75"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a01c5a5e0c02013c6b6d91d5c91d6ce75">test_min_weight_fraction_leaf_with_min_samples_leaf_on_sparse_input</a> (name)</td></tr>
<tr class="separator:a01c5a5e0c02013c6b6d91d5c91d6ce75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a973f9f1b612f1519cb0f604ad4f0d33a" id="r_a973f9f1b612f1519cb0f604ad4f0d33a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a973f9f1b612f1519cb0f604ad4f0d33a">test_min_impurity_decrease</a> ()</td></tr>
<tr class="separator:a973f9f1b612f1519cb0f604ad4f0d33a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a4b4d1385da65ce74d1b93f9988953e" id="r_a3a4b4d1385da65ce74d1b93f9988953e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a3a4b4d1385da65ce74d1b93f9988953e">test_pickle</a> ()</td></tr>
<tr class="separator:a3a4b4d1385da65ce74d1b93f9988953e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3471fb35958cb6bcba467aa931ef4a52" id="r_a3471fb35958cb6bcba467aa931ef4a52"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a3471fb35958cb6bcba467aa931ef4a52">test_multioutput</a> ()</td></tr>
<tr class="separator:a3471fb35958cb6bcba467aa931ef4a52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3a0680e7ec2dc5e8a6c14c69fc11138" id="r_ab3a0680e7ec2dc5e8a6c14c69fc11138"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ab3a0680e7ec2dc5e8a6c14c69fc11138">test_classes_shape</a> ()</td></tr>
<tr class="separator:ab3a0680e7ec2dc5e8a6c14c69fc11138"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a094a53a595c78efebd74a80985dcd237" id="r_a094a53a595c78efebd74a80985dcd237"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a094a53a595c78efebd74a80985dcd237">test_unbalanced_iris</a> ()</td></tr>
<tr class="separator:a094a53a595c78efebd74a80985dcd237"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a415f59497dd7851a02ed9f81255283f7" id="r_a415f59497dd7851a02ed9f81255283f7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a415f59497dd7851a02ed9f81255283f7">test_memory_layout</a> ()</td></tr>
<tr class="separator:a415f59497dd7851a02ed9f81255283f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1aada459c3224d9fabff3dc79eebac5d" id="r_a1aada459c3224d9fabff3dc79eebac5d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a1aada459c3224d9fabff3dc79eebac5d">test_sample_weight</a> ()</td></tr>
<tr class="separator:a1aada459c3224d9fabff3dc79eebac5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c7f03fbc727a15832e070fe0e47d39e" id="r_a2c7f03fbc727a15832e070fe0e47d39e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a2c7f03fbc727a15832e070fe0e47d39e">test_sample_weight_invalid</a> ()</td></tr>
<tr class="separator:a2c7f03fbc727a15832e070fe0e47d39e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45f86c6bcfb976c4aa195d3ca605de59" id="r_a45f86c6bcfb976c4aa195d3ca605de59"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a45f86c6bcfb976c4aa195d3ca605de59">check_class_weights</a> (name)</td></tr>
<tr class="separator:a45f86c6bcfb976c4aa195d3ca605de59"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13805dc993c5fb5a40afa2ae248c293a" id="r_a13805dc993c5fb5a40afa2ae248c293a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a13805dc993c5fb5a40afa2ae248c293a">test_class_weights</a> (name)</td></tr>
<tr class="separator:a13805dc993c5fb5a40afa2ae248c293a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b4a16420a426e18813db7437df900d7" id="r_a9b4a16420a426e18813db7437df900d7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a9b4a16420a426e18813db7437df900d7">check_class_weight_errors</a> (name)</td></tr>
<tr class="separator:a9b4a16420a426e18813db7437df900d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:accbe354e05072278d62d0218c4bd185a" id="r_accbe354e05072278d62d0218c4bd185a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#accbe354e05072278d62d0218c4bd185a">test_class_weight_errors</a> (name)</td></tr>
<tr class="separator:accbe354e05072278d62d0218c4bd185a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafe47030f0ad10b34f1ff512d635ff9f" id="r_aafe47030f0ad10b34f1ff512d635ff9f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aafe47030f0ad10b34f1ff512d635ff9f">test_max_leaf_nodes</a> ()</td></tr>
<tr class="separator:aafe47030f0ad10b34f1ff512d635ff9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a14f860fe9f47a13ac4c4b50fb5b920ab" id="r_a14f860fe9f47a13ac4c4b50fb5b920ab"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a14f860fe9f47a13ac4c4b50fb5b920ab">test_max_leaf_nodes_max_depth</a> ()</td></tr>
<tr class="separator:a14f860fe9f47a13ac4c4b50fb5b920ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94f6561365e5995de348a5175781ca93" id="r_a94f6561365e5995de348a5175781ca93"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a94f6561365e5995de348a5175781ca93">test_arrays_persist</a> ()</td></tr>
<tr class="separator:a94f6561365e5995de348a5175781ca93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65076d784348e7234edf453c5a55f838" id="r_a65076d784348e7234edf453c5a55f838"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a65076d784348e7234edf453c5a55f838">test_only_constant_features</a> ()</td></tr>
<tr class="separator:a65076d784348e7234edf453c5a55f838"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a203b1206d395658669cba43f0786ec2b" id="r_a203b1206d395658669cba43f0786ec2b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a203b1206d395658669cba43f0786ec2b">test_behaviour_constant_feature_after_splits</a> ()</td></tr>
<tr class="separator:a203b1206d395658669cba43f0786ec2b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a374939bc2a0a2922c1c7a36d668e4f28" id="r_a374939bc2a0a2922c1c7a36d668e4f28"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a374939bc2a0a2922c1c7a36d668e4f28">test_with_only_one_non_constant_features</a> ()</td></tr>
<tr class="separator:a374939bc2a0a2922c1c7a36d668e4f28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a372a27a7d8bf57174a65ff03722b4f37" id="r_a372a27a7d8bf57174a65ff03722b4f37"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a372a27a7d8bf57174a65ff03722b4f37">test_big_input</a> ()</td></tr>
<tr class="separator:a372a27a7d8bf57174a65ff03722b4f37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6d2d7300cc94b26692f11c47a71daa1" id="r_ad6d2d7300cc94b26692f11c47a71daa1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ad6d2d7300cc94b26692f11c47a71daa1">test_realloc</a> ()</td></tr>
<tr class="separator:ad6d2d7300cc94b26692f11c47a71daa1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b34ae16c8824256fb5f8d63546dd3c9" id="r_a2b34ae16c8824256fb5f8d63546dd3c9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a2b34ae16c8824256fb5f8d63546dd3c9">test_huge_allocations</a> ()</td></tr>
<tr class="separator:a2b34ae16c8824256fb5f8d63546dd3c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae30b601ecdcb17c2e057839c96f9f589" id="r_ae30b601ecdcb17c2e057839c96f9f589"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ae30b601ecdcb17c2e057839c96f9f589">check_sparse_input</a> (tree, dataset, max_depth=None)</td></tr>
<tr class="separator:ae30b601ecdcb17c2e057839c96f9f589"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a320204ebd54116fa049936e126c77546" id="r_a320204ebd54116fa049936e126c77546"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a320204ebd54116fa049936e126c77546">test_sparse_input</a> (tree_type, dataset)</td></tr>
<tr class="separator:a320204ebd54116fa049936e126c77546"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae54aa93b2d9fac458bb5bbd3770a82d7" id="r_ae54aa93b2d9fac458bb5bbd3770a82d7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ae54aa93b2d9fac458bb5bbd3770a82d7">test_sparse_input_reg_trees</a> (tree_type, dataset)</td></tr>
<tr class="separator:ae54aa93b2d9fac458bb5bbd3770a82d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acce3f0226d0dc73b9f62f56d8286c557" id="r_acce3f0226d0dc73b9f62f56d8286c557"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#acce3f0226d0dc73b9f62f56d8286c557">check_sparse_parameters</a> (tree, dataset)</td></tr>
<tr class="separator:acce3f0226d0dc73b9f62f56d8286c557"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31552cc23946d140ffb1d7a1942782ea" id="r_a31552cc23946d140ffb1d7a1942782ea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a31552cc23946d140ffb1d7a1942782ea">check_sparse_criterion</a> (tree, dataset)</td></tr>
<tr class="separator:a31552cc23946d140ffb1d7a1942782ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a50fdd9c117496277a9ae1e1942d68b" id="r_a6a50fdd9c117496277a9ae1e1942d68b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a6a50fdd9c117496277a9ae1e1942d68b">test_sparse</a> (tree_type, dataset, check)</td></tr>
<tr class="separator:a6a50fdd9c117496277a9ae1e1942d68b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e800f5993e27ad6df28f80a3dcb86c3" id="r_a8e800f5993e27ad6df28f80a3dcb86c3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a8e800f5993e27ad6df28f80a3dcb86c3">check_explicit_sparse_zeros</a> (tree, max_depth=3, <a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#acd4a764a604accf7c5583890acf1642a">n_features</a>=10)</td></tr>
<tr class="separator:a8e800f5993e27ad6df28f80a3dcb86c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55cfc637af70c967ea2c1fa24b07f8ed" id="r_a55cfc637af70c967ea2c1fa24b07f8ed"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a55cfc637af70c967ea2c1fa24b07f8ed">test_explicit_sparse_zeros</a> (tree_type)</td></tr>
<tr class="separator:a55cfc637af70c967ea2c1fa24b07f8ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5425310283a40c55be37512699bce94" id="r_ae5425310283a40c55be37512699bce94"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ae5425310283a40c55be37512699bce94">check_raise_error_on_1d_input</a> (name)</td></tr>
<tr class="separator:ae5425310283a40c55be37512699bce94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2864de832fd8766a040c9188c762fbc" id="r_af2864de832fd8766a040c9188c762fbc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#af2864de832fd8766a040c9188c762fbc">test_1d_input</a> (name)</td></tr>
<tr class="separator:af2864de832fd8766a040c9188c762fbc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0dc5ba22bef20b4d0ad67d83cc789e1" id="r_aa0dc5ba22bef20b4d0ad67d83cc789e1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aa0dc5ba22bef20b4d0ad67d83cc789e1">_check_min_weight_leaf_split_level</a> (TreeEstimator, <a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a0de06db865b18c30d3c9c86a3a05e6b9">X</a>, <a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ae073fd8ff4a679754e7d15fec2ef840d">y</a>, sample_weight)</td></tr>
<tr class="separator:aa0dc5ba22bef20b4d0ad67d83cc789e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3edf4665a10e53111206e6922dcf034a" id="r_a3edf4665a10e53111206e6922dcf034a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a3edf4665a10e53111206e6922dcf034a">check_min_weight_leaf_split_level</a> (name)</td></tr>
<tr class="separator:a3edf4665a10e53111206e6922dcf034a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab02bb58a226a908889acaaa1ad4a9d4f" id="r_ab02bb58a226a908889acaaa1ad4a9d4f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ab02bb58a226a908889acaaa1ad4a9d4f">test_min_weight_leaf_split_level</a> (name)</td></tr>
<tr class="separator:ab02bb58a226a908889acaaa1ad4a9d4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75d58df9831fc228d8cf01f856d3c592" id="r_a75d58df9831fc228d8cf01f856d3c592"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a75d58df9831fc228d8cf01f856d3c592">check_public_apply</a> (name)</td></tr>
<tr class="separator:a75d58df9831fc228d8cf01f856d3c592"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1ddde6453d4dac2333f6e962cdc54e5" id="r_ad1ddde6453d4dac2333f6e962cdc54e5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ad1ddde6453d4dac2333f6e962cdc54e5">check_public_apply_sparse</a> (name)</td></tr>
<tr class="separator:ad1ddde6453d4dac2333f6e962cdc54e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af32ffe19bf998e941e61e07828d98848" id="r_af32ffe19bf998e941e61e07828d98848"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#af32ffe19bf998e941e61e07828d98848">test_public_apply_all_trees</a> (name)</td></tr>
<tr class="separator:af32ffe19bf998e941e61e07828d98848"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20d0b13fee9fb161ed9a1594c16d1aac" id="r_a20d0b13fee9fb161ed9a1594c16d1aac"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a20d0b13fee9fb161ed9a1594c16d1aac">test_public_apply_sparse_trees</a> (name)</td></tr>
<tr class="separator:a20d0b13fee9fb161ed9a1594c16d1aac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae42812d88b9ce4df0c4d74b4af44c446" id="r_ae42812d88b9ce4df0c4d74b4af44c446"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ae42812d88b9ce4df0c4d74b4af44c446">test_decision_path_hardcoded</a> ()</td></tr>
<tr class="separator:ae42812d88b9ce4df0c4d74b4af44c446"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab00099a23acfdbcc2883f92fbd6ba3f3" id="r_ab00099a23acfdbcc2883f92fbd6ba3f3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ab00099a23acfdbcc2883f92fbd6ba3f3">check_decision_path</a> (name)</td></tr>
<tr class="separator:ab00099a23acfdbcc2883f92fbd6ba3f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69779ee3653cbea4e7a111d745e7b5d1" id="r_a69779ee3653cbea4e7a111d745e7b5d1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a69779ee3653cbea4e7a111d745e7b5d1">test_decision_path</a> (name)</td></tr>
<tr class="separator:a69779ee3653cbea4e7a111d745e7b5d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab05089aa1aaa32596f6ffa35cad0b808" id="r_ab05089aa1aaa32596f6ffa35cad0b808"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ab05089aa1aaa32596f6ffa35cad0b808">check_no_sparse_y_support</a> (name)</td></tr>
<tr class="separator:ab05089aa1aaa32596f6ffa35cad0b808"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a944a99e4c1469b44841129e08ea0d99f" id="r_a944a99e4c1469b44841129e08ea0d99f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a944a99e4c1469b44841129e08ea0d99f">test_no_sparse_y_support</a> (name)</td></tr>
<tr class="separator:a944a99e4c1469b44841129e08ea0d99f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31d1afe2a23c432f1bc18d8c4761f902" id="r_a31d1afe2a23c432f1bc18d8c4761f902"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a31d1afe2a23c432f1bc18d8c4761f902">test_mae</a> ()</td></tr>
<tr class="separator:a31d1afe2a23c432f1bc18d8c4761f902"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3160e0d670b66fd2558cc80a5a4a50a4" id="r_a3160e0d670b66fd2558cc80a5a4a50a4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a3160e0d670b66fd2558cc80a5a4a50a4">test_criterion_copy</a> ()</td></tr>
<tr class="separator:a3160e0d670b66fd2558cc80a5a4a50a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a124e747b70c02fd5edad2791f4363bca" id="r_a124e747b70c02fd5edad2791f4363bca"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a124e747b70c02fd5edad2791f4363bca">test_empty_leaf_infinite_threshold</a> ()</td></tr>
<tr class="separator:a124e747b70c02fd5edad2791f4363bca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeee06d4abb24a1409972a857cfeb0ce8" id="r_aeee06d4abb24a1409972a857cfeb0ce8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aeee06d4abb24a1409972a857cfeb0ce8">test_prune_tree_classifier_are_subtrees</a> (criterion, dataset, tree_cls)</td></tr>
<tr class="separator:aeee06d4abb24a1409972a857cfeb0ce8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c1bdd53ac8d387ed01c64734852f824" id="r_a7c1bdd53ac8d387ed01c64734852f824"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a7c1bdd53ac8d387ed01c64734852f824">test_prune_tree_regression_are_subtrees</a> (criterion, dataset, tree_cls)</td></tr>
<tr class="separator:a7c1bdd53ac8d387ed01c64734852f824"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4df924af5e55f9b7c904ff015de390d8" id="r_a4df924af5e55f9b7c904ff015de390d8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a4df924af5e55f9b7c904ff015de390d8">test_prune_single_node_tree</a> ()</td></tr>
<tr class="separator:a4df924af5e55f9b7c904ff015de390d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd2877b5c71050a115681fd906dd7f05" id="r_afd2877b5c71050a115681fd906dd7f05"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#afd2877b5c71050a115681fd906dd7f05">assert_pruning_creates_subtree</a> (estimator_cls, <a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a0de06db865b18c30d3c9c86a3a05e6b9">X</a>, <a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ae073fd8ff4a679754e7d15fec2ef840d">y</a>, pruning_path)</td></tr>
<tr class="separator:afd2877b5c71050a115681fd906dd7f05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad80205402a9ceca4505101bb8591ef7d" id="r_ad80205402a9ceca4505101bb8591ef7d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ad80205402a9ceca4505101bb8591ef7d">assert_is_subtree</a> (tree, subtree)</td></tr>
<tr class="separator:ad80205402a9ceca4505101bb8591ef7d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6f979ab8e52c3a31540f3716cfdbc56" id="r_aa6f979ab8e52c3a31540f3716cfdbc56"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aa6f979ab8e52c3a31540f3716cfdbc56">check_apply_path_readonly</a> (name)</td></tr>
<tr class="separator:aa6f979ab8e52c3a31540f3716cfdbc56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b25927c90204d81098c3cf7577cd1f7" id="r_a7b25927c90204d81098c3cf7577cd1f7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a7b25927c90204d81098c3cf7577cd1f7">test_apply_path_readonly_all_trees</a> (name)</td></tr>
<tr class="separator:a7b25927c90204d81098c3cf7577cd1f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafa7e6bcc6a0a245fac3174707ad4312" id="r_aafa7e6bcc6a0a245fac3174707ad4312"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aafa7e6bcc6a0a245fac3174707ad4312">test_balance_property</a> (criterion, Tree)</td></tr>
<tr class="separator:aafa7e6bcc6a0a245fac3174707ad4312"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac20c705a6368852f17af3555368fb339" id="r_ac20c705a6368852f17af3555368fb339"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ac20c705a6368852f17af3555368fb339">test_poisson_zero_nodes</a> (seed)</td></tr>
<tr class="separator:ac20c705a6368852f17af3555368fb339"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1da86451d3bc347137c678e4d55acf4e" id="r_a1da86451d3bc347137c678e4d55acf4e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a1da86451d3bc347137c678e4d55acf4e">test_poisson_vs_mse</a> ()</td></tr>
<tr class="separator:a1da86451d3bc347137c678e4d55acf4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7257dca1fc4b07dc649b621e92c4bd0" id="r_ae7257dca1fc4b07dc649b621e92c4bd0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ae7257dca1fc4b07dc649b621e92c4bd0">test_decision_tree_regressor_sample_weight_consistency</a> (criterion)</td></tr>
<tr class="separator:ae7257dca1fc4b07dc649b621e92c4bd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af281edcc3b211f692b5142a4d73709da" id="r_af281edcc3b211f692b5142a4d73709da"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#af281edcc3b211f692b5142a4d73709da">test_criterion_entropy_same_as_log_loss</a> (Tree, n_classes)</td></tr>
<tr class="separator:af281edcc3b211f692b5142a4d73709da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c3a51d789f7ffde65382dbc66371c62" id="r_a4c3a51d789f7ffde65382dbc66371c62"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a4c3a51d789f7ffde65382dbc66371c62">test_different_endianness_pickle</a> ()</td></tr>
<tr class="separator:a4c3a51d789f7ffde65382dbc66371c62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbb62314fd844d396074729b442a55b0" id="r_acbb62314fd844d396074729b442a55b0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#acbb62314fd844d396074729b442a55b0">test_different_endianness_joblib_pickle</a> ()</td></tr>
<tr class="separator:acbb62314fd844d396074729b442a55b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a029116b4d5f92965dc9e44adbc12223f" id="r_a029116b4d5f92965dc9e44adbc12223f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a029116b4d5f92965dc9e44adbc12223f">get_different_bitness_node_ndarray</a> (node_ndarray)</td></tr>
<tr class="separator:a029116b4d5f92965dc9e44adbc12223f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab84beafe039b306d440e55830569c9a4" id="r_ab84beafe039b306d440e55830569c9a4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ab84beafe039b306d440e55830569c9a4">get_different_alignment_node_ndarray</a> (node_ndarray)</td></tr>
<tr class="separator:ab84beafe039b306d440e55830569c9a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e0d9a04c9c2057b44e77ffba32e4102" id="r_a3e0d9a04c9c2057b44e77ffba32e4102"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a3e0d9a04c9c2057b44e77ffba32e4102">reduce_tree_with_different_bitness</a> (tree)</td></tr>
<tr class="separator:a3e0d9a04c9c2057b44e77ffba32e4102"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad89f1c5c5d264b827e1195179484a33e" id="r_ad89f1c5c5d264b827e1195179484a33e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ad89f1c5c5d264b827e1195179484a33e">test_different_bitness_pickle</a> ()</td></tr>
<tr class="separator:ad89f1c5c5d264b827e1195179484a33e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aebb22eada9714f6915dbd9667338804c" id="r_aebb22eada9714f6915dbd9667338804c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aebb22eada9714f6915dbd9667338804c">test_different_bitness_joblib_pickle</a> ()</td></tr>
<tr class="separator:aebb22eada9714f6915dbd9667338804c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48b63f3a9ef4fc2cabb93318c9969771" id="r_a48b63f3a9ef4fc2cabb93318c9969771"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a48b63f3a9ef4fc2cabb93318c9969771">test_check_n_classes</a> ()</td></tr>
<tr class="separator:a48b63f3a9ef4fc2cabb93318c9969771"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56d0763ad698165f943ef947c3f1d0b7" id="r_a56d0763ad698165f943ef947c3f1d0b7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a56d0763ad698165f943ef947c3f1d0b7">test_check_value_ndarray</a> ()</td></tr>
<tr class="separator:a56d0763ad698165f943ef947c3f1d0b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f2127ad57fcf4a114d9c448c06b39d1" id="r_a8f2127ad57fcf4a114d9c448c06b39d1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a8f2127ad57fcf4a114d9c448c06b39d1">test_check_node_ndarray</a> ()</td></tr>
<tr class="separator:a8f2127ad57fcf4a114d9c448c06b39d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace858c6ec825a682f976179afe5d834f" id="r_ace858c6ec825a682f976179afe5d834f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ace858c6ec825a682f976179afe5d834f">test_max_features_auto_deprecated</a> ()</td></tr>
<tr class="separator:ace858c6ec825a682f976179afe5d834f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:ac0c7d5516fc331c219c8e12dbb7ef232" id="r_ac0c7d5516fc331c219c8e12dbb7ef232"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ac0c7d5516fc331c219c8e12dbb7ef232">CLF_CRITERIONS</a> = (&quot;gini&quot;, &quot;log_loss&quot;)</td></tr>
<tr class="separator:ac0c7d5516fc331c219c8e12dbb7ef232"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73e7394ed027eaab3306f543937602da" id="r_a73e7394ed027eaab3306f543937602da"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a73e7394ed027eaab3306f543937602da">REG_CRITERIONS</a> = (&quot;squared_error&quot;, &quot;absolute_error&quot;, &quot;friedman_mse&quot;, &quot;poisson&quot;)</td></tr>
<tr class="separator:a73e7394ed027eaab3306f543937602da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65b0f09bdf5886a5e38c16b0ecbeceba" id="r_a65b0f09bdf5886a5e38c16b0ecbeceba"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a65b0f09bdf5886a5e38c16b0ecbeceba">CLF_TREES</a></td></tr>
<tr class="separator:a65b0f09bdf5886a5e38c16b0ecbeceba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94cf81e208b61f2814ddf5b46b8d6534" id="r_a94cf81e208b61f2814ddf5b46b8d6534"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a94cf81e208b61f2814ddf5b46b8d6534">REG_TREES</a></td></tr>
<tr class="separator:a94cf81e208b61f2814ddf5b46b8d6534"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e6a2d744db150e244243332d134d14e" id="r_a8e6a2d744db150e244243332d134d14e"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a8e6a2d744db150e244243332d134d14e">ALL_TREES</a> = dict()</td></tr>
<tr class="separator:a8e6a2d744db150e244243332d134d14e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a433d83a178acb87a185ba7cdab6d0865" id="r_a433d83a178acb87a185ba7cdab6d0865"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a433d83a178acb87a185ba7cdab6d0865">SPARSE_TREES</a></td></tr>
<tr class="separator:a433d83a178acb87a185ba7cdab6d0865"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf23fc59e312a4d66ad97f6de3fd8d5b" id="r_acf23fc59e312a4d66ad97f6de3fd8d5b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#acf23fc59e312a4d66ad97f6de3fd8d5b">X_small</a></td></tr>
<tr class="separator:acf23fc59e312a4d66ad97f6de3fd8d5b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e645db6f8075b1e756813bf302f6be1" id="r_a8e645db6f8075b1e756813bf302f6be1"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a8e645db6f8075b1e756813bf302f6be1">y_small</a> = [1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]</td></tr>
<tr class="separator:a8e645db6f8075b1e756813bf302f6be1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07e5bc0f7613ba34ccd63d9cec5d0392" id="r_a07e5bc0f7613ba34ccd63d9cec5d0392"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a07e5bc0f7613ba34ccd63d9cec5d0392">y_small_reg</a></td></tr>
<tr class="separator:a07e5bc0f7613ba34ccd63d9cec5d0392"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0de06db865b18c30d3c9c86a3a05e6b9" id="r_a0de06db865b18c30d3c9c86a3a05e6b9"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a0de06db865b18c30d3c9c86a3a05e6b9">X</a> = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]</td></tr>
<tr class="separator:a0de06db865b18c30d3c9c86a3a05e6b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae073fd8ff4a679754e7d15fec2ef840d" id="r_ae073fd8ff4a679754e7d15fec2ef840d"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ae073fd8ff4a679754e7d15fec2ef840d">y</a> = [-1, -1, -1, 1, 1, 1]</td></tr>
<tr class="separator:ae073fd8ff4a679754e7d15fec2ef840d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7556c3bfeab511b95be9efe79c476814" id="r_a7556c3bfeab511b95be9efe79c476814"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a7556c3bfeab511b95be9efe79c476814">T</a> = [[-1, -1], [2, 2], [3, 2]]</td></tr>
<tr class="separator:a7556c3bfeab511b95be9efe79c476814"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23f66f07bb7a2371327d858fe8bf9f57" id="r_a23f66f07bb7a2371327d858fe8bf9f57"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a23f66f07bb7a2371327d858fe8bf9f57">true_result</a> = [-1, 1, 1]</td></tr>
<tr class="separator:a23f66f07bb7a2371327d858fe8bf9f57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a123227057b7d0df52753df6008274dc3" id="r_a123227057b7d0df52753df6008274dc3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a123227057b7d0df52753df6008274dc3">iris</a> = datasets.load_iris()</td></tr>
<tr class="separator:a123227057b7d0df52753df6008274dc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5d2285e12a4340cee99d72be75411a4" id="r_ae5d2285e12a4340cee99d72be75411a4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ae5d2285e12a4340cee99d72be75411a4">rng</a> = np.random.RandomState(1)</td></tr>
<tr class="separator:ae5d2285e12a4340cee99d72be75411a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09d9b810e9f94b9abf13833ba86e4ff4" id="r_a09d9b810e9f94b9abf13833ba86e4ff4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a09d9b810e9f94b9abf13833ba86e4ff4">perm</a> = rng.permutation(iris.target.size)</td></tr>
<tr class="separator:a09d9b810e9f94b9abf13833ba86e4ff4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03aec4c1890309dda08ffc9457f5230b" id="r_a03aec4c1890309dda08ffc9457f5230b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a03aec4c1890309dda08ffc9457f5230b">data</a></td></tr>
<tr class="separator:a03aec4c1890309dda08ffc9457f5230b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c1dba4e588d0af9d31cbf427823647a" id="r_a2c1dba4e588d0af9d31cbf427823647a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a2c1dba4e588d0af9d31cbf427823647a">target</a></td></tr>
<tr class="separator:a2c1dba4e588d0af9d31cbf427823647a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a275d2c78e71a2806011bd8b5eaf6577c" id="r_a275d2c78e71a2806011bd8b5eaf6577c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a275d2c78e71a2806011bd8b5eaf6577c">diabetes</a> = datasets.load_diabetes()</td></tr>
<tr class="separator:a275d2c78e71a2806011bd8b5eaf6577c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89ae7de536e1b244bf989a22df9b3091" id="r_a89ae7de536e1b244bf989a22df9b3091"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a89ae7de536e1b244bf989a22df9b3091">digits</a> = datasets.load_digits()</td></tr>
<tr class="separator:a89ae7de536e1b244bf989a22df9b3091"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4d8e42c19195de8407ea5ffdf742db2" id="r_aa4d8e42c19195de8407ea5ffdf742db2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aa4d8e42c19195de8407ea5ffdf742db2">random_state</a> = check_random_state(0)</td></tr>
<tr class="separator:aa4d8e42c19195de8407ea5ffdf742db2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae000948545103c5a188392852c6c70fb" id="r_ae000948545103c5a188392852c6c70fb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ae000948545103c5a188392852c6c70fb">X_multilabel</a></td></tr>
<tr class="separator:ae000948545103c5a188392852c6c70fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68fd5d354ae9364bbfd4e8fc1bb0763c" id="r_a68fd5d354ae9364bbfd4e8fc1bb0763c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a68fd5d354ae9364bbfd4e8fc1bb0763c">y_multilabel</a></td></tr>
<tr class="separator:a68fd5d354ae9364bbfd4e8fc1bb0763c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade3ceeb48ad69723503620d6fc3a7882" id="r_ade3ceeb48ad69723503620d6fc3a7882"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#ade3ceeb48ad69723503620d6fc3a7882">n_samples</a></td></tr>
<tr class="separator:ade3ceeb48ad69723503620d6fc3a7882"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd4a764a604accf7c5583890acf1642a" id="r_acd4a764a604accf7c5583890acf1642a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#acd4a764a604accf7c5583890acf1642a">n_features</a></td></tr>
<tr class="separator:acd4a764a604accf7c5583890acf1642a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6898f36189dd3d0ac4dcef74f5bb2d7c" id="r_a6898f36189dd3d0ac4dcef74f5bb2d7c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a6898f36189dd3d0ac4dcef74f5bb2d7c">X_sparse_pos</a> = random_state.uniform(size=(20, 5))</td></tr>
<tr class="separator:a6898f36189dd3d0ac4dcef74f5bb2d7c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a1a680e9c0377a57eaaf06bb84652eb" id="r_a9a1a680e9c0377a57eaaf06bb84652eb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a9a1a680e9c0377a57eaaf06bb84652eb">y_random</a> = random_state.randint(0, 4, size=(20,))</td></tr>
<tr class="separator:a9a1a680e9c0377a57eaaf06bb84652eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45bb897fd36b9f9381875a9cbcc6766d" id="r_a45bb897fd36b9f9381875a9cbcc6766d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a45bb897fd36b9f9381875a9cbcc6766d">X_sparse_mix</a> = _sparse_random_matrix(20, 10, density=0.25, <a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aa4d8e42c19195de8407ea5ffdf742db2">random_state</a>=0).toarray()</td></tr>
<tr class="separator:a45bb897fd36b9f9381875a9cbcc6766d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a703b14ac9a01489bf499dda532508e37" id="r_a703b14ac9a01489bf499dda532508e37"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#a703b14ac9a01489bf499dda532508e37">DATASETS</a></td></tr>
<tr class="separator:a703b14ac9a01489bf499dda532508e37"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Testing for the tree module (sklearn.tree).
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="aa0dc5ba22bef20b4d0ad67d83cc789e1" name="aa0dc5ba22bef20b4d0ad67d83cc789e1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0dc5ba22bef20b4d0ad67d83cc789e1">&#9670;&#160;</a></span>_check_min_weight_leaf_split_level()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree._check_min_weight_leaf_split_level </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>TreeEstimator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1582</span><span class="keyword">def </span>_check_min_weight_leaf_split_level(TreeEstimator, X, y, sample_weight):</div>
<div class="line"><span class="lineno"> 1583</span>    est = TreeEstimator(random_state=0)</div>
<div class="line"><span class="lineno"> 1584</span>    est.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1585</span>    <span class="keyword">assert</span> est.tree_.max_depth == 1</div>
<div class="line"><span class="lineno"> 1586</span> </div>
<div class="line"><span class="lineno"> 1587</span>    est = TreeEstimator(random_state=0, min_weight_fraction_leaf=0.4)</div>
<div class="line"><span class="lineno"> 1588</span>    est.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1589</span>    <span class="keyword">assert</span> est.tree_.max_depth == 0</div>
<div class="line"><span class="lineno"> 1590</span> </div>
<div class="line"><span class="lineno"> 1591</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad80205402a9ceca4505101bb8591ef7d" name="ad80205402a9ceca4505101bb8591ef7d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad80205402a9ceca4505101bb8591ef7d">&#9670;&#160;</a></span>assert_is_subtree()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.assert_is_subtree </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>subtree</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1898</span><span class="keyword">def </span>assert_is_subtree(tree, subtree):</div>
<div class="line"><span class="lineno"> 1899</span>    <span class="keyword">assert</span> tree.node_count &gt;= subtree.node_count</div>
<div class="line"><span class="lineno"> 1900</span>    <span class="keyword">assert</span> tree.max_depth &gt;= subtree.max_depth</div>
<div class="line"><span class="lineno"> 1901</span> </div>
<div class="line"><span class="lineno"> 1902</span>    tree_c_left = tree.children_left</div>
<div class="line"><span class="lineno"> 1903</span>    tree_c_right = tree.children_right</div>
<div class="line"><span class="lineno"> 1904</span>    subtree_c_left = subtree.children_left</div>
<div class="line"><span class="lineno"> 1905</span>    subtree_c_right = subtree.children_right</div>
<div class="line"><span class="lineno"> 1906</span> </div>
<div class="line"><span class="lineno"> 1907</span>    stack = [(0, 0)]</div>
<div class="line"><span class="lineno"> 1908</span>    <span class="keywordflow">while</span> stack:</div>
<div class="line"><span class="lineno"> 1909</span>        tree_node_idx, subtree_node_idx = stack.pop()</div>
<div class="line"><span class="lineno"> 1910</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno"> 1911</span>            tree.value[tree_node_idx], subtree.value[subtree_node_idx]</div>
<div class="line"><span class="lineno"> 1912</span>        )</div>
<div class="line"><span class="lineno"> 1913</span>        assert_almost_equal(</div>
<div class="line"><span class="lineno"> 1914</span>            tree.impurity[tree_node_idx], subtree.impurity[subtree_node_idx]</div>
<div class="line"><span class="lineno"> 1915</span>        )</div>
<div class="line"><span class="lineno"> 1916</span>        assert_almost_equal(</div>
<div class="line"><span class="lineno"> 1917</span>            tree.n_node_samples[tree_node_idx], subtree.n_node_samples[subtree_node_idx]</div>
<div class="line"><span class="lineno"> 1918</span>        )</div>
<div class="line"><span class="lineno"> 1919</span>        assert_almost_equal(</div>
<div class="line"><span class="lineno"> 1920</span>            tree.weighted_n_node_samples[tree_node_idx],</div>
<div class="line"><span class="lineno"> 1921</span>            subtree.weighted_n_node_samples[subtree_node_idx],</div>
<div class="line"><span class="lineno"> 1922</span>        )</div>
<div class="line"><span class="lineno"> 1923</span> </div>
<div class="line"><span class="lineno"> 1924</span>        <span class="keywordflow">if</span> subtree_c_left[subtree_node_idx] == subtree_c_right[subtree_node_idx]:</div>
<div class="line"><span class="lineno"> 1925</span>            <span class="comment"># is a leaf</span></div>
<div class="line"><span class="lineno"> 1926</span>            assert_almost_equal(TREE_UNDEFINED, subtree.threshold[subtree_node_idx])</div>
<div class="line"><span class="lineno"> 1927</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1928</span>            <span class="comment"># not a leaf</span></div>
<div class="line"><span class="lineno"> 1929</span>            assert_almost_equal(</div>
<div class="line"><span class="lineno"> 1930</span>                tree.threshold[tree_node_idx], subtree.threshold[subtree_node_idx]</div>
<div class="line"><span class="lineno"> 1931</span>            )</div>
<div class="line"><span class="lineno"> 1932</span>            stack.append((tree_c_left[tree_node_idx], subtree_c_left[subtree_node_idx]))</div>
<div class="line"><span class="lineno"> 1933</span>            stack.append(</div>
<div class="line"><span class="lineno"> 1934</span>                (tree_c_right[tree_node_idx], subtree_c_right[subtree_node_idx])</div>
<div class="line"><span class="lineno"> 1935</span>            )</div>
<div class="line"><span class="lineno"> 1936</span> </div>
<div class="line"><span class="lineno"> 1937</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afd2877b5c71050a115681fd906dd7f05" name="afd2877b5c71050a115681fd906dd7f05"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd2877b5c71050a115681fd906dd7f05">&#9670;&#160;</a></span>assert_pruning_creates_subtree()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.assert_pruning_creates_subtree </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>estimator_cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pruning_path</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1883</span><span class="keyword">def </span>assert_pruning_creates_subtree(estimator_cls, X, y, pruning_path):</div>
<div class="line"><span class="lineno"> 1884</span>    <span class="comment"># generate trees with increasing alphas</span></div>
<div class="line"><span class="lineno"> 1885</span>    estimators = []</div>
<div class="line"><span class="lineno"> 1886</span>    <span class="keywordflow">for</span> ccp_alpha <span class="keywordflow">in</span> pruning_path:</div>
<div class="line"><span class="lineno"> 1887</span>        est = estimator_cls(max_leaf_nodes=20, ccp_alpha=ccp_alpha, random_state=0).fit(</div>
<div class="line"><span class="lineno"> 1888</span>            X, y</div>
<div class="line"><span class="lineno"> 1889</span>        )</div>
<div class="line"><span class="lineno"> 1890</span>        estimators.append(est)</div>
<div class="line"><span class="lineno"> 1891</span> </div>
<div class="line"><span class="lineno"> 1892</span>    <span class="comment"># A pruned tree must be a subtree of the previous tree (which had a</span></div>
<div class="line"><span class="lineno"> 1893</span>    <span class="comment"># smaller ccp_alpha)</span></div>
<div class="line"><span class="lineno"> 1894</span>    <span class="keywordflow">for</span> prev_est, next_est <span class="keywordflow">in</span> zip(estimators, estimators[1:]):</div>
<div class="line"><span class="lineno"> 1895</span>        assert_is_subtree(prev_est.tree_, next_est.tree_)</div>
<div class="line"><span class="lineno"> 1896</span> </div>
<div class="line"><span class="lineno"> 1897</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3ec98097203a9148b89eb1808f0c4023" name="a3ec98097203a9148b89eb1808f0c4023"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3ec98097203a9148b89eb1808f0c4023">&#9670;&#160;</a></span>assert_tree_equal()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.assert_tree_equal </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>d</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>message</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  200</span><span class="keyword">def </span>assert_tree_equal(d, s, message):</div>
<div class="line"><span class="lineno">  201</span>    <span class="keyword">assert</span> (</div>
<div class="line"><span class="lineno">  202</span>        s.node_count == d.node_count</div>
<div class="line"><span class="lineno">  203</span>    ), <span class="stringliteral">&quot;{0}: inequal number of node ({1} != {2})&quot;</span>.format(</div>
<div class="line"><span class="lineno">  204</span>        message, s.node_count, d.node_count</div>
<div class="line"><span class="lineno">  205</span>    )</div>
<div class="line"><span class="lineno">  206</span> </div>
<div class="line"><span class="lineno">  207</span>    assert_array_equal(</div>
<div class="line"><span class="lineno">  208</span>        d.children_right, s.children_right, message + <span class="stringliteral">&quot;: inequal children_right&quot;</span></div>
<div class="line"><span class="lineno">  209</span>    )</div>
<div class="line"><span class="lineno">  210</span>    assert_array_equal(</div>
<div class="line"><span class="lineno">  211</span>        d.children_left, s.children_left, message + <span class="stringliteral">&quot;: inequal children_left&quot;</span></div>
<div class="line"><span class="lineno">  212</span>    )</div>
<div class="line"><span class="lineno">  213</span> </div>
<div class="line"><span class="lineno">  214</span>    external = d.children_right == TREE_LEAF</div>
<div class="line"><span class="lineno">  215</span>    internal = np.logical_not(external)</div>
<div class="line"><span class="lineno">  216</span> </div>
<div class="line"><span class="lineno">  217</span>    assert_array_equal(</div>
<div class="line"><span class="lineno">  218</span>        d.feature[internal], s.feature[internal], message + <span class="stringliteral">&quot;: inequal features&quot;</span></div>
<div class="line"><span class="lineno">  219</span>    )</div>
<div class="line"><span class="lineno">  220</span>    assert_array_equal(</div>
<div class="line"><span class="lineno">  221</span>        d.threshold[internal], s.threshold[internal], message + <span class="stringliteral">&quot;: inequal threshold&quot;</span></div>
<div class="line"><span class="lineno">  222</span>    )</div>
<div class="line"><span class="lineno">  223</span>    assert_array_equal(</div>
<div class="line"><span class="lineno">  224</span>        d.n_node_samples.sum(),</div>
<div class="line"><span class="lineno">  225</span>        s.n_node_samples.sum(),</div>
<div class="line"><span class="lineno">  226</span>        message + <span class="stringliteral">&quot;: inequal sum(n_node_samples)&quot;</span>,</div>
<div class="line"><span class="lineno">  227</span>    )</div>
<div class="line"><span class="lineno">  228</span>    assert_array_equal(</div>
<div class="line"><span class="lineno">  229</span>        d.n_node_samples, s.n_node_samples, message + <span class="stringliteral">&quot;: inequal n_node_samples&quot;</span></div>
<div class="line"><span class="lineno">  230</span>    )</div>
<div class="line"><span class="lineno">  231</span> </div>
<div class="line"><span class="lineno">  232</span>    assert_almost_equal(d.impurity, s.impurity, err_msg=message + <span class="stringliteral">&quot;: inequal impurity&quot;</span>)</div>
<div class="line"><span class="lineno">  233</span> </div>
<div class="line"><span class="lineno">  234</span>    assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  235</span>        d.value[external], s.value[external], err_msg=message + <span class="stringliteral">&quot;: inequal value&quot;</span></div>
<div class="line"><span class="lineno">  236</span>    )</div>
<div class="line"><span class="lineno">  237</span> </div>
<div class="line"><span class="lineno">  238</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa6f979ab8e52c3a31540f3716cfdbc56" name="aa6f979ab8e52c3a31540f3716cfdbc56"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa6f979ab8e52c3a31540f3716cfdbc56">&#9670;&#160;</a></span>check_apply_path_readonly()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_apply_path_readonly </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1938</span><span class="keyword">def </span>check_apply_path_readonly(name):</div>
<div class="line"><span class="lineno"> 1939</span>    X_readonly = create_memmap_backed_data(X_small.astype(tree._tree.DTYPE, copy=<span class="keyword">False</span>))</div>
<div class="line"><span class="lineno"> 1940</span>    y_readonly = create_memmap_backed_data(np.array(y_small, dtype=tree._tree.DTYPE))</div>
<div class="line"><span class="lineno"> 1941</span>    est = ALL_TREES[name]()</div>
<div class="line"><span class="lineno"> 1942</span>    est.fit(X_readonly, y_readonly)</div>
<div class="line"><span class="lineno"> 1943</span>    assert_array_equal(est.predict(X_readonly), est.predict(X_small))</div>
<div class="line"><span class="lineno"> 1944</span>    assert_array_equal(</div>
<div class="line"><span class="lineno"> 1945</span>        est.decision_path(X_readonly).todense(), est.decision_path(X_small).todense()</div>
<div class="line"><span class="lineno"> 1946</span>    )</div>
<div class="line"><span class="lineno"> 1947</span> </div>
<div class="line"><span class="lineno"> 1948</span> </div>
<div class="line"><span class="lineno"> 1949</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, ALL_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a9b4a16420a426e18813db7437df900d7" name="a9b4a16420a426e18813db7437df900d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9b4a16420a426e18813db7437df900d7">&#9670;&#160;</a></span>check_class_weight_errors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_class_weight_errors </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1204</span><span class="keyword">def </span>check_class_weight_errors(name):</div>
<div class="line"><span class="lineno"> 1205</span>    <span class="comment"># Test if class_weight raises errors and warnings when expected.</span></div>
<div class="line"><span class="lineno"> 1206</span>    TreeClassifier = CLF_TREES[name]</div>
<div class="line"><span class="lineno"> 1207</span>    _y = np.vstack((y, np.array(y) * 2)).T</div>
<div class="line"><span class="lineno"> 1208</span> </div>
<div class="line"><span class="lineno"> 1209</span>    <span class="comment"># Incorrect length list for multi-output</span></div>
<div class="line"><span class="lineno"> 1210</span>    clf = TreeClassifier(class_weight=[{-1: 0.5, 1: 1.0}], random_state=0)</div>
<div class="line"><span class="lineno"> 1211</span>    err_msg = <span class="stringliteral">&quot;number of elements in class_weight should match number of outputs.&quot;</span></div>
<div class="line"><span class="lineno"> 1212</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=err_msg):</div>
<div class="line"><span class="lineno"> 1213</span>        clf.fit(X, _y)</div>
<div class="line"><span class="lineno"> 1214</span> </div>
<div class="line"><span class="lineno"> 1215</span> </div>
<div class="line"><span class="lineno"> 1216</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, CLF_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a45f86c6bcfb976c4aa195d3ca605de59" name="a45f86c6bcfb976c4aa195d3ca605de59"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45f86c6bcfb976c4aa195d3ca605de59">&#9670;&#160;</a></span>check_class_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_class_weights </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check class_weights resemble sample_weights behavior.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1152</span><span class="keyword">def </span>check_class_weights(name):</div>
<div class="line"><span class="lineno"> 1153</span>    <span class="stringliteral">&quot;&quot;&quot;Check class_weights resemble sample_weights behavior.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1154</span>    TreeClassifier = CLF_TREES[name]</div>
<div class="line"><span class="lineno"> 1155</span> </div>
<div class="line"><span class="lineno"> 1156</span>    <span class="comment"># Iris is balanced, so no effect expected for using &#39;balanced&#39; weights</span></div>
<div class="line"><span class="lineno"> 1157</span>    clf1 = TreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno"> 1158</span>    clf1.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno"> 1159</span>    clf2 = TreeClassifier(class_weight=<span class="stringliteral">&quot;balanced&quot;</span>, random_state=0)</div>
<div class="line"><span class="lineno"> 1160</span>    clf2.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno"> 1161</span>    assert_almost_equal(clf1.feature_importances_, clf2.feature_importances_)</div>
<div class="line"><span class="lineno"> 1162</span> </div>
<div class="line"><span class="lineno"> 1163</span>    <span class="comment"># Make a multi-output problem with three copies of Iris</span></div>
<div class="line"><span class="lineno"> 1164</span>    iris_multi = np.vstack((iris.target, iris.target, iris.target)).T</div>
<div class="line"><span class="lineno"> 1165</span>    <span class="comment"># Create user-defined weights that should balance over the outputs</span></div>
<div class="line"><span class="lineno"> 1166</span>    clf3 = TreeClassifier(</div>
<div class="line"><span class="lineno"> 1167</span>        class_weight=[</div>
<div class="line"><span class="lineno"> 1168</span>            {0: 2.0, 1: 2.0, 2: 1.0},</div>
<div class="line"><span class="lineno"> 1169</span>            {0: 2.0, 1: 1.0, 2: 2.0},</div>
<div class="line"><span class="lineno"> 1170</span>            {0: 1.0, 1: 2.0, 2: 2.0},</div>
<div class="line"><span class="lineno"> 1171</span>        ],</div>
<div class="line"><span class="lineno"> 1172</span>        random_state=0,</div>
<div class="line"><span class="lineno"> 1173</span>    )</div>
<div class="line"><span class="lineno"> 1174</span>    clf3.fit(iris.data, iris_multi)</div>
<div class="line"><span class="lineno"> 1175</span>    assert_almost_equal(clf2.feature_importances_, clf3.feature_importances_)</div>
<div class="line"><span class="lineno"> 1176</span>    <span class="comment"># Check against multi-output &quot;auto&quot; which should also have no effect</span></div>
<div class="line"><span class="lineno"> 1177</span>    clf4 = TreeClassifier(class_weight=<span class="stringliteral">&quot;balanced&quot;</span>, random_state=0)</div>
<div class="line"><span class="lineno"> 1178</span>    clf4.fit(iris.data, iris_multi)</div>
<div class="line"><span class="lineno"> 1179</span>    assert_almost_equal(clf3.feature_importances_, clf4.feature_importances_)</div>
<div class="line"><span class="lineno"> 1180</span> </div>
<div class="line"><span class="lineno"> 1181</span>    <span class="comment"># Inflate importance of class 1, check against user-defined weights</span></div>
<div class="line"><span class="lineno"> 1182</span>    sample_weight = np.ones(iris.target.shape)</div>
<div class="line"><span class="lineno"> 1183</span>    sample_weight[iris.target == 1] *= 100</div>
<div class="line"><span class="lineno"> 1184</span>    class_weight = {0: 1.0, 1: 100.0, 2: 1.0}</div>
<div class="line"><span class="lineno"> 1185</span>    clf1 = TreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno"> 1186</span>    clf1.fit(iris.data, iris.target, sample_weight)</div>
<div class="line"><span class="lineno"> 1187</span>    clf2 = TreeClassifier(class_weight=class_weight, random_state=0)</div>
<div class="line"><span class="lineno"> 1188</span>    clf2.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno"> 1189</span>    assert_almost_equal(clf1.feature_importances_, clf2.feature_importances_)</div>
<div class="line"><span class="lineno"> 1190</span> </div>
<div class="line"><span class="lineno"> 1191</span>    <span class="comment"># Check that sample_weight and class_weight are multiplicative</span></div>
<div class="line"><span class="lineno"> 1192</span>    clf1 = TreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno"> 1193</span>    clf1.fit(iris.data, iris.target, sample_weight**2)</div>
<div class="line"><span class="lineno"> 1194</span>    clf2 = TreeClassifier(class_weight=class_weight, random_state=0)</div>
<div class="line"><span class="lineno"> 1195</span>    clf2.fit(iris.data, iris.target, sample_weight)</div>
<div class="line"><span class="lineno"> 1196</span>    assert_almost_equal(clf1.feature_importances_, clf2.feature_importances_)</div>
<div class="line"><span class="lineno"> 1197</span> </div>
<div class="line"><span class="lineno"> 1198</span> </div>
<div class="line"><span class="lineno"> 1199</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, CLF_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab00099a23acfdbcc2883f92fbd6ba3f3" name="ab00099a23acfdbcc2883f92fbd6ba3f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab00099a23acfdbcc2883f92fbd6ba3f3">&#9670;&#160;</a></span>check_decision_path()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_decision_path </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1642</span><span class="keyword">def </span>check_decision_path(name):</div>
<div class="line"><span class="lineno"> 1643</span>    X = iris.data</div>
<div class="line"><span class="lineno"> 1644</span>    y = iris.target</div>
<div class="line"><span class="lineno"> 1645</span>    n_samples = X.shape[0]</div>
<div class="line"><span class="lineno"> 1646</span> </div>
<div class="line"><span class="lineno"> 1647</span>    TreeEstimator = ALL_TREES[name]</div>
<div class="line"><span class="lineno"> 1648</span>    est = TreeEstimator(random_state=0, max_depth=2)</div>
<div class="line"><span class="lineno"> 1649</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno"> 1650</span> </div>
<div class="line"><span class="lineno"> 1651</span>    node_indicator_csr = est.decision_path(X)</div>
<div class="line"><span class="lineno"> 1652</span>    node_indicator = node_indicator_csr.toarray()</div>
<div class="line"><span class="lineno"> 1653</span>    <span class="keyword">assert</span> node_indicator.shape == (n_samples, est.tree_.node_count)</div>
<div class="line"><span class="lineno"> 1654</span> </div>
<div class="line"><span class="lineno"> 1655</span>    <span class="comment"># Assert that leaves index are correct</span></div>
<div class="line"><span class="lineno"> 1656</span>    leaves = est.apply(X)</div>
<div class="line"><span class="lineno"> 1657</span>    leave_indicator = [node_indicator[i, j] <span class="keywordflow">for</span> i, j <span class="keywordflow">in</span> enumerate(leaves)]</div>
<div class="line"><span class="lineno"> 1658</span>    assert_array_almost_equal(leave_indicator, np.ones(shape=n_samples))</div>
<div class="line"><span class="lineno"> 1659</span> </div>
<div class="line"><span class="lineno"> 1660</span>    <span class="comment"># Ensure only one leave node per sample</span></div>
<div class="line"><span class="lineno"> 1661</span>    all_leaves = est.tree_.children_left == TREE_LEAF</div>
<div class="line"><span class="lineno"> 1662</span>    assert_array_almost_equal(</div>
<div class="line"><span class="lineno"> 1663</span>        np.dot(node_indicator, all_leaves), np.ones(shape=n_samples)</div>
<div class="line"><span class="lineno"> 1664</span>    )</div>
<div class="line"><span class="lineno"> 1665</span> </div>
<div class="line"><span class="lineno"> 1666</span>    <span class="comment"># Ensure max depth is consistent with sum of indicator</span></div>
<div class="line"><span class="lineno"> 1667</span>    max_depth = node_indicator.sum(axis=1).max()</div>
<div class="line"><span class="lineno"> 1668</span>    <span class="keyword">assert</span> est.tree_.max_depth &lt;= max_depth</div>
<div class="line"><span class="lineno"> 1669</span> </div>
<div class="line"><span class="lineno"> 1670</span> </div>
<div class="line"><span class="lineno"> 1671</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, ALL_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a8e800f5993e27ad6df28f80a3dcb86c3" name="a8e800f5993e27ad6df28f80a3dcb86c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e800f5993e27ad6df28f80a3dcb86c3">&#9670;&#160;</a></span>check_explicit_sparse_zeros()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_explicit_sparse_zeros </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_depth</em> = <code>3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_features</em> = <code>10</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1484</span><span class="keyword">def </span>check_explicit_sparse_zeros(tree, max_depth=3, n_features=10):</div>
<div class="line"><span class="lineno"> 1485</span>    TreeEstimator = ALL_TREES[tree]</div>
<div class="line"><span class="lineno"> 1486</span> </div>
<div class="line"><span class="lineno"> 1487</span>    <span class="comment"># n_samples set n_feature to ease construction of a simultaneous</span></div>
<div class="line"><span class="lineno"> 1488</span>    <span class="comment"># construction of a csr and csc matrix</span></div>
<div class="line"><span class="lineno"> 1489</span>    n_samples = n_features</div>
<div class="line"><span class="lineno"> 1490</span>    samples = np.arange(n_samples)</div>
<div class="line"><span class="lineno"> 1491</span> </div>
<div class="line"><span class="lineno"> 1492</span>    <span class="comment"># Generate X, y</span></div>
<div class="line"><span class="lineno"> 1493</span>    random_state = check_random_state(0)</div>
<div class="line"><span class="lineno"> 1494</span>    indices = []</div>
<div class="line"><span class="lineno"> 1495</span>    data = []</div>
<div class="line"><span class="lineno"> 1496</span>    offset = 0</div>
<div class="line"><span class="lineno"> 1497</span>    indptr = [offset]</div>
<div class="line"><span class="lineno"> 1498</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(n_features):</div>
<div class="line"><span class="lineno"> 1499</span>        n_nonzero_i = random_state.binomial(n_samples, 0.5)</div>
<div class="line"><span class="lineno"> 1500</span>        indices_i = random_state.permutation(samples)[:n_nonzero_i]</div>
<div class="line"><span class="lineno"> 1501</span>        indices.append(indices_i)</div>
<div class="line"><span class="lineno"> 1502</span>        data_i = random_state.binomial(3, 0.5, size=(n_nonzero_i,)) - 1</div>
<div class="line"><span class="lineno"> 1503</span>        data.append(data_i)</div>
<div class="line"><span class="lineno"> 1504</span>        offset += n_nonzero_i</div>
<div class="line"><span class="lineno"> 1505</span>        indptr.append(offset)</div>
<div class="line"><span class="lineno"> 1506</span> </div>
<div class="line"><span class="lineno"> 1507</span>    indices = np.concatenate(indices)</div>
<div class="line"><span class="lineno"> 1508</span>    data = np.array(np.concatenate(data), dtype=np.float32)</div>
<div class="line"><span class="lineno"> 1509</span>    X_sparse = csc_matrix((data, indices, indptr), shape=(n_samples, n_features))</div>
<div class="line"><span class="lineno"> 1510</span>    X = X_sparse.toarray()</div>
<div class="line"><span class="lineno"> 1511</span>    X_sparse_test = csr_matrix((data, indices, indptr), shape=(n_samples, n_features))</div>
<div class="line"><span class="lineno"> 1512</span>    X_test = X_sparse_test.toarray()</div>
<div class="line"><span class="lineno"> 1513</span>    y = random_state.randint(0, 3, size=(n_samples,))</div>
<div class="line"><span class="lineno"> 1514</span> </div>
<div class="line"><span class="lineno"> 1515</span>    <span class="comment"># Ensure that X_sparse_test owns its data, indices and indptr array</span></div>
<div class="line"><span class="lineno"> 1516</span>    X_sparse_test = X_sparse_test.copy()</div>
<div class="line"><span class="lineno"> 1517</span> </div>
<div class="line"><span class="lineno"> 1518</span>    <span class="comment"># Ensure that we have explicit zeros</span></div>
<div class="line"><span class="lineno"> 1519</span>    <span class="keyword">assert</span> (X_sparse.data == 0.0).sum() &gt; 0</div>
<div class="line"><span class="lineno"> 1520</span>    <span class="keyword">assert</span> (X_sparse_test.data == 0.0).sum() &gt; 0</div>
<div class="line"><span class="lineno"> 1521</span> </div>
<div class="line"><span class="lineno"> 1522</span>    <span class="comment"># Perform the comparison</span></div>
<div class="line"><span class="lineno"> 1523</span>    d = TreeEstimator(random_state=0, max_depth=max_depth).fit(X, y)</div>
<div class="line"><span class="lineno"> 1524</span>    s = TreeEstimator(random_state=0, max_depth=max_depth).fit(X_sparse, y)</div>
<div class="line"><span class="lineno"> 1525</span> </div>
<div class="line"><span class="lineno"> 1526</span>    assert_tree_equal(</div>
<div class="line"><span class="lineno"> 1527</span>        d.tree_,</div>
<div class="line"><span class="lineno"> 1528</span>        s.tree_,</div>
<div class="line"><span class="lineno"> 1529</span>        <span class="stringliteral">&quot;{0} with dense and sparse format gave different trees&quot;</span>.format(tree),</div>
<div class="line"><span class="lineno"> 1530</span>    )</div>
<div class="line"><span class="lineno"> 1531</span> </div>
<div class="line"><span class="lineno"> 1532</span>    Xs = (X_test, X_sparse_test)</div>
<div class="line"><span class="lineno"> 1533</span>    <span class="keywordflow">for</span> X1, X2 <span class="keywordflow">in</span> product(Xs, Xs):</div>
<div class="line"><span class="lineno"> 1534</span>        assert_array_almost_equal(s.tree_.apply(X1), d.tree_.apply(X2))</div>
<div class="line"><span class="lineno"> 1535</span>        assert_array_almost_equal(s.apply(X1), d.apply(X2))</div>
<div class="line"><span class="lineno"> 1536</span>        assert_array_almost_equal(s.apply(X1), s.tree_.apply(X1))</div>
<div class="line"><span class="lineno"> 1537</span> </div>
<div class="line"><span class="lineno"> 1538</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno"> 1539</span>            s.tree_.decision_path(X1).toarray(), d.tree_.decision_path(X2).toarray()</div>
<div class="line"><span class="lineno"> 1540</span>        )</div>
<div class="line"><span class="lineno"> 1541</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno"> 1542</span>            s.decision_path(X1).toarray(), d.decision_path(X2).toarray()</div>
<div class="line"><span class="lineno"> 1543</span>        )</div>
<div class="line"><span class="lineno"> 1544</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno"> 1545</span>            s.decision_path(X1).toarray(), s.tree_.decision_path(X1).toarray()</div>
<div class="line"><span class="lineno"> 1546</span>        )</div>
<div class="line"><span class="lineno"> 1547</span> </div>
<div class="line"><span class="lineno"> 1548</span>        assert_array_almost_equal(s.predict(X1), d.predict(X2))</div>
<div class="line"><span class="lineno"> 1549</span> </div>
<div class="line"><span class="lineno"> 1550</span>        <span class="keywordflow">if</span> tree <span class="keywordflow">in</span> CLF_TREES:</div>
<div class="line"><span class="lineno"> 1551</span>            assert_array_almost_equal(s.predict_proba(X1), d.predict_proba(X2))</div>
<div class="line"><span class="lineno"> 1552</span> </div>
<div class="line"><span class="lineno"> 1553</span> </div>
<div class="line"><span class="lineno"> 1554</span><span class="preprocessor">@pytest.mark.parametrize(&quot;tree_type&quot;, SPARSE_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a4f8d6a2df67f8251595c8695bb1b4f1f" name="a4f8d6a2df67f8251595c8695bb1b4f1f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f8d6a2df67f8251595c8695bb1b4f1f">&#9670;&#160;</a></span>check_min_weight_fraction_leaf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_min_weight_fraction_leaf </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>datasets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sparse</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test if leaves contain at least min_weight_fraction_leaf of the
training set</pre> <div class="fragment"><div class="line"><span class="lineno">  683</span><span class="keyword">def </span>check_min_weight_fraction_leaf(name, datasets, sparse=False):</div>
<div class="line"><span class="lineno">  684</span>    <span class="stringliteral">&quot;&quot;&quot;Test if leaves contain at least min_weight_fraction_leaf of the</span></div>
<div class="line"><span class="lineno">  685</span><span class="stringliteral">    training set&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  686</span>    <span class="keywordflow">if</span> sparse:</div>
<div class="line"><span class="lineno">  687</span>        X = DATASETS[datasets][<span class="stringliteral">&quot;X_sparse&quot;</span>].astype(np.float32)</div>
<div class="line"><span class="lineno">  688</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  689</span>        X = DATASETS[datasets][<span class="stringliteral">&quot;X&quot;</span>].astype(np.float32)</div>
<div class="line"><span class="lineno">  690</span>    y = DATASETS[datasets][<span class="stringliteral">&quot;y&quot;</span>]</div>
<div class="line"><span class="lineno">  691</span> </div>
<div class="line"><span class="lineno">  692</span>    weights = rng.rand(X.shape[0])</div>
<div class="line"><span class="lineno">  693</span>    total_weight = np.sum(weights)</div>
<div class="line"><span class="lineno">  694</span> </div>
<div class="line"><span class="lineno">  695</span>    TreeEstimator = ALL_TREES[name]</div>
<div class="line"><span class="lineno">  696</span> </div>
<div class="line"><span class="lineno">  697</span>    <span class="comment"># test both DepthFirstTreeBuilder and BestFirstTreeBuilder</span></div>
<div class="line"><span class="lineno">  698</span>    <span class="comment"># by setting max_leaf_nodes</span></div>
<div class="line"><span class="lineno">  699</span>    <span class="keywordflow">for</span> max_leaf_nodes, frac <span class="keywordflow">in</span> product((<span class="keywordtype">None</span>, 1000), np.linspace(0, 0.5, 6)):</div>
<div class="line"><span class="lineno">  700</span>        est = TreeEstimator(</div>
<div class="line"><span class="lineno">  701</span>            min_weight_fraction_leaf=frac, max_leaf_nodes=max_leaf_nodes, random_state=0</div>
<div class="line"><span class="lineno">  702</span>        )</div>
<div class="line"><span class="lineno">  703</span>        est.fit(X, y, sample_weight=weights)</div>
<div class="line"><span class="lineno">  704</span> </div>
<div class="line"><span class="lineno">  705</span>        <span class="keywordflow">if</span> sparse:</div>
<div class="line"><span class="lineno">  706</span>            out = est.tree_.apply(X.tocsr())</div>
<div class="line"><span class="lineno">  707</span> </div>
<div class="line"><span class="lineno">  708</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  709</span>            out = est.tree_.apply(X)</div>
<div class="line"><span class="lineno">  710</span> </div>
<div class="line"><span class="lineno">  711</span>        node_weights = np.bincount(out, weights=weights)</div>
<div class="line"><span class="lineno">  712</span>        <span class="comment"># drop inner nodes</span></div>
<div class="line"><span class="lineno">  713</span>        leaf_weights = node_weights[node_weights != 0]</div>
<div class="line"><span class="lineno">  714</span>        <span class="keyword">assert</span> (</div>
<div class="line"><span class="lineno">  715</span>            np.min(leaf_weights) &gt;= total_weight * est.min_weight_fraction_leaf</div>
<div class="line"><span class="lineno">  716</span>        ), <span class="stringliteral">&quot;Failed with {0} min_weight_fraction_leaf={1}&quot;</span>.format(</div>
<div class="line"><span class="lineno">  717</span>            name, est.min_weight_fraction_leaf</div>
<div class="line"><span class="lineno">  718</span>        )</div>
<div class="line"><span class="lineno">  719</span> </div>
<div class="line"><span class="lineno">  720</span>    <span class="comment"># test case with no weights passed in</span></div>
<div class="line"><span class="lineno">  721</span>    total_weight = X.shape[0]</div>
<div class="line"><span class="lineno">  722</span> </div>
<div class="line"><span class="lineno">  723</span>    <span class="keywordflow">for</span> max_leaf_nodes, frac <span class="keywordflow">in</span> product((<span class="keywordtype">None</span>, 1000), np.linspace(0, 0.5, 6)):</div>
<div class="line"><span class="lineno">  724</span>        est = TreeEstimator(</div>
<div class="line"><span class="lineno">  725</span>            min_weight_fraction_leaf=frac, max_leaf_nodes=max_leaf_nodes, random_state=0</div>
<div class="line"><span class="lineno">  726</span>        )</div>
<div class="line"><span class="lineno">  727</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno">  728</span> </div>
<div class="line"><span class="lineno">  729</span>        <span class="keywordflow">if</span> sparse:</div>
<div class="line"><span class="lineno">  730</span>            out = est.tree_.apply(X.tocsr())</div>
<div class="line"><span class="lineno">  731</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  732</span>            out = est.tree_.apply(X)</div>
<div class="line"><span class="lineno">  733</span> </div>
<div class="line"><span class="lineno">  734</span>        node_weights = np.bincount(out)</div>
<div class="line"><span class="lineno">  735</span>        <span class="comment"># drop inner nodes</span></div>
<div class="line"><span class="lineno">  736</span>        leaf_weights = node_weights[node_weights != 0]</div>
<div class="line"><span class="lineno">  737</span>        <span class="keyword">assert</span> (</div>
<div class="line"><span class="lineno">  738</span>            np.min(leaf_weights) &gt;= total_weight * est.min_weight_fraction_leaf</div>
<div class="line"><span class="lineno">  739</span>        ), <span class="stringliteral">&quot;Failed with {0} min_weight_fraction_leaf={1}&quot;</span>.format(</div>
<div class="line"><span class="lineno">  740</span>            name, est.min_weight_fraction_leaf</div>
<div class="line"><span class="lineno">  741</span>        )</div>
<div class="line"><span class="lineno">  742</span> </div>
<div class="line"><span class="lineno">  743</span> </div>
<div class="line"><span class="lineno">  744</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, ALL_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="af5d6d483fcb17fa89efa1afe49f945d6" name="af5d6d483fcb17fa89efa1afe49f945d6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5d6d483fcb17fa89efa1afe49f945d6">&#9670;&#160;</a></span>check_min_weight_fraction_leaf_with_min_samples_leaf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_min_weight_fraction_leaf_with_min_samples_leaf </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>datasets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sparse</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test the interaction between min_weight_fraction_leaf and
min_samples_leaf when sample_weights is not provided in fit.</pre> <div class="fragment"><div class="line"><span class="lineno">  754</span><span class="keyword">def </span>check_min_weight_fraction_leaf_with_min_samples_leaf(name, datasets, sparse=False):</div>
<div class="line"><span class="lineno">  755</span>    <span class="stringliteral">&quot;&quot;&quot;Test the interaction between min_weight_fraction_leaf and</span></div>
<div class="line"><span class="lineno">  756</span><span class="stringliteral">    min_samples_leaf when sample_weights is not provided in fit.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  757</span>    <span class="keywordflow">if</span> sparse:</div>
<div class="line"><span class="lineno">  758</span>        X = DATASETS[datasets][<span class="stringliteral">&quot;X_sparse&quot;</span>].astype(np.float32)</div>
<div class="line"><span class="lineno">  759</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  760</span>        X = DATASETS[datasets][<span class="stringliteral">&quot;X&quot;</span>].astype(np.float32)</div>
<div class="line"><span class="lineno">  761</span>    y = DATASETS[datasets][<span class="stringliteral">&quot;y&quot;</span>]</div>
<div class="line"><span class="lineno">  762</span> </div>
<div class="line"><span class="lineno">  763</span>    total_weight = X.shape[0]</div>
<div class="line"><span class="lineno">  764</span>    TreeEstimator = ALL_TREES[name]</div>
<div class="line"><span class="lineno">  765</span>    <span class="keywordflow">for</span> max_leaf_nodes, frac <span class="keywordflow">in</span> product((<span class="keywordtype">None</span>, 1000), np.linspace(0, 0.5, 3)):</div>
<div class="line"><span class="lineno">  766</span>        <span class="comment"># test integer min_samples_leaf</span></div>
<div class="line"><span class="lineno">  767</span>        est = TreeEstimator(</div>
<div class="line"><span class="lineno">  768</span>            min_weight_fraction_leaf=frac,</div>
<div class="line"><span class="lineno">  769</span>            max_leaf_nodes=max_leaf_nodes,</div>
<div class="line"><span class="lineno">  770</span>            min_samples_leaf=5,</div>
<div class="line"><span class="lineno">  771</span>            random_state=0,</div>
<div class="line"><span class="lineno">  772</span>        )</div>
<div class="line"><span class="lineno">  773</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno">  774</span> </div>
<div class="line"><span class="lineno">  775</span>        <span class="keywordflow">if</span> sparse:</div>
<div class="line"><span class="lineno">  776</span>            out = est.tree_.apply(X.tocsr())</div>
<div class="line"><span class="lineno">  777</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  778</span>            out = est.tree_.apply(X)</div>
<div class="line"><span class="lineno">  779</span> </div>
<div class="line"><span class="lineno">  780</span>        node_weights = np.bincount(out)</div>
<div class="line"><span class="lineno">  781</span>        <span class="comment"># drop inner nodes</span></div>
<div class="line"><span class="lineno">  782</span>        leaf_weights = node_weights[node_weights != 0]</div>
<div class="line"><span class="lineno">  783</span>        <span class="keyword">assert</span> np.min(leaf_weights) &gt;= max(</div>
<div class="line"><span class="lineno">  784</span>            (total_weight * est.min_weight_fraction_leaf), 5</div>
<div class="line"><span class="lineno">  785</span>        ), <span class="stringliteral">&quot;Failed with {0} min_weight_fraction_leaf={1}, min_samples_leaf={2}&quot;</span>.format(</div>
<div class="line"><span class="lineno">  786</span>            name, est.min_weight_fraction_leaf, est.min_samples_leaf</div>
<div class="line"><span class="lineno">  787</span>        )</div>
<div class="line"><span class="lineno">  788</span>    <span class="keywordflow">for</span> max_leaf_nodes, frac <span class="keywordflow">in</span> product((<span class="keywordtype">None</span>, 1000), np.linspace(0, 0.5, 3)):</div>
<div class="line"><span class="lineno">  789</span>        <span class="comment"># test float min_samples_leaf</span></div>
<div class="line"><span class="lineno">  790</span>        est = TreeEstimator(</div>
<div class="line"><span class="lineno">  791</span>            min_weight_fraction_leaf=frac,</div>
<div class="line"><span class="lineno">  792</span>            max_leaf_nodes=max_leaf_nodes,</div>
<div class="line"><span class="lineno">  793</span>            min_samples_leaf=0.1,</div>
<div class="line"><span class="lineno">  794</span>            random_state=0,</div>
<div class="line"><span class="lineno">  795</span>        )</div>
<div class="line"><span class="lineno">  796</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno">  797</span> </div>
<div class="line"><span class="lineno">  798</span>        <span class="keywordflow">if</span> sparse:</div>
<div class="line"><span class="lineno">  799</span>            out = est.tree_.apply(X.tocsr())</div>
<div class="line"><span class="lineno">  800</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  801</span>            out = est.tree_.apply(X)</div>
<div class="line"><span class="lineno">  802</span> </div>
<div class="line"><span class="lineno">  803</span>        node_weights = np.bincount(out)</div>
<div class="line"><span class="lineno">  804</span>        <span class="comment"># drop inner nodes</span></div>
<div class="line"><span class="lineno">  805</span>        leaf_weights = node_weights[node_weights != 0]</div>
<div class="line"><span class="lineno">  806</span>        <span class="keyword">assert</span> np.min(leaf_weights) &gt;= max(</div>
<div class="line"><span class="lineno">  807</span>            (total_weight * est.min_weight_fraction_leaf),</div>
<div class="line"><span class="lineno">  808</span>            (total_weight * est.min_samples_leaf),</div>
<div class="line"><span class="lineno">  809</span>        ), <span class="stringliteral">&quot;Failed with {0} min_weight_fraction_leaf={1}, min_samples_leaf={2}&quot;</span>.format(</div>
<div class="line"><span class="lineno">  810</span>            name, est.min_weight_fraction_leaf, est.min_samples_leaf</div>
<div class="line"><span class="lineno">  811</span>        )</div>
<div class="line"><span class="lineno">  812</span> </div>
<div class="line"><span class="lineno">  813</span> </div>
<div class="line"><span class="lineno">  814</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, ALL_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a3edf4665a10e53111206e6922dcf034a" name="a3edf4665a10e53111206e6922dcf034a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3edf4665a10e53111206e6922dcf034a">&#9670;&#160;</a></span>check_min_weight_leaf_split_level()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_min_weight_leaf_split_level </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1592</span><span class="keyword">def </span>check_min_weight_leaf_split_level(name):</div>
<div class="line"><span class="lineno"> 1593</span>    TreeEstimator = ALL_TREES[name]</div>
<div class="line"><span class="lineno"> 1594</span> </div>
<div class="line"><span class="lineno"> 1595</span>    X = np.array([[0], [0], [0], [0], [1]])</div>
<div class="line"><span class="lineno"> 1596</span>    y = [0, 0, 0, 0, 1]</div>
<div class="line"><span class="lineno"> 1597</span>    sample_weight = [0.2, 0.2, 0.2, 0.2, 0.2]</div>
<div class="line"><span class="lineno"> 1598</span>    _check_min_weight_leaf_split_level(TreeEstimator, X, y, sample_weight)</div>
<div class="line"><span class="lineno"> 1599</span> </div>
<div class="line"><span class="lineno"> 1600</span>    _check_min_weight_leaf_split_level(TreeEstimator, csc_matrix(X), y, sample_weight)</div>
<div class="line"><span class="lineno"> 1601</span> </div>
<div class="line"><span class="lineno"> 1602</span> </div>
<div class="line"><span class="lineno"> 1603</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, ALL_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab05089aa1aaa32596f6ffa35cad0b808" name="ab05089aa1aaa32596f6ffa35cad0b808"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab05089aa1aaa32596f6ffa35cad0b808">&#9670;&#160;</a></span>check_no_sparse_y_support()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_no_sparse_y_support </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1676</span><span class="keyword">def </span>check_no_sparse_y_support(name):</div>
<div class="line"><span class="lineno"> 1677</span>    X, y = X_multilabel, csr_matrix(y_multilabel)</div>
<div class="line"><span class="lineno"> 1678</span>    TreeEstimator = ALL_TREES[name]</div>
<div class="line"><span class="lineno"> 1679</span>    <span class="keyword">with</span> pytest.raises(TypeError):</div>
<div class="line"><span class="lineno"> 1680</span>        TreeEstimator(random_state=0).fit(X, y)</div>
<div class="line"><span class="lineno"> 1681</span> </div>
<div class="line"><span class="lineno"> 1682</span> </div>
<div class="line"><span class="lineno"> 1683</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, ALL_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a75d58df9831fc228d8cf01f856d3c592" name="a75d58df9831fc228d8cf01f856d3c592"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a75d58df9831fc228d8cf01f856d3c592">&#9670;&#160;</a></span>check_public_apply()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_public_apply </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1608</span><span class="keyword">def </span>check_public_apply(name):</div>
<div class="line"><span class="lineno"> 1609</span>    X_small32 = X_small.astype(tree._tree.DTYPE, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1610</span> </div>
<div class="line"><span class="lineno"> 1611</span>    est = ALL_TREES[name]()</div>
<div class="line"><span class="lineno"> 1612</span>    est.fit(X_small, y_small)</div>
<div class="line"><span class="lineno"> 1613</span>    assert_array_equal(est.apply(X_small), est.tree_.apply(X_small32))</div>
<div class="line"><span class="lineno"> 1614</span> </div>
<div class="line"><span class="lineno"> 1615</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad1ddde6453d4dac2333f6e962cdc54e5" name="ad1ddde6453d4dac2333f6e962cdc54e5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad1ddde6453d4dac2333f6e962cdc54e5">&#9670;&#160;</a></span>check_public_apply_sparse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_public_apply_sparse </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1616</span><span class="keyword">def </span>check_public_apply_sparse(name):</div>
<div class="line"><span class="lineno"> 1617</span>    X_small32 = csr_matrix(X_small.astype(tree._tree.DTYPE, copy=<span class="keyword">False</span>))</div>
<div class="line"><span class="lineno"> 1618</span> </div>
<div class="line"><span class="lineno"> 1619</span>    est = ALL_TREES[name]()</div>
<div class="line"><span class="lineno"> 1620</span>    est.fit(X_small, y_small)</div>
<div class="line"><span class="lineno"> 1621</span>    assert_array_equal(est.apply(X_small), est.tree_.apply(X_small32))</div>
<div class="line"><span class="lineno"> 1622</span> </div>
<div class="line"><span class="lineno"> 1623</span> </div>
<div class="line"><span class="lineno"> 1624</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, ALL_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ae5425310283a40c55be37512699bce94" name="ae5425310283a40c55be37512699bce94"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5425310283a40c55be37512699bce94">&#9670;&#160;</a></span>check_raise_error_on_1d_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_raise_error_on_1d_input </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1560</span><span class="keyword">def </span>check_raise_error_on_1d_input(name):</div>
<div class="line"><span class="lineno"> 1561</span>    TreeEstimator = ALL_TREES[name]</div>
<div class="line"><span class="lineno"> 1562</span> </div>
<div class="line"><span class="lineno"> 1563</span>    X = iris.data[:, 0].ravel()</div>
<div class="line"><span class="lineno"> 1564</span>    X_2d = iris.data[:, 0].reshape((-1, 1))</div>
<div class="line"><span class="lineno"> 1565</span>    y = iris.target</div>
<div class="line"><span class="lineno"> 1566</span> </div>
<div class="line"><span class="lineno"> 1567</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno"> 1568</span>        TreeEstimator(random_state=0).fit(X, y)</div>
<div class="line"><span class="lineno"> 1569</span> </div>
<div class="line"><span class="lineno"> 1570</span>    est = TreeEstimator(random_state=0)</div>
<div class="line"><span class="lineno"> 1571</span>    est.fit(X_2d, y)</div>
<div class="line"><span class="lineno"> 1572</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno"> 1573</span>        est.predict([X])</div>
<div class="line"><span class="lineno"> 1574</span> </div>
<div class="line"><span class="lineno"> 1575</span> </div>
<div class="line"><span class="lineno"> 1576</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, ALL_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a31552cc23946d140ffb1d7a1942782ea" name="a31552cc23946d140ffb1d7a1942782ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a31552cc23946d140ffb1d7a1942782ea">&#9670;&#160;</a></span>check_sparse_criterion()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_sparse_criterion </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dataset</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1455</span><span class="keyword">def </span>check_sparse_criterion(tree, dataset):</div>
<div class="line"><span class="lineno"> 1456</span>    TreeEstimator = ALL_TREES[tree]</div>
<div class="line"><span class="lineno"> 1457</span>    X = DATASETS[dataset][<span class="stringliteral">&quot;X&quot;</span>]</div>
<div class="line"><span class="lineno"> 1458</span>    X_sparse = DATASETS[dataset][<span class="stringliteral">&quot;X_sparse&quot;</span>]</div>
<div class="line"><span class="lineno"> 1459</span>    y = DATASETS[dataset][<span class="stringliteral">&quot;y&quot;</span>]</div>
<div class="line"><span class="lineno"> 1460</span> </div>
<div class="line"><span class="lineno"> 1461</span>    <span class="comment"># Check various criterion</span></div>
<div class="line"><span class="lineno"> 1462</span>    CRITERIONS = REG_CRITERIONS <span class="keywordflow">if</span> tree <span class="keywordflow">in</span> REG_TREES <span class="keywordflow">else</span> CLF_CRITERIONS</div>
<div class="line"><span class="lineno"> 1463</span>    <span class="keywordflow">for</span> criterion <span class="keywordflow">in</span> CRITERIONS:</div>
<div class="line"><span class="lineno"> 1464</span>        d = TreeEstimator(random_state=0, max_depth=3, criterion=criterion).fit(X, y)</div>
<div class="line"><span class="lineno"> 1465</span>        s = TreeEstimator(random_state=0, max_depth=3, criterion=criterion).fit(</div>
<div class="line"><span class="lineno"> 1466</span>            X_sparse, y</div>
<div class="line"><span class="lineno"> 1467</span>        )</div>
<div class="line"><span class="lineno"> 1468</span> </div>
<div class="line"><span class="lineno"> 1469</span>        assert_tree_equal(</div>
<div class="line"><span class="lineno"> 1470</span>            d.tree_,</div>
<div class="line"><span class="lineno"> 1471</span>            s.tree_,</div>
<div class="line"><span class="lineno"> 1472</span>            <span class="stringliteral">&quot;{0} with dense and sparse format gave different trees&quot;</span>.format(tree),</div>
<div class="line"><span class="lineno"> 1473</span>        )</div>
<div class="line"><span class="lineno"> 1474</span>        assert_array_almost_equal(s.predict(X), d.predict(X))</div>
<div class="line"><span class="lineno"> 1475</span> </div>
<div class="line"><span class="lineno"> 1476</span> </div>
<div class="line"><span class="lineno"> 1477</span><span class="preprocessor">@pytest.mark.parametrize(&quot;tree_type&quot;, SPARSE_TREES)</span></div>
<div class="line"><span class="lineno"> 1478</span><span class="preprocessor">@pytest.mark.parametrize(&quot;dataset&quot;, [&quot;sparse-pos&quot;, &quot;sparse-neg&quot;, &quot;sparse-mix&quot;, &quot;zeros&quot;])</span></div>
<div class="line"><span class="lineno"> 1479</span><span class="preprocessor">@pytest.mark.parametrize(&quot;check&quot;, [check_sparse_parameters, check_sparse_criterion])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ae30b601ecdcb17c2e057839c96f9f589" name="ae30b601ecdcb17c2e057839c96f9f589"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae30b601ecdcb17c2e057839c96f9f589">&#9670;&#160;</a></span>check_sparse_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_sparse_input </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dataset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_depth</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1334</span><span class="keyword">def </span>check_sparse_input(tree, dataset, max_depth=None):</div>
<div class="line"><span class="lineno"> 1335</span>    TreeEstimator = ALL_TREES[tree]</div>
<div class="line"><span class="lineno"> 1336</span>    X = DATASETS[dataset][<span class="stringliteral">&quot;X&quot;</span>]</div>
<div class="line"><span class="lineno"> 1337</span>    X_sparse = DATASETS[dataset][<span class="stringliteral">&quot;X_sparse&quot;</span>]</div>
<div class="line"><span class="lineno"> 1338</span>    y = DATASETS[dataset][<span class="stringliteral">&quot;y&quot;</span>]</div>
<div class="line"><span class="lineno"> 1339</span> </div>
<div class="line"><span class="lineno"> 1340</span>    <span class="comment"># Gain testing time</span></div>
<div class="line"><span class="lineno"> 1341</span>    <span class="keywordflow">if</span> dataset <span class="keywordflow">in</span> [<span class="stringliteral">&quot;digits&quot;</span>, <span class="stringliteral">&quot;diabetes&quot;</span>]:</div>
<div class="line"><span class="lineno"> 1342</span>        n_samples = X.shape[0] // 5</div>
<div class="line"><span class="lineno"> 1343</span>        X = X[:n_samples]</div>
<div class="line"><span class="lineno"> 1344</span>        X_sparse = X_sparse[:n_samples]</div>
<div class="line"><span class="lineno"> 1345</span>        y = y[:n_samples]</div>
<div class="line"><span class="lineno"> 1346</span> </div>
<div class="line"><span class="lineno"> 1347</span>    <span class="keywordflow">for</span> sparse_format <span class="keywordflow">in</span> (csr_matrix, csc_matrix, coo_matrix):</div>
<div class="line"><span class="lineno"> 1348</span>        X_sparse = sparse_format(X_sparse)</div>
<div class="line"><span class="lineno"> 1349</span> </div>
<div class="line"><span class="lineno"> 1350</span>        <span class="comment"># Check the default (depth first search)</span></div>
<div class="line"><span class="lineno"> 1351</span>        d = TreeEstimator(random_state=0, max_depth=max_depth).fit(X, y)</div>
<div class="line"><span class="lineno"> 1352</span>        s = TreeEstimator(random_state=0, max_depth=max_depth).fit(X_sparse, y)</div>
<div class="line"><span class="lineno"> 1353</span> </div>
<div class="line"><span class="lineno"> 1354</span>        assert_tree_equal(</div>
<div class="line"><span class="lineno"> 1355</span>            d.tree_,</div>
<div class="line"><span class="lineno"> 1356</span>            s.tree_,</div>
<div class="line"><span class="lineno"> 1357</span>            <span class="stringliteral">&quot;{0} with dense and sparse format gave different trees&quot;</span>.format(tree),</div>
<div class="line"><span class="lineno"> 1358</span>        )</div>
<div class="line"><span class="lineno"> 1359</span> </div>
<div class="line"><span class="lineno"> 1360</span>        y_pred = d.predict(X)</div>
<div class="line"><span class="lineno"> 1361</span>        <span class="keywordflow">if</span> tree <span class="keywordflow">in</span> CLF_TREES:</div>
<div class="line"><span class="lineno"> 1362</span>            y_proba = d.predict_proba(X)</div>
<div class="line"><span class="lineno"> 1363</span>            y_log_proba = d.predict_log_proba(X)</div>
<div class="line"><span class="lineno"> 1364</span> </div>
<div class="line"><span class="lineno"> 1365</span>        <span class="keywordflow">for</span> sparse_matrix <span class="keywordflow">in</span> (csr_matrix, csc_matrix, coo_matrix):</div>
<div class="line"><span class="lineno"> 1366</span>            X_sparse_test = sparse_matrix(X_sparse, dtype=np.float32)</div>
<div class="line"><span class="lineno"> 1367</span> </div>
<div class="line"><span class="lineno"> 1368</span>            assert_array_almost_equal(s.predict(X_sparse_test), y_pred)</div>
<div class="line"><span class="lineno"> 1369</span> </div>
<div class="line"><span class="lineno"> 1370</span>            <span class="keywordflow">if</span> tree <span class="keywordflow">in</span> CLF_TREES:</div>
<div class="line"><span class="lineno"> 1371</span>                assert_array_almost_equal(s.predict_proba(X_sparse_test), y_proba)</div>
<div class="line"><span class="lineno"> 1372</span>                assert_array_almost_equal(</div>
<div class="line"><span class="lineno"> 1373</span>                    s.predict_log_proba(X_sparse_test), y_log_proba</div>
<div class="line"><span class="lineno"> 1374</span>                )</div>
<div class="line"><span class="lineno"> 1375</span> </div>
<div class="line"><span class="lineno"> 1376</span> </div>
<div class="line"><span class="lineno"> 1377</span><span class="preprocessor">@pytest.mark.parametrize(&quot;tree_type&quot;, SPARSE_TREES)</span></div>
<div class="line"><span class="lineno"> 1378</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1379</span>    <span class="stringliteral">&quot;dataset&quot;</span>,</div>
<div class="line"><span class="lineno"> 1380</span>    (</div>
<div class="line"><span class="lineno"> 1381</span>        <span class="stringliteral">&quot;clf_small&quot;</span>,</div>
<div class="line"><span class="lineno"> 1382</span>        <span class="stringliteral">&quot;toy&quot;</span>,</div>
<div class="line"><span class="lineno"> 1383</span>        <span class="stringliteral">&quot;digits&quot;</span>,</div>
<div class="line"><span class="lineno"> 1384</span>        <span class="stringliteral">&quot;multilabel&quot;</span>,</div>
<div class="line"><span class="lineno"> 1385</span>        <span class="stringliteral">&quot;sparse-pos&quot;</span>,</div>
<div class="line"><span class="lineno"> 1386</span>        <span class="stringliteral">&quot;sparse-neg&quot;</span>,</div>
<div class="line"><span class="lineno"> 1387</span>        <span class="stringliteral">&quot;sparse-mix&quot;</span>,</div>
<div class="line"><span class="lineno"> 1388</span>        <span class="stringliteral">&quot;zeros&quot;</span>,</div>
<div class="line"><span class="lineno"> 1389</span>    ),</div>
<div class="line"><span class="lineno"> 1390</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="acce3f0226d0dc73b9f62f56d8286c557" name="acce3f0226d0dc73b9f62f56d8286c557"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acce3f0226d0dc73b9f62f56d8286c557">&#9670;&#160;</a></span>check_sparse_parameters()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.check_sparse_parameters </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dataset</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1404</span><span class="keyword">def </span>check_sparse_parameters(tree, dataset):</div>
<div class="line"><span class="lineno"> 1405</span>    TreeEstimator = ALL_TREES[tree]</div>
<div class="line"><span class="lineno"> 1406</span>    X = DATASETS[dataset][<span class="stringliteral">&quot;X&quot;</span>]</div>
<div class="line"><span class="lineno"> 1407</span>    X_sparse = DATASETS[dataset][<span class="stringliteral">&quot;X_sparse&quot;</span>]</div>
<div class="line"><span class="lineno"> 1408</span>    y = DATASETS[dataset][<span class="stringliteral">&quot;y&quot;</span>]</div>
<div class="line"><span class="lineno"> 1409</span> </div>
<div class="line"><span class="lineno"> 1410</span>    <span class="comment"># Check max_features</span></div>
<div class="line"><span class="lineno"> 1411</span>    d = TreeEstimator(random_state=0, max_features=1, max_depth=2).fit(X, y)</div>
<div class="line"><span class="lineno"> 1412</span>    s = TreeEstimator(random_state=0, max_features=1, max_depth=2).fit(X_sparse, y)</div>
<div class="line"><span class="lineno"> 1413</span>    assert_tree_equal(</div>
<div class="line"><span class="lineno"> 1414</span>        d.tree_,</div>
<div class="line"><span class="lineno"> 1415</span>        s.tree_,</div>
<div class="line"><span class="lineno"> 1416</span>        <span class="stringliteral">&quot;{0} with dense and sparse format gave different trees&quot;</span>.format(tree),</div>
<div class="line"><span class="lineno"> 1417</span>    )</div>
<div class="line"><span class="lineno"> 1418</span>    assert_array_almost_equal(s.predict(X), d.predict(X))</div>
<div class="line"><span class="lineno"> 1419</span> </div>
<div class="line"><span class="lineno"> 1420</span>    <span class="comment"># Check min_samples_split</span></div>
<div class="line"><span class="lineno"> 1421</span>    d = TreeEstimator(random_state=0, max_features=1, min_samples_split=10).fit(X, y)</div>
<div class="line"><span class="lineno"> 1422</span>    s = TreeEstimator(random_state=0, max_features=1, min_samples_split=10).fit(</div>
<div class="line"><span class="lineno"> 1423</span>        X_sparse, y</div>
<div class="line"><span class="lineno"> 1424</span>    )</div>
<div class="line"><span class="lineno"> 1425</span>    assert_tree_equal(</div>
<div class="line"><span class="lineno"> 1426</span>        d.tree_,</div>
<div class="line"><span class="lineno"> 1427</span>        s.tree_,</div>
<div class="line"><span class="lineno"> 1428</span>        <span class="stringliteral">&quot;{0} with dense and sparse format gave different trees&quot;</span>.format(tree),</div>
<div class="line"><span class="lineno"> 1429</span>    )</div>
<div class="line"><span class="lineno"> 1430</span>    assert_array_almost_equal(s.predict(X), d.predict(X))</div>
<div class="line"><span class="lineno"> 1431</span> </div>
<div class="line"><span class="lineno"> 1432</span>    <span class="comment"># Check min_samples_leaf</span></div>
<div class="line"><span class="lineno"> 1433</span>    d = TreeEstimator(random_state=0, min_samples_leaf=X_sparse.shape[0] // 2).fit(X, y)</div>
<div class="line"><span class="lineno"> 1434</span>    s = TreeEstimator(random_state=0, min_samples_leaf=X_sparse.shape[0] // 2).fit(</div>
<div class="line"><span class="lineno"> 1435</span>        X_sparse, y</div>
<div class="line"><span class="lineno"> 1436</span>    )</div>
<div class="line"><span class="lineno"> 1437</span>    assert_tree_equal(</div>
<div class="line"><span class="lineno"> 1438</span>        d.tree_,</div>
<div class="line"><span class="lineno"> 1439</span>        s.tree_,</div>
<div class="line"><span class="lineno"> 1440</span>        <span class="stringliteral">&quot;{0} with dense and sparse format gave different trees&quot;</span>.format(tree),</div>
<div class="line"><span class="lineno"> 1441</span>    )</div>
<div class="line"><span class="lineno"> 1442</span>    assert_array_almost_equal(s.predict(X), d.predict(X))</div>
<div class="line"><span class="lineno"> 1443</span> </div>
<div class="line"><span class="lineno"> 1444</span>    <span class="comment"># Check best-first search</span></div>
<div class="line"><span class="lineno"> 1445</span>    d = TreeEstimator(random_state=0, max_leaf_nodes=3).fit(X, y)</div>
<div class="line"><span class="lineno"> 1446</span>    s = TreeEstimator(random_state=0, max_leaf_nodes=3).fit(X_sparse, y)</div>
<div class="line"><span class="lineno"> 1447</span>    assert_tree_equal(</div>
<div class="line"><span class="lineno"> 1448</span>        d.tree_,</div>
<div class="line"><span class="lineno"> 1449</span>        s.tree_,</div>
<div class="line"><span class="lineno"> 1450</span>        <span class="stringliteral">&quot;{0} with dense and sparse format gave different trees&quot;</span>.format(tree),</div>
<div class="line"><span class="lineno"> 1451</span>    )</div>
<div class="line"><span class="lineno"> 1452</span>    assert_array_almost_equal(s.predict(X), d.predict(X))</div>
<div class="line"><span class="lineno"> 1453</span> </div>
<div class="line"><span class="lineno"> 1454</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab84beafe039b306d440e55830569c9a4" name="ab84beafe039b306d440e55830569c9a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab84beafe039b306d440e55830569c9a4">&#9670;&#160;</a></span>get_different_alignment_node_ndarray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.get_different_alignment_node_ndarray </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>node_ndarray</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2175</span><span class="keyword">def </span>get_different_alignment_node_ndarray(node_ndarray):</div>
<div class="line"><span class="lineno"> 2176</span>    new_dtype_dict = {</div>
<div class="line"><span class="lineno"> 2177</span>        name: dtype <span class="keywordflow">for</span> name, (dtype, _) <span class="keywordflow">in</span> node_ndarray.dtype.fields.items()</div>
<div class="line"><span class="lineno"> 2178</span>    }</div>
<div class="line"><span class="lineno"> 2179</span>    offsets = [offset <span class="keywordflow">for</span> dtype, offset <span class="keywordflow">in</span> node_ndarray.dtype.fields.values()]</div>
<div class="line"><span class="lineno"> 2180</span>    shifted_offsets = [8 + offset <span class="keywordflow">for</span> offset <span class="keywordflow">in</span> offsets]</div>
<div class="line"><span class="lineno"> 2181</span> </div>
<div class="line"><span class="lineno"> 2182</span>    new_dtype = np.dtype(</div>
<div class="line"><span class="lineno"> 2183</span>        {</div>
<div class="line"><span class="lineno"> 2184</span>            <span class="stringliteral">&quot;names&quot;</span>: list(new_dtype_dict.keys()),</div>
<div class="line"><span class="lineno"> 2185</span>            <span class="stringliteral">&quot;formats&quot;</span>: list(new_dtype_dict.values()),</div>
<div class="line"><span class="lineno"> 2186</span>            <span class="stringliteral">&quot;offsets&quot;</span>: shifted_offsets,</div>
<div class="line"><span class="lineno"> 2187</span>        }</div>
<div class="line"><span class="lineno"> 2188</span>    )</div>
<div class="line"><span class="lineno"> 2189</span>    <span class="keywordflow">return</span> node_ndarray.astype(new_dtype, casting=<span class="stringliteral">&quot;same_kind&quot;</span>)</div>
<div class="line"><span class="lineno"> 2190</span> </div>
<div class="line"><span class="lineno"> 2191</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a029116b4d5f92965dc9e44adbc12223f" name="a029116b4d5f92965dc9e44adbc12223f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a029116b4d5f92965dc9e44adbc12223f">&#9670;&#160;</a></span>get_different_bitness_node_ndarray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.get_different_bitness_node_ndarray </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>node_ndarray</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2157</span><span class="keyword">def </span>get_different_bitness_node_ndarray(node_ndarray):</div>
<div class="line"><span class="lineno"> 2158</span>    new_dtype_for_indexing_fields = np.int64 <span class="keywordflow">if</span> _IS_32BIT <span class="keywordflow">else</span> np.int32</div>
<div class="line"><span class="lineno"> 2159</span> </div>
<div class="line"><span class="lineno"> 2160</span>    <span class="comment"># field names in Node struct with SIZE_t types (see sklearn/tree/_tree.pxd)</span></div>
<div class="line"><span class="lineno"> 2161</span>    indexing_field_names = [<span class="stringliteral">&quot;left_child&quot;</span>, <span class="stringliteral">&quot;right_child&quot;</span>, <span class="stringliteral">&quot;feature&quot;</span>, <span class="stringliteral">&quot;n_node_samples&quot;</span>]</div>
<div class="line"><span class="lineno"> 2162</span> </div>
<div class="line"><span class="lineno"> 2163</span>    new_dtype_dict = {</div>
<div class="line"><span class="lineno"> 2164</span>        name: dtype <span class="keywordflow">for</span> name, (dtype, _) <span class="keywordflow">in</span> node_ndarray.dtype.fields.items()</div>
<div class="line"><span class="lineno"> 2165</span>    }</div>
<div class="line"><span class="lineno"> 2166</span>    <span class="keywordflow">for</span> name <span class="keywordflow">in</span> indexing_field_names:</div>
<div class="line"><span class="lineno"> 2167</span>        new_dtype_dict[name] = new_dtype_for_indexing_fields</div>
<div class="line"><span class="lineno"> 2168</span> </div>
<div class="line"><span class="lineno"> 2169</span>    new_dtype = np.dtype(</div>
<div class="line"><span class="lineno"> 2170</span>        {<span class="stringliteral">&quot;names&quot;</span>: list(new_dtype_dict.keys()), <span class="stringliteral">&quot;formats&quot;</span>: list(new_dtype_dict.values())}</div>
<div class="line"><span class="lineno"> 2171</span>    )</div>
<div class="line"><span class="lineno"> 2172</span>    <span class="keywordflow">return</span> node_ndarray.astype(new_dtype, casting=<span class="stringliteral">&quot;same_kind&quot;</span>)</div>
<div class="line"><span class="lineno"> 2173</span> </div>
<div class="line"><span class="lineno"> 2174</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3e0d9a04c9c2057b44e77ffba32e4102" name="a3e0d9a04c9c2057b44e77ffba32e4102"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3e0d9a04c9c2057b44e77ffba32e4102">&#9670;&#160;</a></span>reduce_tree_with_different_bitness()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.reduce_tree_with_different_bitness </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2192</span><span class="keyword">def </span>reduce_tree_with_different_bitness(tree):</div>
<div class="line"><span class="lineno"> 2193</span>    new_dtype = np.int64 <span class="keywordflow">if</span> _IS_32BIT <span class="keywordflow">else</span> np.int32</div>
<div class="line"><span class="lineno"> 2194</span>    tree_cls, (n_features, n_classes, n_outputs), state = tree.__reduce__()</div>
<div class="line"><span class="lineno"> 2195</span>    new_n_classes = n_classes.astype(new_dtype, casting=<span class="stringliteral">&quot;same_kind&quot;</span>)</div>
<div class="line"><span class="lineno"> 2196</span> </div>
<div class="line"><span class="lineno"> 2197</span>    new_state = state.copy()</div>
<div class="line"><span class="lineno"> 2198</span>    new_state[<span class="stringliteral">&quot;nodes&quot;</span>] = get_different_bitness_node_ndarray(new_state[<span class="stringliteral">&quot;nodes&quot;</span>])</div>
<div class="line"><span class="lineno"> 2199</span> </div>
<div class="line"><span class="lineno"> 2200</span>    <span class="keywordflow">return</span> (tree_cls, (n_features, new_n_classes, n_outputs), new_state)</div>
<div class="line"><span class="lineno"> 2201</span> </div>
<div class="line"><span class="lineno"> 2202</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af2864de832fd8766a040c9188c762fbc" name="af2864de832fd8766a040c9188c762fbc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af2864de832fd8766a040c9188c762fbc">&#9670;&#160;</a></span>test_1d_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_1d_input </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1577</span><span class="keyword">def </span>test_1d_input(name):</div>
<div class="line"><span class="lineno"> 1578</span>    <span class="keyword">with</span> ignore_warnings():</div>
<div class="line"><span class="lineno"> 1579</span>        check_raise_error_on_1d_input(name)</div>
<div class="line"><span class="lineno"> 1580</span> </div>
<div class="line"><span class="lineno"> 1581</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7b25927c90204d81098c3cf7577cd1f7" name="a7b25927c90204d81098c3cf7577cd1f7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b25927c90204d81098c3cf7577cd1f7">&#9670;&#160;</a></span>test_apply_path_readonly_all_trees()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_apply_path_readonly_all_trees </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1950</span><span class="keyword">def </span>test_apply_path_readonly_all_trees(name):</div>
<div class="line"><span class="lineno"> 1951</span>    check_apply_path_readonly(name)</div>
<div class="line"><span class="lineno"> 1952</span> </div>
<div class="line"><span class="lineno"> 1953</span> </div>
<div class="line"><span class="lineno"> 1954</span><span class="preprocessor">@pytest.mark.parametrize(&quot;criterion&quot;, [&quot;squared_error&quot;, &quot;friedman_mse&quot;, &quot;poisson&quot;])</span></div>
<div class="line"><span class="lineno"> 1955</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Tree&quot;, REG_TREES.values()</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a5d62b12850c2a4c0ed6c5b3933f83645" name="a5d62b12850c2a4c0ed6c5b3933f83645"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5d62b12850c2a4c0ed6c5b3933f83645">&#9670;&#160;</a></span>test_arrayrepr()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_arrayrepr </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  385</span><span class="keyword">def </span>test_arrayrepr():</div>
<div class="line"><span class="lineno">  386</span>    <span class="comment"># Check the array representation.</span></div>
<div class="line"><span class="lineno">  387</span>    <span class="comment"># Check resize</span></div>
<div class="line"><span class="lineno">  388</span>    X = np.arange(10000)[:, np.newaxis]</div>
<div class="line"><span class="lineno">  389</span>    y = np.arange(10000)</div>
<div class="line"><span class="lineno">  390</span> </div>
<div class="line"><span class="lineno">  391</span>    <span class="keywordflow">for</span> name, Tree <span class="keywordflow">in</span> REG_TREES.items():</div>
<div class="line"><span class="lineno">  392</span>        reg = Tree(max_depth=<span class="keywordtype">None</span>, random_state=0)</div>
<div class="line"><span class="lineno">  393</span>        reg.fit(X, y)</div>
<div class="line"><span class="lineno">  394</span> </div>
<div class="line"><span class="lineno">  395</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a94f6561365e5995de348a5175781ca93" name="a94f6561365e5995de348a5175781ca93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a94f6561365e5995de348a5175781ca93">&#9670;&#160;</a></span>test_arrays_persist()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_arrays_persist </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1239</span><span class="keyword">def </span>test_arrays_persist():</div>
<div class="line"><span class="lineno"> 1240</span>    <span class="comment"># Ensure property arrays&#39; memory stays alive when tree disappears</span></div>
<div class="line"><span class="lineno"> 1241</span>    <span class="comment"># non-regression for #2726</span></div>
<div class="line"><span class="lineno"> 1242</span>    <span class="keywordflow">for</span> attr <span class="keywordflow">in</span> [</div>
<div class="line"><span class="lineno"> 1243</span>        <span class="stringliteral">&quot;n_classes&quot;</span>,</div>
<div class="line"><span class="lineno"> 1244</span>        <span class="stringliteral">&quot;value&quot;</span>,</div>
<div class="line"><span class="lineno"> 1245</span>        <span class="stringliteral">&quot;children_left&quot;</span>,</div>
<div class="line"><span class="lineno"> 1246</span>        <span class="stringliteral">&quot;children_right&quot;</span>,</div>
<div class="line"><span class="lineno"> 1247</span>        <span class="stringliteral">&quot;threshold&quot;</span>,</div>
<div class="line"><span class="lineno"> 1248</span>        <span class="stringliteral">&quot;impurity&quot;</span>,</div>
<div class="line"><span class="lineno"> 1249</span>        <span class="stringliteral">&quot;feature&quot;</span>,</div>
<div class="line"><span class="lineno"> 1250</span>        <span class="stringliteral">&quot;n_node_samples&quot;</span>,</div>
<div class="line"><span class="lineno"> 1251</span>    ]:</div>
<div class="line"><span class="lineno"> 1252</span>        value = getattr(DecisionTreeClassifier().fit([[0], [1]], [0, 1]).tree_, attr)</div>
<div class="line"><span class="lineno"> 1253</span>        <span class="comment"># if pointing to freed memory, contents may be arbitrary</span></div>
<div class="line"><span class="lineno"> 1254</span>        <span class="keyword">assert</span> -3 &lt;= value.flat[0] &lt; 3, <span class="stringliteral">&quot;Array points to arbitrary memory&quot;</span></div>
<div class="line"><span class="lineno"> 1255</span> </div>
<div class="line"><span class="lineno"> 1256</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aafa7e6bcc6a0a245fac3174707ad4312" name="aafa7e6bcc6a0a245fac3174707ad4312"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aafa7e6bcc6a0a245fac3174707ad4312">&#9670;&#160;</a></span>test_balance_property()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_balance_property </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>criterion</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Tree</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1956</span><span class="keyword">def </span>test_balance_property(criterion, Tree):</div>
<div class="line"><span class="lineno"> 1957</span>    <span class="comment"># Test that sum(y_pred)=sum(y_true) on training set.</span></div>
<div class="line"><span class="lineno"> 1958</span>    <span class="comment"># This works if the mean is predicted (should even be true for each leaf).</span></div>
<div class="line"><span class="lineno"> 1959</span>    <span class="comment"># MAE predicts the median and is therefore excluded from this test.</span></div>
<div class="line"><span class="lineno"> 1960</span> </div>
<div class="line"><span class="lineno"> 1961</span>    <span class="comment"># Choose a training set with non-negative targets (for poisson)</span></div>
<div class="line"><span class="lineno"> 1962</span>    X, y = diabetes.data, diabetes.target</div>
<div class="line"><span class="lineno"> 1963</span>    reg = Tree(criterion=criterion)</div>
<div class="line"><span class="lineno"> 1964</span>    reg.fit(X, y)</div>
<div class="line"><span class="lineno"> 1965</span>    <span class="keyword">assert</span> np.sum(reg.predict(X)) == pytest.approx(np.sum(y))</div>
<div class="line"><span class="lineno"> 1966</span> </div>
<div class="line"><span class="lineno"> 1967</span> </div>
<div class="line"><span class="lineno"> 1968</span><span class="preprocessor">@pytest.mark.parametrize(&quot;seed&quot;, range(3)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a203b1206d395658669cba43f0786ec2b" name="a203b1206d395658669cba43f0786ec2b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a203b1206d395658669cba43f0786ec2b">&#9670;&#160;</a></span>test_behaviour_constant_feature_after_splits()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_behaviour_constant_feature_after_splits </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1267</span><span class="keyword">def </span>test_behaviour_constant_feature_after_splits():</div>
<div class="line"><span class="lineno"> 1268</span>    X = np.transpose(</div>
<div class="line"><span class="lineno"> 1269</span>        np.vstack(([[0, 0, 0, 0, 0, 1, 2, 4, 5, 6, 7]], np.zeros((4, 11))))</div>
<div class="line"><span class="lineno"> 1270</span>    )</div>
<div class="line"><span class="lineno"> 1271</span>    y = [0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 3]</div>
<div class="line"><span class="lineno"> 1272</span>    <span class="keywordflow">for</span> name, TreeEstimator <span class="keywordflow">in</span> ALL_TREES.items():</div>
<div class="line"><span class="lineno"> 1273</span>        <span class="comment"># do not check extra random trees</span></div>
<div class="line"><span class="lineno"> 1274</span>        <span class="keywordflow">if</span> <span class="stringliteral">&quot;ExtraTree&quot;</span> <span class="keywordflow">not</span> <span class="keywordflow">in</span> name:</div>
<div class="line"><span class="lineno"> 1275</span>            est = TreeEstimator(random_state=0, max_features=1)</div>
<div class="line"><span class="lineno"> 1276</span>            est.fit(X, y)</div>
<div class="line"><span class="lineno"> 1277</span>            <span class="keyword">assert</span> est.tree_.max_depth == 2</div>
<div class="line"><span class="lineno"> 1278</span>            <span class="keyword">assert</span> est.tree_.node_count == 5</div>
<div class="line"><span class="lineno"> 1279</span> </div>
<div class="line"><span class="lineno"> 1280</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a372a27a7d8bf57174a65ff03722b4f37" name="a372a27a7d8bf57174a65ff03722b4f37"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a372a27a7d8bf57174a65ff03722b4f37">&#9670;&#160;</a></span>test_big_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_big_input </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1298</span><span class="keyword">def </span>test_big_input():</div>
<div class="line"><span class="lineno"> 1299</span>    <span class="comment"># Test if the warning for too large inputs is appropriate.</span></div>
<div class="line"><span class="lineno"> 1300</span>    X = np.repeat(10**40.0, 4).astype(np.float64).reshape(-1, 1)</div>
<div class="line"><span class="lineno"> 1301</span>    clf = DecisionTreeClassifier()</div>
<div class="line"><span class="lineno"> 1302</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;float32&quot;</span>):</div>
<div class="line"><span class="lineno"> 1303</span>        clf.fit(X, [0, 1, 0, 1])</div>
<div class="line"><span class="lineno"> 1304</span> </div>
<div class="line"><span class="lineno"> 1305</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a48b63f3a9ef4fc2cabb93318c9969771" name="a48b63f3a9ef4fc2cabb93318c9969771"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a48b63f3a9ef4fc2cabb93318c9969771">&#9670;&#160;</a></span>test_check_n_classes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_check_n_classes </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2252</span><span class="keyword">def </span>test_check_n_classes():</div>
<div class="line"><span class="lineno"> 2253</span>    expected_dtype = np.dtype(np.int32) <span class="keywordflow">if</span> _IS_32BIT <span class="keywordflow">else</span> np.dtype(np.int64)</div>
<div class="line"><span class="lineno"> 2254</span>    allowed_dtypes = [np.dtype(np.int32), np.dtype(np.int64)]</div>
<div class="line"><span class="lineno"> 2255</span>    allowed_dtypes += [dt.newbyteorder() <span class="keywordflow">for</span> dt <span class="keywordflow">in</span> allowed_dtypes]</div>
<div class="line"><span class="lineno"> 2256</span> </div>
<div class="line"><span class="lineno"> 2257</span>    n_classes = np.array([0, 1], dtype=expected_dtype)</div>
<div class="line"><span class="lineno"> 2258</span>    <span class="keywordflow">for</span> dt <span class="keywordflow">in</span> allowed_dtypes:</div>
<div class="line"><span class="lineno"> 2259</span>        _check_n_classes(n_classes.astype(dt), expected_dtype)</div>
<div class="line"><span class="lineno"> 2260</span> </div>
<div class="line"><span class="lineno"> 2261</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;Wrong dimensions.+n_classes&quot;</span>):</div>
<div class="line"><span class="lineno"> 2262</span>        wrong_dim_n_classes = np.array([[0, 1]], dtype=expected_dtype)</div>
<div class="line"><span class="lineno"> 2263</span>        _check_n_classes(wrong_dim_n_classes, expected_dtype)</div>
<div class="line"><span class="lineno"> 2264</span> </div>
<div class="line"><span class="lineno"> 2265</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;n_classes.+incompatible dtype&quot;</span>):</div>
<div class="line"><span class="lineno"> 2266</span>        wrong_dtype_n_classes = n_classes.astype(np.float64)</div>
<div class="line"><span class="lineno"> 2267</span>        _check_n_classes(wrong_dtype_n_classes, expected_dtype)</div>
<div class="line"><span class="lineno"> 2268</span> </div>
<div class="line"><span class="lineno"> 2269</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8f2127ad57fcf4a114d9c448c06b39d1" name="a8f2127ad57fcf4a114d9c448c06b39d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8f2127ad57fcf4a114d9c448c06b39d1">&#9670;&#160;</a></span>test_check_node_ndarray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_check_node_ndarray </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2303</span><span class="keyword">def </span>test_check_node_ndarray():</div>
<div class="line"><span class="lineno"> 2304</span>    expected_dtype = NODE_DTYPE</div>
<div class="line"><span class="lineno"> 2305</span> </div>
<div class="line"><span class="lineno"> 2306</span>    node_ndarray = np.zeros((5,), dtype=expected_dtype)</div>
<div class="line"><span class="lineno"> 2307</span> </div>
<div class="line"><span class="lineno"> 2308</span>    valid_node_ndarrays = [</div>
<div class="line"><span class="lineno"> 2309</span>        node_ndarray,</div>
<div class="line"><span class="lineno"> 2310</span>        get_different_bitness_node_ndarray(node_ndarray),</div>
<div class="line"><span class="lineno"> 2311</span>        get_different_alignment_node_ndarray(node_ndarray),</div>
<div class="line"><span class="lineno"> 2312</span>    ]</div>
<div class="line"><span class="lineno"> 2313</span>    valid_node_ndarrays += [</div>
<div class="line"><span class="lineno"> 2314</span>        arr.astype(arr.dtype.newbyteorder()) <span class="keywordflow">for</span> arr <span class="keywordflow">in</span> valid_node_ndarrays</div>
<div class="line"><span class="lineno"> 2315</span>    ]</div>
<div class="line"><span class="lineno"> 2316</span> </div>
<div class="line"><span class="lineno"> 2317</span>    <span class="keywordflow">for</span> arr <span class="keywordflow">in</span> valid_node_ndarrays:</div>
<div class="line"><span class="lineno"> 2318</span>        _check_node_ndarray(node_ndarray, expected_dtype=expected_dtype)</div>
<div class="line"><span class="lineno"> 2319</span> </div>
<div class="line"><span class="lineno"> 2320</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;Wrong dimensions.+node array&quot;</span>):</div>
<div class="line"><span class="lineno"> 2321</span>        problematic_node_ndarray = np.zeros((5, 2), dtype=expected_dtype)</div>
<div class="line"><span class="lineno"> 2322</span>        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)</div>
<div class="line"><span class="lineno"> 2323</span> </div>
<div class="line"><span class="lineno"> 2324</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;node array.+C-contiguous&quot;</span>):</div>
<div class="line"><span class="lineno"> 2325</span>        problematic_node_ndarray = node_ndarray[::2]</div>
<div class="line"><span class="lineno"> 2326</span>        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)</div>
<div class="line"><span class="lineno"> 2327</span> </div>
<div class="line"><span class="lineno"> 2328</span>    dtype_dict = {name: dtype <span class="keywordflow">for</span> name, (dtype, _) <span class="keywordflow">in</span> node_ndarray.dtype.fields.items()}</div>
<div class="line"><span class="lineno"> 2329</span> </div>
<div class="line"><span class="lineno"> 2330</span>    <span class="comment"># array with wrong &#39;threshold&#39; field dtype (int64 rather than float64)</span></div>
<div class="line"><span class="lineno"> 2331</span>    new_dtype_dict = dtype_dict.copy()</div>
<div class="line"><span class="lineno"> 2332</span>    new_dtype_dict[<span class="stringliteral">&quot;threshold&quot;</span>] = np.int64</div>
<div class="line"><span class="lineno"> 2333</span> </div>
<div class="line"><span class="lineno"> 2334</span>    new_dtype = np.dtype(</div>
<div class="line"><span class="lineno"> 2335</span>        {<span class="stringliteral">&quot;names&quot;</span>: list(new_dtype_dict.keys()), <span class="stringliteral">&quot;formats&quot;</span>: list(new_dtype_dict.values())}</div>
<div class="line"><span class="lineno"> 2336</span>    )</div>
<div class="line"><span class="lineno"> 2337</span>    problematic_node_ndarray = node_ndarray.astype(new_dtype)</div>
<div class="line"><span class="lineno"> 2338</span> </div>
<div class="line"><span class="lineno"> 2339</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;node array.+incompatible dtype&quot;</span>):</div>
<div class="line"><span class="lineno"> 2340</span>        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)</div>
<div class="line"><span class="lineno"> 2341</span> </div>
<div class="line"><span class="lineno"> 2342</span>    <span class="comment"># array with wrong &#39;left_child&#39; field dtype (float64 rather than int64 or int32)</span></div>
<div class="line"><span class="lineno"> 2343</span>    new_dtype_dict = dtype_dict.copy()</div>
<div class="line"><span class="lineno"> 2344</span>    new_dtype_dict[<span class="stringliteral">&quot;left_child&quot;</span>] = np.float64</div>
<div class="line"><span class="lineno"> 2345</span>    new_dtype = np.dtype(</div>
<div class="line"><span class="lineno"> 2346</span>        {<span class="stringliteral">&quot;names&quot;</span>: list(new_dtype_dict.keys()), <span class="stringliteral">&quot;formats&quot;</span>: list(new_dtype_dict.values())}</div>
<div class="line"><span class="lineno"> 2347</span>    )</div>
<div class="line"><span class="lineno"> 2348</span> </div>
<div class="line"><span class="lineno"> 2349</span>    problematic_node_ndarray = node_ndarray.astype(new_dtype)</div>
<div class="line"><span class="lineno"> 2350</span> </div>
<div class="line"><span class="lineno"> 2351</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;node array.+incompatible dtype&quot;</span>):</div>
<div class="line"><span class="lineno"> 2352</span>        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)</div>
<div class="line"><span class="lineno"> 2353</span> </div>
<div class="line"><span class="lineno"> 2354</span> </div>
<div class="line"><span class="lineno"> 2355</span><span class="comment"># TODO(1.3): Remove</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a56d0763ad698165f943ef947c3f1d0b7" name="a56d0763ad698165f943ef947c3f1d0b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56d0763ad698165f943ef947c3f1d0b7">&#9670;&#160;</a></span>test_check_value_ndarray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_check_value_ndarray </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2270</span><span class="keyword">def </span>test_check_value_ndarray():</div>
<div class="line"><span class="lineno"> 2271</span>    expected_dtype = np.dtype(np.float64)</div>
<div class="line"><span class="lineno"> 2272</span>    expected_shape = (5, 1, 2)</div>
<div class="line"><span class="lineno"> 2273</span>    value_ndarray = np.zeros(expected_shape, dtype=expected_dtype)</div>
<div class="line"><span class="lineno"> 2274</span> </div>
<div class="line"><span class="lineno"> 2275</span>    allowed_dtypes = [expected_dtype, expected_dtype.newbyteorder()]</div>
<div class="line"><span class="lineno"> 2276</span> </div>
<div class="line"><span class="lineno"> 2277</span>    <span class="keywordflow">for</span> dt <span class="keywordflow">in</span> allowed_dtypes:</div>
<div class="line"><span class="lineno"> 2278</span>        _check_value_ndarray(</div>
<div class="line"><span class="lineno"> 2279</span>            value_ndarray, expected_dtype=dt, expected_shape=expected_shape</div>
<div class="line"><span class="lineno"> 2280</span>        )</div>
<div class="line"><span class="lineno"> 2281</span> </div>
<div class="line"><span class="lineno"> 2282</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;Wrong shape.+value array&quot;</span>):</div>
<div class="line"><span class="lineno"> 2283</span>        _check_value_ndarray(</div>
<div class="line"><span class="lineno"> 2284</span>            value_ndarray, expected_dtype=expected_dtype, expected_shape=(1, 2)</div>
<div class="line"><span class="lineno"> 2285</span>        )</div>
<div class="line"><span class="lineno"> 2286</span> </div>
<div class="line"><span class="lineno"> 2287</span>    <span class="keywordflow">for</span> problematic_arr <span class="keywordflow">in</span> [value_ndarray[:, :, :1], np.asfortranarray(value_ndarray)]:</div>
<div class="line"><span class="lineno"> 2288</span>        <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;value array.+C-contiguous&quot;</span>):</div>
<div class="line"><span class="lineno"> 2289</span>            _check_value_ndarray(</div>
<div class="line"><span class="lineno"> 2290</span>                problematic_arr,</div>
<div class="line"><span class="lineno"> 2291</span>                expected_dtype=expected_dtype,</div>
<div class="line"><span class="lineno"> 2292</span>                expected_shape=problematic_arr.shape,</div>
<div class="line"><span class="lineno"> 2293</span>            )</div>
<div class="line"><span class="lineno"> 2294</span> </div>
<div class="line"><span class="lineno"> 2295</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;value array.+incompatible dtype&quot;</span>):</div>
<div class="line"><span class="lineno"> 2296</span>        _check_value_ndarray(</div>
<div class="line"><span class="lineno"> 2297</span>            value_ndarray.astype(np.float32),</div>
<div class="line"><span class="lineno"> 2298</span>            expected_dtype=expected_dtype,</div>
<div class="line"><span class="lineno"> 2299</span>            expected_shape=expected_shape,</div>
<div class="line"><span class="lineno"> 2300</span>        )</div>
<div class="line"><span class="lineno"> 2301</span> </div>
<div class="line"><span class="lineno"> 2302</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="accbe354e05072278d62d0218c4bd185a" name="accbe354e05072278d62d0218c4bd185a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#accbe354e05072278d62d0218c4bd185a">&#9670;&#160;</a></span>test_class_weight_errors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_class_weight_errors </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1217</span><span class="keyword">def </span>test_class_weight_errors(name):</div>
<div class="line"><span class="lineno"> 1218</span>    check_class_weight_errors(name)</div>
<div class="line"><span class="lineno"> 1219</span> </div>
<div class="line"><span class="lineno"> 1220</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a13805dc993c5fb5a40afa2ae248c293a" name="a13805dc993c5fb5a40afa2ae248c293a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a13805dc993c5fb5a40afa2ae248c293a">&#9670;&#160;</a></span>test_class_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_class_weights </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1200</span><span class="keyword">def </span>test_class_weights(name):</div>
<div class="line"><span class="lineno"> 1201</span>    check_class_weights(name)</div>
<div class="line"><span class="lineno"> 1202</span> </div>
<div class="line"><span class="lineno"> 1203</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab3a0680e7ec2dc5e8a6c14c69fc11138" name="ab3a0680e7ec2dc5e8a6c14c69fc11138"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3a0680e7ec2dc5e8a6c14c69fc11138">&#9670;&#160;</a></span>test_classes_shape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_classes_shape </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1007</span><span class="keyword">def </span>test_classes_shape():</div>
<div class="line"><span class="lineno"> 1008</span>    <span class="comment"># Test that n_classes_ and classes_ have proper shape.</span></div>
<div class="line"><span class="lineno"> 1009</span>    <span class="keywordflow">for</span> name, TreeClassifier <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno"> 1010</span>        <span class="comment"># Classification, single output</span></div>
<div class="line"><span class="lineno"> 1011</span>        clf = TreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno"> 1012</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 1013</span> </div>
<div class="line"><span class="lineno"> 1014</span>        <span class="keyword">assert</span> clf.n_classes_ == 2</div>
<div class="line"><span class="lineno"> 1015</span>        assert_array_equal(clf.classes_, [-1, 1])</div>
<div class="line"><span class="lineno"> 1016</span> </div>
<div class="line"><span class="lineno"> 1017</span>        <span class="comment"># Classification, multi-output</span></div>
<div class="line"><span class="lineno"> 1018</span>        _y = np.vstack((y, np.array(y) * 2)).T</div>
<div class="line"><span class="lineno"> 1019</span>        clf = TreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno"> 1020</span>        clf.fit(X, _y)</div>
<div class="line"><span class="lineno"> 1021</span>        <span class="keyword">assert</span> len(clf.n_classes_) == 2</div>
<div class="line"><span class="lineno"> 1022</span>        <span class="keyword">assert</span> len(clf.classes_) == 2</div>
<div class="line"><span class="lineno"> 1023</span>        assert_array_equal(clf.n_classes_, [2, 2])</div>
<div class="line"><span class="lineno"> 1024</span>        assert_array_equal(clf.classes_, [[-1, 1], [-2, 2]])</div>
<div class="line"><span class="lineno"> 1025</span> </div>
<div class="line"><span class="lineno"> 1026</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9dc287bd0c6175372c12aeced8d4dd60" name="a9dc287bd0c6175372c12aeced8d4dd60"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9dc287bd0c6175372c12aeced8d4dd60">&#9670;&#160;</a></span>test_classification_toy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_classification_toy </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  239</span><span class="keyword">def </span>test_classification_toy():</div>
<div class="line"><span class="lineno">  240</span>    <span class="comment"># Check classification on a toy dataset.</span></div>
<div class="line"><span class="lineno">  241</span>    <span class="keywordflow">for</span> name, Tree <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno">  242</span>        clf = Tree(random_state=0)</div>
<div class="line"><span class="lineno">  243</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  244</span>        assert_array_equal(clf.predict(T), true_result, <span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name))</div>
<div class="line"><span class="lineno">  245</span> </div>
<div class="line"><span class="lineno">  246</span>        clf = Tree(max_features=1, random_state=1)</div>
<div class="line"><span class="lineno">  247</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  248</span>        assert_array_equal(clf.predict(T), true_result, <span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name))</div>
<div class="line"><span class="lineno">  249</span> </div>
<div class="line"><span class="lineno">  250</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3160e0d670b66fd2558cc80a5a4a50a4" name="a3160e0d670b66fd2558cc80a5a4a50a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3160e0d670b66fd2558cc80a5a4a50a4">&#9670;&#160;</a></span>test_criterion_copy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_criterion_copy </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1789</span><span class="keyword">def </span>test_criterion_copy():</div>
<div class="line"><span class="lineno"> 1790</span>    <span class="comment"># Let&#39;s check whether copy of our criterion has the same type</span></div>
<div class="line"><span class="lineno"> 1791</span>    <span class="comment"># and properties as original</span></div>
<div class="line"><span class="lineno"> 1792</span>    n_outputs = 3</div>
<div class="line"><span class="lineno"> 1793</span>    n_classes = np.arange(3, dtype=np.intp)</div>
<div class="line"><span class="lineno"> 1794</span>    n_samples = 100</div>
<div class="line"><span class="lineno"> 1795</span> </div>
<div class="line"><span class="lineno"> 1796</span>    <span class="keyword">def </span>_pickle_copy(obj):</div>
<div class="line"><span class="lineno"> 1797</span>        <span class="keywordflow">return</span> pickle.loads(pickle.dumps(obj))</div>
<div class="line"><span class="lineno"> 1798</span> </div>
<div class="line"><span class="lineno"> 1799</span>    <span class="keywordflow">for</span> copy_func <span class="keywordflow">in</span> [copy.copy, copy.deepcopy, _pickle_copy]:</div>
<div class="line"><span class="lineno"> 1800</span>        <span class="keywordflow">for</span> _, typename <span class="keywordflow">in</span> CRITERIA_CLF.items():</div>
<div class="line"><span class="lineno"> 1801</span>            criteria = typename(n_outputs, n_classes)</div>
<div class="line"><span class="lineno"> 1802</span>            result = copy_func(criteria).__reduce__()</div>
<div class="line"><span class="lineno"> 1803</span>            typename_, (n_outputs_, n_classes_), _ = result</div>
<div class="line"><span class="lineno"> 1804</span>            <span class="keyword">assert</span> typename == typename_</div>
<div class="line"><span class="lineno"> 1805</span>            <span class="keyword">assert</span> n_outputs == n_outputs_</div>
<div class="line"><span class="lineno"> 1806</span>            assert_array_equal(n_classes, n_classes_)</div>
<div class="line"><span class="lineno"> 1807</span> </div>
<div class="line"><span class="lineno"> 1808</span>        <span class="keywordflow">for</span> _, typename <span class="keywordflow">in</span> CRITERIA_REG.items():</div>
<div class="line"><span class="lineno"> 1809</span>            criteria = typename(n_outputs, n_samples)</div>
<div class="line"><span class="lineno"> 1810</span>            result = copy_func(criteria).__reduce__()</div>
<div class="line"><span class="lineno"> 1811</span>            typename_, (n_outputs_, n_samples_), _ = result</div>
<div class="line"><span class="lineno"> 1812</span>            <span class="keyword">assert</span> typename == typename_</div>
<div class="line"><span class="lineno"> 1813</span>            <span class="keyword">assert</span> n_outputs == n_outputs_</div>
<div class="line"><span class="lineno"> 1814</span>            <span class="keyword">assert</span> n_samples == n_samples_</div>
<div class="line"><span class="lineno"> 1815</span> </div>
<div class="line"><span class="lineno"> 1816</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af281edcc3b211f692b5142a4d73709da" name="af281edcc3b211f692b5142a4d73709da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af281edcc3b211f692b5142a4d73709da">&#9670;&#160;</a></span>test_criterion_entropy_same_as_log_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_criterion_entropy_same_as_log_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Tree</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_classes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test that criterion=entropy gives same as log_loss.</pre> <div class="fragment"><div class="line"><span class="lineno"> 2084</span><span class="keyword">def </span>test_criterion_entropy_same_as_log_loss(Tree, n_classes):</div>
<div class="line"><span class="lineno"> 2085</span>    <span class="stringliteral">&quot;&quot;&quot;Test that criterion=entropy gives same as log_loss.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 2086</span>    n_samples, n_features = 50, 5</div>
<div class="line"><span class="lineno"> 2087</span>    X, y = datasets.make_classification(</div>
<div class="line"><span class="lineno"> 2088</span>        n_classes=n_classes,</div>
<div class="line"><span class="lineno"> 2089</span>        n_samples=n_samples,</div>
<div class="line"><span class="lineno"> 2090</span>        n_features=n_features,</div>
<div class="line"><span class="lineno"> 2091</span>        n_informative=n_features,</div>
<div class="line"><span class="lineno"> 2092</span>        n_redundant=0,</div>
<div class="line"><span class="lineno"> 2093</span>        random_state=42,</div>
<div class="line"><span class="lineno"> 2094</span>    )</div>
<div class="line"><span class="lineno"> 2095</span>    tree_log_loss = Tree(criterion=<span class="stringliteral">&quot;log_loss&quot;</span>, random_state=43).fit(X, y)</div>
<div class="line"><span class="lineno"> 2096</span>    tree_entropy = Tree(criterion=<span class="stringliteral">&quot;entropy&quot;</span>, random_state=43).fit(X, y)</div>
<div class="line"><span class="lineno"> 2097</span> </div>
<div class="line"><span class="lineno"> 2098</span>    assert_tree_equal(</div>
<div class="line"><span class="lineno"> 2099</span>        tree_log_loss.tree_,</div>
<div class="line"><span class="lineno"> 2100</span>        tree_entropy.tree_,</div>
<div class="line"><span class="lineno"> 2101</span>        f<span class="stringliteral">&quot;{Tree!r} with criterion &#39;entropy&#39; and &#39;log_loss&#39; gave different trees.&quot;</span>,</div>
<div class="line"><span class="lineno"> 2102</span>    )</div>
<div class="line"><span class="lineno"> 2103</span>    assert_allclose(tree_log_loss.predict(X), tree_entropy.predict(X))</div>
<div class="line"><span class="lineno"> 2104</span> </div>
<div class="line"><span class="lineno"> 2105</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a69779ee3653cbea4e7a111d745e7b5d1" name="a69779ee3653cbea4e7a111d745e7b5d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a69779ee3653cbea4e7a111d745e7b5d1">&#9670;&#160;</a></span>test_decision_path()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_decision_path </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1672</span><span class="keyword">def </span>test_decision_path(name):</div>
<div class="line"><span class="lineno"> 1673</span>    check_decision_path(name)</div>
<div class="line"><span class="lineno"> 1674</span> </div>
<div class="line"><span class="lineno"> 1675</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae42812d88b9ce4df0c4d74b4af44c446" name="ae42812d88b9ce4df0c4d74b4af44c446"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae42812d88b9ce4df0c4d74b4af44c446">&#9670;&#160;</a></span>test_decision_path_hardcoded()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_decision_path_hardcoded </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1634</span><span class="keyword">def </span>test_decision_path_hardcoded():</div>
<div class="line"><span class="lineno"> 1635</span>    X = iris.data</div>
<div class="line"><span class="lineno"> 1636</span>    y = iris.target</div>
<div class="line"><span class="lineno"> 1637</span>    est = DecisionTreeClassifier(random_state=0, max_depth=1).fit(X, y)</div>
<div class="line"><span class="lineno"> 1638</span>    node_indicator = est.decision_path(X[:2]).toarray()</div>
<div class="line"><span class="lineno"> 1639</span>    assert_array_equal(node_indicator, [[1, 1, 0], [1, 0, 1]])</div>
<div class="line"><span class="lineno"> 1640</span> </div>
<div class="line"><span class="lineno"> 1641</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae7257dca1fc4b07dc649b621e92c4bd0" name="ae7257dca1fc4b07dc649b621e92c4bd0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae7257dca1fc4b07dc649b621e92c4bd0">&#9670;&#160;</a></span>test_decision_tree_regressor_sample_weight_consistency()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_decision_tree_regressor_sample_weight_consistency </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>criterion</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test that the impact of sample_weight is consistent.</pre> <div class="fragment"><div class="line"><span class="lineno"> 2045</span><span class="keyword">def </span>test_decision_tree_regressor_sample_weight_consistency(criterion):</div>
<div class="line"><span class="lineno"> 2046</span>    <span class="stringliteral">&quot;&quot;&quot;Test that the impact of sample_weight is consistent.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 2047</span>    tree_params = dict(criterion=criterion)</div>
<div class="line"><span class="lineno"> 2048</span>    tree = DecisionTreeRegressor(**tree_params, random_state=42)</div>
<div class="line"><span class="lineno"> 2049</span>    <span class="keywordflow">for</span> kind <span class="keywordflow">in</span> [<span class="stringliteral">&quot;zeros&quot;</span>, <span class="stringliteral">&quot;ones&quot;</span>]:</div>
<div class="line"><span class="lineno"> 2050</span>        check_sample_weights_invariance(</div>
<div class="line"><span class="lineno"> 2051</span>            <span class="stringliteral">&quot;DecisionTreeRegressor_&quot;</span> + criterion, tree, kind=<span class="stringliteral">&quot;zeros&quot;</span></div>
<div class="line"><span class="lineno"> 2052</span>        )</div>
<div class="line"><span class="lineno"> 2053</span> </div>
<div class="line"><span class="lineno"> 2054</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno"> 2055</span>    n_samples, n_features = 10, 5</div>
<div class="line"><span class="lineno"> 2056</span> </div>
<div class="line"><span class="lineno"> 2057</span>    X = rng.rand(n_samples, n_features)</div>
<div class="line"><span class="lineno"> 2058</span>    y = np.mean(X, axis=1) + rng.rand(n_samples)</div>
<div class="line"><span class="lineno"> 2059</span>    <span class="comment"># make it positive in order to work also for poisson criterion</span></div>
<div class="line"><span class="lineno"> 2060</span>    y += np.min(y) + 0.1</div>
<div class="line"><span class="lineno"> 2061</span> </div>
<div class="line"><span class="lineno"> 2062</span>    <span class="comment"># check that multiplying sample_weight by 2 is equivalent</span></div>
<div class="line"><span class="lineno"> 2063</span>    <span class="comment"># to repeating corresponding samples twice</span></div>
<div class="line"><span class="lineno"> 2064</span>    X2 = np.concatenate([X, X[: n_samples // 2]], axis=0)</div>
<div class="line"><span class="lineno"> 2065</span>    y2 = np.concatenate([y, y[: n_samples // 2]])</div>
<div class="line"><span class="lineno"> 2066</span>    sample_weight_1 = np.ones(len(y))</div>
<div class="line"><span class="lineno"> 2067</span>    sample_weight_1[: n_samples // 2] = 2</div>
<div class="line"><span class="lineno"> 2068</span> </div>
<div class="line"><span class="lineno"> 2069</span>    tree1 = DecisionTreeRegressor(**tree_params).fit(</div>
<div class="line"><span class="lineno"> 2070</span>        X, y, sample_weight=sample_weight_1</div>
<div class="line"><span class="lineno"> 2071</span>    )</div>
<div class="line"><span class="lineno"> 2072</span> </div>
<div class="line"><span class="lineno"> 2073</span>    tree2 = DecisionTreeRegressor(**tree_params).fit(X2, y2, sample_weight=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno"> 2074</span> </div>
<div class="line"><span class="lineno"> 2075</span>    <span class="keyword">assert</span> tree1.tree_.node_count == tree2.tree_.node_count</div>
<div class="line"><span class="lineno"> 2076</span>    <span class="comment"># Thresholds, tree.tree_.threshold, and values, tree.tree_.value, are not</span></div>
<div class="line"><span class="lineno"> 2077</span>    <span class="comment"># exactly the same, but on the training set, those differences do not</span></div>
<div class="line"><span class="lineno"> 2078</span>    <span class="comment"># matter and thus predictions are the same.</span></div>
<div class="line"><span class="lineno"> 2079</span>    assert_allclose(tree1.predict(X), tree2.predict(X))</div>
<div class="line"><span class="lineno"> 2080</span> </div>
<div class="line"><span class="lineno"> 2081</span> </div>
<div class="line"><span class="lineno"> 2082</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Tree&quot;, [DecisionTreeClassifier, ExtraTreeClassifier])</span></div>
<div class="line"><span class="lineno"> 2083</span><span class="preprocessor">@pytest.mark.parametrize(&quot;n_classes&quot;, [2, 4])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a6967f02536bdad7574319c6b666b3ea5" name="a6967f02536bdad7574319c6b666b3ea5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6967f02536bdad7574319c6b666b3ea5">&#9670;&#160;</a></span>test_diabetes_overfit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_diabetes_overfit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Tree</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>criterion</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  327</span><span class="keyword">def </span>test_diabetes_overfit(name, Tree, criterion):</div>
<div class="line"><span class="lineno">  328</span>    <span class="comment"># check consistency of overfitted trees on the diabetes dataset</span></div>
<div class="line"><span class="lineno">  329</span>    <span class="comment"># since the trees will overfit, we expect an MSE of 0</span></div>
<div class="line"><span class="lineno">  330</span>    reg = Tree(criterion=criterion, random_state=0)</div>
<div class="line"><span class="lineno">  331</span>    reg.fit(diabetes.data, diabetes.target)</div>
<div class="line"><span class="lineno">  332</span>    score = mean_squared_error(diabetes.target, reg.predict(diabetes.data))</div>
<div class="line"><span class="lineno">  333</span>    <span class="keyword">assert</span> score == pytest.approx(</div>
<div class="line"><span class="lineno">  334</span>        0</div>
<div class="line"><span class="lineno">  335</span>    ), f<span class="stringliteral">&quot;Failed with {name}, criterion = {criterion} and score = {score}&quot;</span></div>
<div class="line"><span class="lineno">  336</span> </div>
<div class="line"><span class="lineno">  337</span> </div>
<div class="line"><span class="lineno">  338</span><span class="preprocessor">@skip_if_32bit</span></div>
<div class="line"><span class="lineno">  339</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name, Tree&quot;, REG_TREES.items()</span>)</div>
<div class="line"><span class="lineno">  340</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  341</span>    <span class="stringliteral">&quot;criterion, max_depth, metric, max_loss&quot;</span>,</div>
<div class="line"><span class="lineno">  342</span>    [</div>
<div class="line"><span class="lineno">  343</span>        (<span class="stringliteral">&quot;squared_error&quot;</span>, 15, mean_squared_error, 60),</div>
<div class="line"><span class="lineno">  344</span>        (<span class="stringliteral">&quot;absolute_error&quot;</span>, 20, mean_squared_error, 60),</div>
<div class="line"><span class="lineno">  345</span>        (<span class="stringliteral">&quot;friedman_mse&quot;</span>, 15, mean_squared_error, 60),</div>
<div class="line"><span class="lineno">  346</span>        (<span class="stringliteral">&quot;poisson&quot;</span>, 15, mean_poisson_deviance, 30),</div>
<div class="line"><span class="lineno">  347</span>    ],</div>
<div class="line"><span class="lineno">  348</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a906dc5fc348c26eb13f94a35a1ac4735" name="a906dc5fc348c26eb13f94a35a1ac4735"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a906dc5fc348c26eb13f94a35a1ac4735">&#9670;&#160;</a></span>test_diabetes_underfit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_diabetes_underfit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Tree</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>criterion</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_depth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>metric</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_loss</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  349</span><span class="keyword">def </span>test_diabetes_underfit(name, Tree, criterion, max_depth, metric, max_loss):</div>
<div class="line"><span class="lineno">  350</span>    <span class="comment"># check consistency of trees when the depth and the number of features are</span></div>
<div class="line"><span class="lineno">  351</span>    <span class="comment"># limited</span></div>
<div class="line"><span class="lineno">  352</span> </div>
<div class="line"><span class="lineno">  353</span>    reg = Tree(criterion=criterion, max_depth=max_depth, max_features=6, random_state=0)</div>
<div class="line"><span class="lineno">  354</span>    reg.fit(diabetes.data, diabetes.target)</div>
<div class="line"><span class="lineno">  355</span>    loss = metric(diabetes.target, reg.predict(diabetes.data))</div>
<div class="line"><span class="lineno">  356</span>    <span class="keyword">assert</span> 0 &lt; loss &lt; max_loss</div>
<div class="line"><span class="lineno">  357</span> </div>
<div class="line"><span class="lineno">  358</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aebb22eada9714f6915dbd9667338804c" name="aebb22eada9714f6915dbd9667338804c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aebb22eada9714f6915dbd9667338804c">&#9670;&#160;</a></span>test_different_bitness_joblib_pickle()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_different_bitness_joblib_pickle </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2225</span><span class="keyword">def </span>test_different_bitness_joblib_pickle():</div>
<div class="line"><span class="lineno"> 2226</span>    <span class="comment"># Make sure that a platform specific pickle generated on a 64 bit</span></div>
<div class="line"><span class="lineno"> 2227</span>    <span class="comment"># platform can be converted at pickle load time into an estimator</span></div>
<div class="line"><span class="lineno"> 2228</span>    <span class="comment"># with Cython code that works with the host&#39;s native integer precision</span></div>
<div class="line"><span class="lineno"> 2229</span>    <span class="comment"># to index nodes in the tree data structure when the host is a 32 bit</span></div>
<div class="line"><span class="lineno"> 2230</span>    <span class="comment"># platform (and vice versa).</span></div>
<div class="line"><span class="lineno"> 2231</span>    X, y = datasets.make_classification(random_state=0)</div>
<div class="line"><span class="lineno"> 2232</span> </div>
<div class="line"><span class="lineno"> 2233</span>    clf = DecisionTreeClassifier(random_state=0, max_depth=3)</div>
<div class="line"><span class="lineno"> 2234</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 2235</span>    score = clf.score(X, y)</div>
<div class="line"><span class="lineno"> 2236</span> </div>
<div class="line"><span class="lineno"> 2237</span>    <span class="keyword">def </span>joblib_dump_with_different_bitness():</div>
<div class="line"><span class="lineno"> 2238</span>        f = io.BytesIO()</div>
<div class="line"><span class="lineno"> 2239</span>        p = NumpyPickler(f)</div>
<div class="line"><span class="lineno"> 2240</span>        p.dispatch_table = copyreg.dispatch_table.copy()</div>
<div class="line"><span class="lineno"> 2241</span>        p.dispatch_table[CythonTree] = reduce_tree_with_different_bitness</div>
<div class="line"><span class="lineno"> 2242</span> </div>
<div class="line"><span class="lineno"> 2243</span>        p.dump(clf)</div>
<div class="line"><span class="lineno"> 2244</span>        f.seek(0)</div>
<div class="line"><span class="lineno"> 2245</span>        <span class="keywordflow">return</span> f</div>
<div class="line"><span class="lineno"> 2246</span> </div>
<div class="line"><span class="lineno"> 2247</span>    new_clf = joblib.load(joblib_dump_with_different_bitness())</div>
<div class="line"><span class="lineno"> 2248</span>    new_score = new_clf.score(X, y)</div>
<div class="line"><span class="lineno"> 2249</span>    <span class="keyword">assert</span> score == pytest.approx(new_score)</div>
<div class="line"><span class="lineno"> 2250</span> </div>
<div class="line"><span class="lineno"> 2251</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad89f1c5c5d264b827e1195179484a33e" name="ad89f1c5c5d264b827e1195179484a33e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad89f1c5c5d264b827e1195179484a33e">&#9670;&#160;</a></span>test_different_bitness_pickle()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_different_bitness_pickle </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2203</span><span class="keyword">def </span>test_different_bitness_pickle():</div>
<div class="line"><span class="lineno"> 2204</span>    X, y = datasets.make_classification(random_state=0)</div>
<div class="line"><span class="lineno"> 2205</span> </div>
<div class="line"><span class="lineno"> 2206</span>    clf = DecisionTreeClassifier(random_state=0, max_depth=3)</div>
<div class="line"><span class="lineno"> 2207</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 2208</span>    score = clf.score(X, y)</div>
<div class="line"><span class="lineno"> 2209</span> </div>
<div class="line"><span class="lineno"> 2210</span>    <span class="keyword">def </span>pickle_dump_with_different_bitness():</div>
<div class="line"><span class="lineno"> 2211</span>        f = io.BytesIO()</div>
<div class="line"><span class="lineno"> 2212</span>        p = pickle.Pickler(f)</div>
<div class="line"><span class="lineno"> 2213</span>        p.dispatch_table = copyreg.dispatch_table.copy()</div>
<div class="line"><span class="lineno"> 2214</span>        p.dispatch_table[CythonTree] = reduce_tree_with_different_bitness</div>
<div class="line"><span class="lineno"> 2215</span> </div>
<div class="line"><span class="lineno"> 2216</span>        p.dump(clf)</div>
<div class="line"><span class="lineno"> 2217</span>        f.seek(0)</div>
<div class="line"><span class="lineno"> 2218</span>        <span class="keywordflow">return</span> f</div>
<div class="line"><span class="lineno"> 2219</span> </div>
<div class="line"><span class="lineno"> 2220</span>    new_clf = pickle.load(pickle_dump_with_different_bitness())</div>
<div class="line"><span class="lineno"> 2221</span>    new_score = new_clf.score(X, y)</div>
<div class="line"><span class="lineno"> 2222</span>    <span class="keyword">assert</span> score == pytest.approx(new_score)</div>
<div class="line"><span class="lineno"> 2223</span> </div>
<div class="line"><span class="lineno"> 2224</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="acbb62314fd844d396074729b442a55b0" name="acbb62314fd844d396074729b442a55b0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acbb62314fd844d396074729b442a55b0">&#9670;&#160;</a></span>test_different_endianness_joblib_pickle()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_different_endianness_joblib_pickle </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2131</span><span class="keyword">def </span>test_different_endianness_joblib_pickle():</div>
<div class="line"><span class="lineno"> 2132</span>    X, y = datasets.make_classification(random_state=0)</div>
<div class="line"><span class="lineno"> 2133</span> </div>
<div class="line"><span class="lineno"> 2134</span>    clf = DecisionTreeClassifier(random_state=0, max_depth=3)</div>
<div class="line"><span class="lineno"> 2135</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 2136</span>    score = clf.score(X, y)</div>
<div class="line"><span class="lineno"> 2137</span> </div>
<div class="line"><span class="lineno"> 2138</span>    <span class="keyword">class </span>NonNativeEndiannessNumpyPickler(NumpyPickler):</div>
<div class="line"><span class="lineno"> 2139</span>        <span class="keyword">def </span>save(self, obj):</div>
<div class="line"><span class="lineno"> 2140</span>            <span class="keywordflow">if</span> isinstance(obj, np.ndarray):</div>
<div class="line"><span class="lineno"> 2141</span>                obj = obj.byteswap().newbyteorder()</div>
<div class="line"><span class="lineno"> 2142</span>            super().save(obj)</div>
<div class="line"><span class="lineno"> 2143</span> </div>
<div class="line"><span class="lineno"> 2144</span>    <span class="keyword">def </span>get_joblib_pickle_non_native_endianness():</div>
<div class="line"><span class="lineno"> 2145</span>        f = io.BytesIO()</div>
<div class="line"><span class="lineno"> 2146</span>        p = NonNativeEndiannessNumpyPickler(f)</div>
<div class="line"><span class="lineno"> 2147</span> </div>
<div class="line"><span class="lineno"> 2148</span>        p.dump(clf)</div>
<div class="line"><span class="lineno"> 2149</span>        f.seek(0)</div>
<div class="line"><span class="lineno"> 2150</span>        <span class="keywordflow">return</span> f</div>
<div class="line"><span class="lineno"> 2151</span> </div>
<div class="line"><span class="lineno"> 2152</span>    new_clf = joblib.load(get_joblib_pickle_non_native_endianness())</div>
<div class="line"><span class="lineno"> 2153</span>    new_score = new_clf.score(X, y)</div>
<div class="line"><span class="lineno"> 2154</span>    <span class="keyword">assert</span> np.isclose(score, new_score)</div>
<div class="line"><span class="lineno"> 2155</span> </div>
<div class="line"><span class="lineno"> 2156</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4c3a51d789f7ffde65382dbc66371c62" name="a4c3a51d789f7ffde65382dbc66371c62"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c3a51d789f7ffde65382dbc66371c62">&#9670;&#160;</a></span>test_different_endianness_pickle()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_different_endianness_pickle </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2106</span><span class="keyword">def </span>test_different_endianness_pickle():</div>
<div class="line"><span class="lineno"> 2107</span>    X, y = datasets.make_classification(random_state=0)</div>
<div class="line"><span class="lineno"> 2108</span> </div>
<div class="line"><span class="lineno"> 2109</span>    clf = DecisionTreeClassifier(random_state=0, max_depth=3)</div>
<div class="line"><span class="lineno"> 2110</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 2111</span>    score = clf.score(X, y)</div>
<div class="line"><span class="lineno"> 2112</span> </div>
<div class="line"><span class="lineno"> 2113</span>    <span class="keyword">def </span>reduce_ndarray(arr):</div>
<div class="line"><span class="lineno"> 2114</span>        <span class="keywordflow">return</span> arr.byteswap().newbyteorder().__reduce__()</div>
<div class="line"><span class="lineno"> 2115</span> </div>
<div class="line"><span class="lineno"> 2116</span>    <span class="keyword">def </span>get_pickle_non_native_endianness():</div>
<div class="line"><span class="lineno"> 2117</span>        f = io.BytesIO()</div>
<div class="line"><span class="lineno"> 2118</span>        p = pickle.Pickler(f)</div>
<div class="line"><span class="lineno"> 2119</span>        p.dispatch_table = copyreg.dispatch_table.copy()</div>
<div class="line"><span class="lineno"> 2120</span>        p.dispatch_table[np.ndarray] = reduce_ndarray</div>
<div class="line"><span class="lineno"> 2121</span> </div>
<div class="line"><span class="lineno"> 2122</span>        p.dump(clf)</div>
<div class="line"><span class="lineno"> 2123</span>        f.seek(0)</div>
<div class="line"><span class="lineno"> 2124</span>        <span class="keywordflow">return</span> f</div>
<div class="line"><span class="lineno"> 2125</span> </div>
<div class="line"><span class="lineno"> 2126</span>    new_clf = pickle.load(get_pickle_non_native_endianness())</div>
<div class="line"><span class="lineno"> 2127</span>    new_score = new_clf.score(X, y)</div>
<div class="line"><span class="lineno"> 2128</span>    <span class="keyword">assert</span> np.isclose(score, new_score)</div>
<div class="line"><span class="lineno"> 2129</span> </div>
<div class="line"><span class="lineno"> 2130</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a124e747b70c02fd5edad2791f4363bca" name="a124e747b70c02fd5edad2791f4363bca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a124e747b70c02fd5edad2791f4363bca">&#9670;&#160;</a></span>test_empty_leaf_infinite_threshold()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_empty_leaf_infinite_threshold </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1817</span><span class="keyword">def </span>test_empty_leaf_infinite_threshold():</div>
<div class="line"><span class="lineno"> 1818</span>    <span class="comment"># try to make empty leaf by using near infinite value.</span></div>
<div class="line"><span class="lineno"> 1819</span>    data = np.random.RandomState(0).randn(100, 11) * 2e38</div>
<div class="line"><span class="lineno"> 1820</span>    data = np.nan_to_num(data.astype(<span class="stringliteral">&quot;float32&quot;</span>))</div>
<div class="line"><span class="lineno"> 1821</span>    X_full = data[:, :-1]</div>
<div class="line"><span class="lineno"> 1822</span>    X_sparse = csc_matrix(X_full)</div>
<div class="line"><span class="lineno"> 1823</span>    y = data[:, -1]</div>
<div class="line"><span class="lineno"> 1824</span>    <span class="keywordflow">for</span> X <span class="keywordflow">in</span> [X_full, X_sparse]:</div>
<div class="line"><span class="lineno"> 1825</span>        tree = DecisionTreeRegressor(random_state=0).fit(X, y)</div>
<div class="line"><span class="lineno"> 1826</span>        terminal_regions = tree.apply(X)</div>
<div class="line"><span class="lineno"> 1827</span>        left_leaf = set(np.where(tree.tree_.children_left == TREE_LEAF)[0])</div>
<div class="line"><span class="lineno"> 1828</span>        empty_leaf = left_leaf.difference(terminal_regions)</div>
<div class="line"><span class="lineno"> 1829</span>        infinite_threshold = np.where(~np.isfinite(tree.tree_.threshold))[0]</div>
<div class="line"><span class="lineno"> 1830</span>        <span class="keyword">assert</span> len(infinite_threshold) == 0</div>
<div class="line"><span class="lineno"> 1831</span>        <span class="keyword">assert</span> len(empty_leaf) == 0</div>
<div class="line"><span class="lineno"> 1832</span> </div>
<div class="line"><span class="lineno"> 1833</span> </div>
<div class="line"><span class="lineno"> 1834</span><span class="preprocessor">@pytest.mark.parametrize(&quot;criterion&quot;, CLF_CRITERIONS)</span></div>
<div class="line"><span class="lineno"> 1835</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1836</span>    <span class="stringliteral">&quot;dataset&quot;</span>, sorted(set(DATASETS.keys()) - {<span class="stringliteral">&quot;reg_small&quot;</span>, <span class="stringliteral">&quot;diabetes&quot;</span>})</div>
<div class="line"><span class="lineno"> 1837</span>)</div>
<div class="line"><span class="lineno"> 1838</span><span class="preprocessor">@pytest.mark.parametrize(&quot;tree_cls&quot;, [DecisionTreeClassifier, ExtraTreeClassifier])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a5131e82712fb9a10246b47b8040fd082" name="a5131e82712fb9a10246b47b8040fd082"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5131e82712fb9a10246b47b8040fd082">&#9670;&#160;</a></span>test_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_error </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  553</span><span class="keyword">def </span>test_error():</div>
<div class="line"><span class="lineno">  554</span>    <span class="comment"># Test that it gives proper exception on deficient input.</span></div>
<div class="line"><span class="lineno">  555</span>    <span class="keywordflow">for</span> name, TreeEstimator <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno">  556</span>        <span class="comment"># predict before fit</span></div>
<div class="line"><span class="lineno">  557</span>        est = TreeEstimator()</div>
<div class="line"><span class="lineno">  558</span>        <span class="keyword">with</span> pytest.raises(NotFittedError):</div>
<div class="line"><span class="lineno">  559</span>            est.predict_proba(X)</div>
<div class="line"><span class="lineno">  560</span> </div>
<div class="line"><span class="lineno">  561</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno">  562</span>        X2 = [[-2, -1, 1]]  <span class="comment"># wrong feature shape for sample</span></div>
<div class="line"><span class="lineno">  563</span>        <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  564</span>            est.predict_proba(X2)</div>
<div class="line"><span class="lineno">  565</span> </div>
<div class="line"><span class="lineno">  566</span>        <span class="comment"># Wrong dimensions</span></div>
<div class="line"><span class="lineno">  567</span>        est = TreeEstimator()</div>
<div class="line"><span class="lineno">  568</span>        y2 = y[:-1]</div>
<div class="line"><span class="lineno">  569</span>        <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  570</span>            est.fit(X, y2)</div>
<div class="line"><span class="lineno">  571</span> </div>
<div class="line"><span class="lineno">  572</span>        <span class="comment"># Test with arrays that are non-contiguous.</span></div>
<div class="line"><span class="lineno">  573</span>        Xf = np.asfortranarray(X)</div>
<div class="line"><span class="lineno">  574</span>        est = TreeEstimator()</div>
<div class="line"><span class="lineno">  575</span>        est.fit(Xf, y)</div>
<div class="line"><span class="lineno">  576</span>        assert_almost_equal(est.predict(T), true_result)</div>
<div class="line"><span class="lineno">  577</span> </div>
<div class="line"><span class="lineno">  578</span>        <span class="comment"># predict before fitting</span></div>
<div class="line"><span class="lineno">  579</span>        est = TreeEstimator()</div>
<div class="line"><span class="lineno">  580</span>        <span class="keyword">with</span> pytest.raises(NotFittedError):</div>
<div class="line"><span class="lineno">  581</span>            est.predict(T)</div>
<div class="line"><span class="lineno">  582</span> </div>
<div class="line"><span class="lineno">  583</span>        <span class="comment"># predict on vector with different dims</span></div>
<div class="line"><span class="lineno">  584</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno">  585</span>        t = np.asarray(T)</div>
<div class="line"><span class="lineno">  586</span>        <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  587</span>            est.predict(t[:, 1:])</div>
<div class="line"><span class="lineno">  588</span> </div>
<div class="line"><span class="lineno">  589</span>        <span class="comment"># wrong sample shape</span></div>
<div class="line"><span class="lineno">  590</span>        Xt = np.array(X).T</div>
<div class="line"><span class="lineno">  591</span> </div>
<div class="line"><span class="lineno">  592</span>        est = TreeEstimator()</div>
<div class="line"><span class="lineno">  593</span>        est.fit(np.dot(X, Xt), y)</div>
<div class="line"><span class="lineno">  594</span>        <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  595</span>            est.predict(X)</div>
<div class="line"><span class="lineno">  596</span>        <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  597</span>            est.apply(X)</div>
<div class="line"><span class="lineno">  598</span> </div>
<div class="line"><span class="lineno">  599</span>        clf = TreeEstimator()</div>
<div class="line"><span class="lineno">  600</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  601</span>        <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  602</span>            clf.predict(Xt)</div>
<div class="line"><span class="lineno">  603</span>        <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  604</span>            clf.apply(Xt)</div>
<div class="line"><span class="lineno">  605</span> </div>
<div class="line"><span class="lineno">  606</span>        <span class="comment"># apply before fitting</span></div>
<div class="line"><span class="lineno">  607</span>        est = TreeEstimator()</div>
<div class="line"><span class="lineno">  608</span>        <span class="keyword">with</span> pytest.raises(NotFittedError):</div>
<div class="line"><span class="lineno">  609</span>            est.apply(T)</div>
<div class="line"><span class="lineno">  610</span> </div>
<div class="line"><span class="lineno">  611</span>    <span class="comment"># non positive target for Poisson splitting Criterion</span></div>
<div class="line"><span class="lineno">  612</span>    est = DecisionTreeRegressor(criterion=<span class="stringliteral">&quot;poisson&quot;</span>)</div>
<div class="line"><span class="lineno">  613</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;y is not positive.*Poisson&quot;</span>):</div>
<div class="line"><span class="lineno">  614</span>        est.fit([[0, 1, 2]], [0, 0, 0])</div>
<div class="line"><span class="lineno">  615</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;Some.*y are negative.*Poisson&quot;</span>):</div>
<div class="line"><span class="lineno">  616</span>        est.fit([[0, 1, 2]], [5, -0.1, 2])</div>
<div class="line"><span class="lineno">  617</span> </div>
<div class="line"><span class="lineno">  618</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a55cfc637af70c967ea2c1fa24b07f8ed" name="a55cfc637af70c967ea2c1fa24b07f8ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a55cfc637af70c967ea2c1fa24b07f8ed">&#9670;&#160;</a></span>test_explicit_sparse_zeros()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_explicit_sparse_zeros </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree_type</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1555</span><span class="keyword">def </span>test_explicit_sparse_zeros(tree_type):</div>
<div class="line"><span class="lineno"> 1556</span>    check_explicit_sparse_zeros(tree_type)</div>
<div class="line"><span class="lineno"> 1557</span> </div>
<div class="line"><span class="lineno"> 1558</span> </div>
<div class="line"><span class="lineno"> 1559</span><span class="preprocessor">@ignore_warnings</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a2b34ae16c8824256fb5f8d63546dd3c9" name="a2b34ae16c8824256fb5f8d63546dd3c9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b34ae16c8824256fb5f8d63546dd3c9">&#9670;&#160;</a></span>test_huge_allocations()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_huge_allocations </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1313</span><span class="keyword">def </span>test_huge_allocations():</div>
<div class="line"><span class="lineno"> 1314</span>    n_bits = 8 * struct.calcsize(<span class="stringliteral">&quot;P&quot;</span>)</div>
<div class="line"><span class="lineno"> 1315</span> </div>
<div class="line"><span class="lineno"> 1316</span>    X = np.random.randn(10, 2)</div>
<div class="line"><span class="lineno"> 1317</span>    y = np.random.randint(0, 2, 10)</div>
<div class="line"><span class="lineno"> 1318</span> </div>
<div class="line"><span class="lineno"> 1319</span>    <span class="comment"># Sanity check: we cannot request more memory than the size of the address</span></div>
<div class="line"><span class="lineno"> 1320</span>    <span class="comment"># space. Currently raises OverflowError.</span></div>
<div class="line"><span class="lineno"> 1321</span>    huge = 2 ** (n_bits + 1)</div>
<div class="line"><span class="lineno"> 1322</span>    clf = DecisionTreeClassifier(splitter=<span class="stringliteral">&quot;best&quot;</span>, max_leaf_nodes=huge)</div>
<div class="line"><span class="lineno"> 1323</span>    <span class="keyword">with</span> pytest.raises(Exception):</div>
<div class="line"><span class="lineno"> 1324</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 1325</span> </div>
<div class="line"><span class="lineno"> 1326</span>    <span class="comment"># Non-regression test: MemoryError used to be dropped by Cython</span></div>
<div class="line"><span class="lineno"> 1327</span>    <span class="comment"># because of missing &quot;except *&quot;.</span></div>
<div class="line"><span class="lineno"> 1328</span>    huge = 2 ** (n_bits - 1) - 1</div>
<div class="line"><span class="lineno"> 1329</span>    clf = DecisionTreeClassifier(splitter=<span class="stringliteral">&quot;best&quot;</span>, max_leaf_nodes=huge)</div>
<div class="line"><span class="lineno"> 1330</span>    <span class="keyword">with</span> pytest.raises(MemoryError):</div>
<div class="line"><span class="lineno"> 1331</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 1332</span> </div>
<div class="line"><span class="lineno"> 1333</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a77e0129331b09da880892265ff5741d0" name="a77e0129331b09da880892265ff5741d0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a77e0129331b09da880892265ff5741d0">&#9670;&#160;</a></span>test_importances()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_importances </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  437</span><span class="keyword">def </span>test_importances():</div>
<div class="line"><span class="lineno">  438</span>    <span class="comment"># Check variable importances.</span></div>
<div class="line"><span class="lineno">  439</span>    X, y = datasets.make_classification(</div>
<div class="line"><span class="lineno">  440</span>        n_samples=5000,</div>
<div class="line"><span class="lineno">  441</span>        n_features=10,</div>
<div class="line"><span class="lineno">  442</span>        n_informative=3,</div>
<div class="line"><span class="lineno">  443</span>        n_redundant=0,</div>
<div class="line"><span class="lineno">  444</span>        n_repeated=0,</div>
<div class="line"><span class="lineno">  445</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  446</span>        random_state=0,</div>
<div class="line"><span class="lineno">  447</span>    )</div>
<div class="line"><span class="lineno">  448</span> </div>
<div class="line"><span class="lineno">  449</span>    <span class="keywordflow">for</span> name, Tree <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno">  450</span>        clf = Tree(random_state=0)</div>
<div class="line"><span class="lineno">  451</span> </div>
<div class="line"><span class="lineno">  452</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  453</span>        importances = clf.feature_importances_</div>
<div class="line"><span class="lineno">  454</span>        n_important = np.sum(importances &gt; 0.1)</div>
<div class="line"><span class="lineno">  455</span> </div>
<div class="line"><span class="lineno">  456</span>        <span class="keyword">assert</span> importances.shape[0] == 10, <span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name)</div>
<div class="line"><span class="lineno">  457</span>        <span class="keyword">assert</span> n_important == 3, <span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name)</div>
<div class="line"><span class="lineno">  458</span> </div>
<div class="line"><span class="lineno">  459</span>    <span class="comment"># Check on iris that importances are the same for all builders</span></div>
<div class="line"><span class="lineno">  460</span>    clf = DecisionTreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno">  461</span>    clf.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  462</span>    clf2 = DecisionTreeClassifier(random_state=0, max_leaf_nodes=len(iris.data))</div>
<div class="line"><span class="lineno">  463</span>    clf2.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  464</span> </div>
<div class="line"><span class="lineno">  465</span>    assert_array_equal(clf.feature_importances_, clf2.feature_importances_)</div>
<div class="line"><span class="lineno">  466</span> </div>
<div class="line"><span class="lineno">  467</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a02e99d9a24e8dd16528fbb6787e5c75f" name="a02e99d9a24e8dd16528fbb6787e5c75f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a02e99d9a24e8dd16528fbb6787e5c75f">&#9670;&#160;</a></span>test_importances_gini_equal_squared_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_importances_gini_equal_squared_error </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  475</span><span class="keyword">def </span>test_importances_gini_equal_squared_error():</div>
<div class="line"><span class="lineno">  476</span>    <span class="comment"># Check that gini is equivalent to squared_error for binary output variable</span></div>
<div class="line"><span class="lineno">  477</span> </div>
<div class="line"><span class="lineno">  478</span>    X, y = datasets.make_classification(</div>
<div class="line"><span class="lineno">  479</span>        n_samples=2000,</div>
<div class="line"><span class="lineno">  480</span>        n_features=10,</div>
<div class="line"><span class="lineno">  481</span>        n_informative=3,</div>
<div class="line"><span class="lineno">  482</span>        n_redundant=0,</div>
<div class="line"><span class="lineno">  483</span>        n_repeated=0,</div>
<div class="line"><span class="lineno">  484</span>        shuffle=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  485</span>        random_state=0,</div>
<div class="line"><span class="lineno">  486</span>    )</div>
<div class="line"><span class="lineno">  487</span> </div>
<div class="line"><span class="lineno">  488</span>    <span class="comment"># The gini index and the mean square error (variance) might differ due</span></div>
<div class="line"><span class="lineno">  489</span>    <span class="comment"># to numerical instability. Since those instabilities mainly occurs at</span></div>
<div class="line"><span class="lineno">  490</span>    <span class="comment"># high tree depth, we restrict this maximal depth.</span></div>
<div class="line"><span class="lineno">  491</span>    clf = DecisionTreeClassifier(criterion=<span class="stringliteral">&quot;gini&quot;</span>, max_depth=5, random_state=0).fit(</div>
<div class="line"><span class="lineno">  492</span>        X, y</div>
<div class="line"><span class="lineno">  493</span>    )</div>
<div class="line"><span class="lineno">  494</span>    reg = DecisionTreeRegressor(</div>
<div class="line"><span class="lineno">  495</span>        criterion=<span class="stringliteral">&quot;squared_error&quot;</span>, max_depth=5, random_state=0</div>
<div class="line"><span class="lineno">  496</span>    ).fit(X, y)</div>
<div class="line"><span class="lineno">  497</span> </div>
<div class="line"><span class="lineno">  498</span>    assert_almost_equal(clf.feature_importances_, reg.feature_importances_)</div>
<div class="line"><span class="lineno">  499</span>    assert_array_equal(clf.tree_.feature, reg.tree_.feature)</div>
<div class="line"><span class="lineno">  500</span>    assert_array_equal(clf.tree_.children_left, reg.tree_.children_left)</div>
<div class="line"><span class="lineno">  501</span>    assert_array_equal(clf.tree_.children_right, reg.tree_.children_right)</div>
<div class="line"><span class="lineno">  502</span>    assert_array_equal(clf.tree_.n_node_samples, reg.tree_.n_node_samples)</div>
<div class="line"><span class="lineno">  503</span> </div>
<div class="line"><span class="lineno">  504</span> </div>
<div class="line"><span class="lineno">  505</span><span class="comment"># TODO(1.3): Remove warning filter</span></div>
<div class="line"><span class="lineno">  506</span><span class="preprocessor">@pytest.mark.filterwarnings(&quot;ignore:`max_features=&#39;auto&#39;` has been deprecated in 1.1&quot;)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a520375ba091f98a989dca7a84228f5c5" name="a520375ba091f98a989dca7a84228f5c5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a520375ba091f98a989dca7a84228f5c5">&#9670;&#160;</a></span>test_importances_raises()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_importances_raises </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  468</span><span class="keyword">def </span>test_importances_raises():</div>
<div class="line"><span class="lineno">  469</span>    <span class="comment"># Check if variable importance before fit raises ValueError.</span></div>
<div class="line"><span class="lineno">  470</span>    clf = DecisionTreeClassifier()</div>
<div class="line"><span class="lineno">  471</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  472</span>        getattr(clf, <span class="stringliteral">&quot;feature_importances_&quot;</span>)</div>
<div class="line"><span class="lineno">  473</span> </div>
<div class="line"><span class="lineno">  474</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abf247a125c58b5a6bb427efed77cf52d" name="abf247a125c58b5a6bb427efed77cf52d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf247a125c58b5a6bb427efed77cf52d">&#9670;&#160;</a></span>test_iris()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_iris </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  307</span><span class="keyword">def </span>test_iris():</div>
<div class="line"><span class="lineno">  308</span>    <span class="comment"># Check consistency on dataset iris.</span></div>
<div class="line"><span class="lineno">  309</span>    <span class="keywordflow">for</span> (name, Tree), criterion <span class="keywordflow">in</span> product(CLF_TREES.items(), CLF_CRITERIONS):</div>
<div class="line"><span class="lineno">  310</span>        clf = Tree(criterion=criterion, random_state=0)</div>
<div class="line"><span class="lineno">  311</span>        clf.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  312</span>        score = accuracy_score(clf.predict(iris.data), iris.target)</div>
<div class="line"><span class="lineno">  313</span>        <span class="keyword">assert</span> score &gt; 0.9, <span class="stringliteral">&quot;Failed with {0}, criterion = {1} and score = {2}&quot;</span>.format(</div>
<div class="line"><span class="lineno">  314</span>            name, criterion, score</div>
<div class="line"><span class="lineno">  315</span>        )</div>
<div class="line"><span class="lineno">  316</span> </div>
<div class="line"><span class="lineno">  317</span>        clf = Tree(criterion=criterion, max_features=2, random_state=0)</div>
<div class="line"><span class="lineno">  318</span>        clf.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  319</span>        score = accuracy_score(clf.predict(iris.data), iris.target)</div>
<div class="line"><span class="lineno">  320</span>        <span class="keyword">assert</span> score &gt; 0.5, <span class="stringliteral">&quot;Failed with {0}, criterion = {1} and score = {2}&quot;</span>.format(</div>
<div class="line"><span class="lineno">  321</span>            name, criterion, score</div>
<div class="line"><span class="lineno">  322</span>        )</div>
<div class="line"><span class="lineno">  323</span> </div>
<div class="line"><span class="lineno">  324</span> </div>
<div class="line"><span class="lineno">  325</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name, Tree&quot;, REG_TREES.items()</span>)</div>
<div class="line"><span class="lineno">  326</span><span class="preprocessor">@pytest.mark.parametrize(&quot;criterion&quot;, REG_CRITERIONS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a31d1afe2a23c432f1bc18d8c4761f902" name="a31d1afe2a23c432f1bc18d8c4761f902"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a31d1afe2a23c432f1bc18d8c4761f902">&#9670;&#160;</a></span>test_mae()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_mae </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check MAE criterion produces correct results on small toy dataset:

------------------
| X | y | weight |
------------------
| 3 | 3 |  0.1   |
| 5 | 3 |  0.3   |
| 8 | 4 |  1.0   |
| 3 | 6 |  0.6   |
| 5 | 7 |  0.3   |
------------------
|sum wt:|  2.3   |
------------------

Because we are dealing with sample weights, we cannot find the median by
simply choosing/averaging the centre value(s), instead we consider the
median where 50% of the cumulative weight is found (in a y sorted data set)
. Therefore with regards to this test data, the cumulative weight is &gt;= 50%
when y = 4.  Therefore:
Median = 4

For all the samples, we can get the total error by summing:
Absolute(Median - y) * weight

I.e., total error = (Absolute(4 - 3) * 0.1)
                  + (Absolute(4 - 3) * 0.3)
                  + (Absolute(4 - 4) * 1.0)
                  + (Absolute(4 - 6) * 0.6)
                  + (Absolute(4 - 7) * 0.3)
                  = 2.5

Impurity = Total error / total weight
         = 2.5 / 2.3
         = 1.08695652173913
         ------------------

From this root node, the next best split is between X values of 3 and 5.
Thus, we have left and right child nodes:

LEFT                    RIGHT
------------------      ------------------
| X | y | weight |      | X | y | weight |
------------------      ------------------
| 3 | 3 |  0.1   |      | 5 | 3 |  0.3   |
| 3 | 6 |  0.6   |      | 8 | 4 |  1.0   |
------------------      | 5 | 7 |  0.3   |
|sum wt:|  0.7   |      ------------------
------------------      |sum wt:|  1.6   |
                        ------------------

Impurity is found in the same way:
Left node Median = 6
Total error = (Absolute(6 - 3) * 0.1)
            + (Absolute(6 - 6) * 0.6)
            = 0.3

Left Impurity = Total error / total weight
        = 0.3 / 0.7
        = 0.428571428571429
        -------------------

Likewise for Right node:
Right node Median = 4
Total error = (Absolute(4 - 3) * 0.3)
            + (Absolute(4 - 4) * 1.0)
            + (Absolute(4 - 7) * 0.3)
            = 1.2

Right Impurity = Total error / total weight
        = 1.2 / 1.6
        = 0.75
        ------
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1689</span><span class="keyword">def </span>test_mae():</div>
<div class="line"><span class="lineno"> 1690</span>    <span class="stringliteral">&quot;&quot;&quot;Check MAE criterion produces correct results on small toy dataset:</span></div>
<div class="line"><span class="lineno"> 1691</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1692</span><span class="stringliteral">    ------------------</span></div>
<div class="line"><span class="lineno"> 1693</span><span class="stringliteral">    | X | y | weight |</span></div>
<div class="line"><span class="lineno"> 1694</span><span class="stringliteral">    ------------------</span></div>
<div class="line"><span class="lineno"> 1695</span><span class="stringliteral">    | 3 | 3 |  0.1   |</span></div>
<div class="line"><span class="lineno"> 1696</span><span class="stringliteral">    | 5 | 3 |  0.3   |</span></div>
<div class="line"><span class="lineno"> 1697</span><span class="stringliteral">    | 8 | 4 |  1.0   |</span></div>
<div class="line"><span class="lineno"> 1698</span><span class="stringliteral">    | 3 | 6 |  0.6   |</span></div>
<div class="line"><span class="lineno"> 1699</span><span class="stringliteral">    | 5 | 7 |  0.3   |</span></div>
<div class="line"><span class="lineno"> 1700</span><span class="stringliteral">    ------------------</span></div>
<div class="line"><span class="lineno"> 1701</span><span class="stringliteral">    |sum wt:|  2.3   |</span></div>
<div class="line"><span class="lineno"> 1702</span><span class="stringliteral">    ------------------</span></div>
<div class="line"><span class="lineno"> 1703</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1704</span><span class="stringliteral">    Because we are dealing with sample weights, we cannot find the median by</span></div>
<div class="line"><span class="lineno"> 1705</span><span class="stringliteral">    simply choosing/averaging the centre value(s), instead we consider the</span></div>
<div class="line"><span class="lineno"> 1706</span><span class="stringliteral">    median where 50% of the cumulative weight is found (in a y sorted data set)</span></div>
<div class="line"><span class="lineno"> 1707</span><span class="stringliteral">    . Therefore with regards to this test data, the cumulative weight is &gt;= 50%</span></div>
<div class="line"><span class="lineno"> 1708</span><span class="stringliteral">    when y = 4.  Therefore:</span></div>
<div class="line"><span class="lineno"> 1709</span><span class="stringliteral">    Median = 4</span></div>
<div class="line"><span class="lineno"> 1710</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1711</span><span class="stringliteral">    For all the samples, we can get the total error by summing:</span></div>
<div class="line"><span class="lineno"> 1712</span><span class="stringliteral">    Absolute(Median - y) * weight</span></div>
<div class="line"><span class="lineno"> 1713</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1714</span><span class="stringliteral">    I.e., total error = (Absolute(4 - 3) * 0.1)</span></div>
<div class="line"><span class="lineno"> 1715</span><span class="stringliteral">                      + (Absolute(4 - 3) * 0.3)</span></div>
<div class="line"><span class="lineno"> 1716</span><span class="stringliteral">                      + (Absolute(4 - 4) * 1.0)</span></div>
<div class="line"><span class="lineno"> 1717</span><span class="stringliteral">                      + (Absolute(4 - 6) * 0.6)</span></div>
<div class="line"><span class="lineno"> 1718</span><span class="stringliteral">                      + (Absolute(4 - 7) * 0.3)</span></div>
<div class="line"><span class="lineno"> 1719</span><span class="stringliteral">                      = 2.5</span></div>
<div class="line"><span class="lineno"> 1720</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1721</span><span class="stringliteral">    Impurity = Total error / total weight</span></div>
<div class="line"><span class="lineno"> 1722</span><span class="stringliteral">             = 2.5 / 2.3</span></div>
<div class="line"><span class="lineno"> 1723</span><span class="stringliteral">             = 1.08695652173913</span></div>
<div class="line"><span class="lineno"> 1724</span><span class="stringliteral">             ------------------</span></div>
<div class="line"><span class="lineno"> 1725</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1726</span><span class="stringliteral">    From this root node, the next best split is between X values of 3 and 5.</span></div>
<div class="line"><span class="lineno"> 1727</span><span class="stringliteral">    Thus, we have left and right child nodes:</span></div>
<div class="line"><span class="lineno"> 1728</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1729</span><span class="stringliteral">    LEFT                    RIGHT</span></div>
<div class="line"><span class="lineno"> 1730</span><span class="stringliteral">    ------------------      ------------------</span></div>
<div class="line"><span class="lineno"> 1731</span><span class="stringliteral">    | X | y | weight |      | X | y | weight |</span></div>
<div class="line"><span class="lineno"> 1732</span><span class="stringliteral">    ------------------      ------------------</span></div>
<div class="line"><span class="lineno"> 1733</span><span class="stringliteral">    | 3 | 3 |  0.1   |      | 5 | 3 |  0.3   |</span></div>
<div class="line"><span class="lineno"> 1734</span><span class="stringliteral">    | 3 | 6 |  0.6   |      | 8 | 4 |  1.0   |</span></div>
<div class="line"><span class="lineno"> 1735</span><span class="stringliteral">    ------------------      | 5 | 7 |  0.3   |</span></div>
<div class="line"><span class="lineno"> 1736</span><span class="stringliteral">    |sum wt:|  0.7   |      ------------------</span></div>
<div class="line"><span class="lineno"> 1737</span><span class="stringliteral">    ------------------      |sum wt:|  1.6   |</span></div>
<div class="line"><span class="lineno"> 1738</span><span class="stringliteral">                            ------------------</span></div>
<div class="line"><span class="lineno"> 1739</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1740</span><span class="stringliteral">    Impurity is found in the same way:</span></div>
<div class="line"><span class="lineno"> 1741</span><span class="stringliteral">    Left node Median = 6</span></div>
<div class="line"><span class="lineno"> 1742</span><span class="stringliteral">    Total error = (Absolute(6 - 3) * 0.1)</span></div>
<div class="line"><span class="lineno"> 1743</span><span class="stringliteral">                + (Absolute(6 - 6) * 0.6)</span></div>
<div class="line"><span class="lineno"> 1744</span><span class="stringliteral">                = 0.3</span></div>
<div class="line"><span class="lineno"> 1745</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1746</span><span class="stringliteral">    Left Impurity = Total error / total weight</span></div>
<div class="line"><span class="lineno"> 1747</span><span class="stringliteral">            = 0.3 / 0.7</span></div>
<div class="line"><span class="lineno"> 1748</span><span class="stringliteral">            = 0.428571428571429</span></div>
<div class="line"><span class="lineno"> 1749</span><span class="stringliteral">            -------------------</span></div>
<div class="line"><span class="lineno"> 1750</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1751</span><span class="stringliteral">    Likewise for Right node:</span></div>
<div class="line"><span class="lineno"> 1752</span><span class="stringliteral">    Right node Median = 4</span></div>
<div class="line"><span class="lineno"> 1753</span><span class="stringliteral">    Total error = (Absolute(4 - 3) * 0.3)</span></div>
<div class="line"><span class="lineno"> 1754</span><span class="stringliteral">                + (Absolute(4 - 4) * 1.0)</span></div>
<div class="line"><span class="lineno"> 1755</span><span class="stringliteral">                + (Absolute(4 - 7) * 0.3)</span></div>
<div class="line"><span class="lineno"> 1756</span><span class="stringliteral">                = 1.2</span></div>
<div class="line"><span class="lineno"> 1757</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1758</span><span class="stringliteral">    Right Impurity = Total error / total weight</span></div>
<div class="line"><span class="lineno"> 1759</span><span class="stringliteral">            = 1.2 / 1.6</span></div>
<div class="line"><span class="lineno"> 1760</span><span class="stringliteral">            = 0.75</span></div>
<div class="line"><span class="lineno"> 1761</span><span class="stringliteral">            ------</span></div>
<div class="line"><span class="lineno"> 1762</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1763</span>    dt_mae = DecisionTreeRegressor(</div>
<div class="line"><span class="lineno"> 1764</span>        random_state=0, criterion=<span class="stringliteral">&quot;absolute_error&quot;</span>, max_leaf_nodes=2</div>
<div class="line"><span class="lineno"> 1765</span>    )</div>
<div class="line"><span class="lineno"> 1766</span> </div>
<div class="line"><span class="lineno"> 1767</span>    <span class="comment"># Test MAE where sample weights are non-uniform (as illustrated above):</span></div>
<div class="line"><span class="lineno"> 1768</span>    dt_mae.fit(</div>
<div class="line"><span class="lineno"> 1769</span>        X=[[3], [5], [3], [8], [5]],</div>
<div class="line"><span class="lineno"> 1770</span>        y=[6, 7, 3, 4, 3],</div>
<div class="line"><span class="lineno"> 1771</span>        sample_weight=[0.6, 0.3, 0.1, 1.0, 0.3],</div>
<div class="line"><span class="lineno"> 1772</span>    )</div>
<div class="line"><span class="lineno"> 1773</span>    assert_allclose(dt_mae.tree_.impurity, [2.5 / 2.3, 0.3 / 0.7, 1.2 / 1.6])</div>
<div class="line"><span class="lineno"> 1774</span>    assert_array_equal(dt_mae.tree_.value.flat, [4.0, 6.0, 4.0])</div>
<div class="line"><span class="lineno"> 1775</span> </div>
<div class="line"><span class="lineno"> 1776</span>    <span class="comment"># Test MAE where all sample weights are uniform:</span></div>
<div class="line"><span class="lineno"> 1777</span>    dt_mae.fit(X=[[3], [5], [3], [8], [5]], y=[6, 7, 3, 4, 3], sample_weight=np.ones(5))</div>
<div class="line"><span class="lineno"> 1778</span>    assert_array_equal(dt_mae.tree_.impurity, [1.4, 1.5, 4.0 / 3.0])</div>
<div class="line"><span class="lineno"> 1779</span>    assert_array_equal(dt_mae.tree_.value.flat, [4, 4.5, 4.0])</div>
<div class="line"><span class="lineno"> 1780</span> </div>
<div class="line"><span class="lineno"> 1781</span>    <span class="comment"># Test MAE where a `sample_weight` is not explicitly provided.</span></div>
<div class="line"><span class="lineno"> 1782</span>    <span class="comment"># This is equivalent to providing uniform sample weights, though</span></div>
<div class="line"><span class="lineno"> 1783</span>    <span class="comment"># the internal logic is different:</span></div>
<div class="line"><span class="lineno"> 1784</span>    dt_mae.fit(X=[[3], [5], [3], [8], [5]], y=[6, 7, 3, 4, 3])</div>
<div class="line"><span class="lineno"> 1785</span>    assert_array_equal(dt_mae.tree_.impurity, [1.4, 1.5, 4.0 / 3.0])</div>
<div class="line"><span class="lineno"> 1786</span>    assert_array_equal(dt_mae.tree_.value.flat, [4, 4.5, 4.0])</div>
<div class="line"><span class="lineno"> 1787</span> </div>
<div class="line"><span class="lineno"> 1788</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a80c1cbf836f4b0013ccb82d6a2455851" name="a80c1cbf836f4b0013ccb82d6a2455851"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80c1cbf836f4b0013ccb82d6a2455851">&#9670;&#160;</a></span>test_max_features()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_max_features </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  507</span><span class="keyword">def </span>test_max_features():</div>
<div class="line"><span class="lineno">  508</span>    <span class="comment"># Check max_features.</span></div>
<div class="line"><span class="lineno">  509</span>    <span class="keywordflow">for</span> name, TreeRegressor <span class="keywordflow">in</span> REG_TREES.items():</div>
<div class="line"><span class="lineno">  510</span>        reg = TreeRegressor(max_features=<span class="stringliteral">&quot;auto&quot;</span>)</div>
<div class="line"><span class="lineno">  511</span>        reg.fit(diabetes.data, diabetes.target)</div>
<div class="line"><span class="lineno">  512</span>        <span class="keyword">assert</span> reg.max_features_ == diabetes.data.shape[1]</div>
<div class="line"><span class="lineno">  513</span> </div>
<div class="line"><span class="lineno">  514</span>    <span class="keywordflow">for</span> name, TreeClassifier <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno">  515</span>        clf = TreeClassifier(max_features=<span class="stringliteral">&quot;auto&quot;</span>)</div>
<div class="line"><span class="lineno">  516</span>        clf.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  517</span>        <span class="keyword">assert</span> clf.max_features_ == 2</div>
<div class="line"><span class="lineno">  518</span> </div>
<div class="line"><span class="lineno">  519</span>    <span class="keywordflow">for</span> name, TreeEstimator <span class="keywordflow">in</span> ALL_TREES.items():</div>
<div class="line"><span class="lineno">  520</span>        est = TreeEstimator(max_features=<span class="stringliteral">&quot;sqrt&quot;</span>)</div>
<div class="line"><span class="lineno">  521</span>        est.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  522</span>        <span class="keyword">assert</span> est.max_features_ == int(np.sqrt(iris.data.shape[1]))</div>
<div class="line"><span class="lineno">  523</span> </div>
<div class="line"><span class="lineno">  524</span>        est = TreeEstimator(max_features=<span class="stringliteral">&quot;log2&quot;</span>)</div>
<div class="line"><span class="lineno">  525</span>        est.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  526</span>        <span class="keyword">assert</span> est.max_features_ == int(np.log2(iris.data.shape[1]))</div>
<div class="line"><span class="lineno">  527</span> </div>
<div class="line"><span class="lineno">  528</span>        est = TreeEstimator(max_features=1)</div>
<div class="line"><span class="lineno">  529</span>        est.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  530</span>        <span class="keyword">assert</span> est.max_features_ == 1</div>
<div class="line"><span class="lineno">  531</span> </div>
<div class="line"><span class="lineno">  532</span>        est = TreeEstimator(max_features=3)</div>
<div class="line"><span class="lineno">  533</span>        est.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  534</span>        <span class="keyword">assert</span> est.max_features_ == 3</div>
<div class="line"><span class="lineno">  535</span> </div>
<div class="line"><span class="lineno">  536</span>        est = TreeEstimator(max_features=0.01)</div>
<div class="line"><span class="lineno">  537</span>        est.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  538</span>        <span class="keyword">assert</span> est.max_features_ == 1</div>
<div class="line"><span class="lineno">  539</span> </div>
<div class="line"><span class="lineno">  540</span>        est = TreeEstimator(max_features=0.5)</div>
<div class="line"><span class="lineno">  541</span>        est.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  542</span>        <span class="keyword">assert</span> est.max_features_ == int(0.5 * iris.data.shape[1])</div>
<div class="line"><span class="lineno">  543</span> </div>
<div class="line"><span class="lineno">  544</span>        est = TreeEstimator(max_features=1.0)</div>
<div class="line"><span class="lineno">  545</span>        est.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  546</span>        <span class="keyword">assert</span> est.max_features_ == iris.data.shape[1]</div>
<div class="line"><span class="lineno">  547</span> </div>
<div class="line"><span class="lineno">  548</span>        est = TreeEstimator(max_features=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  549</span>        est.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  550</span>        <span class="keyword">assert</span> est.max_features_ == iris.data.shape[1]</div>
<div class="line"><span class="lineno">  551</span> </div>
<div class="line"><span class="lineno">  552</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ace858c6ec825a682f976179afe5d834f" name="ace858c6ec825a682f976179afe5d834f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace858c6ec825a682f976179afe5d834f">&#9670;&#160;</a></span>test_max_features_auto_deprecated()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_max_features_auto_deprecated </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2356</span><span class="keyword">def </span>test_max_features_auto_deprecated():</div>
<div class="line"><span class="lineno"> 2357</span>    <span class="keywordflow">for</span> Tree <span class="keywordflow">in</span> CLF_TREES.values():</div>
<div class="line"><span class="lineno"> 2358</span>        tree = Tree(max_features=<span class="stringliteral">&quot;auto&quot;</span>)</div>
<div class="line"><span class="lineno"> 2359</span>        msg = (</div>
<div class="line"><span class="lineno"> 2360</span>            <span class="stringliteral">&quot;`max_features=&#39;auto&#39;` has been deprecated in 1.1 and will be removed in&quot;</span></div>
<div class="line"><span class="lineno"> 2361</span>            <span class="stringliteral">&quot; 1.3. To keep the past behaviour, explicitly set `max_features=&#39;sqrt&#39;`.&quot;</span></div>
<div class="line"><span class="lineno"> 2362</span>        )</div>
<div class="line"><span class="lineno"> 2363</span>        <span class="keyword">with</span> pytest.warns(FutureWarning, match=msg):</div>
<div class="line"><span class="lineno"> 2364</span>            tree.fit(X, y)</div>
<div class="line"><span class="lineno"> 2365</span> </div>
<div class="line"><span class="lineno"> 2366</span>    <span class="keywordflow">for</span> Tree <span class="keywordflow">in</span> REG_TREES.values():</div>
<div class="line"><span class="lineno"> 2367</span>        tree = Tree(max_features=<span class="stringliteral">&quot;auto&quot;</span>)</div>
<div class="line"><span class="lineno"> 2368</span>        msg = (</div>
<div class="line"><span class="lineno"> 2369</span>            <span class="stringliteral">&quot;`max_features=&#39;auto&#39;` has been deprecated in 1.1 and will be removed in&quot;</span></div>
<div class="line"><span class="lineno"> 2370</span>            <span class="stringliteral">&quot; 1.3. To keep the past behaviour, explicitly set `max_features=1.0&#39;`.&quot;</span></div>
<div class="line"><span class="lineno"> 2371</span>        )</div>
<div class="line"><span class="lineno"> 2372</span>        <span class="keyword">with</span> pytest.warns(FutureWarning, match=msg):</div>
<div class="line"><span class="lineno"> 2373</span>            tree.fit(X, y)</div>
</div><!-- fragment -->
</div>
</div>
<a id="aafe47030f0ad10b34f1ff512d635ff9f" name="aafe47030f0ad10b34f1ff512d635ff9f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aafe47030f0ad10b34f1ff512d635ff9f">&#9670;&#160;</a></span>test_max_leaf_nodes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_max_leaf_nodes </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1221</span><span class="keyword">def </span>test_max_leaf_nodes():</div>
<div class="line"><span class="lineno"> 1222</span>    <span class="comment"># Test greedy trees with max_depth + 1 leafs.</span></div>
<div class="line"><span class="lineno"> 1223</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno"> 1224</span>    k = 4</div>
<div class="line"><span class="lineno"> 1225</span>    <span class="keywordflow">for</span> name, TreeEstimator <span class="keywordflow">in</span> ALL_TREES.items():</div>
<div class="line"><span class="lineno"> 1226</span>        est = TreeEstimator(max_depth=<span class="keywordtype">None</span>, max_leaf_nodes=k + 1).fit(X, y)</div>
<div class="line"><span class="lineno"> 1227</span>        <span class="keyword">assert</span> est.get_n_leaves() == k + 1</div>
<div class="line"><span class="lineno"> 1228</span> </div>
<div class="line"><span class="lineno"> 1229</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a14f860fe9f47a13ac4c4b50fb5b920ab" name="a14f860fe9f47a13ac4c4b50fb5b920ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a14f860fe9f47a13ac4c4b50fb5b920ab">&#9670;&#160;</a></span>test_max_leaf_nodes_max_depth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_max_leaf_nodes_max_depth </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1230</span><span class="keyword">def </span>test_max_leaf_nodes_max_depth():</div>
<div class="line"><span class="lineno"> 1231</span>    <span class="comment"># Test precedence of max_leaf_nodes over max_depth.</span></div>
<div class="line"><span class="lineno"> 1232</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno"> 1233</span>    k = 4</div>
<div class="line"><span class="lineno"> 1234</span>    <span class="keywordflow">for</span> name, TreeEstimator <span class="keywordflow">in</span> ALL_TREES.items():</div>
<div class="line"><span class="lineno"> 1235</span>        est = TreeEstimator(max_depth=1, max_leaf_nodes=k).fit(X, y)</div>
<div class="line"><span class="lineno"> 1236</span>        <span class="keyword">assert</span> est.get_depth() == 1</div>
<div class="line"><span class="lineno"> 1237</span> </div>
<div class="line"><span class="lineno"> 1238</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a415f59497dd7851a02ed9f81255283f7" name="a415f59497dd7851a02ed9f81255283f7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a415f59497dd7851a02ed9f81255283f7">&#9670;&#160;</a></span>test_memory_layout()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_memory_layout </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1039</span><span class="keyword">def </span>test_memory_layout():</div>
<div class="line"><span class="lineno"> 1040</span>    <span class="comment"># Check that it works no matter the memory layout</span></div>
<div class="line"><span class="lineno"> 1041</span>    <span class="keywordflow">for</span> (name, TreeEstimator), dtype <span class="keywordflow">in</span> product(</div>
<div class="line"><span class="lineno"> 1042</span>        ALL_TREES.items(), [np.float64, np.float32]</div>
<div class="line"><span class="lineno"> 1043</span>    ):</div>
<div class="line"><span class="lineno"> 1044</span>        est = TreeEstimator(random_state=0)</div>
<div class="line"><span class="lineno"> 1045</span> </div>
<div class="line"><span class="lineno"> 1046</span>        <span class="comment"># Nothing</span></div>
<div class="line"><span class="lineno"> 1047</span>        X = np.asarray(iris.data, dtype=dtype)</div>
<div class="line"><span class="lineno"> 1048</span>        y = iris.target</div>
<div class="line"><span class="lineno"> 1049</span>        assert_array_equal(est.fit(X, y).predict(X), y)</div>
<div class="line"><span class="lineno"> 1050</span> </div>
<div class="line"><span class="lineno"> 1051</span>        <span class="comment"># C-order</span></div>
<div class="line"><span class="lineno"> 1052</span>        X = np.asarray(iris.data, order=<span class="stringliteral">&quot;C&quot;</span>, dtype=dtype)</div>
<div class="line"><span class="lineno"> 1053</span>        y = iris.target</div>
<div class="line"><span class="lineno"> 1054</span>        assert_array_equal(est.fit(X, y).predict(X), y)</div>
<div class="line"><span class="lineno"> 1055</span> </div>
<div class="line"><span class="lineno"> 1056</span>        <span class="comment"># F-order</span></div>
<div class="line"><span class="lineno"> 1057</span>        X = np.asarray(iris.data, order=<span class="stringliteral">&quot;F&quot;</span>, dtype=dtype)</div>
<div class="line"><span class="lineno"> 1058</span>        y = iris.target</div>
<div class="line"><span class="lineno"> 1059</span>        assert_array_equal(est.fit(X, y).predict(X), y)</div>
<div class="line"><span class="lineno"> 1060</span> </div>
<div class="line"><span class="lineno"> 1061</span>        <span class="comment"># Contiguous</span></div>
<div class="line"><span class="lineno"> 1062</span>        X = np.ascontiguousarray(iris.data, dtype=dtype)</div>
<div class="line"><span class="lineno"> 1063</span>        y = iris.target</div>
<div class="line"><span class="lineno"> 1064</span>        assert_array_equal(est.fit(X, y).predict(X), y)</div>
<div class="line"><span class="lineno"> 1065</span> </div>
<div class="line"><span class="lineno"> 1066</span>        <span class="comment"># csr matrix</span></div>
<div class="line"><span class="lineno"> 1067</span>        X = csr_matrix(iris.data, dtype=dtype)</div>
<div class="line"><span class="lineno"> 1068</span>        y = iris.target</div>
<div class="line"><span class="lineno"> 1069</span>        assert_array_equal(est.fit(X, y).predict(X), y)</div>
<div class="line"><span class="lineno"> 1070</span> </div>
<div class="line"><span class="lineno"> 1071</span>        <span class="comment"># csc_matrix</span></div>
<div class="line"><span class="lineno"> 1072</span>        X = csc_matrix(iris.data, dtype=dtype)</div>
<div class="line"><span class="lineno"> 1073</span>        y = iris.target</div>
<div class="line"><span class="lineno"> 1074</span>        assert_array_equal(est.fit(X, y).predict(X), y)</div>
<div class="line"><span class="lineno"> 1075</span> </div>
<div class="line"><span class="lineno"> 1076</span>        <span class="comment"># Strided</span></div>
<div class="line"><span class="lineno"> 1077</span>        X = np.asarray(iris.data[::3], dtype=dtype)</div>
<div class="line"><span class="lineno"> 1078</span>        y = iris.target[::3]</div>
<div class="line"><span class="lineno"> 1079</span>        assert_array_equal(est.fit(X, y).predict(X), y)</div>
<div class="line"><span class="lineno"> 1080</span> </div>
<div class="line"><span class="lineno"> 1081</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a973f9f1b612f1519cb0f604ad4f0d33a" name="a973f9f1b612f1519cb0f604ad4f0d33a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a973f9f1b612f1519cb0f604ad4f0d33a">&#9670;&#160;</a></span>test_min_impurity_decrease()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_min_impurity_decrease </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  824</span><span class="keyword">def </span>test_min_impurity_decrease():</div>
<div class="line"><span class="lineno">  825</span>    <span class="comment"># test if min_impurity_decrease ensure that a split is made only if</span></div>
<div class="line"><span class="lineno">  826</span>    <span class="comment"># if the impurity decrease is at least that value</span></div>
<div class="line"><span class="lineno">  827</span>    X, y = datasets.make_classification(n_samples=10000, random_state=42)</div>
<div class="line"><span class="lineno">  828</span> </div>
<div class="line"><span class="lineno">  829</span>    <span class="comment"># test both DepthFirstTreeBuilder and BestFirstTreeBuilder</span></div>
<div class="line"><span class="lineno">  830</span>    <span class="comment"># by setting max_leaf_nodes</span></div>
<div class="line"><span class="lineno">  831</span>    <span class="keywordflow">for</span> max_leaf_nodes, name <span class="keywordflow">in</span> product((<span class="keywordtype">None</span>, 1000), ALL_TREES.keys()):</div>
<div class="line"><span class="lineno">  832</span>        TreeEstimator = ALL_TREES[name]</div>
<div class="line"><span class="lineno">  833</span> </div>
<div class="line"><span class="lineno">  834</span>        <span class="comment"># Check default value of min_impurity_decrease, 1e-7</span></div>
<div class="line"><span class="lineno">  835</span>        est1 = TreeEstimator(max_leaf_nodes=max_leaf_nodes, random_state=0)</div>
<div class="line"><span class="lineno">  836</span>        <span class="comment"># Check with explicit value of 0.05</span></div>
<div class="line"><span class="lineno">  837</span>        est2 = TreeEstimator(</div>
<div class="line"><span class="lineno">  838</span>            max_leaf_nodes=max_leaf_nodes, min_impurity_decrease=0.05, random_state=0</div>
<div class="line"><span class="lineno">  839</span>        )</div>
<div class="line"><span class="lineno">  840</span>        <span class="comment"># Check with a much lower value of 0.0001</span></div>
<div class="line"><span class="lineno">  841</span>        est3 = TreeEstimator(</div>
<div class="line"><span class="lineno">  842</span>            max_leaf_nodes=max_leaf_nodes, min_impurity_decrease=0.0001, random_state=0</div>
<div class="line"><span class="lineno">  843</span>        )</div>
<div class="line"><span class="lineno">  844</span>        <span class="comment"># Check with a much lower value of 0.1</span></div>
<div class="line"><span class="lineno">  845</span>        est4 = TreeEstimator(</div>
<div class="line"><span class="lineno">  846</span>            max_leaf_nodes=max_leaf_nodes, min_impurity_decrease=0.1, random_state=0</div>
<div class="line"><span class="lineno">  847</span>        )</div>
<div class="line"><span class="lineno">  848</span> </div>
<div class="line"><span class="lineno">  849</span>        <span class="keywordflow">for</span> est, expected_decrease <span class="keywordflow">in</span> (</div>
<div class="line"><span class="lineno">  850</span>            (est1, 1e-7),</div>
<div class="line"><span class="lineno">  851</span>            (est2, 0.05),</div>
<div class="line"><span class="lineno">  852</span>            (est3, 0.0001),</div>
<div class="line"><span class="lineno">  853</span>            (est4, 0.1),</div>
<div class="line"><span class="lineno">  854</span>        ):</div>
<div class="line"><span class="lineno">  855</span>            <span class="keyword">assert</span> (</div>
<div class="line"><span class="lineno">  856</span>                est.min_impurity_decrease &lt;= expected_decrease</div>
<div class="line"><span class="lineno">  857</span>            ), <span class="stringliteral">&quot;Failed, min_impurity_decrease = {0} &gt; {1}&quot;</span>.format(</div>
<div class="line"><span class="lineno">  858</span>                est.min_impurity_decrease, expected_decrease</div>
<div class="line"><span class="lineno">  859</span>            )</div>
<div class="line"><span class="lineno">  860</span>            est.fit(X, y)</div>
<div class="line"><span class="lineno">  861</span>            <span class="keywordflow">for</span> node <span class="keywordflow">in</span> range(est.tree_.node_count):</div>
<div class="line"><span class="lineno">  862</span>                <span class="comment"># If current node is a not leaf node, check if the split was</span></div>
<div class="line"><span class="lineno">  863</span>                <span class="comment"># justified w.r.t the min_impurity_decrease</span></div>
<div class="line"><span class="lineno">  864</span>                <span class="keywordflow">if</span> est.tree_.children_left[node] != TREE_LEAF:</div>
<div class="line"><span class="lineno">  865</span>                    imp_parent = est.tree_.impurity[node]</div>
<div class="line"><span class="lineno">  866</span>                    wtd_n_node = est.tree_.weighted_n_node_samples[node]</div>
<div class="line"><span class="lineno">  867</span> </div>
<div class="line"><span class="lineno">  868</span>                    left = est.tree_.children_left[node]</div>
<div class="line"><span class="lineno">  869</span>                    wtd_n_left = est.tree_.weighted_n_node_samples[left]</div>
<div class="line"><span class="lineno">  870</span>                    imp_left = est.tree_.impurity[left]</div>
<div class="line"><span class="lineno">  871</span>                    wtd_imp_left = wtd_n_left * imp_left</div>
<div class="line"><span class="lineno">  872</span> </div>
<div class="line"><span class="lineno">  873</span>                    right = est.tree_.children_right[node]</div>
<div class="line"><span class="lineno">  874</span>                    wtd_n_right = est.tree_.weighted_n_node_samples[right]</div>
<div class="line"><span class="lineno">  875</span>                    imp_right = est.tree_.impurity[right]</div>
<div class="line"><span class="lineno">  876</span>                    wtd_imp_right = wtd_n_right * imp_right</div>
<div class="line"><span class="lineno">  877</span> </div>
<div class="line"><span class="lineno">  878</span>                    wtd_avg_left_right_imp = wtd_imp_right + wtd_imp_left</div>
<div class="line"><span class="lineno">  879</span>                    wtd_avg_left_right_imp /= wtd_n_node</div>
<div class="line"><span class="lineno">  880</span> </div>
<div class="line"><span class="lineno">  881</span>                    fractional_node_weight = (</div>
<div class="line"><span class="lineno">  882</span>                        est.tree_.weighted_n_node_samples[node] / X.shape[0]</div>
<div class="line"><span class="lineno">  883</span>                    )</div>
<div class="line"><span class="lineno">  884</span> </div>
<div class="line"><span class="lineno">  885</span>                    actual_decrease = fractional_node_weight * (</div>
<div class="line"><span class="lineno">  886</span>                        imp_parent - wtd_avg_left_right_imp</div>
<div class="line"><span class="lineno">  887</span>                    )</div>
<div class="line"><span class="lineno">  888</span> </div>
<div class="line"><span class="lineno">  889</span>                    <span class="keyword">assert</span> (</div>
<div class="line"><span class="lineno">  890</span>                        actual_decrease &gt;= expected_decrease</div>
<div class="line"><span class="lineno">  891</span>                    ), <span class="stringliteral">&quot;Failed with {0} expected min_impurity_decrease={1}&quot;</span>.format(</div>
<div class="line"><span class="lineno">  892</span>                        actual_decrease, expected_decrease</div>
<div class="line"><span class="lineno">  893</span>                    )</div>
<div class="line"><span class="lineno">  894</span> </div>
<div class="line"><span class="lineno">  895</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2e7f854a04b501bec1d94317e23af41d" name="a2e7f854a04b501bec1d94317e23af41d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2e7f854a04b501bec1d94317e23af41d">&#9670;&#160;</a></span>test_min_samples_leaf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_min_samples_leaf </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  650</span><span class="keyword">def </span>test_min_samples_leaf():</div>
<div class="line"><span class="lineno">  651</span>    <span class="comment"># Test if leaves contain more than leaf_count training examples</span></div>
<div class="line"><span class="lineno">  652</span>    X = np.asfortranarray(iris.data, dtype=tree._tree.DTYPE)</div>
<div class="line"><span class="lineno">  653</span>    y = iris.target</div>
<div class="line"><span class="lineno">  654</span> </div>
<div class="line"><span class="lineno">  655</span>    <span class="comment"># test both DepthFirstTreeBuilder and BestFirstTreeBuilder</span></div>
<div class="line"><span class="lineno">  656</span>    <span class="comment"># by setting max_leaf_nodes</span></div>
<div class="line"><span class="lineno">  657</span>    <span class="keywordflow">for</span> max_leaf_nodes, name <span class="keywordflow">in</span> product((<span class="keywordtype">None</span>, 1000), ALL_TREES.keys()):</div>
<div class="line"><span class="lineno">  658</span>        TreeEstimator = ALL_TREES[name]</div>
<div class="line"><span class="lineno">  659</span> </div>
<div class="line"><span class="lineno">  660</span>        <span class="comment"># test integer parameter</span></div>
<div class="line"><span class="lineno">  661</span>        est = TreeEstimator(</div>
<div class="line"><span class="lineno">  662</span>            min_samples_leaf=5, max_leaf_nodes=max_leaf_nodes, random_state=0</div>
<div class="line"><span class="lineno">  663</span>        )</div>
<div class="line"><span class="lineno">  664</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno">  665</span>        out = est.tree_.apply(X)</div>
<div class="line"><span class="lineno">  666</span>        node_counts = np.bincount(out)</div>
<div class="line"><span class="lineno">  667</span>        <span class="comment"># drop inner nodes</span></div>
<div class="line"><span class="lineno">  668</span>        leaf_count = node_counts[node_counts != 0]</div>
<div class="line"><span class="lineno">  669</span>        <span class="keyword">assert</span> np.min(leaf_count) &gt; 4, <span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name)</div>
<div class="line"><span class="lineno">  670</span> </div>
<div class="line"><span class="lineno">  671</span>        <span class="comment"># test float parameter</span></div>
<div class="line"><span class="lineno">  672</span>        est = TreeEstimator(</div>
<div class="line"><span class="lineno">  673</span>            min_samples_leaf=0.1, max_leaf_nodes=max_leaf_nodes, random_state=0</div>
<div class="line"><span class="lineno">  674</span>        )</div>
<div class="line"><span class="lineno">  675</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno">  676</span>        out = est.tree_.apply(X)</div>
<div class="line"><span class="lineno">  677</span>        node_counts = np.bincount(out)</div>
<div class="line"><span class="lineno">  678</span>        <span class="comment"># drop inner nodes</span></div>
<div class="line"><span class="lineno">  679</span>        leaf_count = node_counts[node_counts != 0]</div>
<div class="line"><span class="lineno">  680</span>        <span class="keyword">assert</span> np.min(leaf_count) &gt; 4, <span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name)</div>
<div class="line"><span class="lineno">  681</span> </div>
<div class="line"><span class="lineno">  682</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a004c38aadbea45dd988b72d920858fbe" name="a004c38aadbea45dd988b72d920858fbe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a004c38aadbea45dd988b72d920858fbe">&#9670;&#160;</a></span>test_min_samples_split()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_min_samples_split </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test min_samples_split parameter</pre> <div class="fragment"><div class="line"><span class="lineno">  619</span><span class="keyword">def </span>test_min_samples_split():</div>
<div class="line"><span class="lineno">  620</span>    <span class="stringliteral">&quot;&quot;&quot;Test min_samples_split parameter&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  621</span><span class="stringliteral">    X = np.asfortranarray(iris.data, dtype=tree._tree.DTYPE)</span></div>
<div class="line"><span class="lineno">  622</span><span class="stringliteral">    y = iris.target</span></div>
<div class="line"><span class="lineno">  623</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  624</span><span class="stringliteral">    # test both DepthFirstTreeBuilder and BestFirstTreeBuilder</span></div>
<div class="line"><span class="lineno">  625</span><span class="stringliteral">    # by setting max_leaf_nodes</span></div>
<div class="line"><span class="lineno">  626</span><span class="stringliteral">    for max_leaf_nodes, name in product((None, 1000), ALL_TREES.keys()):</span></div>
<div class="line"><span class="lineno">  627</span><span class="stringliteral">        TreeEstimator = ALL_TREES[name]</span></div>
<div class="line"><span class="lineno">  628</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  629</span><span class="stringliteral">        # test for integer parameter</span></div>
<div class="line"><span class="lineno">  630</span><span class="stringliteral">        est = TreeEstimator(</span></div>
<div class="line"><span class="lineno">  631</span><span class="stringliteral">            min_samples_split=10, max_leaf_nodes=max_leaf_nodes, random_state=0</span></div>
<div class="line"><span class="lineno">  632</span><span class="stringliteral">        )</span></div>
<div class="line"><span class="lineno">  633</span><span class="stringliteral">        est.fit(X, y)</span></div>
<div class="line"><span class="lineno">  634</span><span class="stringliteral">        # count samples on nodes, -1 means it is a leaf</span></div>
<div class="line"><span class="lineno">  635</span><span class="stringliteral">        node_samples = est.tree_.n_node_samples[est.tree_.children_left != -1]</span></div>
<div class="line"><span class="lineno">  636</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  637</span><span class="stringliteral">        assert np.min(node_samples) &gt; 9, &quot;Failed with {0}&quot;.format(name)</span></div>
<div class="line"><span class="lineno">  638</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  639</span><span class="stringliteral">        # test for float parameter</span></div>
<div class="line"><span class="lineno">  640</span><span class="stringliteral">        est = TreeEstimator(</span></div>
<div class="line"><span class="lineno">  641</span><span class="stringliteral">            min_samples_split=0.2, max_leaf_nodes=max_leaf_nodes, random_state=0</span></div>
<div class="line"><span class="lineno">  642</span><span class="stringliteral">        )</span></div>
<div class="line"><span class="lineno">  643</span><span class="stringliteral">        est.fit(X, y)</span></div>
<div class="line"><span class="lineno">  644</span><span class="stringliteral">        # count samples on nodes, -1 means it is a leaf</span></div>
<div class="line"><span class="lineno">  645</span><span class="stringliteral">        node_samples = est.tree_.n_node_samples[est.tree_.children_left != -1]</span></div>
<div class="line"><span class="lineno">  646</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  647</span><span class="stringliteral">        assert np.min(node_samples) &gt; 9, &quot;Failed with {0}&quot;.format(name)</span></div>
<div class="line"><span class="lineno">  648</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  649</span><span class="stringliteral"></span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5f6be513139b600c55e7debeaf81bcbc" name="a5f6be513139b600c55e7debeaf81bcbc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f6be513139b600c55e7debeaf81bcbc">&#9670;&#160;</a></span>test_min_weight_fraction_leaf_on_dense_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_min_weight_fraction_leaf_on_dense_input </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  745</span><span class="keyword">def </span>test_min_weight_fraction_leaf_on_dense_input(name):</div>
<div class="line"><span class="lineno">  746</span>    check_min_weight_fraction_leaf(name, <span class="stringliteral">&quot;iris&quot;</span>)</div>
<div class="line"><span class="lineno">  747</span> </div>
<div class="line"><span class="lineno">  748</span> </div>
<div class="line"><span class="lineno">  749</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, SPARSE_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a3e376ebb5df06a71995ba8f86ccfa336" name="a3e376ebb5df06a71995ba8f86ccfa336"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3e376ebb5df06a71995ba8f86ccfa336">&#9670;&#160;</a></span>test_min_weight_fraction_leaf_on_sparse_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_min_weight_fraction_leaf_on_sparse_input </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  750</span><span class="keyword">def </span>test_min_weight_fraction_leaf_on_sparse_input(name):</div>
<div class="line"><span class="lineno">  751</span>    check_min_weight_fraction_leaf(name, <span class="stringliteral">&quot;multilabel&quot;</span>, <span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  752</span> </div>
<div class="line"><span class="lineno">  753</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a35b9c7562b8ed0fbdcfc4b5eb6f78b9a" name="a35b9c7562b8ed0fbdcfc4b5eb6f78b9a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a35b9c7562b8ed0fbdcfc4b5eb6f78b9a">&#9670;&#160;</a></span>test_min_weight_fraction_leaf_with_min_samples_leaf_on_dense_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_min_weight_fraction_leaf_with_min_samples_leaf_on_dense_input </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  815</span><span class="keyword">def </span>test_min_weight_fraction_leaf_with_min_samples_leaf_on_dense_input(name):</div>
<div class="line"><span class="lineno">  816</span>    check_min_weight_fraction_leaf_with_min_samples_leaf(name, <span class="stringliteral">&quot;iris&quot;</span>)</div>
<div class="line"><span class="lineno">  817</span> </div>
<div class="line"><span class="lineno">  818</span> </div>
<div class="line"><span class="lineno">  819</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, SPARSE_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a01c5a5e0c02013c6b6d91d5c91d6ce75" name="a01c5a5e0c02013c6b6d91d5c91d6ce75"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01c5a5e0c02013c6b6d91d5c91d6ce75">&#9670;&#160;</a></span>test_min_weight_fraction_leaf_with_min_samples_leaf_on_sparse_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_min_weight_fraction_leaf_with_min_samples_leaf_on_sparse_input </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  820</span><span class="keyword">def </span>test_min_weight_fraction_leaf_with_min_samples_leaf_on_sparse_input(name):</div>
<div class="line"><span class="lineno">  821</span>    check_min_weight_fraction_leaf_with_min_samples_leaf(name, <span class="stringliteral">&quot;multilabel&quot;</span>, <span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  822</span> </div>
<div class="line"><span class="lineno">  823</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab02bb58a226a908889acaaa1ad4a9d4f" name="ab02bb58a226a908889acaaa1ad4a9d4f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab02bb58a226a908889acaaa1ad4a9d4f">&#9670;&#160;</a></span>test_min_weight_leaf_split_level()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_min_weight_leaf_split_level </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1604</span><span class="keyword">def </span>test_min_weight_leaf_split_level(name):</div>
<div class="line"><span class="lineno"> 1605</span>    check_min_weight_leaf_split_level(name)</div>
<div class="line"><span class="lineno"> 1606</span> </div>
<div class="line"><span class="lineno"> 1607</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3471fb35958cb6bcba467aa931ef4a52" name="a3471fb35958cb6bcba467aa931ef4a52"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3471fb35958cb6bcba467aa931ef4a52">&#9670;&#160;</a></span>test_multioutput()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_multioutput </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  947</span><span class="keyword">def </span>test_multioutput():</div>
<div class="line"><span class="lineno">  948</span>    <span class="comment"># Check estimators on multi-output problems.</span></div>
<div class="line"><span class="lineno">  949</span>    X = [</div>
<div class="line"><span class="lineno">  950</span>        [-2, -1],</div>
<div class="line"><span class="lineno">  951</span>        [-1, -1],</div>
<div class="line"><span class="lineno">  952</span>        [-1, -2],</div>
<div class="line"><span class="lineno">  953</span>        [1, 1],</div>
<div class="line"><span class="lineno">  954</span>        [1, 2],</div>
<div class="line"><span class="lineno">  955</span>        [2, 1],</div>
<div class="line"><span class="lineno">  956</span>        [-2, 1],</div>
<div class="line"><span class="lineno">  957</span>        [-1, 1],</div>
<div class="line"><span class="lineno">  958</span>        [-1, 2],</div>
<div class="line"><span class="lineno">  959</span>        [2, -1],</div>
<div class="line"><span class="lineno">  960</span>        [1, -1],</div>
<div class="line"><span class="lineno">  961</span>        [1, -2],</div>
<div class="line"><span class="lineno">  962</span>    ]</div>
<div class="line"><span class="lineno">  963</span> </div>
<div class="line"><span class="lineno">  964</span>    y = [</div>
<div class="line"><span class="lineno">  965</span>        [-1, 0],</div>
<div class="line"><span class="lineno">  966</span>        [-1, 0],</div>
<div class="line"><span class="lineno">  967</span>        [-1, 0],</div>
<div class="line"><span class="lineno">  968</span>        [1, 1],</div>
<div class="line"><span class="lineno">  969</span>        [1, 1],</div>
<div class="line"><span class="lineno">  970</span>        [1, 1],</div>
<div class="line"><span class="lineno">  971</span>        [-1, 2],</div>
<div class="line"><span class="lineno">  972</span>        [-1, 2],</div>
<div class="line"><span class="lineno">  973</span>        [-1, 2],</div>
<div class="line"><span class="lineno">  974</span>        [1, 3],</div>
<div class="line"><span class="lineno">  975</span>        [1, 3],</div>
<div class="line"><span class="lineno">  976</span>        [1, 3],</div>
<div class="line"><span class="lineno">  977</span>    ]</div>
<div class="line"><span class="lineno">  978</span> </div>
<div class="line"><span class="lineno">  979</span>    T = [[-1, -1], [1, 1], [-1, 1], [1, -1]]</div>
<div class="line"><span class="lineno">  980</span>    y_true = [[-1, 0], [1, 1], [-1, 2], [1, 3]]</div>
<div class="line"><span class="lineno">  981</span> </div>
<div class="line"><span class="lineno">  982</span>    <span class="comment"># toy classification problem</span></div>
<div class="line"><span class="lineno">  983</span>    <span class="keywordflow">for</span> name, TreeClassifier <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno">  984</span>        clf = TreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno">  985</span>        y_hat = clf.fit(X, y).predict(T)</div>
<div class="line"><span class="lineno">  986</span>        assert_array_equal(y_hat, y_true)</div>
<div class="line"><span class="lineno">  987</span>        <span class="keyword">assert</span> y_hat.shape == (4, 2)</div>
<div class="line"><span class="lineno">  988</span> </div>
<div class="line"><span class="lineno">  989</span>        proba = clf.predict_proba(T)</div>
<div class="line"><span class="lineno">  990</span>        <span class="keyword">assert</span> len(proba) == 2</div>
<div class="line"><span class="lineno">  991</span>        <span class="keyword">assert</span> proba[0].shape == (4, 2)</div>
<div class="line"><span class="lineno">  992</span>        <span class="keyword">assert</span> proba[1].shape == (4, 4)</div>
<div class="line"><span class="lineno">  993</span> </div>
<div class="line"><span class="lineno">  994</span>        log_proba = clf.predict_log_proba(T)</div>
<div class="line"><span class="lineno">  995</span>        <span class="keyword">assert</span> len(log_proba) == 2</div>
<div class="line"><span class="lineno">  996</span>        <span class="keyword">assert</span> log_proba[0].shape == (4, 2)</div>
<div class="line"><span class="lineno">  997</span>        <span class="keyword">assert</span> log_proba[1].shape == (4, 4)</div>
<div class="line"><span class="lineno">  998</span> </div>
<div class="line"><span class="lineno">  999</span>    <span class="comment"># toy regression problem</span></div>
<div class="line"><span class="lineno"> 1000</span>    <span class="keywordflow">for</span> name, TreeRegressor <span class="keywordflow">in</span> REG_TREES.items():</div>
<div class="line"><span class="lineno"> 1001</span>        reg = TreeRegressor(random_state=0)</div>
<div class="line"><span class="lineno"> 1002</span>        y_hat = reg.fit(X, y).predict(T)</div>
<div class="line"><span class="lineno"> 1003</span>        assert_almost_equal(y_hat, y_true)</div>
<div class="line"><span class="lineno"> 1004</span>        <span class="keyword">assert</span> y_hat.shape == (4, 2)</div>
<div class="line"><span class="lineno"> 1005</span> </div>
<div class="line"><span class="lineno"> 1006</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a944a99e4c1469b44841129e08ea0d99f" name="a944a99e4c1469b44841129e08ea0d99f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a944a99e4c1469b44841129e08ea0d99f">&#9670;&#160;</a></span>test_no_sparse_y_support()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_no_sparse_y_support </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1684</span><span class="keyword">def </span>test_no_sparse_y_support(name):</div>
<div class="line"><span class="lineno"> 1685</span>    <span class="comment"># Currently we don&#39;t support sparse y</span></div>
<div class="line"><span class="lineno"> 1686</span>    check_no_sparse_y_support(name)</div>
<div class="line"><span class="lineno"> 1687</span> </div>
<div class="line"><span class="lineno"> 1688</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9769166ca81f2b05958fb558c0e9441a" name="a9769166ca81f2b05958fb558c0e9441a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9769166ca81f2b05958fb558c0e9441a">&#9670;&#160;</a></span>test_numerical_stability()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_numerical_stability </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  412</span><span class="keyword">def </span>test_numerical_stability():</div>
<div class="line"><span class="lineno">  413</span>    <span class="comment"># Check numerical stability.</span></div>
<div class="line"><span class="lineno">  414</span>    X = np.array(</div>
<div class="line"><span class="lineno">  415</span>        [</div>
<div class="line"><span class="lineno">  416</span>            [152.08097839, 140.40744019, 129.75102234, 159.90493774],</div>
<div class="line"><span class="lineno">  417</span>            [142.50700378, 135.81935120, 117.82884979, 162.75781250],</div>
<div class="line"><span class="lineno">  418</span>            [127.28772736, 140.40744019, 129.75102234, 159.90493774],</div>
<div class="line"><span class="lineno">  419</span>            [132.37025452, 143.71923828, 138.35694885, 157.84558105],</div>
<div class="line"><span class="lineno">  420</span>            [103.10237122, 143.71928406, 138.35696411, 157.84559631],</div>
<div class="line"><span class="lineno">  421</span>            [127.71276855, 143.71923828, 138.35694885, 157.84558105],</div>
<div class="line"><span class="lineno">  422</span>            [120.91514587, 140.40744019, 129.75102234, 159.90493774],</div>
<div class="line"><span class="lineno">  423</span>        ]</div>
<div class="line"><span class="lineno">  424</span>    )</div>
<div class="line"><span class="lineno">  425</span> </div>
<div class="line"><span class="lineno">  426</span>    y = np.array([1.0, 0.70209277, 0.53896582, 0.0, 0.90914464, 0.48026916, 0.49622521])</div>
<div class="line"><span class="lineno">  427</span> </div>
<div class="line"><span class="lineno">  428</span>    <span class="keyword">with</span> np.errstate(all=<span class="stringliteral">&quot;raise&quot;</span>):</div>
<div class="line"><span class="lineno">  429</span>        <span class="keywordflow">for</span> name, Tree <span class="keywordflow">in</span> REG_TREES.items():</div>
<div class="line"><span class="lineno">  430</span>            reg = Tree(random_state=0)</div>
<div class="line"><span class="lineno">  431</span>            reg.fit(X, y)</div>
<div class="line"><span class="lineno">  432</span>            reg.fit(X, -y)</div>
<div class="line"><span class="lineno">  433</span>            reg.fit(-X, y)</div>
<div class="line"><span class="lineno">  434</span>            reg.fit(-X, -y)</div>
<div class="line"><span class="lineno">  435</span> </div>
<div class="line"><span class="lineno">  436</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a65076d784348e7234edf453c5a55f838" name="a65076d784348e7234edf453c5a55f838"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65076d784348e7234edf453c5a55f838">&#9670;&#160;</a></span>test_only_constant_features()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_only_constant_features </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1257</span><span class="keyword">def </span>test_only_constant_features():</div>
<div class="line"><span class="lineno"> 1258</span>    random_state = check_random_state(0)</div>
<div class="line"><span class="lineno"> 1259</span>    X = np.zeros((10, 20))</div>
<div class="line"><span class="lineno"> 1260</span>    y = random_state.randint(0, 2, (10,))</div>
<div class="line"><span class="lineno"> 1261</span>    <span class="keywordflow">for</span> name, TreeEstimator <span class="keywordflow">in</span> ALL_TREES.items():</div>
<div class="line"><span class="lineno"> 1262</span>        est = TreeEstimator(random_state=0)</div>
<div class="line"><span class="lineno"> 1263</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno"> 1264</span>        <span class="keyword">assert</span> est.tree_.max_depth == 0</div>
<div class="line"><span class="lineno"> 1265</span> </div>
<div class="line"><span class="lineno"> 1266</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3a4b4d1385da65ce74d1b93f9988953e" name="a3a4b4d1385da65ce74d1b93f9988953e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3a4b4d1385da65ce74d1b93f9988953e">&#9670;&#160;</a></span>test_pickle()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_pickle </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test pickling preserves Tree properties and performance.</pre> <div class="fragment"><div class="line"><span class="lineno">  896</span><span class="keyword">def </span>test_pickle():</div>
<div class="line"><span class="lineno">  897</span>    <span class="stringliteral">&quot;&quot;&quot;Test pickling preserves Tree properties and performance.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  898</span>    <span class="keywordflow">for</span> name, TreeEstimator <span class="keywordflow">in</span> ALL_TREES.items():</div>
<div class="line"><span class="lineno">  899</span>        <span class="keywordflow">if</span> <span class="stringliteral">&quot;Classifier&quot;</span> <span class="keywordflow">in</span> name:</div>
<div class="line"><span class="lineno">  900</span>            X, y = iris.data, iris.target</div>
<div class="line"><span class="lineno">  901</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  902</span>            X, y = diabetes.data, diabetes.target</div>
<div class="line"><span class="lineno">  903</span> </div>
<div class="line"><span class="lineno">  904</span>        est = TreeEstimator(random_state=0)</div>
<div class="line"><span class="lineno">  905</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno">  906</span>        score = est.score(X, y)</div>
<div class="line"><span class="lineno">  907</span> </div>
<div class="line"><span class="lineno">  908</span>        <span class="comment"># test that all class properties are maintained</span></div>
<div class="line"><span class="lineno">  909</span>        attributes = [</div>
<div class="line"><span class="lineno">  910</span>            <span class="stringliteral">&quot;max_depth&quot;</span>,</div>
<div class="line"><span class="lineno">  911</span>            <span class="stringliteral">&quot;node_count&quot;</span>,</div>
<div class="line"><span class="lineno">  912</span>            <span class="stringliteral">&quot;capacity&quot;</span>,</div>
<div class="line"><span class="lineno">  913</span>            <span class="stringliteral">&quot;n_classes&quot;</span>,</div>
<div class="line"><span class="lineno">  914</span>            <span class="stringliteral">&quot;children_left&quot;</span>,</div>
<div class="line"><span class="lineno">  915</span>            <span class="stringliteral">&quot;children_right&quot;</span>,</div>
<div class="line"><span class="lineno">  916</span>            <span class="stringliteral">&quot;n_leaves&quot;</span>,</div>
<div class="line"><span class="lineno">  917</span>            <span class="stringliteral">&quot;feature&quot;</span>,</div>
<div class="line"><span class="lineno">  918</span>            <span class="stringliteral">&quot;threshold&quot;</span>,</div>
<div class="line"><span class="lineno">  919</span>            <span class="stringliteral">&quot;impurity&quot;</span>,</div>
<div class="line"><span class="lineno">  920</span>            <span class="stringliteral">&quot;n_node_samples&quot;</span>,</div>
<div class="line"><span class="lineno">  921</span>            <span class="stringliteral">&quot;weighted_n_node_samples&quot;</span>,</div>
<div class="line"><span class="lineno">  922</span>            <span class="stringliteral">&quot;value&quot;</span>,</div>
<div class="line"><span class="lineno">  923</span>        ]</div>
<div class="line"><span class="lineno">  924</span>        fitted_attribute = {</div>
<div class="line"><span class="lineno">  925</span>            attribute: getattr(est.tree_, attribute) <span class="keywordflow">for</span> attribute <span class="keywordflow">in</span> attributes</div>
<div class="line"><span class="lineno">  926</span>        }</div>
<div class="line"><span class="lineno">  927</span> </div>
<div class="line"><span class="lineno">  928</span>        serialized_object = pickle.dumps(est)</div>
<div class="line"><span class="lineno">  929</span>        est2 = pickle.loads(serialized_object)</div>
<div class="line"><span class="lineno">  930</span>        <span class="keyword">assert</span> type(est2) == est.__class__</div>
<div class="line"><span class="lineno">  931</span> </div>
<div class="line"><span class="lineno">  932</span>        score2 = est2.score(X, y)</div>
<div class="line"><span class="lineno">  933</span>        <span class="keyword">assert</span> (</div>
<div class="line"><span class="lineno">  934</span>            score == score2</div>
<div class="line"><span class="lineno">  935</span>        ), <span class="stringliteral">&quot;Failed to generate same score  after pickling with {0}&quot;</span>.format(name)</div>
<div class="line"><span class="lineno">  936</span>        <span class="keywordflow">for</span> attribute <span class="keywordflow">in</span> fitted_attribute:</div>
<div class="line"><span class="lineno">  937</span>            assert_array_equal(</div>
<div class="line"><span class="lineno">  938</span>                getattr(est2.tree_, attribute),</div>
<div class="line"><span class="lineno">  939</span>                fitted_attribute[attribute],</div>
<div class="line"><span class="lineno">  940</span>                err_msg=(</div>
<div class="line"><span class="lineno">  941</span>                    f<span class="stringliteral">&quot;Failed to generate same attribute {attribute} after pickling with&quot;</span></div>
<div class="line"><span class="lineno">  942</span>                    f<span class="stringliteral">&quot; {name}&quot;</span></div>
<div class="line"><span class="lineno">  943</span>                ),</div>
<div class="line"><span class="lineno">  944</span>            )</div>
<div class="line"><span class="lineno">  945</span> </div>
<div class="line"><span class="lineno">  946</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1da86451d3bc347137c678e4d55acf4e" name="a1da86451d3bc347137c678e4d55acf4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1da86451d3bc347137c678e4d55acf4e">&#9670;&#160;</a></span>test_poisson_vs_mse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_poisson_vs_mse </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 2002</span><span class="keyword">def </span>test_poisson_vs_mse():</div>
<div class="line"><span class="lineno"> 2003</span>    <span class="comment"># For a Poisson distributed target, Poisson loss should give better results</span></div>
<div class="line"><span class="lineno"> 2004</span>    <span class="comment"># than squared error measured in Poisson deviance as metric.</span></div>
<div class="line"><span class="lineno"> 2005</span>    <span class="comment"># We have a similar test, test_poisson(), in</span></div>
<div class="line"><span class="lineno"> 2006</span>    <span class="comment"># sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py</span></div>
<div class="line"><span class="lineno"> 2007</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno"> 2008</span>    n_train, n_test, n_features = 500, 500, 10</div>
<div class="line"><span class="lineno"> 2009</span>    X = datasets.make_low_rank_matrix(</div>
<div class="line"><span class="lineno"> 2010</span>        n_samples=n_train + n_test, n_features=n_features, random_state=rng</div>
<div class="line"><span class="lineno"> 2011</span>    )</div>
<div class="line"><span class="lineno"> 2012</span>    <span class="comment"># We create a log-linear Poisson model and downscale coef as it will get</span></div>
<div class="line"><span class="lineno"> 2013</span>    <span class="comment"># exponentiated.</span></div>
<div class="line"><span class="lineno"> 2014</span>    coef = rng.uniform(low=-2, high=2, size=n_features) / np.max(X, axis=0)</div>
<div class="line"><span class="lineno"> 2015</span>    y = rng.poisson(lam=np.exp(X @ coef))</div>
<div class="line"><span class="lineno"> 2016</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno"> 2017</span>        X, y, test_size=n_test, random_state=rng</div>
<div class="line"><span class="lineno"> 2018</span>    )</div>
<div class="line"><span class="lineno"> 2019</span>    <span class="comment"># We prevent some overfitting by setting min_samples_split=10.</span></div>
<div class="line"><span class="lineno"> 2020</span>    tree_poi = DecisionTreeRegressor(</div>
<div class="line"><span class="lineno"> 2021</span>        criterion=<span class="stringliteral">&quot;poisson&quot;</span>, min_samples_split=10, random_state=rng</div>
<div class="line"><span class="lineno"> 2022</span>    )</div>
<div class="line"><span class="lineno"> 2023</span>    tree_mse = DecisionTreeRegressor(</div>
<div class="line"><span class="lineno"> 2024</span>        criterion=<span class="stringliteral">&quot;squared_error&quot;</span>, min_samples_split=10, random_state=rng</div>
<div class="line"><span class="lineno"> 2025</span>    )</div>
<div class="line"><span class="lineno"> 2026</span> </div>
<div class="line"><span class="lineno"> 2027</span>    tree_poi.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 2028</span>    tree_mse.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 2029</span>    dummy = DummyRegressor(strategy=<span class="stringliteral">&quot;mean&quot;</span>).fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 2030</span> </div>
<div class="line"><span class="lineno"> 2031</span>    <span class="keywordflow">for</span> X, y, val <span class="keywordflow">in</span> [(X_train, y_train, <span class="stringliteral">&quot;train&quot;</span>), (X_test, y_test, <span class="stringliteral">&quot;test&quot;</span>)]:</div>
<div class="line"><span class="lineno"> 2032</span>        metric_poi = mean_poisson_deviance(y, tree_poi.predict(X))</div>
<div class="line"><span class="lineno"> 2033</span>        <span class="comment"># squared_error might produce non-positive predictions =&gt; clip</span></div>
<div class="line"><span class="lineno"> 2034</span>        metric_mse = mean_poisson_deviance(y, np.clip(tree_mse.predict(X), 1e-15, <span class="keywordtype">None</span>))</div>
<div class="line"><span class="lineno"> 2035</span>        metric_dummy = mean_poisson_deviance(y, dummy.predict(X))</div>
<div class="line"><span class="lineno"> 2036</span>        <span class="comment"># As squared_error might correctly predict 0 in train set, its train</span></div>
<div class="line"><span class="lineno"> 2037</span>        <span class="comment"># score can be better than Poisson. This is no longer the case for the</span></div>
<div class="line"><span class="lineno"> 2038</span>        <span class="comment"># test set.</span></div>
<div class="line"><span class="lineno"> 2039</span>        <span class="keywordflow">if</span> val == <span class="stringliteral">&quot;test&quot;</span>:</div>
<div class="line"><span class="lineno"> 2040</span>            <span class="keyword">assert</span> metric_poi &lt; 0.5 * metric_mse</div>
<div class="line"><span class="lineno"> 2041</span>        <span class="keyword">assert</span> metric_poi &lt; 0.75 * metric_dummy</div>
<div class="line"><span class="lineno"> 2042</span> </div>
<div class="line"><span class="lineno"> 2043</span> </div>
<div class="line"><span class="lineno"> 2044</span><span class="preprocessor">@pytest.mark.parametrize(&quot;criterion&quot;, REG_CRITERIONS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ac20c705a6368852f17af3555368fb339" name="ac20c705a6368852f17af3555368fb339"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac20c705a6368852f17af3555368fb339">&#9670;&#160;</a></span>test_poisson_zero_nodes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_poisson_zero_nodes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>seed</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1969</span><span class="keyword">def </span>test_poisson_zero_nodes(seed):</div>
<div class="line"><span class="lineno"> 1970</span>    <span class="comment"># Test that sum(y)=0 and therefore y_pred=0 is forbidden on nodes.</span></div>
<div class="line"><span class="lineno"> 1971</span>    X = [[0, 0], [0, 1], [0, 2], [0, 3], [1, 0], [1, 2], [1, 2], [1, 3]]</div>
<div class="line"><span class="lineno"> 1972</span>    y = [0, 0, 0, 0, 1, 2, 3, 4]</div>
<div class="line"><span class="lineno"> 1973</span>    <span class="comment"># Note that X[:, 0] == 0 is a 100% indicator for y == 0. The tree can</span></div>
<div class="line"><span class="lineno"> 1974</span>    <span class="comment"># easily learn that:</span></div>
<div class="line"><span class="lineno"> 1975</span>    reg = DecisionTreeRegressor(criterion=<span class="stringliteral">&quot;squared_error&quot;</span>, random_state=seed)</div>
<div class="line"><span class="lineno"> 1976</span>    reg.fit(X, y)</div>
<div class="line"><span class="lineno"> 1977</span>    <span class="keyword">assert</span> np.amin(reg.predict(X)) == 0</div>
<div class="line"><span class="lineno"> 1978</span>    <span class="comment"># whereas Poisson must predict strictly positive numbers</span></div>
<div class="line"><span class="lineno"> 1979</span>    reg = DecisionTreeRegressor(criterion=<span class="stringliteral">&quot;poisson&quot;</span>, random_state=seed)</div>
<div class="line"><span class="lineno"> 1980</span>    reg.fit(X, y)</div>
<div class="line"><span class="lineno"> 1981</span>    <span class="keyword">assert</span> np.all(reg.predict(X) &gt; 0)</div>
<div class="line"><span class="lineno"> 1982</span> </div>
<div class="line"><span class="lineno"> 1983</span>    <span class="comment"># Test additional dataset where something could go wrong.</span></div>
<div class="line"><span class="lineno"> 1984</span>    n_features = 10</div>
<div class="line"><span class="lineno"> 1985</span>    X, y = datasets.make_regression(</div>
<div class="line"><span class="lineno"> 1986</span>        effective_rank=n_features * 2 // 3,</div>
<div class="line"><span class="lineno"> 1987</span>        tail_strength=0.6,</div>
<div class="line"><span class="lineno"> 1988</span>        n_samples=1_000,</div>
<div class="line"><span class="lineno"> 1989</span>        n_features=n_features,</div>
<div class="line"><span class="lineno"> 1990</span>        n_informative=n_features * 2 // 3,</div>
<div class="line"><span class="lineno"> 1991</span>        random_state=seed,</div>
<div class="line"><span class="lineno"> 1992</span>    )</div>
<div class="line"><span class="lineno"> 1993</span>    <span class="comment"># some excess zeros</span></div>
<div class="line"><span class="lineno"> 1994</span>    y[(-1 &lt; y) &amp; (y &lt; 0)] = 0</div>
<div class="line"><span class="lineno"> 1995</span>    <span class="comment"># make sure the target is positive</span></div>
<div class="line"><span class="lineno"> 1996</span>    y = np.abs(y)</div>
<div class="line"><span class="lineno"> 1997</span>    reg = DecisionTreeRegressor(criterion=<span class="stringliteral">&quot;poisson&quot;</span>, random_state=seed)</div>
<div class="line"><span class="lineno"> 1998</span>    reg.fit(X, y)</div>
<div class="line"><span class="lineno"> 1999</span>    <span class="keyword">assert</span> np.all(reg.predict(X) &gt; 0)</div>
<div class="line"><span class="lineno"> 2000</span> </div>
<div class="line"><span class="lineno"> 2001</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1cd1b8bbbefb63a84690f13899bba82f" name="a1cd1b8bbbefb63a84690f13899bba82f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1cd1b8bbbefb63a84690f13899bba82f">&#9670;&#160;</a></span>test_probability()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_probability </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  359</span><span class="keyword">def </span>test_probability():</div>
<div class="line"><span class="lineno">  360</span>    <span class="comment"># Predict probabilities using DecisionTreeClassifier.</span></div>
<div class="line"><span class="lineno">  361</span> </div>
<div class="line"><span class="lineno">  362</span>    <span class="keywordflow">for</span> name, Tree <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno">  363</span>        clf = Tree(max_depth=1, max_features=1, random_state=42)</div>
<div class="line"><span class="lineno">  364</span>        clf.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  365</span> </div>
<div class="line"><span class="lineno">  366</span>        prob_predict = clf.predict_proba(iris.data)</div>
<div class="line"><span class="lineno">  367</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  368</span>            np.sum(prob_predict, 1),</div>
<div class="line"><span class="lineno">  369</span>            np.ones(iris.data.shape[0]),</div>
<div class="line"><span class="lineno">  370</span>            err_msg=<span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name),</div>
<div class="line"><span class="lineno">  371</span>        )</div>
<div class="line"><span class="lineno">  372</span>        assert_array_equal(</div>
<div class="line"><span class="lineno">  373</span>            np.argmax(prob_predict, 1),</div>
<div class="line"><span class="lineno">  374</span>            clf.predict(iris.data),</div>
<div class="line"><span class="lineno">  375</span>            err_msg=<span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name),</div>
<div class="line"><span class="lineno">  376</span>        )</div>
<div class="line"><span class="lineno">  377</span>        assert_almost_equal(</div>
<div class="line"><span class="lineno">  378</span>            clf.predict_proba(iris.data),</div>
<div class="line"><span class="lineno">  379</span>            np.exp(clf.predict_log_proba(iris.data)),</div>
<div class="line"><span class="lineno">  380</span>            8,</div>
<div class="line"><span class="lineno">  381</span>            err_msg=<span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name),</div>
<div class="line"><span class="lineno">  382</span>        )</div>
<div class="line"><span class="lineno">  383</span> </div>
<div class="line"><span class="lineno">  384</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4df924af5e55f9b7c904ff015de390d8" name="a4df924af5e55f9b7c904ff015de390d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4df924af5e55f9b7c904ff015de390d8">&#9670;&#160;</a></span>test_prune_single_node_tree()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_prune_single_node_tree </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1871</span><span class="keyword">def </span>test_prune_single_node_tree():</div>
<div class="line"><span class="lineno"> 1872</span>    <span class="comment"># single node tree</span></div>
<div class="line"><span class="lineno"> 1873</span>    clf1 = DecisionTreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno"> 1874</span>    clf1.fit([[0], [1]], [0, 0])</div>
<div class="line"><span class="lineno"> 1875</span> </div>
<div class="line"><span class="lineno"> 1876</span>    <span class="comment"># pruned single node tree</span></div>
<div class="line"><span class="lineno"> 1877</span>    clf2 = DecisionTreeClassifier(random_state=0, ccp_alpha=10)</div>
<div class="line"><span class="lineno"> 1878</span>    clf2.fit([[0], [1]], [0, 0])</div>
<div class="line"><span class="lineno"> 1879</span> </div>
<div class="line"><span class="lineno"> 1880</span>    assert_is_subtree(clf1.tree_, clf2.tree_)</div>
<div class="line"><span class="lineno"> 1881</span> </div>
<div class="line"><span class="lineno"> 1882</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aeee06d4abb24a1409972a857cfeb0ce8" name="aeee06d4abb24a1409972a857cfeb0ce8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeee06d4abb24a1409972a857cfeb0ce8">&#9670;&#160;</a></span>test_prune_tree_classifier_are_subtrees()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_prune_tree_classifier_are_subtrees </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>criterion</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dataset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree_cls</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1839</span><span class="keyword">def </span>test_prune_tree_classifier_are_subtrees(criterion, dataset, tree_cls):</div>
<div class="line"><span class="lineno"> 1840</span>    dataset = DATASETS[dataset]</div>
<div class="line"><span class="lineno"> 1841</span>    X, y = dataset[<span class="stringliteral">&quot;X&quot;</span>], dataset[<span class="stringliteral">&quot;y&quot;</span>]</div>
<div class="line"><span class="lineno"> 1842</span>    est = tree_cls(max_leaf_nodes=20, random_state=0)</div>
<div class="line"><span class="lineno"> 1843</span>    info = est.cost_complexity_pruning_path(X, y)</div>
<div class="line"><span class="lineno"> 1844</span> </div>
<div class="line"><span class="lineno"> 1845</span>    pruning_path = info.ccp_alphas</div>
<div class="line"><span class="lineno"> 1846</span>    impurities = info.impurities</div>
<div class="line"><span class="lineno"> 1847</span>    <span class="keyword">assert</span> np.all(np.diff(pruning_path) &gt;= 0)</div>
<div class="line"><span class="lineno"> 1848</span>    <span class="keyword">assert</span> np.all(np.diff(impurities) &gt;= 0)</div>
<div class="line"><span class="lineno"> 1849</span> </div>
<div class="line"><span class="lineno"> 1850</span>    assert_pruning_creates_subtree(tree_cls, X, y, pruning_path)</div>
<div class="line"><span class="lineno"> 1851</span> </div>
<div class="line"><span class="lineno"> 1852</span> </div>
<div class="line"><span class="lineno"> 1853</span><span class="preprocessor">@pytest.mark.parametrize(&quot;criterion&quot;, REG_CRITERIONS)</span></div>
<div class="line"><span class="lineno"> 1854</span><span class="preprocessor">@pytest.mark.parametrize(&quot;dataset&quot;, DATASETS.keys()</span>)</div>
<div class="line"><span class="lineno"> 1855</span><span class="preprocessor">@pytest.mark.parametrize(&quot;tree_cls&quot;, [DecisionTreeRegressor, ExtraTreeRegressor])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a7c1bdd53ac8d387ed01c64734852f824" name="a7c1bdd53ac8d387ed01c64734852f824"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7c1bdd53ac8d387ed01c64734852f824">&#9670;&#160;</a></span>test_prune_tree_regression_are_subtrees()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_prune_tree_regression_are_subtrees </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>criterion</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dataset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree_cls</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1856</span><span class="keyword">def </span>test_prune_tree_regression_are_subtrees(criterion, dataset, tree_cls):</div>
<div class="line"><span class="lineno"> 1857</span>    dataset = DATASETS[dataset]</div>
<div class="line"><span class="lineno"> 1858</span>    X, y = dataset[<span class="stringliteral">&quot;X&quot;</span>], dataset[<span class="stringliteral">&quot;y&quot;</span>]</div>
<div class="line"><span class="lineno"> 1859</span> </div>
<div class="line"><span class="lineno"> 1860</span>    est = tree_cls(max_leaf_nodes=20, random_state=0)</div>
<div class="line"><span class="lineno"> 1861</span>    info = est.cost_complexity_pruning_path(X, y)</div>
<div class="line"><span class="lineno"> 1862</span> </div>
<div class="line"><span class="lineno"> 1863</span>    pruning_path = info.ccp_alphas</div>
<div class="line"><span class="lineno"> 1864</span>    impurities = info.impurities</div>
<div class="line"><span class="lineno"> 1865</span>    <span class="keyword">assert</span> np.all(np.diff(pruning_path) &gt;= 0)</div>
<div class="line"><span class="lineno"> 1866</span>    <span class="keyword">assert</span> np.all(np.diff(impurities) &gt;= 0)</div>
<div class="line"><span class="lineno"> 1867</span> </div>
<div class="line"><span class="lineno"> 1868</span>    assert_pruning_creates_subtree(tree_cls, X, y, pruning_path)</div>
<div class="line"><span class="lineno"> 1869</span> </div>
<div class="line"><span class="lineno"> 1870</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af32ffe19bf998e941e61e07828d98848" name="af32ffe19bf998e941e61e07828d98848"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af32ffe19bf998e941e61e07828d98848">&#9670;&#160;</a></span>test_public_apply_all_trees()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_public_apply_all_trees </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1625</span><span class="keyword">def </span>test_public_apply_all_trees(name):</div>
<div class="line"><span class="lineno"> 1626</span>    check_public_apply(name)</div>
<div class="line"><span class="lineno"> 1627</span> </div>
<div class="line"><span class="lineno"> 1628</span> </div>
<div class="line"><span class="lineno"> 1629</span><span class="preprocessor">@pytest.mark.parametrize(&quot;name&quot;, SPARSE_TREES)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a20d0b13fee9fb161ed9a1594c16d1aac" name="a20d0b13fee9fb161ed9a1594c16d1aac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20d0b13fee9fb161ed9a1594c16d1aac">&#9670;&#160;</a></span>test_public_apply_sparse_trees()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_public_apply_sparse_trees </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1630</span><span class="keyword">def </span>test_public_apply_sparse_trees(name):</div>
<div class="line"><span class="lineno"> 1631</span>    check_public_apply_sparse(name)</div>
<div class="line"><span class="lineno"> 1632</span> </div>
<div class="line"><span class="lineno"> 1633</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a87db168d8eb431d79a1e6ab566e7561b" name="a87db168d8eb431d79a1e6ab566e7561b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a87db168d8eb431d79a1e6ab566e7561b">&#9670;&#160;</a></span>test_pure_set()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_pure_set </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  396</span><span class="keyword">def </span>test_pure_set():</div>
<div class="line"><span class="lineno">  397</span>    <span class="comment"># Check when y is pure.</span></div>
<div class="line"><span class="lineno">  398</span>    X = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]</div>
<div class="line"><span class="lineno">  399</span>    y = [1, 1, 1, 1, 1, 1]</div>
<div class="line"><span class="lineno">  400</span> </div>
<div class="line"><span class="lineno">  401</span>    <span class="keywordflow">for</span> name, TreeClassifier <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno">  402</span>        clf = TreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno">  403</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  404</span>        assert_array_equal(clf.predict(X), y, err_msg=<span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name))</div>
<div class="line"><span class="lineno">  405</span> </div>
<div class="line"><span class="lineno">  406</span>    <span class="keywordflow">for</span> name, TreeRegressor <span class="keywordflow">in</span> REG_TREES.items():</div>
<div class="line"><span class="lineno">  407</span>        reg = TreeRegressor(random_state=0)</div>
<div class="line"><span class="lineno">  408</span>        reg.fit(X, y)</div>
<div class="line"><span class="lineno">  409</span>        assert_almost_equal(reg.predict(X), y, err_msg=<span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name))</div>
<div class="line"><span class="lineno">  410</span> </div>
<div class="line"><span class="lineno">  411</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad6d2d7300cc94b26692f11c47a71daa1" name="ad6d2d7300cc94b26692f11c47a71daa1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad6d2d7300cc94b26692f11c47a71daa1">&#9670;&#160;</a></span>test_realloc()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_realloc </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1306</span><span class="keyword">def </span>test_realloc():</div>
<div class="line"><span class="lineno"> 1307</span>    <span class="keyword">from</span> sklearn.tree._utils <span class="keyword">import</span> _realloc_test</div>
<div class="line"><span class="lineno"> 1308</span> </div>
<div class="line"><span class="lineno"> 1309</span>    <span class="keyword">with</span> pytest.raises(MemoryError):</div>
<div class="line"><span class="lineno"> 1310</span>        _realloc_test()</div>
<div class="line"><span class="lineno"> 1311</span> </div>
<div class="line"><span class="lineno"> 1312</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="acbae6d17bf807b5f4c8c4e60b0ade633" name="acbae6d17bf807b5f4c8c4e60b0ade633"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acbae6d17bf807b5f4c8c4e60b0ade633">&#9670;&#160;</a></span>test_regression_toy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_regression_toy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Tree</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>criterion</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  265</span><span class="keyword">def </span>test_regression_toy(Tree, criterion):</div>
<div class="line"><span class="lineno">  266</span>    <span class="comment"># Check regression on a toy dataset.</span></div>
<div class="line"><span class="lineno">  267</span>    <span class="keywordflow">if</span> criterion == <span class="stringliteral">&quot;poisson&quot;</span>:</div>
<div class="line"><span class="lineno">  268</span>        <span class="comment"># make target positive while not touching the original y and</span></div>
<div class="line"><span class="lineno">  269</span>        <span class="comment"># true_result</span></div>
<div class="line"><span class="lineno">  270</span>        a = np.abs(np.min(y)) + 1</div>
<div class="line"><span class="lineno">  271</span>        y_train = np.array(y) + a</div>
<div class="line"><span class="lineno">  272</span>        y_test = np.array(true_result) + a</div>
<div class="line"><span class="lineno">  273</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  274</span>        y_train = y</div>
<div class="line"><span class="lineno">  275</span>        y_test = true_result</div>
<div class="line"><span class="lineno">  276</span> </div>
<div class="line"><span class="lineno">  277</span>    reg = Tree(criterion=criterion, random_state=1)</div>
<div class="line"><span class="lineno">  278</span>    reg.fit(X, y_train)</div>
<div class="line"><span class="lineno">  279</span>    assert_allclose(reg.predict(T), y_test)</div>
<div class="line"><span class="lineno">  280</span> </div>
<div class="line"><span class="lineno">  281</span>    clf = Tree(criterion=criterion, max_features=1, random_state=1)</div>
<div class="line"><span class="lineno">  282</span>    clf.fit(X, y_train)</div>
<div class="line"><span class="lineno">  283</span>    assert_allclose(reg.predict(T), y_test)</div>
<div class="line"><span class="lineno">  284</span> </div>
<div class="line"><span class="lineno">  285</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1aada459c3224d9fabff3dc79eebac5d" name="a1aada459c3224d9fabff3dc79eebac5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1aada459c3224d9fabff3dc79eebac5d">&#9670;&#160;</a></span>test_sample_weight()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_sample_weight </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1082</span><span class="keyword">def </span>test_sample_weight():</div>
<div class="line"><span class="lineno"> 1083</span>    <span class="comment"># Check sample weighting.</span></div>
<div class="line"><span class="lineno"> 1084</span>    <span class="comment"># Test that zero-weighted samples are not taken into account</span></div>
<div class="line"><span class="lineno"> 1085</span>    X = np.arange(100)[:, np.newaxis]</div>
<div class="line"><span class="lineno"> 1086</span>    y = np.ones(100)</div>
<div class="line"><span class="lineno"> 1087</span>    y[:50] = 0.0</div>
<div class="line"><span class="lineno"> 1088</span> </div>
<div class="line"><span class="lineno"> 1089</span>    sample_weight = np.ones(100)</div>
<div class="line"><span class="lineno"> 1090</span>    sample_weight[y == 0] = 0.0</div>
<div class="line"><span class="lineno"> 1091</span> </div>
<div class="line"><span class="lineno"> 1092</span>    clf = DecisionTreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno"> 1093</span>    clf.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1094</span>    assert_array_equal(clf.predict(X), np.ones(100))</div>
<div class="line"><span class="lineno"> 1095</span> </div>
<div class="line"><span class="lineno"> 1096</span>    <span class="comment"># Test that low weighted samples are not taken into account at low depth</span></div>
<div class="line"><span class="lineno"> 1097</span>    X = np.arange(200)[:, np.newaxis]</div>
<div class="line"><span class="lineno"> 1098</span>    y = np.zeros(200)</div>
<div class="line"><span class="lineno"> 1099</span>    y[50:100] = 1</div>
<div class="line"><span class="lineno"> 1100</span>    y[100:200] = 2</div>
<div class="line"><span class="lineno"> 1101</span>    X[100:200, 0] = 200</div>
<div class="line"><span class="lineno"> 1102</span> </div>
<div class="line"><span class="lineno"> 1103</span>    sample_weight = np.ones(200)</div>
<div class="line"><span class="lineno"> 1104</span> </div>
<div class="line"><span class="lineno"> 1105</span>    sample_weight[y == 2] = 0.51  <span class="comment"># Samples of class &#39;2&#39; are still weightier</span></div>
<div class="line"><span class="lineno"> 1106</span>    clf = DecisionTreeClassifier(max_depth=1, random_state=0)</div>
<div class="line"><span class="lineno"> 1107</span>    clf.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1108</span>    <span class="keyword">assert</span> clf.tree_.threshold[0] == 149.5</div>
<div class="line"><span class="lineno"> 1109</span> </div>
<div class="line"><span class="lineno"> 1110</span>    sample_weight[y == 2] = 0.5  <span class="comment"># Samples of class &#39;2&#39; are no longer weightier</span></div>
<div class="line"><span class="lineno"> 1111</span>    clf = DecisionTreeClassifier(max_depth=1, random_state=0)</div>
<div class="line"><span class="lineno"> 1112</span>    clf.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1113</span>    <span class="keyword">assert</span> clf.tree_.threshold[0] == 49.5  <span class="comment"># Threshold should have moved</span></div>
<div class="line"><span class="lineno"> 1114</span> </div>
<div class="line"><span class="lineno"> 1115</span>    <span class="comment"># Test that sample weighting is the same as having duplicates</span></div>
<div class="line"><span class="lineno"> 1116</span>    X = iris.data</div>
<div class="line"><span class="lineno"> 1117</span>    y = iris.target</div>
<div class="line"><span class="lineno"> 1118</span> </div>
<div class="line"><span class="lineno"> 1119</span>    duplicates = rng.randint(0, X.shape[0], 100)</div>
<div class="line"><span class="lineno"> 1120</span> </div>
<div class="line"><span class="lineno"> 1121</span>    clf = DecisionTreeClassifier(random_state=1)</div>
<div class="line"><span class="lineno"> 1122</span>    clf.fit(X[duplicates], y[duplicates])</div>
<div class="line"><span class="lineno"> 1123</span> </div>
<div class="line"><span class="lineno"> 1124</span>    sample_weight = np.bincount(duplicates, minlength=X.shape[0])</div>
<div class="line"><span class="lineno"> 1125</span>    clf2 = DecisionTreeClassifier(random_state=1)</div>
<div class="line"><span class="lineno"> 1126</span>    clf2.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1127</span> </div>
<div class="line"><span class="lineno"> 1128</span>    internal = clf.tree_.children_left != tree._tree.TREE_LEAF</div>
<div class="line"><span class="lineno"> 1129</span>    assert_array_almost_equal(</div>
<div class="line"><span class="lineno"> 1130</span>        clf.tree_.threshold[internal], clf2.tree_.threshold[internal]</div>
<div class="line"><span class="lineno"> 1131</span>    )</div>
<div class="line"><span class="lineno"> 1132</span> </div>
<div class="line"><span class="lineno"> 1133</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2c7f03fbc727a15832e070fe0e47d39e" name="a2c7f03fbc727a15832e070fe0e47d39e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2c7f03fbc727a15832e070fe0e47d39e">&#9670;&#160;</a></span>test_sample_weight_invalid()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_sample_weight_invalid </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1134</span><span class="keyword">def </span>test_sample_weight_invalid():</div>
<div class="line"><span class="lineno"> 1135</span>    <span class="comment"># Check sample weighting raises errors.</span></div>
<div class="line"><span class="lineno"> 1136</span>    X = np.arange(100)[:, np.newaxis]</div>
<div class="line"><span class="lineno"> 1137</span>    y = np.ones(100)</div>
<div class="line"><span class="lineno"> 1138</span>    y[:50] = 0.0</div>
<div class="line"><span class="lineno"> 1139</span> </div>
<div class="line"><span class="lineno"> 1140</span>    clf = DecisionTreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno"> 1141</span> </div>
<div class="line"><span class="lineno"> 1142</span>    sample_weight = np.random.rand(100, 1)</div>
<div class="line"><span class="lineno"> 1143</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno"> 1144</span>        clf.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1145</span> </div>
<div class="line"><span class="lineno"> 1146</span>    sample_weight = np.array(0)</div>
<div class="line"><span class="lineno"> 1147</span>    expected_err = <span class="stringliteral">r&quot;Singleton.* cannot be considered a valid collection&quot;</span></div>
<div class="line"><span class="lineno"> 1148</span>    <span class="keyword">with</span> pytest.raises(TypeError, match=expected_err):</div>
<div class="line"><span class="lineno"> 1149</span>        clf.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1150</span> </div>
<div class="line"><span class="lineno"> 1151</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6a50fdd9c117496277a9ae1e1942d68b" name="a6a50fdd9c117496277a9ae1e1942d68b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6a50fdd9c117496277a9ae1e1942d68b">&#9670;&#160;</a></span>test_sparse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_sparse </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dataset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>check</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1480</span><span class="keyword">def </span>test_sparse(tree_type, dataset, check):</div>
<div class="line"><span class="lineno"> 1481</span>    check(tree_type, dataset)</div>
<div class="line"><span class="lineno"> 1482</span> </div>
<div class="line"><span class="lineno"> 1483</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a320204ebd54116fa049936e126c77546" name="a320204ebd54116fa049936e126c77546"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a320204ebd54116fa049936e126c77546">&#9670;&#160;</a></span>test_sparse_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_sparse_input </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dataset</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1391</span><span class="keyword">def </span>test_sparse_input(tree_type, dataset):</div>
<div class="line"><span class="lineno"> 1392</span>    max_depth = 3 <span class="keywordflow">if</span> dataset == <span class="stringliteral">&quot;digits&quot;</span> <span class="keywordflow">else</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1393</span>    check_sparse_input(tree_type, dataset, max_depth)</div>
<div class="line"><span class="lineno"> 1394</span> </div>
<div class="line"><span class="lineno"> 1395</span> </div>
<div class="line"><span class="lineno"> 1396</span><span class="preprocessor">@pytest.mark.parametrize(&quot;tree_type&quot;, sorted(set(SPARSE_TREES)</span>.intersection(REG_TREES)))</div>
<div class="line"><span class="lineno"> 1397</span><span class="preprocessor">@pytest.mark.parametrize(&quot;dataset&quot;, [&quot;diabetes&quot;, &quot;reg_small&quot;])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ae54aa93b2d9fac458bb5bbd3770a82d7" name="ae54aa93b2d9fac458bb5bbd3770a82d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae54aa93b2d9fac458bb5bbd3770a82d7">&#9670;&#160;</a></span>test_sparse_input_reg_trees()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_sparse_input_reg_trees </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tree_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dataset</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1398</span><span class="keyword">def </span>test_sparse_input_reg_trees(tree_type, dataset):</div>
<div class="line"><span class="lineno"> 1399</span>    <span class="comment"># Due to numerical instability of MSE and too strict test, we limit the</span></div>
<div class="line"><span class="lineno"> 1400</span>    <span class="comment"># maximal depth</span></div>
<div class="line"><span class="lineno"> 1401</span>    check_sparse_input(tree_type, dataset, 2)</div>
<div class="line"><span class="lineno"> 1402</span> </div>
<div class="line"><span class="lineno"> 1403</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a094a53a595c78efebd74a80985dcd237" name="a094a53a595c78efebd74a80985dcd237"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a094a53a595c78efebd74a80985dcd237">&#9670;&#160;</a></span>test_unbalanced_iris()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_unbalanced_iris </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1027</span><span class="keyword">def </span>test_unbalanced_iris():</div>
<div class="line"><span class="lineno"> 1028</span>    <span class="comment"># Check class rebalancing.</span></div>
<div class="line"><span class="lineno"> 1029</span>    unbalanced_X = iris.data[:125]</div>
<div class="line"><span class="lineno"> 1030</span>    unbalanced_y = iris.target[:125]</div>
<div class="line"><span class="lineno"> 1031</span>    sample_weight = compute_sample_weight(<span class="stringliteral">&quot;balanced&quot;</span>, unbalanced_y)</div>
<div class="line"><span class="lineno"> 1032</span> </div>
<div class="line"><span class="lineno"> 1033</span>    <span class="keywordflow">for</span> name, TreeClassifier <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno"> 1034</span>        clf = TreeClassifier(random_state=0)</div>
<div class="line"><span class="lineno"> 1035</span>        clf.fit(unbalanced_X, unbalanced_y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1036</span>        assert_almost_equal(clf.predict(unbalanced_X), unbalanced_y)</div>
<div class="line"><span class="lineno"> 1037</span> </div>
<div class="line"><span class="lineno"> 1038</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aefbb6d1db4fa4591e1d4499bea35b020" name="aefbb6d1db4fa4591e1d4499bea35b020"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aefbb6d1db4fa4591e1d4499bea35b020">&#9670;&#160;</a></span>test_weighted_classification_toy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_weighted_classification_toy </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  251</span><span class="keyword">def </span>test_weighted_classification_toy():</div>
<div class="line"><span class="lineno">  252</span>    <span class="comment"># Check classification on a weighted toy dataset.</span></div>
<div class="line"><span class="lineno">  253</span>    <span class="keywordflow">for</span> name, Tree <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno">  254</span>        clf = Tree(random_state=0)</div>
<div class="line"><span class="lineno">  255</span> </div>
<div class="line"><span class="lineno">  256</span>        clf.fit(X, y, sample_weight=np.ones(len(X)))</div>
<div class="line"><span class="lineno">  257</span>        assert_array_equal(clf.predict(T), true_result, <span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name))</div>
<div class="line"><span class="lineno">  258</span> </div>
<div class="line"><span class="lineno">  259</span>        clf.fit(X, y, sample_weight=np.full(len(X), 0.5))</div>
<div class="line"><span class="lineno">  260</span>        assert_array_equal(clf.predict(T), true_result, <span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name))</div>
<div class="line"><span class="lineno">  261</span> </div>
<div class="line"><span class="lineno">  262</span> </div>
<div class="line"><span class="lineno">  263</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Tree&quot;, REG_TREES.values()</span>)</div>
<div class="line"><span class="lineno">  264</span><span class="preprocessor">@pytest.mark.parametrize(&quot;criterion&quot;, REG_CRITERIONS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a374939bc2a0a2922c1c7a36d668e4f28" name="a374939bc2a0a2922c1c7a36d668e4f28"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a374939bc2a0a2922c1c7a36d668e4f28">&#9670;&#160;</a></span>test_with_only_one_non_constant_features()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_with_only_one_non_constant_features </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1281</span><span class="keyword">def </span>test_with_only_one_non_constant_features():</div>
<div class="line"><span class="lineno"> 1282</span>    X = np.hstack([np.array([[1.0], [1.0], [0.0], [0.0]]), np.zeros((4, 1000))])</div>
<div class="line"><span class="lineno"> 1283</span> </div>
<div class="line"><span class="lineno"> 1284</span>    y = np.array([0.0, 1.0, 0.0, 1.0])</div>
<div class="line"><span class="lineno"> 1285</span>    <span class="keywordflow">for</span> name, TreeEstimator <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno"> 1286</span>        est = TreeEstimator(random_state=0, max_features=1)</div>
<div class="line"><span class="lineno"> 1287</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno"> 1288</span>        <span class="keyword">assert</span> est.tree_.max_depth == 1</div>
<div class="line"><span class="lineno"> 1289</span>        assert_array_equal(est.predict_proba(X), np.full((4, 2), 0.5))</div>
<div class="line"><span class="lineno"> 1290</span> </div>
<div class="line"><span class="lineno"> 1291</span>    <span class="keywordflow">for</span> name, TreeEstimator <span class="keywordflow">in</span> REG_TREES.items():</div>
<div class="line"><span class="lineno"> 1292</span>        est = TreeEstimator(random_state=0, max_features=1)</div>
<div class="line"><span class="lineno"> 1293</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno"> 1294</span>        <span class="keyword">assert</span> est.tree_.max_depth == 1</div>
<div class="line"><span class="lineno"> 1295</span>        assert_array_equal(est.predict(X), np.full((4,), 0.5))</div>
<div class="line"><span class="lineno"> 1296</span> </div>
<div class="line"><span class="lineno"> 1297</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aedda82194fbccbc27a9690ec6885923d" name="aedda82194fbccbc27a9690ec6885923d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aedda82194fbccbc27a9690ec6885923d">&#9670;&#160;</a></span>test_xor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.test_xor </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  286</span><span class="keyword">def </span>test_xor():</div>
<div class="line"><span class="lineno">  287</span>    <span class="comment"># Check on a XOR problem</span></div>
<div class="line"><span class="lineno">  288</span>    y = np.zeros((10, 10))</div>
<div class="line"><span class="lineno">  289</span>    y[:5, :5] = 1</div>
<div class="line"><span class="lineno">  290</span>    y[5:, 5:] = 1</div>
<div class="line"><span class="lineno">  291</span> </div>
<div class="line"><span class="lineno">  292</span>    gridx, gridy = np.indices(y.shape)</div>
<div class="line"><span class="lineno">  293</span> </div>
<div class="line"><span class="lineno">  294</span>    X = np.vstack([gridx.ravel(), gridy.ravel()]).T</div>
<div class="line"><span class="lineno">  295</span>    y = y.ravel()</div>
<div class="line"><span class="lineno">  296</span> </div>
<div class="line"><span class="lineno">  297</span>    <span class="keywordflow">for</span> name, Tree <span class="keywordflow">in</span> CLF_TREES.items():</div>
<div class="line"><span class="lineno">  298</span>        clf = Tree(random_state=0)</div>
<div class="line"><span class="lineno">  299</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  300</span>        <span class="keyword">assert</span> clf.score(X, y) == 1.0, <span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name)</div>
<div class="line"><span class="lineno">  301</span> </div>
<div class="line"><span class="lineno">  302</span>        clf = Tree(random_state=0, max_features=1)</div>
<div class="line"><span class="lineno">  303</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  304</span>        <span class="keyword">assert</span> clf.score(X, y) == 1.0, <span class="stringliteral">&quot;Failed with {0}&quot;</span>.format(name)</div>
<div class="line"><span class="lineno">  305</span> </div>
<div class="line"><span class="lineno">  306</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a8e6a2d744db150e244243332d134d14e" name="a8e6a2d744db150e244243332d134d14e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e6a2d744db150e244243332d134d14e">&#9670;&#160;</a></span>ALL_TREES</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">dict sklearn.tree.tests.test_tree.ALL_TREES = dict()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac0c7d5516fc331c219c8e12dbb7ef232" name="ac0c7d5516fc331c219c8e12dbb7ef232"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac0c7d5516fc331c219c8e12dbb7ef232">&#9670;&#160;</a></span>CLF_CRITERIONS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple sklearn.tree.tests.test_tree.CLF_CRITERIONS = (&quot;gini&quot;, &quot;log_loss&quot;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a65b0f09bdf5886a5e38c16b0ecbeceba" name="a65b0f09bdf5886a5e38c16b0ecbeceba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65b0f09bdf5886a5e38c16b0ecbeceba">&#9670;&#160;</a></span>CLF_TREES</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">dict sklearn.tree.tests.test_tree.CLF_TREES</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  {</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;DecisionTreeClassifier&quot;</span>: DecisionTreeClassifier,</div>
<div class="line"><span class="lineno">    3</span>    <span class="stringliteral">&quot;ExtraTreeClassifier&quot;</span>: ExtraTreeClassifier,</div>
<div class="line"><span class="lineno">    4</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a03aec4c1890309dda08ffc9457f5230b" name="a03aec4c1890309dda08ffc9457f5230b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a03aec4c1890309dda08ffc9457f5230b">&#9670;&#160;</a></span>data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a703b14ac9a01489bf499dda532508e37" name="a703b14ac9a01489bf499dda532508e37"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a703b14ac9a01489bf499dda532508e37">&#9670;&#160;</a></span>DATASETS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">dict sklearn.tree.tests.test_tree.DATASETS</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  {</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;iris&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: iris.data, <span class="stringliteral">&quot;y&quot;</span>: iris.target},</div>
<div class="line"><span class="lineno">    3</span>    <span class="stringliteral">&quot;diabetes&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: diabetes.data, <span class="stringliteral">&quot;y&quot;</span>: diabetes.target},</div>
<div class="line"><span class="lineno">    4</span>    <span class="stringliteral">&quot;digits&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: digits.data, <span class="stringliteral">&quot;y&quot;</span>: digits.target},</div>
<div class="line"><span class="lineno">    5</span>    <span class="stringliteral">&quot;toy&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: X, <span class="stringliteral">&quot;y&quot;</span>: y},</div>
<div class="line"><span class="lineno">    6</span>    <span class="stringliteral">&quot;clf_small&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: X_small, <span class="stringliteral">&quot;y&quot;</span>: y_small},</div>
<div class="line"><span class="lineno">    7</span>    <span class="stringliteral">&quot;reg_small&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: X_small, <span class="stringliteral">&quot;y&quot;</span>: y_small_reg},</div>
<div class="line"><span class="lineno">    8</span>    <span class="stringliteral">&quot;multilabel&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: X_multilabel, <span class="stringliteral">&quot;y&quot;</span>: y_multilabel},</div>
<div class="line"><span class="lineno">    9</span>    <span class="stringliteral">&quot;sparse-pos&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: X_sparse_pos, <span class="stringliteral">&quot;y&quot;</span>: y_random},</div>
<div class="line"><span class="lineno">   10</span>    <span class="stringliteral">&quot;sparse-neg&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: -X_sparse_pos, <span class="stringliteral">&quot;y&quot;</span>: y_random},</div>
<div class="line"><span class="lineno">   11</span>    <span class="stringliteral">&quot;sparse-mix&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: X_sparse_mix, <span class="stringliteral">&quot;y&quot;</span>: y_random},</div>
<div class="line"><span class="lineno">   12</span>    <span class="stringliteral">&quot;zeros&quot;</span>: {<span class="stringliteral">&quot;X&quot;</span>: np.zeros((20, 3)), <span class="stringliteral">&quot;y&quot;</span>: y_random},</div>
<div class="line"><span class="lineno">   13</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a275d2c78e71a2806011bd8b5eaf6577c" name="a275d2c78e71a2806011bd8b5eaf6577c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a275d2c78e71a2806011bd8b5eaf6577c">&#9670;&#160;</a></span>diabetes</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.diabetes = datasets.load_diabetes()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a89ae7de536e1b244bf989a22df9b3091" name="a89ae7de536e1b244bf989a22df9b3091"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a89ae7de536e1b244bf989a22df9b3091">&#9670;&#160;</a></span>digits</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.digits = datasets.load_digits()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a123227057b7d0df52753df6008274dc3" name="a123227057b7d0df52753df6008274dc3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a123227057b7d0df52753df6008274dc3">&#9670;&#160;</a></span>iris</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.iris = datasets.load_iris()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acd4a764a604accf7c5583890acf1642a" name="acd4a764a604accf7c5583890acf1642a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd4a764a604accf7c5583890acf1642a">&#9670;&#160;</a></span>n_features</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.n_features</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ade3ceeb48ad69723503620d6fc3a7882" name="ade3ceeb48ad69723503620d6fc3a7882"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade3ceeb48ad69723503620d6fc3a7882">&#9670;&#160;</a></span>n_samples</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.n_samples</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a09d9b810e9f94b9abf13833ba86e4ff4" name="a09d9b810e9f94b9abf13833ba86e4ff4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a09d9b810e9f94b9abf13833ba86e4ff4">&#9670;&#160;</a></span>perm</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.perm = rng.permutation(iris.target.size)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa4d8e42c19195de8407ea5ffdf742db2" name="aa4d8e42c19195de8407ea5ffdf742db2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa4d8e42c19195de8407ea5ffdf742db2">&#9670;&#160;</a></span>random_state</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.random_state = check_random_state(0)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a73e7394ed027eaab3306f543937602da" name="a73e7394ed027eaab3306f543937602da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a73e7394ed027eaab3306f543937602da">&#9670;&#160;</a></span>REG_CRITERIONS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple sklearn.tree.tests.test_tree.REG_CRITERIONS = (&quot;squared_error&quot;, &quot;absolute_error&quot;, &quot;friedman_mse&quot;, &quot;poisson&quot;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a94cf81e208b61f2814ddf5b46b8d6534" name="a94cf81e208b61f2814ddf5b46b8d6534"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a94cf81e208b61f2814ddf5b46b8d6534">&#9670;&#160;</a></span>REG_TREES</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">dict sklearn.tree.tests.test_tree.REG_TREES</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  {</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;DecisionTreeRegressor&quot;</span>: DecisionTreeRegressor,</div>
<div class="line"><span class="lineno">    3</span>    <span class="stringliteral">&quot;ExtraTreeRegressor&quot;</span>: ExtraTreeRegressor,</div>
<div class="line"><span class="lineno">    4</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae5d2285e12a4340cee99d72be75411a4" name="ae5d2285e12a4340cee99d72be75411a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5d2285e12a4340cee99d72be75411a4">&#9670;&#160;</a></span>rng</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.rng = np.random.RandomState(1)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a433d83a178acb87a185ba7cdab6d0865" name="a433d83a178acb87a185ba7cdab6d0865"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a433d83a178acb87a185ba7cdab6d0865">&#9670;&#160;</a></span>SPARSE_TREES</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.tree.tests.test_tree.SPARSE_TREES</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  [</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;DecisionTreeClassifier&quot;</span>,</div>
<div class="line"><span class="lineno">    3</span>    <span class="stringliteral">&quot;DecisionTreeRegressor&quot;</span>,</div>
<div class="line"><span class="lineno">    4</span>    <span class="stringliteral">&quot;ExtraTreeClassifier&quot;</span>,</div>
<div class="line"><span class="lineno">    5</span>    <span class="stringliteral">&quot;ExtraTreeRegressor&quot;</span>,</div>
<div class="line"><span class="lineno">    6</span>]</div>
</div><!-- fragment -->
</div>
</div>
<a id="a7556c3bfeab511b95be9efe79c476814" name="a7556c3bfeab511b95be9efe79c476814"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7556c3bfeab511b95be9efe79c476814">&#9670;&#160;</a></span>T</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.tree.tests.test_tree.T = [[-1, -1], [2, 2], [3, 2]]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2c1dba4e588d0af9d31cbf427823647a" name="a2c1dba4e588d0af9d31cbf427823647a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2c1dba4e588d0af9d31cbf427823647a">&#9670;&#160;</a></span>target</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.target</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a23f66f07bb7a2371327d858fe8bf9f57" name="a23f66f07bb7a2371327d858fe8bf9f57"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a23f66f07bb7a2371327d858fe8bf9f57">&#9670;&#160;</a></span>true_result</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.tree.tests.test_tree.true_result = [-1, 1, 1]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0de06db865b18c30d3c9c86a3a05e6b9" name="a0de06db865b18c30d3c9c86a3a05e6b9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0de06db865b18c30d3c9c86a3a05e6b9">&#9670;&#160;</a></span>X</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.tree.tests.test_tree.X = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae000948545103c5a188392852c6c70fb" name="ae000948545103c5a188392852c6c70fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae000948545103c5a188392852c6c70fb">&#9670;&#160;</a></span>X_multilabel</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.X_multilabel</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acf23fc59e312a4d66ad97f6de3fd8d5b" name="acf23fc59e312a4d66ad97f6de3fd8d5b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acf23fc59e312a4d66ad97f6de3fd8d5b">&#9670;&#160;</a></span>X_small</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.X_small</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  np.array(</div>
<div class="line"><span class="lineno">    2</span>    [</div>
<div class="line"><span class="lineno">    3</span>        [0, 0, 4, 0, 0, 0, 1, -14, 0, -4, 0, 0, 0, 0],</div>
<div class="line"><span class="lineno">    4</span>        [0, 0, 5, 3, 0, -4, 0, 0, 1, -5, 0.2, 0, 4, 1],</div>
<div class="line"><span class="lineno">    5</span>        [-1, -1, 0, 0, -4.5, 0, 0, 2.1, 1, 0, 0, -4.5, 0, 1],</div>
<div class="line"><span class="lineno">    6</span>        [-1, -1, 0, -1.2, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 1],</div>
<div class="line"><span class="lineno">    7</span>        [-1, -1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1],</div>
<div class="line"><span class="lineno">    8</span>        [-1, -2, 0, 4, -3, 10, 4, 0, -3.2, 0, 4, 3, -4, 1],</div>
<div class="line"><span class="lineno">    9</span>        [2.11, 0, -6, -0.5, 0, 11, 0, 0, -3.2, 6, 0.5, 0, -3, 1],</div>
<div class="line"><span class="lineno">   10</span>        [2.11, 0, -6, -0.5, 0, 11, 0, 0, -3.2, 6, 0, 0, -2, 1],</div>
<div class="line"><span class="lineno">   11</span>        [2.11, 8, -6, -0.5, 0, 11, 0, 0, -3.2, 6, 0, 0, -2, 1],</div>
<div class="line"><span class="lineno">   12</span>        [2.11, 8, -6, -0.5, 0, 11, 0, 0, -3.2, 6, 0.5, 0, -1, 0],</div>
<div class="line"><span class="lineno">   13</span>        [2, 8, 5, 1, 0.5, -4, 10, 0, 1, -5, 3, 0, 2, 0],</div>
<div class="line"><span class="lineno">   14</span>        [2, 0, 1, 1, 1, -1, 1, 0, 0, -2, 3, 0, 1, 0],</div>
<div class="line"><span class="lineno">   15</span>        [2, 0, 1, 2, 3, -1, 10, 2, 0, -1, 1, 2, 2, 0],</div>
<div class="line"><span class="lineno">   16</span>        [1, 1, 0, 2, 2, -1, 1, 2, 0, -5, 1, 2, 3, 0],</div>
<div class="line"><span class="lineno">   17</span>        [3, 1, 0, 3, 0, -4, 10, 0, 1, -5, 3, 0, 3, 1],</div>
<div class="line"><span class="lineno">   18</span>        [2.11, 8, -6, -0.5, 0, 1, 0, 0, -3.2, 6, 0.5, 0, -3, 1],</div>
<div class="line"><span class="lineno">   19</span>        [2.11, 8, -6, -0.5, 0, 1, 0, 0, -3.2, 6, 1.5, 1, -1, -1],</div>
<div class="line"><span class="lineno">   20</span>        [2.11, 8, -6, -0.5, 0, 10, 0, 0, -3.2, 6, 0.5, 0, -1, -1],</div>
<div class="line"><span class="lineno">   21</span>        [2, 0, 5, 1, 0.5, -2, 10, 0, 1, -5, 3, 1, 0, -1],</div>
<div class="line"><span class="lineno">   22</span>        [2, 0, 1, 1, 1, -2, 1, 0, 0, -2, 0, 0, 0, 1],</div>
<div class="line"><span class="lineno">   23</span>        [2, 1, 1, 1, 2, -1, 10, 2, 0, -1, 0, 2, 1, 1],</div>
<div class="line"><span class="lineno">   24</span>        [1, 1, 0, 0, 1, -3, 1, 2, 0, -5, 1, 2, 1, 1],</div>
<div class="line"><span class="lineno">   25</span>        [3, 1, 0, 1, 0, -4, 1, 0, 1, -2, 0, 0, 1, 0],</div>
<div class="line"><span class="lineno">   26</span>    ]</div>
<div class="line"><span class="lineno">   27</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a45bb897fd36b9f9381875a9cbcc6766d" name="a45bb897fd36b9f9381875a9cbcc6766d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45bb897fd36b9f9381875a9cbcc6766d">&#9670;&#160;</a></span>X_sparse_mix</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.X_sparse_mix = _sparse_random_matrix(20, 10, density=0.25, <a class="el" href="namespacesklearn_1_1tree_1_1tests_1_1test__tree.html#aa4d8e42c19195de8407ea5ffdf742db2">random_state</a>=0).toarray()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6898f36189dd3d0ac4dcef74f5bb2d7c" name="a6898f36189dd3d0ac4dcef74f5bb2d7c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6898f36189dd3d0ac4dcef74f5bb2d7c">&#9670;&#160;</a></span>X_sparse_pos</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.X_sparse_pos = random_state.uniform(size=(20, 5))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae073fd8ff4a679754e7d15fec2ef840d" name="ae073fd8ff4a679754e7d15fec2ef840d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae073fd8ff4a679754e7d15fec2ef840d">&#9670;&#160;</a></span>y</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.tree.tests.test_tree.y = [-1, -1, -1, 1, 1, 1]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a68fd5d354ae9364bbfd4e8fc1bb0763c" name="a68fd5d354ae9364bbfd4e8fc1bb0763c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68fd5d354ae9364bbfd4e8fc1bb0763c">&#9670;&#160;</a></span>y_multilabel</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.y_multilabel</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9a1a680e9c0377a57eaaf06bb84652eb" name="a9a1a680e9c0377a57eaaf06bb84652eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a1a680e9c0377a57eaaf06bb84652eb">&#9670;&#160;</a></span>y_random</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.tree.tests.test_tree.y_random = random_state.randint(0, 4, size=(20,))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8e645db6f8075b1e756813bf302f6be1" name="a8e645db6f8075b1e756813bf302f6be1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e645db6f8075b1e756813bf302f6be1">&#9670;&#160;</a></span>y_small</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.tree.tests.test_tree.y_small = [1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a07e5bc0f7613ba34ccd63d9cec5d0392" name="a07e5bc0f7613ba34ccd63d9cec5d0392"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07e5bc0f7613ba34ccd63d9cec5d0392">&#9670;&#160;</a></span>y_small_reg</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.tree.tests.test_tree.y_small_reg</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  [</div>
<div class="line"><span class="lineno">    2</span>    1.0,</div>
<div class="line"><span class="lineno">    3</span>    2.1,</div>
<div class="line"><span class="lineno">    4</span>    1.2,</div>
<div class="line"><span class="lineno">    5</span>    0.05,</div>
<div class="line"><span class="lineno">    6</span>    10,</div>
<div class="line"><span class="lineno">    7</span>    2.4,</div>
<div class="line"><span class="lineno">    8</span>    3.1,</div>
<div class="line"><span class="lineno">    9</span>    1.01,</div>
<div class="line"><span class="lineno">   10</span>    0.01,</div>
<div class="line"><span class="lineno">   11</span>    2.98,</div>
<div class="line"><span class="lineno">   12</span>    3.1,</div>
<div class="line"><span class="lineno">   13</span>    1.1,</div>
<div class="line"><span class="lineno">   14</span>    0.0,</div>
<div class="line"><span class="lineno">   15</span>    1.2,</div>
<div class="line"><span class="lineno">   16</span>    2,</div>
<div class="line"><span class="lineno">   17</span>    11,</div>
<div class="line"><span class="lineno">   18</span>    0,</div>
<div class="line"><span class="lineno">   19</span>    0,</div>
<div class="line"><span class="lineno">   20</span>    4.5,</div>
<div class="line"><span class="lineno">   21</span>    0.201,</div>
<div class="line"><span class="lineno">   22</span>    1.06,</div>
<div class="line"><span class="lineno">   23</span>    0.9,</div>
<div class="line"><span class="lineno">   24</span>    0,</div>
<div class="line"><span class="lineno">   25</span>]</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
