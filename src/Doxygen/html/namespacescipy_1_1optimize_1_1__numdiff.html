<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: scipy.optimize._numdiff Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacescipy.html">scipy</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1optimize.html">optimize</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html">_numdiff</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">scipy.optimize._numdiff Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ae3092dc376024776f6b2f8f74d046892" id="r_ae3092dc376024776f6b2f8f74d046892"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html#ae3092dc376024776f6b2f8f74d046892">_adjust_scheme_to_bounds</a> (x0, <a class="el" href="__lapack__subroutines_8h.html#a866dc72abfeae882204974bec3220f3a">h</a>, num_steps, scheme, lb, ub)</td></tr>
<tr class="separator:ae3092dc376024776f6b2f8f74d046892"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7225c7f3c07b9435d5cfd72c00e2a843" id="r_a7225c7f3c07b9435d5cfd72c00e2a843"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html#a7225c7f3c07b9435d5cfd72c00e2a843">_eps_for_method</a> (x0_dtype, f0_dtype, method)</td></tr>
<tr class="separator:a7225c7f3c07b9435d5cfd72c00e2a843"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f1b761f2778bc54ce59add17282f8ad" id="r_a3f1b761f2778bc54ce59add17282f8ad"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html#a3f1b761f2778bc54ce59add17282f8ad">_compute_absolute_step</a> (rel_step, x0, f0, method)</td></tr>
<tr class="separator:a3f1b761f2778bc54ce59add17282f8ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a899f48c0590f3095356a8cff49019c44" id="r_a899f48c0590f3095356a8cff49019c44"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html#a899f48c0590f3095356a8cff49019c44">_prepare_bounds</a> (bounds, x0)</td></tr>
<tr class="separator:a899f48c0590f3095356a8cff49019c44"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81c9baed80ae81b795e95751bbac5f22" id="r_a81c9baed80ae81b795e95751bbac5f22"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html#a81c9baed80ae81b795e95751bbac5f22">group_columns</a> (A, <a class="el" href="__lapack__subroutines_8h.html#a9993259f1ab17738593f079acd0507d9">order</a>=0)</td></tr>
<tr class="separator:a81c9baed80ae81b795e95751bbac5f22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d1a55482bf2058bbc720e9be8d9bf94" id="r_a6d1a55482bf2058bbc720e9be8d9bf94"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html#a6d1a55482bf2058bbc720e9be8d9bf94">approx_derivative</a> (fun, x0, method='3-point', rel_step=None, abs_step=None, f0=None, bounds=(-np.inf, np.inf), sparsity=None, as_linear_operator=False, args=(), kwargs={})</td></tr>
<tr class="separator:a6d1a55482bf2058bbc720e9be8d9bf94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f051ca4b32f22e7027791a76528bfc8" id="r_a0f051ca4b32f22e7027791a76528bfc8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html#a0f051ca4b32f22e7027791a76528bfc8">_linear_operator_difference</a> (fun, x0, f0, <a class="el" href="__lapack__subroutines_8h.html#a866dc72abfeae882204974bec3220f3a">h</a>, method)</td></tr>
<tr class="separator:a0f051ca4b32f22e7027791a76528bfc8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3859a545f34729436a75a7cc72b0af42" id="r_a3859a545f34729436a75a7cc72b0af42"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html#a3859a545f34729436a75a7cc72b0af42">_dense_difference</a> (fun, x0, f0, <a class="el" href="__lapack__subroutines_8h.html#a866dc72abfeae882204974bec3220f3a">h</a>, use_one_sided, method)</td></tr>
<tr class="separator:a3859a545f34729436a75a7cc72b0af42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a36b03aa7984e234b40277bb9faa90309" id="r_a36b03aa7984e234b40277bb9faa90309"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html#a36b03aa7984e234b40277bb9faa90309">_sparse_difference</a> (fun, x0, f0, <a class="el" href="__lapack__subroutines_8h.html#a866dc72abfeae882204974bec3220f3a">h</a>, use_one_sided, structure, groups, method)</td></tr>
<tr class="separator:a36b03aa7984e234b40277bb9faa90309"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48593fae5c9c1b6a1365ff53c6e3d576" id="r_a48593fae5c9c1b6a1365ff53c6e3d576"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1optimize_1_1__numdiff.html#a48593fae5c9c1b6a1365ff53c6e3d576">check_derivative</a> (fun, jac, x0, bounds=(-np.inf, np.inf), args=(), kwargs={})</td></tr>
<tr class="separator:a48593fae5c9c1b6a1365ff53c6e3d576"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Routines for numerical differentiation.</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="ae3092dc376024776f6b2f8f74d046892" name="ae3092dc376024776f6b2f8f74d046892"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae3092dc376024776f6b2f8f74d046892">&#9670;&#160;</a></span>_adjust_scheme_to_bounds()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._numdiff._adjust_scheme_to_bounds </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_steps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>scheme</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>lb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ub</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Adjust final difference scheme to the presence of bounds.

Parameters
----------
x0 : ndarray, shape (n,)
    Point at which we wish to estimate derivative.
h : ndarray, shape (n,)
    Desired absolute finite difference steps.
num_steps : int
    Number of `h` steps in one direction required to implement finite
    difference scheme. For example, 2 means that we need to evaluate
    f(x0 + 2 * h) or f(x0 - 2 * h)
scheme : {'1-sided', '2-sided'}
    Whether steps in one or both directions are required. In other
    words '1-sided' applies to forward and backward schemes, '2-sided'
    applies to center schemes.
lb : ndarray, shape (n,)
    Lower bounds on independent variables.
ub : ndarray, shape (n,)
    Upper bounds on independent variables.

Returns
-------
h_adjusted : ndarray, shape (n,)
    Adjusted absolute step sizes. Step size decreases only if a sign flip
    or switching to one-sided scheme doesn't allow to take a full step.
use_one_sided : ndarray of bool, shape (n,)
    Whether to switch to one-sided scheme. Informative only for
    ``scheme='2-sided'``.
</pre> <div class="fragment"><div class="line"><span class="lineno">   11</span><span class="keyword">def </span>_adjust_scheme_to_bounds(x0, h, num_steps, scheme, lb, ub):</div>
<div class="line"><span class="lineno">   12</span>    <span class="stringliteral">&quot;&quot;&quot;Adjust final difference scheme to the presence of bounds.</span></div>
<div class="line"><span class="lineno">   13</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   14</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   15</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   16</span><span class="stringliteral">    x0 : ndarray, shape (n,)</span></div>
<div class="line"><span class="lineno">   17</span><span class="stringliteral">        Point at which we wish to estimate derivative.</span></div>
<div class="line"><span class="lineno">   18</span><span class="stringliteral">    h : ndarray, shape (n,)</span></div>
<div class="line"><span class="lineno">   19</span><span class="stringliteral">        Desired absolute finite difference steps.</span></div>
<div class="line"><span class="lineno">   20</span><span class="stringliteral">    num_steps : int</span></div>
<div class="line"><span class="lineno">   21</span><span class="stringliteral">        Number of `h` steps in one direction required to implement finite</span></div>
<div class="line"><span class="lineno">   22</span><span class="stringliteral">        difference scheme. For example, 2 means that we need to evaluate</span></div>
<div class="line"><span class="lineno">   23</span><span class="stringliteral">        f(x0 + 2 * h) or f(x0 - 2 * h)</span></div>
<div class="line"><span class="lineno">   24</span><span class="stringliteral">    scheme : {&#39;1-sided&#39;, &#39;2-sided&#39;}</span></div>
<div class="line"><span class="lineno">   25</span><span class="stringliteral">        Whether steps in one or both directions are required. In other</span></div>
<div class="line"><span class="lineno">   26</span><span class="stringliteral">        words &#39;1-sided&#39; applies to forward and backward schemes, &#39;2-sided&#39;</span></div>
<div class="line"><span class="lineno">   27</span><span class="stringliteral">        applies to center schemes.</span></div>
<div class="line"><span class="lineno">   28</span><span class="stringliteral">    lb : ndarray, shape (n,)</span></div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">        Lower bounds on independent variables.</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral">    ub : ndarray, shape (n,)</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral">        Upper bounds on independent variables.</span></div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">    h_adjusted : ndarray, shape (n,)</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">        Adjusted absolute step sizes. Step size decreases only if a sign flip</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral">        or switching to one-sided scheme doesn&#39;t allow to take a full step.</span></div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral">    use_one_sided : ndarray of bool, shape (n,)</span></div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">        Whether to switch to one-sided scheme. Informative only for</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">        ``scheme=&#39;2-sided&#39;``.</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   42</span>    <span class="keywordflow">if</span> scheme == <span class="stringliteral">&#39;1-sided&#39;</span>:</div>
<div class="line"><span class="lineno">   43</span>        use_one_sided = np.ones_like(h, dtype=bool)</div>
<div class="line"><span class="lineno">   44</span>    <span class="keywordflow">elif</span> scheme == <span class="stringliteral">&#39;2-sided&#39;</span>:</div>
<div class="line"><span class="lineno">   45</span>        h = np.abs(h)</div>
<div class="line"><span class="lineno">   46</span>        use_one_sided = np.zeros_like(h, dtype=bool)</div>
<div class="line"><span class="lineno">   47</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   48</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;`scheme` must be &#39;1-sided&#39; or &#39;2-sided&#39;.&quot;</span>)</div>
<div class="line"><span class="lineno">   49</span> </div>
<div class="line"><span class="lineno">   50</span>    <span class="keywordflow">if</span> np.all((lb == -np.inf) &amp; (ub == np.inf)):</div>
<div class="line"><span class="lineno">   51</span>        <span class="keywordflow">return</span> h, use_one_sided</div>
<div class="line"><span class="lineno">   52</span> </div>
<div class="line"><span class="lineno">   53</span>    h_total = h * num_steps</div>
<div class="line"><span class="lineno">   54</span>    h_adjusted = h.copy()</div>
<div class="line"><span class="lineno">   55</span> </div>
<div class="line"><span class="lineno">   56</span>    lower_dist = x0 - lb</div>
<div class="line"><span class="lineno">   57</span>    upper_dist = ub - x0</div>
<div class="line"><span class="lineno">   58</span> </div>
<div class="line"><span class="lineno">   59</span>    <span class="keywordflow">if</span> scheme == <span class="stringliteral">&#39;1-sided&#39;</span>:</div>
<div class="line"><span class="lineno">   60</span>        x = x0 + h_total</div>
<div class="line"><span class="lineno">   61</span>        violated = (x &lt; lb) | (x &gt; ub)</div>
<div class="line"><span class="lineno">   62</span>        fitting = np.abs(h_total) &lt;= np.maximum(lower_dist, upper_dist)</div>
<div class="line"><span class="lineno">   63</span>        h_adjusted[violated &amp; fitting] *= -1</div>
<div class="line"><span class="lineno">   64</span> </div>
<div class="line"><span class="lineno">   65</span>        forward = (upper_dist &gt;= lower_dist) &amp; ~fitting</div>
<div class="line"><span class="lineno">   66</span>        h_adjusted[forward] = upper_dist[forward] / num_steps</div>
<div class="line"><span class="lineno">   67</span>        backward = (upper_dist &lt; lower_dist) &amp; ~fitting</div>
<div class="line"><span class="lineno">   68</span>        h_adjusted[backward] = -lower_dist[backward] / num_steps</div>
<div class="line"><span class="lineno">   69</span>    <span class="keywordflow">elif</span> scheme == <span class="stringliteral">&#39;2-sided&#39;</span>:</div>
<div class="line"><span class="lineno">   70</span>        central = (lower_dist &gt;= h_total) &amp; (upper_dist &gt;= h_total)</div>
<div class="line"><span class="lineno">   71</span> </div>
<div class="line"><span class="lineno">   72</span>        forward = (upper_dist &gt;= lower_dist) &amp; ~central</div>
<div class="line"><span class="lineno">   73</span>        h_adjusted[forward] = np.minimum(</div>
<div class="line"><span class="lineno">   74</span>            h[forward], 0.5 * upper_dist[forward] / num_steps)</div>
<div class="line"><span class="lineno">   75</span>        use_one_sided[forward] = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">   76</span> </div>
<div class="line"><span class="lineno">   77</span>        backward = (upper_dist &lt; lower_dist) &amp; ~central</div>
<div class="line"><span class="lineno">   78</span>        h_adjusted[backward] = -np.minimum(</div>
<div class="line"><span class="lineno">   79</span>            h[backward], 0.5 * lower_dist[backward] / num_steps)</div>
<div class="line"><span class="lineno">   80</span>        use_one_sided[backward] = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">   81</span> </div>
<div class="line"><span class="lineno">   82</span>        min_dist = np.minimum(upper_dist, lower_dist) / num_steps</div>
<div class="line"><span class="lineno">   83</span>        adjusted_central = (~central &amp; (np.abs(h_adjusted) &lt;= min_dist))</div>
<div class="line"><span class="lineno">   84</span>        h_adjusted[adjusted_central] = min_dist[adjusted_central]</div>
<div class="line"><span class="lineno">   85</span>        use_one_sided[adjusted_central] = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">   86</span> </div>
<div class="line"><span class="lineno">   87</span>    <span class="keywordflow">return</span> h_adjusted, use_one_sided</div>
<div class="line"><span class="lineno">   88</span> </div>
<div class="line"><span class="lineno">   89</span> </div>
<div class="line"><span class="lineno">   90</span><span class="preprocessor">@functools.lru_cache()</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a3f1b761f2778bc54ce59add17282f8ad" name="a3f1b761f2778bc54ce59add17282f8ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3f1b761f2778bc54ce59add17282f8ad">&#9670;&#160;</a></span>_compute_absolute_step()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._numdiff._compute_absolute_step </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rel_step</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>f0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Computes an absolute step from a relative step for finite difference
calculation.

Parameters
----------
rel_step: None or array-like
    Relative step for the finite difference calculation
x0 : np.ndarray
    Parameter vector
f0 : np.ndarray or scalar
method : {'2-point', '3-point', 'cs'}

Returns
-------
h : float
    The absolute step size

Notes
-----
`h` will always be np.float64. However, if `x0` or `f0` are
smaller floating point dtypes (e.g. np.float32), then the absolute
step size will be calculated from the smallest floating point size.
</pre> <div class="fragment"><div class="line"><span class="lineno">  144</span><span class="keyword">def </span>_compute_absolute_step(rel_step, x0, f0, method):</div>
<div class="line"><span class="lineno">  145</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">    Computes an absolute step from a relative step for finite difference</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">    calculation.</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">    rel_step: None or array-like</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">        Relative step for the finite difference calculation</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">    x0 : np.ndarray</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">        Parameter vector</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">    f0 : np.ndarray or scalar</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">    method : {&#39;2-point&#39;, &#39;3-point&#39;, &#39;cs&#39;}</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">    h : float</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">        The absolute step size</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">    `h` will always be np.float64. However, if `x0` or `f0` are</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">    smaller floating point dtypes (e.g. np.float32), then the absolute</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">    step size will be calculated from the smallest floating point size.</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  169</span>    <span class="comment"># this is used instead of np.sign(x0) because we need</span></div>
<div class="line"><span class="lineno">  170</span>    <span class="comment"># sign_x0 to be 1 when x0 == 0.</span></div>
<div class="line"><span class="lineno">  171</span>    sign_x0 = (x0 &gt;= 0).astype(float) * 2 - 1</div>
<div class="line"><span class="lineno">  172</span> </div>
<div class="line"><span class="lineno">  173</span>    rstep = _eps_for_method(x0.dtype, f0.dtype, method)</div>
<div class="line"><span class="lineno">  174</span> </div>
<div class="line"><span class="lineno">  175</span>    <span class="keywordflow">if</span> rel_step <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  176</span>        abs_step = rstep * sign_x0 * np.maximum(1.0, np.abs(x0))</div>
<div class="line"><span class="lineno">  177</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  178</span>        <span class="comment"># User has requested specific relative steps.</span></div>
<div class="line"><span class="lineno">  179</span>        <span class="comment"># Don&#39;t multiply by max(1, abs(x0) because if x0 &lt; 1 then their</span></div>
<div class="line"><span class="lineno">  180</span>        <span class="comment"># requested step is not used.</span></div>
<div class="line"><span class="lineno">  181</span>        abs_step = rel_step * sign_x0 * np.abs(x0)</div>
<div class="line"><span class="lineno">  182</span> </div>
<div class="line"><span class="lineno">  183</span>        <span class="comment"># however we don&#39;t want an abs_step of 0, which can happen if</span></div>
<div class="line"><span class="lineno">  184</span>        <span class="comment"># rel_step is 0, or x0 is 0. Instead, substitute a realistic step</span></div>
<div class="line"><span class="lineno">  185</span>        dx = ((x0 + abs_step) - x0)</div>
<div class="line"><span class="lineno">  186</span>        abs_step = np.where(dx == 0,</div>
<div class="line"><span class="lineno">  187</span>                            rstep * sign_x0 * np.maximum(1.0, np.abs(x0)),</div>
<div class="line"><span class="lineno">  188</span>                            abs_step)</div>
<div class="line"><span class="lineno">  189</span> </div>
<div class="line"><span class="lineno">  190</span>    <span class="keywordflow">return</span> abs_step</div>
<div class="line"><span class="lineno">  191</span> </div>
<div class="line"><span class="lineno">  192</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3859a545f34729436a75a7cc72b0af42" name="a3859a545f34729436a75a7cc72b0af42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3859a545f34729436a75a7cc72b0af42">&#9670;&#160;</a></span>_dense_difference()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._numdiff._dense_difference </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>f0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>use_one_sided</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  566</span><span class="keyword">def </span>_dense_difference(fun, x0, f0, h, use_one_sided, method):</div>
<div class="line"><span class="lineno">  567</span>    m = f0.size</div>
<div class="line"><span class="lineno">  568</span>    n = x0.size</div>
<div class="line"><span class="lineno">  569</span>    J_transposed = np.empty((n, m))</div>
<div class="line"><span class="lineno">  570</span>    h_vecs = np.diag(h)</div>
<div class="line"><span class="lineno">  571</span> </div>
<div class="line"><span class="lineno">  572</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(h.size):</div>
<div class="line"><span class="lineno">  573</span>        <span class="keywordflow">if</span> method == <span class="stringliteral">&#39;2-point&#39;</span>:</div>
<div class="line"><span class="lineno">  574</span>            x = x0 + h_vecs[i]</div>
<div class="line"><span class="lineno">  575</span>            dx = x[i] - x0[i]  <span class="comment"># Recompute dx as exactly representable number.</span></div>
<div class="line"><span class="lineno">  576</span>            df = fun(x) - f0</div>
<div class="line"><span class="lineno">  577</span>        <span class="keywordflow">elif</span> method == <span class="stringliteral">&#39;3-point&#39;</span> <span class="keywordflow">and</span> use_one_sided[i]:</div>
<div class="line"><span class="lineno">  578</span>            x1 = x0 + h_vecs[i]</div>
<div class="line"><span class="lineno">  579</span>            x2 = x0 + 2 * h_vecs[i]</div>
<div class="line"><span class="lineno">  580</span>            dx = x2[i] - x0[i]</div>
<div class="line"><span class="lineno">  581</span>            f1 = fun(x1)</div>
<div class="line"><span class="lineno">  582</span>            f2 = fun(x2)</div>
<div class="line"><span class="lineno">  583</span>            df = -3.0 * f0 + 4 * f1 - f2</div>
<div class="line"><span class="lineno">  584</span>        <span class="keywordflow">elif</span> method == <span class="stringliteral">&#39;3-point&#39;</span> <span class="keywordflow">and</span> <span class="keywordflow">not</span> use_one_sided[i]:</div>
<div class="line"><span class="lineno">  585</span>            x1 = x0 - h_vecs[i]</div>
<div class="line"><span class="lineno">  586</span>            x2 = x0 + h_vecs[i]</div>
<div class="line"><span class="lineno">  587</span>            dx = x2[i] - x1[i]</div>
<div class="line"><span class="lineno">  588</span>            f1 = fun(x1)</div>
<div class="line"><span class="lineno">  589</span>            f2 = fun(x2)</div>
<div class="line"><span class="lineno">  590</span>            df = f2 - f1</div>
<div class="line"><span class="lineno">  591</span>        <span class="keywordflow">elif</span> method == <span class="stringliteral">&#39;cs&#39;</span>:</div>
<div class="line"><span class="lineno">  592</span>            f1 = fun(x0 + h_vecs[i]*1.j)</div>
<div class="line"><span class="lineno">  593</span>            df = f1.imag</div>
<div class="line"><span class="lineno">  594</span>            dx = h_vecs[i, i]</div>
<div class="line"><span class="lineno">  595</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  596</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;Never be here.&quot;</span>)</div>
<div class="line"><span class="lineno">  597</span> </div>
<div class="line"><span class="lineno">  598</span>        J_transposed[i] = df / dx</div>
<div class="line"><span class="lineno">  599</span> </div>
<div class="line"><span class="lineno">  600</span>    <span class="keywordflow">if</span> m == 1:</div>
<div class="line"><span class="lineno">  601</span>        J_transposed = np.ravel(J_transposed)</div>
<div class="line"><span class="lineno">  602</span> </div>
<div class="line"><span class="lineno">  603</span>    <span class="keywordflow">return</span> J_transposed.T</div>
<div class="line"><span class="lineno">  604</span> </div>
<div class="line"><span class="lineno">  605</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7225c7f3c07b9435d5cfd72c00e2a843" name="a7225c7f3c07b9435d5cfd72c00e2a843"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7225c7f3c07b9435d5cfd72c00e2a843">&#9670;&#160;</a></span>_eps_for_method()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._numdiff._eps_for_method </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0_dtype</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>f0_dtype</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Calculates relative EPS step to use for a given data type
and numdiff step method.

Progressively smaller steps are used for larger floating point types.

Parameters
----------
f0_dtype: np.dtype
    dtype of function evaluation

x0_dtype: np.dtype
    dtype of parameter vector

method: {'2-point', '3-point', 'cs'}

Returns
-------
EPS: float
    relative step size. May be np.float16, np.float32, np.float64

Notes
-----
The default relative step will be np.float64. However, if x0 or f0 are
smaller floating point types (np.float16, np.float32), then the smallest
floating point type is chosen.
</pre> <div class="fragment"><div class="line"><span class="lineno">   91</span><span class="keyword">def </span>_eps_for_method(x0_dtype, f0_dtype, method):</div>
<div class="line"><span class="lineno">   92</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral">    Calculates relative EPS step to use for a given data type</span></div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral">    and numdiff step method.</span></div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral">    Progressively smaller steps are used for larger floating point types.</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">    f0_dtype: np.dtype</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">        dtype of function evaluation</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">    x0_dtype: np.dtype</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">        dtype of parameter vector</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral">    method: {&#39;2-point&#39;, &#39;3-point&#39;, &#39;cs&#39;}</span></div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral">    EPS: float</span></div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral">        relative step size. May be np.float16, np.float32, np.float64</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">    The default relative step will be np.float64. However, if x0 or f0 are</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral">    smaller floating point types (np.float16, np.float32), then the smallest</span></div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">    floating point type is chosen.</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  119</span>    <span class="comment"># the default EPS value</span></div>
<div class="line"><span class="lineno">  120</span>    EPS = np.finfo(np.float64).eps</div>
<div class="line"><span class="lineno">  121</span> </div>
<div class="line"><span class="lineno">  122</span>    x0_is_fp = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  123</span>    <span class="keywordflow">if</span> np.issubdtype(x0_dtype, np.inexact):</div>
<div class="line"><span class="lineno">  124</span>        <span class="comment"># if you&#39;re a floating point type then over-ride the default EPS</span></div>
<div class="line"><span class="lineno">  125</span>        EPS = np.finfo(x0_dtype).eps</div>
<div class="line"><span class="lineno">  126</span>        x0_itemsize = np.dtype(x0_dtype).itemsize</div>
<div class="line"><span class="lineno">  127</span>        x0_is_fp = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  128</span> </div>
<div class="line"><span class="lineno">  129</span>    <span class="keywordflow">if</span> np.issubdtype(f0_dtype, np.inexact):</div>
<div class="line"><span class="lineno">  130</span>        f0_itemsize = np.dtype(f0_dtype).itemsize</div>
<div class="line"><span class="lineno">  131</span>        <span class="comment"># choose the smallest itemsize between x0 and f0</span></div>
<div class="line"><span class="lineno">  132</span>        <span class="keywordflow">if</span> x0_is_fp <span class="keywordflow">and</span> f0_itemsize &lt; x0_itemsize:</div>
<div class="line"><span class="lineno">  133</span>            EPS = np.finfo(f0_dtype).eps</div>
<div class="line"><span class="lineno">  134</span> </div>
<div class="line"><span class="lineno">  135</span>    <span class="keywordflow">if</span> method <span class="keywordflow">in</span> [<span class="stringliteral">&quot;2-point&quot;</span>, <span class="stringliteral">&quot;cs&quot;</span>]:</div>
<div class="line"><span class="lineno">  136</span>        <span class="keywordflow">return</span> EPS**0.5</div>
<div class="line"><span class="lineno">  137</span>    <span class="keywordflow">elif</span> method <span class="keywordflow">in</span> [<span class="stringliteral">&quot;3-point&quot;</span>]:</div>
<div class="line"><span class="lineno">  138</span>        <span class="keywordflow">return</span> EPS**(1/3)</div>
<div class="line"><span class="lineno">  139</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  140</span>        <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;Unknown step method, should be one of &quot;</span></div>
<div class="line"><span class="lineno">  141</span>                           <span class="stringliteral">&quot;{&#39;2-point&#39;, &#39;3-point&#39;, &#39;cs&#39;}&quot;</span>)</div>
<div class="line"><span class="lineno">  142</span> </div>
<div class="line"><span class="lineno">  143</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0f051ca4b32f22e7027791a76528bfc8" name="a0f051ca4b32f22e7027791a76528bfc8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f051ca4b32f22e7027791a76528bfc8">&#9670;&#160;</a></span>_linear_operator_difference()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._numdiff._linear_operator_difference </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>f0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  525</span><span class="keyword">def </span>_linear_operator_difference(fun, x0, f0, h, method):</div>
<div class="line"><span class="lineno">  526</span>    m = f0.size</div>
<div class="line"><span class="lineno">  527</span>    n = x0.size</div>
<div class="line"><span class="lineno">  528</span> </div>
<div class="line"><span class="lineno">  529</span>    <span class="keywordflow">if</span> method == <span class="stringliteral">&#39;2-point&#39;</span>:</div>
<div class="line"><span class="lineno">  530</span>        <span class="keyword">def </span>matvec(p):</div>
<div class="line"><span class="lineno">  531</span>            <span class="keywordflow">if</span> np.array_equal(p, np.zeros_like(p)):</div>
<div class="line"><span class="lineno">  532</span>                <span class="keywordflow">return</span> np.zeros(m)</div>
<div class="line"><span class="lineno">  533</span>            dx = h / norm(p)</div>
<div class="line"><span class="lineno">  534</span>            x = x0 + dx*p</div>
<div class="line"><span class="lineno">  535</span>            df = fun(x) - f0</div>
<div class="line"><span class="lineno">  536</span>            <span class="keywordflow">return</span> df / dx</div>
<div class="line"><span class="lineno">  537</span> </div>
<div class="line"><span class="lineno">  538</span>    <span class="keywordflow">elif</span> method == <span class="stringliteral">&#39;3-point&#39;</span>:</div>
<div class="line"><span class="lineno">  539</span>        <span class="keyword">def </span>matvec(p):</div>
<div class="line"><span class="lineno">  540</span>            <span class="keywordflow">if</span> np.array_equal(p, np.zeros_like(p)):</div>
<div class="line"><span class="lineno">  541</span>                <span class="keywordflow">return</span> np.zeros(m)</div>
<div class="line"><span class="lineno">  542</span>            dx = 2*h / norm(p)</div>
<div class="line"><span class="lineno">  543</span>            x1 = x0 - (dx/2)*p</div>
<div class="line"><span class="lineno">  544</span>            x2 = x0 + (dx/2)*p</div>
<div class="line"><span class="lineno">  545</span>            f1 = fun(x1)</div>
<div class="line"><span class="lineno">  546</span>            f2 = fun(x2)</div>
<div class="line"><span class="lineno">  547</span>            df = f2 - f1</div>
<div class="line"><span class="lineno">  548</span>            <span class="keywordflow">return</span> df / dx</div>
<div class="line"><span class="lineno">  549</span> </div>
<div class="line"><span class="lineno">  550</span>    <span class="keywordflow">elif</span> method == <span class="stringliteral">&#39;cs&#39;</span>:</div>
<div class="line"><span class="lineno">  551</span>        <span class="keyword">def </span>matvec(p):</div>
<div class="line"><span class="lineno">  552</span>            <span class="keywordflow">if</span> np.array_equal(p, np.zeros_like(p)):</div>
<div class="line"><span class="lineno">  553</span>                <span class="keywordflow">return</span> np.zeros(m)</div>
<div class="line"><span class="lineno">  554</span>            dx = h / norm(p)</div>
<div class="line"><span class="lineno">  555</span>            x = x0 + dx*p*1.j</div>
<div class="line"><span class="lineno">  556</span>            f1 = fun(x)</div>
<div class="line"><span class="lineno">  557</span>            df = f1.imag</div>
<div class="line"><span class="lineno">  558</span>            <span class="keywordflow">return</span> df / dx</div>
<div class="line"><span class="lineno">  559</span> </div>
<div class="line"><span class="lineno">  560</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  561</span>        <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;Never be here.&quot;</span>)</div>
<div class="line"><span class="lineno">  562</span> </div>
<div class="line"><span class="lineno">  563</span>    <span class="keywordflow">return</span> LinearOperator((m, n), matvec)</div>
<div class="line"><span class="lineno">  564</span> </div>
<div class="line"><span class="lineno">  565</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a899f48c0590f3095356a8cff49019c44" name="a899f48c0590f3095356a8cff49019c44"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a899f48c0590f3095356a8cff49019c44">&#9670;&#160;</a></span>_prepare_bounds()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._numdiff._prepare_bounds </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>bounds</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Prepares new-style bounds from a two-tuple specifying the lower and upper
limits for values in x0. If a value is not bound then the lower/upper bound
will be expected to be -np.inf/np.inf.

Examples
--------
&gt;&gt;&gt; _prepare_bounds([(0, 1, 2), (1, 2, np.inf)], [0.5, 1.5, 2.5])
(array([0., 1., 2.]), array([ 1.,  2., inf]))
</pre> <div class="fragment"><div class="line"><span class="lineno">  193</span><span class="keyword">def </span>_prepare_bounds(bounds, x0):</div>
<div class="line"><span class="lineno">  194</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">    Prepares new-style bounds from a two-tuple specifying the lower and upper</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral">    limits for values in x0. If a value is not bound then the lower/upper bound</span></div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral">    will be expected to be -np.inf/np.inf.</span></div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral">    &gt;&gt;&gt; _prepare_bounds([(0, 1, 2), (1, 2, np.inf)], [0.5, 1.5, 2.5])</span></div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral">    (array([0., 1., 2.]), array([ 1.,  2., inf]))</span></div>
<div class="line"><span class="lineno">  203</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  204</span>    lb, ub = [np.asarray(b, dtype=float) <span class="keywordflow">for</span> b <span class="keywordflow">in</span> bounds]</div>
<div class="line"><span class="lineno">  205</span>    <span class="keywordflow">if</span> lb.ndim == 0:</div>
<div class="line"><span class="lineno">  206</span>        lb = np.resize(lb, x0.shape)</div>
<div class="line"><span class="lineno">  207</span> </div>
<div class="line"><span class="lineno">  208</span>    <span class="keywordflow">if</span> ub.ndim == 0:</div>
<div class="line"><span class="lineno">  209</span>        ub = np.resize(ub, x0.shape)</div>
<div class="line"><span class="lineno">  210</span> </div>
<div class="line"><span class="lineno">  211</span>    <span class="keywordflow">return</span> lb, ub</div>
<div class="line"><span class="lineno">  212</span> </div>
<div class="line"><span class="lineno">  213</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a36b03aa7984e234b40277bb9faa90309" name="a36b03aa7984e234b40277bb9faa90309"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a36b03aa7984e234b40277bb9faa90309">&#9670;&#160;</a></span>_sparse_difference()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._numdiff._sparse_difference </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>f0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>use_one_sided</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>structure</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>groups</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  607</span>                       structure, groups, method):</div>
<div class="line"><span class="lineno">  608</span>    m = f0.size</div>
<div class="line"><span class="lineno">  609</span>    n = x0.size</div>
<div class="line"><span class="lineno">  610</span>    row_indices = []</div>
<div class="line"><span class="lineno">  611</span>    col_indices = []</div>
<div class="line"><span class="lineno">  612</span>    fractions = []</div>
<div class="line"><span class="lineno">  613</span> </div>
<div class="line"><span class="lineno">  614</span>    n_groups = np.max(groups) + 1</div>
<div class="line"><span class="lineno">  615</span>    <span class="keywordflow">for</span> group <span class="keywordflow">in</span> range(n_groups):</div>
<div class="line"><span class="lineno">  616</span>        <span class="comment"># Perturb variables which are in the same group simultaneously.</span></div>
<div class="line"><span class="lineno">  617</span>        e = np.equal(group, groups)</div>
<div class="line"><span class="lineno">  618</span>        h_vec = h * e</div>
<div class="line"><span class="lineno">  619</span>        <span class="keywordflow">if</span> method == <span class="stringliteral">&#39;2-point&#39;</span>:</div>
<div class="line"><span class="lineno">  620</span>            x = x0 + h_vec</div>
<div class="line"><span class="lineno">  621</span>            dx = x - x0</div>
<div class="line"><span class="lineno">  622</span>            df = fun(x) - f0</div>
<div class="line"><span class="lineno">  623</span>            <span class="comment"># The result is  written to columns which correspond to perturbed</span></div>
<div class="line"><span class="lineno">  624</span>            <span class="comment"># variables.</span></div>
<div class="line"><span class="lineno">  625</span>            cols, = np.nonzero(e)</div>
<div class="line"><span class="lineno">  626</span>            <span class="comment"># Find all non-zero elements in selected columns of Jacobian.</span></div>
<div class="line"><span class="lineno">  627</span>            i, j, _ = find(structure[:, cols])</div>
<div class="line"><span class="lineno">  628</span>            <span class="comment"># Restore column indices in the full array.</span></div>
<div class="line"><span class="lineno">  629</span>            j = cols[j]</div>
<div class="line"><span class="lineno">  630</span>        <span class="keywordflow">elif</span> method == <span class="stringliteral">&#39;3-point&#39;</span>:</div>
<div class="line"><span class="lineno">  631</span>            <span class="comment"># Here we do conceptually the same but separate one-sided</span></div>
<div class="line"><span class="lineno">  632</span>            <span class="comment"># and two-sided schemes.</span></div>
<div class="line"><span class="lineno">  633</span>            x1 = x0.copy()</div>
<div class="line"><span class="lineno">  634</span>            x2 = x0.copy()</div>
<div class="line"><span class="lineno">  635</span> </div>
<div class="line"><span class="lineno">  636</span>            mask_1 = use_one_sided &amp; e</div>
<div class="line"><span class="lineno">  637</span>            x1[mask_1] += h_vec[mask_1]</div>
<div class="line"><span class="lineno">  638</span>            x2[mask_1] += 2 * h_vec[mask_1]</div>
<div class="line"><span class="lineno">  639</span> </div>
<div class="line"><span class="lineno">  640</span>            mask_2 = ~use_one_sided &amp; e</div>
<div class="line"><span class="lineno">  641</span>            x1[mask_2] -= h_vec[mask_2]</div>
<div class="line"><span class="lineno">  642</span>            x2[mask_2] += h_vec[mask_2]</div>
<div class="line"><span class="lineno">  643</span> </div>
<div class="line"><span class="lineno">  644</span>            dx = np.zeros(n)</div>
<div class="line"><span class="lineno">  645</span>            dx[mask_1] = x2[mask_1] - x0[mask_1]</div>
<div class="line"><span class="lineno">  646</span>            dx[mask_2] = x2[mask_2] - x1[mask_2]</div>
<div class="line"><span class="lineno">  647</span> </div>
<div class="line"><span class="lineno">  648</span>            f1 = fun(x1)</div>
<div class="line"><span class="lineno">  649</span>            f2 = fun(x2)</div>
<div class="line"><span class="lineno">  650</span> </div>
<div class="line"><span class="lineno">  651</span>            cols, = np.nonzero(e)</div>
<div class="line"><span class="lineno">  652</span>            i, j, _ = find(structure[:, cols])</div>
<div class="line"><span class="lineno">  653</span>            j = cols[j]</div>
<div class="line"><span class="lineno">  654</span> </div>
<div class="line"><span class="lineno">  655</span>            mask = use_one_sided[j]</div>
<div class="line"><span class="lineno">  656</span>            df = np.empty(m)</div>
<div class="line"><span class="lineno">  657</span> </div>
<div class="line"><span class="lineno">  658</span>            rows = i[mask]</div>
<div class="line"><span class="lineno">  659</span>            df[rows] = -3 * f0[rows] + 4 * f1[rows] - f2[rows]</div>
<div class="line"><span class="lineno">  660</span> </div>
<div class="line"><span class="lineno">  661</span>            rows = i[~mask]</div>
<div class="line"><span class="lineno">  662</span>            df[rows] = f2[rows] - f1[rows]</div>
<div class="line"><span class="lineno">  663</span>        <span class="keywordflow">elif</span> method == <span class="stringliteral">&#39;cs&#39;</span>:</div>
<div class="line"><span class="lineno">  664</span>            f1 = fun(x0 + h_vec*1.j)</div>
<div class="line"><span class="lineno">  665</span>            df = f1.imag</div>
<div class="line"><span class="lineno">  666</span>            dx = h_vec</div>
<div class="line"><span class="lineno">  667</span>            cols, = np.nonzero(e)</div>
<div class="line"><span class="lineno">  668</span>            i, j, _ = find(structure[:, cols])</div>
<div class="line"><span class="lineno">  669</span>            j = cols[j]</div>
<div class="line"><span class="lineno">  670</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  671</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Never be here.&quot;</span>)</div>
<div class="line"><span class="lineno">  672</span> </div>
<div class="line"><span class="lineno">  673</span>        <span class="comment"># All that&#39;s left is to compute the fraction. We store i, j and</span></div>
<div class="line"><span class="lineno">  674</span>        <span class="comment"># fractions as separate arrays and later construct coo_matrix.</span></div>
<div class="line"><span class="lineno">  675</span>        row_indices.append(i)</div>
<div class="line"><span class="lineno">  676</span>        col_indices.append(j)</div>
<div class="line"><span class="lineno">  677</span>        fractions.append(df[i] / dx[j])</div>
<div class="line"><span class="lineno">  678</span> </div>
<div class="line"><span class="lineno">  679</span>    row_indices = np.hstack(row_indices)</div>
<div class="line"><span class="lineno">  680</span>    col_indices = np.hstack(col_indices)</div>
<div class="line"><span class="lineno">  681</span>    fractions = np.hstack(fractions)</div>
<div class="line"><span class="lineno">  682</span>    J = coo_matrix((fractions, (row_indices, col_indices)), shape=(m, n))</div>
<div class="line"><span class="lineno">  683</span>    <span class="keywordflow">return</span> csr_matrix(J)</div>
<div class="line"><span class="lineno">  684</span> </div>
<div class="line"><span class="lineno">  685</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6d1a55482bf2058bbc720e9be8d9bf94" name="a6d1a55482bf2058bbc720e9be8d9bf94"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6d1a55482bf2058bbc720e9be8d9bf94">&#9670;&#160;</a></span>approx_derivative()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._numdiff.approx_derivative </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em> = <code>'3-point'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rel_step</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>abs_step</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>f0</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>bounds</em> = <code>(-np.inf,&#160;np.inf)</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sparsity</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>as_linear_operator</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>args</em> = <code>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>kwargs</em> = <code>{}</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute finite difference approximation of the derivatives of a
vector-valued function.

If a function maps from R^n to R^m, its derivatives form m-by-n matrix
called the Jacobian, where an element (i, j) is a partial derivative of
f[i] with respect to x[j].

Parameters
----------
fun : callable
    Function of which to estimate the derivatives. The argument x
    passed to this function is ndarray of shape (n,) (never a scalar
    even if n=1). It must return 1-D array_like of shape (m,) or a scalar.
x0 : array_like of shape (n,) or float
    Point at which to estimate the derivatives. Float will be converted
    to a 1-D array.
method : {'3-point', '2-point', 'cs'}, optional
    Finite difference method to use:
        - '2-point' - use the first order accuracy forward or backward
                      difference.
        - '3-point' - use central difference in interior points and the
                      second order accuracy forward or backward difference
                      near the boundary.
        - 'cs' - use a complex-step finite difference scheme. This assumes
                 that the user function is real-valued and can be
                 analytically continued to the complex plane. Otherwise,
                 produces bogus results.
rel_step : None or array_like, optional
    Relative step size to use. If None (default) the absolute step size is
    computed as ``h = rel_step * sign(x0) * max(1, abs(x0))``, with
    `rel_step` being selected automatically, see Notes. Otherwise
    ``h = rel_step * sign(x0) * abs(x0)``. For ``method='3-point'`` the
    sign of `h` is ignored. The calculated step size is possibly adjusted
    to fit into the bounds.
abs_step : array_like, optional
    Absolute step size to use, possibly adjusted to fit into the bounds.
    For ``method='3-point'`` the sign of `abs_step` is ignored. By default
    relative steps are used, only if ``abs_step is not None`` are absolute
    steps used.
f0 : None or array_like, optional
    If not None it is assumed to be equal to ``fun(x0)``, in this case
    the ``fun(x0)`` is not called. Default is None.
bounds : tuple of array_like, optional
    Lower and upper bounds on independent variables. Defaults to no bounds.
    Each bound must match the size of `x0` or be a scalar, in the latter
    case the bound will be the same for all variables. Use it to limit the
    range of function evaluation. Bounds checking is not implemented
    when `as_linear_operator` is True.
sparsity : {None, array_like, sparse matrix, 2-tuple}, optional
    Defines a sparsity structure of the Jacobian matrix. If the Jacobian
    matrix is known to have only few non-zero elements in each row, then
    it's possible to estimate its several columns by a single function
    evaluation [3]_. To perform such economic computations two ingredients
    are required:

    * structure : array_like or sparse matrix of shape (m, n). A zero
      element means that a corresponding element of the Jacobian
      identically equals to zero.
    * groups : array_like of shape (n,). A column grouping for a given
      sparsity structure, use `group_columns` to obtain it.

    A single array or a sparse matrix is interpreted as a sparsity
    structure, and groups are computed inside the function. A tuple is
    interpreted as (structure, groups). If None (default), a standard
    dense differencing will be used.

    Note, that sparse differencing makes sense only for large Jacobian
    matrices where each row contains few non-zero elements.
as_linear_operator : bool, optional
    When True the function returns an `scipy.sparse.linalg.LinearOperator`.
    Otherwise it returns a dense array or a sparse matrix depending on
    `sparsity`. The linear operator provides an efficient way of computing
    ``J.dot(p)`` for any vector ``p`` of shape (n,), but does not allow
    direct access to individual elements of the matrix. By default
    `as_linear_operator` is False.
args, kwargs : tuple and dict, optional
    Additional arguments passed to `fun`. Both empty by default.
    The calling signature is ``fun(x, *args, **kwargs)``.

Returns
-------
J : {ndarray, sparse matrix, LinearOperator}
    Finite difference approximation of the Jacobian matrix.
    If `as_linear_operator` is True returns a LinearOperator
    with shape (m, n). Otherwise it returns a dense array or sparse
    matrix depending on how `sparsity` is defined. If `sparsity`
    is None then a ndarray with shape (m, n) is returned. If
    `sparsity` is not None returns a csr_matrix with shape (m, n).
    For sparse matrices and linear operators it is always returned as
    a 2-D structure, for ndarrays, if m=1 it is returned
    as a 1-D gradient array with shape (n,).

See Also
--------
check_derivative : Check correctness of a function computing derivatives.

Notes
-----
If `rel_step` is not provided, it assigned as ``EPS**(1/s)``, where EPS is
determined from the smallest floating point dtype of `x0` or `fun(x0)`,
``np.finfo(x0.dtype).eps``, s=2 for '2-point' method and
s=3 for '3-point' method. Such relative step approximately minimizes a sum
of truncation and round-off errors, see [1]_. Relative steps are used by
default. However, absolute steps are used when ``abs_step is not None``.
If any of the absolute or relative steps produces an indistinguishable
difference from the original `x0`, ``(x0 + dx) - x0 == 0``, then a
automatic step size is substituted for that particular entry.

A finite difference scheme for '3-point' method is selected automatically.
The well-known central difference scheme is used for points sufficiently
far from the boundary, and 3-point forward or backward scheme is used for
points near the boundary. Both schemes have the second-order accuracy in
terms of Taylor expansion. Refer to [2]_ for the formulas of 3-point
forward and backward difference schemes.

For dense differencing when m=1 Jacobian is returned with a shape (n,),
on the other hand when n=1 Jacobian is returned with a shape (m, 1).
Our motivation is the following: a) It handles a case of gradient
computation (m=1) in a conventional way. b) It clearly separates these two
different cases. b) In all cases np.atleast_2d can be called to get 2-D
Jacobian with correct dimensions.

References
----------
.. [1] W. H. Press et. al. "Numerical Recipes. The Art of Scientific
       Computing. 3rd edition", sec. 5.7.

.. [2] A. Curtis, M. J. D. Powell, and J. Reid, "On the estimation of
       sparse Jacobian matrices", Journal of the Institute of Mathematics
       and its Applications, 13 (1974), pp. 117-120.

.. [3] B. Fornberg, "Generation of Finite Difference Formulas on
       Arbitrarily Spaced Grids", Mathematics of Computation 51, 1988.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from scipy.optimize._numdiff import approx_derivative
&gt;&gt;&gt;
&gt;&gt;&gt; def f(x, c1, c2):
...     return np.array([x[0] * np.sin(c1 * x[1]),
...                      x[0] * np.cos(c2 * x[1])])
...
&gt;&gt;&gt; x0 = np.array([1.0, 0.5 * np.pi])
&gt;&gt;&gt; approx_derivative(f, x0, args=(1, 2))
array([[ 1.,  0.],
       [-1.,  0.]])

Bounds can be used to limit the region of function evaluation.
In the example below we compute left and right derivative at point 1.0.

&gt;&gt;&gt; def g(x):
...     return x**2 if x &gt;= 1 else x
...
&gt;&gt;&gt; x0 = 1.0
&gt;&gt;&gt; approx_derivative(g, x0, bounds=(-np.inf, 1.0))
array([ 1.])
&gt;&gt;&gt; approx_derivative(g, x0, bounds=(1.0, np.inf))
array([ 2.])
</pre> <div class="fragment"><div class="line"><span class="lineno">  277</span>                      as_linear_operator=<span class="keyword">False</span>, args=(), kwargs={}):</div>
<div class="line"><span class="lineno">  278</span>    <span class="stringliteral">&quot;&quot;&quot;Compute finite difference approximation of the derivatives of a</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">    vector-valued function.</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    If a function maps from R^n to R^m, its derivatives form m-by-n matrix</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">    called the Jacobian, where an element (i, j) is a partial derivative of</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">    f[i] with respect to x[j].</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">    fun : callable</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">        Function of which to estimate the derivatives. The argument x</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">        passed to this function is ndarray of shape (n,) (never a scalar</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">        even if n=1). It must return 1-D array_like of shape (m,) or a scalar.</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">    x0 : array_like of shape (n,) or float</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">        Point at which to estimate the derivatives. Float will be converted</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">        to a 1-D array.</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">    method : {&#39;3-point&#39;, &#39;2-point&#39;, &#39;cs&#39;}, optional</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">        Finite difference method to use:</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">            - &#39;2-point&#39; - use the first order accuracy forward or backward</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">                          difference.</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">            - &#39;3-point&#39; - use central difference in interior points and the</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">                          second order accuracy forward or backward difference</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">                          near the boundary.</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">            - &#39;cs&#39; - use a complex-step finite difference scheme. This assumes</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">                     that the user function is real-valued and can be</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">                     analytically continued to the complex plane. Otherwise,</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">                     produces bogus results.</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    rel_step : None or array_like, optional</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">        Relative step size to use. If None (default) the absolute step size is</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">        computed as ``h = rel_step * sign(x0) * max(1, abs(x0))``, with</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">        `rel_step` being selected automatically, see Notes. Otherwise</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">        ``h = rel_step * sign(x0) * abs(x0)``. For ``method=&#39;3-point&#39;`` the</span></div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">        sign of `h` is ignored. The calculated step size is possibly adjusted</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">        to fit into the bounds.</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">    abs_step : array_like, optional</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">        Absolute step size to use, possibly adjusted to fit into the bounds.</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral">        For ``method=&#39;3-point&#39;`` the sign of `abs_step` is ignored. By default</span></div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">        relative steps are used, only if ``abs_step is not None`` are absolute</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral">        steps used.</span></div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral">    f0 : None or array_like, optional</span></div>
<div class="line"><span class="lineno">  318</span><span class="stringliteral">        If not None it is assumed to be equal to ``fun(x0)``, in this case</span></div>
<div class="line"><span class="lineno">  319</span><span class="stringliteral">        the ``fun(x0)`` is not called. Default is None.</span></div>
<div class="line"><span class="lineno">  320</span><span class="stringliteral">    bounds : tuple of array_like, optional</span></div>
<div class="line"><span class="lineno">  321</span><span class="stringliteral">        Lower and upper bounds on independent variables. Defaults to no bounds.</span></div>
<div class="line"><span class="lineno">  322</span><span class="stringliteral">        Each bound must match the size of `x0` or be a scalar, in the latter</span></div>
<div class="line"><span class="lineno">  323</span><span class="stringliteral">        case the bound will be the same for all variables. Use it to limit the</span></div>
<div class="line"><span class="lineno">  324</span><span class="stringliteral">        range of function evaluation. Bounds checking is not implemented</span></div>
<div class="line"><span class="lineno">  325</span><span class="stringliteral">        when `as_linear_operator` is True.</span></div>
<div class="line"><span class="lineno">  326</span><span class="stringliteral">    sparsity : {None, array_like, sparse matrix, 2-tuple}, optional</span></div>
<div class="line"><span class="lineno">  327</span><span class="stringliteral">        Defines a sparsity structure of the Jacobian matrix. If the Jacobian</span></div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral">        matrix is known to have only few non-zero elements in each row, then</span></div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">        it&#39;s possible to estimate its several columns by a single function</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">        evaluation [3]_. To perform such economic computations two ingredients</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral">        are required:</span></div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral">        * structure : array_like or sparse matrix of shape (m, n). A zero</span></div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral">          element means that a corresponding element of the Jacobian</span></div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">          identically equals to zero.</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral">        * groups : array_like of shape (n,). A column grouping for a given</span></div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral">          sparsity structure, use `group_columns` to obtain it.</span></div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral">        A single array or a sparse matrix is interpreted as a sparsity</span></div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">        structure, and groups are computed inside the function. A tuple is</span></div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral">        interpreted as (structure, groups). If None (default), a standard</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral">        dense differencing will be used.</span></div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">        Note, that sparse differencing makes sense only for large Jacobian</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral">        matrices where each row contains few non-zero elements.</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">    as_linear_operator : bool, optional</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">        When True the function returns an `scipy.sparse.linalg.LinearOperator`.</span></div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral">        Otherwise it returns a dense array or a sparse matrix depending on</span></div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">        `sparsity`. The linear operator provides an efficient way of computing</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">        ``J.dot(p)`` for any vector ``p`` of shape (n,), but does not allow</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">        direct access to individual elements of the matrix. By default</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral">        `as_linear_operator` is False.</span></div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral">    args, kwargs : tuple and dict, optional</span></div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">        Additional arguments passed to `fun`. Both empty by default.</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">        The calling signature is ``fun(x, *args, **kwargs)``.</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral">    J : {ndarray, sparse matrix, LinearOperator}</span></div>
<div class="line"><span class="lineno">  360</span><span class="stringliteral">        Finite difference approximation of the Jacobian matrix.</span></div>
<div class="line"><span class="lineno">  361</span><span class="stringliteral">        If `as_linear_operator` is True returns a LinearOperator</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral">        with shape (m, n). Otherwise it returns a dense array or sparse</span></div>
<div class="line"><span class="lineno">  363</span><span class="stringliteral">        matrix depending on how `sparsity` is defined. If `sparsity`</span></div>
<div class="line"><span class="lineno">  364</span><span class="stringliteral">        is None then a ndarray with shape (m, n) is returned. If</span></div>
<div class="line"><span class="lineno">  365</span><span class="stringliteral">        `sparsity` is not None returns a csr_matrix with shape (m, n).</span></div>
<div class="line"><span class="lineno">  366</span><span class="stringliteral">        For sparse matrices and linear operators it is always returned as</span></div>
<div class="line"><span class="lineno">  367</span><span class="stringliteral">        a 2-D structure, for ndarrays, if m=1 it is returned</span></div>
<div class="line"><span class="lineno">  368</span><span class="stringliteral">        as a 1-D gradient array with shape (n,).</span></div>
<div class="line"><span class="lineno">  369</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  370</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  371</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  372</span><span class="stringliteral">    check_derivative : Check correctness of a function computing derivatives.</span></div>
<div class="line"><span class="lineno">  373</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  374</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  375</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  376</span><span class="stringliteral">    If `rel_step` is not provided, it assigned as ``EPS**(1/s)``, where EPS is</span></div>
<div class="line"><span class="lineno">  377</span><span class="stringliteral">    determined from the smallest floating point dtype of `x0` or `fun(x0)`,</span></div>
<div class="line"><span class="lineno">  378</span><span class="stringliteral">    ``np.finfo(x0.dtype).eps``, s=2 for &#39;2-point&#39; method and</span></div>
<div class="line"><span class="lineno">  379</span><span class="stringliteral">    s=3 for &#39;3-point&#39; method. Such relative step approximately minimizes a sum</span></div>
<div class="line"><span class="lineno">  380</span><span class="stringliteral">    of truncation and round-off errors, see [1]_. Relative steps are used by</span></div>
<div class="line"><span class="lineno">  381</span><span class="stringliteral">    default. However, absolute steps are used when ``abs_step is not None``.</span></div>
<div class="line"><span class="lineno">  382</span><span class="stringliteral">    If any of the absolute or relative steps produces an indistinguishable</span></div>
<div class="line"><span class="lineno">  383</span><span class="stringliteral">    difference from the original `x0`, ``(x0 + dx) - x0 == 0``, then a</span></div>
<div class="line"><span class="lineno">  384</span><span class="stringliteral">    automatic step size is substituted for that particular entry.</span></div>
<div class="line"><span class="lineno">  385</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  386</span><span class="stringliteral">    A finite difference scheme for &#39;3-point&#39; method is selected automatically.</span></div>
<div class="line"><span class="lineno">  387</span><span class="stringliteral">    The well-known central difference scheme is used for points sufficiently</span></div>
<div class="line"><span class="lineno">  388</span><span class="stringliteral">    far from the boundary, and 3-point forward or backward scheme is used for</span></div>
<div class="line"><span class="lineno">  389</span><span class="stringliteral">    points near the boundary. Both schemes have the second-order accuracy in</span></div>
<div class="line"><span class="lineno">  390</span><span class="stringliteral">    terms of Taylor expansion. Refer to [2]_ for the formulas of 3-point</span></div>
<div class="line"><span class="lineno">  391</span><span class="stringliteral">    forward and backward difference schemes.</span></div>
<div class="line"><span class="lineno">  392</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  393</span><span class="stringliteral">    For dense differencing when m=1 Jacobian is returned with a shape (n,),</span></div>
<div class="line"><span class="lineno">  394</span><span class="stringliteral">    on the other hand when n=1 Jacobian is returned with a shape (m, 1).</span></div>
<div class="line"><span class="lineno">  395</span><span class="stringliteral">    Our motivation is the following: a) It handles a case of gradient</span></div>
<div class="line"><span class="lineno">  396</span><span class="stringliteral">    computation (m=1) in a conventional way. b) It clearly separates these two</span></div>
<div class="line"><span class="lineno">  397</span><span class="stringliteral">    different cases. b) In all cases np.atleast_2d can be called to get 2-D</span></div>
<div class="line"><span class="lineno">  398</span><span class="stringliteral">    Jacobian with correct dimensions.</span></div>
<div class="line"><span class="lineno">  399</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  400</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  402</span><span class="stringliteral">    .. [1] W. H. Press et. al. &quot;Numerical Recipes. The Art of Scientific</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral">           Computing. 3rd edition&quot;, sec. 5.7.</span></div>
<div class="line"><span class="lineno">  404</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral">    .. [2] A. Curtis, M. J. D. Powell, and J. Reid, &quot;On the estimation of</span></div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">           sparse Jacobian matrices&quot;, Journal of the Institute of Mathematics</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral">           and its Applications, 13 (1974), pp. 117-120.</span></div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral">    .. [3] B. Fornberg, &quot;Generation of Finite Difference Formulas on</span></div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral">           Arbitrarily Spaced Grids&quot;, Mathematics of Computation 51, 1988.</span></div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  414</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  415</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.optimize._numdiff import approx_derivative</span></div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral">    &gt;&gt;&gt;</span></div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral">    &gt;&gt;&gt; def f(x, c1, c2):</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">    ...     return np.array([x[0] * np.sin(c1 * x[1]),</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">    ...                      x[0] * np.cos(c2 * x[1])])</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral">    ...</span></div>
<div class="line"><span class="lineno">  421</span><span class="stringliteral">    &gt;&gt;&gt; x0 = np.array([1.0, 0.5 * np.pi])</span></div>
<div class="line"><span class="lineno">  422</span><span class="stringliteral">    &gt;&gt;&gt; approx_derivative(f, x0, args=(1, 2))</span></div>
<div class="line"><span class="lineno">  423</span><span class="stringliteral">    array([[ 1.,  0.],</span></div>
<div class="line"><span class="lineno">  424</span><span class="stringliteral">           [-1.,  0.]])</span></div>
<div class="line"><span class="lineno">  425</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  426</span><span class="stringliteral">    Bounds can be used to limit the region of function evaluation.</span></div>
<div class="line"><span class="lineno">  427</span><span class="stringliteral">    In the example below we compute left and right derivative at point 1.0.</span></div>
<div class="line"><span class="lineno">  428</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  429</span><span class="stringliteral">    &gt;&gt;&gt; def g(x):</span></div>
<div class="line"><span class="lineno">  430</span><span class="stringliteral">    ...     return x**2 if x &gt;= 1 else x</span></div>
<div class="line"><span class="lineno">  431</span><span class="stringliteral">    ...</span></div>
<div class="line"><span class="lineno">  432</span><span class="stringliteral">    &gt;&gt;&gt; x0 = 1.0</span></div>
<div class="line"><span class="lineno">  433</span><span class="stringliteral">    &gt;&gt;&gt; approx_derivative(g, x0, bounds=(-np.inf, 1.0))</span></div>
<div class="line"><span class="lineno">  434</span><span class="stringliteral">    array([ 1.])</span></div>
<div class="line"><span class="lineno">  435</span><span class="stringliteral">    &gt;&gt;&gt; approx_derivative(g, x0, bounds=(1.0, np.inf))</span></div>
<div class="line"><span class="lineno">  436</span><span class="stringliteral">    array([ 2.])</span></div>
<div class="line"><span class="lineno">  437</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  438</span>    <span class="keywordflow">if</span> method <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&#39;2-point&#39;</span>, <span class="stringliteral">&#39;3-point&#39;</span>, <span class="stringliteral">&#39;cs&#39;</span>]:</div>
<div class="line"><span class="lineno">  439</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Unknown method &#39;%s&#39;. &quot;</span> % method)</div>
<div class="line"><span class="lineno">  440</span> </div>
<div class="line"><span class="lineno">  441</span>    x0 = np.atleast_1d(x0)</div>
<div class="line"><span class="lineno">  442</span>    <span class="keywordflow">if</span> x0.ndim &gt; 1:</div>
<div class="line"><span class="lineno">  443</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;`x0` must have at most 1 dimension.&quot;</span>)</div>
<div class="line"><span class="lineno">  444</span> </div>
<div class="line"><span class="lineno">  445</span>    lb, ub = _prepare_bounds(bounds, x0)</div>
<div class="line"><span class="lineno">  446</span> </div>
<div class="line"><span class="lineno">  447</span>    <span class="keywordflow">if</span> lb.shape != x0.shape <span class="keywordflow">or</span> ub.shape != x0.shape:</div>
<div class="line"><span class="lineno">  448</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Inconsistent shapes between bounds and `x0`.&quot;</span>)</div>
<div class="line"><span class="lineno">  449</span> </div>
<div class="line"><span class="lineno">  450</span>    <span class="keywordflow">if</span> as_linear_operator <span class="keywordflow">and</span> <span class="keywordflow">not</span> (np.all(np.isinf(lb))</div>
<div class="line"><span class="lineno">  451</span>                                   <span class="keywordflow">and</span> np.all(np.isinf(ub))):</div>
<div class="line"><span class="lineno">  452</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Bounds not supported when &quot;</span></div>
<div class="line"><span class="lineno">  453</span>                         <span class="stringliteral">&quot;`as_linear_operator` is True.&quot;</span>)</div>
<div class="line"><span class="lineno">  454</span> </div>
<div class="line"><span class="lineno">  455</span>    <span class="keyword">def </span>fun_wrapped(x):</div>
<div class="line"><span class="lineno">  456</span>        f = np.atleast_1d(fun(x, *args, **kwargs))</div>
<div class="line"><span class="lineno">  457</span>        <span class="keywordflow">if</span> f.ndim &gt; 1:</div>
<div class="line"><span class="lineno">  458</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;`fun` return value has &quot;</span></div>
<div class="line"><span class="lineno">  459</span>                               <span class="stringliteral">&quot;more than 1 dimension.&quot;</span>)</div>
<div class="line"><span class="lineno">  460</span>        <span class="keywordflow">return</span> f</div>
<div class="line"><span class="lineno">  461</span> </div>
<div class="line"><span class="lineno">  462</span>    <span class="keywordflow">if</span> f0 <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  463</span>        f0 = fun_wrapped(x0)</div>
<div class="line"><span class="lineno">  464</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  465</span>        f0 = np.atleast_1d(f0)</div>
<div class="line"><span class="lineno">  466</span>        <span class="keywordflow">if</span> f0.ndim &gt; 1:</div>
<div class="line"><span class="lineno">  467</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;`f0` passed has more than 1 dimension.&quot;</span>)</div>
<div class="line"><span class="lineno">  468</span> </div>
<div class="line"><span class="lineno">  469</span>    <span class="keywordflow">if</span> np.any((x0 &lt; lb) | (x0 &gt; ub)):</div>
<div class="line"><span class="lineno">  470</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;`x0` violates bound constraints.&quot;</span>)</div>
<div class="line"><span class="lineno">  471</span> </div>
<div class="line"><span class="lineno">  472</span>    <span class="keywordflow">if</span> as_linear_operator:</div>
<div class="line"><span class="lineno">  473</span>        <span class="keywordflow">if</span> rel_step <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  474</span>            rel_step = _eps_for_method(x0.dtype, f0.dtype, method)</div>
<div class="line"><span class="lineno">  475</span> </div>
<div class="line"><span class="lineno">  476</span>        <span class="keywordflow">return</span> _linear_operator_difference(fun_wrapped, x0,</div>
<div class="line"><span class="lineno">  477</span>                                           f0, rel_step, method)</div>
<div class="line"><span class="lineno">  478</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  479</span>        <span class="comment"># by default we use rel_step</span></div>
<div class="line"><span class="lineno">  480</span>        <span class="keywordflow">if</span> abs_step <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  481</span>            h = _compute_absolute_step(rel_step, x0, f0, method)</div>
<div class="line"><span class="lineno">  482</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  483</span>            <span class="comment"># user specifies an absolute step</span></div>
<div class="line"><span class="lineno">  484</span>            sign_x0 = (x0 &gt;= 0).astype(float) * 2 - 1</div>
<div class="line"><span class="lineno">  485</span>            h = abs_step</div>
<div class="line"><span class="lineno">  486</span> </div>
<div class="line"><span class="lineno">  487</span>            <span class="comment"># cannot have a zero step. This might happen if x0 is very large</span></div>
<div class="line"><span class="lineno">  488</span>            <span class="comment"># or small. In which case fall back to relative step.</span></div>
<div class="line"><span class="lineno">  489</span>            dx = ((x0 + h) - x0)</div>
<div class="line"><span class="lineno">  490</span>            h = np.where(dx == 0,</div>
<div class="line"><span class="lineno">  491</span>                         _eps_for_method(x0.dtype, f0.dtype, method) *</div>
<div class="line"><span class="lineno">  492</span>                         sign_x0 * np.maximum(1.0, np.abs(x0)),</div>
<div class="line"><span class="lineno">  493</span>                         h)</div>
<div class="line"><span class="lineno">  494</span> </div>
<div class="line"><span class="lineno">  495</span>        <span class="keywordflow">if</span> method == <span class="stringliteral">&#39;2-point&#39;</span>:</div>
<div class="line"><span class="lineno">  496</span>            h, use_one_sided = _adjust_scheme_to_bounds(</div>
<div class="line"><span class="lineno">  497</span>                x0, h, 1, <span class="stringliteral">&#39;1-sided&#39;</span>, lb, ub)</div>
<div class="line"><span class="lineno">  498</span>        <span class="keywordflow">elif</span> method == <span class="stringliteral">&#39;3-point&#39;</span>:</div>
<div class="line"><span class="lineno">  499</span>            h, use_one_sided = _adjust_scheme_to_bounds(</div>
<div class="line"><span class="lineno">  500</span>                x0, h, 1, <span class="stringliteral">&#39;2-sided&#39;</span>, lb, ub)</div>
<div class="line"><span class="lineno">  501</span>        <span class="keywordflow">elif</span> method == <span class="stringliteral">&#39;cs&#39;</span>:</div>
<div class="line"><span class="lineno">  502</span>            use_one_sided = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  503</span> </div>
<div class="line"><span class="lineno">  504</span>        <span class="keywordflow">if</span> sparsity <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  505</span>            <span class="keywordflow">return</span> _dense_difference(fun_wrapped, x0, f0, h,</div>
<div class="line"><span class="lineno">  506</span>                                     use_one_sided, method)</div>
<div class="line"><span class="lineno">  507</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  508</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> issparse(sparsity) <span class="keywordflow">and</span> len(sparsity) == 2:</div>
<div class="line"><span class="lineno">  509</span>                structure, groups = sparsity</div>
<div class="line"><span class="lineno">  510</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  511</span>                structure = sparsity</div>
<div class="line"><span class="lineno">  512</span>                groups = group_columns(sparsity)</div>
<div class="line"><span class="lineno">  513</span> </div>
<div class="line"><span class="lineno">  514</span>            <span class="keywordflow">if</span> issparse(structure):</div>
<div class="line"><span class="lineno">  515</span>                structure = csc_matrix(structure)</div>
<div class="line"><span class="lineno">  516</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  517</span>                structure = np.atleast_2d(structure)</div>
<div class="line"><span class="lineno">  518</span> </div>
<div class="line"><span class="lineno">  519</span>            groups = np.atleast_1d(groups)</div>
<div class="line"><span class="lineno">  520</span>            <span class="keywordflow">return</span> _sparse_difference(fun_wrapped, x0, f0, h,</div>
<div class="line"><span class="lineno">  521</span>                                      use_one_sided, structure,</div>
<div class="line"><span class="lineno">  522</span>                                      groups, method)</div>
<div class="line"><span class="lineno">  523</span> </div>
<div class="line"><span class="lineno">  524</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a48593fae5c9c1b6a1365ff53c6e3d576" name="a48593fae5c9c1b6a1365ff53c6e3d576"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a48593fae5c9c1b6a1365ff53c6e3d576">&#9670;&#160;</a></span>check_derivative()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._numdiff.check_derivative </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fun</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>jac</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>bounds</em> = <code>(-np.inf,&#160;np.inf)</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>args</em> = <code>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>kwargs</em> = <code>{}</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check correctness of a function computing derivatives (Jacobian or
gradient) by comparison with a finite difference approximation.

Parameters
----------
fun : callable
    Function of which to estimate the derivatives. The argument x
    passed to this function is ndarray of shape (n,) (never a scalar
    even if n=1). It must return 1-D array_like of shape (m,) or a scalar.
jac : callable
    Function which computes Jacobian matrix of `fun`. It must work with
    argument x the same way as `fun`. The return value must be array_like
    or sparse matrix with an appropriate shape.
x0 : array_like of shape (n,) or float
    Point at which to estimate the derivatives. Float will be converted
    to 1-D array.
bounds : 2-tuple of array_like, optional
    Lower and upper bounds on independent variables. Defaults to no bounds.
    Each bound must match the size of `x0` or be a scalar, in the latter
    case the bound will be the same for all variables. Use it to limit the
    range of function evaluation.
args, kwargs : tuple and dict, optional
    Additional arguments passed to `fun` and `jac`. Both empty by default.
    The calling signature is ``fun(x, *args, **kwargs)`` and the same
    for `jac`.

Returns
-------
accuracy : float
    The maximum among all relative errors for elements with absolute values
    higher than 1 and absolute errors for elements with absolute values
    less or equal than 1. If `accuracy` is on the order of 1e-6 or lower,
    then it is likely that your `jac` implementation is correct.

See Also
--------
approx_derivative : Compute finite difference approximation of derivative.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from scipy.optimize._numdiff import check_derivative
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; def f(x, c1, c2):
...     return np.array([x[0] * np.sin(c1 * x[1]),
...                      x[0] * np.cos(c2 * x[1])])
...
&gt;&gt;&gt; def jac(x, c1, c2):
...     return np.array([
...         [np.sin(c1 * x[1]),  c1 * x[0] * np.cos(c1 * x[1])],
...         [np.cos(c2 * x[1]), -c2 * x[0] * np.sin(c2 * x[1])]
...     ])
...
&gt;&gt;&gt;
&gt;&gt;&gt; x0 = np.array([1.0, 0.5 * np.pi])
&gt;&gt;&gt; check_derivative(f, jac, x0, args=(1, 2))
2.4492935982947064e-16
</pre> <div class="fragment"><div class="line"><span class="lineno">  687</span>                     kwargs={}):</div>
<div class="line"><span class="lineno">  688</span>    <span class="stringliteral">&quot;&quot;&quot;Check correctness of a function computing derivatives (Jacobian or</span></div>
<div class="line"><span class="lineno">  689</span><span class="stringliteral">    gradient) by comparison with a finite difference approximation.</span></div>
<div class="line"><span class="lineno">  690</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  691</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  692</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  693</span><span class="stringliteral">    fun : callable</span></div>
<div class="line"><span class="lineno">  694</span><span class="stringliteral">        Function of which to estimate the derivatives. The argument x</span></div>
<div class="line"><span class="lineno">  695</span><span class="stringliteral">        passed to this function is ndarray of shape (n,) (never a scalar</span></div>
<div class="line"><span class="lineno">  696</span><span class="stringliteral">        even if n=1). It must return 1-D array_like of shape (m,) or a scalar.</span></div>
<div class="line"><span class="lineno">  697</span><span class="stringliteral">    jac : callable</span></div>
<div class="line"><span class="lineno">  698</span><span class="stringliteral">        Function which computes Jacobian matrix of `fun`. It must work with</span></div>
<div class="line"><span class="lineno">  699</span><span class="stringliteral">        argument x the same way as `fun`. The return value must be array_like</span></div>
<div class="line"><span class="lineno">  700</span><span class="stringliteral">        or sparse matrix with an appropriate shape.</span></div>
<div class="line"><span class="lineno">  701</span><span class="stringliteral">    x0 : array_like of shape (n,) or float</span></div>
<div class="line"><span class="lineno">  702</span><span class="stringliteral">        Point at which to estimate the derivatives. Float will be converted</span></div>
<div class="line"><span class="lineno">  703</span><span class="stringliteral">        to 1-D array.</span></div>
<div class="line"><span class="lineno">  704</span><span class="stringliteral">    bounds : 2-tuple of array_like, optional</span></div>
<div class="line"><span class="lineno">  705</span><span class="stringliteral">        Lower and upper bounds on independent variables. Defaults to no bounds.</span></div>
<div class="line"><span class="lineno">  706</span><span class="stringliteral">        Each bound must match the size of `x0` or be a scalar, in the latter</span></div>
<div class="line"><span class="lineno">  707</span><span class="stringliteral">        case the bound will be the same for all variables. Use it to limit the</span></div>
<div class="line"><span class="lineno">  708</span><span class="stringliteral">        range of function evaluation.</span></div>
<div class="line"><span class="lineno">  709</span><span class="stringliteral">    args, kwargs : tuple and dict, optional</span></div>
<div class="line"><span class="lineno">  710</span><span class="stringliteral">        Additional arguments passed to `fun` and `jac`. Both empty by default.</span></div>
<div class="line"><span class="lineno">  711</span><span class="stringliteral">        The calling signature is ``fun(x, *args, **kwargs)`` and the same</span></div>
<div class="line"><span class="lineno">  712</span><span class="stringliteral">        for `jac`.</span></div>
<div class="line"><span class="lineno">  713</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  714</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  715</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  716</span><span class="stringliteral">    accuracy : float</span></div>
<div class="line"><span class="lineno">  717</span><span class="stringliteral">        The maximum among all relative errors for elements with absolute values</span></div>
<div class="line"><span class="lineno">  718</span><span class="stringliteral">        higher than 1 and absolute errors for elements with absolute values</span></div>
<div class="line"><span class="lineno">  719</span><span class="stringliteral">        less or equal than 1. If `accuracy` is on the order of 1e-6 or lower,</span></div>
<div class="line"><span class="lineno">  720</span><span class="stringliteral">        then it is likely that your `jac` implementation is correct.</span></div>
<div class="line"><span class="lineno">  721</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  722</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  723</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  724</span><span class="stringliteral">    approx_derivative : Compute finite difference approximation of derivative.</span></div>
<div class="line"><span class="lineno">  725</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  726</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  727</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  728</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  729</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.optimize._numdiff import check_derivative</span></div>
<div class="line"><span class="lineno">  730</span><span class="stringliteral">    &gt;&gt;&gt;</span></div>
<div class="line"><span class="lineno">  731</span><span class="stringliteral">    &gt;&gt;&gt;</span></div>
<div class="line"><span class="lineno">  732</span><span class="stringliteral">    &gt;&gt;&gt; def f(x, c1, c2):</span></div>
<div class="line"><span class="lineno">  733</span><span class="stringliteral">    ...     return np.array([x[0] * np.sin(c1 * x[1]),</span></div>
<div class="line"><span class="lineno">  734</span><span class="stringliteral">    ...                      x[0] * np.cos(c2 * x[1])])</span></div>
<div class="line"><span class="lineno">  735</span><span class="stringliteral">    ...</span></div>
<div class="line"><span class="lineno">  736</span><span class="stringliteral">    &gt;&gt;&gt; def jac(x, c1, c2):</span></div>
<div class="line"><span class="lineno">  737</span><span class="stringliteral">    ...     return np.array([</span></div>
<div class="line"><span class="lineno">  738</span><span class="stringliteral">    ...         [np.sin(c1 * x[1]),  c1 * x[0] * np.cos(c1 * x[1])],</span></div>
<div class="line"><span class="lineno">  739</span><span class="stringliteral">    ...         [np.cos(c2 * x[1]), -c2 * x[0] * np.sin(c2 * x[1])]</span></div>
<div class="line"><span class="lineno">  740</span><span class="stringliteral">    ...     ])</span></div>
<div class="line"><span class="lineno">  741</span><span class="stringliteral">    ...</span></div>
<div class="line"><span class="lineno">  742</span><span class="stringliteral">    &gt;&gt;&gt;</span></div>
<div class="line"><span class="lineno">  743</span><span class="stringliteral">    &gt;&gt;&gt; x0 = np.array([1.0, 0.5 * np.pi])</span></div>
<div class="line"><span class="lineno">  744</span><span class="stringliteral">    &gt;&gt;&gt; check_derivative(f, jac, x0, args=(1, 2))</span></div>
<div class="line"><span class="lineno">  745</span><span class="stringliteral">    2.4492935982947064e-16</span></div>
<div class="line"><span class="lineno">  746</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  747</span>    J_to_test = jac(x0, *args, **kwargs)</div>
<div class="line"><span class="lineno">  748</span>    <span class="keywordflow">if</span> issparse(J_to_test):</div>
<div class="line"><span class="lineno">  749</span>        J_diff = approx_derivative(fun, x0, bounds=bounds, sparsity=J_to_test,</div>
<div class="line"><span class="lineno">  750</span>                                   args=args, kwargs=kwargs)</div>
<div class="line"><span class="lineno">  751</span>        J_to_test = csr_matrix(J_to_test)</div>
<div class="line"><span class="lineno">  752</span>        abs_err = J_to_test - J_diff</div>
<div class="line"><span class="lineno">  753</span>        i, j, abs_err_data = find(abs_err)</div>
<div class="line"><span class="lineno">  754</span>        J_diff_data = np.asarray(J_diff[i, j]).ravel()</div>
<div class="line"><span class="lineno">  755</span>        <span class="keywordflow">return</span> np.max(np.abs(abs_err_data) /</div>
<div class="line"><span class="lineno">  756</span>                      np.maximum(1, np.abs(J_diff_data)))</div>
<div class="line"><span class="lineno">  757</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  758</span>        J_diff = approx_derivative(fun, x0, bounds=bounds,</div>
<div class="line"><span class="lineno">  759</span>                                   args=args, kwargs=kwargs)</div>
<div class="line"><span class="lineno">  760</span>        abs_err = np.abs(J_to_test - J_diff)</div>
<div class="line"><span class="lineno">  761</span>        <span class="keywordflow">return</span> np.max(abs_err / np.maximum(1, np.abs(J_diff)))</div>
</div><!-- fragment -->
</div>
</div>
<a id="a81c9baed80ae81b795e95751bbac5f22" name="a81c9baed80ae81b795e95751bbac5f22"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a81c9baed80ae81b795e95751bbac5f22">&#9670;&#160;</a></span>group_columns()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.optimize._numdiff.group_columns </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>order</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Group columns of a 2-D matrix for sparse finite differencing [1]_.

Two columns are in the same group if in each row at least one of them
has zero. A greedy sequential algorithm is used to construct groups.

Parameters
----------
A : array_like or sparse matrix, shape (m, n)
    Matrix of which to group columns.
order : int, iterable of int with shape (n,) or None
    Permutation array which defines the order of columns enumeration.
    If int or None, a random permutation is used with `order` used as
    a random seed. Default is 0, that is use a random permutation but
    guarantee repeatability.

Returns
-------
groups : ndarray of int, shape (n,)
    Contains values from 0 to n_groups-1, where n_groups is the number
    of found groups. Each value ``groups[i]`` is an index of a group to
    which ith column assigned. The procedure was helpful only if
    n_groups is significantly less than n.

References
----------
.. [1] A. Curtis, M. J. D. Powell, and J. Reid, "On the estimation of
       sparse Jacobian matrices", Journal of the Institute of Mathematics
       and its Applications, 13 (1974), pp. 117-120.
</pre> <div class="fragment"><div class="line"><span class="lineno">  214</span><span class="keyword">def </span>group_columns(A, order=0):</div>
<div class="line"><span class="lineno">  215</span>    <span class="stringliteral">&quot;&quot;&quot;Group columns of a 2-D matrix for sparse finite differencing [1]_.</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">    Two columns are in the same group if in each row at least one of them</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">    has zero. A greedy sequential algorithm is used to construct groups.</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">    A : array_like or sparse matrix, shape (m, n)</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">        Matrix of which to group columns.</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">    order : int, iterable of int with shape (n,) or None</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">        Permutation array which defines the order of columns enumeration.</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">        If int or None, a random permutation is used with `order` used as</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">        a random seed. Default is 0, that is use a random permutation but</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">        guarantee repeatability.</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">    groups : ndarray of int, shape (n,)</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">        Contains values from 0 to n_groups-1, where n_groups is the number</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">        of found groups. Each value ``groups[i]`` is an index of a group to</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">        which ith column assigned. The procedure was helpful only if</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">        n_groups is significantly less than n.</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">    .. [1] A. Curtis, M. J. D. Powell, and J. Reid, &quot;On the estimation of</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">           sparse Jacobian matrices&quot;, Journal of the Institute of Mathematics</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">           and its Applications, 13 (1974), pp. 117-120.</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  244</span>    <span class="keywordflow">if</span> issparse(A):</div>
<div class="line"><span class="lineno">  245</span>        A = csc_matrix(A)</div>
<div class="line"><span class="lineno">  246</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  247</span>        A = np.atleast_2d(A)</div>
<div class="line"><span class="lineno">  248</span>        A = (A != 0).astype(np.int32)</div>
<div class="line"><span class="lineno">  249</span> </div>
<div class="line"><span class="lineno">  250</span>    <span class="keywordflow">if</span> A.ndim != 2:</div>
<div class="line"><span class="lineno">  251</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;`A` must be 2-dimensional.&quot;</span>)</div>
<div class="line"><span class="lineno">  252</span> </div>
<div class="line"><span class="lineno">  253</span>    m, n = A.shape</div>
<div class="line"><span class="lineno">  254</span> </div>
<div class="line"><span class="lineno">  255</span>    <span class="keywordflow">if</span> order <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">or</span> np.isscalar(order):</div>
<div class="line"><span class="lineno">  256</span>        rng = np.random.RandomState(order)</div>
<div class="line"><span class="lineno">  257</span>        order = rng.permutation(n)</div>
<div class="line"><span class="lineno">  258</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  259</span>        order = np.asarray(order)</div>
<div class="line"><span class="lineno">  260</span>        <span class="keywordflow">if</span> order.shape != (n,):</div>
<div class="line"><span class="lineno">  261</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;`order` has incorrect shape.&quot;</span>)</div>
<div class="line"><span class="lineno">  262</span> </div>
<div class="line"><span class="lineno">  263</span>    A = A[:, order]</div>
<div class="line"><span class="lineno">  264</span> </div>
<div class="line"><span class="lineno">  265</span>    <span class="keywordflow">if</span> issparse(A):</div>
<div class="line"><span class="lineno">  266</span>        groups = group_sparse(m, n, A.indices, A.indptr)</div>
<div class="line"><span class="lineno">  267</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  268</span>        groups = group_dense(m, n, A)</div>
<div class="line"><span class="lineno">  269</span> </div>
<div class="line"><span class="lineno">  270</span>    groups[order] = groups.copy()</div>
<div class="line"><span class="lineno">  271</span> </div>
<div class="line"><span class="lineno">  272</span>    <span class="keywordflow">return</span> groups</div>
<div class="line"><span class="lineno">  273</span> </div>
<div class="line"><span class="lineno">  274</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
