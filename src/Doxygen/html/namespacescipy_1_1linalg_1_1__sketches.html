<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: scipy.linalg._sketches Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacescipy.html">scipy</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1linalg.html">linalg</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1linalg_1_1__sketches.html">_sketches</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">scipy.linalg._sketches Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a34ac2c9b55daa493578ce03b85322451" id="r_a34ac2c9b55daa493578ce03b85322451"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1linalg_1_1__sketches.html#a34ac2c9b55daa493578ce03b85322451">cwt_matrix</a> (n_rows, n_columns, seed=None)</td></tr>
<tr class="separator:a34ac2c9b55daa493578ce03b85322451"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a423ca282fc3a7b74fefcd1640133e9d2" id="r_a423ca282fc3a7b74fefcd1640133e9d2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1linalg_1_1__sketches.html#a423ca282fc3a7b74fefcd1640133e9d2">clarkson_woodruff_transform</a> (input_matrix, sketch_size, seed=None)</td></tr>
<tr class="separator:a423ca282fc3a7b74fefcd1640133e9d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment"> Sketching-based Matrix Computations </pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a423ca282fc3a7b74fefcd1640133e9d2" name="a423ca282fc3a7b74fefcd1640133e9d2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a423ca282fc3a7b74fefcd1640133e9d2">&#9670;&#160;</a></span>clarkson_woodruff_transform()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.linalg._sketches.clarkson_woodruff_transform </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_matrix</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sketch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>seed</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Applies a Clarkson-Woodruff Transform/sketch to the input matrix.

    Given an input_matrix ``A`` of size ``(n, d)``, compute a matrix ``A'`` of
    size (sketch_size, d) so that

    .. math:: \|Ax\| \approx \|A'x\|

    with high probability via the Clarkson-Woodruff Transform, otherwise
    known as the CountSketch matrix.

    Parameters
    ----------
    input_matrix : array_like
        Input matrix, of shape ``(n, d)``.
    sketch_size : int
        Number of rows for the sketch.
    seed : {None, int, `numpy.random.Generator`,
            `numpy.random.RandomState`}, optional

        If `seed` is None (or `np.random`), the `numpy.random.RandomState`
        singleton is used.
        If `seed` is an int, a new ``RandomState`` instance is used,
        seeded with `seed`.
        If `seed` is already a ``Generator`` or ``RandomState`` instance then
        that instance is used.

    Returns
    -------
    A' : array_like
        Sketch of the input matrix ``A``, of size ``(sketch_size, d)``.

    Notes
    -----
    To make the statement

    .. math:: \|Ax\| \approx \|A'x\|

    precise, observe the following result which is adapted from the
    proof of Theorem 14 of [2]_ via Markov's Inequality. If we have
    a sketch size ``sketch_size=k`` which is at least

    .. math:: k \geq \frac{2}{\epsilon^2\delta}

    Then for any fixed vector ``x``,

    .. math:: \|Ax\| = (1\pm\epsilon)\|A'x\|

    with probability at least one minus delta.

    This implementation takes advantage of sparsity: computing
    a sketch takes time proportional to ``A.nnz``. Data ``A`` which
    is in ``scipy.sparse.csc_matrix`` format gives the quickest
    computation time for sparse input.

    &gt;&gt;&gt; from scipy import linalg
    &gt;&gt;&gt; from scipy import sparse
    &gt;&gt;&gt; rng = np.random.default_rng()
    &gt;&gt;&gt; n_rows, n_columns, density, sketch_n_rows = 15000, 100, 0.01, 200
    &gt;&gt;&gt; A = sparse.rand(n_rows, n_columns, density=density, format='csc')
    &gt;&gt;&gt; B = sparse.rand(n_rows, n_columns, density=density, format='csr')
    &gt;&gt;&gt; C = sparse.rand(n_rows, n_columns, density=density, format='coo')
    &gt;&gt;&gt; D = rng.standard_normal((n_rows, n_columns))
    &gt;&gt;&gt; SA = linalg.clarkson_woodruff_transform(A, sketch_n_rows) # fastest
    &gt;&gt;&gt; SB = linalg.clarkson_woodruff_transform(B, sketch_n_rows) # fast
    &gt;&gt;&gt; SC = linalg.clarkson_woodruff_transform(C, sketch_n_rows) # slower
    &gt;&gt;&gt; SD = linalg.clarkson_woodruff_transform(D, sketch_n_rows) # slowest

    That said, this method does perform well on dense inputs, just slower
    on a relative scale.

    Examples
    --------
    Given a big dense matrix ``A``:

    &gt;&gt;&gt; from scipy import linalg
    &gt;&gt;&gt; n_rows, n_columns, sketch_n_rows = 15000, 100, 200
    &gt;&gt;&gt; rng = np.random.default_rng()
    &gt;&gt;&gt; A = rng.standard_normal((n_rows, n_columns))
    &gt;&gt;&gt; sketch = linalg.clarkson_woodruff_transform(A, sketch_n_rows)
    &gt;&gt;&gt; sketch.shape
    (200, 100)
    &gt;&gt;&gt; norm_A = np.linalg.norm(A)
    &gt;&gt;&gt; norm_sketch = np.linalg.norm(sketch)

    Now with high probability, the true norm ``norm_A`` is close to
    the sketched norm ``norm_sketch`` in absolute value.

    Similarly, applying our sketch preserves the solution to a linear
    regression of :math:`\min \|Ax - b\|`.

    &gt;&gt;&gt; from scipy import linalg
    &gt;&gt;&gt; n_rows, n_columns, sketch_n_rows = 15000, 100, 200
    &gt;&gt;&gt; rng = np.random.default_rng()
    &gt;&gt;&gt; A = rng.standard_normal((n_rows, n_columns))
    &gt;&gt;&gt; b = rng.standard_normal(n_rows)
    &gt;&gt;&gt; x = np.linalg.lstsq(A, b, rcond=None)
    &gt;&gt;&gt; Ab = np.hstack((A, b.reshape(-1,1)))
    &gt;&gt;&gt; SAb = linalg.clarkson_woodruff_transform(Ab, sketch_n_rows)
    &gt;&gt;&gt; SA, Sb = SAb[:,:-1], SAb[:,-1]
    &gt;&gt;&gt; x_sketched = np.linalg.lstsq(SA, Sb, rcond=None)

    As with the matrix norm example, ``np.linalg.norm(A @ x - b)``
    is close to ``np.linalg.norm(A @ x_sketched - b)`` with high
    probability.

    References
    ----------
    .. [1] Kenneth L. Clarkson and David P. Woodruff. Low rank approximation and
           regression in input sparsity time. In STOC, 2013.

    .. [2] David P. Woodruff. Sketching as a tool for numerical linear algebra.
           In Foundations and Trends in Theoretical Computer Science, 2014.</pre> <div class="fragment"><div class="line"><span class="lineno">   58</span><span class="keyword">def </span>clarkson_woodruff_transform(input_matrix, sketch_size, seed=None):</div>
<div class="line"><span class="lineno">   59</span>    <span class="stringliteral">r&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">    Applies a Clarkson-Woodruff Transform/sketch to the input matrix.</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">    Given an input_matrix ``A`` of size ``(n, d)``, compute a matrix ``A&#39;`` of</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">    size (sketch_size, d) so that</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">    .. math:: \|Ax\| \approx \|A&#39;x\|</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    with high probability via the Clarkson-Woodruff Transform, otherwise</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">    known as the CountSketch matrix.</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">    input_matrix : array_like</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">        Input matrix, of shape ``(n, d)``.</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">    sketch_size : int</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">        Number of rows for the sketch.</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">    seed : {None, int, `numpy.random.Generator`,</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">            `numpy.random.RandomState`}, optional</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">        If `seed` is None (or `np.random`), the `numpy.random.RandomState`</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">        singleton is used.</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral">        If `seed` is an int, a new ``RandomState`` instance is used,</span></div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">        seeded with `seed`.</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">        If `seed` is already a ``Generator`` or ``RandomState`` instance then</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral">        that instance is used.</span></div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">    A&#39; : array_like</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">        Sketch of the input matrix ``A``, of size ``(sketch_size, d)``.</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral">    To make the statement</span></div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral">    .. math:: \|Ax\| \approx \|A&#39;x\|</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral">    precise, observe the following result which is adapted from the</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">    proof of Theorem 14 of [2]_ via Markov&#39;s Inequality. If we have</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">    a sketch size ``sketch_size=k`` which is at least</span></div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">    .. math:: k \geq \frac{2}{\epsilon^2\delta}</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">    Then for any fixed vector ``x``,</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral">    .. math:: \|Ax\| = (1\pm\epsilon)\|A&#39;x\|</span></div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral">    with probability at least one minus delta.</span></div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">    This implementation takes advantage of sparsity: computing</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral">    a sketch takes time proportional to ``A.nnz``. Data ``A`` which</span></div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral">    is in ``scipy.sparse.csc_matrix`` format gives the quickest</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral">    computation time for sparse input.</span></div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">    &gt;&gt;&gt; from scipy import linalg</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">    &gt;&gt;&gt; from scipy import sparse</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral">    &gt;&gt;&gt; rng = np.random.default_rng()</span></div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">    &gt;&gt;&gt; n_rows, n_columns, density, sketch_n_rows = 15000, 100, 0.01, 200</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">    &gt;&gt;&gt; A = sparse.rand(n_rows, n_columns, density=density, format=&#39;csc&#39;)</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral">    &gt;&gt;&gt; B = sparse.rand(n_rows, n_columns, density=density, format=&#39;csr&#39;)</span></div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral">    &gt;&gt;&gt; C = sparse.rand(n_rows, n_columns, density=density, format=&#39;coo&#39;)</span></div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral">    &gt;&gt;&gt; D = rng.standard_normal((n_rows, n_columns))</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">    &gt;&gt;&gt; SA = linalg.clarkson_woodruff_transform(A, sketch_n_rows) # fastest</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">    &gt;&gt;&gt; SB = linalg.clarkson_woodruff_transform(B, sketch_n_rows) # fast</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">    &gt;&gt;&gt; SC = linalg.clarkson_woodruff_transform(C, sketch_n_rows) # slower</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral">    &gt;&gt;&gt; SD = linalg.clarkson_woodruff_transform(D, sketch_n_rows) # slowest</span></div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral">    That said, this method does perform well on dense inputs, just slower</span></div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral">    on a relative scale.</span></div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral">    Given a big dense matrix ``A``:</span></div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">    &gt;&gt;&gt; from scipy import linalg</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">    &gt;&gt;&gt; n_rows, n_columns, sketch_n_rows = 15000, 100, 200</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">    &gt;&gt;&gt; rng = np.random.default_rng()</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">    &gt;&gt;&gt; A = rng.standard_normal((n_rows, n_columns))</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">    &gt;&gt;&gt; sketch = linalg.clarkson_woodruff_transform(A, sketch_n_rows)</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral">    &gt;&gt;&gt; sketch.shape</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">    (200, 100)</span></div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">    &gt;&gt;&gt; norm_A = np.linalg.norm(A)</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">    &gt;&gt;&gt; norm_sketch = np.linalg.norm(sketch)</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">    Now with high probability, the true norm ``norm_A`` is close to</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">    the sketched norm ``norm_sketch`` in absolute value.</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">    Similarly, applying our sketch preserves the solution to a linear</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">    regression of :math:`\min \|Ax - b\|`.</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">    &gt;&gt;&gt; from scipy import linalg</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">    &gt;&gt;&gt; n_rows, n_columns, sketch_n_rows = 15000, 100, 200</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">    &gt;&gt;&gt; rng = np.random.default_rng()</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">    &gt;&gt;&gt; A = rng.standard_normal((n_rows, n_columns))</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">    &gt;&gt;&gt; b = rng.standard_normal(n_rows)</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">    &gt;&gt;&gt; x = np.linalg.lstsq(A, b, rcond=None)</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">    &gt;&gt;&gt; Ab = np.hstack((A, b.reshape(-1,1)))</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">    &gt;&gt;&gt; SAb = linalg.clarkson_woodruff_transform(Ab, sketch_n_rows)</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">    &gt;&gt;&gt; SA, Sb = SAb[:,:-1], SAb[:,-1]</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">    &gt;&gt;&gt; x_sketched = np.linalg.lstsq(SA, Sb, rcond=None)</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">    As with the matrix norm example, ``np.linalg.norm(A @ x - b)``</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">    is close to ``np.linalg.norm(A @ x_sketched - b)`` with high</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">    probability.</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">    .. [1] Kenneth L. Clarkson and David P. Woodruff. Low rank approximation and</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">           regression in input sparsity time. In STOC, 2013.</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">    .. [2] David P. Woodruff. Sketching as a tool for numerical linear algebra.</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">           In Foundations and Trends in Theoretical Computer Science, 2014.</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  174</span>    S = cwt_matrix(sketch_size, input_matrix.shape[0], seed)</div>
<div class="line"><span class="lineno">  175</span>    <span class="keywordflow">return</span> S.dot(input_matrix)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a34ac2c9b55daa493578ce03b85322451" name="a34ac2c9b55daa493578ce03b85322451"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34ac2c9b55daa493578ce03b85322451">&#9670;&#160;</a></span>cwt_matrix()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.linalg._sketches.cwt_matrix </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_columns</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>seed</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Generate a matrix S which represents a Clarkson-Woodruff transform.

    Given the desired size of matrix, the method returns a matrix S of size
    (n_rows, n_columns) where each column has all the entries set to 0
    except for one position which has been randomly set to +1 or -1 with
    equal probability.

    Parameters
    ----------
    n_rows : int
        Number of rows of S
    n_columns : int
        Number of columns of S
    seed : {None, int, `numpy.random.Generator`,
            `numpy.random.RandomState`}, optional

        If `seed` is None (or `np.random`), the `numpy.random.RandomState`
        singleton is used.
        If `seed` is an int, a new ``RandomState`` instance is used,
        seeded with `seed`.
        If `seed` is already a ``Generator`` or ``RandomState`` instance then
        that instance is used.

    Returns
    -------
    S : (n_rows, n_columns) csc_matrix
        The returned matrix has ``n_columns`` nonzero entries.

    Notes
    -----
    Given a matrix A, with probability at least 9/10,
    .. math:: \|SA\| = (1 \pm \epsilon)\|A\|
    Where the error epsilon is related to the size of S.</pre> <div class="fragment"><div class="line"><span class="lineno">   14</span><span class="keyword">def </span>cwt_matrix(n_rows, n_columns, seed=None):</div>
<div class="line"><span class="lineno">   15</span>    <span class="stringliteral">r&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   16</span><span class="stringliteral">    Generate a matrix S which represents a Clarkson-Woodruff transform.</span></div>
<div class="line"><span class="lineno">   17</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   18</span><span class="stringliteral">    Given the desired size of matrix, the method returns a matrix S of size</span></div>
<div class="line"><span class="lineno">   19</span><span class="stringliteral">    (n_rows, n_columns) where each column has all the entries set to 0</span></div>
<div class="line"><span class="lineno">   20</span><span class="stringliteral">    except for one position which has been randomly set to +1 or -1 with</span></div>
<div class="line"><span class="lineno">   21</span><span class="stringliteral">    equal probability.</span></div>
<div class="line"><span class="lineno">   22</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   23</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   24</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   25</span><span class="stringliteral">    n_rows : int</span></div>
<div class="line"><span class="lineno">   26</span><span class="stringliteral">        Number of rows of S</span></div>
<div class="line"><span class="lineno">   27</span><span class="stringliteral">    n_columns : int</span></div>
<div class="line"><span class="lineno">   28</span><span class="stringliteral">        Number of columns of S</span></div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">    seed : {None, int, `numpy.random.Generator`,</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral">            `numpy.random.RandomState`}, optional</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">        If `seed` is None (or `np.random`), the `numpy.random.RandomState`</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">        singleton is used.</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">        If `seed` is an int, a new ``RandomState`` instance is used,</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">        seeded with `seed`.</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">        If `seed` is already a ``Generator`` or ``RandomState`` instance then</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral">        that instance is used.</span></div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">    S : (n_rows, n_columns) csc_matrix</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral">        The returned matrix has ``n_columns`` nonzero entries.</span></div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">    Given a matrix A, with probability at least 9/10,</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">    .. math:: \|SA\| = (1 \pm \epsilon)\|A\|</span></div>
<div class="line"><span class="lineno">   48</span><span class="stringliteral">    Where the error epsilon is related to the size of S.</span></div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   50</span>    rng = check_random_state(seed)</div>
<div class="line"><span class="lineno">   51</span>    rows = rng_integers(rng, 0, n_rows, n_columns)</div>
<div class="line"><span class="lineno">   52</span>    cols = np.arange(n_columns+1)</div>
<div class="line"><span class="lineno">   53</span>    signs = rng.choice([1, -1], n_columns)</div>
<div class="line"><span class="lineno">   54</span>    S = csc_matrix((signs, rows, cols),shape=(n_rows, n_columns))</div>
<div class="line"><span class="lineno">   55</span>    <span class="keywordflow">return</span> S</div>
<div class="line"><span class="lineno">   56</span> </div>
<div class="line"><span class="lineno">   57</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
