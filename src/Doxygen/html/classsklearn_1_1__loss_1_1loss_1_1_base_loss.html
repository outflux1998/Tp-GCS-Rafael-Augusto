<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn._loss.loss.BaseLoss Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1__loss.html">_loss</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1__loss_1_1loss.html">loss</a></li><li class="navelem"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html">BaseLoss</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pub-static-attribs">Static Public Attributes</a> &#124;
<a href="classsklearn_1_1__loss_1_1loss_1_1_base_loss-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">sklearn._loss.loss.BaseLoss Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for sklearn._loss.loss.BaseLoss:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classsklearn_1_1__loss_1_1loss_1_1_base_loss.png" usemap="#sklearn._5Floss.loss.BaseLoss_map" alt=""/>
  <map id="sklearn._5Floss.loss.BaseLoss_map" name="sklearn._5Floss.loss.BaseLoss_map">
<area href="classsklearn_1_1__loss_1_1loss_1_1_absolute_error.html" alt="sklearn._loss.loss.AbsoluteError" shape="rect" coords="262,56,514,80"/>
<area href="classsklearn_1_1__loss_1_1loss_1_1_half_binomial_loss.html" alt="sklearn._loss.loss.HalfBinomialLoss" shape="rect" coords="262,112,514,136"/>
<area href="classsklearn_1_1__loss_1_1loss_1_1_half_gamma_loss.html" alt="sklearn._loss.loss.HalfGammaLoss" shape="rect" coords="262,168,514,192"/>
<area href="classsklearn_1_1__loss_1_1loss_1_1_half_multinomial_loss.html" alt="sklearn._loss.loss.HalfMultinomialLoss" shape="rect" coords="262,224,514,248"/>
<area href="classsklearn_1_1__loss_1_1loss_1_1_half_poisson_loss.html" alt="sklearn._loss.loss.HalfPoissonLoss" shape="rect" coords="262,280,514,304"/>
<area href="classsklearn_1_1__loss_1_1loss_1_1_half_squared_error.html" alt="sklearn._loss.loss.HalfSquaredError" shape="rect" coords="262,336,514,360"/>
<area href="classsklearn_1_1__loss_1_1loss_1_1_half_tweedie_loss.html" alt="sklearn._loss.loss.HalfTweedieLoss" shape="rect" coords="262,392,514,416"/>
<area href="classsklearn_1_1__loss_1_1loss_1_1_half_tweedie_loss_identity.html" alt="sklearn._loss.loss.HalfTweedieLossIdentity" shape="rect" coords="262,448,514,472"/>
<area href="classsklearn_1_1__loss_1_1loss_1_1_pinball_loss.html" alt="sklearn._loss.loss.PinballLoss" shape="rect" coords="262,504,514,528"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a050f99cd8950283f434ace55115a40f7" id="r_a050f99cd8950283f434ace55115a40f7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a050f99cd8950283f434ace55115a40f7">__init__</a> (self, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a2ac0fa5ee5b2367424987b8615b68504">closs</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a8b3ad72e068f068732da4e6b9232e456">link</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#af23ae122eda60d60851e8bc38c5c85ce">n_classes</a>=None)</td></tr>
<tr class="separator:a050f99cd8950283f434ace55115a40f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf48e9151cdfbf2a35fda2f78fff42ae" id="r_acf48e9151cdfbf2a35fda2f78fff42ae"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#acf48e9151cdfbf2a35fda2f78fff42ae">in_y_true_range</a> (self, y)</td></tr>
<tr class="separator:acf48e9151cdfbf2a35fda2f78fff42ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af11ab89ac55cbdc1fc3b64dc68e8e75d" id="r_af11ab89ac55cbdc1fc3b64dc68e8e75d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#af11ab89ac55cbdc1fc3b64dc68e8e75d">in_y_pred_range</a> (self, y)</td></tr>
<tr class="separator:af11ab89ac55cbdc1fc3b64dc68e8e75d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae355aae4c96c62732fb026e5241d9321" id="r_ae355aae4c96c62732fb026e5241d9321"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#ae355aae4c96c62732fb026e5241d9321">loss</a> (self, y_true, raw_prediction, sample_weight=None, loss_out=None, n_threads=1)</td></tr>
<tr class="separator:ae355aae4c96c62732fb026e5241d9321"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8c71136140d8c86d2d5bd5ace8bbd41d" id="r_a8c71136140d8c86d2d5bd5ace8bbd41d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a8c71136140d8c86d2d5bd5ace8bbd41d">loss_gradient</a> (self, y_true, raw_prediction, sample_weight=None, loss_out=None, gradient_out=None, n_threads=1)</td></tr>
<tr class="separator:a8c71136140d8c86d2d5bd5ace8bbd41d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff7a3496ececc5dd431f51815620a4b9" id="r_aff7a3496ececc5dd431f51815620a4b9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#aff7a3496ececc5dd431f51815620a4b9">gradient</a> (self, y_true, raw_prediction, sample_weight=None, gradient_out=None, n_threads=1)</td></tr>
<tr class="separator:aff7a3496ececc5dd431f51815620a4b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7b33139cdecec21fd2044c9a618c94d" id="r_ae7b33139cdecec21fd2044c9a618c94d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#ae7b33139cdecec21fd2044c9a618c94d">gradient_hessian</a> (self, y_true, raw_prediction, sample_weight=None, gradient_out=None, hessian_out=None, n_threads=1)</td></tr>
<tr class="separator:ae7b33139cdecec21fd2044c9a618c94d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a294afc783ab728aa3bfd859988493b35" id="r_a294afc783ab728aa3bfd859988493b35"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a294afc783ab728aa3bfd859988493b35">__call__</a> (self, y_true, raw_prediction, sample_weight=None, n_threads=1)</td></tr>
<tr class="separator:a294afc783ab728aa3bfd859988493b35"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40afc87a56422158efbb681e18868a08" id="r_a40afc87a56422158efbb681e18868a08"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a40afc87a56422158efbb681e18868a08">fit_intercept_only</a> (self, y_true, sample_weight=None)</td></tr>
<tr class="separator:a40afc87a56422158efbb681e18868a08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc7a673025ec0b05993a924d54d6a6c5" id="r_afc7a673025ec0b05993a924d54d6a6c5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#afc7a673025ec0b05993a924d54d6a6c5">constant_to_optimal_zero</a> (self, y_true, sample_weight=None)</td></tr>
<tr class="separator:afc7a673025ec0b05993a924d54d6a6c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a481e142c26f1a4db2dfaf2f7648fa725" id="r_a481e142c26f1a4db2dfaf2f7648fa725"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a481e142c26f1a4db2dfaf2f7648fa725">init_gradient_and_hessian</a> (self, n_samples, dtype=np.float64, <a class="el" href="__lapack__subroutines_8h.html#a9993259f1ab17738593f079acd0507d9">order</a>=&quot;F&quot;)</td></tr>
<tr class="separator:a481e142c26f1a4db2dfaf2f7648fa725"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a2ac0fa5ee5b2367424987b8615b68504" id="r_a2ac0fa5ee5b2367424987b8615b68504"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a2ac0fa5ee5b2367424987b8615b68504">closs</a></td></tr>
<tr class="separator:a2ac0fa5ee5b2367424987b8615b68504"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b3ad72e068f068732da4e6b9232e456" id="r_a8b3ad72e068f068732da4e6b9232e456"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a8b3ad72e068f068732da4e6b9232e456">link</a></td></tr>
<tr class="separator:a8b3ad72e068f068732da4e6b9232e456"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada9acc010b0ab4b457f50f3a170e7013" id="r_ada9acc010b0ab4b457f50f3a170e7013"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#ada9acc010b0ab4b457f50f3a170e7013">approx_hessian</a></td></tr>
<tr class="separator:ada9acc010b0ab4b457f50f3a170e7013"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa79306c6b3e4e91e621c81695e0cc4d4" id="r_aa79306c6b3e4e91e621c81695e0cc4d4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#aa79306c6b3e4e91e621c81695e0cc4d4">constant_hessian</a></td></tr>
<tr class="separator:aa79306c6b3e4e91e621c81695e0cc4d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af23ae122eda60d60851e8bc38c5c85ce" id="r_af23ae122eda60d60851e8bc38c5c85ce"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#af23ae122eda60d60851e8bc38c5c85ce">n_classes</a></td></tr>
<tr class="separator:af23ae122eda60d60851e8bc38c5c85ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87a5c64b956653d473dfdc03b166b2fe" id="r_a87a5c64b956653d473dfdc03b166b2fe"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a87a5c64b956653d473dfdc03b166b2fe">interval_y_true</a></td></tr>
<tr class="separator:a87a5c64b956653d473dfdc03b166b2fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4aa175acb7ee145417f199c73f131707" id="r_a4aa175acb7ee145417f199c73f131707"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a4aa175acb7ee145417f199c73f131707">interval_y_pred</a></td></tr>
<tr class="separator:a4aa175acb7ee145417f199c73f131707"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-static-attribs" name="pub-static-attribs"></a>
Static Public Attributes</h2></td></tr>
<tr class="memitem:ad38d68671d8b0604ac278813a5139959" id="r_ad38d68671d8b0604ac278813a5139959"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#ad38d68671d8b0604ac278813a5139959">need_update_leaves_values</a> = False</td></tr>
<tr class="separator:ad38d68671d8b0604ac278813a5139959"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d8526c6ce3454df71ea3328d46cb75b" id="r_a1d8526c6ce3454df71ea3328d46cb75b"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#a1d8526c6ce3454df71ea3328d46cb75b">differentiable</a> = True</td></tr>
<tr class="separator:a1d8526c6ce3454df71ea3328d46cb75b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba86d98f29852fcffb6c2a244a1da10d" id="r_aba86d98f29852fcffb6c2a244a1da10d"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_base_loss.html#aba86d98f29852fcffb6c2a244a1da10d">is_multiclass</a> = False</td></tr>
<tr class="separator:aba86d98f29852fcffb6c2a244a1da10d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Base class for a loss function of 1-dimensional targets.

Conventions:

    - y_true.shape = sample_weight.shape = (n_samples,)
    - y_pred.shape = raw_prediction.shape = (n_samples,)
    - If is_multiclass is true (multiclass classification), then
      y_pred.shape = raw_prediction.shape = (n_samples, n_classes)
      Note that this corresponds to the return value of decision_function.

y_true, y_pred, sample_weight and raw_prediction must either be all float64
or all float32.
gradient and hessian must be either both float64 or both float32.

Note that y_pred = link.inverse(raw_prediction).

Specific loss classes can inherit specific link classes to satisfy
BaseLink's abstractmethods.

Parameters
----------
sample_weight : {None, ndarray}
    If sample_weight is None, the hessian might be constant.
n_classes : {None, int}
    The number of classes for classification, else None.

Attributes
----------
closs: CyLossFunction
link : BaseLink
interval_y_true : Interval
    Valid interval for y_true
interval_y_pred : Interval
    Valid Interval for y_pred
differentiable : bool
    Indicates whether or not loss function is differentiable in
    raw_prediction everywhere.
need_update_leaves_values : bool
    Indicates whether decision trees in gradient boosting need to uptade
    leave values after having been fit to the (negative) gradients.
approx_hessian : bool
    Indicates whether the hessian is approximated or exact. If,
    approximated, it should be larger or equal to the exact one.
constant_hessian : bool
    Indicates whether the hessian is one for this loss.
is_multiclass : bool
    Indicates whether n_classes &gt; 2 is allowed.
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a050f99cd8950283f434ace55115a40f7" name="a050f99cd8950283f434ace55115a40f7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a050f99cd8950283f434ace55115a40f7">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>closs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>link</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_classes</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reimplemented in <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_squared_error.html#a12fcc0196495006a251c07a8a20da166">sklearn._loss.loss.HalfSquaredError</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_absolute_error.html#a6698a0abc1c648f07739077247e1b51d">sklearn._loss.loss.AbsoluteError</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_poisson_loss.html#ac9c453ea6c0d2fc67690b53efb537bf1">sklearn._loss.loss.HalfPoissonLoss</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_gamma_loss.html#a3fe80aaf468565af8c5a169007e5bb87">sklearn._loss.loss.HalfGammaLoss</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_binomial_loss.html#a03bb09948f5055e822a0452124f00ff1">sklearn._loss.loss.HalfBinomialLoss</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_multinomial_loss.html#a112b861f422bd859e3d4d06930cb3254">sklearn._loss.loss.HalfMultinomialLoss</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_tweedie_loss.html#a166e9602006020897da538420926b7d9">sklearn._loss.loss.HalfTweedieLoss</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_tweedie_loss_identity.html#a2b3531915177c4dedca43fe059e64b37">sklearn._loss.loss.HalfTweedieLossIdentity</a>, and <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_pinball_loss.html#a81e66bfebfe798ac553248d7928ebb3f">sklearn._loss.loss.PinballLoss</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  125</span>    <span class="keyword">def </span>__init__(self, closs, link, n_classes=None):</div>
<div class="line"><span class="lineno">  126</span>        self.closs = closs</div>
<div class="line"><span class="lineno">  127</span>        self.link = link</div>
<div class="line"><span class="lineno">  128</span>        self.approx_hessian = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  129</span>        self.constant_hessian = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  130</span>        self.n_classes = n_classes</div>
<div class="line"><span class="lineno">  131</span>        self.interval_y_true = Interval(-np.inf, np.inf, <span class="keyword">False</span>, <span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  132</span>        self.interval_y_pred = self.link.interval_y_pred</div>
<div class="line"><span class="lineno">  133</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a294afc783ab728aa3bfd859988493b35" name="a294afc783ab728aa3bfd859988493b35"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a294afc783ab728aa3bfd859988493b35">&#9670;&#160;</a></span>__call__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.__call__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>raw_prediction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_threads</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the weighted average loss.

Parameters
----------
y_true : C-contiguous array of shape (n_samples,)
    Observed, true target values.
raw_prediction : C-contiguous array of shape (n_samples,) or array of \
    shape (n_samples, n_classes)
    Raw prediction values (in link space).
sample_weight : None or C-contiguous array of shape (n_samples,)
    Sample weights.
n_threads : int, default=1
    Might use openmp thread parallelism.

Returns
-------
loss : float
    Mean or averaged loss function.
</pre> <div class="fragment"><div class="line"><span class="lineno">  387</span>    <span class="keyword">def </span>__call__(self, y_true, raw_prediction, sample_weight=None, n_threads=1):</div>
<div class="line"><span class="lineno">  388</span>        <span class="stringliteral">&quot;&quot;&quot;Compute the weighted average loss.</span></div>
<div class="line"><span class="lineno">  389</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  390</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  391</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  392</span><span class="stringliteral">        y_true : C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  393</span><span class="stringliteral">            Observed, true target values.</span></div>
<div class="line"><span class="lineno">  394</span><span class="stringliteral">        raw_prediction : C-contiguous array of shape (n_samples,) or array of \</span></div>
<div class="line"><span class="lineno">  395</span><span class="stringliteral">            shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  396</span><span class="stringliteral">            Raw prediction values (in link space).</span></div>
<div class="line"><span class="lineno">  397</span><span class="stringliteral">        sample_weight : None or C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  398</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><span class="lineno">  399</span><span class="stringliteral">        n_threads : int, default=1</span></div>
<div class="line"><span class="lineno">  400</span><span class="stringliteral">            Might use openmp thread parallelism.</span></div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  402</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  404</span><span class="stringliteral">        loss : float</span></div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral">            Mean or averaged loss function.</span></div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  407</span>        <span class="keywordflow">return</span> np.average(</div>
<div class="line"><span class="lineno">  408</span>            self.loss(</div>
<div class="line"><span class="lineno">  409</span>                y_true=y_true,</div>
<div class="line"><span class="lineno">  410</span>                raw_prediction=raw_prediction,</div>
<div class="line"><span class="lineno">  411</span>                sample_weight=<span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  412</span>                loss_out=<span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  413</span>                n_threads=n_threads,</div>
<div class="line"><span class="lineno">  414</span>            ),</div>
<div class="line"><span class="lineno">  415</span>            weights=sample_weight,</div>
<div class="line"><span class="lineno">  416</span>        )</div>
<div class="line"><span class="lineno">  417</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afc7a673025ec0b05993a924d54d6a6c5" name="afc7a673025ec0b05993a924d54d6a6c5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afc7a673025ec0b05993a924d54d6a6c5">&#9670;&#160;</a></span>constant_to_optimal_zero()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.constant_to_optimal_zero </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Calculate term dropped in loss.

With this term added, the loss of perfect predictions is zero.
</pre> 
<p>Reimplemented in <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_poisson_loss.html#a0452b3e4776ba0622ff016553c9f0606">sklearn._loss.loss.HalfPoissonLoss</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_gamma_loss.html#af4daf777b84688710a0ed01f94954a46">sklearn._loss.loss.HalfGammaLoss</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_tweedie_loss.html#a120eb86ddc3c7a8adce985a98f56e283">sklearn._loss.loss.HalfTweedieLoss</a>, and <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_binomial_loss.html#aded07705d714690528b90dce6a64c05d">sklearn._loss.loss.HalfBinomialLoss</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  460</span>    <span class="keyword">def </span>constant_to_optimal_zero(self, y_true, sample_weight=None):</div>
<div class="line"><span class="lineno">  461</span>        <span class="stringliteral">&quot;&quot;&quot;Calculate term dropped in loss.</span></div>
<div class="line"><span class="lineno">  462</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  463</span><span class="stringliteral">        With this term added, the loss of perfect predictions is zero.</span></div>
<div class="line"><span class="lineno">  464</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  465</span>        <span class="keywordflow">return</span> np.zeros_like(y_true)</div>
<div class="line"><span class="lineno">  466</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a40afc87a56422158efbb681e18868a08" name="a40afc87a56422158efbb681e18868a08"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40afc87a56422158efbb681e18868a08">&#9670;&#160;</a></span>fit_intercept_only()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.fit_intercept_only </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute raw_prediction of an intercept-only model.

This can be used as initial estimates of predictions, i.e. before the
first iteration in fit.

Parameters
----------
y_true : array-like of shape (n_samples,)
    Observed, true target values.
sample_weight : None or array of shape (n_samples,)
    Sample weights.

Returns
-------
raw_prediction : numpy scalar or array of shape (n_classes,)
    Raw predictions of an intercept-only model.
</pre> 
<p>Reimplemented in <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_absolute_error.html#a781e2c4db12449c57511d7a8612fc765">sklearn._loss.loss.AbsoluteError</a>, <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_pinball_loss.html#a58d11f3baec2fb7e61e84f040840247f">sklearn._loss.loss.PinballLoss</a>, and <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_multinomial_loss.html#a4bcf9c17a89fec83b8846d71f1df444f">sklearn._loss.loss.HalfMultinomialLoss</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  418</span>    <span class="keyword">def </span>fit_intercept_only(self, y_true, sample_weight=None):</div>
<div class="line"><span class="lineno">  419</span>        <span class="stringliteral">&quot;&quot;&quot;Compute raw_prediction of an intercept-only model.</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  421</span><span class="stringliteral">        This can be used as initial estimates of predictions, i.e. before the</span></div>
<div class="line"><span class="lineno">  422</span><span class="stringliteral">        first iteration in fit.</span></div>
<div class="line"><span class="lineno">  423</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  424</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  425</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  426</span><span class="stringliteral">        y_true : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  427</span><span class="stringliteral">            Observed, true target values.</span></div>
<div class="line"><span class="lineno">  428</span><span class="stringliteral">        sample_weight : None or array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  429</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><span class="lineno">  430</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  431</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  432</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  433</span><span class="stringliteral">        raw_prediction : numpy scalar or array of shape (n_classes,)</span></div>
<div class="line"><span class="lineno">  434</span><span class="stringliteral">            Raw predictions of an intercept-only model.</span></div>
<div class="line"><span class="lineno">  435</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  436</span>        <span class="comment"># As default, take weighted average of the target over the samples</span></div>
<div class="line"><span class="lineno">  437</span>        <span class="comment"># axis=0 and then transform into link-scale (raw_prediction).</span></div>
<div class="line"><span class="lineno">  438</span>        y_pred = np.average(y_true, weights=sample_weight, axis=0)</div>
<div class="line"><span class="lineno">  439</span>        eps = 10 * np.finfo(y_pred.dtype).eps</div>
<div class="line"><span class="lineno">  440</span> </div>
<div class="line"><span class="lineno">  441</span>        <span class="keywordflow">if</span> self.interval_y_pred.low == -np.inf:</div>
<div class="line"><span class="lineno">  442</span>            a_min = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  443</span>        <span class="keywordflow">elif</span> self.interval_y_pred.low_inclusive:</div>
<div class="line"><span class="lineno">  444</span>            a_min = self.interval_y_pred.low</div>
<div class="line"><span class="lineno">  445</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  446</span>            a_min = self.interval_y_pred.low + eps</div>
<div class="line"><span class="lineno">  447</span> </div>
<div class="line"><span class="lineno">  448</span>        <span class="keywordflow">if</span> self.interval_y_pred.high == np.inf:</div>
<div class="line"><span class="lineno">  449</span>            a_max = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  450</span>        <span class="keywordflow">elif</span> self.interval_y_pred.high_inclusive:</div>
<div class="line"><span class="lineno">  451</span>            a_max = self.interval_y_pred.high</div>
<div class="line"><span class="lineno">  452</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  453</span>            a_max = self.interval_y_pred.high - eps</div>
<div class="line"><span class="lineno">  454</span> </div>
<div class="line"><span class="lineno">  455</span>        <span class="keywordflow">if</span> a_min <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> a_max <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  456</span>            <span class="keywordflow">return</span> self.link.link(y_pred)</div>
<div class="line"><span class="lineno">  457</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  458</span>            <span class="keywordflow">return</span> self.link.link(np.clip(y_pred, a_min, a_max))</div>
<div class="line"><span class="lineno">  459</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aff7a3496ececc5dd431f51815620a4b9" name="aff7a3496ececc5dd431f51815620a4b9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff7a3496ececc5dd431f51815620a4b9">&#9670;&#160;</a></span>gradient()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.gradient </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>raw_prediction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gradient_out</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_threads</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute gradient of loss w.r.t raw_prediction for each input.

Parameters
----------
y_true : C-contiguous array of shape (n_samples,)
    Observed, true target values.
raw_prediction : C-contiguous array of shape (n_samples,) or array of \
    shape (n_samples, n_classes)
    Raw prediction values (in link space).
sample_weight : None or C-contiguous array of shape (n_samples,)
    Sample weights.
gradient_out : None or C-contiguous array of shape (n_samples,) or array \
    of shape (n_samples, n_classes)
    A location into which the result is stored. If None, a new array
    might be created.
n_threads : int, default=1
    Might use openmp thread parallelism.

Returns
-------
gradient : array of shape (n_samples,) or (n_samples, n_classes)
    Element-wise gradients.
</pre> <div class="fragment"><div class="line"><span class="lineno">  273</span>    ):</div>
<div class="line"><span class="lineno">  274</span>        <span class="stringliteral">&quot;&quot;&quot;Compute gradient of loss w.r.t raw_prediction for each input.</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">        y_true : C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">            Observed, true target values.</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">        raw_prediction : C-contiguous array of shape (n_samples,) or array of \</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">            shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">            Raw prediction values (in link space).</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">        sample_weight : None or C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">        gradient_out : None or C-contiguous array of shape (n_samples,) or array \</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">            of shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">            A location into which the result is stored. If None, a new array</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">            might be created.</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">        n_threads : int, default=1</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">            Might use openmp thread parallelism.</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">        gradient : array of shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">            Element-wise gradients.</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  297</span>        <span class="keywordflow">if</span> gradient_out <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  298</span>            gradient_out = np.empty_like(raw_prediction)</div>
<div class="line"><span class="lineno">  299</span> </div>
<div class="line"><span class="lineno">  300</span>        <span class="comment"># Be graceful to shape (n_samples, 1) -&gt; (n_samples,)</span></div>
<div class="line"><span class="lineno">  301</span>        <span class="keywordflow">if</span> raw_prediction.ndim == 2 <span class="keywordflow">and</span> raw_prediction.shape[1] == 1:</div>
<div class="line"><span class="lineno">  302</span>            raw_prediction = raw_prediction.squeeze(1)</div>
<div class="line"><span class="lineno">  303</span>        <span class="keywordflow">if</span> gradient_out.ndim == 2 <span class="keywordflow">and</span> gradient_out.shape[1] == 1:</div>
<div class="line"><span class="lineno">  304</span>            gradient_out = gradient_out.squeeze(1)</div>
<div class="line"><span class="lineno">  305</span> </div>
<div class="line"><span class="lineno">  306</span>        y_true = ReadonlyArrayWrapper(y_true)</div>
<div class="line"><span class="lineno">  307</span>        raw_prediction = ReadonlyArrayWrapper(raw_prediction)</div>
<div class="line"><span class="lineno">  308</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  309</span>            sample_weight = ReadonlyArrayWrapper(sample_weight)</div>
<div class="line"><span class="lineno">  310</span>        <span class="keywordflow">return</span> self.closs.gradient(</div>
<div class="line"><span class="lineno">  311</span>            y_true=y_true,</div>
<div class="line"><span class="lineno">  312</span>            raw_prediction=raw_prediction,</div>
<div class="line"><span class="lineno">  313</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  314</span>            gradient_out=gradient_out,</div>
<div class="line"><span class="lineno">  315</span>            n_threads=n_threads,</div>
<div class="line"><span class="lineno">  316</span>        )</div>
<div class="line"><span class="lineno">  317</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae7b33139cdecec21fd2044c9a618c94d" name="ae7b33139cdecec21fd2044c9a618c94d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae7b33139cdecec21fd2044c9a618c94d">&#9670;&#160;</a></span>gradient_hessian()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.gradient_hessian </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>raw_prediction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gradient_out</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hessian_out</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_threads</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute gradient and hessian of loss w.r.t raw_prediction.

Parameters
----------
y_true : C-contiguous array of shape (n_samples,)
    Observed, true target values.
raw_prediction : C-contiguous array of shape (n_samples,) or array of \
    shape (n_samples, n_classes)
    Raw prediction values (in link space).
sample_weight : None or C-contiguous array of shape (n_samples,)
    Sample weights.
gradient_out : None or C-contiguous array of shape (n_samples,) or array \
    of shape (n_samples, n_classes)
    A location into which the gradient is stored. If None, a new array
    might be created.
hessian_out : None or C-contiguous array of shape (n_samples,) or array \
    of shape (n_samples, n_classes)
    A location into which the hessian is stored. If None, a new array
    might be created.
n_threads : int, default=1
    Might use openmp thread parallelism.

Returns
-------
gradient : arrays of shape (n_samples,) or (n_samples, n_classes)
    Element-wise gradients.

hessian : arrays of shape (n_samples,) or (n_samples, n_classes)
    Element-wise hessians.
</pre> <div class="fragment"><div class="line"><span class="lineno">  326</span>    ):</div>
<div class="line"><span class="lineno">  327</span>        <span class="stringliteral">&quot;&quot;&quot;Compute gradient and hessian of loss w.r.t raw_prediction.</span></div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral">        y_true : C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">            Observed, true target values.</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral">        raw_prediction : C-contiguous array of shape (n_samples,) or array of \</span></div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral">            shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">            Raw prediction values (in link space).</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral">        sample_weight : None or C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral">        gradient_out : None or C-contiguous array of shape (n_samples,) or array \</span></div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral">            of shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">            A location into which the gradient is stored. If None, a new array</span></div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral">            might be created.</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral">        hessian_out : None or C-contiguous array of shape (n_samples,) or array \</span></div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral">            of shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">            A location into which the hessian is stored. If None, a new array</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral">            might be created.</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">        n_threads : int, default=1</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">            Might use openmp thread parallelism.</span></div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">        gradient : arrays of shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral">            Element-wise gradients.</span></div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">        hessian : arrays of shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">            Element-wise hessians.</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  357</span>        <span class="keywordflow">if</span> gradient_out <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  358</span>            <span class="keywordflow">if</span> hessian_out <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  359</span>                gradient_out = np.empty_like(raw_prediction)</div>
<div class="line"><span class="lineno">  360</span>                hessian_out = np.empty_like(raw_prediction)</div>
<div class="line"><span class="lineno">  361</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  362</span>                gradient_out = np.empty_like(hessian_out)</div>
<div class="line"><span class="lineno">  363</span>        <span class="keywordflow">elif</span> hessian_out <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  364</span>            hessian_out = np.empty_like(gradient_out)</div>
<div class="line"><span class="lineno">  365</span> </div>
<div class="line"><span class="lineno">  366</span>        <span class="comment"># Be graceful to shape (n_samples, 1) -&gt; (n_samples,)</span></div>
<div class="line"><span class="lineno">  367</span>        <span class="keywordflow">if</span> raw_prediction.ndim == 2 <span class="keywordflow">and</span> raw_prediction.shape[1] == 1:</div>
<div class="line"><span class="lineno">  368</span>            raw_prediction = raw_prediction.squeeze(1)</div>
<div class="line"><span class="lineno">  369</span>        <span class="keywordflow">if</span> gradient_out.ndim == 2 <span class="keywordflow">and</span> gradient_out.shape[1] == 1:</div>
<div class="line"><span class="lineno">  370</span>            gradient_out = gradient_out.squeeze(1)</div>
<div class="line"><span class="lineno">  371</span>        <span class="keywordflow">if</span> hessian_out.ndim == 2 <span class="keywordflow">and</span> hessian_out.shape[1] == 1:</div>
<div class="line"><span class="lineno">  372</span>            hessian_out = hessian_out.squeeze(1)</div>
<div class="line"><span class="lineno">  373</span> </div>
<div class="line"><span class="lineno">  374</span>        y_true = ReadonlyArrayWrapper(y_true)</div>
<div class="line"><span class="lineno">  375</span>        raw_prediction = ReadonlyArrayWrapper(raw_prediction)</div>
<div class="line"><span class="lineno">  376</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  377</span>            sample_weight = ReadonlyArrayWrapper(sample_weight)</div>
<div class="line"><span class="lineno">  378</span>        <span class="keywordflow">return</span> self.closs.gradient_hessian(</div>
<div class="line"><span class="lineno">  379</span>            y_true=y_true,</div>
<div class="line"><span class="lineno">  380</span>            raw_prediction=raw_prediction,</div>
<div class="line"><span class="lineno">  381</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  382</span>            gradient_out=gradient_out,</div>
<div class="line"><span class="lineno">  383</span>            hessian_out=hessian_out,</div>
<div class="line"><span class="lineno">  384</span>            n_threads=n_threads,</div>
<div class="line"><span class="lineno">  385</span>        )</div>
<div class="line"><span class="lineno">  386</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af11ab89ac55cbdc1fc3b64dc68e8e75d" name="af11ab89ac55cbdc1fc3b64dc68e8e75d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af11ab89ac55cbdc1fc3b64dc68e8e75d">&#9670;&#160;</a></span>in_y_pred_range()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.in_y_pred_range </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return True if y is in the valid range of y_pred.

Parameters
----------
y : ndarray
</pre> <div class="fragment"><div class="line"><span class="lineno">  143</span>    <span class="keyword">def </span>in_y_pred_range(self, y):</div>
<div class="line"><span class="lineno">  144</span>        <span class="stringliteral">&quot;&quot;&quot;Return True if y is in the valid range of y_pred.</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">        y : ndarray</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  150</span>        <span class="keywordflow">return</span> self.interval_y_pred.includes(y)</div>
<div class="line"><span class="lineno">  151</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="acf48e9151cdfbf2a35fda2f78fff42ae" name="acf48e9151cdfbf2a35fda2f78fff42ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acf48e9151cdfbf2a35fda2f78fff42ae">&#9670;&#160;</a></span>in_y_true_range()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.in_y_true_range </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return True if y is in the valid range of y_true.

Parameters
----------
y : ndarray
</pre> 
<p>Reimplemented in <a class="el" href="classsklearn_1_1__loss_1_1loss_1_1_half_multinomial_loss.html#a8046828f4b662cd939351d99ad8cdb71">sklearn._loss.loss.HalfMultinomialLoss</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  134</span>    <span class="keyword">def </span>in_y_true_range(self, y):</div>
<div class="line"><span class="lineno">  135</span>        <span class="stringliteral">&quot;&quot;&quot;Return True if y is in the valid range of y_true.</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral">        y : ndarray</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  141</span>        <span class="keywordflow">return</span> self.interval_y_true.includes(y)</div>
<div class="line"><span class="lineno">  142</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a481e142c26f1a4db2dfaf2f7648fa725" name="a481e142c26f1a4db2dfaf2f7648fa725"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a481e142c26f1a4db2dfaf2f7648fa725">&#9670;&#160;</a></span>init_gradient_and_hessian()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.init_gradient_and_hessian </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em> = <code>np.float64</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>order</em> = <code>&quot;F&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Initialize arrays for gradients and hessians.

Unless hessians are constant, arrays are initialized with undefined values.

Parameters
----------
n_samples : int
    The number of samples, usually passed to `fit()`.
dtype : {np.float64, np.float32}, default=np.float64
    The dtype of the arrays gradient and hessian.
order : {'C', 'F'}, default='F'
    Order of the arrays gradient and hessian. The default 'F' makes the arrays
    contiguous along samples.

Returns
-------
gradient : C-contiguous array of shape (n_samples,) or array of shape \
    (n_samples, n_classes)
    Empty array (allocated but not initialized) to be used as argument
    gradient_out.
hessian : C-contiguous array of shape (n_samples,), array of shape
    (n_samples, n_classes) or shape (1,)
    Empty (allocated but not initialized) array to be used as argument
    hessian_out.
    If constant_hessian is True (e.g. `HalfSquaredError`), the array is
    initialized to ``1``.
</pre> <div class="fragment"><div class="line"><span class="lineno">  467</span>    <span class="keyword">def </span>init_gradient_and_hessian(self, n_samples, dtype=np.float64, order=&quot;F&quot;):</div>
<div class="line"><span class="lineno">  468</span>        <span class="stringliteral">&quot;&quot;&quot;Initialize arrays for gradients and hessians.</span></div>
<div class="line"><span class="lineno">  469</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  470</span><span class="stringliteral">        Unless hessians are constant, arrays are initialized with undefined values.</span></div>
<div class="line"><span class="lineno">  471</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  472</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  473</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  474</span><span class="stringliteral">        n_samples : int</span></div>
<div class="line"><span class="lineno">  475</span><span class="stringliteral">            The number of samples, usually passed to `fit()`.</span></div>
<div class="line"><span class="lineno">  476</span><span class="stringliteral">        dtype : {np.float64, np.float32}, default=np.float64</span></div>
<div class="line"><span class="lineno">  477</span><span class="stringliteral">            The dtype of the arrays gradient and hessian.</span></div>
<div class="line"><span class="lineno">  478</span><span class="stringliteral">        order : {&#39;C&#39;, &#39;F&#39;}, default=&#39;F&#39;</span></div>
<div class="line"><span class="lineno">  479</span><span class="stringliteral">            Order of the arrays gradient and hessian. The default &#39;F&#39; makes the arrays</span></div>
<div class="line"><span class="lineno">  480</span><span class="stringliteral">            contiguous along samples.</span></div>
<div class="line"><span class="lineno">  481</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  482</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  483</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  484</span><span class="stringliteral">        gradient : C-contiguous array of shape (n_samples,) or array of shape \</span></div>
<div class="line"><span class="lineno">  485</span><span class="stringliteral">            (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  486</span><span class="stringliteral">            Empty array (allocated but not initialized) to be used as argument</span></div>
<div class="line"><span class="lineno">  487</span><span class="stringliteral">            gradient_out.</span></div>
<div class="line"><span class="lineno">  488</span><span class="stringliteral">        hessian : C-contiguous array of shape (n_samples,), array of shape</span></div>
<div class="line"><span class="lineno">  489</span><span class="stringliteral">            (n_samples, n_classes) or shape (1,)</span></div>
<div class="line"><span class="lineno">  490</span><span class="stringliteral">            Empty (allocated but not initialized) array to be used as argument</span></div>
<div class="line"><span class="lineno">  491</span><span class="stringliteral">            hessian_out.</span></div>
<div class="line"><span class="lineno">  492</span><span class="stringliteral">            If constant_hessian is True (e.g. `HalfSquaredError`), the array is</span></div>
<div class="line"><span class="lineno">  493</span><span class="stringliteral">            initialized to ``1``.</span></div>
<div class="line"><span class="lineno">  494</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  495</span>        <span class="keywordflow">if</span> dtype <span class="keywordflow">not</span> <span class="keywordflow">in</span> (np.float32, np.float64):</div>
<div class="line"><span class="lineno">  496</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  497</span>                <span class="stringliteral">&quot;Valid options for &#39;dtype&#39; are np.float32 and np.float64. &quot;</span></div>
<div class="line"><span class="lineno">  498</span>                f<span class="stringliteral">&quot;Got dtype={dtype} instead.&quot;</span></div>
<div class="line"><span class="lineno">  499</span>            )</div>
<div class="line"><span class="lineno">  500</span> </div>
<div class="line"><span class="lineno">  501</span>        <span class="keywordflow">if</span> self.is_multiclass:</div>
<div class="line"><span class="lineno">  502</span>            shape = (n_samples, self.n_classes)</div>
<div class="line"><span class="lineno">  503</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  504</span>            shape = (n_samples,)</div>
<div class="line"><span class="lineno">  505</span>        gradient = np.empty(shape=shape, dtype=dtype, order=order)</div>
<div class="line"><span class="lineno">  506</span> </div>
<div class="line"><span class="lineno">  507</span>        <span class="keywordflow">if</span> self.constant_hessian:</div>
<div class="line"><span class="lineno">  508</span>            <span class="comment"># If the hessians are constant, we consider them equal to 1.</span></div>
<div class="line"><span class="lineno">  509</span>            <span class="comment"># - This is correct for HalfSquaredError</span></div>
<div class="line"><span class="lineno">  510</span>            <span class="comment"># - For AbsoluteError, hessians are actually 0, but they are</span></div>
<div class="line"><span class="lineno">  511</span>            <span class="comment">#   always ignored anyway.</span></div>
<div class="line"><span class="lineno">  512</span>            hessian = np.ones(shape=(1,), dtype=dtype)</div>
<div class="line"><span class="lineno">  513</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  514</span>            hessian = np.empty(shape=shape, dtype=dtype, order=order)</div>
<div class="line"><span class="lineno">  515</span> </div>
<div class="line"><span class="lineno">  516</span>        <span class="keywordflow">return</span> gradient, hessian</div>
<div class="line"><span class="lineno">  517</span> </div>
<div class="line"><span class="lineno">  518</span> </div>
<div class="line"><span class="lineno">  519</span><span class="comment"># Note: Naturally, we would inherit in the following order</span></div>
<div class="line"><span class="lineno">  520</span><span class="comment">#         class HalfSquaredError(IdentityLink, CyHalfSquaredError, BaseLoss)</span></div>
<div class="line"><span class="lineno">  521</span><span class="comment">#       But because of https://github.com/cython/cython/issues/4350 we</span></div>
<div class="line"><span class="lineno">  522</span><span class="comment">#       set BaseLoss as the last one. This, of course, changes the MRO.</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ae355aae4c96c62732fb026e5241d9321" name="ae355aae4c96c62732fb026e5241d9321"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae355aae4c96c62732fb026e5241d9321">&#9670;&#160;</a></span>loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>raw_prediction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss_out</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_threads</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the pointwise loss value for each input.

Parameters
----------
y_true : C-contiguous array of shape (n_samples,)
    Observed, true target values.
raw_prediction : C-contiguous array of shape (n_samples,) or array of \
    shape (n_samples, n_classes)
    Raw prediction values (in link space).
sample_weight : None or C-contiguous array of shape (n_samples,)
    Sample weights.
loss_out : None or C-contiguous array of shape (n_samples,)
    A location into which the result is stored. If None, a new array
    might be created.
n_threads : int, default=1
    Might use openmp thread parallelism.

Returns
-------
loss : array of shape (n_samples,)
    Element-wise loss function.
</pre> <div class="fragment"><div class="line"><span class="lineno">  159</span>    ):</div>
<div class="line"><span class="lineno">  160</span>        <span class="stringliteral">&quot;&quot;&quot;Compute the pointwise loss value for each input.</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        y_true : C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">            Observed, true target values.</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">        raw_prediction : C-contiguous array of shape (n_samples,) or array of \</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">            shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">            Raw prediction values (in link space).</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral">        sample_weight : None or C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">        loss_out : None or C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral">            A location into which the result is stored. If None, a new array</span></div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">            might be created.</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">        n_threads : int, default=1</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">            Might use openmp thread parallelism.</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">        loss : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">            Element-wise loss function.</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  182</span>        <span class="keywordflow">if</span> loss_out <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  183</span>            loss_out = np.empty_like(y_true)</div>
<div class="line"><span class="lineno">  184</span>        <span class="comment"># Be graceful to shape (n_samples, 1) -&gt; (n_samples,)</span></div>
<div class="line"><span class="lineno">  185</span>        <span class="keywordflow">if</span> raw_prediction.ndim == 2 <span class="keywordflow">and</span> raw_prediction.shape[1] == 1:</div>
<div class="line"><span class="lineno">  186</span>            raw_prediction = raw_prediction.squeeze(1)</div>
<div class="line"><span class="lineno">  187</span> </div>
<div class="line"><span class="lineno">  188</span>        y_true = ReadonlyArrayWrapper(y_true)</div>
<div class="line"><span class="lineno">  189</span>        raw_prediction = ReadonlyArrayWrapper(raw_prediction)</div>
<div class="line"><span class="lineno">  190</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  191</span>            sample_weight = ReadonlyArrayWrapper(sample_weight)</div>
<div class="line"><span class="lineno">  192</span>        <span class="keywordflow">return</span> self.closs.loss(</div>
<div class="line"><span class="lineno">  193</span>            y_true=y_true,</div>
<div class="line"><span class="lineno">  194</span>            raw_prediction=raw_prediction,</div>
<div class="line"><span class="lineno">  195</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  196</span>            loss_out=loss_out,</div>
<div class="line"><span class="lineno">  197</span>            n_threads=n_threads,</div>
<div class="line"><span class="lineno">  198</span>        )</div>
<div class="line"><span class="lineno">  199</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8c71136140d8c86d2d5bd5ace8bbd41d" name="a8c71136140d8c86d2d5bd5ace8bbd41d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8c71136140d8c86d2d5bd5ace8bbd41d">&#9670;&#160;</a></span>loss_gradient()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.loss_gradient </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>raw_prediction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss_out</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gradient_out</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_threads</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute loss and gradient w.r.t. raw_prediction for each input.

Parameters
----------
y_true : C-contiguous array of shape (n_samples,)
    Observed, true target values.
raw_prediction : C-contiguous array of shape (n_samples,) or array of \
    shape (n_samples, n_classes)
    Raw prediction values (in link space).
sample_weight : None or C-contiguous array of shape (n_samples,)
    Sample weights.
loss_out : None or C-contiguous array of shape (n_samples,)
    A location into which the loss is stored. If None, a new array
    might be created.
gradient_out : None or C-contiguous array of shape (n_samples,) or array \
    of shape (n_samples, n_classes)
    A location into which the gradient is stored. If None, a new array
    might be created.
n_threads : int, default=1
    Might use openmp thread parallelism.

Returns
-------
loss : array of shape (n_samples,)
    Element-wise loss function.

gradient : array of shape (n_samples,) or (n_samples, n_classes)
    Element-wise gradients.
</pre> <div class="fragment"><div class="line"><span class="lineno">  208</span>    ):</div>
<div class="line"><span class="lineno">  209</span>        <span class="stringliteral">&quot;&quot;&quot;Compute loss and gradient w.r.t. raw_prediction for each input.</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral">        y_true : C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">            Observed, true target values.</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">        raw_prediction : C-contiguous array of shape (n_samples,) or array of \</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">            shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">            Raw prediction values (in link space).</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">        sample_weight : None or C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">        loss_out : None or C-contiguous array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">            A location into which the loss is stored. If None, a new array</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">            might be created.</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">        gradient_out : None or C-contiguous array of shape (n_samples,) or array \</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">            of shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">            A location into which the gradient is stored. If None, a new array</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">            might be created.</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">        n_threads : int, default=1</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">            Might use openmp thread parallelism.</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">        loss : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">            Element-wise loss function.</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">        gradient : array of shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">            Element-wise gradients.</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  238</span>        <span class="keywordflow">if</span> loss_out <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  239</span>            <span class="keywordflow">if</span> gradient_out <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  240</span>                loss_out = np.empty_like(y_true)</div>
<div class="line"><span class="lineno">  241</span>                gradient_out = np.empty_like(raw_prediction)</div>
<div class="line"><span class="lineno">  242</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  243</span>                loss_out = np.empty_like(y_true, dtype=gradient_out.dtype)</div>
<div class="line"><span class="lineno">  244</span>        <span class="keywordflow">elif</span> gradient_out <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  245</span>            gradient_out = np.empty_like(raw_prediction, dtype=loss_out.dtype)</div>
<div class="line"><span class="lineno">  246</span> </div>
<div class="line"><span class="lineno">  247</span>        <span class="comment"># Be graceful to shape (n_samples, 1) -&gt; (n_samples,)</span></div>
<div class="line"><span class="lineno">  248</span>        <span class="keywordflow">if</span> raw_prediction.ndim == 2 <span class="keywordflow">and</span> raw_prediction.shape[1] == 1:</div>
<div class="line"><span class="lineno">  249</span>            raw_prediction = raw_prediction.squeeze(1)</div>
<div class="line"><span class="lineno">  250</span>        <span class="keywordflow">if</span> gradient_out.ndim == 2 <span class="keywordflow">and</span> gradient_out.shape[1] == 1:</div>
<div class="line"><span class="lineno">  251</span>            gradient_out = gradient_out.squeeze(1)</div>
<div class="line"><span class="lineno">  252</span> </div>
<div class="line"><span class="lineno">  253</span>        y_true = ReadonlyArrayWrapper(y_true)</div>
<div class="line"><span class="lineno">  254</span>        raw_prediction = ReadonlyArrayWrapper(raw_prediction)</div>
<div class="line"><span class="lineno">  255</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  256</span>            sample_weight = ReadonlyArrayWrapper(sample_weight)</div>
<div class="line"><span class="lineno">  257</span>        <span class="keywordflow">return</span> self.closs.loss_gradient(</div>
<div class="line"><span class="lineno">  258</span>            y_true=y_true,</div>
<div class="line"><span class="lineno">  259</span>            raw_prediction=raw_prediction,</div>
<div class="line"><span class="lineno">  260</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  261</span>            loss_out=loss_out,</div>
<div class="line"><span class="lineno">  262</span>            gradient_out=gradient_out,</div>
<div class="line"><span class="lineno">  263</span>            n_threads=n_threads,</div>
<div class="line"><span class="lineno">  264</span>        )</div>
<div class="line"><span class="lineno">  265</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="ada9acc010b0ab4b457f50f3a170e7013" name="ada9acc010b0ab4b457f50f3a170e7013"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ada9acc010b0ab4b457f50f3a170e7013">&#9670;&#160;</a></span>approx_hessian</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.approx_hessian</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2ac0fa5ee5b2367424987b8615b68504" name="a2ac0fa5ee5b2367424987b8615b68504"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2ac0fa5ee5b2367424987b8615b68504">&#9670;&#160;</a></span>closs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.closs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa79306c6b3e4e91e621c81695e0cc4d4" name="aa79306c6b3e4e91e621c81695e0cc4d4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa79306c6b3e4e91e621c81695e0cc4d4">&#9670;&#160;</a></span>constant_hessian</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.constant_hessian</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1d8526c6ce3454df71ea3328d46cb75b" name="a1d8526c6ce3454df71ea3328d46cb75b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d8526c6ce3454df71ea3328d46cb75b">&#9670;&#160;</a></span>differentiable</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool sklearn._loss.loss.BaseLoss.differentiable = True</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a4aa175acb7ee145417f199c73f131707" name="a4aa175acb7ee145417f199c73f131707"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4aa175acb7ee145417f199c73f131707">&#9670;&#160;</a></span>interval_y_pred</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.interval_y_pred</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a87a5c64b956653d473dfdc03b166b2fe" name="a87a5c64b956653d473dfdc03b166b2fe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a87a5c64b956653d473dfdc03b166b2fe">&#9670;&#160;</a></span>interval_y_true</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.interval_y_true</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aba86d98f29852fcffb6c2a244a1da10d" name="aba86d98f29852fcffb6c2a244a1da10d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba86d98f29852fcffb6c2a244a1da10d">&#9670;&#160;</a></span>is_multiclass</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool sklearn._loss.loss.BaseLoss.is_multiclass = False</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a8b3ad72e068f068732da4e6b9232e456" name="a8b3ad72e068f068732da4e6b9232e456"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8b3ad72e068f068732da4e6b9232e456">&#9670;&#160;</a></span>link</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.link</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af23ae122eda60d60851e8bc38c5c85ce" name="af23ae122eda60d60851e8bc38c5c85ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af23ae122eda60d60851e8bc38c5c85ce">&#9670;&#160;</a></span>n_classes</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn._loss.loss.BaseLoss.n_classes</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad38d68671d8b0604ac278813a5139959" name="ad38d68671d8b0604ac278813a5139959"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad38d68671d8b0604ac278813a5139959">&#9670;&#160;</a></span>need_update_leaves_values</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool sklearn._loss.loss.BaseLoss.need_update_leaves_values = False</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/rafael/Documents/GitHub/PUC-GCES-PY/Tp-GCS-Rafael-Augusto/venv/lib/python3.9/site-packages/sklearn/_loss/<a class="el" href="loss_8py.html">loss.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
