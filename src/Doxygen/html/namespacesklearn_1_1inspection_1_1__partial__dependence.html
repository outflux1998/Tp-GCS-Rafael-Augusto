<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.inspection._partial_dependence Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1inspection.html">inspection</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1inspection_1_1__partial__dependence.html">_partial_dependence</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.inspection._partial_dependence Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a65ce773d6186a145ab441ce63084a386" id="r_a65ce773d6186a145ab441ce63084a386"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1inspection_1_1__partial__dependence.html#a65ce773d6186a145ab441ce63084a386">_grid_from_X</a> (X, percentiles, is_categorical, grid_resolution)</td></tr>
<tr class="separator:a65ce773d6186a145ab441ce63084a386"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2efd20fe885379a42a2deb7c4aec67be" id="r_a2efd20fe885379a42a2deb7c4aec67be"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1inspection_1_1__partial__dependence.html#a2efd20fe885379a42a2deb7c4aec67be">_partial_dependence_recursion</a> (<a class="el" href="__lapack__subroutines_8h.html#a20cd275d1dea5cba0a51b3e106f3e130">est</a>, grid, features)</td></tr>
<tr class="separator:a2efd20fe885379a42a2deb7c4aec67be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a477bc015108a8895892c7a0b8ff46ef6" id="r_a477bc015108a8895892c7a0b8ff46ef6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1inspection_1_1__partial__dependence.html#a477bc015108a8895892c7a0b8ff46ef6">_partial_dependence_brute</a> (<a class="el" href="__lapack__subroutines_8h.html#a20cd275d1dea5cba0a51b3e106f3e130">est</a>, grid, features, X, response_method)</td></tr>
<tr class="separator:a477bc015108a8895892c7a0b8ff46ef6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac28294da9bf630b12f10d5bd9c6eaf5d" id="r_ac28294da9bf630b12f10d5bd9c6eaf5d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1inspection_1_1__partial__dependence.html#ac28294da9bf630b12f10d5bd9c6eaf5d">partial_dependence</a> (estimator, X, features, *categorical_features=None, feature_names=None, response_method=&quot;auto&quot;, percentiles=(0.05, 0.95), grid_resolution=100, method=&quot;auto&quot;, kind=&quot;average&quot;)</td></tr>
<tr class="separator:ac28294da9bf630b12f10d5bd9c6eaf5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Partial dependence plots for regression and classification models.</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a65ce773d6186a145ab441ce63084a386" name="a65ce773d6186a145ab441ce63084a386"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65ce773d6186a145ab441ce63084a386">&#9670;&#160;</a></span>_grid_from_X()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.inspection._partial_dependence._grid_from_X </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>percentiles</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_categorical</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>grid_resolution</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate a grid of points based on the percentiles of X.

The grid is a cartesian product between the columns of ``values``. The
ith column of ``values`` consists in ``grid_resolution`` equally-spaced
points between the percentiles of the jth column of X.

If ``grid_resolution`` is bigger than the number of unique values in the
j-th column of X or if the feature is a categorical feature (by inspecting
`is_categorical`) , then those unique values will be used instead.

Parameters
----------
X : array-like of shape (n_samples, n_target_features)
    The data.

percentiles : tuple of float
    The percentiles which are used to construct the extreme values of
    the grid. Must be in [0, 1].

is_categorical : list of bool
    For each feature, tells whether it is categorical or not. If a feature
    is categorical, then the values used will be the unique ones
    (i.e. categories) instead of the percentiles.

grid_resolution : int
    The number of equally spaced points to be placed on the grid for each
    feature.

Returns
-------
grid : ndarray of shape (n_points, n_target_features)
    A value for each feature at each point in the grid. ``n_points`` is
    always ``&lt;= grid_resolution ** X.shape[1]``.

values : list of 1d ndarrays
    The values with which the grid has been created. The size of each
    array ``values[j]`` is either ``grid_resolution``, or the number of
    unique values in ``X[:, j]``, whichever is smaller.
</pre> <div class="fragment"><div class="line"><span class="lineno">   39</span><span class="keyword">def </span>_grid_from_X(X, percentiles, is_categorical, grid_resolution):</div>
<div class="line"><span class="lineno">   40</span>    <span class="stringliteral">&quot;&quot;&quot;Generate a grid of points based on the percentiles of X.</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral">    The grid is a cartesian product between the columns of ``values``. The</span></div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">    ith column of ``values`` consists in ``grid_resolution`` equally-spaced</span></div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">    points between the percentiles of the jth column of X.</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">    If ``grid_resolution`` is bigger than the number of unique values in the</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">    j-th column of X or if the feature is a categorical feature (by inspecting</span></div>
<div class="line"><span class="lineno">   48</span><span class="stringliteral">    `is_categorical`) , then those unique values will be used instead.</span></div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">    X : array-like of shape (n_samples, n_target_features)</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">        The data.</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">    percentiles : tuple of float</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral">        The percentiles which are used to construct the extreme values of</span></div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral">        the grid. Must be in [0, 1].</span></div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">    is_categorical : list of bool</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">        For each feature, tells whether it is categorical or not. If a feature</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral">        is categorical, then the values used will be the unique ones</span></div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">        (i.e. categories) instead of the percentiles.</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    grid_resolution : int</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">        The number of equally spaced points to be placed on the grid for each</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">        feature.</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    grid : ndarray of shape (n_points, n_target_features)</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">        A value for each feature at each point in the grid. ``n_points`` is</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">        always ``&lt;= grid_resolution ** X.shape[1]``.</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">    values : list of 1d ndarrays</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">        The values with which the grid has been created. The size of each</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">        array ``values[j]`` is either ``grid_resolution``, or the number of</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">        unique values in ``X[:, j]``, whichever is smaller.</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   79</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(percentiles, Iterable) <span class="keywordflow">or</span> len(percentiles) != 2:</div>
<div class="line"><span class="lineno">   80</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;&#39;percentiles&#39; must be a sequence of 2 elements.&quot;</span>)</div>
<div class="line"><span class="lineno">   81</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> all(0 &lt;= x &lt;= 1 <span class="keywordflow">for</span> x <span class="keywordflow">in</span> percentiles):</div>
<div class="line"><span class="lineno">   82</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;&#39;percentiles&#39; values must be in [0, 1].&quot;</span>)</div>
<div class="line"><span class="lineno">   83</span>    <span class="keywordflow">if</span> percentiles[0] &gt;= percentiles[1]:</div>
<div class="line"><span class="lineno">   84</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;percentiles[0] must be strictly less than percentiles[1].&quot;</span>)</div>
<div class="line"><span class="lineno">   85</span> </div>
<div class="line"><span class="lineno">   86</span>    <span class="keywordflow">if</span> grid_resolution &lt;= 1:</div>
<div class="line"><span class="lineno">   87</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;&#39;grid_resolution&#39; must be strictly greater than 1.&quot;</span>)</div>
<div class="line"><span class="lineno">   88</span> </div>
<div class="line"><span class="lineno">   89</span>    values = []</div>
<div class="line"><span class="lineno">   90</span>    <span class="keywordflow">for</span> feature, is_cat <span class="keywordflow">in</span> enumerate(is_categorical):</div>
<div class="line"><span class="lineno">   91</span>        uniques = np.unique(_safe_indexing(X, feature, axis=1))</div>
<div class="line"><span class="lineno">   92</span>        <span class="keywordflow">if</span> is_cat <span class="keywordflow">or</span> uniques.shape[0] &lt; grid_resolution:</div>
<div class="line"><span class="lineno">   93</span>            <span class="comment"># Use the unique values either because:</span></div>
<div class="line"><span class="lineno">   94</span>            <span class="comment"># - feature has low resolution use unique values</span></div>
<div class="line"><span class="lineno">   95</span>            <span class="comment"># - feature is categorical</span></div>
<div class="line"><span class="lineno">   96</span>            axis = uniques</div>
<div class="line"><span class="lineno">   97</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   98</span>            <span class="comment"># create axis based on percentiles and grid resolution</span></div>
<div class="line"><span class="lineno">   99</span>            emp_percentiles = mquantiles(</div>
<div class="line"><span class="lineno">  100</span>                _safe_indexing(X, feature, axis=1), prob=percentiles, axis=0</div>
<div class="line"><span class="lineno">  101</span>            )</div>
<div class="line"><span class="lineno">  102</span>            <span class="keywordflow">if</span> np.allclose(emp_percentiles[0], emp_percentiles[1]):</div>
<div class="line"><span class="lineno">  103</span>                <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  104</span>                    <span class="stringliteral">&quot;percentiles are too close to each other, &quot;</span></div>
<div class="line"><span class="lineno">  105</span>                    <span class="stringliteral">&quot;unable to build the grid. Please choose percentiles &quot;</span></div>
<div class="line"><span class="lineno">  106</span>                    <span class="stringliteral">&quot;that are further apart.&quot;</span></div>
<div class="line"><span class="lineno">  107</span>                )</div>
<div class="line"><span class="lineno">  108</span>            axis = np.linspace(</div>
<div class="line"><span class="lineno">  109</span>                emp_percentiles[0],</div>
<div class="line"><span class="lineno">  110</span>                emp_percentiles[1],</div>
<div class="line"><span class="lineno">  111</span>                num=grid_resolution,</div>
<div class="line"><span class="lineno">  112</span>                endpoint=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  113</span>            )</div>
<div class="line"><span class="lineno">  114</span>        values.append(axis)</div>
<div class="line"><span class="lineno">  115</span> </div>
<div class="line"><span class="lineno">  116</span>    <span class="keywordflow">return</span> cartesian(values), values</div>
<div class="line"><span class="lineno">  117</span> </div>
<div class="line"><span class="lineno">  118</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a477bc015108a8895892c7a0b8ff46ef6" name="a477bc015108a8895892c7a0b8ff46ef6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a477bc015108a8895892c7a0b8ff46ef6">&#9670;&#160;</a></span>_partial_dependence_brute()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.inspection._partial_dependence._partial_dependence_brute </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>est</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>grid</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>features</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>response_method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  129</span><span class="keyword">def </span>_partial_dependence_brute(est, grid, features, X, response_method):</div>
<div class="line"><span class="lineno">  130</span> </div>
<div class="line"><span class="lineno">  131</span>    predictions = []</div>
<div class="line"><span class="lineno">  132</span>    averaged_predictions = []</div>
<div class="line"><span class="lineno">  133</span> </div>
<div class="line"><span class="lineno">  134</span>    <span class="comment"># define the prediction_method (predict, predict_proba, decision_function).</span></div>
<div class="line"><span class="lineno">  135</span>    <span class="keywordflow">if</span> is_regressor(est):</div>
<div class="line"><span class="lineno">  136</span>        prediction_method = est.predict</div>
<div class="line"><span class="lineno">  137</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  138</span>        predict_proba = getattr(est, <span class="stringliteral">&quot;predict_proba&quot;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  139</span>        decision_function = getattr(est, <span class="stringliteral">&quot;decision_function&quot;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  140</span>        <span class="keywordflow">if</span> response_method == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  141</span>            <span class="comment"># try predict_proba, then decision_function if it doesn&#39;t exist</span></div>
<div class="line"><span class="lineno">  142</span>            prediction_method = predict_proba <span class="keywordflow">or</span> decision_function</div>
<div class="line"><span class="lineno">  143</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  144</span>            prediction_method = (</div>
<div class="line"><span class="lineno">  145</span>                predict_proba</div>
<div class="line"><span class="lineno">  146</span>                <span class="keywordflow">if</span> response_method == <span class="stringliteral">&quot;predict_proba&quot;</span></div>
<div class="line"><span class="lineno">  147</span>                <span class="keywordflow">else</span> decision_function</div>
<div class="line"><span class="lineno">  148</span>            )</div>
<div class="line"><span class="lineno">  149</span>        <span class="keywordflow">if</span> prediction_method <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  150</span>            <span class="keywordflow">if</span> response_method == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  151</span>                <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  152</span>                    <span class="stringliteral">&quot;The estimator has no predict_proba and no &quot;</span></div>
<div class="line"><span class="lineno">  153</span>                    <span class="stringliteral">&quot;decision_function method.&quot;</span></div>
<div class="line"><span class="lineno">  154</span>                )</div>
<div class="line"><span class="lineno">  155</span>            <span class="keywordflow">elif</span> response_method == <span class="stringliteral">&quot;predict_proba&quot;</span>:</div>
<div class="line"><span class="lineno">  156</span>                <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;The estimator has no predict_proba method.&quot;</span>)</div>
<div class="line"><span class="lineno">  157</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  158</span>                <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;The estimator has no decision_function method.&quot;</span>)</div>
<div class="line"><span class="lineno">  159</span> </div>
<div class="line"><span class="lineno">  160</span>    X_eval = X.copy()</div>
<div class="line"><span class="lineno">  161</span>    <span class="keywordflow">for</span> new_values <span class="keywordflow">in</span> grid:</div>
<div class="line"><span class="lineno">  162</span>        <span class="keywordflow">for</span> i, variable <span class="keywordflow">in</span> enumerate(features):</div>
<div class="line"><span class="lineno">  163</span>            _safe_assign(X_eval, new_values[i], column_indexer=variable)</div>
<div class="line"><span class="lineno">  164</span> </div>
<div class="line"><span class="lineno">  165</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  166</span>            <span class="comment"># Note: predictions is of shape</span></div>
<div class="line"><span class="lineno">  167</span>            <span class="comment"># (n_points,) for non-multioutput regressors</span></div>
<div class="line"><span class="lineno">  168</span>            <span class="comment"># (n_points, n_tasks) for multioutput regressors</span></div>
<div class="line"><span class="lineno">  169</span>            <span class="comment"># (n_points, 1) for the regressors in cross_decomposition (I think)</span></div>
<div class="line"><span class="lineno">  170</span>            <span class="comment"># (n_points, 2) for binary classification</span></div>
<div class="line"><span class="lineno">  171</span>            <span class="comment"># (n_points, n_classes) for multiclass classification</span></div>
<div class="line"><span class="lineno">  172</span>            pred = prediction_method(X_eval)</div>
<div class="line"><span class="lineno">  173</span> </div>
<div class="line"><span class="lineno">  174</span>            predictions.append(pred)</div>
<div class="line"><span class="lineno">  175</span>            <span class="comment"># average over samples</span></div>
<div class="line"><span class="lineno">  176</span>            averaged_predictions.append(np.mean(pred, axis=0))</div>
<div class="line"><span class="lineno">  177</span>        <span class="keywordflow">except</span> NotFittedError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  178</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;&#39;estimator&#39; parameter must be a fitted estimator&quot;</span>) <span class="keyword">from</span> e</div>
<div class="line"><span class="lineno">  179</span> </div>
<div class="line"><span class="lineno">  180</span>    n_samples = X.shape[0]</div>
<div class="line"><span class="lineno">  181</span> </div>
<div class="line"><span class="lineno">  182</span>    <span class="comment"># reshape to (n_targets, n_instances, n_points) where n_targets is:</span></div>
<div class="line"><span class="lineno">  183</span>    <span class="comment"># - 1 for non-multioutput regression and binary classification (shape is</span></div>
<div class="line"><span class="lineno">  184</span>    <span class="comment">#   already correct in those cases)</span></div>
<div class="line"><span class="lineno">  185</span>    <span class="comment"># - n_tasks for multi-output regression</span></div>
<div class="line"><span class="lineno">  186</span>    <span class="comment"># - n_classes for multiclass classification.</span></div>
<div class="line"><span class="lineno">  187</span>    predictions = np.array(predictions).T</div>
<div class="line"><span class="lineno">  188</span>    <span class="keywordflow">if</span> is_regressor(est) <span class="keywordflow">and</span> predictions.ndim == 2:</div>
<div class="line"><span class="lineno">  189</span>        <span class="comment"># non-multioutput regression, shape is (n_instances, n_points,)</span></div>
<div class="line"><span class="lineno">  190</span>        predictions = predictions.reshape(n_samples, -1)</div>
<div class="line"><span class="lineno">  191</span>    <span class="keywordflow">elif</span> is_classifier(est) <span class="keywordflow">and</span> predictions.shape[0] == 2:</div>
<div class="line"><span class="lineno">  192</span>        <span class="comment"># Binary classification, shape is (2, n_instances, n_points).</span></div>
<div class="line"><span class="lineno">  193</span>        <span class="comment"># we output the effect of **positive** class</span></div>
<div class="line"><span class="lineno">  194</span>        predictions = predictions[1]</div>
<div class="line"><span class="lineno">  195</span>        predictions = predictions.reshape(n_samples, -1)</div>
<div class="line"><span class="lineno">  196</span> </div>
<div class="line"><span class="lineno">  197</span>    <span class="comment"># reshape averaged_predictions to (n_targets, n_points) where n_targets is:</span></div>
<div class="line"><span class="lineno">  198</span>    <span class="comment"># - 1 for non-multioutput regression and binary classification (shape is</span></div>
<div class="line"><span class="lineno">  199</span>    <span class="comment">#   already correct in those cases)</span></div>
<div class="line"><span class="lineno">  200</span>    <span class="comment"># - n_tasks for multi-output regression</span></div>
<div class="line"><span class="lineno">  201</span>    <span class="comment"># - n_classes for multiclass classification.</span></div>
<div class="line"><span class="lineno">  202</span>    averaged_predictions = np.array(averaged_predictions).T</div>
<div class="line"><span class="lineno">  203</span>    <span class="keywordflow">if</span> is_regressor(est) <span class="keywordflow">and</span> averaged_predictions.ndim == 1:</div>
<div class="line"><span class="lineno">  204</span>        <span class="comment"># non-multioutput regression, shape is (n_points,)</span></div>
<div class="line"><span class="lineno">  205</span>        averaged_predictions = averaged_predictions.reshape(1, -1)</div>
<div class="line"><span class="lineno">  206</span>    <span class="keywordflow">elif</span> is_classifier(est) <span class="keywordflow">and</span> averaged_predictions.shape[0] == 2:</div>
<div class="line"><span class="lineno">  207</span>        <span class="comment"># Binary classification, shape is (2, n_points).</span></div>
<div class="line"><span class="lineno">  208</span>        <span class="comment"># we output the effect of **positive** class</span></div>
<div class="line"><span class="lineno">  209</span>        averaged_predictions = averaged_predictions[1]</div>
<div class="line"><span class="lineno">  210</span>        averaged_predictions = averaged_predictions.reshape(1, -1)</div>
<div class="line"><span class="lineno">  211</span> </div>
<div class="line"><span class="lineno">  212</span>    <span class="keywordflow">return</span> averaged_predictions, predictions</div>
<div class="line"><span class="lineno">  213</span> </div>
<div class="line"><span class="lineno">  214</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2efd20fe885379a42a2deb7c4aec67be" name="a2efd20fe885379a42a2deb7c4aec67be"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2efd20fe885379a42a2deb7c4aec67be">&#9670;&#160;</a></span>_partial_dependence_recursion()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.inspection._partial_dependence._partial_dependence_recursion </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>est</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>grid</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>features</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  119</span><span class="keyword">def </span>_partial_dependence_recursion(est, grid, features):</div>
<div class="line"><span class="lineno">  120</span>    averaged_predictions = est._compute_partial_dependence_recursion(grid, features)</div>
<div class="line"><span class="lineno">  121</span>    <span class="keywordflow">if</span> averaged_predictions.ndim == 1:</div>
<div class="line"><span class="lineno">  122</span>        <span class="comment"># reshape to (1, n_points) for consistency with</span></div>
<div class="line"><span class="lineno">  123</span>        <span class="comment"># _partial_dependence_brute</span></div>
<div class="line"><span class="lineno">  124</span>        averaged_predictions = averaged_predictions.reshape(1, -1)</div>
<div class="line"><span class="lineno">  125</span> </div>
<div class="line"><span class="lineno">  126</span>    <span class="keywordflow">return</span> averaged_predictions</div>
<div class="line"><span class="lineno">  127</span> </div>
<div class="line"><span class="lineno">  128</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac28294da9bf630b12f10d5bd9c6eaf5d" name="ac28294da9bf630b12f10d5bd9c6eaf5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac28294da9bf630b12f10d5bd9c6eaf5d">&#9670;&#160;</a></span>partial_dependence()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.inspection._partial_dependence.partial_dependence </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>estimator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>features</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>categorical_features</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>feature_names</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>response_method</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>percentiles</em> = <code>(0.05,&#160;0.95)</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>grid_resolution</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>kind</em> = <code>&quot;average&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Partial dependence of ``features``.

Partial dependence of a feature (or a set of features) corresponds to
the average response of an estimator for each possible value of the
feature.

Read more in the :ref:`User Guide &lt;partial_dependence&gt;`.

.. warning::

    For :class:`~sklearn.ensemble.GradientBoostingClassifier` and
    :class:`~sklearn.ensemble.GradientBoostingRegressor`, the
    `'recursion'` method (used by default) will not account for the `init`
    predictor of the boosting process. In practice, this will produce
    the same values as `'brute'` up to a constant offset in the target
    response, provided that `init` is a constant estimator (which is the
    default). However, if `init` is not a constant estimator, the
    partial dependence values are incorrect for `'recursion'` because the
    offset will be sample-dependent. It is preferable to use the `'brute'`
    method. Note that this only applies to
    :class:`~sklearn.ensemble.GradientBoostingClassifier` and
    :class:`~sklearn.ensemble.GradientBoostingRegressor`, not to
    :class:`~sklearn.ensemble.HistGradientBoostingClassifier` and
    :class:`~sklearn.ensemble.HistGradientBoostingRegressor`.

Parameters
----------
estimator : BaseEstimator
    A fitted estimator object implementing :term:`predict`,
    :term:`predict_proba`, or :term:`decision_function`.
    Multioutput-multiclass classifiers are not supported.

X : {array-like or dataframe} of shape (n_samples, n_features)
    ``X`` is used to generate a grid of values for the target
    ``features`` (where the partial dependence will be evaluated), and
    also to generate values for the complement features when the
    `method` is 'brute'.

features : array-like of {int, str}
    The feature (e.g. `[0]`) or pair of interacting features
    (e.g. `[(0, 1)]`) for which the partial dependency should be computed.

categorical_features : array-like of shape (n_features,) or shape \
        (n_categorical_features,), dtype={bool, int, str}, default=None
    Indicates the categorical features.

    - `None`: no feature will be considered categorical;
    - boolean array-like: boolean mask of shape `(n_features,)`
        indicating which features are categorical. Thus, this array has
        the same shape has `X.shape[1]`;
    - integer or string array-like: integer indices or strings
        indicating categorical features.

    .. versionadded:: 1.2

feature_names : array-like of shape (n_features,), dtype=str, default=None
    Name of each feature; `feature_names[i]` holds the name of the feature
    with index `i`.
    By default, the name of the feature corresponds to their numerical
    index for NumPy array and their column name for pandas dataframe.

    .. versionadded:: 1.2

response_method : {'auto', 'predict_proba', 'decision_function'}, \
        default='auto'
    Specifies whether to use :term:`predict_proba` or
    :term:`decision_function` as the target response. For regressors
    this parameter is ignored and the response is always the output of
    :term:`predict`. By default, :term:`predict_proba` is tried first
    and we revert to :term:`decision_function` if it doesn't exist. If
    ``method`` is 'recursion', the response is always the output of
    :term:`decision_function`.

percentiles : tuple of float, default=(0.05, 0.95)
    The lower and upper percentile used to create the extreme values
    for the grid. Must be in [0, 1].

grid_resolution : int, default=100
    The number of equally spaced points on the grid, for each target
    feature.

method : {'auto', 'recursion', 'brute'}, default='auto'
    The method used to calculate the averaged predictions:

    - `'recursion'` is only supported for some tree-based estimators
      (namely
      :class:`~sklearn.ensemble.GradientBoostingClassifier`,
      :class:`~sklearn.ensemble.GradientBoostingRegressor`,
      :class:`~sklearn.ensemble.HistGradientBoostingClassifier`,
      :class:`~sklearn.ensemble.HistGradientBoostingRegressor`,
      :class:`~sklearn.tree.DecisionTreeRegressor`,
      :class:`~sklearn.ensemble.RandomForestRegressor`,
      ) when `kind='average'`.
      This is more efficient in terms of speed.
      With this method, the target response of a
      classifier is always the decision function, not the predicted
      probabilities. Since the `'recursion'` method implicitly computes
      the average of the Individual Conditional Expectation (ICE) by
      design, it is not compatible with ICE and thus `kind` must be
      `'average'`.

    - `'brute'` is supported for any estimator, but is more
      computationally intensive.

    - `'auto'`: the `'recursion'` is used for estimators that support it,
      and `'brute'` is used otherwise.

    Please see :ref:`this note &lt;pdp_method_differences&gt;` for
    differences between the `'brute'` and `'recursion'` method.

kind : {'average', 'individual', 'both'}, default='average'
    Whether to return the partial dependence averaged across all the
    samples in the dataset or one value per sample or both.
    See Returns below.

    Note that the fast `method='recursion'` option is only available for
    `kind='average'`. Computing individual dependencies requires using the
    slower `method='brute'` option.

    .. versionadded:: 0.24

Returns
-------
predictions : :class:`~sklearn.utils.Bunch`
    Dictionary-like object, with the following attributes.

    individual : ndarray of shape (n_outputs, n_instances, \
            len(values[0]), len(values[1]), ...)
        The predictions for all the points in the grid for all
        samples in X. This is also known as Individual
        Conditional Expectation (ICE)

    average : ndarray of shape (n_outputs, len(values[0]), \
            len(values[1]), ...)
        The predictions for all the points in the grid, averaged
        over all samples in X (or over the training data if
        ``method`` is 'recursion').
        Only available when ``kind='both'``.

    values : seq of 1d ndarrays
        The values with which the grid has been created. The generated
        grid is a cartesian product of the arrays in ``values``.
        ``len(values) == len(features)``. The size of each array
        ``values[j]`` is either ``grid_resolution``, or the number of
        unique values in ``X[:, j]``, whichever is smaller.

    ``n_outputs`` corresponds to the number of classes in a multi-class
    setting, or to the number of tasks for multi-output regression.
    For classical regression and binary classification ``n_outputs==1``.
    ``n_values_feature_j`` corresponds to the size ``values[j]``.

See Also
--------
PartialDependenceDisplay.from_estimator : Plot Partial Dependence.
PartialDependenceDisplay : Partial Dependence visualization.

Examples
--------
&gt;&gt;&gt; X = [[0, 0, 2], [1, 0, 0]]
&gt;&gt;&gt; y = [0, 1]
&gt;&gt;&gt; from sklearn.ensemble import GradientBoostingClassifier
&gt;&gt;&gt; gb = GradientBoostingClassifier(random_state=0).fit(X, y)
&gt;&gt;&gt; partial_dependence(gb, features=[0], X=X, percentiles=(0, 1),
...                    grid_resolution=2) # doctest: +SKIP
(array([[-4.52...,  4.52...]]), [array([ 0.,  1.])])
</pre> <div class="fragment"><div class="line"><span class="lineno">  227</span>):</div>
<div class="line"><span class="lineno">  228</span>    <span class="stringliteral">&quot;&quot;&quot;Partial dependence of ``features``.</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">    Partial dependence of a feature (or a set of features) corresponds to</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">    the average response of an estimator for each possible value of the</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">    feature.</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;partial_dependence&gt;`.</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">    .. warning::</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">        For :class:`~sklearn.ensemble.GradientBoostingClassifier` and</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        :class:`~sklearn.ensemble.GradientBoostingRegressor`, the</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">        `&#39;recursion&#39;` method (used by default) will not account for the `init`</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">        predictor of the boosting process. In practice, this will produce</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">        the same values as `&#39;brute&#39;` up to a constant offset in the target</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">        response, provided that `init` is a constant estimator (which is the</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">        default). However, if `init` is not a constant estimator, the</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">        partial dependence values are incorrect for `&#39;recursion&#39;` because the</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">        offset will be sample-dependent. It is preferable to use the `&#39;brute&#39;`</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">        method. Note that this only applies to</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">        :class:`~sklearn.ensemble.GradientBoostingClassifier` and</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">        :class:`~sklearn.ensemble.GradientBoostingRegressor`, not to</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">        :class:`~sklearn.ensemble.HistGradientBoostingClassifier` and</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">        :class:`~sklearn.ensemble.HistGradientBoostingRegressor`.</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">    estimator : BaseEstimator</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">        A fitted estimator object implementing :term:`predict`,</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">        :term:`predict_proba`, or :term:`decision_function`.</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">        Multioutput-multiclass classifiers are not supported.</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">    X : {array-like or dataframe} of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">        ``X`` is used to generate a grid of values for the target</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">        ``features`` (where the partial dependence will be evaluated), and</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">        also to generate values for the complement features when the</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">        `method` is &#39;brute&#39;.</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">    features : array-like of {int, str}</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">        The feature (e.g. `[0]`) or pair of interacting features</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">        (e.g. `[(0, 1)]`) for which the partial dependency should be computed.</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">    categorical_features : array-like of shape (n_features,) or shape \</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">            (n_categorical_features,), dtype={bool, int, str}, default=None</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral">        Indicates the categorical features.</span></div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral">        - `None`: no feature will be considered categorical;</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">        - boolean array-like: boolean mask of shape `(n_features,)`</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">            indicating which features are categorical. Thus, this array has</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral">            the same shape has `X.shape[1]`;</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">        - integer or string array-like: integer indices or strings</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">            indicating categorical features.</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">        .. versionadded:: 1.2</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">    feature_names : array-like of shape (n_features,), dtype=str, default=None</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">        Name of each feature; `feature_names[i]` holds the name of the feature</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">        with index `i`.</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">        By default, the name of the feature corresponds to their numerical</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">        index for NumPy array and their column name for pandas dataframe.</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">        .. versionadded:: 1.2</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">    response_method : {&#39;auto&#39;, &#39;predict_proba&#39;, &#39;decision_function&#39;}, \</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">            default=&#39;auto&#39;</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">        Specifies whether to use :term:`predict_proba` or</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">        :term:`decision_function` as the target response. For regressors</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">        this parameter is ignored and the response is always the output of</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">        :term:`predict`. By default, :term:`predict_proba` is tried first</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">        and we revert to :term:`decision_function` if it doesn&#39;t exist. If</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">        ``method`` is &#39;recursion&#39;, the response is always the output of</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">        :term:`decision_function`.</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">    percentiles : tuple of float, default=(0.05, 0.95)</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">        The lower and upper percentile used to create the extreme values</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">        for the grid. Must be in [0, 1].</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    grid_resolution : int, default=100</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">        The number of equally spaced points on the grid, for each target</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">        feature.</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">    method : {&#39;auto&#39;, &#39;recursion&#39;, &#39;brute&#39;}, default=&#39;auto&#39;</span></div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">        The method used to calculate the averaged predictions:</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">        - `&#39;recursion&#39;` is only supported for some tree-based estimators</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">          (namely</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral">          :class:`~sklearn.ensemble.GradientBoostingClassifier`,</span></div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">          :class:`~sklearn.ensemble.GradientBoostingRegressor`,</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral">          :class:`~sklearn.ensemble.HistGradientBoostingClassifier`,</span></div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral">          :class:`~sklearn.ensemble.HistGradientBoostingRegressor`,</span></div>
<div class="line"><span class="lineno">  318</span><span class="stringliteral">          :class:`~sklearn.tree.DecisionTreeRegressor`,</span></div>
<div class="line"><span class="lineno">  319</span><span class="stringliteral">          :class:`~sklearn.ensemble.RandomForestRegressor`,</span></div>
<div class="line"><span class="lineno">  320</span><span class="stringliteral">          ) when `kind=&#39;average&#39;`.</span></div>
<div class="line"><span class="lineno">  321</span><span class="stringliteral">          This is more efficient in terms of speed.</span></div>
<div class="line"><span class="lineno">  322</span><span class="stringliteral">          With this method, the target response of a</span></div>
<div class="line"><span class="lineno">  323</span><span class="stringliteral">          classifier is always the decision function, not the predicted</span></div>
<div class="line"><span class="lineno">  324</span><span class="stringliteral">          probabilities. Since the `&#39;recursion&#39;` method implicitly computes</span></div>
<div class="line"><span class="lineno">  325</span><span class="stringliteral">          the average of the Individual Conditional Expectation (ICE) by</span></div>
<div class="line"><span class="lineno">  326</span><span class="stringliteral">          design, it is not compatible with ICE and thus `kind` must be</span></div>
<div class="line"><span class="lineno">  327</span><span class="stringliteral">          `&#39;average&#39;`.</span></div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">        - `&#39;brute&#39;` is supported for any estimator, but is more</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">          computationally intensive.</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">        - `&#39;auto&#39;`: the `&#39;recursion&#39;` is used for estimators that support it,</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral">          and `&#39;brute&#39;` is used otherwise.</span></div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">        Please see :ref:`this note &lt;pdp_method_differences&gt;` for</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral">        differences between the `&#39;brute&#39;` and `&#39;recursion&#39;` method.</span></div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral">    kind : {&#39;average&#39;, &#39;individual&#39;, &#39;both&#39;}, default=&#39;average&#39;</span></div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral">        Whether to return the partial dependence averaged across all the</span></div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">        samples in the dataset or one value per sample or both.</span></div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral">        See Returns below.</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral">        Note that the fast `method=&#39;recursion&#39;` option is only available for</span></div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">        `kind=&#39;average&#39;`. Computing individual dependencies requires using the</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral">        slower `method=&#39;brute&#39;` option.</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">        .. versionadded:: 0.24</span></div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">    predictions : :class:`~sklearn.utils.Bunch`</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral">        Dictionary-like object, with the following attributes.</span></div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">        individual : ndarray of shape (n_outputs, n_instances, \</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">                len(values[0]), len(values[1]), ...)</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral">            The predictions for all the points in the grid for all</span></div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">            samples in X. This is also known as Individual</span></div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral">            Conditional Expectation (ICE)</span></div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  360</span><span class="stringliteral">        average : ndarray of shape (n_outputs, len(values[0]), \</span></div>
<div class="line"><span class="lineno">  361</span><span class="stringliteral">                len(values[1]), ...)</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral">            The predictions for all the points in the grid, averaged</span></div>
<div class="line"><span class="lineno">  363</span><span class="stringliteral">            over all samples in X (or over the training data if</span></div>
<div class="line"><span class="lineno">  364</span><span class="stringliteral">            ``method`` is &#39;recursion&#39;).</span></div>
<div class="line"><span class="lineno">  365</span><span class="stringliteral">            Only available when ``kind=&#39;both&#39;``.</span></div>
<div class="line"><span class="lineno">  366</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  367</span><span class="stringliteral">        values : seq of 1d ndarrays</span></div>
<div class="line"><span class="lineno">  368</span><span class="stringliteral">            The values with which the grid has been created. The generated</span></div>
<div class="line"><span class="lineno">  369</span><span class="stringliteral">            grid is a cartesian product of the arrays in ``values``.</span></div>
<div class="line"><span class="lineno">  370</span><span class="stringliteral">            ``len(values) == len(features)``. The size of each array</span></div>
<div class="line"><span class="lineno">  371</span><span class="stringliteral">            ``values[j]`` is either ``grid_resolution``, or the number of</span></div>
<div class="line"><span class="lineno">  372</span><span class="stringliteral">            unique values in ``X[:, j]``, whichever is smaller.</span></div>
<div class="line"><span class="lineno">  373</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  374</span><span class="stringliteral">        ``n_outputs`` corresponds to the number of classes in a multi-class</span></div>
<div class="line"><span class="lineno">  375</span><span class="stringliteral">        setting, or to the number of tasks for multi-output regression.</span></div>
<div class="line"><span class="lineno">  376</span><span class="stringliteral">        For classical regression and binary classification ``n_outputs==1``.</span></div>
<div class="line"><span class="lineno">  377</span><span class="stringliteral">        ``n_values_feature_j`` corresponds to the size ``values[j]``.</span></div>
<div class="line"><span class="lineno">  378</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  379</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  380</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  381</span><span class="stringliteral">    PartialDependenceDisplay.from_estimator : Plot Partial Dependence.</span></div>
<div class="line"><span class="lineno">  382</span><span class="stringliteral">    PartialDependenceDisplay : Partial Dependence visualization.</span></div>
<div class="line"><span class="lineno">  383</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  384</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  385</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  386</span><span class="stringliteral">    &gt;&gt;&gt; X = [[0, 0, 2], [1, 0, 0]]</span></div>
<div class="line"><span class="lineno">  387</span><span class="stringliteral">    &gt;&gt;&gt; y = [0, 1]</span></div>
<div class="line"><span class="lineno">  388</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.ensemble import GradientBoostingClassifier</span></div>
<div class="line"><span class="lineno">  389</span><span class="stringliteral">    &gt;&gt;&gt; gb = GradientBoostingClassifier(random_state=0).fit(X, y)</span></div>
<div class="line"><span class="lineno">  390</span><span class="stringliteral">    &gt;&gt;&gt; partial_dependence(gb, features=[0], X=X, percentiles=(0, 1),</span></div>
<div class="line"><span class="lineno">  391</span><span class="stringliteral">    ...                    grid_resolution=2) # doctest: +SKIP</span></div>
<div class="line"><span class="lineno">  392</span><span class="stringliteral">    (array([[-4.52...,  4.52...]]), [array([ 0.,  1.])])</span></div>
<div class="line"><span class="lineno">  393</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  394</span>    check_is_fitted(estimator)</div>
<div class="line"><span class="lineno">  395</span> </div>
<div class="line"><span class="lineno">  396</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> (is_classifier(estimator) <span class="keywordflow">or</span> is_regressor(estimator)):</div>
<div class="line"><span class="lineno">  397</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;&#39;estimator&#39; must be a fitted regressor or classifier.&quot;</span>)</div>
<div class="line"><span class="lineno">  398</span> </div>
<div class="line"><span class="lineno">  399</span>    <span class="keywordflow">if</span> is_classifier(estimator) <span class="keywordflow">and</span> isinstance(estimator.classes_[0], np.ndarray):</div>
<div class="line"><span class="lineno">  400</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Multiclass-multioutput estimators are not supported&quot;</span>)</div>
<div class="line"><span class="lineno">  401</span> </div>
<div class="line"><span class="lineno">  402</span>    <span class="comment"># Use check_array only on lists and other non-array-likes / sparse. Do not</span></div>
<div class="line"><span class="lineno">  403</span>    <span class="comment"># convert DataFrame into a NumPy array.</span></div>
<div class="line"><span class="lineno">  404</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> (hasattr(X, <span class="stringliteral">&quot;__array__&quot;</span>) <span class="keywordflow">or</span> sparse.issparse(X)):</div>
<div class="line"><span class="lineno">  405</span>        X = check_array(X, force_all_finite=<span class="stringliteral">&quot;allow-nan&quot;</span>, dtype=object)</div>
<div class="line"><span class="lineno">  406</span> </div>
<div class="line"><span class="lineno">  407</span>    accepted_responses = (<span class="stringliteral">&quot;auto&quot;</span>, <span class="stringliteral">&quot;predict_proba&quot;</span>, <span class="stringliteral">&quot;decision_function&quot;</span>)</div>
<div class="line"><span class="lineno">  408</span>    <span class="keywordflow">if</span> response_method <span class="keywordflow">not</span> <span class="keywordflow">in</span> accepted_responses:</div>
<div class="line"><span class="lineno">  409</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  410</span>            <span class="stringliteral">&quot;response_method {} is invalid. Accepted response_method names &quot;</span></div>
<div class="line"><span class="lineno">  411</span>            <span class="stringliteral">&quot;are {}.&quot;</span>.format(response_method, <span class="stringliteral">&quot;, &quot;</span>.join(accepted_responses))</div>
<div class="line"><span class="lineno">  412</span>        )</div>
<div class="line"><span class="lineno">  413</span> </div>
<div class="line"><span class="lineno">  414</span>    <span class="keywordflow">if</span> is_regressor(estimator) <span class="keywordflow">and</span> response_method != <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  415</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  416</span>            <span class="stringliteral">&quot;The response_method parameter is ignored for regressors and &quot;</span></div>
<div class="line"><span class="lineno">  417</span>            <span class="stringliteral">&quot;must be &#39;auto&#39;.&quot;</span></div>
<div class="line"><span class="lineno">  418</span>        )</div>
<div class="line"><span class="lineno">  419</span> </div>
<div class="line"><span class="lineno">  420</span>    accepted_methods = (<span class="stringliteral">&quot;brute&quot;</span>, <span class="stringliteral">&quot;recursion&quot;</span>, <span class="stringliteral">&quot;auto&quot;</span>)</div>
<div class="line"><span class="lineno">  421</span>    <span class="keywordflow">if</span> method <span class="keywordflow">not</span> <span class="keywordflow">in</span> accepted_methods:</div>
<div class="line"><span class="lineno">  422</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  423</span>            <span class="stringliteral">&quot;method {} is invalid. Accepted method names are {}.&quot;</span>.format(</div>
<div class="line"><span class="lineno">  424</span>                method, <span class="stringliteral">&quot;, &quot;</span>.join(accepted_methods)</div>
<div class="line"><span class="lineno">  425</span>            )</div>
<div class="line"><span class="lineno">  426</span>        )</div>
<div class="line"><span class="lineno">  427</span> </div>
<div class="line"><span class="lineno">  428</span>    <span class="keywordflow">if</span> kind != <span class="stringliteral">&quot;average&quot;</span>:</div>
<div class="line"><span class="lineno">  429</span>        <span class="keywordflow">if</span> method == <span class="stringliteral">&quot;recursion&quot;</span>:</div>
<div class="line"><span class="lineno">  430</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  431</span>                <span class="stringliteral">&quot;The &#39;recursion&#39; method only applies when &#39;kind&#39; is set to &#39;average&#39;&quot;</span></div>
<div class="line"><span class="lineno">  432</span>            )</div>
<div class="line"><span class="lineno">  433</span>        method = <span class="stringliteral">&quot;brute&quot;</span></div>
<div class="line"><span class="lineno">  434</span> </div>
<div class="line"><span class="lineno">  435</span>    <span class="keywordflow">if</span> method == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  436</span>        <span class="keywordflow">if</span> isinstance(estimator, BaseGradientBoosting) <span class="keywordflow">and</span> estimator.init <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  437</span>            method = <span class="stringliteral">&quot;recursion&quot;</span></div>
<div class="line"><span class="lineno">  438</span>        <span class="keywordflow">elif</span> isinstance(</div>
<div class="line"><span class="lineno">  439</span>            estimator,</div>
<div class="line"><span class="lineno">  440</span>            (BaseHistGradientBoosting, DecisionTreeRegressor, RandomForestRegressor),</div>
<div class="line"><span class="lineno">  441</span>        ):</div>
<div class="line"><span class="lineno">  442</span>            method = <span class="stringliteral">&quot;recursion&quot;</span></div>
<div class="line"><span class="lineno">  443</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  444</span>            method = <span class="stringliteral">&quot;brute&quot;</span></div>
<div class="line"><span class="lineno">  445</span> </div>
<div class="line"><span class="lineno">  446</span>    <span class="keywordflow">if</span> method == <span class="stringliteral">&quot;recursion&quot;</span>:</div>
<div class="line"><span class="lineno">  447</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(</div>
<div class="line"><span class="lineno">  448</span>            estimator,</div>
<div class="line"><span class="lineno">  449</span>            (</div>
<div class="line"><span class="lineno">  450</span>                BaseGradientBoosting,</div>
<div class="line"><span class="lineno">  451</span>                BaseHistGradientBoosting,</div>
<div class="line"><span class="lineno">  452</span>                DecisionTreeRegressor,</div>
<div class="line"><span class="lineno">  453</span>                RandomForestRegressor,</div>
<div class="line"><span class="lineno">  454</span>            ),</div>
<div class="line"><span class="lineno">  455</span>        ):</div>
<div class="line"><span class="lineno">  456</span>            supported_classes_recursion = (</div>
<div class="line"><span class="lineno">  457</span>                <span class="stringliteral">&quot;GradientBoostingClassifier&quot;</span>,</div>
<div class="line"><span class="lineno">  458</span>                <span class="stringliteral">&quot;GradientBoostingRegressor&quot;</span>,</div>
<div class="line"><span class="lineno">  459</span>                <span class="stringliteral">&quot;HistGradientBoostingClassifier&quot;</span>,</div>
<div class="line"><span class="lineno">  460</span>                <span class="stringliteral">&quot;HistGradientBoostingRegressor&quot;</span>,</div>
<div class="line"><span class="lineno">  461</span>                <span class="stringliteral">&quot;HistGradientBoostingRegressor&quot;</span>,</div>
<div class="line"><span class="lineno">  462</span>                <span class="stringliteral">&quot;DecisionTreeRegressor&quot;</span>,</div>
<div class="line"><span class="lineno">  463</span>                <span class="stringliteral">&quot;RandomForestRegressor&quot;</span>,</div>
<div class="line"><span class="lineno">  464</span>            )</div>
<div class="line"><span class="lineno">  465</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  466</span>                <span class="stringliteral">&quot;Only the following estimators support the &#39;recursion&#39; &quot;</span></div>
<div class="line"><span class="lineno">  467</span>                <span class="stringliteral">&quot;method: {}. Try using method=&#39;brute&#39;.&quot;</span>.format(</div>
<div class="line"><span class="lineno">  468</span>                    <span class="stringliteral">&quot;, &quot;</span>.join(supported_classes_recursion)</div>
<div class="line"><span class="lineno">  469</span>                )</div>
<div class="line"><span class="lineno">  470</span>            )</div>
<div class="line"><span class="lineno">  471</span>        <span class="keywordflow">if</span> response_method == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  472</span>            response_method = <span class="stringliteral">&quot;decision_function&quot;</span></div>
<div class="line"><span class="lineno">  473</span> </div>
<div class="line"><span class="lineno">  474</span>        <span class="keywordflow">if</span> response_method != <span class="stringliteral">&quot;decision_function&quot;</span>:</div>
<div class="line"><span class="lineno">  475</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  476</span>                <span class="stringliteral">&quot;With the &#39;recursion&#39; method, the response_method must be &quot;</span></div>
<div class="line"><span class="lineno">  477</span>                <span class="stringliteral">&quot;&#39;decision_function&#39;. Got {}.&quot;</span>.format(response_method)</div>
<div class="line"><span class="lineno">  478</span>            )</div>
<div class="line"><span class="lineno">  479</span> </div>
<div class="line"><span class="lineno">  480</span>    <span class="keywordflow">if</span> _determine_key_type(features, accept_slice=<span class="keyword">False</span>) == <span class="stringliteral">&quot;int&quot;</span>:</div>
<div class="line"><span class="lineno">  481</span>        <span class="comment"># _get_column_indices() supports negative indexing. Here, we limit</span></div>
<div class="line"><span class="lineno">  482</span>        <span class="comment"># the indexing to be positive. The upper bound will be checked</span></div>
<div class="line"><span class="lineno">  483</span>        <span class="comment"># by _get_column_indices()</span></div>
<div class="line"><span class="lineno">  484</span>        <span class="keywordflow">if</span> np.any(np.less(features, 0)):</div>
<div class="line"><span class="lineno">  485</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;all features must be in [0, {}]&quot;</span>.format(X.shape[1] - 1))</div>
<div class="line"><span class="lineno">  486</span> </div>
<div class="line"><span class="lineno">  487</span>    features_indices = np.asarray(</div>
<div class="line"><span class="lineno">  488</span>        _get_column_indices(X, features), dtype=np.int32, order=<span class="stringliteral">&quot;C&quot;</span></div>
<div class="line"><span class="lineno">  489</span>    ).ravel()</div>
<div class="line"><span class="lineno">  490</span> </div>
<div class="line"><span class="lineno">  491</span>    feature_names = _check_feature_names(X, feature_names)</div>
<div class="line"><span class="lineno">  492</span> </div>
<div class="line"><span class="lineno">  493</span>    n_features = X.shape[1]</div>
<div class="line"><span class="lineno">  494</span>    <span class="keywordflow">if</span> categorical_features <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  495</span>        is_categorical = [<span class="keyword">False</span>] * len(features_indices)</div>
<div class="line"><span class="lineno">  496</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  497</span>        categorical_features = np.array(categorical_features, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  498</span>        <span class="keywordflow">if</span> categorical_features.dtype.kind == <span class="stringliteral">&quot;b&quot;</span>:</div>
<div class="line"><span class="lineno">  499</span>            <span class="comment"># categorical features provided as a list of boolean</span></div>
<div class="line"><span class="lineno">  500</span>            <span class="keywordflow">if</span> categorical_features.size != n_features:</div>
<div class="line"><span class="lineno">  501</span>                <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  502</span>                    <span class="stringliteral">&quot;When `categorical_features` is a boolean array-like, &quot;</span></div>
<div class="line"><span class="lineno">  503</span>                    <span class="stringliteral">&quot;the array should be of shape (n_features,). Got &quot;</span></div>
<div class="line"><span class="lineno">  504</span>                    f<span class="stringliteral">&quot;{categorical_features.size} elements while `X` contains &quot;</span></div>
<div class="line"><span class="lineno">  505</span>                    f<span class="stringliteral">&quot;{n_features} features.&quot;</span></div>
<div class="line"><span class="lineno">  506</span>                )</div>
<div class="line"><span class="lineno">  507</span>            is_categorical = [categorical_features[idx] <span class="keywordflow">for</span> idx <span class="keywordflow">in</span> features_indices]</div>
<div class="line"><span class="lineno">  508</span>        <span class="keywordflow">elif</span> categorical_features.dtype.kind <span class="keywordflow">in</span> (<span class="stringliteral">&quot;i&quot;</span>, <span class="stringliteral">&quot;O&quot;</span>, <span class="stringliteral">&quot;U&quot;</span>):</div>
<div class="line"><span class="lineno">  509</span>            <span class="comment"># categorical features provided as a list of indices or feature names</span></div>
<div class="line"><span class="lineno">  510</span>            categorical_features_idx = [</div>
<div class="line"><span class="lineno">  511</span>                _get_feature_index(cat, feature_names=feature_names)</div>
<div class="line"><span class="lineno">  512</span>                <span class="keywordflow">for</span> cat <span class="keywordflow">in</span> categorical_features</div>
<div class="line"><span class="lineno">  513</span>            ]</div>
<div class="line"><span class="lineno">  514</span>            is_categorical = [</div>
<div class="line"><span class="lineno">  515</span>                idx <span class="keywordflow">in</span> categorical_features_idx <span class="keywordflow">for</span> idx <span class="keywordflow">in</span> features_indices</div>
<div class="line"><span class="lineno">  516</span>            ]</div>
<div class="line"><span class="lineno">  517</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  518</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  519</span>                <span class="stringliteral">&quot;Expected `categorical_features` to be an array-like of boolean,&quot;</span></div>
<div class="line"><span class="lineno">  520</span>                f<span class="stringliteral">&quot; integer, or string. Got {categorical_features.dtype} instead.&quot;</span></div>
<div class="line"><span class="lineno">  521</span>            )</div>
<div class="line"><span class="lineno">  522</span> </div>
<div class="line"><span class="lineno">  523</span>    grid, values = _grid_from_X(</div>
<div class="line"><span class="lineno">  524</span>        _safe_indexing(X, features_indices, axis=1),</div>
<div class="line"><span class="lineno">  525</span>        percentiles,</div>
<div class="line"><span class="lineno">  526</span>        is_categorical,</div>
<div class="line"><span class="lineno">  527</span>        grid_resolution,</div>
<div class="line"><span class="lineno">  528</span>    )</div>
<div class="line"><span class="lineno">  529</span> </div>
<div class="line"><span class="lineno">  530</span>    <span class="keywordflow">if</span> method == <span class="stringliteral">&quot;brute&quot;</span>:</div>
<div class="line"><span class="lineno">  531</span>        averaged_predictions, predictions = _partial_dependence_brute(</div>
<div class="line"><span class="lineno">  532</span>            estimator, grid, features_indices, X, response_method</div>
<div class="line"><span class="lineno">  533</span>        )</div>
<div class="line"><span class="lineno">  534</span> </div>
<div class="line"><span class="lineno">  535</span>        <span class="comment"># reshape predictions to</span></div>
<div class="line"><span class="lineno">  536</span>        <span class="comment"># (n_outputs, n_instances, n_values_feature_0, n_values_feature_1, ...)</span></div>
<div class="line"><span class="lineno">  537</span>        predictions = predictions.reshape(</div>
<div class="line"><span class="lineno">  538</span>            -1, X.shape[0], *[val.shape[0] <span class="keywordflow">for</span> val <span class="keywordflow">in</span> values]</div>
<div class="line"><span class="lineno">  539</span>        )</div>
<div class="line"><span class="lineno">  540</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  541</span>        averaged_predictions = _partial_dependence_recursion(</div>
<div class="line"><span class="lineno">  542</span>            estimator, grid, features_indices</div>
<div class="line"><span class="lineno">  543</span>        )</div>
<div class="line"><span class="lineno">  544</span> </div>
<div class="line"><span class="lineno">  545</span>    <span class="comment"># reshape averaged_predictions to</span></div>
<div class="line"><span class="lineno">  546</span>    <span class="comment"># (n_outputs, n_values_feature_0, n_values_feature_1, ...)</span></div>
<div class="line"><span class="lineno">  547</span>    averaged_predictions = averaged_predictions.reshape(</div>
<div class="line"><span class="lineno">  548</span>        -1, *[val.shape[0] <span class="keywordflow">for</span> val <span class="keywordflow">in</span> values]</div>
<div class="line"><span class="lineno">  549</span>    )</div>
<div class="line"><span class="lineno">  550</span> </div>
<div class="line"><span class="lineno">  551</span>    <span class="keywordflow">if</span> kind == <span class="stringliteral">&quot;average&quot;</span>:</div>
<div class="line"><span class="lineno">  552</span>        <span class="keywordflow">return</span> Bunch(average=averaged_predictions, values=values)</div>
<div class="line"><span class="lineno">  553</span>    <span class="keywordflow">elif</span> kind == <span class="stringliteral">&quot;individual&quot;</span>:</div>
<div class="line"><span class="lineno">  554</span>        <span class="keywordflow">return</span> Bunch(individual=predictions, values=values)</div>
<div class="line"><span class="lineno">  555</span>    <span class="keywordflow">else</span>:  <span class="comment"># kind=&#39;both&#39;</span></div>
<div class="line"><span class="lineno">  556</span>        <span class="keywordflow">return</span> Bunch(</div>
<div class="line"><span class="lineno">  557</span>            average=averaged_predictions,</div>
<div class="line"><span class="lineno">  558</span>            individual=predictions,</div>
<div class="line"><span class="lineno">  559</span>            values=values,</div>
<div class="line"><span class="lineno">  560</span>        )</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
