<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1neural__network.html">neural_network</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1neural__network_1_1__multilayer__perceptron.html">_multilayer_perceptron</a></li><li class="navelem"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html">BaseMultilayerPerceptron</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="#pro-static-attribs">Static Protected Attributes</a> &#124;
<a href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.png" usemap="#sklearn.neural_5Fnetwork._5Fmultilayer_5Fperceptron.BaseMultilayerPerceptron_map" alt=""/>
  <map id="sklearn.neural_5Fnetwork._5Fmultilayer_5Fperceptron.BaseMultilayerPerceptron_map" name="sklearn.neural_5Fnetwork._5Fmultilayer_5Fperceptron.BaseMultilayerPerceptron_map">
<area href="classsklearn_1_1base_1_1_base_estimator.html" alt="sklearn.base.BaseEstimator" shape="rect" coords="0,0,429,24"/>
<area href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_m_l_p_classifier.html" alt="sklearn.neural_network._multilayer_perceptron.MLPClassifier" shape="rect" coords="219,112,648,136"/>
<area href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_m_l_p_regressor.html" alt="sklearn.neural_network._multilayer_perceptron.MLPRegressor" shape="rect" coords="658,112,1087,136"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a8628ba21a9488704719d13836024cab6" id="r_a8628ba21a9488704719d13836024cab6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a8628ba21a9488704719d13836024cab6">__init__</a> (self, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a7053e621a032a08513a2453f2367bd74">hidden_layer_sizes</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a4b0df81b8358d50d0743405c659ed6b6">activation</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#aff27bf94ddf05461ed9282969ee64be9">solver</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a2b40afead813fd9060912fdc5c8c5585">alpha</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a256cb593f7457b57e20e030cb4297b4e">batch_size</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a0bd28615806017485087b01098172f8f">learning_rate</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a7bb6a222df4472c2f8219ba605f490c3">learning_rate_init</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#adb94c71df194fdc6d51b67e8e5bc93bc">power_t</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a318bdf742f2e44c92f36b7a0c0912a83">max_iter</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a04baf032eed9f8a39c8d32dd0c27e066">loss</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a3dc00b9cd7811c0f2a93016e9c31557a">shuffle</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a5f9e6d09bc3196361c46192640196624">random_state</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#af3fc521b13aae045b9e10387f34b0ba1">tol</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#abb3113bc3c7d179d4a7e9443f2090036">verbose</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a96c5a6ce572a9cfe24350c3f1b737116">warm_start</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#ad05c99ca6c9254da855b5d3fd2728f34">momentum</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#aa19a4c76b460a193cd87c03cc5e30280">nesterovs_momentum</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#aa019948ee2d7ac810cea9942dd3d5187">early_stopping</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a85298d7736f4e7fe4b167fc8ff51aaa6">validation_fraction</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#af338625696b13b08848be17ec42a3bcb">beta_1</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a4a0b9ab6cfff8afb6a02e09c65bfe064">beta_2</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a0c95ef33cbc4840aa36c1cee559e1c9b">epsilon</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a0f052dea4e28c577fa309c8c104ea9f7">n_iter_no_change</a>, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#ad0fedbabf4cba29b7e6800c566ed759e">max_fun</a>)</td></tr>
<tr class="separator:a8628ba21a9488704719d13836024cab6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40ff3842b506b0f6caec20e22eb4a9bb" id="r_a40ff3842b506b0f6caec20e22eb4a9bb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a40ff3842b506b0f6caec20e22eb4a9bb">fit</a> (self, X, y)</td></tr>
<tr class="separator:a40ff3842b506b0f6caec20e22eb4a9bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:a5c3e0c802dfacfbaceafb925c411b211 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a5c3e0c802dfacfbaceafb925c411b211"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a5c3e0c802dfacfbaceafb925c411b211">get_params</a> (self, deep=True)</td></tr>
<tr class="separator:a5c3e0c802dfacfbaceafb925c411b211 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8177e7086e8cbed1fec2bcdae9202c1 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_af8177e7086e8cbed1fec2bcdae9202c1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#af8177e7086e8cbed1fec2bcdae9202c1">set_params</a> (self, **params)</td></tr>
<tr class="separator:af8177e7086e8cbed1fec2bcdae9202c1 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5da47f044a7f6bc188b93722cad7a4c inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ad5da47f044a7f6bc188b93722cad7a4c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ad5da47f044a7f6bc188b93722cad7a4c">__repr__</a> (self, N_CHAR_MAX=700)</td></tr>
<tr class="separator:ad5da47f044a7f6bc188b93722cad7a4c inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f3d56fd989ef4230f70670d6128549e inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a1f3d56fd989ef4230f70670d6128549e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a1f3d56fd989ef4230f70670d6128549e">__getstate__</a> (self)</td></tr>
<tr class="separator:a1f3d56fd989ef4230f70670d6128549e inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e30cf35986d0ed01728b435e83bd427 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a4e30cf35986d0ed01728b435e83bd427"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a4e30cf35986d0ed01728b435e83bd427">__setstate__</a> (self, state)</td></tr>
<tr class="separator:a4e30cf35986d0ed01728b435e83bd427 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a4b0df81b8358d50d0743405c659ed6b6" id="r_a4b0df81b8358d50d0743405c659ed6b6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a4b0df81b8358d50d0743405c659ed6b6">activation</a></td></tr>
<tr class="separator:a4b0df81b8358d50d0743405c659ed6b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff27bf94ddf05461ed9282969ee64be9" id="r_aff27bf94ddf05461ed9282969ee64be9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#aff27bf94ddf05461ed9282969ee64be9">solver</a></td></tr>
<tr class="separator:aff27bf94ddf05461ed9282969ee64be9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b40afead813fd9060912fdc5c8c5585" id="r_a2b40afead813fd9060912fdc5c8c5585"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a2b40afead813fd9060912fdc5c8c5585">alpha</a></td></tr>
<tr class="separator:a2b40afead813fd9060912fdc5c8c5585"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a256cb593f7457b57e20e030cb4297b4e" id="r_a256cb593f7457b57e20e030cb4297b4e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a256cb593f7457b57e20e030cb4297b4e">batch_size</a></td></tr>
<tr class="separator:a256cb593f7457b57e20e030cb4297b4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0bd28615806017485087b01098172f8f" id="r_a0bd28615806017485087b01098172f8f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a0bd28615806017485087b01098172f8f">learning_rate</a></td></tr>
<tr class="separator:a0bd28615806017485087b01098172f8f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bb6a222df4472c2f8219ba605f490c3" id="r_a7bb6a222df4472c2f8219ba605f490c3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a7bb6a222df4472c2f8219ba605f490c3">learning_rate_init</a></td></tr>
<tr class="separator:a7bb6a222df4472c2f8219ba605f490c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb94c71df194fdc6d51b67e8e5bc93bc" id="r_adb94c71df194fdc6d51b67e8e5bc93bc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#adb94c71df194fdc6d51b67e8e5bc93bc">power_t</a></td></tr>
<tr class="separator:adb94c71df194fdc6d51b67e8e5bc93bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a318bdf742f2e44c92f36b7a0c0912a83" id="r_a318bdf742f2e44c92f36b7a0c0912a83"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a318bdf742f2e44c92f36b7a0c0912a83">max_iter</a></td></tr>
<tr class="separator:a318bdf742f2e44c92f36b7a0c0912a83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04baf032eed9f8a39c8d32dd0c27e066" id="r_a04baf032eed9f8a39c8d32dd0c27e066"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a04baf032eed9f8a39c8d32dd0c27e066">loss</a></td></tr>
<tr class="separator:a04baf032eed9f8a39c8d32dd0c27e066"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7053e621a032a08513a2453f2367bd74" id="r_a7053e621a032a08513a2453f2367bd74"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a7053e621a032a08513a2453f2367bd74">hidden_layer_sizes</a></td></tr>
<tr class="separator:a7053e621a032a08513a2453f2367bd74"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3dc00b9cd7811c0f2a93016e9c31557a" id="r_a3dc00b9cd7811c0f2a93016e9c31557a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a3dc00b9cd7811c0f2a93016e9c31557a">shuffle</a></td></tr>
<tr class="separator:a3dc00b9cd7811c0f2a93016e9c31557a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f9e6d09bc3196361c46192640196624" id="r_a5f9e6d09bc3196361c46192640196624"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a5f9e6d09bc3196361c46192640196624">random_state</a></td></tr>
<tr class="separator:a5f9e6d09bc3196361c46192640196624"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3fc521b13aae045b9e10387f34b0ba1" id="r_af3fc521b13aae045b9e10387f34b0ba1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#af3fc521b13aae045b9e10387f34b0ba1">tol</a></td></tr>
<tr class="separator:af3fc521b13aae045b9e10387f34b0ba1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb3113bc3c7d179d4a7e9443f2090036" id="r_abb3113bc3c7d179d4a7e9443f2090036"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#abb3113bc3c7d179d4a7e9443f2090036">verbose</a></td></tr>
<tr class="separator:abb3113bc3c7d179d4a7e9443f2090036"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96c5a6ce572a9cfe24350c3f1b737116" id="r_a96c5a6ce572a9cfe24350c3f1b737116"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a96c5a6ce572a9cfe24350c3f1b737116">warm_start</a></td></tr>
<tr class="separator:a96c5a6ce572a9cfe24350c3f1b737116"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad05c99ca6c9254da855b5d3fd2728f34" id="r_ad05c99ca6c9254da855b5d3fd2728f34"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#ad05c99ca6c9254da855b5d3fd2728f34">momentum</a></td></tr>
<tr class="separator:ad05c99ca6c9254da855b5d3fd2728f34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa19a4c76b460a193cd87c03cc5e30280" id="r_aa19a4c76b460a193cd87c03cc5e30280"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#aa19a4c76b460a193cd87c03cc5e30280">nesterovs_momentum</a></td></tr>
<tr class="separator:aa19a4c76b460a193cd87c03cc5e30280"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa019948ee2d7ac810cea9942dd3d5187" id="r_aa019948ee2d7ac810cea9942dd3d5187"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#aa019948ee2d7ac810cea9942dd3d5187">early_stopping</a></td></tr>
<tr class="separator:aa019948ee2d7ac810cea9942dd3d5187"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85298d7736f4e7fe4b167fc8ff51aaa6" id="r_a85298d7736f4e7fe4b167fc8ff51aaa6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a85298d7736f4e7fe4b167fc8ff51aaa6">validation_fraction</a></td></tr>
<tr class="separator:a85298d7736f4e7fe4b167fc8ff51aaa6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af338625696b13b08848be17ec42a3bcb" id="r_af338625696b13b08848be17ec42a3bcb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#af338625696b13b08848be17ec42a3bcb">beta_1</a></td></tr>
<tr class="separator:af338625696b13b08848be17ec42a3bcb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a0b9ab6cfff8afb6a02e09c65bfe064" id="r_a4a0b9ab6cfff8afb6a02e09c65bfe064"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a4a0b9ab6cfff8afb6a02e09c65bfe064">beta_2</a></td></tr>
<tr class="separator:a4a0b9ab6cfff8afb6a02e09c65bfe064"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c95ef33cbc4840aa36c1cee559e1c9b" id="r_a0c95ef33cbc4840aa36c1cee559e1c9b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a0c95ef33cbc4840aa36c1cee559e1c9b">epsilon</a></td></tr>
<tr class="separator:a0c95ef33cbc4840aa36c1cee559e1c9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f052dea4e28c577fa309c8c104ea9f7" id="r_a0f052dea4e28c577fa309c8c104ea9f7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a0f052dea4e28c577fa309c8c104ea9f7">n_iter_no_change</a></td></tr>
<tr class="separator:a0f052dea4e28c577fa309c8c104ea9f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0fedbabf4cba29b7e6800c566ed759e" id="r_ad0fedbabf4cba29b7e6800c566ed759e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#ad0fedbabf4cba29b7e6800c566ed759e">max_fun</a></td></tr>
<tr class="separator:ad0fedbabf4cba29b7e6800c566ed759e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4db5d73babe4976fac6b50ac73dccec" id="r_ac4db5d73babe4976fac6b50ac73dccec"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#ac4db5d73babe4976fac6b50ac73dccec">n_iter_</a></td></tr>
<tr class="separator:ac4db5d73babe4976fac6b50ac73dccec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1cdc4a9b4f8c1d00572be3ba7400d728" id="r_a1cdc4a9b4f8c1d00572be3ba7400d728"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a1cdc4a9b4f8c1d00572be3ba7400d728">t_</a></td></tr>
<tr class="separator:a1cdc4a9b4f8c1d00572be3ba7400d728"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac913f3e320e35d56add32462793c14e7" id="r_ac913f3e320e35d56add32462793c14e7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#ac913f3e320e35d56add32462793c14e7">n_outputs_</a></td></tr>
<tr class="separator:ac913f3e320e35d56add32462793c14e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5cda8eac7691d634a8687ec9b7c40ba3" id="r_a5cda8eac7691d634a8687ec9b7c40ba3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a></td></tr>
<tr class="separator:a5cda8eac7691d634a8687ec9b7c40ba3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afff2a19fd7ef7908183a44f2d2f87485" id="r_afff2a19fd7ef7908183a44f2d2f87485"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#afff2a19fd7ef7908183a44f2d2f87485">out_activation_</a></td></tr>
<tr class="separator:afff2a19fd7ef7908183a44f2d2f87485"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7a0f6e03d3ae3b265b7165e0a825ea1" id="r_ae7a0f6e03d3ae3b265b7165e0a825ea1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#ae7a0f6e03d3ae3b265b7165e0a825ea1">coefs_</a></td></tr>
<tr class="separator:ae7a0f6e03d3ae3b265b7165e0a825ea1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a942a95fba4263f47bcb5f1a7043e4167" id="r_a942a95fba4263f47bcb5f1a7043e4167"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a942a95fba4263f47bcb5f1a7043e4167">intercepts_</a></td></tr>
<tr class="separator:a942a95fba4263f47bcb5f1a7043e4167"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a848de96e596982a29e67ef603e761c63" id="r_a848de96e596982a29e67ef603e761c63"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a848de96e596982a29e67ef603e761c63">loss_curve_</a></td></tr>
<tr class="separator:a848de96e596982a29e67ef603e761c63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af524824394d7bacfc14b4f750df09bfa" id="r_af524824394d7bacfc14b4f750df09bfa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#af524824394d7bacfc14b4f750df09bfa">validation_scores_</a></td></tr>
<tr class="separator:af524824394d7bacfc14b4f750df09bfa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9772e422910c066bd1214dc5e01f984" id="r_af9772e422910c066bd1214dc5e01f984"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#af9772e422910c066bd1214dc5e01f984">best_validation_score_</a></td></tr>
<tr class="separator:af9772e422910c066bd1214dc5e01f984"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af40bcadc6bac794f5ac49e146d787262" id="r_af40bcadc6bac794f5ac49e146d787262"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#af40bcadc6bac794f5ac49e146d787262">best_loss_</a></td></tr>
<tr class="separator:af40bcadc6bac794f5ac49e146d787262"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27576cf472db61b06d2951267d01df7a" id="r_a27576cf472db61b06d2951267d01df7a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a27576cf472db61b06d2951267d01df7a">loss_</a></td></tr>
<tr class="separator:a27576cf472db61b06d2951267d01df7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:a66d54a0fbf5710ff325104e2d2c9d7b0 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator" id="r_a66d54a0fbf5710ff325104e2d2c9d7b0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a66d54a0fbf5710ff325104e2d2c9d7b0">n_features_in_</a></td></tr>
<tr class="separator:a66d54a0fbf5710ff325104e2d2c9d7b0 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ad6c8c0f63c0b4c97c501765e93cc78 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator" id="r_a2ad6c8c0f63c0b4c97c501765e93cc78"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a2ad6c8c0f63c0b4c97c501765e93cc78">feature_names_in_</a></td></tr>
<tr class="separator:a2ad6c8c0f63c0b4c97c501765e93cc78 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-methods" name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:ab5407ee4ebf264a65951d66ac2dca857" id="r_ab5407ee4ebf264a65951d66ac2dca857"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#ab5407ee4ebf264a65951d66ac2dca857">_unpack</a> (self, packed_parameters)</td></tr>
<tr class="separator:ab5407ee4ebf264a65951d66ac2dca857"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a446fb221b8ffb5dac45f7b0506729351" id="r_a446fb221b8ffb5dac45f7b0506729351"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a446fb221b8ffb5dac45f7b0506729351">_forward_pass</a> (self, activations)</td></tr>
<tr class="separator:a446fb221b8ffb5dac45f7b0506729351"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6a44fba6cb57698d9d8a8c4a2867903" id="r_aa6a44fba6cb57698d9d8a8c4a2867903"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#aa6a44fba6cb57698d9d8a8c4a2867903">_forward_pass_fast</a> (self, X)</td></tr>
<tr class="separator:aa6a44fba6cb57698d9d8a8c4a2867903"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46cf904635ed5548ba37304dfdb8d28e" id="r_a46cf904635ed5548ba37304dfdb8d28e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a46cf904635ed5548ba37304dfdb8d28e">_compute_loss_grad</a> (self, layer, n_samples, activations, deltas, coef_grads, intercept_grads)</td></tr>
<tr class="separator:a46cf904635ed5548ba37304dfdb8d28e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ea066e5139d7be0b21167649581ec7a" id="r_a6ea066e5139d7be0b21167649581ec7a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a6ea066e5139d7be0b21167649581ec7a">_loss_grad_lbfgs</a> (self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)</td></tr>
<tr class="separator:a6ea066e5139d7be0b21167649581ec7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67bd08bd5d520e7b5cf3005a29401541" id="r_a67bd08bd5d520e7b5cf3005a29401541"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a67bd08bd5d520e7b5cf3005a29401541">_backprop</a> (self, X, y, activations, deltas, coef_grads, intercept_grads)</td></tr>
<tr class="separator:a67bd08bd5d520e7b5cf3005a29401541"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8cd7dbf0b493aab5c0f7e053575be1e" id="r_aa8cd7dbf0b493aab5c0f7e053575be1e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#aa8cd7dbf0b493aab5c0f7e053575be1e">_initialize</a> (self, y, layer_units, dtype)</td></tr>
<tr class="separator:aa8cd7dbf0b493aab5c0f7e053575be1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e03c7f5817e706517ad8ca12110c99f" id="r_a7e03c7f5817e706517ad8ca12110c99f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a7e03c7f5817e706517ad8ca12110c99f">_init_coef</a> (self, fan_in, fan_out, dtype)</td></tr>
<tr class="separator:a7e03c7f5817e706517ad8ca12110c99f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a15ada7bfbc3eacbc772c2923214c859e" id="r_a15ada7bfbc3eacbc772c2923214c859e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a15ada7bfbc3eacbc772c2923214c859e">_fit</a> (self, X, y, incremental=False)</td></tr>
<tr class="separator:a15ada7bfbc3eacbc772c2923214c859e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1233d7d0c70bf92d6a02113738fb1d84" id="r_a1233d7d0c70bf92d6a02113738fb1d84"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a1233d7d0c70bf92d6a02113738fb1d84">_fit_lbfgs</a> (self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)</td></tr>
<tr class="separator:a1233d7d0c70bf92d6a02113738fb1d84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b8a08220068d3733566eff2982fd9e7" id="r_a7b8a08220068d3733566eff2982fd9e7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a7b8a08220068d3733566eff2982fd9e7">_fit_stochastic</a> (self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units, incremental)</td></tr>
<tr class="separator:a7b8a08220068d3733566eff2982fd9e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3440369c98c29e0cb9495106b6156d84" id="r_a3440369c98c29e0cb9495106b6156d84"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a3440369c98c29e0cb9495106b6156d84">_update_no_improvement_count</a> (self, <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#aa019948ee2d7ac810cea9942dd3d5187">early_stopping</a>, X_val, y_val)</td></tr>
<tr class="separator:a3440369c98c29e0cb9495106b6156d84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1638380aac8a9c0576ce752d17a4bd8" id="r_ac1638380aac8a9c0576ce752d17a4bd8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#ac1638380aac8a9c0576ce752d17a4bd8">_check_solver</a> (self)</td></tr>
<tr class="separator:ac1638380aac8a9c0576ce752d17a4bd8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:ab7620691376c89dd6b11583a7ec88056 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ab7620691376c89dd6b11583a7ec88056"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ab7620691376c89dd6b11583a7ec88056">_get_param_names</a> (cls)</td></tr>
<tr class="separator:ab7620691376c89dd6b11583a7ec88056 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8c4c3c1db15de8e006c18fce6b8bad3 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ad8c4c3c1db15de8e006c18fce6b8bad3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ad8c4c3c1db15de8e006c18fce6b8bad3">_more_tags</a> (self)</td></tr>
<tr class="separator:ad8c4c3c1db15de8e006c18fce6b8bad3 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17c0074e0a07bf88909d50bbd89a2735 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a17c0074e0a07bf88909d50bbd89a2735"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a17c0074e0a07bf88909d50bbd89a2735">_get_tags</a> (self)</td></tr>
<tr class="separator:a17c0074e0a07bf88909d50bbd89a2735 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeced67fac6e13c3a6e7f6866e83c02f5 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_aeced67fac6e13c3a6e7f6866e83c02f5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#aeced67fac6e13c3a6e7f6866e83c02f5">_check_n_features</a> (self, X, reset)</td></tr>
<tr class="separator:aeced67fac6e13c3a6e7f6866e83c02f5 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a167be2ae43526843680356c2b2712125 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a167be2ae43526843680356c2b2712125"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a167be2ae43526843680356c2b2712125">_check_feature_names</a> (self, X, *reset)</td></tr>
<tr class="separator:a167be2ae43526843680356c2b2712125 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a846c04fab4a234189ebac04e5ed9b8a6 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a846c04fab4a234189ebac04e5ed9b8a6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a846c04fab4a234189ebac04e5ed9b8a6">_validate_data</a> (self, X=&quot;no_validation&quot;, y=&quot;no_validation&quot;, reset=True, validate_separately=False, **check_params)</td></tr>
<tr class="separator:a846c04fab4a234189ebac04e5ed9b8a6 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8f8e87d8b09ffa6ac9a38403510b839 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_aa8f8e87d8b09ffa6ac9a38403510b839"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#aa8f8e87d8b09ffa6ac9a38403510b839">_validate_params</a> (self)</td></tr>
<tr class="separator:aa8f8e87d8b09ffa6ac9a38403510b839 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f2a9aeff923062d9b8d64ff8ae9a15f inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a1f2a9aeff923062d9b8d64ff8ae9a15f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a1f2a9aeff923062d9b8d64ff8ae9a15f">_repr_html_</a> (self)</td></tr>
<tr class="separator:a1f2a9aeff923062d9b8d64ff8ae9a15f inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab49884d0348bb8bf19b65d1d68cffcaf inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ab49884d0348bb8bf19b65d1d68cffcaf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ab49884d0348bb8bf19b65d1d68cffcaf">_repr_html_inner</a> (self)</td></tr>
<tr class="separator:ab49884d0348bb8bf19b65d1d68cffcaf inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1dde4ef8aac627f20f205e41a0b14efc inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a1dde4ef8aac627f20f205e41a0b14efc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a1dde4ef8aac627f20f205e41a0b14efc">_repr_mimebundle_</a> (self, **kwargs)</td></tr>
<tr class="separator:a1dde4ef8aac627f20f205e41a0b14efc inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-attribs" name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a5bd17016407c86648c4f1014a7ba6666" id="r_a5bd17016407c86648c4f1014a7ba6666"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a5bd17016407c86648c4f1014a7ba6666">_no_improvement_count</a></td></tr>
<tr class="separator:a5bd17016407c86648c4f1014a7ba6666"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a215bc7c01b70f8525b1e8f1c0c035e4a" id="r_a215bc7c01b70f8525b1e8f1c0c035e4a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a215bc7c01b70f8525b1e8f1c0c035e4a">_random_state</a></td></tr>
<tr class="separator:a215bc7c01b70f8525b1e8f1c0c035e4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4eaf0911d400b823eceba8ba8f676efc" id="r_a4eaf0911d400b823eceba8ba8f676efc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a4eaf0911d400b823eceba8ba8f676efc">_coef_indptr</a></td></tr>
<tr class="separator:a4eaf0911d400b823eceba8ba8f676efc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aace356676d3fdc48ae2d7a07786ddb2c" id="r_aace356676d3fdc48ae2d7a07786ddb2c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#aace356676d3fdc48ae2d7a07786ddb2c">_intercept_indptr</a></td></tr>
<tr class="separator:aace356676d3fdc48ae2d7a07786ddb2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad70c8d44857d1403a88f8536a679007c" id="r_ad70c8d44857d1403a88f8536a679007c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#ad70c8d44857d1403a88f8536a679007c">_loss_grad_lbfgs</a></td></tr>
<tr class="separator:ad70c8d44857d1403a88f8536a679007c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9335dce7fccc3077842f4deccf52ac98" id="r_a9335dce7fccc3077842f4deccf52ac98"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a9335dce7fccc3077842f4deccf52ac98">_optimizer</a></td></tr>
<tr class="separator:a9335dce7fccc3077842f4deccf52ac98"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94a861f862371e1bd35aa87a3726dd03" id="r_a94a861f862371e1bd35aa87a3726dd03"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a94a861f862371e1bd35aa87a3726dd03">_best_coefs</a></td></tr>
<tr class="separator:a94a861f862371e1bd35aa87a3726dd03"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e5aa13446925e788dd76b612c567088" id="r_a6e5aa13446925e788dd76b612c567088"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a6e5aa13446925e788dd76b612c567088">_best_intercepts</a></td></tr>
<tr class="separator:a6e5aa13446925e788dd76b612c567088"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_attribs_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pro_attribs_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Protected Attributes inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:aa788e7d07aae196ad4045be35ec03ebd inherit pro_attribs_classsklearn_1_1base_1_1_base_estimator" id="r_aa788e7d07aae196ad4045be35ec03ebd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#aa788e7d07aae196ad4045be35ec03ebd">_parameter_constraints</a></td></tr>
<tr class="separator:aa788e7d07aae196ad4045be35ec03ebd inherit pro_attribs_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-static-attribs" name="pro-static-attribs"></a>
Static Protected Attributes</h2></td></tr>
<tr class="memitem:a6ec5070db5c8915a73cdf6369d0b8efa" id="r_a6ec5070db5c8915a73cdf6369d0b8efa"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_base_multilayer_perceptron.html#a6ec5070db5c8915a73cdf6369d0b8efa">_parameter_constraints</a></td></tr>
<tr class="separator:a6ec5070db5c8915a73cdf6369d0b8efa"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Base class for MLP classification and regression.

Warning: This class should not be used directly.
Use derived classes instead.

.. versionadded:: 0.18
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a8628ba21a9488704719d13836024cab6" name="a8628ba21a9488704719d13836024cab6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8628ba21a9488704719d13836024cab6">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hidden_layer_sizes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>solver</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learning_rate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learning_rate_init</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>power_t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>shuffle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>warm_start</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>momentum</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>nesterovs_momentum</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>early_stopping</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>validation_fraction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>beta_1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>beta_2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_iter_no_change</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_fun</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reimplemented in <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_m_l_p_classifier.html#ae479fbeda4eeb8e474f260d151fac0af">sklearn.neural_network._multilayer_perceptron.MLPClassifier</a>, and <a class="el" href="classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1_m_l_p_regressor.html#a12f5d13f223808b062f3a5316c8752dd">sklearn.neural_network._multilayer_perceptron.MLPRegressor</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  121</span>    ):</div>
<div class="line"><span class="lineno">  122</span>        self.activation = activation</div>
<div class="line"><span class="lineno">  123</span>        self.solver = solver</div>
<div class="line"><span class="lineno">  124</span>        self.alpha = alpha</div>
<div class="line"><span class="lineno">  125</span>        self.batch_size = batch_size</div>
<div class="line"><span class="lineno">  126</span>        self.learning_rate = learning_rate</div>
<div class="line"><span class="lineno">  127</span>        self.learning_rate_init = learning_rate_init</div>
<div class="line"><span class="lineno">  128</span>        self.power_t = power_t</div>
<div class="line"><span class="lineno">  129</span>        self.max_iter = max_iter</div>
<div class="line"><span class="lineno">  130</span>        self.loss = loss</div>
<div class="line"><span class="lineno">  131</span>        self.hidden_layer_sizes = hidden_layer_sizes</div>
<div class="line"><span class="lineno">  132</span>        self.shuffle = shuffle</div>
<div class="line"><span class="lineno">  133</span>        self.random_state = random_state</div>
<div class="line"><span class="lineno">  134</span>        self.tol = tol</div>
<div class="line"><span class="lineno">  135</span>        self.verbose = verbose</div>
<div class="line"><span class="lineno">  136</span>        self.warm_start = warm_start</div>
<div class="line"><span class="lineno">  137</span>        self.momentum = momentum</div>
<div class="line"><span class="lineno">  138</span>        self.nesterovs_momentum = nesterovs_momentum</div>
<div class="line"><span class="lineno">  139</span>        self.early_stopping = early_stopping</div>
<div class="line"><span class="lineno">  140</span>        self.validation_fraction = validation_fraction</div>
<div class="line"><span class="lineno">  141</span>        self.beta_1 = beta_1</div>
<div class="line"><span class="lineno">  142</span>        self.beta_2 = beta_2</div>
<div class="line"><span class="lineno">  143</span>        self.epsilon = epsilon</div>
<div class="line"><span class="lineno">  144</span>        self.n_iter_no_change = n_iter_no_change</div>
<div class="line"><span class="lineno">  145</span>        self.max_fun = max_fun</div>
<div class="line"><span class="lineno">  146</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a67bd08bd5d520e7b5cf3005a29401541" name="a67bd08bd5d520e7b5cf3005a29401541"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a67bd08bd5d520e7b5cf3005a29401541">&#9670;&#160;</a></span>_backprop()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._backprop </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>deltas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>coef_grads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>intercept_grads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute the MLP loss function and its corresponding derivatives
with respect to each parameter: weights and bias vectors.

Parameters
----------
X : {array-like, sparse matrix} of shape (n_samples, n_features)
    The input data.

y : ndarray of shape (n_samples,)
    The target values.

activations : list, length = n_layers - 1
     The ith element of the list holds the values of the ith layer.

deltas : list, length = n_layers - 1
    The ith element of the list holds the difference between the
    activations of the i + 1 layer and the backpropagated error.
    More specifically, deltas are gradients of loss with respect to z
    in each layer, where z = wx + b is the value of a particular layer
    before passing through the activation function

coef_grads : list, length = n_layers - 1
    The ith element contains the amount of change used to update the
    coefficient parameters of the ith layer in an iteration.

intercept_grads : list, length = n_layers - 1
    The ith element contains the amount of change used to update the
    intercept parameters of the ith layer in an iteration.

Returns
-------
loss : float
coef_grads : list, length = n_layers - 1
intercept_grads : list, length = n_layers - 1
</pre> <div class="fragment"><div class="line"><span class="lineno">  278</span>    <span class="keyword">def </span>_backprop(self, X, y, activations, deltas, coef_grads, intercept_grads):</div>
<div class="line"><span class="lineno">  279</span>        <span class="stringliteral">&quot;&quot;&quot;Compute the MLP loss function and its corresponding derivatives</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">        with respect to each parameter: weights and bias vectors.</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">        y : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">            The target values.</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">        activations : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">             The ith element of the list holds the values of the ith layer.</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">        deltas : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">            The ith element of the list holds the difference between the</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">            activations of the i + 1 layer and the backpropagated error.</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">            More specifically, deltas are gradients of loss with respect to z</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">            in each layer, where z = wx + b is the value of a particular layer</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">            before passing through the activation function</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">        coef_grads : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">            The ith element contains the amount of change used to update the</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">            coefficient parameters of the ith layer in an iteration.</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">        intercept_grads : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">            The ith element contains the amount of change used to update the</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">            intercept parameters of the ith layer in an iteration.</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">        loss : float</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">        coef_grads : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">        intercept_grads : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  314</span>        n_samples = X.shape[0]</div>
<div class="line"><span class="lineno">  315</span> </div>
<div class="line"><span class="lineno">  316</span>        <span class="comment"># Forward propagate</span></div>
<div class="line"><span class="lineno">  317</span>        activations = self._forward_pass(activations)</div>
<div class="line"><span class="lineno">  318</span> </div>
<div class="line"><span class="lineno">  319</span>        <span class="comment"># Get loss</span></div>
<div class="line"><span class="lineno">  320</span>        loss_func_name = self.loss</div>
<div class="line"><span class="lineno">  321</span>        <span class="keywordflow">if</span> loss_func_name == <span class="stringliteral">&quot;log_loss&quot;</span> <span class="keywordflow">and</span> self.out_activation_ == <span class="stringliteral">&quot;logistic&quot;</span>:</div>
<div class="line"><span class="lineno">  322</span>            loss_func_name = <span class="stringliteral">&quot;binary_log_loss&quot;</span></div>
<div class="line"><span class="lineno">  323</span>        loss = LOSS_FUNCTIONS[loss_func_name](y, activations[-1])</div>
<div class="line"><span class="lineno">  324</span>        <span class="comment"># Add L2 regularization term to loss</span></div>
<div class="line"><span class="lineno">  325</span>        values = 0</div>
<div class="line"><span class="lineno">  326</span>        <span class="keywordflow">for</span> s <span class="keywordflow">in</span> self.coefs_:</div>
<div class="line"><span class="lineno">  327</span>            s = s.ravel()</div>
<div class="line"><span class="lineno">  328</span>            values += np.dot(s, s)</div>
<div class="line"><span class="lineno">  329</span>        loss += (0.5 * self.alpha) * values / n_samples</div>
<div class="line"><span class="lineno">  330</span> </div>
<div class="line"><span class="lineno">  331</span>        <span class="comment"># Backward propagate</span></div>
<div class="line"><span class="lineno">  332</span>        last = self.n_layers_ - 2</div>
<div class="line"><span class="lineno">  333</span> </div>
<div class="line"><span class="lineno">  334</span>        <span class="comment"># The calculation of delta[last] here works with following</span></div>
<div class="line"><span class="lineno">  335</span>        <span class="comment"># combinations of output activation and loss function:</span></div>
<div class="line"><span class="lineno">  336</span>        <span class="comment"># sigmoid and binary cross entropy, softmax and categorical cross</span></div>
<div class="line"><span class="lineno">  337</span>        <span class="comment"># entropy, and identity with squared loss</span></div>
<div class="line"><span class="lineno">  338</span>        deltas[last] = activations[-1] - y</div>
<div class="line"><span class="lineno">  339</span> </div>
<div class="line"><span class="lineno">  340</span>        <span class="comment"># Compute gradient for the last layer</span></div>
<div class="line"><span class="lineno">  341</span>        self._compute_loss_grad(</div>
<div class="line"><span class="lineno">  342</span>            last, n_samples, activations, deltas, coef_grads, intercept_grads</div>
<div class="line"><span class="lineno">  343</span>        )</div>
<div class="line"><span class="lineno">  344</span> </div>
<div class="line"><span class="lineno">  345</span>        inplace_derivative = DERIVATIVES[self.activation]</div>
<div class="line"><span class="lineno">  346</span>        <span class="comment"># Iterate over the hidden layers</span></div>
<div class="line"><span class="lineno">  347</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.n_layers_ - 2, 0, -1):</div>
<div class="line"><span class="lineno">  348</span>            deltas[i - 1] = safe_sparse_dot(deltas[i], self.coefs_[i].T)</div>
<div class="line"><span class="lineno">  349</span>            inplace_derivative(activations[i], deltas[i - 1])</div>
<div class="line"><span class="lineno">  350</span> </div>
<div class="line"><span class="lineno">  351</span>            self._compute_loss_grad(</div>
<div class="line"><span class="lineno">  352</span>                i - 1, n_samples, activations, deltas, coef_grads, intercept_grads</div>
<div class="line"><span class="lineno">  353</span>            )</div>
<div class="line"><span class="lineno">  354</span> </div>
<div class="line"><span class="lineno">  355</span>        <span class="keywordflow">return</span> loss, coef_grads, intercept_grads</div>
<div class="line"><span class="lineno">  356</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac1638380aac8a9c0576ce752d17a4bd8" name="ac1638380aac8a9c0576ce752d17a4bd8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac1638380aac8a9c0576ce752d17a4bd8">&#9670;&#160;</a></span>_check_solver()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._check_solver </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  744</span>    <span class="keyword">def </span>_check_solver(self):</div>
<div class="line"><span class="lineno">  745</span>        <span class="keywordflow">if</span> self.solver <span class="keywordflow">not</span> <span class="keywordflow">in</span> _STOCHASTIC_SOLVERS:</div>
<div class="line"><span class="lineno">  746</span>            <span class="keywordflow">raise</span> AttributeError(</div>
<div class="line"><span class="lineno">  747</span>                <span class="stringliteral">&quot;partial_fit is only available for stochastic&quot;</span></div>
<div class="line"><span class="lineno">  748</span>                <span class="stringliteral">&quot; optimizers. %s is not stochastic.&quot;</span></div>
<div class="line"><span class="lineno">  749</span>                % self.solver</div>
<div class="line"><span class="lineno">  750</span>            )</div>
<div class="line"><span class="lineno">  751</span>        <span class="keywordflow">return</span> <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  752</span> </div>
<div class="line"><span class="lineno">  753</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a46cf904635ed5548ba37304dfdb8d28e" name="a46cf904635ed5548ba37304dfdb8d28e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46cf904635ed5548ba37304dfdb8d28e">&#9670;&#160;</a></span>_compute_loss_grad()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._compute_loss_grad </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>deltas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>coef_grads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>intercept_grads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute the gradient of loss with respect to coefs and intercept for
specified layer.

This function does backpropagation for the specified one layer.
</pre> <div class="fragment"><div class="line"><span class="lineno">  216</span>    ):</div>
<div class="line"><span class="lineno">  217</span>        <span class="stringliteral">&quot;&quot;&quot;Compute the gradient of loss with respect to coefs and intercept for</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">        specified layer.</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">        This function does backpropagation for the specified one layer.</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  222</span>        coef_grads[layer] = safe_sparse_dot(activations[layer].T, deltas[layer])</div>
<div class="line"><span class="lineno">  223</span>        coef_grads[layer] += self.alpha * self.coefs_[layer]</div>
<div class="line"><span class="lineno">  224</span>        coef_grads[layer] /= n_samples</div>
<div class="line"><span class="lineno">  225</span> </div>
<div class="line"><span class="lineno">  226</span>        intercept_grads[layer] = np.mean(deltas[layer], 0)</div>
<div class="line"><span class="lineno">  227</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a15ada7bfbc3eacbc772c2923214c859e" name="a15ada7bfbc3eacbc772c2923214c859e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a15ada7bfbc3eacbc772c2923214c859e">&#9670;&#160;</a></span>_fit()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._fit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>incremental</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  417</span>    <span class="keyword">def </span>_fit(self, X, y, incremental=False):</div>
<div class="line"><span class="lineno">  418</span>        <span class="comment"># Make sure self.hidden_layer_sizes is a list</span></div>
<div class="line"><span class="lineno">  419</span>        hidden_layer_sizes = self.hidden_layer_sizes</div>
<div class="line"><span class="lineno">  420</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(hidden_layer_sizes, <span class="stringliteral">&quot;__iter__&quot;</span>):</div>
<div class="line"><span class="lineno">  421</span>            hidden_layer_sizes = [hidden_layer_sizes]</div>
<div class="line"><span class="lineno">  422</span>        hidden_layer_sizes = list(hidden_layer_sizes)</div>
<div class="line"><span class="lineno">  423</span> </div>
<div class="line"><span class="lineno">  424</span>        <span class="keywordflow">if</span> np.any(np.array(hidden_layer_sizes) &lt;= 0):</div>
<div class="line"><span class="lineno">  425</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  426</span>                <span class="stringliteral">&quot;hidden_layer_sizes must be &gt; 0, got %s.&quot;</span> % hidden_layer_sizes</div>
<div class="line"><span class="lineno">  427</span>            )</div>
<div class="line"><span class="lineno">  428</span>        first_pass = <span class="keywordflow">not</span> hasattr(self, <span class="stringliteral">&quot;coefs_&quot;</span>) <span class="keywordflow">or</span> (</div>
<div class="line"><span class="lineno">  429</span>            <span class="keywordflow">not</span> self.warm_start <span class="keywordflow">and</span> <span class="keywordflow">not</span> incremental</div>
<div class="line"><span class="lineno">  430</span>        )</div>
<div class="line"><span class="lineno">  431</span> </div>
<div class="line"><span class="lineno">  432</span>        X, y = self._validate_input(X, y, incremental, reset=first_pass)</div>
<div class="line"><span class="lineno">  433</span> </div>
<div class="line"><span class="lineno">  434</span>        n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  435</span> </div>
<div class="line"><span class="lineno">  436</span>        <span class="comment"># Ensure y is 2D</span></div>
<div class="line"><span class="lineno">  437</span>        <span class="keywordflow">if</span> y.ndim == 1:</div>
<div class="line"><span class="lineno">  438</span>            y = y.reshape((-1, 1))</div>
<div class="line"><span class="lineno">  439</span> </div>
<div class="line"><span class="lineno">  440</span>        self.n_outputs_ = y.shape[1]</div>
<div class="line"><span class="lineno">  441</span> </div>
<div class="line"><span class="lineno">  442</span>        layer_units = [n_features] + hidden_layer_sizes + [self.n_outputs_]</div>
<div class="line"><span class="lineno">  443</span> </div>
<div class="line"><span class="lineno">  444</span>        <span class="comment"># check random state</span></div>
<div class="line"><span class="lineno">  445</span>        self._random_state = check_random_state(self.random_state)</div>
<div class="line"><span class="lineno">  446</span> </div>
<div class="line"><span class="lineno">  447</span>        <span class="keywordflow">if</span> first_pass:</div>
<div class="line"><span class="lineno">  448</span>            <span class="comment"># First time training the model</span></div>
<div class="line"><span class="lineno">  449</span>            self._initialize(y, layer_units, X.dtype)</div>
<div class="line"><span class="lineno">  450</span> </div>
<div class="line"><span class="lineno">  451</span>        <span class="comment"># Initialize lists</span></div>
<div class="line"><span class="lineno">  452</span>        activations = [X] + [<span class="keywordtype">None</span>] * (len(layer_units) - 1)</div>
<div class="line"><span class="lineno">  453</span>        deltas = [<span class="keywordtype">None</span>] * (len(activations) - 1)</div>
<div class="line"><span class="lineno">  454</span> </div>
<div class="line"><span class="lineno">  455</span>        coef_grads = [</div>
<div class="line"><span class="lineno">  456</span>            np.empty((n_fan_in_, n_fan_out_), dtype=X.dtype)</div>
<div class="line"><span class="lineno">  457</span>            <span class="keywordflow">for</span> n_fan_in_, n_fan_out_ <span class="keywordflow">in</span> zip(layer_units[:-1], layer_units[1:])</div>
<div class="line"><span class="lineno">  458</span>        ]</div>
<div class="line"><span class="lineno">  459</span> </div>
<div class="line"><span class="lineno">  460</span>        intercept_grads = [</div>
<div class="line"><span class="lineno">  461</span>            np.empty(n_fan_out_, dtype=X.dtype) <span class="keywordflow">for</span> n_fan_out_ <span class="keywordflow">in</span> layer_units[1:]</div>
<div class="line"><span class="lineno">  462</span>        ]</div>
<div class="line"><span class="lineno">  463</span> </div>
<div class="line"><span class="lineno">  464</span>        <span class="comment"># Run the Stochastic optimization solver</span></div>
<div class="line"><span class="lineno">  465</span>        <span class="keywordflow">if</span> self.solver <span class="keywordflow">in</span> _STOCHASTIC_SOLVERS:</div>
<div class="line"><span class="lineno">  466</span>            self._fit_stochastic(</div>
<div class="line"><span class="lineno">  467</span>                X,</div>
<div class="line"><span class="lineno">  468</span>                y,</div>
<div class="line"><span class="lineno">  469</span>                activations,</div>
<div class="line"><span class="lineno">  470</span>                deltas,</div>
<div class="line"><span class="lineno">  471</span>                coef_grads,</div>
<div class="line"><span class="lineno">  472</span>                intercept_grads,</div>
<div class="line"><span class="lineno">  473</span>                layer_units,</div>
<div class="line"><span class="lineno">  474</span>                incremental,</div>
<div class="line"><span class="lineno">  475</span>            )</div>
<div class="line"><span class="lineno">  476</span> </div>
<div class="line"><span class="lineno">  477</span>        <span class="comment"># Run the LBFGS solver</span></div>
<div class="line"><span class="lineno">  478</span>        <span class="keywordflow">elif</span> self.solver == <span class="stringliteral">&quot;lbfgs&quot;</span>:</div>
<div class="line"><span class="lineno">  479</span>            self._fit_lbfgs(</div>
<div class="line"><span class="lineno">  480</span>                X, y, activations, deltas, coef_grads, intercept_grads, layer_units</div>
<div class="line"><span class="lineno">  481</span>            )</div>
<div class="line"><span class="lineno">  482</span> </div>
<div class="line"><span class="lineno">  483</span>        <span class="comment"># validate parameter weights</span></div>
<div class="line"><span class="lineno">  484</span>        weights = chain(self.coefs_, self.intercepts_)</div>
<div class="line"><span class="lineno">  485</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> all(np.isfinite(w).all() <span class="keywordflow">for</span> w <span class="keywordflow">in</span> weights):</div>
<div class="line"><span class="lineno">  486</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  487</span>                <span class="stringliteral">&quot;Solver produced non-finite parameter weights. The input data may&quot;</span></div>
<div class="line"><span class="lineno">  488</span>                <span class="stringliteral">&quot; contain large values and need to be preprocessed.&quot;</span></div>
<div class="line"><span class="lineno">  489</span>            )</div>
<div class="line"><span class="lineno">  490</span> </div>
<div class="line"><span class="lineno">  491</span>        <span class="keywordflow">return</span> self</div>
<div class="line"><span class="lineno">  492</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1233d7d0c70bf92d6a02113738fb1d84" name="a1233d7d0c70bf92d6a02113738fb1d84"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1233d7d0c70bf92d6a02113738fb1d84">&#9670;&#160;</a></span>_fit_lbfgs()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._fit_lbfgs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>deltas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>coef_grads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>intercept_grads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layer_units</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  495</span>    ):</div>
<div class="line"><span class="lineno">  496</span>        <span class="comment"># Store meta information for the parameters</span></div>
<div class="line"><span class="lineno">  497</span>        self._coef_indptr = []</div>
<div class="line"><span class="lineno">  498</span>        self._intercept_indptr = []</div>
<div class="line"><span class="lineno">  499</span>        start = 0</div>
<div class="line"><span class="lineno">  500</span> </div>
<div class="line"><span class="lineno">  501</span>        <span class="comment"># Save sizes and indices of coefficients for faster unpacking</span></div>
<div class="line"><span class="lineno">  502</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.n_layers_ - 1):</div>
<div class="line"><span class="lineno">  503</span>            n_fan_in, n_fan_out = layer_units[i], layer_units[i + 1]</div>
<div class="line"><span class="lineno">  504</span> </div>
<div class="line"><span class="lineno">  505</span>            end = start + (n_fan_in * n_fan_out)</div>
<div class="line"><span class="lineno">  506</span>            self._coef_indptr.append((start, end, (n_fan_in, n_fan_out)))</div>
<div class="line"><span class="lineno">  507</span>            start = end</div>
<div class="line"><span class="lineno">  508</span> </div>
<div class="line"><span class="lineno">  509</span>        <span class="comment"># Save sizes and indices of intercepts for faster unpacking</span></div>
<div class="line"><span class="lineno">  510</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.n_layers_ - 1):</div>
<div class="line"><span class="lineno">  511</span>            end = start + layer_units[i + 1]</div>
<div class="line"><span class="lineno">  512</span>            self._intercept_indptr.append((start, end))</div>
<div class="line"><span class="lineno">  513</span>            start = end</div>
<div class="line"><span class="lineno">  514</span> </div>
<div class="line"><span class="lineno">  515</span>        <span class="comment"># Run LBFGS</span></div>
<div class="line"><span class="lineno">  516</span>        packed_coef_inter = _pack(self.coefs_, self.intercepts_)</div>
<div class="line"><span class="lineno">  517</span> </div>
<div class="line"><span class="lineno">  518</span>        <span class="keywordflow">if</span> self.verbose <span class="keywordflow">is</span> <span class="keyword">True</span> <span class="keywordflow">or</span> self.verbose &gt;= 1:</div>
<div class="line"><span class="lineno">  519</span>            iprint = 1</div>
<div class="line"><span class="lineno">  520</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  521</span>            iprint = -1</div>
<div class="line"><span class="lineno">  522</span> </div>
<div class="line"><span class="lineno">  523</span>        opt_res = scipy.optimize.minimize(</div>
<div class="line"><span class="lineno">  524</span>            self._loss_grad_lbfgs,</div>
<div class="line"><span class="lineno">  525</span>            packed_coef_inter,</div>
<div class="line"><span class="lineno">  526</span>            method=<span class="stringliteral">&quot;L-BFGS-B&quot;</span>,</div>
<div class="line"><span class="lineno">  527</span>            jac=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  528</span>            options={</div>
<div class="line"><span class="lineno">  529</span>                <span class="stringliteral">&quot;maxfun&quot;</span>: self.max_fun,</div>
<div class="line"><span class="lineno">  530</span>                <span class="stringliteral">&quot;maxiter&quot;</span>: self.max_iter,</div>
<div class="line"><span class="lineno">  531</span>                <span class="stringliteral">&quot;iprint&quot;</span>: iprint,</div>
<div class="line"><span class="lineno">  532</span>                <span class="stringliteral">&quot;gtol&quot;</span>: self.tol,</div>
<div class="line"><span class="lineno">  533</span>            },</div>
<div class="line"><span class="lineno">  534</span>            args=(X, y, activations, deltas, coef_grads, intercept_grads),</div>
<div class="line"><span class="lineno">  535</span>        )</div>
<div class="line"><span class="lineno">  536</span>        self.n_iter_ = _check_optimize_result(<span class="stringliteral">&quot;lbfgs&quot;</span>, opt_res, self.max_iter)</div>
<div class="line"><span class="lineno">  537</span>        self.loss_ = opt_res.fun</div>
<div class="line"><span class="lineno">  538</span>        self._unpack(opt_res.x)</div>
<div class="line"><span class="lineno">  539</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7b8a08220068d3733566eff2982fd9e7" name="a7b8a08220068d3733566eff2982fd9e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b8a08220068d3733566eff2982fd9e7">&#9670;&#160;</a></span>_fit_stochastic()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._fit_stochastic </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>deltas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>coef_grads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>intercept_grads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layer_units</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>incremental</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  550</span>    ):</div>
<div class="line"><span class="lineno">  551</span> </div>
<div class="line"><span class="lineno">  552</span>        params = self.coefs_ + self.intercepts_</div>
<div class="line"><span class="lineno">  553</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> incremental <span class="keywordflow">or</span> <span class="keywordflow">not</span> hasattr(self, <span class="stringliteral">&quot;_optimizer&quot;</span>):</div>
<div class="line"><span class="lineno">  554</span>            <span class="keywordflow">if</span> self.solver == <span class="stringliteral">&quot;sgd&quot;</span>:</div>
<div class="line"><span class="lineno">  555</span>                self._optimizer = SGDOptimizer(</div>
<div class="line"><span class="lineno">  556</span>                    params,</div>
<div class="line"><span class="lineno">  557</span>                    self.learning_rate_init,</div>
<div class="line"><span class="lineno">  558</span>                    self.learning_rate,</div>
<div class="line"><span class="lineno">  559</span>                    self.momentum,</div>
<div class="line"><span class="lineno">  560</span>                    self.nesterovs_momentum,</div>
<div class="line"><span class="lineno">  561</span>                    self.power_t,</div>
<div class="line"><span class="lineno">  562</span>                )</div>
<div class="line"><span class="lineno">  563</span>            <span class="keywordflow">elif</span> self.solver == <span class="stringliteral">&quot;adam&quot;</span>:</div>
<div class="line"><span class="lineno">  564</span>                self._optimizer = AdamOptimizer(</div>
<div class="line"><span class="lineno">  565</span>                    params,</div>
<div class="line"><span class="lineno">  566</span>                    self.learning_rate_init,</div>
<div class="line"><span class="lineno">  567</span>                    self.beta_1,</div>
<div class="line"><span class="lineno">  568</span>                    self.beta_2,</div>
<div class="line"><span class="lineno">  569</span>                    self.epsilon,</div>
<div class="line"><span class="lineno">  570</span>                )</div>
<div class="line"><span class="lineno">  571</span> </div>
<div class="line"><span class="lineno">  572</span>        <span class="comment"># early_stopping in partial_fit doesn&#39;t make sense</span></div>
<div class="line"><span class="lineno">  573</span>        early_stopping = self.early_stopping <span class="keywordflow">and</span> <span class="keywordflow">not</span> incremental</div>
<div class="line"><span class="lineno">  574</span>        <span class="keywordflow">if</span> early_stopping:</div>
<div class="line"><span class="lineno">  575</span>            <span class="comment"># don&#39;t stratify in multilabel classification</span></div>
<div class="line"><span class="lineno">  576</span>            should_stratify = is_classifier(self) <span class="keywordflow">and</span> self.n_outputs_ == 1</div>
<div class="line"><span class="lineno">  577</span>            stratify = y <span class="keywordflow">if</span> should_stratify <span class="keywordflow">else</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  578</span>            X, X_val, y, y_val = train_test_split(</div>
<div class="line"><span class="lineno">  579</span>                X,</div>
<div class="line"><span class="lineno">  580</span>                y,</div>
<div class="line"><span class="lineno">  581</span>                random_state=self._random_state,</div>
<div class="line"><span class="lineno">  582</span>                test_size=self.validation_fraction,</div>
<div class="line"><span class="lineno">  583</span>                stratify=stratify,</div>
<div class="line"><span class="lineno">  584</span>            )</div>
<div class="line"><span class="lineno">  585</span>            <span class="keywordflow">if</span> is_classifier(self):</div>
<div class="line"><span class="lineno">  586</span>                y_val = self._label_binarizer.inverse_transform(y_val)</div>
<div class="line"><span class="lineno">  587</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  588</span>            X_val = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  589</span>            y_val = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  590</span> </div>
<div class="line"><span class="lineno">  591</span>        n_samples = X.shape[0]</div>
<div class="line"><span class="lineno">  592</span>        sample_idx = np.arange(n_samples, dtype=int)</div>
<div class="line"><span class="lineno">  593</span> </div>
<div class="line"><span class="lineno">  594</span>        <span class="keywordflow">if</span> self.batch_size == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  595</span>            batch_size = min(200, n_samples)</div>
<div class="line"><span class="lineno">  596</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  597</span>            <span class="keywordflow">if</span> self.batch_size &gt; n_samples:</div>
<div class="line"><span class="lineno">  598</span>                warnings.warn(</div>
<div class="line"><span class="lineno">  599</span>                    <span class="stringliteral">&quot;Got `batch_size` less than 1 or larger than &quot;</span></div>
<div class="line"><span class="lineno">  600</span>                    <span class="stringliteral">&quot;sample size. It is going to be clipped&quot;</span></div>
<div class="line"><span class="lineno">  601</span>                )</div>
<div class="line"><span class="lineno">  602</span>            batch_size = np.clip(self.batch_size, 1, n_samples)</div>
<div class="line"><span class="lineno">  603</span> </div>
<div class="line"><span class="lineno">  604</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  605</span>            <span class="keywordflow">for</span> it <span class="keywordflow">in</span> range(self.max_iter):</div>
<div class="line"><span class="lineno">  606</span>                <span class="keywordflow">if</span> self.shuffle:</div>
<div class="line"><span class="lineno">  607</span>                    <span class="comment"># Only shuffle the sample indices instead of X and y to</span></div>
<div class="line"><span class="lineno">  608</span>                    <span class="comment"># reduce the memory footprint. These indices will be used</span></div>
<div class="line"><span class="lineno">  609</span>                    <span class="comment"># to slice the X and y.</span></div>
<div class="line"><span class="lineno">  610</span>                    sample_idx = shuffle(sample_idx, random_state=self._random_state)</div>
<div class="line"><span class="lineno">  611</span> </div>
<div class="line"><span class="lineno">  612</span>                accumulated_loss = 0.0</div>
<div class="line"><span class="lineno">  613</span>                <span class="keywordflow">for</span> batch_slice <span class="keywordflow">in</span> gen_batches(n_samples, batch_size):</div>
<div class="line"><span class="lineno">  614</span>                    <span class="keywordflow">if</span> self.shuffle:</div>
<div class="line"><span class="lineno">  615</span>                        X_batch = _safe_indexing(X, sample_idx[batch_slice])</div>
<div class="line"><span class="lineno">  616</span>                        y_batch = y[sample_idx[batch_slice]]</div>
<div class="line"><span class="lineno">  617</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  618</span>                        X_batch = X[batch_slice]</div>
<div class="line"><span class="lineno">  619</span>                        y_batch = y[batch_slice]</div>
<div class="line"><span class="lineno">  620</span> </div>
<div class="line"><span class="lineno">  621</span>                    activations[0] = X_batch</div>
<div class="line"><span class="lineno">  622</span>                    batch_loss, coef_grads, intercept_grads = self._backprop(</div>
<div class="line"><span class="lineno">  623</span>                        X_batch,</div>
<div class="line"><span class="lineno">  624</span>                        y_batch,</div>
<div class="line"><span class="lineno">  625</span>                        activations,</div>
<div class="line"><span class="lineno">  626</span>                        deltas,</div>
<div class="line"><span class="lineno">  627</span>                        coef_grads,</div>
<div class="line"><span class="lineno">  628</span>                        intercept_grads,</div>
<div class="line"><span class="lineno">  629</span>                    )</div>
<div class="line"><span class="lineno">  630</span>                    accumulated_loss += batch_loss * (</div>
<div class="line"><span class="lineno">  631</span>                        batch_slice.stop - batch_slice.start</div>
<div class="line"><span class="lineno">  632</span>                    )</div>
<div class="line"><span class="lineno">  633</span> </div>
<div class="line"><span class="lineno">  634</span>                    <span class="comment"># update weights</span></div>
<div class="line"><span class="lineno">  635</span>                    grads = coef_grads + intercept_grads</div>
<div class="line"><span class="lineno">  636</span>                    self._optimizer.update_params(params, grads)</div>
<div class="line"><span class="lineno">  637</span> </div>
<div class="line"><span class="lineno">  638</span>                self.n_iter_ += 1</div>
<div class="line"><span class="lineno">  639</span>                self.loss_ = accumulated_loss / X.shape[0]</div>
<div class="line"><span class="lineno">  640</span> </div>
<div class="line"><span class="lineno">  641</span>                self.t_ += n_samples</div>
<div class="line"><span class="lineno">  642</span>                self.loss_curve_.append(self.loss_)</div>
<div class="line"><span class="lineno">  643</span>                <span class="keywordflow">if</span> self.verbose:</div>
<div class="line"><span class="lineno">  644</span>                    print(<span class="stringliteral">&quot;Iteration %d, loss = %.8f&quot;</span> % (self.n_iter_, self.loss_))</div>
<div class="line"><span class="lineno">  645</span> </div>
<div class="line"><span class="lineno">  646</span>                <span class="comment"># update no_improvement_count based on training loss or</span></div>
<div class="line"><span class="lineno">  647</span>                <span class="comment"># validation score according to early_stopping</span></div>
<div class="line"><span class="lineno">  648</span>                self._update_no_improvement_count(early_stopping, X_val, y_val)</div>
<div class="line"><span class="lineno">  649</span> </div>
<div class="line"><span class="lineno">  650</span>                <span class="comment"># for learning rate that needs to be updated at iteration end</span></div>
<div class="line"><span class="lineno">  651</span>                self._optimizer.iteration_ends(self.t_)</div>
<div class="line"><span class="lineno">  652</span> </div>
<div class="line"><span class="lineno">  653</span>                <span class="keywordflow">if</span> self._no_improvement_count &gt; self.n_iter_no_change:</div>
<div class="line"><span class="lineno">  654</span>                    <span class="comment"># not better than last `n_iter_no_change` iterations by tol</span></div>
<div class="line"><span class="lineno">  655</span>                    <span class="comment"># stop or decrease learning rate</span></div>
<div class="line"><span class="lineno">  656</span>                    <span class="keywordflow">if</span> early_stopping:</div>
<div class="line"><span class="lineno">  657</span>                        msg = (</div>
<div class="line"><span class="lineno">  658</span>                            <span class="stringliteral">&quot;Validation score did not improve more than &quot;</span></div>
<div class="line"><span class="lineno">  659</span>                            <span class="stringliteral">&quot;tol=%f for %d consecutive epochs.&quot;</span></div>
<div class="line"><span class="lineno">  660</span>                            % (self.tol, self.n_iter_no_change)</div>
<div class="line"><span class="lineno">  661</span>                        )</div>
<div class="line"><span class="lineno">  662</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  663</span>                        msg = (</div>
<div class="line"><span class="lineno">  664</span>                            <span class="stringliteral">&quot;Training loss did not improve more than tol=%f&quot;</span></div>
<div class="line"><span class="lineno">  665</span>                            <span class="stringliteral">&quot; for %d consecutive epochs.&quot;</span></div>
<div class="line"><span class="lineno">  666</span>                            % (self.tol, self.n_iter_no_change)</div>
<div class="line"><span class="lineno">  667</span>                        )</div>
<div class="line"><span class="lineno">  668</span> </div>
<div class="line"><span class="lineno">  669</span>                    is_stopping = self._optimizer.trigger_stopping(msg, self.verbose)</div>
<div class="line"><span class="lineno">  670</span>                    <span class="keywordflow">if</span> is_stopping:</div>
<div class="line"><span class="lineno">  671</span>                        <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  672</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  673</span>                        self._no_improvement_count = 0</div>
<div class="line"><span class="lineno">  674</span> </div>
<div class="line"><span class="lineno">  675</span>                <span class="keywordflow">if</span> incremental:</div>
<div class="line"><span class="lineno">  676</span>                    <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  677</span> </div>
<div class="line"><span class="lineno">  678</span>                <span class="keywordflow">if</span> self.n_iter_ == self.max_iter:</div>
<div class="line"><span class="lineno">  679</span>                    warnings.warn(</div>
<div class="line"><span class="lineno">  680</span>                        <span class="stringliteral">&quot;Stochastic Optimizer: Maximum iterations (%d) &quot;</span></div>
<div class="line"><span class="lineno">  681</span>                        <span class="stringliteral">&quot;reached and the optimization hasn&#39;t converged yet.&quot;</span></div>
<div class="line"><span class="lineno">  682</span>                        % self.max_iter,</div>
<div class="line"><span class="lineno">  683</span>                        ConvergenceWarning,</div>
<div class="line"><span class="lineno">  684</span>                    )</div>
<div class="line"><span class="lineno">  685</span>        <span class="keywordflow">except</span> KeyboardInterrupt:</div>
<div class="line"><span class="lineno">  686</span>            warnings.warn(<span class="stringliteral">&quot;Training interrupted by user.&quot;</span>)</div>
<div class="line"><span class="lineno">  687</span> </div>
<div class="line"><span class="lineno">  688</span>        <span class="keywordflow">if</span> early_stopping:</div>
<div class="line"><span class="lineno">  689</span>            <span class="comment"># restore best weights</span></div>
<div class="line"><span class="lineno">  690</span>            self.coefs_ = self._best_coefs</div>
<div class="line"><span class="lineno">  691</span>            self.intercepts_ = self._best_intercepts</div>
<div class="line"><span class="lineno">  692</span>            self.validation_scores_ = self.validation_scores_</div>
<div class="line"><span class="lineno">  693</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a446fb221b8ffb5dac45f7b0506729351" name="a446fb221b8ffb5dac45f7b0506729351"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a446fb221b8ffb5dac45f7b0506729351">&#9670;&#160;</a></span>_forward_pass()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._forward_pass </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activations</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Perform a forward pass on the network by computing the values
of the neurons in the hidden layers and the output layer.

Parameters
----------
activations : list, length = n_layers - 1
    The ith element of the list holds the values of the ith layer.
</pre> <div class="fragment"><div class="line"><span class="lineno">  156</span>    <span class="keyword">def </span>_forward_pass(self, activations):</div>
<div class="line"><span class="lineno">  157</span>        <span class="stringliteral">&quot;&quot;&quot;Perform a forward pass on the network by computing the values</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">        of the neurons in the hidden layers and the output layer.</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">        activations : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">            The ith element of the list holds the values of the ith layer.</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  165</span>        hidden_activation = ACTIVATIONS[self.activation]</div>
<div class="line"><span class="lineno">  166</span>        <span class="comment"># Iterate over the hidden layers</span></div>
<div class="line"><span class="lineno">  167</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.n_layers_ - 1):</div>
<div class="line"><span class="lineno">  168</span>            activations[i + 1] = safe_sparse_dot(activations[i], self.coefs_[i])</div>
<div class="line"><span class="lineno">  169</span>            activations[i + 1] += self.intercepts_[i]</div>
<div class="line"><span class="lineno">  170</span> </div>
<div class="line"><span class="lineno">  171</span>            <span class="comment"># For the hidden layers</span></div>
<div class="line"><span class="lineno">  172</span>            <span class="keywordflow">if</span> (i + 1) != (self.n_layers_ - 1):</div>
<div class="line"><span class="lineno">  173</span>                hidden_activation(activations[i + 1])</div>
<div class="line"><span class="lineno">  174</span> </div>
<div class="line"><span class="lineno">  175</span>        <span class="comment"># For the last layer</span></div>
<div class="line"><span class="lineno">  176</span>        output_activation = ACTIVATIONS[self.out_activation_]</div>
<div class="line"><span class="lineno">  177</span>        output_activation(activations[i + 1])</div>
<div class="line"><span class="lineno">  178</span> </div>
<div class="line"><span class="lineno">  179</span>        <span class="keywordflow">return</span> activations</div>
<div class="line"><span class="lineno">  180</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa6a44fba6cb57698d9d8a8c4a2867903" name="aa6a44fba6cb57698d9d8a8c4a2867903"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa6a44fba6cb57698d9d8a8c4a2867903">&#9670;&#160;</a></span>_forward_pass_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._forward_pass_fast </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Predict using the trained model

This is the same as _forward_pass but does not record the activations
of all layers and only returns the last layer's activation.

Parameters
----------
X : {array-like, sparse matrix} of shape (n_samples, n_features)
    The input data.

Returns
-------
y_pred : ndarray of shape (n_samples,) or (n_samples, n_outputs)
    The decision function of the samples for each class in the model.
</pre> <div class="fragment"><div class="line"><span class="lineno">  181</span>    <span class="keyword">def </span>_forward_pass_fast(self, X):</div>
<div class="line"><span class="lineno">  182</span>        <span class="stringliteral">&quot;&quot;&quot;Predict using the trained model</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral">        This is the same as _forward_pass but does not record the activations</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">        of all layers and only returns the last layer&#39;s activation.</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">        y_pred : ndarray of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">            The decision function of the samples for each class in the model.</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  197</span>        X = self._validate_data(X, accept_sparse=[<span class="stringliteral">&quot;csr&quot;</span>, <span class="stringliteral">&quot;csc&quot;</span>], reset=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  198</span> </div>
<div class="line"><span class="lineno">  199</span>        <span class="comment"># Initialize first layer</span></div>
<div class="line"><span class="lineno">  200</span>        activation = X</div>
<div class="line"><span class="lineno">  201</span> </div>
<div class="line"><span class="lineno">  202</span>        <span class="comment"># Forward propagate</span></div>
<div class="line"><span class="lineno">  203</span>        hidden_activation = ACTIVATIONS[self.activation]</div>
<div class="line"><span class="lineno">  204</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.n_layers_ - 1):</div>
<div class="line"><span class="lineno">  205</span>            activation = safe_sparse_dot(activation, self.coefs_[i])</div>
<div class="line"><span class="lineno">  206</span>            activation += self.intercepts_[i]</div>
<div class="line"><span class="lineno">  207</span>            <span class="keywordflow">if</span> i != self.n_layers_ - 2:</div>
<div class="line"><span class="lineno">  208</span>                hidden_activation(activation)</div>
<div class="line"><span class="lineno">  209</span>        output_activation = ACTIVATIONS[self.out_activation_]</div>
<div class="line"><span class="lineno">  210</span>        output_activation(activation)</div>
<div class="line"><span class="lineno">  211</span> </div>
<div class="line"><span class="lineno">  212</span>        <span class="keywordflow">return</span> activation</div>
<div class="line"><span class="lineno">  213</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7e03c7f5817e706517ad8ca12110c99f" name="a7e03c7f5817e706517ad8ca12110c99f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7e03c7f5817e706517ad8ca12110c99f">&#9670;&#160;</a></span>_init_coef()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._init_coef </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fan_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fan_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  400</span>    <span class="keyword">def </span>_init_coef(self, fan_in, fan_out, dtype):</div>
<div class="line"><span class="lineno">  401</span>        <span class="comment"># Use the initialization method recommended by</span></div>
<div class="line"><span class="lineno">  402</span>        <span class="comment"># Glorot et al.</span></div>
<div class="line"><span class="lineno">  403</span>        factor = 6.0</div>
<div class="line"><span class="lineno">  404</span>        <span class="keywordflow">if</span> self.activation == <span class="stringliteral">&quot;logistic&quot;</span>:</div>
<div class="line"><span class="lineno">  405</span>            factor = 2.0</div>
<div class="line"><span class="lineno">  406</span>        init_bound = np.sqrt(factor / (fan_in + fan_out))</div>
<div class="line"><span class="lineno">  407</span> </div>
<div class="line"><span class="lineno">  408</span>        <span class="comment"># Generate weights and bias:</span></div>
<div class="line"><span class="lineno">  409</span>        coef_init = self._random_state.uniform(</div>
<div class="line"><span class="lineno">  410</span>            -init_bound, init_bound, (fan_in, fan_out)</div>
<div class="line"><span class="lineno">  411</span>        )</div>
<div class="line"><span class="lineno">  412</span>        intercept_init = self._random_state.uniform(-init_bound, init_bound, fan_out)</div>
<div class="line"><span class="lineno">  413</span>        coef_init = coef_init.astype(dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  414</span>        intercept_init = intercept_init.astype(dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  415</span>        <span class="keywordflow">return</span> coef_init, intercept_init</div>
<div class="line"><span class="lineno">  416</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa8cd7dbf0b493aab5c0f7e053575be1e" name="aa8cd7dbf0b493aab5c0f7e053575be1e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa8cd7dbf0b493aab5c0f7e053575be1e">&#9670;&#160;</a></span>_initialize()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._initialize </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layer_units</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  357</span>    <span class="keyword">def </span>_initialize(self, y, layer_units, dtype):</div>
<div class="line"><span class="lineno">  358</span>        <span class="comment"># set all attributes, allocate weights etc for first call</span></div>
<div class="line"><span class="lineno">  359</span>        <span class="comment"># Initialize parameters</span></div>
<div class="line"><span class="lineno">  360</span>        self.n_iter_ = 0</div>
<div class="line"><span class="lineno">  361</span>        self.t_ = 0</div>
<div class="line"><span class="lineno">  362</span>        self.n_outputs_ = y.shape[1]</div>
<div class="line"><span class="lineno">  363</span> </div>
<div class="line"><span class="lineno">  364</span>        <span class="comment"># Compute the number of layers</span></div>
<div class="line"><span class="lineno">  365</span>        self.n_layers_ = len(layer_units)</div>
<div class="line"><span class="lineno">  366</span> </div>
<div class="line"><span class="lineno">  367</span>        <span class="comment"># Output for regression</span></div>
<div class="line"><span class="lineno">  368</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> is_classifier(self):</div>
<div class="line"><span class="lineno">  369</span>            self.out_activation_ = <span class="stringliteral">&quot;identity&quot;</span></div>
<div class="line"><span class="lineno">  370</span>        <span class="comment"># Output for multi class</span></div>
<div class="line"><span class="lineno">  371</span>        <span class="keywordflow">elif</span> self._label_binarizer.y_type_ == <span class="stringliteral">&quot;multiclass&quot;</span>:</div>
<div class="line"><span class="lineno">  372</span>            self.out_activation_ = <span class="stringliteral">&quot;softmax&quot;</span></div>
<div class="line"><span class="lineno">  373</span>        <span class="comment"># Output for binary class and multi-label</span></div>
<div class="line"><span class="lineno">  374</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  375</span>            self.out_activation_ = <span class="stringliteral">&quot;logistic&quot;</span></div>
<div class="line"><span class="lineno">  376</span> </div>
<div class="line"><span class="lineno">  377</span>        <span class="comment"># Initialize coefficient and intercept layers</span></div>
<div class="line"><span class="lineno">  378</span>        self.coefs_ = []</div>
<div class="line"><span class="lineno">  379</span>        self.intercepts_ = []</div>
<div class="line"><span class="lineno">  380</span> </div>
<div class="line"><span class="lineno">  381</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.n_layers_ - 1):</div>
<div class="line"><span class="lineno">  382</span>            coef_init, intercept_init = self._init_coef(</div>
<div class="line"><span class="lineno">  383</span>                layer_units[i], layer_units[i + 1], dtype</div>
<div class="line"><span class="lineno">  384</span>            )</div>
<div class="line"><span class="lineno">  385</span>            self.coefs_.append(coef_init)</div>
<div class="line"><span class="lineno">  386</span>            self.intercepts_.append(intercept_init)</div>
<div class="line"><span class="lineno">  387</span> </div>
<div class="line"><span class="lineno">  388</span>        <span class="keywordflow">if</span> self.solver <span class="keywordflow">in</span> _STOCHASTIC_SOLVERS:</div>
<div class="line"><span class="lineno">  389</span>            self.loss_curve_ = []</div>
<div class="line"><span class="lineno">  390</span>            self._no_improvement_count = 0</div>
<div class="line"><span class="lineno">  391</span>            <span class="keywordflow">if</span> self.early_stopping:</div>
<div class="line"><span class="lineno">  392</span>                self.validation_scores_ = []</div>
<div class="line"><span class="lineno">  393</span>                self.best_validation_score_ = -np.inf</div>
<div class="line"><span class="lineno">  394</span>                self.best_loss_ = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  395</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  396</span>                self.best_loss_ = np.inf</div>
<div class="line"><span class="lineno">  397</span>                self.validation_scores_ = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  398</span>                self.best_validation_score_ = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  399</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6ea066e5139d7be0b21167649581ec7a" name="a6ea066e5139d7be0b21167649581ec7a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ea066e5139d7be0b21167649581ec7a">&#9670;&#160;</a></span>_loss_grad_lbfgs()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._loss_grad_lbfgs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>packed_coef_inter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>deltas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>coef_grads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>intercept_grads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute the MLP loss function and its corresponding derivatives
with respect to the different parameters given in the initialization.

Returned gradients are packed in a single vector so it can be used
in lbfgs

Parameters
----------
packed_coef_inter : ndarray
    A vector comprising the flattened coefficients and intercepts.

X : {array-like, sparse matrix} of shape (n_samples, n_features)
    The input data.

y : ndarray of shape (n_samples,)
    The target values.

activations : list, length = n_layers - 1
    The ith element of the list holds the values of the ith layer.

deltas : list, length = n_layers - 1
    The ith element of the list holds the difference between the
    activations of the i + 1 layer and the backpropagated error.
    More specifically, deltas are gradients of loss with respect to z
    in each layer, where z = wx + b is the value of a particular layer
    before passing through the activation function

coef_grads : list, length = n_layers - 1
    The ith element contains the amount of change used to update the
    coefficient parameters of the ith layer in an iteration.

intercept_grads : list, length = n_layers - 1
    The ith element contains the amount of change used to update the
    intercept parameters of the ith layer in an iteration.

Returns
-------
loss : float
grad : array-like, shape (number of nodes of all layers,)
</pre> <div class="fragment"><div class="line"><span class="lineno">  230</span>    ):</div>
<div class="line"><span class="lineno">  231</span>        <span class="stringliteral">&quot;&quot;&quot;Compute the MLP loss function and its corresponding derivatives</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">        with respect to the different parameters given in the initialization.</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">        Returned gradients are packed in a single vector so it can be used</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">        in lbfgs</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        packed_coef_inter : ndarray</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">            A vector comprising the flattened coefficients and intercepts.</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">        y : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">            The target values.</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">        activations : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">            The ith element of the list holds the values of the ith layer.</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">        deltas : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">            The ith element of the list holds the difference between the</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">            activations of the i + 1 layer and the backpropagated error.</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">            More specifically, deltas are gradients of loss with respect to z</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">            in each layer, where z = wx + b is the value of a particular layer</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">            before passing through the activation function</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">        coef_grads : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">            The ith element contains the amount of change used to update the</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">            coefficient parameters of the ith layer in an iteration.</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">        intercept_grads : list, length = n_layers - 1</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">            The ith element contains the amount of change used to update the</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">            intercept parameters of the ith layer in an iteration.</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">        loss : float</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral">        grad : array-like, shape (number of nodes of all layers,)</span></div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  271</span>        self._unpack(packed_coef_inter)</div>
<div class="line"><span class="lineno">  272</span>        loss, coef_grads, intercept_grads = self._backprop(</div>
<div class="line"><span class="lineno">  273</span>            X, y, activations, deltas, coef_grads, intercept_grads</div>
<div class="line"><span class="lineno">  274</span>        )</div>
<div class="line"><span class="lineno">  275</span>        grad = _pack(coef_grads, intercept_grads)</div>
<div class="line"><span class="lineno">  276</span>        <span class="keywordflow">return</span> loss, grad</div>
<div class="line"><span class="lineno">  277</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab5407ee4ebf264a65951d66ac2dca857" name="ab5407ee4ebf264a65951d66ac2dca857"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab5407ee4ebf264a65951d66ac2dca857">&#9670;&#160;</a></span>_unpack()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._unpack </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>packed_parameters</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Extract the coefficients and intercepts from packed_parameters.</pre> <div class="fragment"><div class="line"><span class="lineno">  147</span>    <span class="keyword">def </span>_unpack(self, packed_parameters):</div>
<div class="line"><span class="lineno">  148</span>        <span class="stringliteral">&quot;&quot;&quot;Extract the coefficients and intercepts from packed_parameters.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  149</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.n_layers_ - 1):</div>
<div class="line"><span class="lineno">  150</span>            start, end, shape = self._coef_indptr[i]</div>
<div class="line"><span class="lineno">  151</span>            self.coefs_[i] = np.reshape(packed_parameters[start:end], shape)</div>
<div class="line"><span class="lineno">  152</span> </div>
<div class="line"><span class="lineno">  153</span>            start, end = self._intercept_indptr[i]</div>
<div class="line"><span class="lineno">  154</span>            self.intercepts_[i] = packed_parameters[start:end]</div>
<div class="line"><span class="lineno">  155</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3440369c98c29e0cb9495106b6156d84" name="a3440369c98c29e0cb9495106b6156d84"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3440369c98c29e0cb9495106b6156d84">&#9670;&#160;</a></span>_update_no_improvement_count()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._update_no_improvement_count </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>early_stopping</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_val</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_val</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  694</span>    <span class="keyword">def </span>_update_no_improvement_count(self, early_stopping, X_val, y_val):</div>
<div class="line"><span class="lineno">  695</span>        <span class="keywordflow">if</span> early_stopping:</div>
<div class="line"><span class="lineno">  696</span>            <span class="comment"># compute validation score, use that for stopping</span></div>
<div class="line"><span class="lineno">  697</span>            self.validation_scores_.append(self.score(X_val, y_val))</div>
<div class="line"><span class="lineno">  698</span> </div>
<div class="line"><span class="lineno">  699</span>            <span class="keywordflow">if</span> self.verbose:</div>
<div class="line"><span class="lineno">  700</span>                print(<span class="stringliteral">&quot;Validation score: %f&quot;</span> % self.validation_scores_[-1])</div>
<div class="line"><span class="lineno">  701</span>            <span class="comment"># update best parameters</span></div>
<div class="line"><span class="lineno">  702</span>            <span class="comment"># use validation_scores_, not loss_curve_</span></div>
<div class="line"><span class="lineno">  703</span>            <span class="comment"># let&#39;s hope no-one overloads .score with mse</span></div>
<div class="line"><span class="lineno">  704</span>            last_valid_score = self.validation_scores_[-1]</div>
<div class="line"><span class="lineno">  705</span> </div>
<div class="line"><span class="lineno">  706</span>            <span class="keywordflow">if</span> last_valid_score &lt; (self.best_validation_score_ + self.tol):</div>
<div class="line"><span class="lineno">  707</span>                self._no_improvement_count += 1</div>
<div class="line"><span class="lineno">  708</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  709</span>                self._no_improvement_count = 0</div>
<div class="line"><span class="lineno">  710</span> </div>
<div class="line"><span class="lineno">  711</span>            <span class="keywordflow">if</span> last_valid_score &gt; self.best_validation_score_:</div>
<div class="line"><span class="lineno">  712</span>                self.best_validation_score_ = last_valid_score</div>
<div class="line"><span class="lineno">  713</span>                self._best_coefs = [c.copy() <span class="keywordflow">for</span> c <span class="keywordflow">in</span> self.coefs_]</div>
<div class="line"><span class="lineno">  714</span>                self._best_intercepts = [i.copy() <span class="keywordflow">for</span> i <span class="keywordflow">in</span> self.intercepts_]</div>
<div class="line"><span class="lineno">  715</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  716</span>            <span class="keywordflow">if</span> self.loss_curve_[-1] &gt; self.best_loss_ - self.tol:</div>
<div class="line"><span class="lineno">  717</span>                self._no_improvement_count += 1</div>
<div class="line"><span class="lineno">  718</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  719</span>                self._no_improvement_count = 0</div>
<div class="line"><span class="lineno">  720</span>            <span class="keywordflow">if</span> self.loss_curve_[-1] &lt; self.best_loss_:</div>
<div class="line"><span class="lineno">  721</span>                self.best_loss_ = self.loss_curve_[-1]</div>
<div class="line"><span class="lineno">  722</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a40ff3842b506b0f6caec20e22eb4a9bb" name="a40ff3842b506b0f6caec20e22eb4a9bb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40ff3842b506b0f6caec20e22eb4a9bb">&#9670;&#160;</a></span>fit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.fit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Fit the model to data matrix X and target(s) y.

Parameters
----------
X : ndarray or sparse matrix of shape (n_samples, n_features)
    The input data.

y : ndarray of shape (n_samples,) or (n_samples, n_outputs)
    The target values (class labels in classification, real numbers in
    regression).

Returns
-------
self : object
    Returns a trained MLP model.
</pre> <div class="fragment"><div class="line"><span class="lineno">  723</span>    <span class="keyword">def </span>fit(self, X, y):</div>
<div class="line"><span class="lineno">  724</span>        <span class="stringliteral">&quot;&quot;&quot;Fit the model to data matrix X and target(s) y.</span></div>
<div class="line"><span class="lineno">  725</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  726</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  727</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  728</span><span class="stringliteral">        X : ndarray or sparse matrix of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  729</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><span class="lineno">  730</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  731</span><span class="stringliteral">        y : ndarray of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><span class="lineno">  732</span><span class="stringliteral">            The target values (class labels in classification, real numbers in</span></div>
<div class="line"><span class="lineno">  733</span><span class="stringliteral">            regression).</span></div>
<div class="line"><span class="lineno">  734</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  735</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  736</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  737</span><span class="stringliteral">        self : object</span></div>
<div class="line"><span class="lineno">  738</span><span class="stringliteral">            Returns a trained MLP model.</span></div>
<div class="line"><span class="lineno">  739</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  740</span>        self._validate_params()</div>
<div class="line"><span class="lineno">  741</span> </div>
<div class="line"><span class="lineno">  742</span>        <span class="keywordflow">return</span> self._fit(X, y, incremental=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  743</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a94a861f862371e1bd35aa87a3726dd03" name="a94a861f862371e1bd35aa87a3726dd03"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a94a861f862371e1bd35aa87a3726dd03">&#9670;&#160;</a></span>_best_coefs</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._best_coefs</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a6e5aa13446925e788dd76b612c567088" name="a6e5aa13446925e788dd76b612c567088"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6e5aa13446925e788dd76b612c567088">&#9670;&#160;</a></span>_best_intercepts</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._best_intercepts</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a4eaf0911d400b823eceba8ba8f676efc" name="a4eaf0911d400b823eceba8ba8f676efc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4eaf0911d400b823eceba8ba8f676efc">&#9670;&#160;</a></span>_coef_indptr</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._coef_indptr</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aace356676d3fdc48ae2d7a07786ddb2c" name="aace356676d3fdc48ae2d7a07786ddb2c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aace356676d3fdc48ae2d7a07786ddb2c">&#9670;&#160;</a></span>_intercept_indptr</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._intercept_indptr</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ad70c8d44857d1403a88f8536a679007c" name="ad70c8d44857d1403a88f8536a679007c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad70c8d44857d1403a88f8536a679007c">&#9670;&#160;</a></span>_loss_grad_lbfgs</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._loss_grad_lbfgs</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a5bd17016407c86648c4f1014a7ba6666" name="a5bd17016407c86648c4f1014a7ba6666"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5bd17016407c86648c4f1014a7ba6666">&#9670;&#160;</a></span>_no_improvement_count</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._no_improvement_count</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a9335dce7fccc3077842f4deccf52ac98" name="a9335dce7fccc3077842f4deccf52ac98"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9335dce7fccc3077842f4deccf52ac98">&#9670;&#160;</a></span>_optimizer</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._optimizer</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a6ec5070db5c8915a73cdf6369d0b8efa" name="a6ec5070db5c8915a73cdf6369d0b8efa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ec5070db5c8915a73cdf6369d0b8efa">&#9670;&#160;</a></span>_parameter_constraints</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">dict sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._parameter_constraints</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a215bc7c01b70f8525b1e8f1c0c035e4a" name="a215bc7c01b70f8525b1e8f1c0c035e4a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a215bc7c01b70f8525b1e8f1c0c035e4a">&#9670;&#160;</a></span>_random_state</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._random_state</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a4b0df81b8358d50d0743405c659ed6b6" name="a4b0df81b8358d50d0743405c659ed6b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4b0df81b8358d50d0743405c659ed6b6">&#9670;&#160;</a></span>activation</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.activation</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2b40afead813fd9060912fdc5c8c5585" name="a2b40afead813fd9060912fdc5c8c5585"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b40afead813fd9060912fdc5c8c5585">&#9670;&#160;</a></span>alpha</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.alpha</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a256cb593f7457b57e20e030cb4297b4e" name="a256cb593f7457b57e20e030cb4297b4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a256cb593f7457b57e20e030cb4297b4e">&#9670;&#160;</a></span>batch_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.batch_size</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af40bcadc6bac794f5ac49e146d787262" name="af40bcadc6bac794f5ac49e146d787262"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af40bcadc6bac794f5ac49e146d787262">&#9670;&#160;</a></span>best_loss_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.best_loss_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af9772e422910c066bd1214dc5e01f984" name="af9772e422910c066bd1214dc5e01f984"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af9772e422910c066bd1214dc5e01f984">&#9670;&#160;</a></span>best_validation_score_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.best_validation_score_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af338625696b13b08848be17ec42a3bcb" name="af338625696b13b08848be17ec42a3bcb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af338625696b13b08848be17ec42a3bcb">&#9670;&#160;</a></span>beta_1</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.beta_1</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4a0b9ab6cfff8afb6a02e09c65bfe064" name="a4a0b9ab6cfff8afb6a02e09c65bfe064"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a0b9ab6cfff8afb6a02e09c65bfe064">&#9670;&#160;</a></span>beta_2</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.beta_2</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae7a0f6e03d3ae3b265b7165e0a825ea1" name="ae7a0f6e03d3ae3b265b7165e0a825ea1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae7a0f6e03d3ae3b265b7165e0a825ea1">&#9670;&#160;</a></span>coefs_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.coefs_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa019948ee2d7ac810cea9942dd3d5187" name="aa019948ee2d7ac810cea9942dd3d5187"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa019948ee2d7ac810cea9942dd3d5187">&#9670;&#160;</a></span>early_stopping</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.early_stopping</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0c95ef33cbc4840aa36c1cee559e1c9b" name="a0c95ef33cbc4840aa36c1cee559e1c9b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c95ef33cbc4840aa36c1cee559e1c9b">&#9670;&#160;</a></span>epsilon</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.epsilon</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7053e621a032a08513a2453f2367bd74" name="a7053e621a032a08513a2453f2367bd74"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7053e621a032a08513a2453f2367bd74">&#9670;&#160;</a></span>hidden_layer_sizes</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.hidden_layer_sizes</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a942a95fba4263f47bcb5f1a7043e4167" name="a942a95fba4263f47bcb5f1a7043e4167"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a942a95fba4263f47bcb5f1a7043e4167">&#9670;&#160;</a></span>intercepts_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.intercepts_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0bd28615806017485087b01098172f8f" name="a0bd28615806017485087b01098172f8f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0bd28615806017485087b01098172f8f">&#9670;&#160;</a></span>learning_rate</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.learning_rate</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7bb6a222df4472c2f8219ba605f490c3" name="a7bb6a222df4472c2f8219ba605f490c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7bb6a222df4472c2f8219ba605f490c3">&#9670;&#160;</a></span>learning_rate_init</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.learning_rate_init</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a04baf032eed9f8a39c8d32dd0c27e066" name="a04baf032eed9f8a39c8d32dd0c27e066"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a04baf032eed9f8a39c8d32dd0c27e066">&#9670;&#160;</a></span>loss</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.loss</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a27576cf472db61b06d2951267d01df7a" name="a27576cf472db61b06d2951267d01df7a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a27576cf472db61b06d2951267d01df7a">&#9670;&#160;</a></span>loss_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.loss_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a848de96e596982a29e67ef603e761c63" name="a848de96e596982a29e67ef603e761c63"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a848de96e596982a29e67ef603e761c63">&#9670;&#160;</a></span>loss_curve_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.loss_curve_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad0fedbabf4cba29b7e6800c566ed759e" name="ad0fedbabf4cba29b7e6800c566ed759e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad0fedbabf4cba29b7e6800c566ed759e">&#9670;&#160;</a></span>max_fun</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.max_fun</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a318bdf742f2e44c92f36b7a0c0912a83" name="a318bdf742f2e44c92f36b7a0c0912a83"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a318bdf742f2e44c92f36b7a0c0912a83">&#9670;&#160;</a></span>max_iter</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.max_iter</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad05c99ca6c9254da855b5d3fd2728f34" name="ad05c99ca6c9254da855b5d3fd2728f34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad05c99ca6c9254da855b5d3fd2728f34">&#9670;&#160;</a></span>momentum</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.momentum</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac4db5d73babe4976fac6b50ac73dccec" name="ac4db5d73babe4976fac6b50ac73dccec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac4db5d73babe4976fac6b50ac73dccec">&#9670;&#160;</a></span>n_iter_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.n_iter_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0f052dea4e28c577fa309c8c104ea9f7" name="a0f052dea4e28c577fa309c8c104ea9f7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f052dea4e28c577fa309c8c104ea9f7">&#9670;&#160;</a></span>n_iter_no_change</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.n_iter_no_change</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5cda8eac7691d634a8687ec9b7c40ba3" name="a5cda8eac7691d634a8687ec9b7c40ba3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5cda8eac7691d634a8687ec9b7c40ba3">&#9670;&#160;</a></span>n_layers_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.n_layers_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac913f3e320e35d56add32462793c14e7" name="ac913f3e320e35d56add32462793c14e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac913f3e320e35d56add32462793c14e7">&#9670;&#160;</a></span>n_outputs_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.n_outputs_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa19a4c76b460a193cd87c03cc5e30280" name="aa19a4c76b460a193cd87c03cc5e30280"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa19a4c76b460a193cd87c03cc5e30280">&#9670;&#160;</a></span>nesterovs_momentum</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.nesterovs_momentum</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afff2a19fd7ef7908183a44f2d2f87485" name="afff2a19fd7ef7908183a44f2d2f87485"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afff2a19fd7ef7908183a44f2d2f87485">&#9670;&#160;</a></span>out_activation_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.out_activation_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adb94c71df194fdc6d51b67e8e5bc93bc" name="adb94c71df194fdc6d51b67e8e5bc93bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb94c71df194fdc6d51b67e8e5bc93bc">&#9670;&#160;</a></span>power_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.power_t</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5f9e6d09bc3196361c46192640196624" name="a5f9e6d09bc3196361c46192640196624"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f9e6d09bc3196361c46192640196624">&#9670;&#160;</a></span>random_state</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.random_state</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3dc00b9cd7811c0f2a93016e9c31557a" name="a3dc00b9cd7811c0f2a93016e9c31557a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3dc00b9cd7811c0f2a93016e9c31557a">&#9670;&#160;</a></span>shuffle</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.shuffle</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aff27bf94ddf05461ed9282969ee64be9" name="aff27bf94ddf05461ed9282969ee64be9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff27bf94ddf05461ed9282969ee64be9">&#9670;&#160;</a></span>solver</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.solver</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1cdc4a9b4f8c1d00572be3ba7400d728" name="a1cdc4a9b4f8c1d00572be3ba7400d728"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1cdc4a9b4f8c1d00572be3ba7400d728">&#9670;&#160;</a></span>t_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.t_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af3fc521b13aae045b9e10387f34b0ba1" name="af3fc521b13aae045b9e10387f34b0ba1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af3fc521b13aae045b9e10387f34b0ba1">&#9670;&#160;</a></span>tol</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.tol</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a85298d7736f4e7fe4b167fc8ff51aaa6" name="a85298d7736f4e7fe4b167fc8ff51aaa6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85298d7736f4e7fe4b167fc8ff51aaa6">&#9670;&#160;</a></span>validation_fraction</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.validation_fraction</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af524824394d7bacfc14b4f750df09bfa" name="af524824394d7bacfc14b4f750df09bfa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af524824394d7bacfc14b4f750df09bfa">&#9670;&#160;</a></span>validation_scores_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.validation_scores_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abb3113bc3c7d179d4a7e9443f2090036" name="abb3113bc3c7d179d4a7e9443f2090036"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb3113bc3c7d179d4a7e9443f2090036">&#9670;&#160;</a></span>verbose</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.verbose</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a96c5a6ce572a9cfe24350c3f1b737116" name="a96c5a6ce572a9cfe24350c3f1b737116"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96c5a6ce572a9cfe24350c3f1b737116">&#9670;&#160;</a></span>warm_start</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.warm_start</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/rafael/Documents/GitHub/PUC-GCES-PY/Tp-GCS-Rafael-Augusto/venv/lib/python3.9/site-packages/sklearn/neural_network/<a class="el" href="__multilayer__perceptron_8py.html">_multilayer_perceptron.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
