<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: gensim.models.ldaseqmodel.sslm Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacegensim.html">gensim</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models.html">models</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1ldaseqmodel.html">ldaseqmodel</a></li><li class="navelem"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html">sslm</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">gensim.models.ldaseqmodel.sslm Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for gensim.models.ldaseqmodel.sslm:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.png" usemap="#gensim.models.ldaseqmodel.sslm_map" alt=""/>
  <map id="gensim.models.ldaseqmodel.sslm_map" name="gensim.models.ldaseqmodel.sslm_map">
<area href="classgensim_1_1utils_1_1_save_load.html" alt="gensim.utils.SaveLoad" shape="rect" coords="0,56,195,80"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a2a94335e0c374164560479131f55f52b" id="r_a2a94335e0c374164560479131f55f52b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a2a94335e0c374164560479131f55f52b">__init__</a> (self, <a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#ae40d534e3ce1360cdc856766e15d60eb">vocab_len</a>=None, <a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a8b98b0fb94692a5b9a275b3247e448c3">num_time_slices</a>=None, <a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a6cdc23685ec6343812f11f4b7857f840">num_topics</a>=None, <a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#abb8405d942d998257189e895aa53a52d">obs_variance</a>=0.5, <a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a25a988aef7bc737b96daf1c32d6cdb62">chain_variance</a>=0.005)</td></tr>
<tr class="separator:a2a94335e0c374164560479131f55f52b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff27a78469f4a6d03b6a1a3611969c53" id="r_aff27a78469f4a6d03b6a1a3611969c53"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#aff27a78469f4a6d03b6a1a3611969c53">update_zeta</a> (self)</td></tr>
<tr class="separator:aff27a78469f4a6d03b6a1a3611969c53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97d0f5e57223b662ca2739db836ca1c1" id="r_a97d0f5e57223b662ca2739db836ca1c1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a97d0f5e57223b662ca2739db836ca1c1">compute_post_variance</a> (self, word, <a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a25a988aef7bc737b96daf1c32d6cdb62">chain_variance</a>)</td></tr>
<tr class="separator:a97d0f5e57223b662ca2739db836ca1c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79c716cfcd75c2d2925d9c28830f43f2" id="r_a79c716cfcd75c2d2925d9c28830f43f2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a79c716cfcd75c2d2925d9c28830f43f2">compute_post_mean</a> (self, word, <a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a25a988aef7bc737b96daf1c32d6cdb62">chain_variance</a>)</td></tr>
<tr class="separator:a79c716cfcd75c2d2925d9c28830f43f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7db1031c813820353226e33d1454d83" id="r_af7db1031c813820353226e33d1454d83"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#af7db1031c813820353226e33d1454d83">compute_expected_log_prob</a> (self)</td></tr>
<tr class="separator:af7db1031c813820353226e33d1454d83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeee1cf639283a7a9102bb1ce10e4faa6" id="r_aeee1cf639283a7a9102bb1ce10e4faa6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#aeee1cf639283a7a9102bb1ce10e4faa6">sslm_counts_init</a> (self, <a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#abb8405d942d998257189e895aa53a52d">obs_variance</a>, <a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a25a988aef7bc737b96daf1c32d6cdb62">chain_variance</a>, sstats)</td></tr>
<tr class="separator:aeee1cf639283a7a9102bb1ce10e4faa6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a728043b1ec19d61d8a6fbbcae40cad93" id="r_a728043b1ec19d61d8a6fbbcae40cad93"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a728043b1ec19d61d8a6fbbcae40cad93">fit_sslm</a> (self, sstats)</td></tr>
<tr class="separator:a728043b1ec19d61d8a6fbbcae40cad93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca66f644c2d2af713584752dd95776f4" id="r_aca66f644c2d2af713584752dd95776f4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#aca66f644c2d2af713584752dd95776f4">compute_bound</a> (self, sstats, totals)</td></tr>
<tr class="separator:aca66f644c2d2af713584752dd95776f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae464b9cbe0ced460ddb2ba75d5457648" id="r_ae464b9cbe0ced460ddb2ba75d5457648"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#ae464b9cbe0ced460ddb2ba75d5457648">update_obs</a> (self, sstats, totals)</td></tr>
<tr class="separator:ae464b9cbe0ced460ddb2ba75d5457648"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8be2133f75e7470798f666d892a94d2e" id="r_a8be2133f75e7470798f666d892a94d2e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a8be2133f75e7470798f666d892a94d2e">compute_mean_deriv</a> (self, word, time, deriv)</td></tr>
<tr class="separator:a8be2133f75e7470798f666d892a94d2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b0c53c68c4ad74693910c4175db65cd" id="r_a1b0c53c68c4ad74693910c4175db65cd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a1b0c53c68c4ad74693910c4175db65cd">compute_obs_deriv</a> (self, word, word_counts, totals, mean_deriv_mtx, deriv)</td></tr>
<tr class="separator:a1b0c53c68c4ad74693910c4175db65cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classgensim_1_1utils_1_1_save_load"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classgensim_1_1utils_1_1_save_load')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classgensim_1_1utils_1_1_save_load.html">gensim.utils.SaveLoad</a></td></tr>
<tr class="memitem:a70d054bfd9dfd1373fef9e0e691a24b5 inherit pub_methods_classgensim_1_1utils_1_1_save_load" id="r_a70d054bfd9dfd1373fef9e0e691a24b5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1utils_1_1_save_load.html#a70d054bfd9dfd1373fef9e0e691a24b5">load</a> (cls, fname, mmap=None)</td></tr>
<tr class="separator:a70d054bfd9dfd1373fef9e0e691a24b5 inherit pub_methods_classgensim_1_1utils_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0767537a6eb767dfe4fb8cf6d5fc221c inherit pub_methods_classgensim_1_1utils_1_1_save_load" id="r_a0767537a6eb767dfe4fb8cf6d5fc221c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1utils_1_1_save_load.html#a0767537a6eb767dfe4fb8cf6d5fc221c">save</a> (self, fname_or_handle, separately=None, sep_limit=10 *1024 **2, ignore=frozenset(), pickle_protocol=2)</td></tr>
<tr class="separator:a0767537a6eb767dfe4fb8cf6d5fc221c inherit pub_methods_classgensim_1_1utils_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:ae40d534e3ce1360cdc856766e15d60eb" id="r_ae40d534e3ce1360cdc856766e15d60eb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#ae40d534e3ce1360cdc856766e15d60eb">vocab_len</a></td></tr>
<tr class="separator:ae40d534e3ce1360cdc856766e15d60eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b98b0fb94692a5b9a275b3247e448c3" id="r_a8b98b0fb94692a5b9a275b3247e448c3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a8b98b0fb94692a5b9a275b3247e448c3">num_time_slices</a></td></tr>
<tr class="separator:a8b98b0fb94692a5b9a275b3247e448c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb8405d942d998257189e895aa53a52d" id="r_abb8405d942d998257189e895aa53a52d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#abb8405d942d998257189e895aa53a52d">obs_variance</a></td></tr>
<tr class="separator:abb8405d942d998257189e895aa53a52d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25a988aef7bc737b96daf1c32d6cdb62" id="r_a25a988aef7bc737b96daf1c32d6cdb62"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a25a988aef7bc737b96daf1c32d6cdb62">chain_variance</a></td></tr>
<tr class="separator:a25a988aef7bc737b96daf1c32d6cdb62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6cdc23685ec6343812f11f4b7857f840" id="r_a6cdc23685ec6343812f11f4b7857f840"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a6cdc23685ec6343812f11f4b7857f840">num_topics</a></td></tr>
<tr class="separator:a6cdc23685ec6343812f11f4b7857f840"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a407c417576af74e377f23e8fdf6f73" id="r_a8a407c417576af74e377f23e8fdf6f73"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a8a407c417576af74e377f23e8fdf6f73">obs</a></td></tr>
<tr class="separator:a8a407c417576af74e377f23e8fdf6f73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a52d286c0e81135540340253b10c5e485" id="r_a52d286c0e81135540340253b10c5e485"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a52d286c0e81135540340253b10c5e485">e_log_prob</a></td></tr>
<tr class="separator:a52d286c0e81135540340253b10c5e485"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63ae953aa6cc56b8f04d74643251fb29" id="r_a63ae953aa6cc56b8f04d74643251fb29"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a63ae953aa6cc56b8f04d74643251fb29">mean</a></td></tr>
<tr class="separator:a63ae953aa6cc56b8f04d74643251fb29"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a60a4ac49f90cf2dcb03e681849e8244c" id="r_a60a4ac49f90cf2dcb03e681849e8244c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a60a4ac49f90cf2dcb03e681849e8244c">fwd_mean</a></td></tr>
<tr class="separator:a60a4ac49f90cf2dcb03e681849e8244c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a559e12c929d69234792049299abb5042" id="r_a559e12c929d69234792049299abb5042"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a559e12c929d69234792049299abb5042">fwd_variance</a></td></tr>
<tr class="separator:a559e12c929d69234792049299abb5042"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4acb92b44d16a5419f076206fe18be1" id="r_ae4acb92b44d16a5419f076206fe18be1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#ae4acb92b44d16a5419f076206fe18be1">variance</a></td></tr>
<tr class="separator:ae4acb92b44d16a5419f076206fe18be1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad06da84e89718493de6dd39e93ea6d50" id="r_ad06da84e89718493de6dd39e93ea6d50"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#ad06da84e89718493de6dd39e93ea6d50">zeta</a></td></tr>
<tr class="separator:ad06da84e89718493de6dd39e93ea6d50"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18b604a8fd0ef693103e0ef98b63e567" id="r_a18b604a8fd0ef693103e0ef98b63e567"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a18b604a8fd0ef693103e0ef98b63e567">m_update_coeff</a></td></tr>
<tr class="separator:a18b604a8fd0ef693103e0ef98b63e567"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58d7a3274664b00193b2543a03ec14b6" id="r_a58d7a3274664b00193b2543a03ec14b6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a58d7a3274664b00193b2543a03ec14b6">mean_t</a></td></tr>
<tr class="separator:a58d7a3274664b00193b2543a03ec14b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f5796e0a9c753a07c4603c3a39184e6" id="r_a1f5796e0a9c753a07c4603c3a39184e6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a1f5796e0a9c753a07c4603c3a39184e6">variance_t</a></td></tr>
<tr class="separator:a1f5796e0a9c753a07c4603c3a39184e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b00983a499d0c686fcc8c4fbd615d7a" id="r_a1b00983a499d0c686fcc8c4fbd615d7a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a1b00983a499d0c686fcc8c4fbd615d7a">influence_sum_lgl</a></td></tr>
<tr class="separator:a1b00983a499d0c686fcc8c4fbd615d7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b13e9ccf86feef830ff197d1235aa94" id="r_a3b13e9ccf86feef830ff197d1235aa94"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a3b13e9ccf86feef830ff197d1235aa94">w_phi_l</a></td></tr>
<tr class="separator:a3b13e9ccf86feef830ff197d1235aa94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a893ce8803ac0ae4371b67e550c922cee" id="r_a893ce8803ac0ae4371b67e550c922cee"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a893ce8803ac0ae4371b67e550c922cee">w_phi_sum</a></td></tr>
<tr class="separator:a893ce8803ac0ae4371b67e550c922cee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03592d1e16d670eac963d68e009ed829" id="r_a03592d1e16d670eac963d68e009ed829"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a03592d1e16d670eac963d68e009ed829">w_phi_l_sq</a></td></tr>
<tr class="separator:a03592d1e16d670eac963d68e009ed829"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89c950f7b8c556191c0acad5228cbff6" id="r_a89c950f7b8c556191c0acad5228cbff6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a89c950f7b8c556191c0acad5228cbff6">m_update_coeff_g</a></td></tr>
<tr class="separator:a89c950f7b8c556191c0acad5228cbff6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d5b0e52bb8b95fa23dd3dbf94e79709" id="r_a2d5b0e52bb8b95fa23dd3dbf94e79709"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1ldaseqmodel_1_1sslm.html#a2d5b0e52bb8b95fa23dd3dbf94e79709">temp_vect</a></td></tr>
<tr class="separator:a2d5b0e52bb8b95fa23dd3dbf94e79709"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="inherited" name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pro_methods_classgensim_1_1utils_1_1_save_load"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classgensim_1_1utils_1_1_save_load')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classgensim_1_1utils_1_1_save_load.html">gensim.utils.SaveLoad</a></td></tr>
<tr class="memitem:ace7b79d8870c44c2bab0d590a5aca91e inherit pro_methods_classgensim_1_1utils_1_1_save_load" id="r_ace7b79d8870c44c2bab0d590a5aca91e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1utils_1_1_save_load.html#ace7b79d8870c44c2bab0d590a5aca91e">_load_specials</a> (self, fname, mmap, compress, subname)</td></tr>
<tr class="separator:ace7b79d8870c44c2bab0d590a5aca91e inherit pro_methods_classgensim_1_1utils_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd9faa42ba3aae8f0a175418889d425c inherit pro_methods_classgensim_1_1utils_1_1_save_load" id="r_acd9faa42ba3aae8f0a175418889d425c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1utils_1_1_save_load.html#acd9faa42ba3aae8f0a175418889d425c">_smart_save</a> (self, fname, separately=None, sep_limit=10 *1024 **2, ignore=frozenset(), pickle_protocol=2)</td></tr>
<tr class="separator:acd9faa42ba3aae8f0a175418889d425c inherit pro_methods_classgensim_1_1utils_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bae38a76fa8264d2c8759b9d40a6f5c inherit pro_methods_classgensim_1_1utils_1_1_save_load" id="r_a4bae38a76fa8264d2c8759b9d40a6f5c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1utils_1_1_save_load.html#a4bae38a76fa8264d2c8759b9d40a6f5c">_save_specials</a> (self, fname, separately, sep_limit, ignore, pickle_protocol, compress, subname)</td></tr>
<tr class="separator:a4bae38a76fa8264d2c8759b9d40a6f5c inherit pro_methods_classgensim_1_1utils_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_static_methods_classgensim_1_1utils_1_1_save_load"><td colspan="2" onclick="javascript:toggleInherit('pro_static_methods_classgensim_1_1utils_1_1_save_load')"><img src="closed.png" alt="-"/>&#160;Static Protected Member Functions inherited from <a class="el" href="classgensim_1_1utils_1_1_save_load.html">gensim.utils.SaveLoad</a></td></tr>
<tr class="memitem:a6cf051b348407267110444260535d143 inherit pro_static_methods_classgensim_1_1utils_1_1_save_load" id="r_a6cf051b348407267110444260535d143"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1utils_1_1_save_load.html#a6cf051b348407267110444260535d143">_adapt_by_suffix</a> (fname)</td></tr>
<tr class="separator:a6cf051b348407267110444260535d143 inherit pro_static_methods_classgensim_1_1utils_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Encapsulate the inner State Space Language Model for DTM.

Some important attributes of this class:

    * `obs` is a matrix containing the document to topic ratios.
    * `e_log_prob` is a matrix containing the topic to word ratios.
    * `mean` contains the mean values to be used for inference for each word for a time slice.
    * `variance` contains the variance values to be used for inference of word in a time slice.
    * `fwd_mean` and`fwd_variance` are the forward posterior values for the mean and the variance.
    * `zeta` is an extra variational parameter with a value for each time slice.</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a2a94335e0c374164560479131f55f52b" name="a2a94335e0c374164560479131f55f52b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2a94335e0c374164560479131f55f52b">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vocab_len</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_time_slices</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_topics</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>obs_variance</em> = <code>0.5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>chain_variance</em> = <code>0.005</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  700</span>    <span class="keyword">def </span>__init__(self, vocab_len=None, num_time_slices=None, num_topics=None, obs_variance=0.5, chain_variance=0.005):</div>
<div class="line"><span class="lineno">  701</span>        self.vocab_len = vocab_len</div>
<div class="line"><span class="lineno">  702</span>        self.num_time_slices = num_time_slices</div>
<div class="line"><span class="lineno">  703</span>        self.obs_variance = obs_variance</div>
<div class="line"><span class="lineno">  704</span>        self.chain_variance = chain_variance</div>
<div class="line"><span class="lineno">  705</span>        self.num_topics = num_topics</div>
<div class="line"><span class="lineno">  706</span> </div>
<div class="line"><span class="lineno">  707</span>        <span class="comment"># setting up matrices</span></div>
<div class="line"><span class="lineno">  708</span>        self.obs = np.zeros((vocab_len, num_time_slices))</div>
<div class="line"><span class="lineno">  709</span>        self.e_log_prob = np.zeros((vocab_len, num_time_slices))</div>
<div class="line"><span class="lineno">  710</span>        self.mean = np.zeros((vocab_len, num_time_slices + 1))</div>
<div class="line"><span class="lineno">  711</span>        self.fwd_mean = np.zeros((vocab_len, num_time_slices + 1))</div>
<div class="line"><span class="lineno">  712</span>        self.fwd_variance = np.zeros((vocab_len, num_time_slices + 1))</div>
<div class="line"><span class="lineno">  713</span>        self.variance = np.zeros((vocab_len, num_time_slices + 1))</div>
<div class="line"><span class="lineno">  714</span>        self.zeta = np.zeros(num_time_slices)</div>
<div class="line"><span class="lineno">  715</span> </div>
<div class="line"><span class="lineno">  716</span>        <span class="comment"># the following are class variables which are to be integrated during Document Influence Model</span></div>
<div class="line"><span class="lineno">  717</span>        self.m_update_coeff = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  718</span>        self.mean_t = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  719</span>        self.variance_t = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  720</span>        self.influence_sum_lgl = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  721</span>        self.w_phi_l = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  722</span>        self.w_phi_sum = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  723</span>        self.w_phi_l_sq = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  724</span>        self.m_update_coeff_g = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  725</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="aca66f644c2d2af713584752dd95776f4" name="aca66f644c2d2af713584752dd95776f4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca66f644c2d2af713584752dd95776f4">&#9670;&#160;</a></span>compute_bound()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.compute_bound </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sstats</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>totals</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the maximized lower bound achieved for the log probability of the true posterior.

Uses the formula presented in the appendix of the DTM paper (formula no. 5).

Parameters
----------
sstats : numpy.ndarray
    Sufficient statistics for a particular topic. Corresponds to matrix beta in the linked paper for the first
    time slice, expected shape (`self.vocab_len`, `num_topics`).
totals : list of int of length `len(self.time_slice)`
    The totals for each time slice.

Returns
-------
float
    The maximized lower bound.</pre> <div class="fragment"><div class="line"><span class="lineno">  976</span>    <span class="keyword">def </span>compute_bound(self, sstats, totals):</div>
<div class="line"><span class="lineno">  977</span>        <span class="stringliteral">&quot;&quot;&quot;Compute the maximized lower bound achieved for the log probability of the true posterior.</span></div>
<div class="line"><span class="lineno">  978</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  979</span><span class="stringliteral">        Uses the formula presented in the appendix of the DTM paper (formula no. 5).</span></div>
<div class="line"><span class="lineno">  980</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  981</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  982</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  983</span><span class="stringliteral">        sstats : numpy.ndarray</span></div>
<div class="line"><span class="lineno">  984</span><span class="stringliteral">            Sufficient statistics for a particular topic. Corresponds to matrix beta in the linked paper for the first</span></div>
<div class="line"><span class="lineno">  985</span><span class="stringliteral">            time slice, expected shape (`self.vocab_len`, `num_topics`).</span></div>
<div class="line"><span class="lineno">  986</span><span class="stringliteral">        totals : list of int of length `len(self.time_slice)`</span></div>
<div class="line"><span class="lineno">  987</span><span class="stringliteral">            The totals for each time slice.</span></div>
<div class="line"><span class="lineno">  988</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  989</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  990</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  991</span><span class="stringliteral">        float</span></div>
<div class="line"><span class="lineno">  992</span><span class="stringliteral">            The maximized lower bound.</span></div>
<div class="line"><span class="lineno">  993</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  994</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  995</span>        w = self.vocab_len</div>
<div class="line"><span class="lineno">  996</span>        t = self.num_time_slices</div>
<div class="line"><span class="lineno">  997</span> </div>
<div class="line"><span class="lineno">  998</span>        term_1 = 0</div>
<div class="line"><span class="lineno">  999</span>        term_2 = 0</div>
<div class="line"><span class="lineno"> 1000</span>        term_3 = 0</div>
<div class="line"><span class="lineno"> 1001</span> </div>
<div class="line"><span class="lineno"> 1002</span>        val = 0</div>
<div class="line"><span class="lineno"> 1003</span>        ent = 0</div>
<div class="line"><span class="lineno"> 1004</span> </div>
<div class="line"><span class="lineno"> 1005</span>        chain_variance = self.chain_variance</div>
<div class="line"><span class="lineno"> 1006</span>        <span class="comment"># computing mean, fwd_mean</span></div>
<div class="line"><span class="lineno"> 1007</span>        self.mean, self.fwd_mean = \</div>
<div class="line"><span class="lineno"> 1008</span>            (np.array(x) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> zip(*(self.compute_post_mean(w, self.chain_variance) <span class="keywordflow">for</span> w <span class="keywordflow">in</span> range(w))))</div>
<div class="line"><span class="lineno"> 1009</span>        self.zeta = self.update_zeta()</div>
<div class="line"><span class="lineno"> 1010</span> </div>
<div class="line"><span class="lineno"> 1011</span>        val = sum(self.variance[w][0] - self.variance[w][t] <span class="keywordflow">for</span> w <span class="keywordflow">in</span> range(w)) / 2 * chain_variance</div>
<div class="line"><span class="lineno"> 1012</span> </div>
<div class="line"><span class="lineno"> 1013</span>        logger.info(<span class="stringliteral">&quot;Computing bound, all times&quot;</span>)</div>
<div class="line"><span class="lineno"> 1014</span> </div>
<div class="line"><span class="lineno"> 1015</span>        <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(1, t + 1):</div>
<div class="line"><span class="lineno"> 1016</span>            term_1 = 0.0</div>
<div class="line"><span class="lineno"> 1017</span>            term_2 = 0.0</div>
<div class="line"><span class="lineno"> 1018</span>            ent = 0.0</div>
<div class="line"><span class="lineno"> 1019</span>            <span class="keywordflow">for</span> w <span class="keywordflow">in</span> range(w):</div>
<div class="line"><span class="lineno"> 1020</span> </div>
<div class="line"><span class="lineno"> 1021</span>                m = self.mean[w][t]</div>
<div class="line"><span class="lineno"> 1022</span>                prev_m = self.mean[w][t - 1]</div>
<div class="line"><span class="lineno"> 1023</span> </div>
<div class="line"><span class="lineno"> 1024</span>                v = self.variance[w][t]</div>
<div class="line"><span class="lineno"> 1025</span> </div>
<div class="line"><span class="lineno"> 1026</span>                <span class="comment"># w_phi_l is only used in Document Influence Model; the values are always zero in this case</span></div>
<div class="line"><span class="lineno"> 1027</span>                <span class="comment"># w_phi_l = sslm.w_phi_l[w][t - 1]</span></div>
<div class="line"><span class="lineno"> 1028</span>                <span class="comment"># exp_i = np.exp(-prev_m)</span></div>
<div class="line"><span class="lineno"> 1029</span>                <span class="comment"># term_1 += (np.power(m - prev_m - (w_phi_l * exp_i), 2) / (2 * chain_variance)) -</span></div>
<div class="line"><span class="lineno"> 1030</span>                <span class="comment"># (v / chain_variance) - np.log(chain_variance)</span></div>
<div class="line"><span class="lineno"> 1031</span> </div>
<div class="line"><span class="lineno"> 1032</span>                term_1 += \</div>
<div class="line"><span class="lineno"> 1033</span>                    (np.power(m - prev_m, 2) / (2 * chain_variance)) - (v / chain_variance) - np.log(chain_variance)</div>
<div class="line"><span class="lineno"> 1034</span>                term_2 += sstats[w][t - 1] * m</div>
<div class="line"><span class="lineno"> 1035</span>                ent += np.log(v) / 2  <span class="comment"># note the 2pi&#39;s cancel with term1 (see doc)</span></div>
<div class="line"><span class="lineno"> 1036</span> </div>
<div class="line"><span class="lineno"> 1037</span>            term_3 = -totals[t - 1] * np.log(self.zeta[t - 1])</div>
<div class="line"><span class="lineno"> 1038</span>            val += term_2 + term_3 + ent - term_1</div>
<div class="line"><span class="lineno"> 1039</span> </div>
<div class="line"><span class="lineno"> 1040</span>        <span class="keywordflow">return</span> val</div>
<div class="line"><span class="lineno"> 1041</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af7db1031c813820353226e33d1454d83" name="af7db1031c813820353226e33d1454d83"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af7db1031c813820353226e33d1454d83">&#9670;&#160;</a></span>compute_expected_log_prob()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.compute_expected_log_prob </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the expected log probability given values of m.

The appendix describes the Expectation of log-probabilities in equation 5 of the DTM paper;
The below implementation is the result of solving the equation and is implemented as in the original
Blei DTM code.

Returns
-------
numpy.ndarray of float
    The expected value for the log probabilities for each word and time slice.</pre> <div class="fragment"><div class="line"><span class="lineno">  860</span>    <span class="keyword">def </span>compute_expected_log_prob(self):</div>
<div class="line"><span class="lineno">  861</span>        <span class="stringliteral">&quot;&quot;&quot;Compute the expected log probability given values of m.</span></div>
<div class="line"><span class="lineno">  862</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  863</span><span class="stringliteral">        The appendix describes the Expectation of log-probabilities in equation 5 of the DTM paper;</span></div>
<div class="line"><span class="lineno">  864</span><span class="stringliteral">        The below implementation is the result of solving the equation and is implemented as in the original</span></div>
<div class="line"><span class="lineno">  865</span><span class="stringliteral">        Blei DTM code.</span></div>
<div class="line"><span class="lineno">  866</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  867</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  868</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  869</span><span class="stringliteral">        numpy.ndarray of float</span></div>
<div class="line"><span class="lineno">  870</span><span class="stringliteral">            The expected value for the log probabilities for each word and time slice.</span></div>
<div class="line"><span class="lineno">  871</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  872</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  873</span>        <span class="keywordflow">for</span> (w, t), val <span class="keywordflow">in</span> np.ndenumerate(self.e_log_prob):</div>
<div class="line"><span class="lineno">  874</span>            self.e_log_prob[w][t] = self.mean[w][t + 1] - np.log(self.zeta[t])</div>
<div class="line"><span class="lineno">  875</span>        <span class="keywordflow">return</span> self.e_log_prob</div>
<div class="line"><span class="lineno">  876</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8be2133f75e7470798f666d892a94d2e" name="a8be2133f75e7470798f666d892a94d2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8be2133f75e7470798f666d892a94d2e">&#9670;&#160;</a></span>compute_mean_deriv()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.compute_mean_deriv </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>time</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>deriv</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Helper functions for optimizing a function.

Compute the derivative of:

.. :math::

    E[\beta_{t,w}]/d obs_{s,w} for t = 1:T.

Parameters
----------
word : int
    The word's ID.
time : int
    The time slice.
deriv : list of float
    Derivative for each time slice.

Returns
-------
list of float
    Mean derivative for each time slice.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1118</span>    <span class="keyword">def </span>compute_mean_deriv(self, word, time, deriv):</div>
<div class="line"><span class="lineno"> 1119</span>        <span class="stringliteral">&quot;&quot;&quot;Helper functions for optimizing a function.</span></div>
<div class="line"><span class="lineno"> 1120</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1121</span><span class="stringliteral">        Compute the derivative of:</span></div>
<div class="line"><span class="lineno"> 1122</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1123</span><span class="stringliteral">        .. :math::</span></div>
<div class="line"><span class="lineno"> 1124</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1125</span><span class="stringliteral">            E[\beta_{t,w}]/d obs_{s,w} for t = 1:T.</span></div>
<div class="line"><span class="lineno"> 1126</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1127</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno"> 1128</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno"> 1129</span><span class="stringliteral">        word : int</span></div>
<div class="line"><span class="lineno"> 1130</span><span class="stringliteral">            The word&#39;s ID.</span></div>
<div class="line"><span class="lineno"> 1131</span><span class="stringliteral">        time : int</span></div>
<div class="line"><span class="lineno"> 1132</span><span class="stringliteral">            The time slice.</span></div>
<div class="line"><span class="lineno"> 1133</span><span class="stringliteral">        deriv : list of float</span></div>
<div class="line"><span class="lineno"> 1134</span><span class="stringliteral">            Derivative for each time slice.</span></div>
<div class="line"><span class="lineno"> 1135</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1136</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno"> 1137</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno"> 1138</span><span class="stringliteral">        list of float</span></div>
<div class="line"><span class="lineno"> 1139</span><span class="stringliteral">            Mean derivative for each time slice.</span></div>
<div class="line"><span class="lineno"> 1140</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1141</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1142</span> </div>
<div class="line"><span class="lineno"> 1143</span>        T = self.num_time_slices</div>
<div class="line"><span class="lineno"> 1144</span>        fwd_variance = self.variance[word]</div>
<div class="line"><span class="lineno"> 1145</span> </div>
<div class="line"><span class="lineno"> 1146</span>        deriv[0] = 0</div>
<div class="line"><span class="lineno"> 1147</span> </div>
<div class="line"><span class="lineno"> 1148</span>        <span class="comment"># forward pass</span></div>
<div class="line"><span class="lineno"> 1149</span>        <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(1, T + 1):</div>
<div class="line"><span class="lineno"> 1150</span>            <span class="keywordflow">if</span> self.obs_variance &gt; 0.0:</div>
<div class="line"><span class="lineno"> 1151</span>                w = self.obs_variance / (fwd_variance[t - 1] + self.chain_variance + self.obs_variance)</div>
<div class="line"><span class="lineno"> 1152</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1153</span>                w = 0.0</div>
<div class="line"><span class="lineno"> 1154</span>            val = w * deriv[t - 1]</div>
<div class="line"><span class="lineno"> 1155</span>            <span class="keywordflow">if</span> time == t - 1:</div>
<div class="line"><span class="lineno"> 1156</span>                val += (1 - w)</div>
<div class="line"><span class="lineno"> 1157</span>            deriv[t] = val</div>
<div class="line"><span class="lineno"> 1158</span> </div>
<div class="line"><span class="lineno"> 1159</span>        <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(T - 1, -1, -1):</div>
<div class="line"><span class="lineno"> 1160</span>            <span class="keywordflow">if</span> self.chain_variance == 0.0:</div>
<div class="line"><span class="lineno"> 1161</span>                w = 0.0</div>
<div class="line"><span class="lineno"> 1162</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1163</span>                w = self.chain_variance / (fwd_variance[t] + self.chain_variance)</div>
<div class="line"><span class="lineno"> 1164</span>            deriv[t] = w * deriv[t] + (1 - w) * deriv[t + 1]</div>
<div class="line"><span class="lineno"> 1165</span> </div>
<div class="line"><span class="lineno"> 1166</span>        <span class="keywordflow">return</span> deriv</div>
<div class="line"><span class="lineno"> 1167</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1b0c53c68c4ad74693910c4175db65cd" name="a1b0c53c68c4ad74693910c4175db65cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1b0c53c68c4ad74693910c4175db65cd">&#9670;&#160;</a></span>compute_obs_deriv()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.compute_obs_deriv </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_counts</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>totals</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mean_deriv_mtx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>deriv</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Derivation of obs which is used in derivative function `df_obs` while optimizing.

Parameters
----------
word : int
    The word's ID.
word_counts : list of int
    Total word counts for each time slice.
totals : list of int of length `len(self.time_slice)`
    The totals for each time slice.
mean_deriv_mtx : list of float
    Mean derivative for each time slice.
deriv : list of float
    Mean derivative for each time slice.

Returns
-------
list of float
    Mean derivative for each time slice.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1168</span>    <span class="keyword">def </span>compute_obs_deriv(self, word, word_counts, totals, mean_deriv_mtx, deriv):</div>
<div class="line"><span class="lineno"> 1169</span>        <span class="stringliteral">&quot;&quot;&quot;Derivation of obs which is used in derivative function `df_obs` while optimizing.</span></div>
<div class="line"><span class="lineno"> 1170</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1171</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno"> 1172</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno"> 1173</span><span class="stringliteral">        word : int</span></div>
<div class="line"><span class="lineno"> 1174</span><span class="stringliteral">            The word&#39;s ID.</span></div>
<div class="line"><span class="lineno"> 1175</span><span class="stringliteral">        word_counts : list of int</span></div>
<div class="line"><span class="lineno"> 1176</span><span class="stringliteral">            Total word counts for each time slice.</span></div>
<div class="line"><span class="lineno"> 1177</span><span class="stringliteral">        totals : list of int of length `len(self.time_slice)`</span></div>
<div class="line"><span class="lineno"> 1178</span><span class="stringliteral">            The totals for each time slice.</span></div>
<div class="line"><span class="lineno"> 1179</span><span class="stringliteral">        mean_deriv_mtx : list of float</span></div>
<div class="line"><span class="lineno"> 1180</span><span class="stringliteral">            Mean derivative for each time slice.</span></div>
<div class="line"><span class="lineno"> 1181</span><span class="stringliteral">        deriv : list of float</span></div>
<div class="line"><span class="lineno"> 1182</span><span class="stringliteral">            Mean derivative for each time slice.</span></div>
<div class="line"><span class="lineno"> 1183</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1184</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno"> 1185</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno"> 1186</span><span class="stringliteral">        list of float</span></div>
<div class="line"><span class="lineno"> 1187</span><span class="stringliteral">            Mean derivative for each time slice.</span></div>
<div class="line"><span class="lineno"> 1188</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1189</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1190</span> </div>
<div class="line"><span class="lineno"> 1191</span>        <span class="comment"># flag</span></div>
<div class="line"><span class="lineno"> 1192</span>        init_mult = 1000</div>
<div class="line"><span class="lineno"> 1193</span> </div>
<div class="line"><span class="lineno"> 1194</span>        T = self.num_time_slices</div>
<div class="line"><span class="lineno"> 1195</span> </div>
<div class="line"><span class="lineno"> 1196</span>        mean = self.mean[word]</div>
<div class="line"><span class="lineno"> 1197</span>        variance = self.variance[word]</div>
<div class="line"><span class="lineno"> 1198</span> </div>
<div class="line"><span class="lineno"> 1199</span>        <span class="comment"># only used for DIM mode</span></div>
<div class="line"><span class="lineno"> 1200</span>        <span class="comment"># w_phi_l = self.w_phi_l[word]</span></div>
<div class="line"><span class="lineno"> 1201</span>        <span class="comment"># m_update_coeff = self.m_update_coeff[word]</span></div>
<div class="line"><span class="lineno"> 1202</span> </div>
<div class="line"><span class="lineno"> 1203</span>        <span class="comment"># temp_vector holds temporary zeta values</span></div>
<div class="line"><span class="lineno"> 1204</span>        self.temp_vect = np.zeros(T)</div>
<div class="line"><span class="lineno"> 1205</span> </div>
<div class="line"><span class="lineno"> 1206</span>        <span class="keywordflow">for</span> u <span class="keywordflow">in</span> range(T):</div>
<div class="line"><span class="lineno"> 1207</span>            self.temp_vect[u] = np.exp(mean[u + 1] + variance[u + 1] / 2)</div>
<div class="line"><span class="lineno"> 1208</span> </div>
<div class="line"><span class="lineno"> 1209</span>        <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(T):</div>
<div class="line"><span class="lineno"> 1210</span>            mean_deriv = mean_deriv_mtx[t]</div>
<div class="line"><span class="lineno"> 1211</span>            term1 = 0</div>
<div class="line"><span class="lineno"> 1212</span>            term2 = 0</div>
<div class="line"><span class="lineno"> 1213</span>            term3 = 0</div>
<div class="line"><span class="lineno"> 1214</span>            term4 = 0</div>
<div class="line"><span class="lineno"> 1215</span> </div>
<div class="line"><span class="lineno"> 1216</span>            <span class="keywordflow">for</span> u <span class="keywordflow">in</span> range(1, T + 1):</div>
<div class="line"><span class="lineno"> 1217</span>                mean_u = mean[u]</div>
<div class="line"><span class="lineno"> 1218</span>                mean_u_prev = mean[u - 1]</div>
<div class="line"><span class="lineno"> 1219</span>                dmean_u = mean_deriv[u]</div>
<div class="line"><span class="lineno"> 1220</span>                dmean_u_prev = mean_deriv[u - 1]</div>
<div class="line"><span class="lineno"> 1221</span> </div>
<div class="line"><span class="lineno"> 1222</span>                term1 += (mean_u - mean_u_prev) * (dmean_u - dmean_u_prev)</div>
<div class="line"><span class="lineno"> 1223</span>                term2 += (word_counts[u - 1] - (totals[u - 1] * self.temp_vect[u - 1] / self.zeta[u - 1])) * dmean_u</div>
<div class="line"><span class="lineno"> 1224</span> </div>
<div class="line"><span class="lineno"> 1225</span>                model = <span class="stringliteral">&quot;DTM&quot;</span></div>
<div class="line"><span class="lineno"> 1226</span>                <span class="keywordflow">if</span> model == <span class="stringliteral">&quot;DIM&quot;</span>:</div>
<div class="line"><span class="lineno"> 1227</span>                    <span class="comment"># do some stuff</span></div>
<div class="line"><span class="lineno"> 1228</span>                    <span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno"> 1229</span> </div>
<div class="line"><span class="lineno"> 1230</span>            <span class="keywordflow">if</span> self.chain_variance:</div>
<div class="line"><span class="lineno"> 1231</span>                term1 = - (term1 / self.chain_variance)</div>
<div class="line"><span class="lineno"> 1232</span>                term1 = term1 - (mean[0] * mean_deriv[0]) / (init_mult * self.chain_variance)</div>
<div class="line"><span class="lineno"> 1233</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1234</span>                term1 = 0.0</div>
<div class="line"><span class="lineno"> 1235</span> </div>
<div class="line"><span class="lineno"> 1236</span>            deriv[t] = term1 + term2 + term3 + term4</div>
<div class="line"><span class="lineno"> 1237</span> </div>
<div class="line"><span class="lineno"> 1238</span>        <span class="keywordflow">return</span> deriv</div>
<div class="line"><span class="lineno"> 1239</span> </div>
<div class="line"><span class="lineno"> 1240</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a79c716cfcd75c2d2925d9c28830f43f2" name="a79c716cfcd75c2d2925d9c28830f43f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a79c716cfcd75c2d2925d9c28830f43f2">&#9670;&#160;</a></span>compute_post_mean()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.compute_post_mean </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>chain_variance</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get the mean, based on the `Variational Kalman Filtering approach for Approximate Inference (section 3.1)
&lt;https://mimno.infosci.cornell.edu/info6150/readings/dynamic_topic_models.pdf&gt;`_.

Notes
-----
This function essentially computes E[\beta_{t,w}] for t = 1:T.

.. :math::

    Fwd_Mean(t) ≡  E(beta_{t,w} | beta_ˆ 1:t )
    = (obs_variance / fwd_variance[t - 1] + chain_variance + obs_variance ) * fwd_mean[t - 1] +
    (1 - (obs_variance / fwd_variance[t - 1] + chain_variance + obs_variance)) * beta

.. :math::

    Mean(t) ≡ E(beta_{t,w} | beta_ˆ 1:T )
    = fwd_mean[t - 1] + (obs_variance / fwd_variance[t - 1] + obs_variance) +
    (1 - obs_variance / fwd_variance[t - 1] + obs_variance)) * mean[t]

Parameters
----------
word: int
    The word's ID.
chain_variance : float
    Gaussian parameter defined in the beta distribution to dictate how the beta values evolve over time.

Returns
-------
(numpy.ndarray, numpy.ndarray)
    The first returned value is the mean of each word in each time slice, the second value is the
    inferred posterior mean for the same pairs.</pre> <div class="fragment"><div class="line"><span class="lineno">  804</span>    <span class="keyword">def </span>compute_post_mean(self, word, chain_variance):</div>
<div class="line"><span class="lineno">  805</span>        <span class="stringliteral">&quot;&quot;&quot;Get the mean, based on the `Variational Kalman Filtering approach for Approximate Inference (section 3.1)</span></div>
<div class="line"><span class="lineno">  806</span><span class="stringliteral">        &lt;https://mimno.infosci.cornell.edu/info6150/readings/dynamic_topic_models.pdf&gt;`_.</span></div>
<div class="line"><span class="lineno">  807</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  808</span><span class="stringliteral">        Notes</span></div>
<div class="line"><span class="lineno">  809</span><span class="stringliteral">        -----</span></div>
<div class="line"><span class="lineno">  810</span><span class="stringliteral">        This function essentially computes E[\beta_{t,w}] for t = 1:T.</span></div>
<div class="line"><span class="lineno">  811</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  812</span><span class="stringliteral">        .. :math::</span></div>
<div class="line"><span class="lineno">  813</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  814</span><span class="stringliteral">            Fwd_Mean(t) ≡  E(beta_{t,w} | beta_ˆ 1:t )</span></div>
<div class="line"><span class="lineno">  815</span><span class="stringliteral">            = (obs_variance / fwd_variance[t - 1] + chain_variance + obs_variance ) * fwd_mean[t - 1] +</span></div>
<div class="line"><span class="lineno">  816</span><span class="stringliteral">            (1 - (obs_variance / fwd_variance[t - 1] + chain_variance + obs_variance)) * beta</span></div>
<div class="line"><span class="lineno">  817</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  818</span><span class="stringliteral">        .. :math::</span></div>
<div class="line"><span class="lineno">  819</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  820</span><span class="stringliteral">            Mean(t) ≡ E(beta_{t,w} | beta_ˆ 1:T )</span></div>
<div class="line"><span class="lineno">  821</span><span class="stringliteral">            = fwd_mean[t - 1] + (obs_variance / fwd_variance[t - 1] + obs_variance) +</span></div>
<div class="line"><span class="lineno">  822</span><span class="stringliteral">            (1 - obs_variance / fwd_variance[t - 1] + obs_variance)) * mean[t]</span></div>
<div class="line"><span class="lineno">  823</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  824</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  825</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  826</span><span class="stringliteral">        word: int</span></div>
<div class="line"><span class="lineno">  827</span><span class="stringliteral">            The word&#39;s ID.</span></div>
<div class="line"><span class="lineno">  828</span><span class="stringliteral">        chain_variance : float</span></div>
<div class="line"><span class="lineno">  829</span><span class="stringliteral">            Gaussian parameter defined in the beta distribution to dictate how the beta values evolve over time.</span></div>
<div class="line"><span class="lineno">  830</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  831</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  832</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  833</span><span class="stringliteral">        (numpy.ndarray, numpy.ndarray)</span></div>
<div class="line"><span class="lineno">  834</span><span class="stringliteral">            The first returned value is the mean of each word in each time slice, the second value is the</span></div>
<div class="line"><span class="lineno">  835</span><span class="stringliteral">            inferred posterior mean for the same pairs.</span></div>
<div class="line"><span class="lineno">  836</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  837</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  838</span>        T = self.num_time_slices</div>
<div class="line"><span class="lineno">  839</span>        obs = self.obs[word]</div>
<div class="line"><span class="lineno">  840</span>        fwd_variance = self.fwd_variance[word]</div>
<div class="line"><span class="lineno">  841</span>        mean = self.mean[word]</div>
<div class="line"><span class="lineno">  842</span>        fwd_mean = self.fwd_mean[word]</div>
<div class="line"><span class="lineno">  843</span> </div>
<div class="line"><span class="lineno">  844</span>        <span class="comment"># forward</span></div>
<div class="line"><span class="lineno">  845</span>        fwd_mean[0] = 0</div>
<div class="line"><span class="lineno">  846</span>        <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(1, T + 1):</div>
<div class="line"><span class="lineno">  847</span>            c = self.obs_variance / (fwd_variance[t - 1] + chain_variance + self.obs_variance)</div>
<div class="line"><span class="lineno">  848</span>            fwd_mean[t] = c * fwd_mean[t - 1] + (1 - c) * obs[t - 1]</div>
<div class="line"><span class="lineno">  849</span> </div>
<div class="line"><span class="lineno">  850</span>        <span class="comment"># backward pass</span></div>
<div class="line"><span class="lineno">  851</span>        mean[T] = fwd_mean[T]</div>
<div class="line"><span class="lineno">  852</span>        <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(T - 1, -1, -1):</div>
<div class="line"><span class="lineno">  853</span>            <span class="keywordflow">if</span> chain_variance == 0.0:</div>
<div class="line"><span class="lineno">  854</span>                c = 0.0</div>
<div class="line"><span class="lineno">  855</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  856</span>                c = chain_variance / (fwd_variance[t] + chain_variance)</div>
<div class="line"><span class="lineno">  857</span>            mean[t] = c * fwd_mean[t] + (1 - c) * mean[t + 1]</div>
<div class="line"><span class="lineno">  858</span>        <span class="keywordflow">return</span> mean, fwd_mean</div>
<div class="line"><span class="lineno">  859</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a97d0f5e57223b662ca2739db836ca1c1" name="a97d0f5e57223b662ca2739db836ca1c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a97d0f5e57223b662ca2739db836ca1c1">&#9670;&#160;</a></span>compute_post_variance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.compute_post_variance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>chain_variance</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get the variance, based on the `Variational Kalman Filtering approach for Approximate Inference (section 3.1)
&lt;https://mimno.infosci.cornell.edu/info6150/readings/dynamic_topic_models.pdf&gt;`_.

This function accepts the word to compute variance for, along with the associated sslm class object,
and returns the `variance` and the posterior approximation `fwd_variance`.

Notes
-----
This function essentially computes Var[\beta_{t,w}] for t = 1:T

.. :math::

    fwd\_variance[t] \equiv E((beta_{t,w}-mean_{t,w})^2 |beta_{t}\ for\ 1:t) =
    (obs\_variance / fwd\_variance[t - 1] + chain\_variance + obs\_variance ) *
    (fwd\_variance[t - 1] + obs\_variance)

.. :math::

    variance[t] \equiv E((beta_{t,w}-mean\_cap_{t,w})^2 |beta\_cap_{t}\ for\ 1:t) =
    fwd\_variance[t - 1] + (fwd\_variance[t - 1] / fwd\_variance[t - 1] + obs\_variance)^2 *
    (variance[t - 1] - (fwd\_variance[t-1] + obs\_variance))

Parameters
----------
word: int
    The word's ID.
chain_variance : float
    Gaussian parameter defined in the beta distribution to dictate how the beta values evolve over time.

Returns
-------
(numpy.ndarray, numpy.ndarray)
    The first returned value is the variance of each word in each time slice, the second value is the
    inferred posterior variance for the same pairs.</pre> <div class="fragment"><div class="line"><span class="lineno">  742</span>    <span class="keyword">def </span>compute_post_variance(self, word, chain_variance):</div>
<div class="line"><span class="lineno">  743</span>        <span class="stringliteral">r&quot;&quot;&quot;Get the variance, based on the `Variational Kalman Filtering approach for Approximate Inference (section 3.1)</span></div>
<div class="line"><span class="lineno">  744</span><span class="stringliteral">        &lt;https://mimno.infosci.cornell.edu/info6150/readings/dynamic_topic_models.pdf&gt;`_.</span></div>
<div class="line"><span class="lineno">  745</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  746</span><span class="stringliteral">        This function accepts the word to compute variance for, along with the associated sslm class object,</span></div>
<div class="line"><span class="lineno">  747</span><span class="stringliteral">        and returns the `variance` and the posterior approximation `fwd_variance`.</span></div>
<div class="line"><span class="lineno">  748</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  749</span><span class="stringliteral">        Notes</span></div>
<div class="line"><span class="lineno">  750</span><span class="stringliteral">        -----</span></div>
<div class="line"><span class="lineno">  751</span><span class="stringliteral">        This function essentially computes Var[\beta_{t,w}] for t = 1:T</span></div>
<div class="line"><span class="lineno">  752</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  753</span><span class="stringliteral">        .. :math::</span></div>
<div class="line"><span class="lineno">  754</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  755</span><span class="stringliteral">            fwd\_variance[t] \equiv E((beta_{t,w}-mean_{t,w})^2 |beta_{t}\ for\ 1:t) =</span></div>
<div class="line"><span class="lineno">  756</span><span class="stringliteral">            (obs\_variance / fwd\_variance[t - 1] + chain\_variance + obs\_variance ) *</span></div>
<div class="line"><span class="lineno">  757</span><span class="stringliteral">            (fwd\_variance[t - 1] + obs\_variance)</span></div>
<div class="line"><span class="lineno">  758</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  759</span><span class="stringliteral">        .. :math::</span></div>
<div class="line"><span class="lineno">  760</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  761</span><span class="stringliteral">            variance[t] \equiv E((beta_{t,w}-mean\_cap_{t,w})^2 |beta\_cap_{t}\ for\ 1:t) =</span></div>
<div class="line"><span class="lineno">  762</span><span class="stringliteral">            fwd\_variance[t - 1] + (fwd\_variance[t - 1] / fwd\_variance[t - 1] + obs\_variance)^2 *</span></div>
<div class="line"><span class="lineno">  763</span><span class="stringliteral">            (variance[t - 1] - (fwd\_variance[t-1] + obs\_variance))</span></div>
<div class="line"><span class="lineno">  764</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  765</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  766</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  767</span><span class="stringliteral">        word: int</span></div>
<div class="line"><span class="lineno">  768</span><span class="stringliteral">            The word&#39;s ID.</span></div>
<div class="line"><span class="lineno">  769</span><span class="stringliteral">        chain_variance : float</span></div>
<div class="line"><span class="lineno">  770</span><span class="stringliteral">            Gaussian parameter defined in the beta distribution to dictate how the beta values evolve over time.</span></div>
<div class="line"><span class="lineno">  771</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  772</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  773</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  774</span><span class="stringliteral">        (numpy.ndarray, numpy.ndarray)</span></div>
<div class="line"><span class="lineno">  775</span><span class="stringliteral">            The first returned value is the variance of each word in each time slice, the second value is the</span></div>
<div class="line"><span class="lineno">  776</span><span class="stringliteral">            inferred posterior variance for the same pairs.</span></div>
<div class="line"><span class="lineno">  777</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  778</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  779</span>        INIT_VARIANCE_CONST = 1000</div>
<div class="line"><span class="lineno">  780</span> </div>
<div class="line"><span class="lineno">  781</span>        T = self.num_time_slices</div>
<div class="line"><span class="lineno">  782</span>        variance = self.variance[word]</div>
<div class="line"><span class="lineno">  783</span>        fwd_variance = self.fwd_variance[word]</div>
<div class="line"><span class="lineno">  784</span>        <span class="comment"># forward pass. Set initial variance very high</span></div>
<div class="line"><span class="lineno">  785</span>        fwd_variance[0] = chain_variance * INIT_VARIANCE_CONST</div>
<div class="line"><span class="lineno">  786</span>        <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(1, T + 1):</div>
<div class="line"><span class="lineno">  787</span>            <span class="keywordflow">if</span> self.obs_variance:</div>
<div class="line"><span class="lineno">  788</span>                c = self.obs_variance / (fwd_variance[t - 1] + chain_variance + self.obs_variance)</div>
<div class="line"><span class="lineno">  789</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  790</span>                c = 0</div>
<div class="line"><span class="lineno">  791</span>            fwd_variance[t] = c * (fwd_variance[t - 1] + chain_variance)</div>
<div class="line"><span class="lineno">  792</span> </div>
<div class="line"><span class="lineno">  793</span>        <span class="comment"># backward pass</span></div>
<div class="line"><span class="lineno">  794</span>        variance[T] = fwd_variance[T]</div>
<div class="line"><span class="lineno">  795</span>        <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(T - 1, -1, -1):</div>
<div class="line"><span class="lineno">  796</span>            <span class="keywordflow">if</span> fwd_variance[t] &gt; 0.0:</div>
<div class="line"><span class="lineno">  797</span>                c = np.power((fwd_variance[t] / (fwd_variance[t] + chain_variance)), 2)</div>
<div class="line"><span class="lineno">  798</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  799</span>                c = 0</div>
<div class="line"><span class="lineno">  800</span>            variance[t] = (c * (variance[t + 1] - chain_variance)) + ((1 - c) * fwd_variance[t])</div>
<div class="line"><span class="lineno">  801</span> </div>
<div class="line"><span class="lineno">  802</span>        <span class="keywordflow">return</span> variance, fwd_variance</div>
<div class="line"><span class="lineno">  803</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a728043b1ec19d61d8a6fbbcae40cad93" name="a728043b1ec19d61d8a6fbbcae40cad93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a728043b1ec19d61d8a6fbbcae40cad93">&#9670;&#160;</a></span>fit_sslm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.fit_sslm </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sstats</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Fits variational distribution.

This is essentially the m-step.
Maximizes the approximation of the true posterior for a particular topic using the provided sufficient
statistics. Updates the values using :meth:`~gensim.models.ldaseqmodel.sslm.update_obs` and
:meth:`~gensim.models.ldaseqmodel.sslm.compute_expected_log_prob`.

Parameters
----------
sstats : numpy.ndarray
    Sufficient statistics for a particular topic. Corresponds to matrix beta in the linked paper for the
    current time slice, expected shape (`self.vocab_len`, `num_topics`).

Returns
-------
float
    The lower bound for the true posterior achieved using the fitted approximate distribution.</pre> <div class="fragment"><div class="line"><span class="lineno">  917</span>    <span class="keyword">def </span>fit_sslm(self, sstats):</div>
<div class="line"><span class="lineno">  918</span>        <span class="stringliteral">&quot;&quot;&quot;Fits variational distribution.</span></div>
<div class="line"><span class="lineno">  919</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  920</span><span class="stringliteral">        This is essentially the m-step.</span></div>
<div class="line"><span class="lineno">  921</span><span class="stringliteral">        Maximizes the approximation of the true posterior for a particular topic using the provided sufficient</span></div>
<div class="line"><span class="lineno">  922</span><span class="stringliteral">        statistics. Updates the values using :meth:`~gensim.models.ldaseqmodel.sslm.update_obs` and</span></div>
<div class="line"><span class="lineno">  923</span><span class="stringliteral">        :meth:`~gensim.models.ldaseqmodel.sslm.compute_expected_log_prob`.</span></div>
<div class="line"><span class="lineno">  924</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  925</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  926</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  927</span><span class="stringliteral">        sstats : numpy.ndarray</span></div>
<div class="line"><span class="lineno">  928</span><span class="stringliteral">            Sufficient statistics for a particular topic. Corresponds to matrix beta in the linked paper for the</span></div>
<div class="line"><span class="lineno">  929</span><span class="stringliteral">            current time slice, expected shape (`self.vocab_len`, `num_topics`).</span></div>
<div class="line"><span class="lineno">  930</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  931</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  932</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  933</span><span class="stringliteral">        float</span></div>
<div class="line"><span class="lineno">  934</span><span class="stringliteral">            The lower bound for the true posterior achieved using the fitted approximate distribution.</span></div>
<div class="line"><span class="lineno">  935</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  936</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  937</span>        W = self.vocab_len</div>
<div class="line"><span class="lineno">  938</span>        bound = 0</div>
<div class="line"><span class="lineno">  939</span>        old_bound = 0</div>
<div class="line"><span class="lineno">  940</span>        sslm_fit_threshold = 1e-6</div>
<div class="line"><span class="lineno">  941</span>        sslm_max_iter = 2</div>
<div class="line"><span class="lineno">  942</span>        converged = sslm_fit_threshold + 1</div>
<div class="line"><span class="lineno">  943</span> </div>
<div class="line"><span class="lineno">  944</span>        <span class="comment"># computing variance, fwd_variance</span></div>
<div class="line"><span class="lineno">  945</span>        self.variance, self.fwd_variance = \</div>
<div class="line"><span class="lineno">  946</span>            (np.array(x) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> zip(*(self.compute_post_variance(w, self.chain_variance) <span class="keywordflow">for</span> w <span class="keywordflow">in</span> range(W))))</div>
<div class="line"><span class="lineno">  947</span> </div>
<div class="line"><span class="lineno">  948</span>        <span class="comment"># column sum of sstats</span></div>
<div class="line"><span class="lineno">  949</span>        totals = sstats.sum(axis=0)</div>
<div class="line"><span class="lineno">  950</span>        iter_ = 0</div>
<div class="line"><span class="lineno">  951</span> </div>
<div class="line"><span class="lineno">  952</span>        model = <span class="stringliteral">&quot;DTM&quot;</span></div>
<div class="line"><span class="lineno">  953</span>        <span class="keywordflow">if</span> model == <span class="stringliteral">&quot;DTM&quot;</span>:</div>
<div class="line"><span class="lineno">  954</span>            bound = self.compute_bound(sstats, totals)</div>
<div class="line"><span class="lineno">  955</span>        <span class="keywordflow">if</span> model == <span class="stringliteral">&quot;DIM&quot;</span>:</div>
<div class="line"><span class="lineno">  956</span>            bound = self.compute_bound_fixed(sstats, totals)</div>
<div class="line"><span class="lineno">  957</span> </div>
<div class="line"><span class="lineno">  958</span>        logger.info(<span class="stringliteral">&quot;initial sslm bound is %f&quot;</span>, bound)</div>
<div class="line"><span class="lineno">  959</span> </div>
<div class="line"><span class="lineno">  960</span>        <span class="keywordflow">while</span> converged &gt; sslm_fit_threshold <span class="keywordflow">and</span> iter_ &lt; sslm_max_iter:</div>
<div class="line"><span class="lineno">  961</span>            iter_ += 1</div>
<div class="line"><span class="lineno">  962</span>            old_bound = bound</div>
<div class="line"><span class="lineno">  963</span>            self.obs, self.zeta = self.update_obs(sstats, totals)</div>
<div class="line"><span class="lineno">  964</span> </div>
<div class="line"><span class="lineno">  965</span>            <span class="keywordflow">if</span> model == <span class="stringliteral">&quot;DTM&quot;</span>:</div>
<div class="line"><span class="lineno">  966</span>                bound = self.compute_bound(sstats, totals)</div>
<div class="line"><span class="lineno">  967</span>            <span class="keywordflow">if</span> model == <span class="stringliteral">&quot;DIM&quot;</span>:</div>
<div class="line"><span class="lineno">  968</span>                bound = self.compute_bound_fixed(sstats, totals)</div>
<div class="line"><span class="lineno">  969</span> </div>
<div class="line"><span class="lineno">  970</span>            converged = np.fabs((bound - old_bound) / old_bound)</div>
<div class="line"><span class="lineno">  971</span>            logger.info(<span class="stringliteral">&quot;iteration %i iteration lda seq bound is %f convergence is %f&quot;</span>, iter_, bound, converged)</div>
<div class="line"><span class="lineno">  972</span> </div>
<div class="line"><span class="lineno">  973</span>        self.e_log_prob = self.compute_expected_log_prob()</div>
<div class="line"><span class="lineno">  974</span>        <span class="keywordflow">return</span> bound</div>
<div class="line"><span class="lineno">  975</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aeee1cf639283a7a9102bb1ce10e4faa6" name="aeee1cf639283a7a9102bb1ce10e4faa6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeee1cf639283a7a9102bb1ce10e4faa6">&#9670;&#160;</a></span>sslm_counts_init()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.sslm_counts_init </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>obs_variance</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>chain_variance</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sstats</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Initialize the State Space Language Model with LDA sufficient statistics.

Called for each topic-chain and initializes initial mean, variance and Topic-Word probabilities
for the first time-slice.

Parameters
----------
obs_variance : float, optional
    Observed variance used to approximate the true and forward variance.
chain_variance : float
    Gaussian parameter defined in the beta distribution to dictate how the beta values evolve over time.
sstats : numpy.ndarray
    Sufficient statistics of the LDA model. Corresponds to matrix beta in the linked paper for time slice 0,
    expected shape (`self.vocab_len`, `num_topics`).</pre> <div class="fragment"><div class="line"><span class="lineno">  877</span>    <span class="keyword">def </span>sslm_counts_init(self, obs_variance, chain_variance, sstats):</div>
<div class="line"><span class="lineno">  878</span>        <span class="stringliteral">&quot;&quot;&quot;Initialize the State Space Language Model with LDA sufficient statistics.</span></div>
<div class="line"><span class="lineno">  879</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  880</span><span class="stringliteral">        Called for each topic-chain and initializes initial mean, variance and Topic-Word probabilities</span></div>
<div class="line"><span class="lineno">  881</span><span class="stringliteral">        for the first time-slice.</span></div>
<div class="line"><span class="lineno">  882</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  883</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  884</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  885</span><span class="stringliteral">        obs_variance : float, optional</span></div>
<div class="line"><span class="lineno">  886</span><span class="stringliteral">            Observed variance used to approximate the true and forward variance.</span></div>
<div class="line"><span class="lineno">  887</span><span class="stringliteral">        chain_variance : float</span></div>
<div class="line"><span class="lineno">  888</span><span class="stringliteral">            Gaussian parameter defined in the beta distribution to dictate how the beta values evolve over time.</span></div>
<div class="line"><span class="lineno">  889</span><span class="stringliteral">        sstats : numpy.ndarray</span></div>
<div class="line"><span class="lineno">  890</span><span class="stringliteral">            Sufficient statistics of the LDA model. Corresponds to matrix beta in the linked paper for time slice 0,</span></div>
<div class="line"><span class="lineno">  891</span><span class="stringliteral">            expected shape (`self.vocab_len`, `num_topics`).</span></div>
<div class="line"><span class="lineno">  892</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  893</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  894</span>        W = self.vocab_len</div>
<div class="line"><span class="lineno">  895</span>        T = self.num_time_slices</div>
<div class="line"><span class="lineno">  896</span> </div>
<div class="line"><span class="lineno">  897</span>        log_norm_counts = np.copy(sstats)</div>
<div class="line"><span class="lineno">  898</span>        log_norm_counts /= sum(log_norm_counts)</div>
<div class="line"><span class="lineno">  899</span>        log_norm_counts += 1.0 / W</div>
<div class="line"><span class="lineno">  900</span>        log_norm_counts /= sum(log_norm_counts)</div>
<div class="line"><span class="lineno">  901</span>        log_norm_counts = np.log(log_norm_counts)</div>
<div class="line"><span class="lineno">  902</span> </div>
<div class="line"><span class="lineno">  903</span>        <span class="comment"># setting variational observations to transformed counts</span></div>
<div class="line"><span class="lineno">  904</span>        self.obs = (np.repeat(log_norm_counts, T, axis=0)).reshape(W, T)</div>
<div class="line"><span class="lineno">  905</span>        <span class="comment"># set variational parameters</span></div>
<div class="line"><span class="lineno">  906</span>        self.obs_variance = obs_variance</div>
<div class="line"><span class="lineno">  907</span>        self.chain_variance = chain_variance</div>
<div class="line"><span class="lineno">  908</span> </div>
<div class="line"><span class="lineno">  909</span>        <span class="comment"># compute post variance, mean</span></div>
<div class="line"><span class="lineno">  910</span>        <span class="keywordflow">for</span> w <span class="keywordflow">in</span> range(W):</div>
<div class="line"><span class="lineno">  911</span>            self.variance[w], self.fwd_variance[w] = self.compute_post_variance(w, self.chain_variance)</div>
<div class="line"><span class="lineno">  912</span>            self.mean[w], self.fwd_mean[w] = self.compute_post_mean(w, self.chain_variance)</div>
<div class="line"><span class="lineno">  913</span> </div>
<div class="line"><span class="lineno">  914</span>        self.zeta = self.update_zeta()</div>
<div class="line"><span class="lineno">  915</span>        self.e_log_prob = self.compute_expected_log_prob()</div>
<div class="line"><span class="lineno">  916</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae464b9cbe0ced460ddb2ba75d5457648" name="ae464b9cbe0ced460ddb2ba75d5457648"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae464b9cbe0ced460ddb2ba75d5457648">&#9670;&#160;</a></span>update_obs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.update_obs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sstats</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>totals</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Optimize the bound with respect to the observed variables.

TODO:
This is by far the slowest function in the whole algorithm.
Replacing or improving the performance of this would greatly speed things up.

Parameters
----------
sstats : numpy.ndarray
    Sufficient statistics for a particular topic. Corresponds to matrix beta in the linked paper for the first
    time slice, expected shape (`self.vocab_len`, `num_topics`).
totals : list of int of length `len(self.time_slice)`
    The totals for each time slice.

Returns
-------
(numpy.ndarray of float, numpy.ndarray of float)
    The updated optimized values for obs and the zeta variational parameter.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1042</span>    <span class="keyword">def </span>update_obs(self, sstats, totals):</div>
<div class="line"><span class="lineno"> 1043</span>        <span class="stringliteral">&quot;&quot;&quot;Optimize the bound with respect to the observed variables.</span></div>
<div class="line"><span class="lineno"> 1044</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1045</span><span class="stringliteral">        TODO:</span></div>
<div class="line"><span class="lineno"> 1046</span><span class="stringliteral">        This is by far the slowest function in the whole algorithm.</span></div>
<div class="line"><span class="lineno"> 1047</span><span class="stringliteral">        Replacing or improving the performance of this would greatly speed things up.</span></div>
<div class="line"><span class="lineno"> 1048</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1049</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno"> 1050</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno"> 1051</span><span class="stringliteral">        sstats : numpy.ndarray</span></div>
<div class="line"><span class="lineno"> 1052</span><span class="stringliteral">            Sufficient statistics for a particular topic. Corresponds to matrix beta in the linked paper for the first</span></div>
<div class="line"><span class="lineno"> 1053</span><span class="stringliteral">            time slice, expected shape (`self.vocab_len`, `num_topics`).</span></div>
<div class="line"><span class="lineno"> 1054</span><span class="stringliteral">        totals : list of int of length `len(self.time_slice)`</span></div>
<div class="line"><span class="lineno"> 1055</span><span class="stringliteral">            The totals for each time slice.</span></div>
<div class="line"><span class="lineno"> 1056</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1057</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno"> 1058</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno"> 1059</span><span class="stringliteral">        (numpy.ndarray of float, numpy.ndarray of float)</span></div>
<div class="line"><span class="lineno"> 1060</span><span class="stringliteral">            The updated optimized values for obs and the zeta variational parameter.</span></div>
<div class="line"><span class="lineno"> 1061</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1062</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1063</span> </div>
<div class="line"><span class="lineno"> 1064</span>        OBS_NORM_CUTOFF = 2</div>
<div class="line"><span class="lineno"> 1065</span>        STEP_SIZE = 0.01</div>
<div class="line"><span class="lineno"> 1066</span>        TOL = 1e-3</div>
<div class="line"><span class="lineno"> 1067</span> </div>
<div class="line"><span class="lineno"> 1068</span>        W = self.vocab_len</div>
<div class="line"><span class="lineno"> 1069</span>        T = self.num_time_slices</div>
<div class="line"><span class="lineno"> 1070</span> </div>
<div class="line"><span class="lineno"> 1071</span>        runs = 0</div>
<div class="line"><span class="lineno"> 1072</span>        mean_deriv_mtx = np.zeros((T, T + 1))</div>
<div class="line"><span class="lineno"> 1073</span> </div>
<div class="line"><span class="lineno"> 1074</span>        norm_cutoff_obs = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1075</span>        <span class="keywordflow">for</span> w <span class="keywordflow">in</span> range(W):</div>
<div class="line"><span class="lineno"> 1076</span>            w_counts = sstats[w]</div>
<div class="line"><span class="lineno"> 1077</span>            counts_norm = 0</div>
<div class="line"><span class="lineno"> 1078</span>            <span class="comment"># now we find L2 norm of w_counts</span></div>
<div class="line"><span class="lineno"> 1079</span>            <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(w_counts)):</div>
<div class="line"><span class="lineno"> 1080</span>                counts_norm += w_counts[i] * w_counts[i]</div>
<div class="line"><span class="lineno"> 1081</span> </div>
<div class="line"><span class="lineno"> 1082</span>            counts_norm = np.sqrt(counts_norm)</div>
<div class="line"><span class="lineno"> 1083</span> </div>
<div class="line"><span class="lineno"> 1084</span>            <span class="keywordflow">if</span> counts_norm &lt; OBS_NORM_CUTOFF <span class="keywordflow">and</span> norm_cutoff_obs <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1085</span>                obs = self.obs[w]</div>
<div class="line"><span class="lineno"> 1086</span>                norm_cutoff_obs = np.copy(obs)</div>
<div class="line"><span class="lineno"> 1087</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1088</span>                <span class="keywordflow">if</span> counts_norm &lt; OBS_NORM_CUTOFF:</div>
<div class="line"><span class="lineno"> 1089</span>                    w_counts = np.zeros(len(w_counts))</div>
<div class="line"><span class="lineno"> 1090</span> </div>
<div class="line"><span class="lineno"> 1091</span>                <span class="comment"># TODO: apply lambda function</span></div>
<div class="line"><span class="lineno"> 1092</span>                <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(T):</div>
<div class="line"><span class="lineno"> 1093</span>                    mean_deriv_mtx[t] = self.compute_mean_deriv(w, t, mean_deriv_mtx[t])</div>
<div class="line"><span class="lineno"> 1094</span> </div>
<div class="line"><span class="lineno"> 1095</span>                deriv = np.zeros(T)</div>
<div class="line"><span class="lineno"> 1096</span>                args = self, w_counts, totals, mean_deriv_mtx, w, deriv</div>
<div class="line"><span class="lineno"> 1097</span>                obs = self.obs[w]</div>
<div class="line"><span class="lineno"> 1098</span>                model = <span class="stringliteral">&quot;DTM&quot;</span></div>
<div class="line"><span class="lineno"> 1099</span> </div>
<div class="line"><span class="lineno"> 1100</span>                <span class="keywordflow">if</span> model == <span class="stringliteral">&quot;DTM&quot;</span>:</div>
<div class="line"><span class="lineno"> 1101</span>                    <span class="comment"># slowest part of method</span></div>
<div class="line"><span class="lineno"> 1102</span>                    obs = optimize.fmin_cg(</div>
<div class="line"><span class="lineno"> 1103</span>                        f=f_obs, fprime=df_obs, x0=obs, gtol=TOL, args=args, epsilon=STEP_SIZE, disp=0</div>
<div class="line"><span class="lineno"> 1104</span>                    )</div>
<div class="line"><span class="lineno"> 1105</span>                <span class="keywordflow">if</span> model == <span class="stringliteral">&quot;DIM&quot;</span>:</div>
<div class="line"><span class="lineno"> 1106</span>                    <span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno"> 1107</span>                runs += 1</div>
<div class="line"><span class="lineno"> 1108</span> </div>
<div class="line"><span class="lineno"> 1109</span>                <span class="keywordflow">if</span> counts_norm &lt; OBS_NORM_CUTOFF:</div>
<div class="line"><span class="lineno"> 1110</span>                    norm_cutoff_obs = obs</div>
<div class="line"><span class="lineno"> 1111</span> </div>
<div class="line"><span class="lineno"> 1112</span>                self.obs[w] = obs</div>
<div class="line"><span class="lineno"> 1113</span> </div>
<div class="line"><span class="lineno"> 1114</span>        self.zeta = self.update_zeta()</div>
<div class="line"><span class="lineno"> 1115</span> </div>
<div class="line"><span class="lineno"> 1116</span>        <span class="keywordflow">return</span> self.obs, self.zeta</div>
<div class="line"><span class="lineno"> 1117</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aff27a78469f4a6d03b6a1a3611969c53" name="aff27a78469f4a6d03b6a1a3611969c53"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff27a78469f4a6d03b6a1a3611969c53">&#9670;&#160;</a></span>update_zeta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.update_zeta </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update the Zeta variational parameter.

Zeta is described in the appendix and is equal to sum (exp(mean[word] + Variance[word] / 2)),
over every time-slice. It is the value of variational parameter zeta which maximizes the lower bound.

Returns
-------
list of float
    The updated zeta values for each time slice.</pre> <div class="fragment"><div class="line"><span class="lineno">  726</span>    <span class="keyword">def </span>update_zeta(self):</div>
<div class="line"><span class="lineno">  727</span>        <span class="stringliteral">&quot;&quot;&quot;Update the Zeta variational parameter.</span></div>
<div class="line"><span class="lineno">  728</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  729</span><span class="stringliteral">        Zeta is described in the appendix and is equal to sum (exp(mean[word] + Variance[word] / 2)),</span></div>
<div class="line"><span class="lineno">  730</span><span class="stringliteral">        over every time-slice. It is the value of variational parameter zeta which maximizes the lower bound.</span></div>
<div class="line"><span class="lineno">  731</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  732</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  733</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  734</span><span class="stringliteral">        list of float</span></div>
<div class="line"><span class="lineno">  735</span><span class="stringliteral">            The updated zeta values for each time slice.</span></div>
<div class="line"><span class="lineno">  736</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  737</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  738</span>        <span class="keywordflow">for</span> j, val <span class="keywordflow">in</span> enumerate(self.zeta):</div>
<div class="line"><span class="lineno">  739</span>            self.zeta[j] = np.sum(np.exp(self.mean[:, j + 1] + self.variance[:, j + 1] / 2))</div>
<div class="line"><span class="lineno">  740</span>        <span class="keywordflow">return</span> self.zeta</div>
<div class="line"><span class="lineno">  741</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a25a988aef7bc737b96daf1c32d6cdb62" name="a25a988aef7bc737b96daf1c32d6cdb62"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25a988aef7bc737b96daf1c32d6cdb62">&#9670;&#160;</a></span>chain_variance</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.chain_variance</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a52d286c0e81135540340253b10c5e485" name="a52d286c0e81135540340253b10c5e485"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a52d286c0e81135540340253b10c5e485">&#9670;&#160;</a></span>e_log_prob</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.e_log_prob</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a60a4ac49f90cf2dcb03e681849e8244c" name="a60a4ac49f90cf2dcb03e681849e8244c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a60a4ac49f90cf2dcb03e681849e8244c">&#9670;&#160;</a></span>fwd_mean</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.fwd_mean</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a559e12c929d69234792049299abb5042" name="a559e12c929d69234792049299abb5042"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a559e12c929d69234792049299abb5042">&#9670;&#160;</a></span>fwd_variance</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.fwd_variance</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1b00983a499d0c686fcc8c4fbd615d7a" name="a1b00983a499d0c686fcc8c4fbd615d7a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1b00983a499d0c686fcc8c4fbd615d7a">&#9670;&#160;</a></span>influence_sum_lgl</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.influence_sum_lgl</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a18b604a8fd0ef693103e0ef98b63e567" name="a18b604a8fd0ef693103e0ef98b63e567"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18b604a8fd0ef693103e0ef98b63e567">&#9670;&#160;</a></span>m_update_coeff</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.m_update_coeff</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a89c950f7b8c556191c0acad5228cbff6" name="a89c950f7b8c556191c0acad5228cbff6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a89c950f7b8c556191c0acad5228cbff6">&#9670;&#160;</a></span>m_update_coeff_g</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.m_update_coeff_g</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a63ae953aa6cc56b8f04d74643251fb29" name="a63ae953aa6cc56b8f04d74643251fb29"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a63ae953aa6cc56b8f04d74643251fb29">&#9670;&#160;</a></span>mean</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.mean</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a58d7a3274664b00193b2543a03ec14b6" name="a58d7a3274664b00193b2543a03ec14b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a58d7a3274664b00193b2543a03ec14b6">&#9670;&#160;</a></span>mean_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.mean_t</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8b98b0fb94692a5b9a275b3247e448c3" name="a8b98b0fb94692a5b9a275b3247e448c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8b98b0fb94692a5b9a275b3247e448c3">&#9670;&#160;</a></span>num_time_slices</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.num_time_slices</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6cdc23685ec6343812f11f4b7857f840" name="a6cdc23685ec6343812f11f4b7857f840"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6cdc23685ec6343812f11f4b7857f840">&#9670;&#160;</a></span>num_topics</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.num_topics</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8a407c417576af74e377f23e8fdf6f73" name="a8a407c417576af74e377f23e8fdf6f73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a407c417576af74e377f23e8fdf6f73">&#9670;&#160;</a></span>obs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.obs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abb8405d942d998257189e895aa53a52d" name="abb8405d942d998257189e895aa53a52d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb8405d942d998257189e895aa53a52d">&#9670;&#160;</a></span>obs_variance</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.obs_variance</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2d5b0e52bb8b95fa23dd3dbf94e79709" name="a2d5b0e52bb8b95fa23dd3dbf94e79709"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d5b0e52bb8b95fa23dd3dbf94e79709">&#9670;&#160;</a></span>temp_vect</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.temp_vect</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae4acb92b44d16a5419f076206fe18be1" name="ae4acb92b44d16a5419f076206fe18be1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4acb92b44d16a5419f076206fe18be1">&#9670;&#160;</a></span>variance</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.variance</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1f5796e0a9c753a07c4603c3a39184e6" name="a1f5796e0a9c753a07c4603c3a39184e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f5796e0a9c753a07c4603c3a39184e6">&#9670;&#160;</a></span>variance_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.variance_t</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae40d534e3ce1360cdc856766e15d60eb" name="ae40d534e3ce1360cdc856766e15d60eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae40d534e3ce1360cdc856766e15d60eb">&#9670;&#160;</a></span>vocab_len</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.vocab_len</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3b13e9ccf86feef830ff197d1235aa94" name="a3b13e9ccf86feef830ff197d1235aa94"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3b13e9ccf86feef830ff197d1235aa94">&#9670;&#160;</a></span>w_phi_l</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.w_phi_l</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a03592d1e16d670eac963d68e009ed829" name="a03592d1e16d670eac963d68e009ed829"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a03592d1e16d670eac963d68e009ed829">&#9670;&#160;</a></span>w_phi_l_sq</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.w_phi_l_sq</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a893ce8803ac0ae4371b67e550c922cee" name="a893ce8803ac0ae4371b67e550c922cee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a893ce8803ac0ae4371b67e550c922cee">&#9670;&#160;</a></span>w_phi_sum</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.w_phi_sum</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad06da84e89718493de6dd39e93ea6d50" name="ad06da84e89718493de6dd39e93ea6d50"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad06da84e89718493de6dd39e93ea6d50">&#9670;&#160;</a></span>zeta</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.ldaseqmodel.sslm.zeta</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/rafael/Documents/GitHub/PUC-GCES-PY/Tp-GCS-Rafael-Augusto/venv/lib/python3.9/site-packages/gensim/models/<a class="el" href="models_2ldaseqmodel_8py.html">ldaseqmodel.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
