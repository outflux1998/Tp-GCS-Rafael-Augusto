<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: joblib.parallel.Parallel Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacejoblib.html">joblib</a></li><li class="navelem"><a class="el" href="namespacejoblib_1_1parallel.html">parallel</a></li><li class="navelem"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html">Parallel</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classjoblib_1_1parallel_1_1_parallel-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">joblib.parallel.Parallel Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for joblib.parallel.Parallel:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classjoblib_1_1parallel_1_1_parallel.png" usemap="#joblib.parallel.Parallel_map" alt=""/>
  <map id="joblib.parallel.Parallel_map" name="joblib.parallel.Parallel_map">
<area href="classjoblib_1_1logger_1_1_logger.html" title="class Logger" alt="joblib.logger.Logger" shape="rect" coords="0,56,135,80"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a6cf37e7757f32f9c60ff358984c0fabf" id="r_a6cf37e7757f32f9c60ff358984c0fabf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a6cf37e7757f32f9c60ff358984c0fabf">__init__</a> (self, <a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#aa9fce54124ba60d7fc9b2f83f3819306">n_jobs</a>=None, backend=None, <a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a2c869582163997e78d4b4c0abce7b509">verbose</a>=0, <a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a7c5f6666c363e8fd8a857f07255dd499">timeout</a>=None, <a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a53217086dabf65c881eb026885e5f69b">pre_dispatch</a>='2 *<a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#aa9fce54124ba60d7fc9b2f83f3819306">n_jobs</a>', <a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#abb17d0040d42a0fbcba8035059977912">batch_size</a>='auto', temp_folder=None, max_nbytes='1M', mmap_mode='<a class="el" href="__lapack__subroutines_8h.html#a952912404e837594f7cbfb183beeacd4">r</a>', prefer=None, require=None)</td></tr>
<tr class="separator:a6cf37e7757f32f9c60ff358984c0fabf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aadf3cb72e227cc0d00c8f18b74d846e7" id="r_aadf3cb72e227cc0d00c8f18b74d846e7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#aadf3cb72e227cc0d00c8f18b74d846e7">__enter__</a> (self)</td></tr>
<tr class="separator:aadf3cb72e227cc0d00c8f18b74d846e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48f995847159a9e489f5761bc7196d01" id="r_a48f995847159a9e489f5761bc7196d01"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a48f995847159a9e489f5761bc7196d01">__exit__</a> (self, exc_type, exc_value, traceback)</td></tr>
<tr class="separator:a48f995847159a9e489f5761bc7196d01"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7cd4ff5b77c9672ec7b3525d3882833" id="r_ab7cd4ff5b77c9672ec7b3525d3882833"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#ab7cd4ff5b77c9672ec7b3525d3882833">dispatch_next</a> (self)</td></tr>
<tr class="separator:ab7cd4ff5b77c9672ec7b3525d3882833"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7257695d3890ae0eb1c7a0dd3e380f87" id="r_a7257695d3890ae0eb1c7a0dd3e380f87"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a7257695d3890ae0eb1c7a0dd3e380f87">dispatch_one_batch</a> (self, iterator)</td></tr>
<tr class="separator:a7257695d3890ae0eb1c7a0dd3e380f87"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab339e2ead11d57d805acdc8367f890ea" id="r_ab339e2ead11d57d805acdc8367f890ea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#ab339e2ead11d57d805acdc8367f890ea">print_progress</a> (self)</td></tr>
<tr class="separator:ab339e2ead11d57d805acdc8367f890ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad707177c2dddb16705da493131be515" id="r_aad707177c2dddb16705da493131be515"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#aad707177c2dddb16705da493131be515">retrieve</a> (self)</td></tr>
<tr class="separator:aad707177c2dddb16705da493131be515"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a399d3be1249a5de0d8d4083b5a26af06" id="r_a399d3be1249a5de0d8d4083b5a26af06"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a399d3be1249a5de0d8d4083b5a26af06">__call__</a> (self, iterable)</td></tr>
<tr class="separator:a399d3be1249a5de0d8d4083b5a26af06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01e6729b1fedc51bdeeb70224a5508f4" id="r_a01e6729b1fedc51bdeeb70224a5508f4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a01e6729b1fedc51bdeeb70224a5508f4">__repr__</a> (self)</td></tr>
<tr class="separator:a01e6729b1fedc51bdeeb70224a5508f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classjoblib_1_1logger_1_1_logger"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classjoblib_1_1logger_1_1_logger')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classjoblib_1_1logger_1_1_logger.html">joblib.logger.Logger</a></td></tr>
<tr class="memitem:a5136a0a386a184e315d115860f4f261d inherit pub_methods_classjoblib_1_1logger_1_1_logger" id="r_a5136a0a386a184e315d115860f4f261d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1logger_1_1_logger.html#a5136a0a386a184e315d115860f4f261d">warn</a> (self, msg)</td></tr>
<tr class="separator:a5136a0a386a184e315d115860f4f261d inherit pub_methods_classjoblib_1_1logger_1_1_logger"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe53da0719066071f725256a5d5ce153 inherit pub_methods_classjoblib_1_1logger_1_1_logger" id="r_afe53da0719066071f725256a5d5ce153"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1logger_1_1_logger.html#afe53da0719066071f725256a5d5ce153">debug</a> (self, msg)</td></tr>
<tr class="separator:afe53da0719066071f725256a5d5ce153 inherit pub_methods_classjoblib_1_1logger_1_1_logger"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe4b6477884706f2a411232132a6c0e9 inherit pub_methods_classjoblib_1_1logger_1_1_logger" id="r_afe4b6477884706f2a411232132a6c0e9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1logger_1_1_logger.html#afe4b6477884706f2a411232132a6c0e9">format</a> (self, obj, indent=0)</td></tr>
<tr class="separator:afe4b6477884706f2a411232132a6c0e9 inherit pub_methods_classjoblib_1_1logger_1_1_logger"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:aa9fce54124ba60d7fc9b2f83f3819306" id="r_aa9fce54124ba60d7fc9b2f83f3819306"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#aa9fce54124ba60d7fc9b2f83f3819306">n_jobs</a></td></tr>
<tr class="separator:aa9fce54124ba60d7fc9b2f83f3819306"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c869582163997e78d4b4c0abce7b509" id="r_a2c869582163997e78d4b4c0abce7b509"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a2c869582163997e78d4b4c0abce7b509">verbose</a></td></tr>
<tr class="separator:a2c869582163997e78d4b4c0abce7b509"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c5f6666c363e8fd8a857f07255dd499" id="r_a7c5f6666c363e8fd8a857f07255dd499"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a7c5f6666c363e8fd8a857f07255dd499">timeout</a></td></tr>
<tr class="separator:a7c5f6666c363e8fd8a857f07255dd499"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53217086dabf65c881eb026885e5f69b" id="r_a53217086dabf65c881eb026885e5f69b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a53217086dabf65c881eb026885e5f69b">pre_dispatch</a></td></tr>
<tr class="separator:a53217086dabf65c881eb026885e5f69b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb17d0040d42a0fbcba8035059977912" id="r_abb17d0040d42a0fbcba8035059977912"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#abb17d0040d42a0fbcba8035059977912">batch_size</a></td></tr>
<tr class="separator:abb17d0040d42a0fbcba8035059977912"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a795e034c5c7a48d556a63ebd47c9181e" id="r_a795e034c5c7a48d556a63ebd47c9181e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a795e034c5c7a48d556a63ebd47c9181e">n_dispatched_batches</a></td></tr>
<tr class="separator:a795e034c5c7a48d556a63ebd47c9181e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68961cae3e508b55ff56f8a8bc2e1b37" id="r_a68961cae3e508b55ff56f8a8bc2e1b37"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a68961cae3e508b55ff56f8a8bc2e1b37">n_completed_tasks</a></td></tr>
<tr class="separator:a68961cae3e508b55ff56f8a8bc2e1b37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ed7c7e6b2cc7f1fa2c31245e195bd32" id="r_a4ed7c7e6b2cc7f1fa2c31245e195bd32"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a4ed7c7e6b2cc7f1fa2c31245e195bd32">n_dispatched_tasks</a></td></tr>
<tr class="separator:a4ed7c7e6b2cc7f1fa2c31245e195bd32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classjoblib_1_1logger_1_1_logger"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classjoblib_1_1logger_1_1_logger')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classjoblib_1_1logger_1_1_logger.html">joblib.logger.Logger</a></td></tr>
<tr class="memitem:a111c6eaef572b39726d0dcae8c7a6de8 inherit pub_attribs_classjoblib_1_1logger_1_1_logger" id="r_a111c6eaef572b39726d0dcae8c7a6de8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1logger_1_1_logger.html#a111c6eaef572b39726d0dcae8c7a6de8">depth</a></td></tr>
<tr class="separator:a111c6eaef572b39726d0dcae8c7a6de8 inherit pub_attribs_classjoblib_1_1logger_1_1_logger"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-methods" name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:ace0b86aef7fc721dde4c290eca3f7bce" id="r_ace0b86aef7fc721dde4c290eca3f7bce"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#ace0b86aef7fc721dde4c290eca3f7bce">_initialize_backend</a> (self)</td></tr>
<tr class="separator:ace0b86aef7fc721dde4c290eca3f7bce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24345a2dd355b4c1995b5a24af672021" id="r_a24345a2dd355b4c1995b5a24af672021"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a24345a2dd355b4c1995b5a24af672021">_effective_n_jobs</a> (self)</td></tr>
<tr class="separator:a24345a2dd355b4c1995b5a24af672021"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a662f48da88f58d22e92535d18dcaf939" id="r_a662f48da88f58d22e92535d18dcaf939"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a662f48da88f58d22e92535d18dcaf939">_terminate_backend</a> (self)</td></tr>
<tr class="separator:a662f48da88f58d22e92535d18dcaf939"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4cbe2f0f9fca19526312991ef3391f0f" id="r_a4cbe2f0f9fca19526312991ef3391f0f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a4cbe2f0f9fca19526312991ef3391f0f">_dispatch</a> (self, batch)</td></tr>
<tr class="separator:a4cbe2f0f9fca19526312991ef3391f0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f6324266200e8e2b1146ec85134b3dd" id="r_a6f6324266200e8e2b1146ec85134b3dd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a6f6324266200e8e2b1146ec85134b3dd">_print</a> (self, msg, msg_args)</td></tr>
<tr class="separator:a6f6324266200e8e2b1146ec85134b3dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-attribs" name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:abc8930a2089f12fb4b5c12b08e5e2ad6" id="r_abc8930a2089f12fb4b5c12b08e5e2ad6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#abc8930a2089f12fb4b5c12b08e5e2ad6">_ready_batches</a></td></tr>
<tr class="separator:abc8930a2089f12fb4b5c12b08e5e2ad6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a378961466accd2ae025782ce79ebf5b8" id="r_a378961466accd2ae025782ce79ebf5b8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a378961466accd2ae025782ce79ebf5b8">_id</a></td></tr>
<tr class="separator:a378961466accd2ae025782ce79ebf5b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a648f550237e74f35875e69c65c9a91aa" id="r_a648f550237e74f35875e69c65c9a91aa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a648f550237e74f35875e69c65c9a91aa">_reducer_callback</a></td></tr>
<tr class="separator:a648f550237e74f35875e69c65c9a91aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a66fe24acb915168852147fb9d4950b" id="r_a0a66fe24acb915168852147fb9d4950b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a0a66fe24acb915168852147fb9d4950b">_backend_args</a></td></tr>
<tr class="separator:a0a66fe24acb915168852147fb9d4950b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a130645bd94d2c62cb84305c60b7d6dd5" id="r_a130645bd94d2c62cb84305c60b7d6dd5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a130645bd94d2c62cb84305c60b7d6dd5">_backend</a></td></tr>
<tr class="separator:a130645bd94d2c62cb84305c60b7d6dd5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad51d2cde7166aaafa6d69c1a28cc05e4" id="r_ad51d2cde7166aaafa6d69c1a28cc05e4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#ad51d2cde7166aaafa6d69c1a28cc05e4">_output</a></td></tr>
<tr class="separator:ad51d2cde7166aaafa6d69c1a28cc05e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5894974362fef32b82d66f312a2347ea" id="r_a5894974362fef32b82d66f312a2347ea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a5894974362fef32b82d66f312a2347ea">_jobs</a></td></tr>
<tr class="separator:a5894974362fef32b82d66f312a2347ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabfc96c79d9381404d545537070883a4" id="r_aabfc96c79d9381404d545537070883a4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#aabfc96c79d9381404d545537070883a4">_managed_backend</a></td></tr>
<tr class="separator:aabfc96c79d9381404d545537070883a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab20a877575bdcc945336205da3138219" id="r_ab20a877575bdcc945336205da3138219"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#ab20a877575bdcc945336205da3138219">_lock</a></td></tr>
<tr class="separator:ab20a877575bdcc945336205da3138219"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af35def4fd94856d6afc9c9d2c59aa504" id="r_af35def4fd94856d6afc9c9d2c59aa504"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#af35def4fd94856d6afc9c9d2c59aa504">_original_iterator</a></td></tr>
<tr class="separator:af35def4fd94856d6afc9c9d2c59aa504"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afcd9a2eae7c1ee0786bbddca8143d647" id="r_afcd9a2eae7c1ee0786bbddca8143d647"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#afcd9a2eae7c1ee0786bbddca8143d647">_iterating</a></td></tr>
<tr class="separator:afcd9a2eae7c1ee0786bbddca8143d647"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2e260a9ddbfa8738dc59fb8b5fec8bae" id="r_a2e260a9ddbfa8738dc59fb8b5fec8bae"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a2e260a9ddbfa8738dc59fb8b5fec8bae">_pickle_cache</a></td></tr>
<tr class="separator:a2e260a9ddbfa8738dc59fb8b5fec8bae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97aaa384a45edd9848ac1b061c22b1f5" id="r_a97aaa384a45edd9848ac1b061c22b1f5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a97aaa384a45edd9848ac1b061c22b1f5">_pre_dispatch_amount</a></td></tr>
<tr class="separator:a97aaa384a45edd9848ac1b061c22b1f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2013b39466418456096803bb2aed8fc4" id="r_a2013b39466418456096803bb2aed8fc4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a2013b39466418456096803bb2aed8fc4">_aborting</a></td></tr>
<tr class="separator:a2013b39466418456096803bb2aed8fc4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4cbe19d44152ad9681155fc72c9426fd" id="r_a4cbe19d44152ad9681155fc72c9426fd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a4cbe19d44152ad9681155fc72c9426fd">_cached_effective_n_jobs</a></td></tr>
<tr class="separator:a4cbe19d44152ad9681155fc72c9426fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58c2d0096bf6fdf43c0567bae332e1b2" id="r_a58c2d0096bf6fdf43c0567bae332e1b2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#a58c2d0096bf6fdf43c0567bae332e1b2">_start_time</a></td></tr>
<tr class="separator:a58c2d0096bf6fdf43c0567bae332e1b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment"> Helper class for readable parallel mapping.

    Read more in the :ref:`User Guide &lt;parallel&gt;`.

    Parameters
    -----------
    n_jobs: int, default: None
        The maximum number of concurrently running jobs, such as the number
        of Python worker processes when backend="multiprocessing"
        or the size of the thread-pool when backend="threading".
        If -1 all CPUs are used. If 1 is given, no parallel computing code
        is used at all, which is useful for debugging. For n_jobs below -1,
        (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all
        CPUs but one are used.
        None is a marker for 'unset' that will be interpreted as n_jobs=1
        (sequential execution) unless the call is performed under a
        :func:`~parallel_backend` context manager that sets another value
        for n_jobs.
    backend: str, ParallelBackendBase instance or None, default: 'loky'
        Specify the parallelization backend implementation.
        Supported backends are:

        - "loky" used by default, can induce some
          communication and memory overhead when exchanging input and
          output data with the worker Python processes. On some rare
          systems (such as Pyiodide), the loky backend may not be
          available.
        - "multiprocessing" previous process-based backend based on
          `multiprocessing.Pool`. Less robust than `loky`.
        - "threading" is a very low-overhead backend but it suffers
          from the Python Global Interpreter Lock if the called function
          relies a lot on Python objects. "threading" is mostly useful
          when the execution bottleneck is a compiled extension that
          explicitly releases the GIL (for instance a Cython loop wrapped
          in a "with nogil" block or an expensive call to a library such
          as NumPy).
        - finally, you can register backends by calling
          :func:`~register_parallel_backend`. This will allow you to
          implement a backend of your liking.

        It is not recommended to hard-code the backend name in a call to
        :class:`~Parallel` in a library. Instead it is recommended to set
        soft hints (prefer) or hard constraints (require) so as to make it
        possible for library users to change the backend from the outside
        using the :func:`~parallel_backend` context manager.
    prefer: str in {'processes', 'threads'} or None, default: None
        Soft hint to choose the default backend if no specific backend
        was selected with the :func:`~parallel_backend` context manager.
        The default process-based backend is 'loky' and the default
        thread-based backend is 'threading'. Ignored if the ``backend``
        parameter is specified.
    require: 'sharedmem' or None, default None
        Hard constraint to select the backend. If set to 'sharedmem',
        the selected backend will be single-host and thread-based even
        if the user asked for a non-thread based backend with
        parallel_backend.
    verbose: int, optional
        The verbosity level: if non zero, progress messages are
        printed. Above 50, the output is sent to stdout.
        The frequency of the messages increases with the verbosity level.
        If it more than 10, all iterations are reported.
    timeout: float, optional
        Timeout limit for each task to complete.  If any task takes longer
        a TimeOutError will be raised. Only applied when n_jobs != 1
    pre_dispatch: {'all', integer, or expression, as in '3*n_jobs'}
        The number of batches (of tasks) to be pre-dispatched.
        Default is '2*n_jobs'. When batch_size="auto" this is reasonable
        default and the workers should never starve. Note that only basic
        arithmetics are allowed here and no modules can be used in this
        expression.
    batch_size: int or 'auto', default: 'auto'
        The number of atomic tasks to dispatch at once to each
        worker. When individual evaluations are very fast, dispatching
        calls to workers can be slower than sequential computation because
        of the overhead. Batching fast computations together can mitigate
        this.
        The ``'auto'`` strategy keeps track of the time it takes for a batch
        to complete, and dynamically adjusts the batch size to keep the time
        on the order of half a second, using a heuristic. The initial batch
        size is 1.
        ``batch_size="auto"`` with ``backend="threading"`` will dispatch
        batches of a single task at a time as the threading backend has
        very little overhead and using larger batch size has not proved to
        bring any gain in that case.
    temp_folder: str, optional
        Folder to be used by the pool for memmapping large arrays
        for sharing memory with worker processes. If None, this will try in
        order:

        - a folder pointed by the JOBLIB_TEMP_FOLDER environment
          variable,
        - /dev/shm if the folder exists and is writable: this is a
          RAM disk filesystem available by default on modern Linux
          distributions,
        - the default system temporary folder that can be
          overridden with TMP, TMPDIR or TEMP environment
          variables, typically /tmp under Unix operating systems.

        Only active when backend="loky" or "multiprocessing".
    max_nbytes int, str, or None, optional, 1M by default
        Threshold on the size of arrays passed to the workers that
        triggers automated memory mapping in temp_folder. Can be an int
        in Bytes, or a human-readable string, e.g., '1M' for 1 megabyte.
        Use None to disable memmapping of large arrays.
        Only active when backend="loky" or "multiprocessing".
    mmap_mode: {None, 'r+', 'r', 'w+', 'c'}, default: 'r'
        Memmapping mode for numpy arrays passed to workers. None will
        disable memmapping, other modes defined in the numpy.memmap doc:
        https://numpy.org/doc/stable/reference/generated/numpy.memmap.html
        Also, see 'max_nbytes' parameter documentation for more details.

    Notes
    -----

    This object uses workers to compute in parallel the application of a
    function to many different arguments. The main functionality it brings
    in addition to using the raw multiprocessing or concurrent.futures API
    are (see examples for details):

    * More readable code, in particular since it avoids
      constructing list of arguments.

    * Easier debugging:
        - informative tracebacks even when the error happens on
          the client side
        - using 'n_jobs=1' enables to turn off parallel computing
          for debugging without changing the codepath
        - early capture of pickling errors

    * An optional progress meter.

    * Interruption of multiprocesses jobs with 'Ctrl-C'

    * Flexible pickling control for the communication to and from
      the worker processes.

    * Ability to use shared memory efficiently with worker
      processes for large numpy-based datastructures.

    Examples
    --------

    A simple example:

    &gt;&gt;&gt; from math import sqrt
    &gt;&gt;&gt; from joblib import Parallel, delayed
    &gt;&gt;&gt; Parallel(n_jobs=1)(delayed(sqrt)(i**2) for i in range(10))
    [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]

    Reshaping the output when the function has several return
    values:

    &gt;&gt;&gt; from math import modf
    &gt;&gt;&gt; from joblib import Parallel, delayed
    &gt;&gt;&gt; r = Parallel(n_jobs=1)(delayed(modf)(i/2.) for i in range(10))
    &gt;&gt;&gt; res, i = zip(*r)
    &gt;&gt;&gt; res
    (0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5)
    &gt;&gt;&gt; i
    (0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0)

    The progress meter: the higher the value of `verbose`, the more
    messages:

    &gt;&gt;&gt; from time import sleep
    &gt;&gt;&gt; from joblib import Parallel, delayed
    &gt;&gt;&gt; r = Parallel(n_jobs=2, verbose=10)(delayed(sleep)(.2) for _ in range(10)) #doctest: +SKIP
    [Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.6s
    [Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.8s
    [Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    1.4s finished

    Traceback example, note how the line of the error is indicated
    as well as the values of the parameter passed to the function that
    triggered the exception, even though the traceback happens in the
    child process:

    &gt;&gt;&gt; from heapq import nlargest
    &gt;&gt;&gt; from joblib import Parallel, delayed
    &gt;&gt;&gt; Parallel(n_jobs=2)(delayed(nlargest)(2, n) for n in (range(4), 'abcde', 3)) #doctest: +SKIP
    #...
    ---------------------------------------------------------------------------
    Sub-process traceback:
    ---------------------------------------------------------------------------
    TypeError                                          Mon Nov 12 11:37:46 2012
    PID: 12934                                    Python 2.7.3: /usr/bin/python
    ...........................................................................
    /usr/lib/python2.7/heapq.pyc in nlargest(n=2, iterable=3, key=None)
        419         if n &gt;= size:
        420             return sorted(iterable, key=key, reverse=True)[:n]
        421
        422     # When key is none, use simpler decoration
        423     if key is None:
    --&gt; 424         it = izip(iterable, count(0,-1))                    # decorate
        425         result = _nlargest(n, it)
        426         return map(itemgetter(0), result)                   # undecorate
        427
        428     # General case, slowest method
     TypeError: izip argument #1 must support iteration
    ___________________________________________________________________________


    Using pre_dispatch in a producer/consumer situation, where the
    data is generated on the fly. Note how the producer is first
    called 3 times before the parallel loop is initiated, and then
    called to generate new data on the fly:

    &gt;&gt;&gt; from math import sqrt
    &gt;&gt;&gt; from joblib import Parallel, delayed
    &gt;&gt;&gt; def producer():
    ...     for i in range(6):
    ...         print('Produced %s' % i)
    ...         yield i
    &gt;&gt;&gt; out = Parallel(n_jobs=2, verbose=100, pre_dispatch='1.5*n_jobs')(
    ...                delayed(sqrt)(i) for i in producer()) #doctest: +SKIP
    Produced 0
    Produced 1
    Produced 2
    [Parallel(n_jobs=2)]: Done 1 jobs     | elapsed:  0.0s
    Produced 3
    [Parallel(n_jobs=2)]: Done 2 jobs     | elapsed:  0.0s
    Produced 4
    [Parallel(n_jobs=2)]: Done 3 jobs     | elapsed:  0.0s
    Produced 5
    [Parallel(n_jobs=2)]: Done 4 jobs     | elapsed:  0.0s
    [Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s remaining: 0.0s
    [Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s finished</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a6cf37e7757f32f9c60ff358984c0fabf" name="a6cf37e7757f32f9c60ff358984c0fabf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6cf37e7757f32f9c60ff358984c0fabf">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>depth</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>backend</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>timeout</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pre_dispatch</em> = <code>'2&#160;*&#160;<a class="el" href="classjoblib_1_1parallel_1_1_parallel.html#aa9fce54124ba60d7fc9b2f83f3819306">n_jobs</a>'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_size</em> = <code>'auto'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>temp_folder</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_nbytes</em> = <code>'1M'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mmap_mode</em> = <code>'<a class="el" href="__lapack__subroutines_8h.html#a952912404e837594f7cbfb183beeacd4">r</a>'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>prefer</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>require</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Parameters
    ----------
    depth: int, optional
        The depth of objects printed.
</pre> 
<p>Reimplemented from <a class="el" href="classjoblib_1_1logger_1_1_logger.html#ae1bfe623fead8100c789ffd85643b739">joblib.logger.Logger</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  672</span>                 prefer=<span class="keywordtype">None</span>, require=<span class="keywordtype">None</span>):</div>
<div class="line"><span class="lineno">  673</span>        active_backend, context_n_jobs = get_active_backend(</div>
<div class="line"><span class="lineno">  674</span>            prefer=prefer, require=require, verbose=verbose)</div>
<div class="line"><span class="lineno">  675</span>        nesting_level = active_backend.nesting_level</div>
<div class="line"><span class="lineno">  676</span>        <span class="keywordflow">if</span> backend <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> n_jobs <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  677</span>            <span class="comment"># If we are under a parallel_backend context manager, look up</span></div>
<div class="line"><span class="lineno">  678</span>            <span class="comment"># the default number of jobs and use that instead:</span></div>
<div class="line"><span class="lineno">  679</span>            n_jobs = context_n_jobs</div>
<div class="line"><span class="lineno">  680</span>        <span class="keywordflow">if</span> n_jobs <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  681</span>            <span class="comment"># No specific context override and no specific value request:</span></div>
<div class="line"><span class="lineno">  682</span>            <span class="comment"># default to 1.</span></div>
<div class="line"><span class="lineno">  683</span>            n_jobs = 1</div>
<div class="line"><span class="lineno">  684</span>        self.n_jobs = n_jobs</div>
<div class="line"><span class="lineno">  685</span>        self.verbose = verbose</div>
<div class="line"><span class="lineno">  686</span>        self.timeout = timeout</div>
<div class="line"><span class="lineno">  687</span>        self.pre_dispatch = pre_dispatch</div>
<div class="line"><span class="lineno">  688</span>        self._ready_batches = queue.Queue()</div>
<div class="line"><span class="lineno">  689</span>        self._id = uuid4().hex</div>
<div class="line"><span class="lineno">  690</span>        self._reducer_callback = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  691</span> </div>
<div class="line"><span class="lineno">  692</span>        <span class="keywordflow">if</span> isinstance(max_nbytes, str):</div>
<div class="line"><span class="lineno">  693</span>            max_nbytes = memstr_to_bytes(max_nbytes)</div>
<div class="line"><span class="lineno">  694</span> </div>
<div class="line"><span class="lineno">  695</span>        self._backend_args = dict(</div>
<div class="line"><span class="lineno">  696</span>            max_nbytes=max_nbytes,</div>
<div class="line"><span class="lineno">  697</span>            mmap_mode=mmap_mode,</div>
<div class="line"><span class="lineno">  698</span>            temp_folder=temp_folder,</div>
<div class="line"><span class="lineno">  699</span>            prefer=prefer,</div>
<div class="line"><span class="lineno">  700</span>            require=require,</div>
<div class="line"><span class="lineno">  701</span>            verbose=max(0, self.verbose - 50),</div>
<div class="line"><span class="lineno">  702</span>        )</div>
<div class="line"><span class="lineno">  703</span>        <span class="keywordflow">if</span> DEFAULT_MP_CONTEXT <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  704</span>            self._backend_args[<span class="stringliteral">&#39;context&#39;</span>] = DEFAULT_MP_CONTEXT</div>
<div class="line"><span class="lineno">  705</span>        <span class="keywordflow">elif</span> hasattr(mp, <span class="stringliteral">&quot;get_context&quot;</span>):</div>
<div class="line"><span class="lineno">  706</span>            self._backend_args[<span class="stringliteral">&#39;context&#39;</span>] = mp.get_context()</div>
<div class="line"><span class="lineno">  707</span> </div>
<div class="line"><span class="lineno">  708</span>        <span class="keywordflow">if</span> backend <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  709</span>            backend = active_backend</div>
<div class="line"><span class="lineno">  710</span> </div>
<div class="line"><span class="lineno">  711</span>        <span class="keywordflow">elif</span> isinstance(backend, ParallelBackendBase):</div>
<div class="line"><span class="lineno">  712</span>            <span class="comment"># Use provided backend as is, with the current nesting_level if it</span></div>
<div class="line"><span class="lineno">  713</span>            <span class="comment"># is not set yet.</span></div>
<div class="line"><span class="lineno">  714</span>            <span class="keywordflow">if</span> backend.nesting_level <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  715</span>                backend.nesting_level = nesting_level</div>
<div class="line"><span class="lineno">  716</span> </div>
<div class="line"><span class="lineno">  717</span>        <span class="keywordflow">elif</span> hasattr(backend, <span class="stringliteral">&#39;Pool&#39;</span>) <span class="keywordflow">and</span> hasattr(backend, <span class="stringliteral">&#39;Lock&#39;</span>):</div>
<div class="line"><span class="lineno">  718</span>            <span class="comment"># Make it possible to pass a custom multiprocessing context as</span></div>
<div class="line"><span class="lineno">  719</span>            <span class="comment"># backend to change the start method to forkserver or spawn or</span></div>
<div class="line"><span class="lineno">  720</span>            <span class="comment"># preload modules on the forkserver helper process.</span></div>
<div class="line"><span class="lineno">  721</span>            self._backend_args[<span class="stringliteral">&#39;context&#39;</span>] = backend</div>
<div class="line"><span class="lineno">  722</span>            backend = MultiprocessingBackend(nesting_level=nesting_level)</div>
<div class="line"><span class="lineno">  723</span> </div>
<div class="line"><span class="lineno">  724</span>        <span class="keywordflow">elif</span> backend <span class="keywordflow">not</span> <span class="keywordflow">in</span> BACKENDS <span class="keywordflow">and</span> backend <span class="keywordflow">in</span> MAYBE_AVAILABLE_BACKENDS:</div>
<div class="line"><span class="lineno">  725</span>            warnings.warn(</div>
<div class="line"><span class="lineno">  726</span>                f<span class="stringliteral">&quot;joblib backend &#39;{backend}&#39; is not available on &quot;</span></div>
<div class="line"><span class="lineno">  727</span>                f<span class="stringliteral">&quot;your system, falling back to {DEFAULT_BACKEND}.&quot;</span>,</div>
<div class="line"><span class="lineno">  728</span>                UserWarning,</div>
<div class="line"><span class="lineno">  729</span>                stacklevel=2)</div>
<div class="line"><span class="lineno">  730</span>            BACKENDS[backend] = BACKENDS[DEFAULT_BACKEND]</div>
<div class="line"><span class="lineno">  731</span>            backend = BACKENDS[DEFAULT_BACKEND](nesting_level=nesting_level)</div>
<div class="line"><span class="lineno">  732</span> </div>
<div class="line"><span class="lineno">  733</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  734</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  735</span>                backend_factory = BACKENDS[backend]</div>
<div class="line"><span class="lineno">  736</span>            <span class="keywordflow">except</span> KeyError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  737</span>                <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Invalid backend: %s, expected one of %r&quot;</span></div>
<div class="line"><span class="lineno">  738</span>                                 % (backend, sorted(BACKENDS.keys()))) <span class="keyword">from</span> e</div>
<div class="line"><span class="lineno">  739</span>            backend = backend_factory(nesting_level=nesting_level)</div>
<div class="line"><span class="lineno">  740</span> </div>
<div class="line"><span class="lineno">  741</span>        <span class="keywordflow">if</span> (require == <span class="stringliteral">&#39;sharedmem&#39;</span> <span class="keywordflow">and</span></div>
<div class="line"><span class="lineno">  742</span>                <span class="keywordflow">not</span> getattr(backend, <span class="stringliteral">&#39;supports_sharedmem&#39;</span>, <span class="keyword">False</span>)):</div>
<div class="line"><span class="lineno">  743</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Backend %s does not support shared memory&quot;</span></div>
<div class="line"><span class="lineno">  744</span>                             % backend)</div>
<div class="line"><span class="lineno">  745</span> </div>
<div class="line"><span class="lineno">  746</span>        <span class="keywordflow">if</span> (batch_size == <span class="stringliteral">&#39;auto&#39;</span> <span class="keywordflow">or</span> isinstance(batch_size, Integral) <span class="keywordflow">and</span></div>
<div class="line"><span class="lineno">  747</span>                batch_size &gt; 0):</div>
<div class="line"><span class="lineno">  748</span>            self.batch_size = batch_size</div>
<div class="line"><span class="lineno">  749</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  750</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  751</span>                <span class="stringliteral">&quot;batch_size must be &#39;auto&#39; or a positive integer, got: %r&quot;</span></div>
<div class="line"><span class="lineno">  752</span>                % batch_size)</div>
<div class="line"><span class="lineno">  753</span> </div>
<div class="line"><span class="lineno">  754</span>        self._backend = backend</div>
<div class="line"><span class="lineno">  755</span>        self._output = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  756</span>        self._jobs = list()</div>
<div class="line"><span class="lineno">  757</span>        self._managed_backend = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  758</span> </div>
<div class="line"><span class="lineno">  759</span>        <span class="comment"># This lock is used coordinate the main thread of this process with</span></div>
<div class="line"><span class="lineno">  760</span>        <span class="comment"># the async callback thread of our the pool.</span></div>
<div class="line"><span class="lineno">  761</span>        self._lock = threading.RLock()</div>
<div class="line"><span class="lineno">  762</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a399d3be1249a5de0d8d4083b5a26af06" name="a399d3be1249a5de0d8d4083b5a26af06"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a399d3be1249a5de0d8d4083b5a26af06">&#9670;&#160;</a></span>__call__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.__call__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>iterable</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1000</span>    <span class="keyword">def </span>__call__(self, iterable):</div>
<div class="line"><span class="lineno"> 1001</span>        <span class="keywordflow">if</span> self._jobs:</div>
<div class="line"><span class="lineno"> 1002</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;This Parallel instance is already running&#39;</span>)</div>
<div class="line"><span class="lineno"> 1003</span>        <span class="comment"># A flag used to abort the dispatching of jobs in case an</span></div>
<div class="line"><span class="lineno"> 1004</span>        <span class="comment"># exception is found</span></div>
<div class="line"><span class="lineno"> 1005</span>        self._aborting = <span class="keyword">False</span></div>
<div class="line"><span class="lineno"> 1006</span> </div>
<div class="line"><span class="lineno"> 1007</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self._managed_backend:</div>
<div class="line"><span class="lineno"> 1008</span>            n_jobs = self._initialize_backend()</div>
<div class="line"><span class="lineno"> 1009</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1010</span>            n_jobs = self._effective_n_jobs()</div>
<div class="line"><span class="lineno"> 1011</span> </div>
<div class="line"><span class="lineno"> 1012</span>        <span class="keywordflow">if</span> isinstance(self._backend, LokyBackend):</div>
<div class="line"><span class="lineno"> 1013</span>            <span class="comment"># For the loky backend, we add a callback executed when reducing</span></div>
<div class="line"><span class="lineno"> 1014</span>            <span class="comment"># BatchCalls, that makes the loky executor use a temporary folder</span></div>
<div class="line"><span class="lineno"> 1015</span>            <span class="comment"># specific to this Parallel object when pickling temporary memmaps.</span></div>
<div class="line"><span class="lineno"> 1016</span>            <span class="comment"># This callback is necessary to ensure that several Parallel</span></div>
<div class="line"><span class="lineno"> 1017</span>            <span class="comment"># objects using the same resuable executor don&#39;t use the same</span></div>
<div class="line"><span class="lineno"> 1018</span>            <span class="comment"># temporary resources.</span></div>
<div class="line"><span class="lineno"> 1019</span> </div>
<div class="line"><span class="lineno"> 1020</span>            <span class="keyword">def </span>_batched_calls_reducer_callback():</div>
<div class="line"><span class="lineno"> 1021</span>                <span class="comment"># Relevant implementation detail: the following lines, called</span></div>
<div class="line"><span class="lineno"> 1022</span>                <span class="comment"># when reducing BatchedCalls, are called in a thread-safe</span></div>
<div class="line"><span class="lineno"> 1023</span>                <span class="comment"># situation, meaning that the context of the temporary folder</span></div>
<div class="line"><span class="lineno"> 1024</span>                <span class="comment"># manager will not be changed in between the callback execution</span></div>
<div class="line"><span class="lineno"> 1025</span>                <span class="comment"># and the end of the BatchedCalls pickling. The reason is that</span></div>
<div class="line"><span class="lineno"> 1026</span>                <span class="comment"># pickling (the only place where set_current_context is used)</span></div>
<div class="line"><span class="lineno"> 1027</span>                <span class="comment"># is done from a single thread (the queue_feeder_thread).</span></div>
<div class="line"><span class="lineno"> 1028</span>                self._backend._workers._temp_folder_manager.set_current_context(  <span class="comment"># noqa</span></div>
<div class="line"><span class="lineno"> 1029</span>                    self._id</div>
<div class="line"><span class="lineno"> 1030</span>                )</div>
<div class="line"><span class="lineno"> 1031</span>            self._reducer_callback = _batched_calls_reducer_callback</div>
<div class="line"><span class="lineno"> 1032</span> </div>
<div class="line"><span class="lineno"> 1033</span>        <span class="comment"># self._effective_n_jobs should be called in the Parallel.__call__</span></div>
<div class="line"><span class="lineno"> 1034</span>        <span class="comment"># thread only -- store its value in an attribute for further queries.</span></div>
<div class="line"><span class="lineno"> 1035</span>        self._cached_effective_n_jobs = n_jobs</div>
<div class="line"><span class="lineno"> 1036</span> </div>
<div class="line"><span class="lineno"> 1037</span>        backend_name = self._backend.__class__.__name__</div>
<div class="line"><span class="lineno"> 1038</span>        <span class="keywordflow">if</span> n_jobs == 0:</div>
<div class="line"><span class="lineno"> 1039</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;%s has no active worker.&quot;</span> % backend_name)</div>
<div class="line"><span class="lineno"> 1040</span> </div>
<div class="line"><span class="lineno"> 1041</span>        self._print(<span class="stringliteral">&quot;Using backend %s with %d concurrent workers.&quot;</span>,</div>
<div class="line"><span class="lineno"> 1042</span>                    (backend_name, n_jobs))</div>
<div class="line"><span class="lineno"> 1043</span>        <span class="keywordflow">if</span> hasattr(self._backend, <span class="stringliteral">&#39;start_call&#39;</span>):</div>
<div class="line"><span class="lineno"> 1044</span>            self._backend.start_call()</div>
<div class="line"><span class="lineno"> 1045</span>        iterator = <a class="code hl_variable" href="__lapack__subroutines_8h.html#a60590d91febfcb54d88443940cd5f23e">iter</a>(iterable)</div>
<div class="line"><span class="lineno"> 1046</span>        pre_dispatch = self.pre_dispatch</div>
<div class="line"><span class="lineno"> 1047</span> </div>
<div class="line"><span class="lineno"> 1048</span>        <span class="keywordflow">if</span> pre_dispatch == <span class="stringliteral">&#39;all&#39;</span> <span class="keywordflow">or</span> n_jobs == 1:</div>
<div class="line"><span class="lineno"> 1049</span>            <span class="comment"># prevent further dispatch via multiprocessing callback thread</span></div>
<div class="line"><span class="lineno"> 1050</span>            self._original_iterator = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1051</span>            self._pre_dispatch_amount = 0</div>
<div class="line"><span class="lineno"> 1052</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1053</span>            self._original_iterator = iterator</div>
<div class="line"><span class="lineno"> 1054</span>            <span class="keywordflow">if</span> hasattr(pre_dispatch, <span class="stringliteral">&#39;endswith&#39;</span>):</div>
<div class="line"><span class="lineno"> 1055</span>                pre_dispatch = eval_expr(</div>
<div class="line"><span class="lineno"> 1056</span>                    pre_dispatch.replace(<span class="stringliteral">&quot;n_jobs&quot;</span>, str(n_jobs))</div>
<div class="line"><span class="lineno"> 1057</span>                )</div>
<div class="line"><span class="lineno"> 1058</span>            self._pre_dispatch_amount = pre_dispatch = int(pre_dispatch)</div>
<div class="line"><span class="lineno"> 1059</span> </div>
<div class="line"><span class="lineno"> 1060</span>            <span class="comment"># The main thread will consume the first pre_dispatch items and</span></div>
<div class="line"><span class="lineno"> 1061</span>            <span class="comment"># the remaining items will later be lazily dispatched by async</span></div>
<div class="line"><span class="lineno"> 1062</span>            <span class="comment"># callbacks upon task completions.</span></div>
<div class="line"><span class="lineno"> 1063</span> </div>
<div class="line"><span class="lineno"> 1064</span>            <span class="comment"># TODO: this iterator should be batch_size * n_jobs</span></div>
<div class="line"><span class="lineno"> 1065</span>            iterator = itertools.islice(iterator, self._pre_dispatch_amount)</div>
<div class="line"><span class="lineno"> 1066</span> </div>
<div class="line"><span class="lineno"> 1067</span>        self._start_time = time.time()</div>
<div class="line"><span class="lineno"> 1068</span>        self.n_dispatched_batches = 0</div>
<div class="line"><span class="lineno"> 1069</span>        self.n_dispatched_tasks = 0</div>
<div class="line"><span class="lineno"> 1070</span>        self.n_completed_tasks = 0</div>
<div class="line"><span class="lineno"> 1071</span>        <span class="comment"># Use a caching dict for callables that are pickled with cloudpickle to</span></div>
<div class="line"><span class="lineno"> 1072</span>        <span class="comment"># improve performances. This cache is used only in the case of</span></div>
<div class="line"><span class="lineno"> 1073</span>        <span class="comment"># functions that are defined in the __main__ module, functions that are</span></div>
<div class="line"><span class="lineno"> 1074</span>        <span class="comment"># defined locally (inside another function) and lambda expressions.</span></div>
<div class="line"><span class="lineno"> 1075</span>        self._pickle_cache = dict()</div>
<div class="line"><span class="lineno"> 1076</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno"> 1077</span>            <span class="comment"># Only set self._iterating to True if at least a batch</span></div>
<div class="line"><span class="lineno"> 1078</span>            <span class="comment"># was dispatched. In particular this covers the edge</span></div>
<div class="line"><span class="lineno"> 1079</span>            <span class="comment"># case of Parallel used with an exhausted iterator. If</span></div>
<div class="line"><span class="lineno"> 1080</span>            <span class="comment"># self._original_iterator is None, then this means either</span></div>
<div class="line"><span class="lineno"> 1081</span>            <span class="comment"># that pre_dispatch == &quot;all&quot;, n_jobs == 1 or that the first batch</span></div>
<div class="line"><span class="lineno"> 1082</span>            <span class="comment"># was very quick and its callback already dispatched all the</span></div>
<div class="line"><span class="lineno"> 1083</span>            <span class="comment"># remaining jobs.</span></div>
<div class="line"><span class="lineno"> 1084</span>            self._iterating = <span class="keyword">False</span></div>
<div class="line"><span class="lineno"> 1085</span>            <span class="keywordflow">if</span> self.dispatch_one_batch(iterator):</div>
<div class="line"><span class="lineno"> 1086</span>                self._iterating = self._original_iterator <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1087</span> </div>
<div class="line"><span class="lineno"> 1088</span>            <span class="keywordflow">while</span> self.dispatch_one_batch(iterator):</div>
<div class="line"><span class="lineno"> 1089</span>                <span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno"> 1090</span> </div>
<div class="line"><span class="lineno"> 1091</span>            <span class="keywordflow">if</span> pre_dispatch == <span class="stringliteral">&quot;all&quot;</span> <span class="keywordflow">or</span> n_jobs == 1:</div>
<div class="line"><span class="lineno"> 1092</span>                <span class="comment"># The iterable was consumed all at once by the above for loop.</span></div>
<div class="line"><span class="lineno"> 1093</span>                <span class="comment"># No need to wait for async callbacks to trigger to</span></div>
<div class="line"><span class="lineno"> 1094</span>                <span class="comment"># consumption.</span></div>
<div class="line"><span class="lineno"> 1095</span>                self._iterating = <span class="keyword">False</span></div>
<div class="line"><span class="lineno"> 1096</span> </div>
<div class="line"><span class="lineno"> 1097</span>            <span class="keyword">with</span> self._backend.retrieval_context():</div>
<div class="line"><span class="lineno"> 1098</span>                self.retrieve()</div>
<div class="line"><span class="lineno"> 1099</span>            <span class="comment"># Make sure that we get a last message telling us we are done</span></div>
<div class="line"><span class="lineno"> 1100</span>            elapsed_time = time.time() - self._start_time</div>
<div class="line"><span class="lineno"> 1101</span>            self._print(<span class="stringliteral">&#39;Done %3i out of %3i | elapsed: %s finished&#39;</span>,</div>
<div class="line"><span class="lineno"> 1102</span>                        (len(self._output), len(self._output),</div>
<div class="line"><span class="lineno"> 1103</span>                         short_format_time(elapsed_time)))</div>
<div class="line"><span class="lineno"> 1104</span>        <span class="keywordflow">finally</span>:</div>
<div class="line"><span class="lineno"> 1105</span>            <span class="keywordflow">if</span> hasattr(self._backend, <span class="stringliteral">&#39;stop_call&#39;</span>):</div>
<div class="line"><span class="lineno"> 1106</span>                self._backend.stop_call()</div>
<div class="line"><span class="lineno"> 1107</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> self._managed_backend:</div>
<div class="line"><span class="lineno"> 1108</span>                self._terminate_backend()</div>
<div class="line"><span class="lineno"> 1109</span>            self._jobs = list()</div>
<div class="line"><span class="lineno"> 1110</span>            self._pickle_cache = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1111</span>        output = self._output</div>
<div class="line"><span class="lineno"> 1112</span>        self._output = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1113</span>        <span class="keywordflow">return</span> output</div>
<div class="line"><span class="lineno"> 1114</span> </div>
<div class="ttc" id="a__lapack__subroutines_8h_html_a60590d91febfcb54d88443940cd5f23e"><div class="ttname"><a href="__lapack__subroutines_8h.html#a60590d91febfcb54d88443940cd5f23e">iter</a></div><div class="ttdeci">void int double int double double double double int int * iter</div><div class="ttdef"><b>Definition</b> _lapack_subroutines.h:623</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="aadf3cb72e227cc0d00c8f18b74d846e7" name="aadf3cb72e227cc0d00c8f18b74d846e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aadf3cb72e227cc0d00c8f18b74d846e7">&#9670;&#160;</a></span>__enter__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.__enter__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  763</span>    <span class="keyword">def </span>__enter__(self):</div>
<div class="line"><span class="lineno">  764</span>        self._managed_backend = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  765</span>        self._initialize_backend()</div>
<div class="line"><span class="lineno">  766</span>        <span class="keywordflow">return</span> self</div>
<div class="line"><span class="lineno">  767</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a48f995847159a9e489f5761bc7196d01" name="a48f995847159a9e489f5761bc7196d01"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a48f995847159a9e489f5761bc7196d01">&#9670;&#160;</a></span>__exit__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.__exit__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>exc_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>exc_value</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>traceback</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  768</span>    <span class="keyword">def </span>__exit__(self, exc_type, exc_value, traceback):</div>
<div class="line"><span class="lineno">  769</span>        self._terminate_backend()</div>
<div class="line"><span class="lineno">  770</span>        self._managed_backend = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  771</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a01e6729b1fedc51bdeeb70224a5508f4" name="a01e6729b1fedc51bdeeb70224a5508f4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01e6729b1fedc51bdeeb70224a5508f4">&#9670;&#160;</a></span>__repr__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.__repr__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1115</span>    <span class="keyword">def </span>__repr__(self):</div>
<div class="line"><span class="lineno"> 1116</span>        <span class="keywordflow">return</span> <span class="stringliteral">&#39;%s(n_jobs=%s)&#39;</span> % (self.__class__.__name__, self.n_jobs)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a4cbe2f0f9fca19526312991ef3391f0f" name="a4cbe2f0f9fca19526312991ef3391f0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4cbe2f0f9fca19526312991ef3391f0f">&#9670;&#160;</a></span>_dispatch()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._dispatch </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Queue the batch for computing, with or without multiprocessing

WARNING: this method is not thread-safe: it should be only called
indirectly via dispatch_one_batch.</pre> <div class="fragment"><div class="line"><span class="lineno">  801</span>    <span class="keyword">def </span>_dispatch(self, batch):</div>
<div class="line"><span class="lineno">  802</span>        <span class="stringliteral">&quot;&quot;&quot;Queue the batch for computing, with or without multiprocessing</span></div>
<div class="line"><span class="lineno">  803</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  804</span><span class="stringliteral">        WARNING: this method is not thread-safe: it should be only called</span></div>
<div class="line"><span class="lineno">  805</span><span class="stringliteral">        indirectly via dispatch_one_batch.</span></div>
<div class="line"><span class="lineno">  806</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  807</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  808</span>        <span class="comment"># If job.get() catches an exception, it closes the queue:</span></div>
<div class="line"><span class="lineno">  809</span>        <span class="keywordflow">if</span> self._aborting:</div>
<div class="line"><span class="lineno">  810</span>            <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno">  811</span> </div>
<div class="line"><span class="lineno">  812</span>        self.n_dispatched_tasks += len(batch)</div>
<div class="line"><span class="lineno">  813</span>        self.n_dispatched_batches += 1</div>
<div class="line"><span class="lineno">  814</span> </div>
<div class="line"><span class="lineno">  815</span>        dispatch_timestamp = time.time()</div>
<div class="line"><span class="lineno">  816</span>        cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)</div>
<div class="line"><span class="lineno">  817</span>        <span class="keyword">with</span> self._lock:</div>
<div class="line"><span class="lineno">  818</span>            job_idx = len(self._jobs)</div>
<div class="line"><span class="lineno">  819</span>            job = self._backend.apply_async(batch, callback=cb)</div>
<div class="line"><span class="lineno">  820</span>            <span class="comment"># A job can complete so quickly than its callback is</span></div>
<div class="line"><span class="lineno">  821</span>            <span class="comment"># called before we get here, causing self._jobs to</span></div>
<div class="line"><span class="lineno">  822</span>            <span class="comment"># grow. To ensure correct results ordering, .insert is</span></div>
<div class="line"><span class="lineno">  823</span>            <span class="comment"># used (rather than .append) in the following line</span></div>
<div class="line"><span class="lineno">  824</span>            self._jobs.insert(job_idx, job)</div>
<div class="line"><span class="lineno">  825</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a24345a2dd355b4c1995b5a24af672021" name="a24345a2dd355b4c1995b5a24af672021"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24345a2dd355b4c1995b5a24af672021">&#9670;&#160;</a></span>_effective_n_jobs()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._effective_n_jobs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  792</span>    <span class="keyword">def </span>_effective_n_jobs(self):</div>
<div class="line"><span class="lineno">  793</span>        <span class="keywordflow">if</span> self._backend:</div>
<div class="line"><span class="lineno">  794</span>            <span class="keywordflow">return</span> self._backend.effective_n_jobs(self.n_jobs)</div>
<div class="line"><span class="lineno">  795</span>        <span class="keywordflow">return</span> 1</div>
<div class="line"><span class="lineno">  796</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ace0b86aef7fc721dde4c290eca3f7bce" name="ace0b86aef7fc721dde4c290eca3f7bce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace0b86aef7fc721dde4c290eca3f7bce">&#9670;&#160;</a></span>_initialize_backend()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._initialize_backend </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Build a process or thread pool and return the number of workers</pre> <div class="fragment"><div class="line"><span class="lineno">  772</span>    <span class="keyword">def </span>_initialize_backend(self):</div>
<div class="line"><span class="lineno">  773</span>        <span class="stringliteral">&quot;&quot;&quot;Build a process or thread pool and return the number of workers&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  774</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  775</span>            n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,</div>
<div class="line"><span class="lineno">  776</span>                                             **self._backend_args)</div>
<div class="line"><span class="lineno">  777</span>            <span class="keywordflow">if</span> self.timeout <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> <span class="keywordflow">not</span> self._backend.supports_timeout:</div>
<div class="line"><span class="lineno">  778</span>                warnings.warn(</div>
<div class="line"><span class="lineno">  779</span>                    <span class="stringliteral">&#39;The backend class {!r} does not support timeout. &#39;</span></div>
<div class="line"><span class="lineno">  780</span>                    <span class="stringliteral">&quot;You have set &#39;timeout={}&#39; in Parallel but &quot;</span></div>
<div class="line"><span class="lineno">  781</span>                    <span class="stringliteral">&quot;the &#39;timeout&#39; parameter will not be used.&quot;</span>.format(</div>
<div class="line"><span class="lineno">  782</span>                        self._backend.__class__.__name__,</div>
<div class="line"><span class="lineno">  783</span>                        self.timeout))</div>
<div class="line"><span class="lineno">  784</span> </div>
<div class="line"><span class="lineno">  785</span>        <span class="keywordflow">except</span> FallbackToBackend <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  786</span>            <span class="comment"># Recursively initialize the backend in case of requested fallback.</span></div>
<div class="line"><span class="lineno">  787</span>            self._backend = e.backend</div>
<div class="line"><span class="lineno">  788</span>            n_jobs = self._initialize_backend()</div>
<div class="line"><span class="lineno">  789</span> </div>
<div class="line"><span class="lineno">  790</span>        <span class="keywordflow">return</span> n_jobs</div>
<div class="line"><span class="lineno">  791</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6f6324266200e8e2b1146ec85134b3dd" name="a6f6324266200e8e2b1146ec85134b3dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6f6324266200e8e2b1146ec85134b3dd">&#9670;&#160;</a></span>_print()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._print </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>msg</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>msg_args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Display the message on stout or stderr depending on verbosity</pre> <div class="fragment"><div class="line"><span class="lineno">  904</span>    <span class="keyword">def </span>_print(self, msg, msg_args):</div>
<div class="line"><span class="lineno">  905</span>        <span class="stringliteral">&quot;&quot;&quot;Display the message on stout or stderr depending on verbosity&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  906</span>        <span class="comment"># XXX: Not using the logger framework: need to</span></div>
<div class="line"><span class="lineno">  907</span>        <span class="comment"># learn to use logger better.</span></div>
<div class="line"><span class="lineno">  908</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.verbose:</div>
<div class="line"><span class="lineno">  909</span>            <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno">  910</span>        <span class="keywordflow">if</span> self.verbose &lt; 50:</div>
<div class="line"><span class="lineno">  911</span>            writer = sys.stderr.write</div>
<div class="line"><span class="lineno">  912</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  913</span>            writer = sys.stdout.write</div>
<div class="line"><span class="lineno">  914</span>        msg = msg % msg_args</div>
<div class="line"><span class="lineno">  915</span>        writer(<span class="stringliteral">&#39;[%s]: %s\n&#39;</span> % (self, msg))</div>
<div class="line"><span class="lineno">  916</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a662f48da88f58d22e92535d18dcaf939" name="a662f48da88f58d22e92535d18dcaf939"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a662f48da88f58d22e92535d18dcaf939">&#9670;&#160;</a></span>_terminate_backend()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._terminate_backend </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  797</span>    <span class="keyword">def </span>_terminate_backend(self):</div>
<div class="line"><span class="lineno">  798</span>        <span class="keywordflow">if</span> self._backend <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  799</span>            self._backend.terminate()</div>
<div class="line"><span class="lineno">  800</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab7cd4ff5b77c9672ec7b3525d3882833" name="ab7cd4ff5b77c9672ec7b3525d3882833"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab7cd4ff5b77c9672ec7b3525d3882833">&#9670;&#160;</a></span>dispatch_next()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.dispatch_next </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Dispatch more data for parallel processing

This method is meant to be called concurrently by the multiprocessing
callback. We rely on the thread-safety of dispatch_one_batch to protect
against concurrent consumption of the unprotected iterator.</pre> <div class="fragment"><div class="line"><span class="lineno">  826</span>    <span class="keyword">def </span>dispatch_next(self):</div>
<div class="line"><span class="lineno">  827</span>        <span class="stringliteral">&quot;&quot;&quot;Dispatch more data for parallel processing</span></div>
<div class="line"><span class="lineno">  828</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  829</span><span class="stringliteral">        This method is meant to be called concurrently by the multiprocessing</span></div>
<div class="line"><span class="lineno">  830</span><span class="stringliteral">        callback. We rely on the thread-safety of dispatch_one_batch to protect</span></div>
<div class="line"><span class="lineno">  831</span><span class="stringliteral">        against concurrent consumption of the unprotected iterator.</span></div>
<div class="line"><span class="lineno">  832</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  833</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  834</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.dispatch_one_batch(self._original_iterator):</div>
<div class="line"><span class="lineno">  835</span>            self._iterating = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  836</span>            self._original_iterator = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  837</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7257695d3890ae0eb1c7a0dd3e380f87" name="a7257695d3890ae0eb1c7a0dd3e380f87"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7257695d3890ae0eb1c7a0dd3e380f87">&#9670;&#160;</a></span>dispatch_one_batch()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.dispatch_one_batch </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>iterator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Prefetch the tasks for the next batch and dispatch them.

The effective size of the batch is computed here.
If there are no more jobs to dispatch, return False, else return True.

The iterator consumption and dispatching is protected by the same
lock so calling this function should be thread safe.</pre> <div class="fragment"><div class="line"><span class="lineno">  838</span>    <span class="keyword">def </span>dispatch_one_batch(self, iterator):</div>
<div class="line"><span class="lineno">  839</span>        <span class="stringliteral">&quot;&quot;&quot;Prefetch the tasks for the next batch and dispatch them.</span></div>
<div class="line"><span class="lineno">  840</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  841</span><span class="stringliteral">        The effective size of the batch is computed here.</span></div>
<div class="line"><span class="lineno">  842</span><span class="stringliteral">        If there are no more jobs to dispatch, return False, else return True.</span></div>
<div class="line"><span class="lineno">  843</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  844</span><span class="stringliteral">        The iterator consumption and dispatching is protected by the same</span></div>
<div class="line"><span class="lineno">  845</span><span class="stringliteral">        lock so calling this function should be thread safe.</span></div>
<div class="line"><span class="lineno">  846</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  847</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  848</span>        <span class="keywordflow">if</span> self.batch_size == <span class="stringliteral">&#39;auto&#39;</span>:</div>
<div class="line"><span class="lineno">  849</span>            batch_size = self._backend.compute_batch_size()</div>
<div class="line"><span class="lineno">  850</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  851</span>            <span class="comment"># Fixed batch size strategy</span></div>
<div class="line"><span class="lineno">  852</span>            batch_size = self.batch_size</div>
<div class="line"><span class="lineno">  853</span> </div>
<div class="line"><span class="lineno">  854</span>        <span class="keyword">with</span> self._lock:</div>
<div class="line"><span class="lineno">  855</span>            <span class="comment"># to ensure an even distribution of the workolad between workers,</span></div>
<div class="line"><span class="lineno">  856</span>            <span class="comment"># we look ahead in the original iterators more than batch_size</span></div>
<div class="line"><span class="lineno">  857</span>            <span class="comment"># tasks - However, we keep consuming only one batch at each</span></div>
<div class="line"><span class="lineno">  858</span>            <span class="comment"># dispatch_one_batch call. The extra tasks are stored in a local</span></div>
<div class="line"><span class="lineno">  859</span>            <span class="comment"># queue, _ready_batches, that is looked-up prior to re-consuming</span></div>
<div class="line"><span class="lineno">  860</span>            <span class="comment"># tasks from the origal iterator.</span></div>
<div class="line"><span class="lineno">  861</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  862</span>                tasks = self._ready_batches.get(block=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  863</span>            <span class="keywordflow">except</span> queue.Empty:</div>
<div class="line"><span class="lineno">  864</span>                <span class="comment"># slice the iterator n_jobs * batchsize items at a time. If the</span></div>
<div class="line"><span class="lineno">  865</span>                <span class="comment"># slice returns less than that, then the current batchsize puts</span></div>
<div class="line"><span class="lineno">  866</span>                <span class="comment"># too much weight on a subset of workers, while other may end</span></div>
<div class="line"><span class="lineno">  867</span>                <span class="comment"># up starving. So in this case, re-scale the batch size</span></div>
<div class="line"><span class="lineno">  868</span>                <span class="comment"># accordingly to distribute evenly the last items between all</span></div>
<div class="line"><span class="lineno">  869</span>                <span class="comment"># workers.</span></div>
<div class="line"><span class="lineno">  870</span>                n_jobs = self._cached_effective_n_jobs</div>
<div class="line"><span class="lineno">  871</span>                big_batch_size = batch_size * n_jobs</div>
<div class="line"><span class="lineno">  872</span> </div>
<div class="line"><span class="lineno">  873</span>                islice = list(itertools.islice(iterator, big_batch_size))</div>
<div class="line"><span class="lineno">  874</span>                <span class="keywordflow">if</span> len(islice) == 0:</div>
<div class="line"><span class="lineno">  875</span>                    <span class="keywordflow">return</span> <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  876</span>                <span class="keywordflow">elif</span> (iterator <span class="keywordflow">is</span> self._original_iterator</div>
<div class="line"><span class="lineno">  877</span>                      <span class="keywordflow">and</span> len(islice) &lt; big_batch_size):</div>
<div class="line"><span class="lineno">  878</span>                    <span class="comment"># We reached the end of the original iterator (unless</span></div>
<div class="line"><span class="lineno">  879</span>                    <span class="comment"># iterator is the ``pre_dispatch``-long initial slice of</span></div>
<div class="line"><span class="lineno">  880</span>                    <span class="comment"># the original iterator) -- decrease the batch size to</span></div>
<div class="line"><span class="lineno">  881</span>                    <span class="comment"># account for potential variance in the batches running</span></div>
<div class="line"><span class="lineno">  882</span>                    <span class="comment"># time.</span></div>
<div class="line"><span class="lineno">  883</span>                    final_batch_size = max(1, len(islice) // (10 * n_jobs))</div>
<div class="line"><span class="lineno">  884</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  885</span>                    final_batch_size = max(1, len(islice) // n_jobs)</div>
<div class="line"><span class="lineno">  886</span> </div>
<div class="line"><span class="lineno">  887</span>                <span class="comment"># enqueue n_jobs batches in a local queue</span></div>
<div class="line"><span class="lineno">  888</span>                <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(0, len(islice), final_batch_size):</div>
<div class="line"><span class="lineno">  889</span>                    tasks = BatchedCalls(islice[i:i + final_batch_size],</div>
<div class="line"><span class="lineno">  890</span>                                         self._backend.get_nested_backend(),</div>
<div class="line"><span class="lineno">  891</span>                                         self._reducer_callback,</div>
<div class="line"><span class="lineno">  892</span>                                         self._pickle_cache)</div>
<div class="line"><span class="lineno">  893</span>                    self._ready_batches.put(tasks)</div>
<div class="line"><span class="lineno">  894</span> </div>
<div class="line"><span class="lineno">  895</span>                <span class="comment"># finally, get one task.</span></div>
<div class="line"><span class="lineno">  896</span>                tasks = self._ready_batches.get(block=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  897</span>            <span class="keywordflow">if</span> len(tasks) == 0:</div>
<div class="line"><span class="lineno">  898</span>                <span class="comment"># No more tasks available in the iterator: tell caller to stop.</span></div>
<div class="line"><span class="lineno">  899</span>                <span class="keywordflow">return</span> <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  900</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  901</span>                self._dispatch(tasks)</div>
<div class="line"><span class="lineno">  902</span>                <span class="keywordflow">return</span> <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  903</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab339e2ead11d57d805acdc8367f890ea" name="ab339e2ead11d57d805acdc8367f890ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab339e2ead11d57d805acdc8367f890ea">&#9670;&#160;</a></span>print_progress()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.print_progress </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Display the process of the parallel execution only a fraction
   of time, controlled by self.verbose.
</pre> <div class="fragment"><div class="line"><span class="lineno">  917</span>    <span class="keyword">def </span>print_progress(self):</div>
<div class="line"><span class="lineno">  918</span>        <span class="stringliteral">&quot;&quot;&quot;Display the process of the parallel execution only a fraction</span></div>
<div class="line"><span class="lineno">  919</span><span class="stringliteral">           of time, controlled by self.verbose.</span></div>
<div class="line"><span class="lineno">  920</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  921</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.verbose:</div>
<div class="line"><span class="lineno">  922</span>            <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno">  923</span>        elapsed_time = time.time() - self._start_time</div>
<div class="line"><span class="lineno">  924</span> </div>
<div class="line"><span class="lineno">  925</span>        <span class="comment"># Original job iterator becomes None once it has been fully</span></div>
<div class="line"><span class="lineno">  926</span>        <span class="comment"># consumed : at this point we know the total number of jobs and we are</span></div>
<div class="line"><span class="lineno">  927</span>        <span class="comment"># able to display an estimation of the remaining time based on already</span></div>
<div class="line"><span class="lineno">  928</span>        <span class="comment"># completed jobs. Otherwise, we simply display the number of completed</span></div>
<div class="line"><span class="lineno">  929</span>        <span class="comment"># tasks.</span></div>
<div class="line"><span class="lineno">  930</span>        <span class="keywordflow">if</span> self._original_iterator <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  931</span>            <span class="keywordflow">if</span> _verbosity_filter(self.n_dispatched_batches, self.verbose):</div>
<div class="line"><span class="lineno">  932</span>                <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno">  933</span>            self._print(<span class="stringliteral">&#39;Done %3i tasks      | elapsed: %s&#39;</span>,</div>
<div class="line"><span class="lineno">  934</span>                        (self.n_completed_tasks,</div>
<div class="line"><span class="lineno">  935</span>                         short_format_time(elapsed_time), ))</div>
<div class="line"><span class="lineno">  936</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  937</span>            index = self.n_completed_tasks</div>
<div class="line"><span class="lineno">  938</span>            <span class="comment"># We are finished dispatching</span></div>
<div class="line"><span class="lineno">  939</span>            total_tasks = self.n_dispatched_tasks</div>
<div class="line"><span class="lineno">  940</span>            <span class="comment"># We always display the first loop</span></div>
<div class="line"><span class="lineno">  941</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> index == 0:</div>
<div class="line"><span class="lineno">  942</span>                <span class="comment"># Display depending on the number of remaining items</span></div>
<div class="line"><span class="lineno">  943</span>                <span class="comment"># A message as soon as we finish dispatching, cursor is 0</span></div>
<div class="line"><span class="lineno">  944</span>                cursor = (total_tasks - index + 1 -</div>
<div class="line"><span class="lineno">  945</span>                          self._pre_dispatch_amount)</div>
<div class="line"><span class="lineno">  946</span>                frequency = (total_tasks // self.verbose) + 1</div>
<div class="line"><span class="lineno">  947</span>                is_last_item = (index + 1 == total_tasks)</div>
<div class="line"><span class="lineno">  948</span>                <span class="keywordflow">if</span> (is_last_item <span class="keywordflow">or</span> cursor % frequency):</div>
<div class="line"><span class="lineno">  949</span>                    <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno">  950</span>            remaining_time = (elapsed_time / index) * \</div>
<div class="line"><span class="lineno">  951</span>                             (self.n_dispatched_tasks - index * 1.0)</div>
<div class="line"><span class="lineno">  952</span>            <span class="comment"># only display status if remaining time is greater or equal to 0</span></div>
<div class="line"><span class="lineno">  953</span>            self._print(<span class="stringliteral">&#39;Done %3i out of %3i | elapsed: %s remaining: %s&#39;</span>,</div>
<div class="line"><span class="lineno">  954</span>                        (index,</div>
<div class="line"><span class="lineno">  955</span>                         total_tasks,</div>
<div class="line"><span class="lineno">  956</span>                         short_format_time(elapsed_time),</div>
<div class="line"><span class="lineno">  957</span>                         short_format_time(remaining_time),</div>
<div class="line"><span class="lineno">  958</span>                         ))</div>
<div class="line"><span class="lineno">  959</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aad707177c2dddb16705da493131be515" name="aad707177c2dddb16705da493131be515"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aad707177c2dddb16705da493131be515">&#9670;&#160;</a></span>retrieve()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.retrieve </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  960</span>    <span class="keyword">def </span>retrieve(self):</div>
<div class="line"><span class="lineno">  961</span>        self._output = list()</div>
<div class="line"><span class="lineno">  962</span>        <span class="keywordflow">while</span> self._iterating <span class="keywordflow">or</span> len(self._jobs) &gt; 0:</div>
<div class="line"><span class="lineno">  963</span>            <span class="keywordflow">if</span> len(self._jobs) == 0:</div>
<div class="line"><span class="lineno">  964</span>                <span class="comment"># Wait for an async callback to dispatch new jobs</span></div>
<div class="line"><span class="lineno">  965</span>                time.sleep(0.01)</div>
<div class="line"><span class="lineno">  966</span>                <span class="keywordflow">continue</span></div>
<div class="line"><span class="lineno">  967</span>            <span class="comment"># We need to be careful: the job list can be filling up as</span></div>
<div class="line"><span class="lineno">  968</span>            <span class="comment"># we empty it and Python list are not thread-safe by default hence</span></div>
<div class="line"><span class="lineno">  969</span>            <span class="comment"># the use of the lock</span></div>
<div class="line"><span class="lineno">  970</span>            <span class="keyword">with</span> self._lock:</div>
<div class="line"><span class="lineno">  971</span>                job = self._jobs.pop(0)</div>
<div class="line"><span class="lineno">  972</span> </div>
<div class="line"><span class="lineno">  973</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  974</span>                <span class="keywordflow">if</span> getattr(self._backend, <span class="stringliteral">&#39;supports_timeout&#39;</span>, <span class="keyword">False</span>):</div>
<div class="line"><span class="lineno">  975</span>                    self._output.extend(job.get(timeout=self.timeout))</div>
<div class="line"><span class="lineno">  976</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  977</span>                    self._output.extend(job.get())</div>
<div class="line"><span class="lineno">  978</span> </div>
<div class="line"><span class="lineno">  979</span>            <span class="keywordflow">except</span> BaseException <span class="keyword">as</span> exception:</div>
<div class="line"><span class="lineno">  980</span>                <span class="comment"># Note: we catch any BaseException instead of just Exception</span></div>
<div class="line"><span class="lineno">  981</span>                <span class="comment"># instances to also include KeyboardInterrupt.</span></div>
<div class="line"><span class="lineno">  982</span> </div>
<div class="line"><span class="lineno">  983</span>                <span class="comment"># Stop dispatching any new job in the async callback thread</span></div>
<div class="line"><span class="lineno">  984</span>                self._aborting = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  985</span> </div>
<div class="line"><span class="lineno">  986</span>                <span class="comment"># If the backend allows it, cancel or kill remaining running</span></div>
<div class="line"><span class="lineno">  987</span>                <span class="comment"># tasks without waiting for the results as we will raise</span></div>
<div class="line"><span class="lineno">  988</span>                <span class="comment"># the exception we got back to the caller instead of returning</span></div>
<div class="line"><span class="lineno">  989</span>                <span class="comment"># any result.</span></div>
<div class="line"><span class="lineno">  990</span>                backend = self._backend</div>
<div class="line"><span class="lineno">  991</span>                <span class="keywordflow">if</span> (backend <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span></div>
<div class="line"><span class="lineno">  992</span>                        hasattr(backend, <span class="stringliteral">&#39;abort_everything&#39;</span>)):</div>
<div class="line"><span class="lineno">  993</span>                    <span class="comment"># If the backend is managed externally we need to make sure</span></div>
<div class="line"><span class="lineno">  994</span>                    <span class="comment"># to leave it in a working state to allow for future jobs</span></div>
<div class="line"><span class="lineno">  995</span>                    <span class="comment"># scheduling.</span></div>
<div class="line"><span class="lineno">  996</span>                    ensure_ready = self._managed_backend</div>
<div class="line"><span class="lineno">  997</span>                    backend.abort_everything(ensure_ready=ensure_ready)</div>
<div class="line"><span class="lineno">  998</span>                <span class="keywordflow">raise</span></div>
<div class="line"><span class="lineno">  999</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a2013b39466418456096803bb2aed8fc4" name="a2013b39466418456096803bb2aed8fc4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2013b39466418456096803bb2aed8fc4">&#9670;&#160;</a></span>_aborting</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._aborting</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a130645bd94d2c62cb84305c60b7d6dd5" name="a130645bd94d2c62cb84305c60b7d6dd5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a130645bd94d2c62cb84305c60b7d6dd5">&#9670;&#160;</a></span>_backend</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._backend</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a0a66fe24acb915168852147fb9d4950b" name="a0a66fe24acb915168852147fb9d4950b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a66fe24acb915168852147fb9d4950b">&#9670;&#160;</a></span>_backend_args</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._backend_args</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a4cbe19d44152ad9681155fc72c9426fd" name="a4cbe19d44152ad9681155fc72c9426fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4cbe19d44152ad9681155fc72c9426fd">&#9670;&#160;</a></span>_cached_effective_n_jobs</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._cached_effective_n_jobs</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a378961466accd2ae025782ce79ebf5b8" name="a378961466accd2ae025782ce79ebf5b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a378961466accd2ae025782ce79ebf5b8">&#9670;&#160;</a></span>_id</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._id</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="afcd9a2eae7c1ee0786bbddca8143d647" name="afcd9a2eae7c1ee0786bbddca8143d647"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afcd9a2eae7c1ee0786bbddca8143d647">&#9670;&#160;</a></span>_iterating</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._iterating</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a5894974362fef32b82d66f312a2347ea" name="a5894974362fef32b82d66f312a2347ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5894974362fef32b82d66f312a2347ea">&#9670;&#160;</a></span>_jobs</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._jobs</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ab20a877575bdcc945336205da3138219" name="ab20a877575bdcc945336205da3138219"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab20a877575bdcc945336205da3138219">&#9670;&#160;</a></span>_lock</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._lock</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aabfc96c79d9381404d545537070883a4" name="aabfc96c79d9381404d545537070883a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aabfc96c79d9381404d545537070883a4">&#9670;&#160;</a></span>_managed_backend</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._managed_backend</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="af35def4fd94856d6afc9c9d2c59aa504" name="af35def4fd94856d6afc9c9d2c59aa504"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af35def4fd94856d6afc9c9d2c59aa504">&#9670;&#160;</a></span>_original_iterator</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._original_iterator</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ad51d2cde7166aaafa6d69c1a28cc05e4" name="ad51d2cde7166aaafa6d69c1a28cc05e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad51d2cde7166aaafa6d69c1a28cc05e4">&#9670;&#160;</a></span>_output</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._output</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a2e260a9ddbfa8738dc59fb8b5fec8bae" name="a2e260a9ddbfa8738dc59fb8b5fec8bae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2e260a9ddbfa8738dc59fb8b5fec8bae">&#9670;&#160;</a></span>_pickle_cache</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._pickle_cache</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a97aaa384a45edd9848ac1b061c22b1f5" name="a97aaa384a45edd9848ac1b061c22b1f5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a97aaa384a45edd9848ac1b061c22b1f5">&#9670;&#160;</a></span>_pre_dispatch_amount</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._pre_dispatch_amount</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="abc8930a2089f12fb4b5c12b08e5e2ad6" name="abc8930a2089f12fb4b5c12b08e5e2ad6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abc8930a2089f12fb4b5c12b08e5e2ad6">&#9670;&#160;</a></span>_ready_batches</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._ready_batches</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a648f550237e74f35875e69c65c9a91aa" name="a648f550237e74f35875e69c65c9a91aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a648f550237e74f35875e69c65c9a91aa">&#9670;&#160;</a></span>_reducer_callback</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._reducer_callback</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a58c2d0096bf6fdf43c0567bae332e1b2" name="a58c2d0096bf6fdf43c0567bae332e1b2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a58c2d0096bf6fdf43c0567bae332e1b2">&#9670;&#160;</a></span>_start_time</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel._start_time</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="abb17d0040d42a0fbcba8035059977912" name="abb17d0040d42a0fbcba8035059977912"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb17d0040d42a0fbcba8035059977912">&#9670;&#160;</a></span>batch_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.batch_size</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a68961cae3e508b55ff56f8a8bc2e1b37" name="a68961cae3e508b55ff56f8a8bc2e1b37"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68961cae3e508b55ff56f8a8bc2e1b37">&#9670;&#160;</a></span>n_completed_tasks</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.n_completed_tasks</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a795e034c5c7a48d556a63ebd47c9181e" name="a795e034c5c7a48d556a63ebd47c9181e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a795e034c5c7a48d556a63ebd47c9181e">&#9670;&#160;</a></span>n_dispatched_batches</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.n_dispatched_batches</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4ed7c7e6b2cc7f1fa2c31245e195bd32" name="a4ed7c7e6b2cc7f1fa2c31245e195bd32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4ed7c7e6b2cc7f1fa2c31245e195bd32">&#9670;&#160;</a></span>n_dispatched_tasks</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.n_dispatched_tasks</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa9fce54124ba60d7fc9b2f83f3819306" name="aa9fce54124ba60d7fc9b2f83f3819306"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa9fce54124ba60d7fc9b2f83f3819306">&#9670;&#160;</a></span>n_jobs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.n_jobs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a53217086dabf65c881eb026885e5f69b" name="a53217086dabf65c881eb026885e5f69b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a53217086dabf65c881eb026885e5f69b">&#9670;&#160;</a></span>pre_dispatch</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.pre_dispatch</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7c5f6666c363e8fd8a857f07255dd499" name="a7c5f6666c363e8fd8a857f07255dd499"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7c5f6666c363e8fd8a857f07255dd499">&#9670;&#160;</a></span>timeout</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.timeout</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2c869582163997e78d4b4c0abce7b509" name="a2c869582163997e78d4b4c0abce7b509"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2c869582163997e78d4b4c0abce7b509">&#9670;&#160;</a></span>verbose</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">joblib.parallel.Parallel.verbose</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/rafael/Documents/GitHub/PUC-GCES-PY/Tp-GCS-Rafael-Augusto/venv/lib/python3.9/site-packages/joblib/<a class="el" href="joblib_2parallel_8py.html">parallel.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
