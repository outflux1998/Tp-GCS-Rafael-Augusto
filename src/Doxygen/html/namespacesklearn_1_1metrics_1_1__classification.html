<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.metrics._classification Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1metrics.html">metrics</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html">_classification</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.metrics._classification Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a346ed1eea7dc119562be2c93704eb299" id="r_a346ed1eea7dc119562be2c93704eb299"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a346ed1eea7dc119562be2c93704eb299">_check_zero_division</a> (zero_division)</td></tr>
<tr class="separator:a346ed1eea7dc119562be2c93704eb299"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab052693e5a75a63b200115e2c3949926" id="r_ab052693e5a75a63b200115e2c3949926"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#ab052693e5a75a63b200115e2c3949926">_check_targets</a> (y_true, y_pred)</td></tr>
<tr class="separator:ab052693e5a75a63b200115e2c3949926"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ccf4ae3c4a9b5d25728addac0464d08" id="r_a5ccf4ae3c4a9b5d25728addac0464d08"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a5ccf4ae3c4a9b5d25728addac0464d08">_weighted_sum</a> (sample_score, sample_weight, normalize=False)</td></tr>
<tr class="separator:a5ccf4ae3c4a9b5d25728addac0464d08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac65b5d5cebb2903179d198e758fee97c" id="r_ac65b5d5cebb2903179d198e758fee97c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#ac65b5d5cebb2903179d198e758fee97c">accuracy_score</a> (y_true, y_pred, *normalize=True, sample_weight=None)</td></tr>
<tr class="separator:ac65b5d5cebb2903179d198e758fee97c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9c0ac1227a02fe7b672aad2a98f301f" id="r_ae9c0ac1227a02fe7b672aad2a98f301f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#ae9c0ac1227a02fe7b672aad2a98f301f">confusion_matrix</a> (y_true, y_pred, *labels=None, sample_weight=None, normalize=None)</td></tr>
<tr class="separator:ae9c0ac1227a02fe7b672aad2a98f301f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1358dfb90c80aab40483bc7f2effa9c1" id="r_a1358dfb90c80aab40483bc7f2effa9c1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a1358dfb90c80aab40483bc7f2effa9c1">multilabel_confusion_matrix</a> (y_true, y_pred, *sample_weight=None, labels=None, samplewise=False)</td></tr>
<tr class="separator:a1358dfb90c80aab40483bc7f2effa9c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7bd039c8960d00f76b0b8cca4376b1c" id="r_ab7bd039c8960d00f76b0b8cca4376b1c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#ab7bd039c8960d00f76b0b8cca4376b1c">cohen_kappa_score</a> (<a class="el" href="__ufuncs__defs_8h.html#a438e4e72d1b4726377a10fdb64903c35">y1</a>, y2, *labels=None, weights=None, sample_weight=None)</td></tr>
<tr class="separator:ab7bd039c8960d00f76b0b8cca4376b1c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2d31021335d26ff38be78b103785ebf" id="r_ab2d31021335d26ff38be78b103785ebf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#ab2d31021335d26ff38be78b103785ebf">jaccard_score</a> (y_true, y_pred, *labels=None, pos_label=1, average=&quot;binary&quot;, sample_weight=None, zero_division=&quot;warn&quot;)</td></tr>
<tr class="separator:ab2d31021335d26ff38be78b103785ebf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac935fbac0b7b6eb7d9a7bc52ecb750c0" id="r_ac935fbac0b7b6eb7d9a7bc52ecb750c0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#ac935fbac0b7b6eb7d9a7bc52ecb750c0">matthews_corrcoef</a> (y_true, y_pred, *sample_weight=None)</td></tr>
<tr class="separator:ac935fbac0b7b6eb7d9a7bc52ecb750c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba3dbfc2fa006a79a93786b039a7cf47" id="r_aba3dbfc2fa006a79a93786b039a7cf47"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#aba3dbfc2fa006a79a93786b039a7cf47">zero_one_loss</a> (y_true, y_pred, *normalize=True, sample_weight=None)</td></tr>
<tr class="separator:aba3dbfc2fa006a79a93786b039a7cf47"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8907858d9147ef9e0b71391e04e04904" id="r_a8907858d9147ef9e0b71391e04e04904"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a8907858d9147ef9e0b71391e04e04904">f1_score</a> (y_true, y_pred, *labels=None, pos_label=1, average=&quot;binary&quot;, sample_weight=None, zero_division=&quot;warn&quot;)</td></tr>
<tr class="separator:a8907858d9147ef9e0b71391e04e04904"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa014456eb6be5e0e51a83a59bd4c8fa1" id="r_aa014456eb6be5e0e51a83a59bd4c8fa1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#aa014456eb6be5e0e51a83a59bd4c8fa1">fbeta_score</a> (y_true, y_pred, *beta, labels=None, pos_label=1, average=&quot;binary&quot;, sample_weight=None, zero_division=&quot;warn&quot;)</td></tr>
<tr class="separator:aa014456eb6be5e0e51a83a59bd4c8fa1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0aebe969f1ab1fec83528c39979d699a" id="r_a0aebe969f1ab1fec83528c39979d699a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a0aebe969f1ab1fec83528c39979d699a">_prf_divide</a> (numerator, denominator, metric, modifier, average, warn_for, zero_division=&quot;warn&quot;)</td></tr>
<tr class="separator:a0aebe969f1ab1fec83528c39979d699a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b2a6e4f3795b2fbc6aaa89025757de0" id="r_a0b2a6e4f3795b2fbc6aaa89025757de0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a0b2a6e4f3795b2fbc6aaa89025757de0">_warn_prf</a> (average, modifier, msg_start, result_size)</td></tr>
<tr class="separator:a0b2a6e4f3795b2fbc6aaa89025757de0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c8f32774ecf6aeebfa0b0b44cd33ec3" id="r_a3c8f32774ecf6aeebfa0b0b44cd33ec3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a3c8f32774ecf6aeebfa0b0b44cd33ec3">_check_set_wise_labels</a> (y_true, y_pred, average, labels, pos_label)</td></tr>
<tr class="separator:a3c8f32774ecf6aeebfa0b0b44cd33ec3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7abca91902c61236fccfb9f6610b2cfc" id="r_a7abca91902c61236fccfb9f6610b2cfc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a7abca91902c61236fccfb9f6610b2cfc">precision_recall_fscore_support</a> (y_true, y_pred, *beta=1.0, labels=None, pos_label=1, average=None, warn_for=(&quot;precision&quot;, &quot;recall&quot;, &quot;f-score&quot;), sample_weight=None, zero_division=&quot;warn&quot;)</td></tr>
<tr class="separator:a7abca91902c61236fccfb9f6610b2cfc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a555f0a846fe7c4c4cde12132fd5fdfa5" id="r_a555f0a846fe7c4c4cde12132fd5fdfa5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a555f0a846fe7c4c4cde12132fd5fdfa5">class_likelihood_ratios</a> (y_true, y_pred, *labels=None, sample_weight=None, raise_warning=True)</td></tr>
<tr class="separator:a555f0a846fe7c4c4cde12132fd5fdfa5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae96317cbd7ecabc2f028cf89a82f048" id="r_aae96317cbd7ecabc2f028cf89a82f048"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#aae96317cbd7ecabc2f028cf89a82f048">precision_score</a> (y_true, y_pred, *labels=None, pos_label=1, average=&quot;binary&quot;, sample_weight=None, zero_division=&quot;warn&quot;)</td></tr>
<tr class="separator:aae96317cbd7ecabc2f028cf89a82f048"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2ee2077fbf603931b794ddf7e84c641" id="r_ab2ee2077fbf603931b794ddf7e84c641"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#ab2ee2077fbf603931b794ddf7e84c641">recall_score</a> (y_true, y_pred, *labels=None, pos_label=1, average=&quot;binary&quot;, sample_weight=None, zero_division=&quot;warn&quot;)</td></tr>
<tr class="separator:ab2ee2077fbf603931b794ddf7e84c641"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0bcc3de25c081bab2890f44d0db71bd0" id="r_a0bcc3de25c081bab2890f44d0db71bd0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a0bcc3de25c081bab2890f44d0db71bd0">balanced_accuracy_score</a> (y_true, y_pred, *sample_weight=None, adjusted=False)</td></tr>
<tr class="separator:a0bcc3de25c081bab2890f44d0db71bd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd0e1ec22f72fb2ee674b6775cd106b9" id="r_abd0e1ec22f72fb2ee674b6775cd106b9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#abd0e1ec22f72fb2ee674b6775cd106b9">classification_report</a> (y_true, y_pred, *labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division=&quot;warn&quot;)</td></tr>
<tr class="separator:abd0e1ec22f72fb2ee674b6775cd106b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67ff64fc973d76f925985cdc2ab3b2f9" id="r_a67ff64fc973d76f925985cdc2ab3b2f9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a67ff64fc973d76f925985cdc2ab3b2f9">hamming_loss</a> (y_true, y_pred, *sample_weight=None)</td></tr>
<tr class="separator:a67ff64fc973d76f925985cdc2ab3b2f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a060a52ebda7e5eef61bf94a6c444acb7" id="r_a060a52ebda7e5eef61bf94a6c444acb7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a060a52ebda7e5eef61bf94a6c444acb7">log_loss</a> (y_true, y_pred, *<a class="el" href="__lapack__subroutines_8h.html#a57833d05f43fd1408080af6eec88fc43">eps</a>=&quot;auto&quot;, normalize=True, sample_weight=None, labels=None)</td></tr>
<tr class="separator:a060a52ebda7e5eef61bf94a6c444acb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c5755dc95b64fb760a15fa07a71e22e" id="r_a4c5755dc95b64fb760a15fa07a71e22e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a4c5755dc95b64fb760a15fa07a71e22e">hinge_loss</a> (y_true, pred_decision, *labels=None, sample_weight=None)</td></tr>
<tr class="separator:a4c5755dc95b64fb760a15fa07a71e22e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d9f66247b974cfdc112ee06b16fdd79" id="r_a2d9f66247b974cfdc112ee06b16fdd79"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__classification.html#a2d9f66247b974cfdc112ee06b16fdd79">brier_score_loss</a> (y_true, y_prob, *sample_weight=None, pos_label=None)</td></tr>
<tr class="separator:a2d9f66247b974cfdc112ee06b16fdd79"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Metrics to assess performance on classification task given class prediction.

Functions named as ``*_score`` return a scalar value to maximize: the higher
the better.

Function named as ``*_error`` or ``*_loss`` return a scalar value to minimize:
the lower the better.
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a3c8f32774ecf6aeebfa0b0b44cd33ec3" name="a3c8f32774ecf6aeebfa0b0b44cd33ec3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3c8f32774ecf6aeebfa0b0b44cd33ec3">&#9670;&#160;</a></span>_check_set_wise_labels()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification._check_set_wise_labels </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>labels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Validation associated with set-wise metrics.

Returns identified labels.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1365</span><span class="keyword">def </span>_check_set_wise_labels(y_true, y_pred, average, labels, pos_label):</div>
<div class="line"><span class="lineno"> 1366</span>    <span class="stringliteral">&quot;&quot;&quot;Validation associated with set-wise metrics.</span></div>
<div class="line"><span class="lineno"> 1367</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1368</span><span class="stringliteral">    Returns identified labels.</span></div>
<div class="line"><span class="lineno"> 1369</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1370</span>    average_options = (<span class="keywordtype">None</span>, <span class="stringliteral">&quot;micro&quot;</span>, <span class="stringliteral">&quot;macro&quot;</span>, <span class="stringliteral">&quot;weighted&quot;</span>, <span class="stringliteral">&quot;samples&quot;</span>)</div>
<div class="line"><span class="lineno"> 1371</span>    <span class="keywordflow">if</span> average <span class="keywordflow">not</span> <span class="keywordflow">in</span> average_options <span class="keywordflow">and</span> average != <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno"> 1372</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;average has to be one of &quot;</span> + str(average_options))</div>
<div class="line"><span class="lineno"> 1373</span> </div>
<div class="line"><span class="lineno"> 1374</span>    y_type, y_true, y_pred = _check_targets(y_true, y_pred)</div>
<div class="line"><span class="lineno"> 1375</span>    <span class="comment"># Convert to Python primitive type to avoid NumPy type / Python str</span></div>
<div class="line"><span class="lineno"> 1376</span>    <span class="comment"># comparison. See https://github.com/numpy/numpy/issues/6784</span></div>
<div class="line"><span class="lineno"> 1377</span>    present_labels = unique_labels(y_true, y_pred).tolist()</div>
<div class="line"><span class="lineno"> 1378</span>    <span class="keywordflow">if</span> average == <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno"> 1379</span>        <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno"> 1380</span>            <span class="keywordflow">if</span> pos_label <span class="keywordflow">not</span> <span class="keywordflow">in</span> present_labels:</div>
<div class="line"><span class="lineno"> 1381</span>                <span class="keywordflow">if</span> len(present_labels) &gt;= 2:</div>
<div class="line"><span class="lineno"> 1382</span>                    <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1383</span>                        f<span class="stringliteral">&quot;pos_label={pos_label} is not a valid label. It &quot;</span></div>
<div class="line"><span class="lineno"> 1384</span>                        f<span class="stringliteral">&quot;should be one of {present_labels}&quot;</span></div>
<div class="line"><span class="lineno"> 1385</span>                    )</div>
<div class="line"><span class="lineno"> 1386</span>            labels = [pos_label]</div>
<div class="line"><span class="lineno"> 1387</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1388</span>            average_options = list(average_options)</div>
<div class="line"><span class="lineno"> 1389</span>            <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;multiclass&quot;</span>:</div>
<div class="line"><span class="lineno"> 1390</span>                average_options.remove(<span class="stringliteral">&quot;samples&quot;</span>)</div>
<div class="line"><span class="lineno"> 1391</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1392</span>                <span class="stringliteral">&quot;Target is %s but average=&#39;binary&#39;. Please &quot;</span></div>
<div class="line"><span class="lineno"> 1393</span>                <span class="stringliteral">&quot;choose another average setting, one of %r.&quot;</span> % (y_type, average_options)</div>
<div class="line"><span class="lineno"> 1394</span>            )</div>
<div class="line"><span class="lineno"> 1395</span>    <span class="keywordflow">elif</span> pos_label <span class="keywordflow">not</span> <span class="keywordflow">in</span> (<span class="keywordtype">None</span>, 1):</div>
<div class="line"><span class="lineno"> 1396</span>        warnings.warn(</div>
<div class="line"><span class="lineno"> 1397</span>            <span class="stringliteral">&quot;Note that pos_label (set to %r) is ignored when &quot;</span></div>
<div class="line"><span class="lineno"> 1398</span>            <span class="stringliteral">&quot;average != &#39;binary&#39; (got %r). You may use &quot;</span></div>
<div class="line"><span class="lineno"> 1399</span>            <span class="stringliteral">&quot;labels=[pos_label] to specify a single positive class.&quot;</span></div>
<div class="line"><span class="lineno"> 1400</span>            % (pos_label, average),</div>
<div class="line"><span class="lineno"> 1401</span>            UserWarning,</div>
<div class="line"><span class="lineno"> 1402</span>        )</div>
<div class="line"><span class="lineno"> 1403</span>    <span class="keywordflow">return</span> labels</div>
<div class="line"><span class="lineno"> 1404</span> </div>
<div class="line"><span class="lineno"> 1405</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab052693e5a75a63b200115e2c3949926" name="ab052693e5a75a63b200115e2c3949926"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab052693e5a75a63b200115e2c3949926">&#9670;&#160;</a></span>_check_targets()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification._check_targets </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Check that y_true and y_pred belong to the same classification task.

This converts multiclass or binary types to a common shape, and raises a
ValueError for a mix of multilabel and multiclass targets, a mix of
multilabel formats, for the presence of continuous-valued or multioutput
targets, or for targets of different lengths.

Column vectors are squeezed to 1d, while multilabel formats are returned
as CSR sparse label indicators.

Parameters
----------
y_true : array-like

y_pred : array-like

Returns
-------
type_true : one of {'multilabel-indicator', 'multiclass', 'binary'}
    The type of the true target data, as output by
    ``utils.multiclass.type_of_target``.

y_true : array or indicator matrix

y_pred : array or indicator matrix
</pre> <div class="fragment"><div class="line"><span class="lineno">   59</span><span class="keyword">def </span>_check_targets(y_true, y_pred):</div>
<div class="line"><span class="lineno">   60</span>    <span class="stringliteral">&quot;&quot;&quot;Check that y_true and y_pred belong to the same classification task.</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">    This converts multiclass or binary types to a common shape, and raises a</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">    ValueError for a mix of multilabel and multiclass targets, a mix of</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    multilabel formats, for the presence of continuous-valued or multioutput</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">    targets, or for targets of different lengths.</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    Column vectors are squeezed to 1d, while multilabel formats are returned</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">    as CSR sparse label indicators.</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">    y_true : array-like</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">    y_pred : array-like</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">    type_true : one of {&#39;multilabel-indicator&#39;, &#39;multiclass&#39;, &#39;binary&#39;}</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">        The type of the true target data, as output by</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">        ``utils.multiclass.type_of_target``.</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">    y_true : array or indicator matrix</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral">    y_pred : array or indicator matrix</span></div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   86</span>    check_consistent_length(y_true, y_pred)</div>
<div class="line"><span class="lineno">   87</span>    type_true = type_of_target(y_true, input_name=<span class="stringliteral">&quot;y_true&quot;</span>)</div>
<div class="line"><span class="lineno">   88</span>    type_pred = type_of_target(y_pred, input_name=<span class="stringliteral">&quot;y_pred&quot;</span>)</div>
<div class="line"><span class="lineno">   89</span> </div>
<div class="line"><span class="lineno">   90</span>    y_type = {type_true, type_pred}</div>
<div class="line"><span class="lineno">   91</span>    <span class="keywordflow">if</span> y_type == {<span class="stringliteral">&quot;binary&quot;</span>, <span class="stringliteral">&quot;multiclass&quot;</span>}:</div>
<div class="line"><span class="lineno">   92</span>        y_type = {<span class="stringliteral">&quot;multiclass&quot;</span>}</div>
<div class="line"><span class="lineno">   93</span> </div>
<div class="line"><span class="lineno">   94</span>    <span class="keywordflow">if</span> len(y_type) &gt; 1:</div>
<div class="line"><span class="lineno">   95</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">   96</span>            <span class="stringliteral">&quot;Classification metrics can&#39;t handle a mix of {0} and {1} targets&quot;</span>.format(</div>
<div class="line"><span class="lineno">   97</span>                type_true, type_pred</div>
<div class="line"><span class="lineno">   98</span>            )</div>
<div class="line"><span class="lineno">   99</span>        )</div>
<div class="line"><span class="lineno">  100</span> </div>
<div class="line"><span class="lineno">  101</span>    <span class="comment"># We can&#39;t have more than one value on y_type =&gt; The set is no more needed</span></div>
<div class="line"><span class="lineno">  102</span>    y_type = y_type.pop()</div>
<div class="line"><span class="lineno">  103</span> </div>
<div class="line"><span class="lineno">  104</span>    <span class="comment"># No metrics support &quot;multiclass-multioutput&quot; format</span></div>
<div class="line"><span class="lineno">  105</span>    <span class="keywordflow">if</span> y_type <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&quot;binary&quot;</span>, <span class="stringliteral">&quot;multiclass&quot;</span>, <span class="stringliteral">&quot;multilabel-indicator&quot;</span>]:</div>
<div class="line"><span class="lineno">  106</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;{0} is not supported&quot;</span>.format(y_type))</div>
<div class="line"><span class="lineno">  107</span> </div>
<div class="line"><span class="lineno">  108</span>    <span class="keywordflow">if</span> y_type <span class="keywordflow">in</span> [<span class="stringliteral">&quot;binary&quot;</span>, <span class="stringliteral">&quot;multiclass&quot;</span>]:</div>
<div class="line"><span class="lineno">  109</span>        y_true = column_or_1d(y_true)</div>
<div class="line"><span class="lineno">  110</span>        y_pred = column_or_1d(y_pred)</div>
<div class="line"><span class="lineno">  111</span>        <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno">  112</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  113</span>                unique_values = np.union1d(y_true, y_pred)</div>
<div class="line"><span class="lineno">  114</span>            <span class="keywordflow">except</span> TypeError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  115</span>                <span class="comment"># We expect y_true and y_pred to be of the same data type.</span></div>
<div class="line"><span class="lineno">  116</span>                <span class="comment"># If `y_true` was provided to the classifier as strings,</span></div>
<div class="line"><span class="lineno">  117</span>                <span class="comment"># `y_pred` given by the classifier will also be encoded with</span></div>
<div class="line"><span class="lineno">  118</span>                <span class="comment"># strings. So we raise a meaningful error</span></div>
<div class="line"><span class="lineno">  119</span>                <span class="keywordflow">raise</span> TypeError(</div>
<div class="line"><span class="lineno">  120</span>                    <span class="stringliteral">&quot;Labels in y_true and y_pred should be of the same type. &quot;</span></div>
<div class="line"><span class="lineno">  121</span>                    f<span class="stringliteral">&quot;Got y_true={np.unique(y_true)} and &quot;</span></div>
<div class="line"><span class="lineno">  122</span>                    f<span class="stringliteral">&quot;y_pred={np.unique(y_pred)}. Make sure that the &quot;</span></div>
<div class="line"><span class="lineno">  123</span>                    <span class="stringliteral">&quot;predictions provided by the classifier coincides with &quot;</span></div>
<div class="line"><span class="lineno">  124</span>                    <span class="stringliteral">&quot;the true labels.&quot;</span></div>
<div class="line"><span class="lineno">  125</span>                ) <span class="keyword">from</span> e</div>
<div class="line"><span class="lineno">  126</span>            <span class="keywordflow">if</span> len(unique_values) &gt; 2:</div>
<div class="line"><span class="lineno">  127</span>                y_type = <span class="stringliteral">&quot;multiclass&quot;</span></div>
<div class="line"><span class="lineno">  128</span> </div>
<div class="line"><span class="lineno">  129</span>    <span class="keywordflow">if</span> y_type.startswith(<span class="stringliteral">&quot;multilabel&quot;</span>):</div>
<div class="line"><span class="lineno">  130</span>        y_true = csr_matrix(y_true)</div>
<div class="line"><span class="lineno">  131</span>        y_pred = csr_matrix(y_pred)</div>
<div class="line"><span class="lineno">  132</span>        y_type = <span class="stringliteral">&quot;multilabel-indicator&quot;</span></div>
<div class="line"><span class="lineno">  133</span> </div>
<div class="line"><span class="lineno">  134</span>    <span class="keywordflow">return</span> y_type, y_true, y_pred</div>
<div class="line"><span class="lineno">  135</span> </div>
<div class="line"><span class="lineno">  136</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a346ed1eea7dc119562be2c93704eb299" name="a346ed1eea7dc119562be2c93704eb299"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a346ed1eea7dc119562be2c93704eb299">&#9670;&#160;</a></span>_check_zero_division()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification._check_zero_division </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zero_division</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   49</span><span class="keyword">def </span>_check_zero_division(zero_division):</div>
<div class="line"><span class="lineno">   50</span>    <span class="keywordflow">if</span> isinstance(zero_division, str) <span class="keywordflow">and</span> zero_division == <span class="stringliteral">&quot;warn&quot;</span>:</div>
<div class="line"><span class="lineno">   51</span>        <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno">   52</span>    <span class="keywordflow">elif</span> isinstance(zero_division, (int, float)) <span class="keywordflow">and</span> zero_division <span class="keywordflow">in</span> [0, 1]:</div>
<div class="line"><span class="lineno">   53</span>        <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno">   54</span>    <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">   55</span>        <span class="stringliteral">&#39;Got zero_division={0}. Must be one of [&quot;warn&quot;, 0, 1]&#39;</span>.format(zero_division)</div>
<div class="line"><span class="lineno">   56</span>    )</div>
<div class="line"><span class="lineno">   57</span> </div>
<div class="line"><span class="lineno">   58</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0aebe969f1ab1fec83528c39979d699a" name="a0aebe969f1ab1fec83528c39979d699a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0aebe969f1ab1fec83528c39979d699a">&#9670;&#160;</a></span>_prf_divide()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification._prf_divide </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>numerator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>denominator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>metric</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>modifier</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>warn_for</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zero_division</em> = <code>&quot;warn&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Performs division and handles divide-by-zero.

On zero-division, sets the corresponding result elements equal to
0 or 1 (according to ``zero_division``). Plus, if
``zero_division != "warn"`` raises a warning.

The metric, modifier and average arguments are used only for determining
an appropriate warning.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1303</span>):</div>
<div class="line"><span class="lineno"> 1304</span>    <span class="stringliteral">&quot;&quot;&quot;Performs division and handles divide-by-zero.</span></div>
<div class="line"><span class="lineno"> 1305</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1306</span><span class="stringliteral">    On zero-division, sets the corresponding result elements equal to</span></div>
<div class="line"><span class="lineno"> 1307</span><span class="stringliteral">    0 or 1 (according to ``zero_division``). Plus, if</span></div>
<div class="line"><span class="lineno"> 1308</span><span class="stringliteral">    ``zero_division != &quot;warn&quot;`` raises a warning.</span></div>
<div class="line"><span class="lineno"> 1309</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1310</span><span class="stringliteral">    The metric, modifier and average arguments are used only for determining</span></div>
<div class="line"><span class="lineno"> 1311</span><span class="stringliteral">    an appropriate warning.</span></div>
<div class="line"><span class="lineno"> 1312</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1313</span>    mask = denominator == 0.0</div>
<div class="line"><span class="lineno"> 1314</span>    denominator = denominator.copy()</div>
<div class="line"><span class="lineno"> 1315</span>    denominator[mask] = 1  <span class="comment"># avoid infs/nans</span></div>
<div class="line"><span class="lineno"> 1316</span>    result = numerator / denominator</div>
<div class="line"><span class="lineno"> 1317</span> </div>
<div class="line"><span class="lineno"> 1318</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.any(mask):</div>
<div class="line"><span class="lineno"> 1319</span>        <span class="keywordflow">return</span> result</div>
<div class="line"><span class="lineno"> 1320</span> </div>
<div class="line"><span class="lineno"> 1321</span>    <span class="comment"># if ``zero_division=1``, set those with denominator == 0 equal to 1</span></div>
<div class="line"><span class="lineno"> 1322</span>    result[mask] = 0.0 <span class="keywordflow">if</span> zero_division <span class="keywordflow">in</span> [<span class="stringliteral">&quot;warn&quot;</span>, 0] <span class="keywordflow">else</span> 1.0</div>
<div class="line"><span class="lineno"> 1323</span> </div>
<div class="line"><span class="lineno"> 1324</span>    <span class="comment"># the user will be removing warnings if zero_division is set to something</span></div>
<div class="line"><span class="lineno"> 1325</span>    <span class="comment"># different than its default value. If we are computing only f-score</span></div>
<div class="line"><span class="lineno"> 1326</span>    <span class="comment"># the warning will be raised only if precision and recall are ill-defined</span></div>
<div class="line"><span class="lineno"> 1327</span>    <span class="keywordflow">if</span> zero_division != <span class="stringliteral">&quot;warn&quot;</span> <span class="keywordflow">or</span> metric <span class="keywordflow">not</span> <span class="keywordflow">in</span> warn_for:</div>
<div class="line"><span class="lineno"> 1328</span>        <span class="keywordflow">return</span> result</div>
<div class="line"><span class="lineno"> 1329</span> </div>
<div class="line"><span class="lineno"> 1330</span>    <span class="comment"># build appropriate warning</span></div>
<div class="line"><span class="lineno"> 1331</span>    <span class="comment"># E.g. &quot;Precision and F-score are ill-defined and being set to 0.0 in</span></div>
<div class="line"><span class="lineno"> 1332</span>    <span class="comment"># labels with no predicted samples. Use ``zero_division`` parameter to</span></div>
<div class="line"><span class="lineno"> 1333</span>    <span class="comment"># control this behavior.&quot;</span></div>
<div class="line"><span class="lineno"> 1334</span> </div>
<div class="line"><span class="lineno"> 1335</span>    <span class="keywordflow">if</span> metric <span class="keywordflow">in</span> warn_for <span class="keywordflow">and</span> <span class="stringliteral">&quot;f-score&quot;</span> <span class="keywordflow">in</span> warn_for:</div>
<div class="line"><span class="lineno"> 1336</span>        msg_start = <span class="stringliteral">&quot;{0} and F-score are&quot;</span>.format(metric.title())</div>
<div class="line"><span class="lineno"> 1337</span>    <span class="keywordflow">elif</span> metric <span class="keywordflow">in</span> warn_for:</div>
<div class="line"><span class="lineno"> 1338</span>        msg_start = <span class="stringliteral">&quot;{0} is&quot;</span>.format(metric.title())</div>
<div class="line"><span class="lineno"> 1339</span>    <span class="keywordflow">elif</span> <span class="stringliteral">&quot;f-score&quot;</span> <span class="keywordflow">in</span> warn_for:</div>
<div class="line"><span class="lineno"> 1340</span>        msg_start = <span class="stringliteral">&quot;F-score is&quot;</span></div>
<div class="line"><span class="lineno"> 1341</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1342</span>        <span class="keywordflow">return</span> result</div>
<div class="line"><span class="lineno"> 1343</span> </div>
<div class="line"><span class="lineno"> 1344</span>    _warn_prf(average, modifier, msg_start, len(result))</div>
<div class="line"><span class="lineno"> 1345</span> </div>
<div class="line"><span class="lineno"> 1346</span>    <span class="keywordflow">return</span> result</div>
<div class="line"><span class="lineno"> 1347</span> </div>
<div class="line"><span class="lineno"> 1348</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0b2a6e4f3795b2fbc6aaa89025757de0" name="a0b2a6e4f3795b2fbc6aaa89025757de0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b2a6e4f3795b2fbc6aaa89025757de0">&#9670;&#160;</a></span>_warn_prf()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification._warn_prf </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>modifier</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>msg_start</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>result_size</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1349</span><span class="keyword">def </span>_warn_prf(average, modifier, msg_start, result_size):</div>
<div class="line"><span class="lineno"> 1350</span>    axis0, axis1 = <span class="stringliteral">&quot;sample&quot;</span>, <span class="stringliteral">&quot;label&quot;</span></div>
<div class="line"><span class="lineno"> 1351</span>    <span class="keywordflow">if</span> average == <span class="stringliteral">&quot;samples&quot;</span>:</div>
<div class="line"><span class="lineno"> 1352</span>        axis0, axis1 = axis1, axis0</div>
<div class="line"><span class="lineno"> 1353</span>    msg = (</div>
<div class="line"><span class="lineno"> 1354</span>        <span class="stringliteral">&quot;{0} ill-defined and being set to 0.0 {{0}} &quot;</span></div>
<div class="line"><span class="lineno"> 1355</span>        <span class="stringliteral">&quot;no {1} {2}s. Use `zero_division` parameter to control&quot;</span></div>
<div class="line"><span class="lineno"> 1356</span>        <span class="stringliteral">&quot; this behavior.&quot;</span>.format(msg_start, modifier, axis0)</div>
<div class="line"><span class="lineno"> 1357</span>    )</div>
<div class="line"><span class="lineno"> 1358</span>    <span class="keywordflow">if</span> result_size == 1:</div>
<div class="line"><span class="lineno"> 1359</span>        msg = msg.format(<span class="stringliteral">&quot;due to&quot;</span>)</div>
<div class="line"><span class="lineno"> 1360</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1361</span>        msg = msg.format(<span class="stringliteral">&quot;in {0}s with&quot;</span>.format(axis1))</div>
<div class="line"><span class="lineno"> 1362</span>    warnings.warn(msg, UndefinedMetricWarning, stacklevel=2)</div>
<div class="line"><span class="lineno"> 1363</span> </div>
<div class="line"><span class="lineno"> 1364</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5ccf4ae3c4a9b5d25728addac0464d08" name="a5ccf4ae3c4a9b5d25728addac0464d08"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ccf4ae3c4a9b5d25728addac0464d08">&#9670;&#160;</a></span>_weighted_sum()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification._weighted_sum </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  137</span><span class="keyword">def </span>_weighted_sum(sample_score, sample_weight, normalize=False):</div>
<div class="line"><span class="lineno">  138</span>    <span class="keywordflow">if</span> normalize:</div>
<div class="line"><span class="lineno">  139</span>        <span class="keywordflow">return</span> np.average(sample_score, weights=sample_weight)</div>
<div class="line"><span class="lineno">  140</span>    <span class="keywordflow">elif</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  141</span>        <span class="keywordflow">return</span> np.dot(sample_score, sample_weight)</div>
<div class="line"><span class="lineno">  142</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  143</span>        <span class="keywordflow">return</span> sample_score.sum()</div>
<div class="line"><span class="lineno">  144</span> </div>
<div class="line"><span class="lineno">  145</span> </div>
<div class="line"><span class="lineno">  146</span><span class="preprocessor">@validate_params</span>(</div>
<div class="line"><span class="lineno">  147</span>    {</div>
<div class="line"><span class="lineno">  148</span>        <span class="stringliteral">&quot;y_true&quot;</span>: [<span class="stringliteral">&quot;array-like&quot;</span>, <span class="stringliteral">&quot;sparse matrix&quot;</span>],</div>
<div class="line"><span class="lineno">  149</span>        <span class="stringliteral">&quot;y_pred&quot;</span>: [<span class="stringliteral">&quot;array-like&quot;</span>, <span class="stringliteral">&quot;sparse matrix&quot;</span>],</div>
<div class="line"><span class="lineno">  150</span>        <span class="stringliteral">&quot;normalize&quot;</span>: [<span class="stringliteral">&quot;boolean&quot;</span>],</div>
<div class="line"><span class="lineno">  151</span>        <span class="stringliteral">&quot;sample_weight&quot;</span>: [<span class="stringliteral">&quot;array-like&quot;</span>, <span class="keywordtype">None</span>],</div>
<div class="line"><span class="lineno">  152</span>    }</div>
<div class="line"><span class="lineno">  153</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ac65b5d5cebb2903179d198e758fee97c" name="ac65b5d5cebb2903179d198e758fee97c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac65b5d5cebb2903179d198e758fee97c">&#9670;&#160;</a></span>accuracy_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.accuracy_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>normalize</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Accuracy classification score.

In multilabel classification, this function computes subset accuracy:
the set of labels predicted for a sample must *exactly* match the
corresponding set of labels in y_true.

Read more in the :ref:`User Guide &lt;accuracy_score&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) labels.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Predicted labels, as returned by a classifier.

normalize : bool, default=True
    If ``False``, return the number of correctly classified samples.
    Otherwise, return the fraction of correctly classified samples.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
score : float
    If ``normalize == True``, return the fraction of correctly
    classified samples (float), else returns the number of correctly
    classified samples (int).

    The best performance is 1 with ``normalize == True`` and the number
    of samples with ``normalize == False``.

See Also
--------
balanced_accuracy_score : Compute the balanced accuracy to deal with
    imbalanced datasets.
jaccard_score : Compute the Jaccard similarity coefficient score.
hamming_loss : Compute the average Hamming loss or Hamming distance between
    two sets of samples.
zero_one_loss : Compute the Zero-one classification loss. By default, the
    function will return the percentage of imperfectly predicted subsets.

Notes
-----
In binary classification, this function is equal to the `jaccard_score`
function.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import accuracy_score
&gt;&gt;&gt; y_pred = [0, 2, 1, 3]
&gt;&gt;&gt; y_true = [0, 1, 2, 3]
&gt;&gt;&gt; accuracy_score(y_true, y_pred)
0.5
&gt;&gt;&gt; accuracy_score(y_true, y_pred, normalize=False)
2

In the multilabel case with binary label indicators:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))
0.5
</pre> <div class="fragment"><div class="line"><span class="lineno">  154</span><span class="keyword">def </span>accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None):</div>
<div class="line"><span class="lineno">  155</span>    <span class="stringliteral">&quot;&quot;&quot;Accuracy classification score.</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">    In multilabel classification, this function computes subset accuracy:</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">    the set of labels predicted for a sample must *exactly* match the</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">    corresponding set of labels in y_true.</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;accuracy_score&gt;`.</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">        Ground truth (correct) labels.</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral">        Predicted labels, as returned by a classifier.</span></div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">    normalize : bool, default=True</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral">        If ``False``, return the number of correctly classified samples.</span></div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">        Otherwise, return the fraction of correctly classified samples.</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">    score : float</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">        If ``normalize == True``, return the fraction of correctly</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">        classified samples (float), else returns the number of correctly</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">        classified samples (int).</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">        The best performance is 1 with ``normalize == True`` and the number</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">        of samples with ``normalize == False``.</span></div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral">    balanced_accuracy_score : Compute the balanced accuracy to deal with</span></div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral">        imbalanced datasets.</span></div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">    jaccard_score : Compute the Jaccard similarity coefficient score.</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral">    hamming_loss : Compute the average Hamming loss or Hamming distance between</span></div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">        two sets of samples.</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">    zero_one_loss : Compute the Zero-one classification loss. By default, the</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral">        function will return the percentage of imperfectly predicted subsets.</span></div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral">    In binary classification, this function is equal to the `jaccard_score`</span></div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral">    function.</span></div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  203</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  204</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  205</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import accuracy_score</span></div>
<div class="line"><span class="lineno">  206</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 2, 1, 3]</span></div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 1, 2, 3]</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">    &gt;&gt;&gt; accuracy_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">    0.5</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">    &gt;&gt;&gt; accuracy_score(y_true, y_pred, normalize=False)</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">    2</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral">    In the multilabel case with binary label indicators:</span></div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">    &gt;&gt;&gt; accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">    0.5</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  219</span> </div>
<div class="line"><span class="lineno">  220</span>    <span class="comment"># Compute accuracy for each possible representation</span></div>
<div class="line"><span class="lineno">  221</span>    y_type, y_true, y_pred = _check_targets(y_true, y_pred)</div>
<div class="line"><span class="lineno">  222</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  223</span>    <span class="keywordflow">if</span> y_type.startswith(<span class="stringliteral">&quot;multilabel&quot;</span>):</div>
<div class="line"><span class="lineno">  224</span>        differing_labels = count_nonzero(y_true - y_pred, axis=1)</div>
<div class="line"><span class="lineno">  225</span>        score = differing_labels == 0</div>
<div class="line"><span class="lineno">  226</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  227</span>        score = y_true == y_pred</div>
<div class="line"><span class="lineno">  228</span> </div>
<div class="line"><span class="lineno">  229</span>    <span class="keywordflow">return</span> _weighted_sum(score, sample_weight, normalize)</div>
<div class="line"><span class="lineno">  230</span> </div>
<div class="line"><span class="lineno">  231</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0bcc3de25c081bab2890f44d0db71bd0" name="a0bcc3de25c081bab2890f44d0db71bd0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0bcc3de25c081bab2890f44d0db71bd0">&#9670;&#160;</a></span>balanced_accuracy_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.balanced_accuracy_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>adjusted</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the balanced accuracy.

The balanced accuracy in binary and multiclass classification problems to
deal with imbalanced datasets. It is defined as the average of recall
obtained on each class.

The best value is 1 and the worst value is 0 when ``adjusted=False``.

Read more in the :ref:`User Guide &lt;balanced_accuracy_score&gt;`.

.. versionadded:: 0.20

Parameters
----------
y_true : 1d array-like
    Ground truth (correct) target values.

y_pred : 1d array-like
    Estimated targets as returned by a classifier.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

adjusted : bool, default=False
    When true, the result is adjusted for chance, so that random
    performance would score 0, while keeping perfect performance at a score
    of 1.

Returns
-------
balanced_accuracy : float
    Balanced accuracy score.

See Also
--------
average_precision_score : Compute average precision (AP) from prediction
    scores.
precision_score : Compute the precision score.
recall_score : Compute the recall score.
roc_auc_score : Compute Area Under the Receiver Operating Characteristic
    Curve (ROC AUC) from prediction scores.

Notes
-----
Some literature promotes alternative definitions of balanced accuracy. Our
definition is equivalent to :func:`accuracy_score` with class-balanced
sample weights, and shares desirable properties with the binary case.
See the :ref:`User Guide &lt;balanced_accuracy_score&gt;`.

References
----------
.. [1] Brodersen, K.H.; Ong, C.S.; Stephan, K.E.; Buhmann, J.M. (2010).
       The balanced accuracy and its posterior distribution.
       Proceedings of the 20th International Conference on Pattern
       Recognition, 3121-24.
.. [2] John. D. Kelleher, Brian Mac Namee, Aoife D'Arcy, (2015).
       `Fundamentals of Machine Learning for Predictive Data Analytics:
       Algorithms, Worked Examples, and Case Studies
       &lt;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&gt;`_.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import balanced_accuracy_score
&gt;&gt;&gt; y_true = [0, 1, 0, 0, 1, 0]
&gt;&gt;&gt; y_pred = [0, 1, 0, 0, 0, 1]
&gt;&gt;&gt; balanced_accuracy_score(y_true, y_pred)
0.625
</pre> <div class="fragment"><div class="line"><span class="lineno"> 2111</span><span class="keyword">def </span>balanced_accuracy_score(y_true, y_pred, *, sample_weight=None, adjusted=False):</div>
<div class="line"><span class="lineno"> 2112</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the balanced accuracy.</span></div>
<div class="line"><span class="lineno"> 2113</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2114</span><span class="stringliteral">    The balanced accuracy in binary and multiclass classification problems to</span></div>
<div class="line"><span class="lineno"> 2115</span><span class="stringliteral">    deal with imbalanced datasets. It is defined as the average of recall</span></div>
<div class="line"><span class="lineno"> 2116</span><span class="stringliteral">    obtained on each class.</span></div>
<div class="line"><span class="lineno"> 2117</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2118</span><span class="stringliteral">    The best value is 1 and the worst value is 0 when ``adjusted=False``.</span></div>
<div class="line"><span class="lineno"> 2119</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2120</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;balanced_accuracy_score&gt;`.</span></div>
<div class="line"><span class="lineno"> 2121</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2122</span><span class="stringliteral">    .. versionadded:: 0.20</span></div>
<div class="line"><span class="lineno"> 2123</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2124</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 2125</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2126</span><span class="stringliteral">    y_true : 1d array-like</span></div>
<div class="line"><span class="lineno"> 2127</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 2128</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2129</span><span class="stringliteral">    y_pred : 1d array-like</span></div>
<div class="line"><span class="lineno"> 2130</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno"> 2131</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2132</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 2133</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 2134</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2135</span><span class="stringliteral">    adjusted : bool, default=False</span></div>
<div class="line"><span class="lineno"> 2136</span><span class="stringliteral">        When true, the result is adjusted for chance, so that random</span></div>
<div class="line"><span class="lineno"> 2137</span><span class="stringliteral">        performance would score 0, while keeping perfect performance at a score</span></div>
<div class="line"><span class="lineno"> 2138</span><span class="stringliteral">        of 1.</span></div>
<div class="line"><span class="lineno"> 2139</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2140</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 2141</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 2142</span><span class="stringliteral">    balanced_accuracy : float</span></div>
<div class="line"><span class="lineno"> 2143</span><span class="stringliteral">        Balanced accuracy score.</span></div>
<div class="line"><span class="lineno"> 2144</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2145</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 2146</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2147</span><span class="stringliteral">    average_precision_score : Compute average precision (AP) from prediction</span></div>
<div class="line"><span class="lineno"> 2148</span><span class="stringliteral">        scores.</span></div>
<div class="line"><span class="lineno"> 2149</span><span class="stringliteral">    precision_score : Compute the precision score.</span></div>
<div class="line"><span class="lineno"> 2150</span><span class="stringliteral">    recall_score : Compute the recall score.</span></div>
<div class="line"><span class="lineno"> 2151</span><span class="stringliteral">    roc_auc_score : Compute Area Under the Receiver Operating Characteristic</span></div>
<div class="line"><span class="lineno"> 2152</span><span class="stringliteral">        Curve (ROC AUC) from prediction scores.</span></div>
<div class="line"><span class="lineno"> 2153</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2154</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 2155</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 2156</span><span class="stringliteral">    Some literature promotes alternative definitions of balanced accuracy. Our</span></div>
<div class="line"><span class="lineno"> 2157</span><span class="stringliteral">    definition is equivalent to :func:`accuracy_score` with class-balanced</span></div>
<div class="line"><span class="lineno"> 2158</span><span class="stringliteral">    sample weights, and shares desirable properties with the binary case.</span></div>
<div class="line"><span class="lineno"> 2159</span><span class="stringliteral">    See the :ref:`User Guide &lt;balanced_accuracy_score&gt;`.</span></div>
<div class="line"><span class="lineno"> 2160</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2161</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 2162</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2163</span><span class="stringliteral">    .. [1] Brodersen, K.H.; Ong, C.S.; Stephan, K.E.; Buhmann, J.M. (2010).</span></div>
<div class="line"><span class="lineno"> 2164</span><span class="stringliteral">           The balanced accuracy and its posterior distribution.</span></div>
<div class="line"><span class="lineno"> 2165</span><span class="stringliteral">           Proceedings of the 20th International Conference on Pattern</span></div>
<div class="line"><span class="lineno"> 2166</span><span class="stringliteral">           Recognition, 3121-24.</span></div>
<div class="line"><span class="lineno"> 2167</span><span class="stringliteral">    .. [2] John. D. Kelleher, Brian Mac Namee, Aoife D&#39;Arcy, (2015).</span></div>
<div class="line"><span class="lineno"> 2168</span><span class="stringliteral">           `Fundamentals of Machine Learning for Predictive Data Analytics:</span></div>
<div class="line"><span class="lineno"> 2169</span><span class="stringliteral">           Algorithms, Worked Examples, and Case Studies</span></div>
<div class="line"><span class="lineno"> 2170</span><span class="stringliteral">           &lt;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&gt;`_.</span></div>
<div class="line"><span class="lineno"> 2171</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2172</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 2173</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2174</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import balanced_accuracy_score</span></div>
<div class="line"><span class="lineno"> 2175</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 1, 0, 0, 1, 0]</span></div>
<div class="line"><span class="lineno"> 2176</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 1, 0, 0, 0, 1]</span></div>
<div class="line"><span class="lineno"> 2177</span><span class="stringliteral">    &gt;&gt;&gt; balanced_accuracy_score(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 2178</span><span class="stringliteral">    0.625</span></div>
<div class="line"><span class="lineno"> 2179</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 2180</span>    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 2181</span>    <span class="keyword">with</span> np.errstate(divide=<span class="stringliteral">&quot;ignore&quot;</span>, invalid=<span class="stringliteral">&quot;ignore&quot;</span>):</div>
<div class="line"><span class="lineno"> 2182</span>        per_class = np.diag(C) / C.sum(axis=1)</div>
<div class="line"><span class="lineno"> 2183</span>    <span class="keywordflow">if</span> np.any(np.isnan(per_class)):</div>
<div class="line"><span class="lineno"> 2184</span>        warnings.warn(<span class="stringliteral">&quot;y_pred contains classes not in y_true&quot;</span>)</div>
<div class="line"><span class="lineno"> 2185</span>        per_class = per_class[~np.isnan(per_class)]</div>
<div class="line"><span class="lineno"> 2186</span>    score = np.mean(per_class)</div>
<div class="line"><span class="lineno"> 2187</span>    <span class="keywordflow">if</span> adjusted:</div>
<div class="line"><span class="lineno"> 2188</span>        n_classes = len(per_class)</div>
<div class="line"><span class="lineno"> 2189</span>        chance = 1 / n_classes</div>
<div class="line"><span class="lineno"> 2190</span>        score -= chance</div>
<div class="line"><span class="lineno"> 2191</span>        score /= 1 - chance</div>
<div class="line"><span class="lineno"> 2192</span>    <span class="keywordflow">return</span> score</div>
<div class="line"><span class="lineno"> 2193</span> </div>
<div class="line"><span class="lineno"> 2194</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2d9f66247b974cfdc112ee06b16fdd79" name="a2d9f66247b974cfdc112ee06b16fdd79"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d9f66247b974cfdc112ee06b16fdd79">&#9670;&#160;</a></span>brier_score_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.brier_score_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_prob</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the Brier score loss.

The smaller the Brier score loss, the better, hence the naming with "loss".
The Brier score measures the mean squared difference between the predicted
probability and the actual outcome. The Brier score always
takes on a value between zero and one, since this is the largest
possible difference between a predicted probability (which must be
between zero and one) and the actual outcome (which can take on values
of only 0 and 1). It can be decomposed as the sum of refinement loss and
calibration loss.

The Brier score is appropriate for binary and categorical outcomes that
can be structured as true or false, but is inappropriate for ordinal
variables which can take on three or more values (this is because the
Brier score assumes that all possible outcomes are equivalently
"distant" from one another). Which label is considered to be the positive
label is controlled via the parameter `pos_label`, which defaults to
the greater label unless `y_true` is all 0 or all -1, in which case
`pos_label` defaults to 1.

Read more in the :ref:`User Guide &lt;brier_score_loss&gt;`.

Parameters
----------
y_true : array of shape (n_samples,)
    True targets.

y_prob : array of shape (n_samples,)
    Probabilities of the positive class.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

pos_label : int or str, default=None
    Label of the positive class. `pos_label` will be inferred in the
    following manner:

    * if `y_true` in {-1, 1} or {0, 1}, `pos_label` defaults to 1;
    * else if `y_true` contains string, an error will be raised and
      `pos_label` should be explicitly specified;
    * otherwise, `pos_label` defaults to the greater label,
      i.e. `np.unique(y_true)[-1]`.

Returns
-------
score : float
    Brier score loss.

References
----------
.. [1] `Wikipedia entry for the Brier score
        &lt;https://en.wikipedia.org/wiki/Brier_score&gt;`_.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import brier_score_loss
&gt;&gt;&gt; y_true = np.array([0, 1, 1, 0])
&gt;&gt;&gt; y_true_categorical = np.array(["spam", "ham", "ham", "spam"])
&gt;&gt;&gt; y_prob = np.array([0.1, 0.9, 0.8, 0.3])
&gt;&gt;&gt; brier_score_loss(y_true, y_prob)
0.037...
&gt;&gt;&gt; brier_score_loss(y_true, 1-y_prob, pos_label=0)
0.037...
&gt;&gt;&gt; brier_score_loss(y_true_categorical, y_prob, pos_label="ham")
0.037...
&gt;&gt;&gt; brier_score_loss(y_true, np.array(y_prob) &gt; 0.5)
0.0
</pre> <div class="fragment"><div class="line"><span class="lineno"> 2803</span><span class="keyword">def </span>brier_score_loss(y_true, y_prob, *, sample_weight=None, pos_label=None):</div>
<div class="line"><span class="lineno"> 2804</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the Brier score loss.</span></div>
<div class="line"><span class="lineno"> 2805</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2806</span><span class="stringliteral">    The smaller the Brier score loss, the better, hence the naming with &quot;loss&quot;.</span></div>
<div class="line"><span class="lineno"> 2807</span><span class="stringliteral">    The Brier score measures the mean squared difference between the predicted</span></div>
<div class="line"><span class="lineno"> 2808</span><span class="stringliteral">    probability and the actual outcome. The Brier score always</span></div>
<div class="line"><span class="lineno"> 2809</span><span class="stringliteral">    takes on a value between zero and one, since this is the largest</span></div>
<div class="line"><span class="lineno"> 2810</span><span class="stringliteral">    possible difference between a predicted probability (which must be</span></div>
<div class="line"><span class="lineno"> 2811</span><span class="stringliteral">    between zero and one) and the actual outcome (which can take on values</span></div>
<div class="line"><span class="lineno"> 2812</span><span class="stringliteral">    of only 0 and 1). It can be decomposed as the sum of refinement loss and</span></div>
<div class="line"><span class="lineno"> 2813</span><span class="stringliteral">    calibration loss.</span></div>
<div class="line"><span class="lineno"> 2814</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2815</span><span class="stringliteral">    The Brier score is appropriate for binary and categorical outcomes that</span></div>
<div class="line"><span class="lineno"> 2816</span><span class="stringliteral">    can be structured as true or false, but is inappropriate for ordinal</span></div>
<div class="line"><span class="lineno"> 2817</span><span class="stringliteral">    variables which can take on three or more values (this is because the</span></div>
<div class="line"><span class="lineno"> 2818</span><span class="stringliteral">    Brier score assumes that all possible outcomes are equivalently</span></div>
<div class="line"><span class="lineno"> 2819</span><span class="stringliteral">    &quot;distant&quot; from one another). Which label is considered to be the positive</span></div>
<div class="line"><span class="lineno"> 2820</span><span class="stringliteral">    label is controlled via the parameter `pos_label`, which defaults to</span></div>
<div class="line"><span class="lineno"> 2821</span><span class="stringliteral">    the greater label unless `y_true` is all 0 or all -1, in which case</span></div>
<div class="line"><span class="lineno"> 2822</span><span class="stringliteral">    `pos_label` defaults to 1.</span></div>
<div class="line"><span class="lineno"> 2823</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2824</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;brier_score_loss&gt;`.</span></div>
<div class="line"><span class="lineno"> 2825</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2826</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 2827</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2828</span><span class="stringliteral">    y_true : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 2829</span><span class="stringliteral">        True targets.</span></div>
<div class="line"><span class="lineno"> 2830</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2831</span><span class="stringliteral">    y_prob : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 2832</span><span class="stringliteral">        Probabilities of the positive class.</span></div>
<div class="line"><span class="lineno"> 2833</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2834</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 2835</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 2836</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2837</span><span class="stringliteral">    pos_label : int or str, default=None</span></div>
<div class="line"><span class="lineno"> 2838</span><span class="stringliteral">        Label of the positive class. `pos_label` will be inferred in the</span></div>
<div class="line"><span class="lineno"> 2839</span><span class="stringliteral">        following manner:</span></div>
<div class="line"><span class="lineno"> 2840</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2841</span><span class="stringliteral">        * if `y_true` in {-1, 1} or {0, 1}, `pos_label` defaults to 1;</span></div>
<div class="line"><span class="lineno"> 2842</span><span class="stringliteral">        * else if `y_true` contains string, an error will be raised and</span></div>
<div class="line"><span class="lineno"> 2843</span><span class="stringliteral">          `pos_label` should be explicitly specified;</span></div>
<div class="line"><span class="lineno"> 2844</span><span class="stringliteral">        * otherwise, `pos_label` defaults to the greater label,</span></div>
<div class="line"><span class="lineno"> 2845</span><span class="stringliteral">          i.e. `np.unique(y_true)[-1]`.</span></div>
<div class="line"><span class="lineno"> 2846</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2847</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 2848</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 2849</span><span class="stringliteral">    score : float</span></div>
<div class="line"><span class="lineno"> 2850</span><span class="stringliteral">        Brier score loss.</span></div>
<div class="line"><span class="lineno"> 2851</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2852</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 2853</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2854</span><span class="stringliteral">    .. [1] `Wikipedia entry for the Brier score</span></div>
<div class="line"><span class="lineno"> 2855</span><span class="stringliteral">            &lt;https://en.wikipedia.org/wiki/Brier_score&gt;`_.</span></div>
<div class="line"><span class="lineno"> 2856</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2857</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 2858</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2859</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno"> 2860</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import brier_score_loss</span></div>
<div class="line"><span class="lineno"> 2861</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([0, 1, 1, 0])</span></div>
<div class="line"><span class="lineno"> 2862</span><span class="stringliteral">    &gt;&gt;&gt; y_true_categorical = np.array([&quot;spam&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;spam&quot;])</span></div>
<div class="line"><span class="lineno"> 2863</span><span class="stringliteral">    &gt;&gt;&gt; y_prob = np.array([0.1, 0.9, 0.8, 0.3])</span></div>
<div class="line"><span class="lineno"> 2864</span><span class="stringliteral">    &gt;&gt;&gt; brier_score_loss(y_true, y_prob)</span></div>
<div class="line"><span class="lineno"> 2865</span><span class="stringliteral">    0.037...</span></div>
<div class="line"><span class="lineno"> 2866</span><span class="stringliteral">    &gt;&gt;&gt; brier_score_loss(y_true, 1-y_prob, pos_label=0)</span></div>
<div class="line"><span class="lineno"> 2867</span><span class="stringliteral">    0.037...</span></div>
<div class="line"><span class="lineno"> 2868</span><span class="stringliteral">    &gt;&gt;&gt; brier_score_loss(y_true_categorical, y_prob, pos_label=&quot;ham&quot;)</span></div>
<div class="line"><span class="lineno"> 2869</span><span class="stringliteral">    0.037...</span></div>
<div class="line"><span class="lineno"> 2870</span><span class="stringliteral">    &gt;&gt;&gt; brier_score_loss(y_true, np.array(y_prob) &gt; 0.5)</span></div>
<div class="line"><span class="lineno"> 2871</span><span class="stringliteral">    0.0</span></div>
<div class="line"><span class="lineno"> 2872</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 2873</span>    y_true = column_or_1d(y_true)</div>
<div class="line"><span class="lineno"> 2874</span>    y_prob = column_or_1d(y_prob)</div>
<div class="line"><span class="lineno"> 2875</span>    assert_all_finite(y_true)</div>
<div class="line"><span class="lineno"> 2876</span>    assert_all_finite(y_prob)</div>
<div class="line"><span class="lineno"> 2877</span>    check_consistent_length(y_true, y_prob, sample_weight)</div>
<div class="line"><span class="lineno"> 2878</span> </div>
<div class="line"><span class="lineno"> 2879</span>    y_type = type_of_target(y_true, input_name=<span class="stringliteral">&quot;y_true&quot;</span>)</div>
<div class="line"><span class="lineno"> 2880</span>    <span class="keywordflow">if</span> y_type != <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno"> 2881</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 2882</span>            <span class="stringliteral">&quot;Only binary classification is supported. The type of the target &quot;</span></div>
<div class="line"><span class="lineno"> 2883</span>            f<span class="stringliteral">&quot;is {y_type}.&quot;</span></div>
<div class="line"><span class="lineno"> 2884</span>        )</div>
<div class="line"><span class="lineno"> 2885</span> </div>
<div class="line"><span class="lineno"> 2886</span>    <span class="keywordflow">if</span> y_prob.max() &gt; 1:</div>
<div class="line"><span class="lineno"> 2887</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;y_prob contains values greater than 1.&quot;</span>)</div>
<div class="line"><span class="lineno"> 2888</span>    <span class="keywordflow">if</span> y_prob.min() &lt; 0:</div>
<div class="line"><span class="lineno"> 2889</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;y_prob contains values less than 0.&quot;</span>)</div>
<div class="line"><span class="lineno"> 2890</span> </div>
<div class="line"><span class="lineno"> 2891</span>    <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno"> 2892</span>        pos_label = _check_pos_label_consistency(pos_label, y_true)</div>
<div class="line"><span class="lineno"> 2893</span>    <span class="keywordflow">except</span> ValueError:</div>
<div class="line"><span class="lineno"> 2894</span>        classes = np.unique(y_true)</div>
<div class="line"><span class="lineno"> 2895</span>        <span class="keywordflow">if</span> classes.dtype.kind <span class="keywordflow">not</span> <span class="keywordflow">in</span> (<span class="stringliteral">&quot;O&quot;</span>, <span class="stringliteral">&quot;U&quot;</span>, <span class="stringliteral">&quot;S&quot;</span>):</div>
<div class="line"><span class="lineno"> 2896</span>            <span class="comment"># for backward compatibility, if classes are not string then</span></div>
<div class="line"><span class="lineno"> 2897</span>            <span class="comment"># `pos_label` will correspond to the greater label</span></div>
<div class="line"><span class="lineno"> 2898</span>            pos_label = classes[-1]</div>
<div class="line"><span class="lineno"> 2899</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2900</span>            <span class="keywordflow">raise</span></div>
<div class="line"><span class="lineno"> 2901</span>    y_true = np.array(y_true == pos_label, int)</div>
<div class="line"><span class="lineno"> 2902</span>    <span class="keywordflow">return</span> np.average((y_true - y_prob) ** 2, weights=sample_weight)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a555f0a846fe7c4c4cde12132fd5fdfa5" name="a555f0a846fe7c4c4cde12132fd5fdfa5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a555f0a846fe7c4c4cde12132fd5fdfa5">&#9670;&#160;</a></span>class_likelihood_ratios()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.class_likelihood_ratios </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>raise_warning</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute binary classification positive and negative likelihood ratios.

The positive likelihood ratio is `LR+ = sensitivity / (1 - specificity)`
where the sensitivity or recall is the ratio `tp / (tp + fn)` and the
specificity is `tn / (tn + fp)`. The negative likelihood ratio is `LR- = (1
- sensitivity) / specificity`. Here `tp` is the number of true positives,
`fp` the number of false positives, `tn` is the number of true negatives and
`fn` the number of false negatives. Both class likelihood ratios can be used
to obtain post-test probabilities given a pre-test probability.

`LR+` ranges from 1 to infinity. A `LR+` of 1 indicates that the probability
of predicting the positive class is the same for samples belonging to either
class; therefore, the test is useless. The greater `LR+` is, the more a
positive prediction is likely to be a true positive when compared with the
pre-test probability. A value of `LR+` lower than 1 is invalid as it would
indicate that the odds of a sample being a true positive decrease with
respect to the pre-test odds.

`LR-` ranges from 0 to 1. The closer it is to 0, the lower the probability
of a given sample to be a false negative. A `LR-` of 1 means the test is
useless because the odds of having the condition did not change after the
test. A value of `LR-` greater than 1 invalidates the classifier as it
indicates an increase in the odds of a sample belonging to the positive
class after being classified as negative. This is the case when the
classifier systematically predicts the opposite of the true label.

A typical application in medicine is to identify the positive/negative class
to the presence/absence of a disease, respectively; the classifier being a
diagnostic test; the pre-test probability of an individual having the
disease can be the prevalence of such disease (proportion of a particular
population found to be affected by a medical condition); and the post-test
probabilities would be the probability that the condition is truly present
given a positive test result.

Read more in the :ref:`User Guide &lt;class_likelihood_ratios&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) target values.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Estimated targets as returned by a classifier.

labels : array-like, default=None
    List of labels to index the matrix. This may be used to select the
    positive and negative classes with the ordering `labels=[negative_class,
    positive_class]`. If `None` is given, those that appear at least once in
    `y_true` or `y_pred` are used in sorted order.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

raise_warning : bool, default=True
    Whether or not a case-specific warning message is raised when there is a
    zero division. Even if the error is not raised, the function will return
    nan in such cases.

Returns
-------
(positive_likelihood_ratio, negative_likelihood_ratio) : tuple
    A tuple of two float, the first containing the Positive likelihood ratio
    and the second the Negative likelihood ratio.

Warns
-----
When `false positive == 0`, the positive likelihood ratio is undefined.
When `true negative == 0`, the negative likelihood ratio is undefined.
When `true positive + false negative == 0` both ratios are undefined.
In such cases, `UserWarning` will be raised if raise_warning=True.

References
----------
.. [1] `Wikipedia entry for the Likelihood ratios in diagnostic testing
       &lt;https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing&gt;`_.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import class_likelihood_ratios
&gt;&gt;&gt; class_likelihood_ratios([0, 1, 0, 1, 0], [1, 1, 0, 0, 0])
(1.5, 0.75)
&gt;&gt;&gt; y_true = np.array(["non-cat", "cat", "non-cat", "cat", "non-cat"])
&gt;&gt;&gt; y_pred = np.array(["cat", "cat", "non-cat", "non-cat", "non-cat"])
&gt;&gt;&gt; class_likelihood_ratios(y_true, y_pred)
(1.33..., 0.66...)
&gt;&gt;&gt; y_true = np.array(["non-zebra", "zebra", "non-zebra", "zebra", "non-zebra"])
&gt;&gt;&gt; y_pred = np.array(["zebra", "zebra", "non-zebra", "non-zebra", "non-zebra"])
&gt;&gt;&gt; class_likelihood_ratios(y_true, y_pred)
(1.5, 0.75)

To avoid ambiguities, use the notation `labels=[negative_class,
positive_class]`

&gt;&gt;&gt; y_true = np.array(["non-cat", "cat", "non-cat", "cat", "non-cat"])
&gt;&gt;&gt; y_pred = np.array(["cat", "cat", "non-cat", "non-cat", "non-cat"])
&gt;&gt;&gt; class_likelihood_ratios(y_true, y_pred, labels=["non-cat", "cat"])
(1.5, 0.75)
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1664</span>):</div>
<div class="line"><span class="lineno"> 1665</span>    <span class="stringliteral">&quot;&quot;&quot;Compute binary classification positive and negative likelihood ratios.</span></div>
<div class="line"><span class="lineno"> 1666</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1667</span><span class="stringliteral">    The positive likelihood ratio is `LR+ = sensitivity / (1 - specificity)`</span></div>
<div class="line"><span class="lineno"> 1668</span><span class="stringliteral">    where the sensitivity or recall is the ratio `tp / (tp + fn)` and the</span></div>
<div class="line"><span class="lineno"> 1669</span><span class="stringliteral">    specificity is `tn / (tn + fp)`. The negative likelihood ratio is `LR- = (1</span></div>
<div class="line"><span class="lineno"> 1670</span><span class="stringliteral">    - sensitivity) / specificity`. Here `tp` is the number of true positives,</span></div>
<div class="line"><span class="lineno"> 1671</span><span class="stringliteral">    `fp` the number of false positives, `tn` is the number of true negatives and</span></div>
<div class="line"><span class="lineno"> 1672</span><span class="stringliteral">    `fn` the number of false negatives. Both class likelihood ratios can be used</span></div>
<div class="line"><span class="lineno"> 1673</span><span class="stringliteral">    to obtain post-test probabilities given a pre-test probability.</span></div>
<div class="line"><span class="lineno"> 1674</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1675</span><span class="stringliteral">    `LR+` ranges from 1 to infinity. A `LR+` of 1 indicates that the probability</span></div>
<div class="line"><span class="lineno"> 1676</span><span class="stringliteral">    of predicting the positive class is the same for samples belonging to either</span></div>
<div class="line"><span class="lineno"> 1677</span><span class="stringliteral">    class; therefore, the test is useless. The greater `LR+` is, the more a</span></div>
<div class="line"><span class="lineno"> 1678</span><span class="stringliteral">    positive prediction is likely to be a true positive when compared with the</span></div>
<div class="line"><span class="lineno"> 1679</span><span class="stringliteral">    pre-test probability. A value of `LR+` lower than 1 is invalid as it would</span></div>
<div class="line"><span class="lineno"> 1680</span><span class="stringliteral">    indicate that the odds of a sample being a true positive decrease with</span></div>
<div class="line"><span class="lineno"> 1681</span><span class="stringliteral">    respect to the pre-test odds.</span></div>
<div class="line"><span class="lineno"> 1682</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1683</span><span class="stringliteral">    `LR-` ranges from 0 to 1. The closer it is to 0, the lower the probability</span></div>
<div class="line"><span class="lineno"> 1684</span><span class="stringliteral">    of a given sample to be a false negative. A `LR-` of 1 means the test is</span></div>
<div class="line"><span class="lineno"> 1685</span><span class="stringliteral">    useless because the odds of having the condition did not change after the</span></div>
<div class="line"><span class="lineno"> 1686</span><span class="stringliteral">    test. A value of `LR-` greater than 1 invalidates the classifier as it</span></div>
<div class="line"><span class="lineno"> 1687</span><span class="stringliteral">    indicates an increase in the odds of a sample belonging to the positive</span></div>
<div class="line"><span class="lineno"> 1688</span><span class="stringliteral">    class after being classified as negative. This is the case when the</span></div>
<div class="line"><span class="lineno"> 1689</span><span class="stringliteral">    classifier systematically predicts the opposite of the true label.</span></div>
<div class="line"><span class="lineno"> 1690</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1691</span><span class="stringliteral">    A typical application in medicine is to identify the positive/negative class</span></div>
<div class="line"><span class="lineno"> 1692</span><span class="stringliteral">    to the presence/absence of a disease, respectively; the classifier being a</span></div>
<div class="line"><span class="lineno"> 1693</span><span class="stringliteral">    diagnostic test; the pre-test probability of an individual having the</span></div>
<div class="line"><span class="lineno"> 1694</span><span class="stringliteral">    disease can be the prevalence of such disease (proportion of a particular</span></div>
<div class="line"><span class="lineno"> 1695</span><span class="stringliteral">    population found to be affected by a medical condition); and the post-test</span></div>
<div class="line"><span class="lineno"> 1696</span><span class="stringliteral">    probabilities would be the probability that the condition is truly present</span></div>
<div class="line"><span class="lineno"> 1697</span><span class="stringliteral">    given a positive test result.</span></div>
<div class="line"><span class="lineno"> 1698</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1699</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;class_likelihood_ratios&gt;`.</span></div>
<div class="line"><span class="lineno"> 1700</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1701</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1702</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1703</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1704</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 1705</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1706</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1707</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno"> 1708</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1709</span><span class="stringliteral">    labels : array-like, default=None</span></div>
<div class="line"><span class="lineno"> 1710</span><span class="stringliteral">        List of labels to index the matrix. This may be used to select the</span></div>
<div class="line"><span class="lineno"> 1711</span><span class="stringliteral">        positive and negative classes with the ordering `labels=[negative_class,</span></div>
<div class="line"><span class="lineno"> 1712</span><span class="stringliteral">        positive_class]`. If `None` is given, those that appear at least once in</span></div>
<div class="line"><span class="lineno"> 1713</span><span class="stringliteral">        `y_true` or `y_pred` are used in sorted order.</span></div>
<div class="line"><span class="lineno"> 1714</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1715</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1716</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1717</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1718</span><span class="stringliteral">    raise_warning : bool, default=True</span></div>
<div class="line"><span class="lineno"> 1719</span><span class="stringliteral">        Whether or not a case-specific warning message is raised when there is a</span></div>
<div class="line"><span class="lineno"> 1720</span><span class="stringliteral">        zero division. Even if the error is not raised, the function will return</span></div>
<div class="line"><span class="lineno"> 1721</span><span class="stringliteral">        nan in such cases.</span></div>
<div class="line"><span class="lineno"> 1722</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1723</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1724</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1725</span><span class="stringliteral">    (positive_likelihood_ratio, negative_likelihood_ratio) : tuple</span></div>
<div class="line"><span class="lineno"> 1726</span><span class="stringliteral">        A tuple of two float, the first containing the Positive likelihood ratio</span></div>
<div class="line"><span class="lineno"> 1727</span><span class="stringliteral">        and the second the Negative likelihood ratio.</span></div>
<div class="line"><span class="lineno"> 1728</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1729</span><span class="stringliteral">    Warns</span></div>
<div class="line"><span class="lineno"> 1730</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1731</span><span class="stringliteral">    When `false positive == 0`, the positive likelihood ratio is undefined.</span></div>
<div class="line"><span class="lineno"> 1732</span><span class="stringliteral">    When `true negative == 0`, the negative likelihood ratio is undefined.</span></div>
<div class="line"><span class="lineno"> 1733</span><span class="stringliteral">    When `true positive + false negative == 0` both ratios are undefined.</span></div>
<div class="line"><span class="lineno"> 1734</span><span class="stringliteral">    In such cases, `UserWarning` will be raised if raise_warning=True.</span></div>
<div class="line"><span class="lineno"> 1735</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1736</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1737</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1738</span><span class="stringliteral">    .. [1] `Wikipedia entry for the Likelihood ratios in diagnostic testing</span></div>
<div class="line"><span class="lineno"> 1739</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing&gt;`_.</span></div>
<div class="line"><span class="lineno"> 1740</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1741</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1742</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1743</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno"> 1744</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import class_likelihood_ratios</span></div>
<div class="line"><span class="lineno"> 1745</span><span class="stringliteral">    &gt;&gt;&gt; class_likelihood_ratios([0, 1, 0, 1, 0], [1, 1, 0, 0, 0])</span></div>
<div class="line"><span class="lineno"> 1746</span><span class="stringliteral">    (1.5, 0.75)</span></div>
<div class="line"><span class="lineno"> 1747</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([&quot;non-cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;])</span></div>
<div class="line"><span class="lineno"> 1748</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = np.array([&quot;cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;, &quot;non-cat&quot;, &quot;non-cat&quot;])</span></div>
<div class="line"><span class="lineno"> 1749</span><span class="stringliteral">    &gt;&gt;&gt; class_likelihood_ratios(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 1750</span><span class="stringliteral">    (1.33..., 0.66...)</span></div>
<div class="line"><span class="lineno"> 1751</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([&quot;non-zebra&quot;, &quot;zebra&quot;, &quot;non-zebra&quot;, &quot;zebra&quot;, &quot;non-zebra&quot;])</span></div>
<div class="line"><span class="lineno"> 1752</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = np.array([&quot;zebra&quot;, &quot;zebra&quot;, &quot;non-zebra&quot;, &quot;non-zebra&quot;, &quot;non-zebra&quot;])</span></div>
<div class="line"><span class="lineno"> 1753</span><span class="stringliteral">    &gt;&gt;&gt; class_likelihood_ratios(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 1754</span><span class="stringliteral">    (1.5, 0.75)</span></div>
<div class="line"><span class="lineno"> 1755</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1756</span><span class="stringliteral">    To avoid ambiguities, use the notation `labels=[negative_class,</span></div>
<div class="line"><span class="lineno"> 1757</span><span class="stringliteral">    positive_class]`</span></div>
<div class="line"><span class="lineno"> 1758</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1759</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([&quot;non-cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;])</span></div>
<div class="line"><span class="lineno"> 1760</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = np.array([&quot;cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;, &quot;non-cat&quot;, &quot;non-cat&quot;])</span></div>
<div class="line"><span class="lineno"> 1761</span><span class="stringliteral">    &gt;&gt;&gt; class_likelihood_ratios(y_true, y_pred, labels=[&quot;non-cat&quot;, &quot;cat&quot;])</span></div>
<div class="line"><span class="lineno"> 1762</span><span class="stringliteral">    (1.5, 0.75)</span></div>
<div class="line"><span class="lineno"> 1763</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1764</span> </div>
<div class="line"><span class="lineno"> 1765</span>    y_type, y_true, y_pred = _check_targets(y_true, y_pred)</div>
<div class="line"><span class="lineno"> 1766</span>    <span class="keywordflow">if</span> y_type != <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno"> 1767</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1768</span>            <span class="stringliteral">&quot;class_likelihood_ratios only supports binary classification &quot;</span></div>
<div class="line"><span class="lineno"> 1769</span>            f<span class="stringliteral">&quot;problems, got targets of type: {y_type}&quot;</span></div>
<div class="line"><span class="lineno"> 1770</span>        )</div>
<div class="line"><span class="lineno"> 1771</span> </div>
<div class="line"><span class="lineno"> 1772</span>    cm = confusion_matrix(</div>
<div class="line"><span class="lineno"> 1773</span>        y_true,</div>
<div class="line"><span class="lineno"> 1774</span>        y_pred,</div>
<div class="line"><span class="lineno"> 1775</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno"> 1776</span>        labels=labels,</div>
<div class="line"><span class="lineno"> 1777</span>    )</div>
<div class="line"><span class="lineno"> 1778</span> </div>
<div class="line"><span class="lineno"> 1779</span>    <span class="comment"># Case when `y_test` contains a single class and `y_test == y_pred`.</span></div>
<div class="line"><span class="lineno"> 1780</span>    <span class="comment"># This may happen when cross-validating imbalanced data and should</span></div>
<div class="line"><span class="lineno"> 1781</span>    <span class="comment"># not be interpreted as a perfect score.</span></div>
<div class="line"><span class="lineno"> 1782</span>    <span class="keywordflow">if</span> cm.shape == (1, 1):</div>
<div class="line"><span class="lineno"> 1783</span>        msg = <span class="stringliteral">&quot;samples of only one class were seen during testing &quot;</span></div>
<div class="line"><span class="lineno"> 1784</span>        <span class="keywordflow">if</span> raise_warning:</div>
<div class="line"><span class="lineno"> 1785</span>            warnings.warn(msg, UserWarning, stacklevel=2)</div>
<div class="line"><span class="lineno"> 1786</span>        positive_likelihood_ratio = np.nan</div>
<div class="line"><span class="lineno"> 1787</span>        negative_likelihood_ratio = np.nan</div>
<div class="line"><span class="lineno"> 1788</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1789</span>        tn, fp, fn, tp = cm.ravel()</div>
<div class="line"><span class="lineno"> 1790</span>        support_pos = tp + fn</div>
<div class="line"><span class="lineno"> 1791</span>        support_neg = tn + fp</div>
<div class="line"><span class="lineno"> 1792</span>        pos_num = tp * support_neg</div>
<div class="line"><span class="lineno"> 1793</span>        pos_denom = fp * support_pos</div>
<div class="line"><span class="lineno"> 1794</span>        neg_num = fn * support_neg</div>
<div class="line"><span class="lineno"> 1795</span>        neg_denom = tn * support_pos</div>
<div class="line"><span class="lineno"> 1796</span> </div>
<div class="line"><span class="lineno"> 1797</span>        <span class="comment"># If zero division warn and set scores to nan, else divide</span></div>
<div class="line"><span class="lineno"> 1798</span>        <span class="keywordflow">if</span> support_pos == 0:</div>
<div class="line"><span class="lineno"> 1799</span>            msg = <span class="stringliteral">&quot;no samples of the positive class were present in the testing set &quot;</span></div>
<div class="line"><span class="lineno"> 1800</span>            <span class="keywordflow">if</span> raise_warning:</div>
<div class="line"><span class="lineno"> 1801</span>                warnings.warn(msg, UserWarning, stacklevel=2)</div>
<div class="line"><span class="lineno"> 1802</span>            positive_likelihood_ratio = np.nan</div>
<div class="line"><span class="lineno"> 1803</span>            negative_likelihood_ratio = np.nan</div>
<div class="line"><span class="lineno"> 1804</span>        <span class="keywordflow">if</span> fp == 0:</div>
<div class="line"><span class="lineno"> 1805</span>            <span class="keywordflow">if</span> tp == 0:</div>
<div class="line"><span class="lineno"> 1806</span>                msg = <span class="stringliteral">&quot;no samples predicted for the positive class&quot;</span></div>
<div class="line"><span class="lineno"> 1807</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1808</span>                msg = <span class="stringliteral">&quot;positive_likelihood_ratio ill-defined and being set to nan &quot;</span></div>
<div class="line"><span class="lineno"> 1809</span>            <span class="keywordflow">if</span> raise_warning:</div>
<div class="line"><span class="lineno"> 1810</span>                warnings.warn(msg, UserWarning, stacklevel=2)</div>
<div class="line"><span class="lineno"> 1811</span>            positive_likelihood_ratio = np.nan</div>
<div class="line"><span class="lineno"> 1812</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1813</span>            positive_likelihood_ratio = pos_num / pos_denom</div>
<div class="line"><span class="lineno"> 1814</span>        <span class="keywordflow">if</span> tn == 0:</div>
<div class="line"><span class="lineno"> 1815</span>            msg = <span class="stringliteral">&quot;negative_likelihood_ratio ill-defined and being set to nan &quot;</span></div>
<div class="line"><span class="lineno"> 1816</span>            <span class="keywordflow">if</span> raise_warning:</div>
<div class="line"><span class="lineno"> 1817</span>                warnings.warn(msg, UserWarning, stacklevel=2)</div>
<div class="line"><span class="lineno"> 1818</span>            negative_likelihood_ratio = np.nan</div>
<div class="line"><span class="lineno"> 1819</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1820</span>            negative_likelihood_ratio = neg_num / neg_denom</div>
<div class="line"><span class="lineno"> 1821</span> </div>
<div class="line"><span class="lineno"> 1822</span>    <span class="keywordflow">return</span> positive_likelihood_ratio, negative_likelihood_ratio</div>
<div class="line"><span class="lineno"> 1823</span> </div>
<div class="line"><span class="lineno"> 1824</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abd0e1ec22f72fb2ee674b6775cd106b9" name="abd0e1ec22f72fb2ee674b6775cd106b9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd0e1ec22f72fb2ee674b6775cd106b9">&#9670;&#160;</a></span>classification_report()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.classification_report </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>target_names</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>digits</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_dict</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zero_division</em> = <code>&quot;warn&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Build a text report showing the main classification metrics.

Read more in the :ref:`User Guide &lt;classification_report&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) target values.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Estimated targets as returned by a classifier.

labels : array-like of shape (n_labels,), default=None
    Optional list of label indices to include in the report.

target_names : list of str of shape (n_labels,), default=None
    Optional display names matching the labels (same order).

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

digits : int, default=2
    Number of digits for formatting output floating point values.
    When ``output_dict`` is ``True``, this will be ignored and the
    returned values will not be rounded.

output_dict : bool, default=False
    If True, return output as dict.

    .. versionadded:: 0.20

zero_division : "warn", 0 or 1, default="warn"
    Sets the value to return when there is a zero division. If set to
    "warn", this acts as 0, but warnings are also raised.

Returns
-------
report : str or dict
    Text summary of the precision, recall, F1 score for each class.
    Dictionary returned if output_dict is True. Dictionary has the
    following structure::

        {'label 1': {'precision':0.5,
                     'recall':1.0,
                     'f1-score':0.67,
                     'support':1},
         'label 2': { ... },
          ...
        }

    The reported averages include macro average (averaging the unweighted
    mean per label), weighted average (averaging the support-weighted mean
    per label), and sample average (only for multilabel classification).
    Micro average (averaging the total true positives, false negatives and
    false positives) is only shown for multi-label or multi-class
    with a subset of classes, because it corresponds to accuracy
    otherwise and would be the same for all metrics.
    See also :func:`precision_recall_fscore_support` for more details
    on averages.

    Note that in binary classification, recall of the positive class
    is also known as "sensitivity"; recall of the negative class is
    "specificity".

See Also
--------
precision_recall_fscore_support: Compute precision, recall, F-measure and
    support for each class.
confusion_matrix: Compute confusion matrix to evaluate the accuracy of a
    classification.
multilabel_confusion_matrix: Compute a confusion matrix for each class or sample.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import classification_report
&gt;&gt;&gt; y_true = [0, 1, 2, 2, 2]
&gt;&gt;&gt; y_pred = [0, 0, 2, 2, 1]
&gt;&gt;&gt; target_names = ['class 0', 'class 1', 'class 2']
&gt;&gt;&gt; print(classification_report(y_true, y_pred, target_names=target_names))
              precision    recall  f1-score   support
&lt;BLANKLINE&gt;
     class 0       0.50      1.00      0.67         1
     class 1       0.00      0.00      0.00         1
     class 2       1.00      0.67      0.80         3
&lt;BLANKLINE&gt;
    accuracy                           0.60         5
   macro avg       0.50      0.56      0.49         5
weighted avg       0.70      0.60      0.61         5
&lt;BLANKLINE&gt;
&gt;&gt;&gt; y_pred = [1, 1, 0]
&gt;&gt;&gt; y_true = [1, 1, 1]
&gt;&gt;&gt; print(classification_report(y_true, y_pred, labels=[1, 2, 3]))
              precision    recall  f1-score   support
&lt;BLANKLINE&gt;
           1       1.00      0.67      0.80         3
           2       0.00      0.00      0.00         0
           3       0.00      0.00      0.00         0
&lt;BLANKLINE&gt;
   micro avg       1.00      0.67      0.80         3
   macro avg       0.33      0.22      0.27         3
weighted avg       1.00      0.67      0.80         3
&lt;BLANKLINE&gt;
</pre> <div class="fragment"><div class="line"><span class="lineno"> 2205</span>):</div>
<div class="line"><span class="lineno"> 2206</span>    <span class="stringliteral">&quot;&quot;&quot;Build a text report showing the main classification metrics.</span></div>
<div class="line"><span class="lineno"> 2207</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2208</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;classification_report&gt;`.</span></div>
<div class="line"><span class="lineno"> 2209</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2210</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 2211</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2212</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 2213</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 2214</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2215</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 2216</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno"> 2217</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2218</span><span class="stringliteral">    labels : array-like of shape (n_labels,), default=None</span></div>
<div class="line"><span class="lineno"> 2219</span><span class="stringliteral">        Optional list of label indices to include in the report.</span></div>
<div class="line"><span class="lineno"> 2220</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2221</span><span class="stringliteral">    target_names : list of str of shape (n_labels,), default=None</span></div>
<div class="line"><span class="lineno"> 2222</span><span class="stringliteral">        Optional display names matching the labels (same order).</span></div>
<div class="line"><span class="lineno"> 2223</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2224</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 2225</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 2226</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2227</span><span class="stringliteral">    digits : int, default=2</span></div>
<div class="line"><span class="lineno"> 2228</span><span class="stringliteral">        Number of digits for formatting output floating point values.</span></div>
<div class="line"><span class="lineno"> 2229</span><span class="stringliteral">        When ``output_dict`` is ``True``, this will be ignored and the</span></div>
<div class="line"><span class="lineno"> 2230</span><span class="stringliteral">        returned values will not be rounded.</span></div>
<div class="line"><span class="lineno"> 2231</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2232</span><span class="stringliteral">    output_dict : bool, default=False</span></div>
<div class="line"><span class="lineno"> 2233</span><span class="stringliteral">        If True, return output as dict.</span></div>
<div class="line"><span class="lineno"> 2234</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2235</span><span class="stringliteral">        .. versionadded:: 0.20</span></div>
<div class="line"><span class="lineno"> 2236</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2237</span><span class="stringliteral">    zero_division : &quot;warn&quot;, 0 or 1, default=&quot;warn&quot;</span></div>
<div class="line"><span class="lineno"> 2238</span><span class="stringliteral">        Sets the value to return when there is a zero division. If set to</span></div>
<div class="line"><span class="lineno"> 2239</span><span class="stringliteral">        &quot;warn&quot;, this acts as 0, but warnings are also raised.</span></div>
<div class="line"><span class="lineno"> 2240</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2241</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 2242</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 2243</span><span class="stringliteral">    report : str or dict</span></div>
<div class="line"><span class="lineno"> 2244</span><span class="stringliteral">        Text summary of the precision, recall, F1 score for each class.</span></div>
<div class="line"><span class="lineno"> 2245</span><span class="stringliteral">        Dictionary returned if output_dict is True. Dictionary has the</span></div>
<div class="line"><span class="lineno"> 2246</span><span class="stringliteral">        following structure::</span></div>
<div class="line"><span class="lineno"> 2247</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2248</span><span class="stringliteral">            {&#39;label 1&#39;: {&#39;precision&#39;:0.5,</span></div>
<div class="line"><span class="lineno"> 2249</span><span class="stringliteral">                         &#39;recall&#39;:1.0,</span></div>
<div class="line"><span class="lineno"> 2250</span><span class="stringliteral">                         &#39;f1-score&#39;:0.67,</span></div>
<div class="line"><span class="lineno"> 2251</span><span class="stringliteral">                         &#39;support&#39;:1},</span></div>
<div class="line"><span class="lineno"> 2252</span><span class="stringliteral">             &#39;label 2&#39;: { ... },</span></div>
<div class="line"><span class="lineno"> 2253</span><span class="stringliteral">              ...</span></div>
<div class="line"><span class="lineno"> 2254</span><span class="stringliteral">            }</span></div>
<div class="line"><span class="lineno"> 2255</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2256</span><span class="stringliteral">        The reported averages include macro average (averaging the unweighted</span></div>
<div class="line"><span class="lineno"> 2257</span><span class="stringliteral">        mean per label), weighted average (averaging the support-weighted mean</span></div>
<div class="line"><span class="lineno"> 2258</span><span class="stringliteral">        per label), and sample average (only for multilabel classification).</span></div>
<div class="line"><span class="lineno"> 2259</span><span class="stringliteral">        Micro average (averaging the total true positives, false negatives and</span></div>
<div class="line"><span class="lineno"> 2260</span><span class="stringliteral">        false positives) is only shown for multi-label or multi-class</span></div>
<div class="line"><span class="lineno"> 2261</span><span class="stringliteral">        with a subset of classes, because it corresponds to accuracy</span></div>
<div class="line"><span class="lineno"> 2262</span><span class="stringliteral">        otherwise and would be the same for all metrics.</span></div>
<div class="line"><span class="lineno"> 2263</span><span class="stringliteral">        See also :func:`precision_recall_fscore_support` for more details</span></div>
<div class="line"><span class="lineno"> 2264</span><span class="stringliteral">        on averages.</span></div>
<div class="line"><span class="lineno"> 2265</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2266</span><span class="stringliteral">        Note that in binary classification, recall of the positive class</span></div>
<div class="line"><span class="lineno"> 2267</span><span class="stringliteral">        is also known as &quot;sensitivity&quot;; recall of the negative class is</span></div>
<div class="line"><span class="lineno"> 2268</span><span class="stringliteral">        &quot;specificity&quot;.</span></div>
<div class="line"><span class="lineno"> 2269</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2270</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 2271</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2272</span><span class="stringliteral">    precision_recall_fscore_support: Compute precision, recall, F-measure and</span></div>
<div class="line"><span class="lineno"> 2273</span><span class="stringliteral">        support for each class.</span></div>
<div class="line"><span class="lineno"> 2274</span><span class="stringliteral">    confusion_matrix: Compute confusion matrix to evaluate the accuracy of a</span></div>
<div class="line"><span class="lineno"> 2275</span><span class="stringliteral">        classification.</span></div>
<div class="line"><span class="lineno"> 2276</span><span class="stringliteral">    multilabel_confusion_matrix: Compute a confusion matrix for each class or sample.</span></div>
<div class="line"><span class="lineno"> 2277</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2278</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 2279</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2280</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import classification_report</span></div>
<div class="line"><span class="lineno"> 2281</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 1, 2, 2, 2]</span></div>
<div class="line"><span class="lineno"> 2282</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 0, 2, 2, 1]</span></div>
<div class="line"><span class="lineno"> 2283</span><span class="stringliteral">    &gt;&gt;&gt; target_names = [&#39;class 0&#39;, &#39;class 1&#39;, &#39;class 2&#39;]</span></div>
<div class="line"><span class="lineno"> 2284</span><span class="stringliteral">    &gt;&gt;&gt; print(classification_report(y_true, y_pred, target_names=target_names))</span></div>
<div class="line"><span class="lineno"> 2285</span><span class="stringliteral">                  precision    recall  f1-score   support</span></div>
<div class="line"><span class="lineno"> 2286</span><span class="stringliteral">    &lt;BLANKLINE&gt;</span></div>
<div class="line"><span class="lineno"> 2287</span><span class="stringliteral">         class 0       0.50      1.00      0.67         1</span></div>
<div class="line"><span class="lineno"> 2288</span><span class="stringliteral">         class 1       0.00      0.00      0.00         1</span></div>
<div class="line"><span class="lineno"> 2289</span><span class="stringliteral">         class 2       1.00      0.67      0.80         3</span></div>
<div class="line"><span class="lineno"> 2290</span><span class="stringliteral">    &lt;BLANKLINE&gt;</span></div>
<div class="line"><span class="lineno"> 2291</span><span class="stringliteral">        accuracy                           0.60         5</span></div>
<div class="line"><span class="lineno"> 2292</span><span class="stringliteral">       macro avg       0.50      0.56      0.49         5</span></div>
<div class="line"><span class="lineno"> 2293</span><span class="stringliteral">    weighted avg       0.70      0.60      0.61         5</span></div>
<div class="line"><span class="lineno"> 2294</span><span class="stringliteral">    &lt;BLANKLINE&gt;</span></div>
<div class="line"><span class="lineno"> 2295</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [1, 1, 0]</span></div>
<div class="line"><span class="lineno"> 2296</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [1, 1, 1]</span></div>
<div class="line"><span class="lineno"> 2297</span><span class="stringliteral">    &gt;&gt;&gt; print(classification_report(y_true, y_pred, labels=[1, 2, 3]))</span></div>
<div class="line"><span class="lineno"> 2298</span><span class="stringliteral">                  precision    recall  f1-score   support</span></div>
<div class="line"><span class="lineno"> 2299</span><span class="stringliteral">    &lt;BLANKLINE&gt;</span></div>
<div class="line"><span class="lineno"> 2300</span><span class="stringliteral">               1       1.00      0.67      0.80         3</span></div>
<div class="line"><span class="lineno"> 2301</span><span class="stringliteral">               2       0.00      0.00      0.00         0</span></div>
<div class="line"><span class="lineno"> 2302</span><span class="stringliteral">               3       0.00      0.00      0.00         0</span></div>
<div class="line"><span class="lineno"> 2303</span><span class="stringliteral">    &lt;BLANKLINE&gt;</span></div>
<div class="line"><span class="lineno"> 2304</span><span class="stringliteral">       micro avg       1.00      0.67      0.80         3</span></div>
<div class="line"><span class="lineno"> 2305</span><span class="stringliteral">       macro avg       0.33      0.22      0.27         3</span></div>
<div class="line"><span class="lineno"> 2306</span><span class="stringliteral">    weighted avg       1.00      0.67      0.80         3</span></div>
<div class="line"><span class="lineno"> 2307</span><span class="stringliteral">    &lt;BLANKLINE&gt;</span></div>
<div class="line"><span class="lineno"> 2308</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 2309</span> </div>
<div class="line"><span class="lineno"> 2310</span>    y_type, y_true, y_pred = _check_targets(y_true, y_pred)</div>
<div class="line"><span class="lineno"> 2311</span> </div>
<div class="line"><span class="lineno"> 2312</span>    <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 2313</span>        labels = unique_labels(y_true, y_pred)</div>
<div class="line"><span class="lineno"> 2314</span>        labels_given = <span class="keyword">False</span></div>
<div class="line"><span class="lineno"> 2315</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2316</span>        labels = np.asarray(labels)</div>
<div class="line"><span class="lineno"> 2317</span>        labels_given = <span class="keyword">True</span></div>
<div class="line"><span class="lineno"> 2318</span> </div>
<div class="line"><span class="lineno"> 2319</span>    <span class="comment"># labelled micro average</span></div>
<div class="line"><span class="lineno"> 2320</span>    micro_is_accuracy = (y_type == <span class="stringliteral">&quot;multiclass&quot;</span> <span class="keywordflow">or</span> y_type == <span class="stringliteral">&quot;binary&quot;</span>) <span class="keywordflow">and</span> (</div>
<div class="line"><span class="lineno"> 2321</span>        <span class="keywordflow">not</span> labels_given <span class="keywordflow">or</span> (set(labels) == set(unique_labels(y_true, y_pred)))</div>
<div class="line"><span class="lineno"> 2322</span>    )</div>
<div class="line"><span class="lineno"> 2323</span> </div>
<div class="line"><span class="lineno"> 2324</span>    <span class="keywordflow">if</span> target_names <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> len(labels) != len(target_names):</div>
<div class="line"><span class="lineno"> 2325</span>        <span class="keywordflow">if</span> labels_given:</div>
<div class="line"><span class="lineno"> 2326</span>            warnings.warn(</div>
<div class="line"><span class="lineno"> 2327</span>                <span class="stringliteral">&quot;labels size, {0}, does not match size of target_names, {1}&quot;</span>.format(</div>
<div class="line"><span class="lineno"> 2328</span>                    len(labels), len(target_names)</div>
<div class="line"><span class="lineno"> 2329</span>                )</div>
<div class="line"><span class="lineno"> 2330</span>            )</div>
<div class="line"><span class="lineno"> 2331</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2332</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 2333</span>                <span class="stringliteral">&quot;Number of classes, {0}, does not match size of &quot;</span></div>
<div class="line"><span class="lineno"> 2334</span>                <span class="stringliteral">&quot;target_names, {1}. Try specifying the labels &quot;</span></div>
<div class="line"><span class="lineno"> 2335</span>                <span class="stringliteral">&quot;parameter&quot;</span>.format(len(labels), len(target_names))</div>
<div class="line"><span class="lineno"> 2336</span>            )</div>
<div class="line"><span class="lineno"> 2337</span>    <span class="keywordflow">if</span> target_names <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 2338</span>        target_names = [<span class="stringliteral">&quot;%s&quot;</span> % l <span class="keywordflow">for</span> l <span class="keywordflow">in</span> labels]</div>
<div class="line"><span class="lineno"> 2339</span> </div>
<div class="line"><span class="lineno"> 2340</span>    headers = [<span class="stringliteral">&quot;precision&quot;</span>, <span class="stringliteral">&quot;recall&quot;</span>, <span class="stringliteral">&quot;f1-score&quot;</span>, <span class="stringliteral">&quot;support&quot;</span>]</div>
<div class="line"><span class="lineno"> 2341</span>    <span class="comment"># compute per-class results without averaging</span></div>
<div class="line"><span class="lineno"> 2342</span>    p, r, f1, s = precision_recall_fscore_support(</div>
<div class="line"><span class="lineno"> 2343</span>        y_true,</div>
<div class="line"><span class="lineno"> 2344</span>        y_pred,</div>
<div class="line"><span class="lineno"> 2345</span>        labels=labels,</div>
<div class="line"><span class="lineno"> 2346</span>        average=<span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 2347</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno"> 2348</span>        zero_division=zero_division,</div>
<div class="line"><span class="lineno"> 2349</span>    )</div>
<div class="line"><span class="lineno"> 2350</span>    rows = zip(target_names, p, r, f1, s)</div>
<div class="line"><span class="lineno"> 2351</span> </div>
<div class="line"><span class="lineno"> 2352</span>    <span class="keywordflow">if</span> y_type.startswith(<span class="stringliteral">&quot;multilabel&quot;</span>):</div>
<div class="line"><span class="lineno"> 2353</span>        average_options = (<span class="stringliteral">&quot;micro&quot;</span>, <span class="stringliteral">&quot;macro&quot;</span>, <span class="stringliteral">&quot;weighted&quot;</span>, <span class="stringliteral">&quot;samples&quot;</span>)</div>
<div class="line"><span class="lineno"> 2354</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2355</span>        average_options = (<span class="stringliteral">&quot;micro&quot;</span>, <span class="stringliteral">&quot;macro&quot;</span>, <span class="stringliteral">&quot;weighted&quot;</span>)</div>
<div class="line"><span class="lineno"> 2356</span> </div>
<div class="line"><span class="lineno"> 2357</span>    <span class="keywordflow">if</span> output_dict:</div>
<div class="line"><span class="lineno"> 2358</span>        report_dict = {label[0]: label[1:] <span class="keywordflow">for</span> label <span class="keywordflow">in</span> rows}</div>
<div class="line"><span class="lineno"> 2359</span>        <span class="keywordflow">for</span> label, scores <span class="keywordflow">in</span> report_dict.items():</div>
<div class="line"><span class="lineno"> 2360</span>            report_dict[label] = dict(zip(headers, [i.item() <span class="keywordflow">for</span> i <span class="keywordflow">in</span> scores]))</div>
<div class="line"><span class="lineno"> 2361</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2362</span>        longest_last_line_heading = <span class="stringliteral">&quot;weighted avg&quot;</span></div>
<div class="line"><span class="lineno"> 2363</span>        name_width = max(len(cn) <span class="keywordflow">for</span> cn <span class="keywordflow">in</span> target_names)</div>
<div class="line"><span class="lineno"> 2364</span>        width = max(name_width, len(longest_last_line_heading), digits)</div>
<div class="line"><span class="lineno"> 2365</span>        head_fmt = <span class="stringliteral">&quot;{:&gt;{width}s} &quot;</span> + <span class="stringliteral">&quot; {:&gt;9}&quot;</span> * len(headers)</div>
<div class="line"><span class="lineno"> 2366</span>        report = head_fmt.format(<span class="stringliteral">&quot;&quot;</span>, *headers, width=width)</div>
<div class="line"><span class="lineno"> 2367</span>        report += <span class="stringliteral">&quot;\n\n&quot;</span></div>
<div class="line"><span class="lineno"> 2368</span>        row_fmt = <span class="stringliteral">&quot;{:&gt;{width}s} &quot;</span> + <span class="stringliteral">&quot; {:&gt;9.{digits}f}&quot;</span> * 3 + <span class="stringliteral">&quot; {:&gt;9}\n&quot;</span></div>
<div class="line"><span class="lineno"> 2369</span>        <span class="keywordflow">for</span> row <span class="keywordflow">in</span> rows:</div>
<div class="line"><span class="lineno"> 2370</span>            report += row_fmt.format(*row, width=width, digits=digits)</div>
<div class="line"><span class="lineno"> 2371</span>        report += <span class="stringliteral">&quot;\n&quot;</span></div>
<div class="line"><span class="lineno"> 2372</span> </div>
<div class="line"><span class="lineno"> 2373</span>    <span class="comment"># compute all applicable averages</span></div>
<div class="line"><span class="lineno"> 2374</span>    <span class="keywordflow">for</span> average <span class="keywordflow">in</span> average_options:</div>
<div class="line"><span class="lineno"> 2375</span>        <span class="keywordflow">if</span> average.startswith(<span class="stringliteral">&quot;micro&quot;</span>) <span class="keywordflow">and</span> micro_is_accuracy:</div>
<div class="line"><span class="lineno"> 2376</span>            line_heading = <span class="stringliteral">&quot;accuracy&quot;</span></div>
<div class="line"><span class="lineno"> 2377</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2378</span>            line_heading = average + <span class="stringliteral">&quot; avg&quot;</span></div>
<div class="line"><span class="lineno"> 2379</span> </div>
<div class="line"><span class="lineno"> 2380</span>        <span class="comment"># compute averages with specified averaging method</span></div>
<div class="line"><span class="lineno"> 2381</span>        avg_p, avg_r, avg_f1, _ = precision_recall_fscore_support(</div>
<div class="line"><span class="lineno"> 2382</span>            y_true,</div>
<div class="line"><span class="lineno"> 2383</span>            y_pred,</div>
<div class="line"><span class="lineno"> 2384</span>            labels=labels,</div>
<div class="line"><span class="lineno"> 2385</span>            average=average,</div>
<div class="line"><span class="lineno"> 2386</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno"> 2387</span>            zero_division=zero_division,</div>
<div class="line"><span class="lineno"> 2388</span>        )</div>
<div class="line"><span class="lineno"> 2389</span>        avg = [avg_p, avg_r, avg_f1, np.sum(s)]</div>
<div class="line"><span class="lineno"> 2390</span> </div>
<div class="line"><span class="lineno"> 2391</span>        <span class="keywordflow">if</span> output_dict:</div>
<div class="line"><span class="lineno"> 2392</span>            report_dict[line_heading] = dict(zip(headers, [i.item() <span class="keywordflow">for</span> i <span class="keywordflow">in</span> avg]))</div>
<div class="line"><span class="lineno"> 2393</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2394</span>            <span class="keywordflow">if</span> line_heading == <span class="stringliteral">&quot;accuracy&quot;</span>:</div>
<div class="line"><span class="lineno"> 2395</span>                row_fmt_accuracy = (</div>
<div class="line"><span class="lineno"> 2396</span>                    <span class="stringliteral">&quot;{:&gt;{width}s} &quot;</span></div>
<div class="line"><span class="lineno"> 2397</span>                    + <span class="stringliteral">&quot; {:&gt;9.{digits}}&quot;</span> * 2</div>
<div class="line"><span class="lineno"> 2398</span>                    + <span class="stringliteral">&quot; {:&gt;9.{digits}f}&quot;</span></div>
<div class="line"><span class="lineno"> 2399</span>                    + <span class="stringliteral">&quot; {:&gt;9}\n&quot;</span></div>
<div class="line"><span class="lineno"> 2400</span>                )</div>
<div class="line"><span class="lineno"> 2401</span>                report += row_fmt_accuracy.format(</div>
<div class="line"><span class="lineno"> 2402</span>                    line_heading, <span class="stringliteral">&quot;&quot;</span>, <span class="stringliteral">&quot;&quot;</span>, *avg[2:], width=width, digits=digits</div>
<div class="line"><span class="lineno"> 2403</span>                )</div>
<div class="line"><span class="lineno"> 2404</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2405</span>                report += row_fmt.format(line_heading, *avg, width=width, digits=digits)</div>
<div class="line"><span class="lineno"> 2406</span> </div>
<div class="line"><span class="lineno"> 2407</span>    <span class="keywordflow">if</span> output_dict:</div>
<div class="line"><span class="lineno"> 2408</span>        <span class="keywordflow">if</span> <span class="stringliteral">&quot;accuracy&quot;</span> <span class="keywordflow">in</span> report_dict.keys():</div>
<div class="line"><span class="lineno"> 2409</span>            report_dict[<span class="stringliteral">&quot;accuracy&quot;</span>] = report_dict[<span class="stringliteral">&quot;accuracy&quot;</span>][<span class="stringliteral">&quot;precision&quot;</span>]</div>
<div class="line"><span class="lineno"> 2410</span>        <span class="keywordflow">return</span> report_dict</div>
<div class="line"><span class="lineno"> 2411</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2412</span>        <span class="keywordflow">return</span> report</div>
<div class="line"><span class="lineno"> 2413</span> </div>
<div class="line"><span class="lineno"> 2414</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab7bd039c8960d00f76b0b8cca4376b1c" name="ab7bd039c8960d00f76b0b8cca4376b1c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab7bd039c8960d00f76b0b8cca4376b1c">&#9670;&#160;</a></span>cohen_kappa_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.cohen_kappa_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>weights</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute Cohen's kappa: a statistic that measures inter-annotator agreement.

This function computes Cohen's kappa [1]_, a score that expresses the level
of agreement between two annotators on a classification problem. It is
defined as

.. math::
\kappa = (p_o - p_e) / (1 - p_e)

where :math:`p_o` is the empirical probability of agreement on the label
assigned to any sample (the observed agreement ratio), and :math:`p_e` is
the expected agreement when both annotators assign labels randomly.
:math:`p_e` is estimated using a per-annotator empirical prior over the
class labels [2]_.

Read more in the :ref:`User Guide &lt;cohen_kappa&gt;`.

Parameters
----------
y1 : array of shape (n_samples,)
Labels assigned by the first annotator.

y2 : array of shape (n_samples,)
Labels assigned by the second annotator. The kappa statistic is
symmetric, so swapping ``y1`` and ``y2`` doesn't change the value.

labels : array-like of shape (n_classes,), default=None
List of labels to index the matrix. This may be used to select a
subset of labels. If `None`, all labels that appear at least once in
``y1`` or ``y2`` are used.

weights : {'linear', 'quadratic'}, default=None
Weighting type to calculate the score. `None` means no weighted;
"linear" means linear weighted; "quadratic" means quadratic weighted.

sample_weight : array-like of shape (n_samples,), default=None
Sample weights.

Returns
-------
kappa : float
The kappa statistic, which is a number between -1 and 1. The maximum
value means complete agreement; zero or lower means chance agreement.

References
----------
.. [1] :doi:`J. Cohen (1960). "A coefficient of agreement for nominal scales".
   Educational and Psychological Measurement 20(1):37-46.
   &lt;10.1177/001316446002000104&gt;`
.. [2] `R. Artstein and M. Poesio (2008). "Inter-coder agreement for
   computational linguistics". Computational Linguistics 34(4):555-596
   &lt;https://www.mitpressjournals.org/doi/pdf/10.1162/coli.07-034-R2&gt;`_.
.. [3] `Wikipedia entry for the Cohen's kappa
    &lt;https://en.wikipedia.org/wiki/Cohen%27s_kappa&gt;`_.
</pre> <div class="fragment"><div class="line"><span class="lineno">  598</span><span class="keyword">def </span>cohen_kappa_score(y1, y2, *, labels=None, weights=None, sample_weight=None):</div>
<div class="line"><span class="lineno">  599</span>    <span class="stringliteral">r&quot;&quot;&quot;Compute Cohen&#39;s kappa: a statistic that measures inter-annotator agreement.</span></div>
<div class="line"><span class="lineno">  600</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  601</span><span class="stringliteral">    This function computes Cohen&#39;s kappa [1]_, a score that expresses the level</span></div>
<div class="line"><span class="lineno">  602</span><span class="stringliteral">    of agreement between two annotators on a classification problem. It is</span></div>
<div class="line"><span class="lineno">  603</span><span class="stringliteral">    defined as</span></div>
<div class="line"><span class="lineno">  604</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  605</span><span class="stringliteral">    .. math::</span></div>
<div class="line"><span class="lineno">  606</span><span class="stringliteral">        \kappa = (p_o - p_e) / (1 - p_e)</span></div>
<div class="line"><span class="lineno">  607</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  608</span><span class="stringliteral">    where :math:`p_o` is the empirical probability of agreement on the label</span></div>
<div class="line"><span class="lineno">  609</span><span class="stringliteral">    assigned to any sample (the observed agreement ratio), and :math:`p_e` is</span></div>
<div class="line"><span class="lineno">  610</span><span class="stringliteral">    the expected agreement when both annotators assign labels randomly.</span></div>
<div class="line"><span class="lineno">  611</span><span class="stringliteral">    :math:`p_e` is estimated using a per-annotator empirical prior over the</span></div>
<div class="line"><span class="lineno">  612</span><span class="stringliteral">    class labels [2]_.</span></div>
<div class="line"><span class="lineno">  613</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  614</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;cohen_kappa&gt;`.</span></div>
<div class="line"><span class="lineno">  615</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  616</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  617</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  618</span><span class="stringliteral">    y1 : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  619</span><span class="stringliteral">        Labels assigned by the first annotator.</span></div>
<div class="line"><span class="lineno">  620</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  621</span><span class="stringliteral">    y2 : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  622</span><span class="stringliteral">        Labels assigned by the second annotator. The kappa statistic is</span></div>
<div class="line"><span class="lineno">  623</span><span class="stringliteral">        symmetric, so swapping ``y1`` and ``y2`` doesn&#39;t change the value.</span></div>
<div class="line"><span class="lineno">  624</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  625</span><span class="stringliteral">    labels : array-like of shape (n_classes,), default=None</span></div>
<div class="line"><span class="lineno">  626</span><span class="stringliteral">        List of labels to index the matrix. This may be used to select a</span></div>
<div class="line"><span class="lineno">  627</span><span class="stringliteral">        subset of labels. If `None`, all labels that appear at least once in</span></div>
<div class="line"><span class="lineno">  628</span><span class="stringliteral">        ``y1`` or ``y2`` are used.</span></div>
<div class="line"><span class="lineno">  629</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  630</span><span class="stringliteral">    weights : {&#39;linear&#39;, &#39;quadratic&#39;}, default=None</span></div>
<div class="line"><span class="lineno">  631</span><span class="stringliteral">        Weighting type to calculate the score. `None` means no weighted;</span></div>
<div class="line"><span class="lineno">  632</span><span class="stringliteral">        &quot;linear&quot; means linear weighted; &quot;quadratic&quot; means quadratic weighted.</span></div>
<div class="line"><span class="lineno">  633</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  634</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  635</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  636</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  637</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  638</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  639</span><span class="stringliteral">    kappa : float</span></div>
<div class="line"><span class="lineno">  640</span><span class="stringliteral">        The kappa statistic, which is a number between -1 and 1. The maximum</span></div>
<div class="line"><span class="lineno">  641</span><span class="stringliteral">        value means complete agreement; zero or lower means chance agreement.</span></div>
<div class="line"><span class="lineno">  642</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  643</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  644</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  645</span><span class="stringliteral">    .. [1] :doi:`J. Cohen (1960). &quot;A coefficient of agreement for nominal scales&quot;.</span></div>
<div class="line"><span class="lineno">  646</span><span class="stringliteral">           Educational and Psychological Measurement 20(1):37-46.</span></div>
<div class="line"><span class="lineno">  647</span><span class="stringliteral">           &lt;10.1177/001316446002000104&gt;`</span></div>
<div class="line"><span class="lineno">  648</span><span class="stringliteral">    .. [2] `R. Artstein and M. Poesio (2008). &quot;Inter-coder agreement for</span></div>
<div class="line"><span class="lineno">  649</span><span class="stringliteral">           computational linguistics&quot;. Computational Linguistics 34(4):555-596</span></div>
<div class="line"><span class="lineno">  650</span><span class="stringliteral">           &lt;https://www.mitpressjournals.org/doi/pdf/10.1162/coli.07-034-R2&gt;`_.</span></div>
<div class="line"><span class="lineno">  651</span><span class="stringliteral">    .. [3] `Wikipedia entry for the Cohen&#39;s kappa</span></div>
<div class="line"><span class="lineno">  652</span><span class="stringliteral">            &lt;https://en.wikipedia.org/wiki/Cohen%27s_kappa&gt;`_.</span></div>
<div class="line"><span class="lineno">  653</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  654</span>    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  655</span>    n_classes = confusion.shape[0]</div>
<div class="line"><span class="lineno">  656</span>    sum0 = np.sum(confusion, axis=0)</div>
<div class="line"><span class="lineno">  657</span>    sum1 = np.sum(confusion, axis=1)</div>
<div class="line"><span class="lineno">  658</span>    expected = np.outer(sum0, sum1) / np.sum(sum0)</div>
<div class="line"><span class="lineno">  659</span> </div>
<div class="line"><span class="lineno">  660</span>    <span class="keywordflow">if</span> weights <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  661</span>        w_mat = np.ones([n_classes, n_classes], dtype=int)</div>
<div class="line"><span class="lineno">  662</span>        w_mat.flat[:: n_classes + 1] = 0</div>
<div class="line"><span class="lineno">  663</span>    <span class="keywordflow">elif</span> weights == <span class="stringliteral">&quot;linear&quot;</span> <span class="keywordflow">or</span> weights == <span class="stringliteral">&quot;quadratic&quot;</span>:</div>
<div class="line"><span class="lineno">  664</span>        w_mat = np.zeros([n_classes, n_classes], dtype=int)</div>
<div class="line"><span class="lineno">  665</span>        w_mat += np.arange(n_classes)</div>
<div class="line"><span class="lineno">  666</span>        <span class="keywordflow">if</span> weights == <span class="stringliteral">&quot;linear&quot;</span>:</div>
<div class="line"><span class="lineno">  667</span>            w_mat = np.abs(w_mat - w_mat.T)</div>
<div class="line"><span class="lineno">  668</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  669</span>            w_mat = (w_mat - w_mat.T) ** 2</div>
<div class="line"><span class="lineno">  670</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  671</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Unknown kappa weighting type.&quot;</span>)</div>
<div class="line"><span class="lineno">  672</span> </div>
<div class="line"><span class="lineno">  673</span>    k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)</div>
<div class="line"><span class="lineno">  674</span>    <span class="keywordflow">return</span> 1 - k</div>
<div class="line"><span class="lineno">  675</span> </div>
<div class="line"><span class="lineno">  676</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae9c0ac1227a02fe7b672aad2a98f301f" name="ae9c0ac1227a02fe7b672aad2a98f301f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9c0ac1227a02fe7b672aad2a98f301f">&#9670;&#160;</a></span>confusion_matrix()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.confusion_matrix </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute confusion matrix to evaluate the accuracy of a classification.

By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`
is equal to the number of observations known to be in group :math:`i` and
predicted to be in group :math:`j`.

Thus in binary classification, the count of true negatives is
:math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is
:math:`C_{1,1}` and false positives is :math:`C_{0,1}`.

Read more in the :ref:`User Guide &lt;confusion_matrix&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,)
    Ground truth (correct) target values.

y_pred : array-like of shape (n_samples,)
    Estimated targets as returned by a classifier.

labels : array-like of shape (n_classes), default=None
    List of labels to index the matrix. This may be used to reorder
    or select a subset of labels.
    If ``None`` is given, those that appear at least once
    in ``y_true`` or ``y_pred`` are used in sorted order.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

    .. versionadded:: 0.18

normalize : {'true', 'pred', 'all'}, default=None
    Normalizes confusion matrix over the true (rows), predicted (columns)
    conditions or all the population. If None, confusion matrix will not be
    normalized.

Returns
-------
C : ndarray of shape (n_classes, n_classes)
    Confusion matrix whose i-th row and j-th
    column entry indicates the number of
    samples with true label being i-th class
    and predicted label being j-th class.

See Also
--------
ConfusionMatrixDisplay.from_estimator : Plot the confusion matrix
    given an estimator, the data, and the label.
ConfusionMatrixDisplay.from_predictions : Plot the confusion matrix
    given the true and predicted labels.
ConfusionMatrixDisplay : Confusion Matrix visualization.

References
----------
.. [1] `Wikipedia entry for the Confusion matrix
       &lt;https://en.wikipedia.org/wiki/Confusion_matrix&gt;`_
       (Wikipedia and other references may use a different
       convention for axes).

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import confusion_matrix
&gt;&gt;&gt; y_true = [2, 0, 2, 2, 0, 1]
&gt;&gt;&gt; y_pred = [0, 0, 2, 2, 0, 2]
&gt;&gt;&gt; confusion_matrix(y_true, y_pred)
array([[2, 0, 0],
       [0, 0, 1],
       [1, 0, 2]])

&gt;&gt;&gt; y_true = ["cat", "ant", "cat", "cat", "ant", "bird"]
&gt;&gt;&gt; y_pred = ["ant", "ant", "cat", "cat", "ant", "cat"]
&gt;&gt;&gt; confusion_matrix(y_true, y_pred, labels=["ant", "bird", "cat"])
array([[2, 0, 0],
       [0, 0, 1],
       [1, 0, 2]])

In the binary case, we can extract true positives, etc as follows:

&gt;&gt;&gt; tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()
&gt;&gt;&gt; (tn, fp, fn, tp)
(0, 2, 1, 1)
</pre> <div class="fragment"><div class="line"><span class="lineno">  234</span>):</div>
<div class="line"><span class="lineno">  235</span>    <span class="stringliteral">&quot;&quot;&quot;Compute confusion matrix to evaluate the accuracy of a classification.</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">    is equal to the number of observations known to be in group :math:`i` and</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">    predicted to be in group :math:`j`.</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">    Thus in binary classification, the count of true negatives is</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">    :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">    :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;confusion_matrix&gt;`.</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">    y_true : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">    y_pred : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">    labels : array-like of shape (n_classes), default=None</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">        List of labels to index the matrix. This may be used to reorder</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">        or select a subset of labels.</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">        If ``None`` is given, those that appear at least once</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">        in ``y_true`` or ``y_pred`` are used in sorted order.</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">        .. versionadded:: 0.18</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">    normalize : {&#39;true&#39;, &#39;pred&#39;, &#39;all&#39;}, default=None</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">        Normalizes confusion matrix over the true (rows), predicted (columns)</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">        conditions or all the population. If None, confusion matrix will not be</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral">        normalized.</span></div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">    C : ndarray of shape (n_classes, n_classes)</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral">        Confusion matrix whose i-th row and j-th</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">        column entry indicates the number of</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">        samples with true label being i-th class</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral">        and predicted label being j-th class.</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    ConfusionMatrixDisplay.from_estimator : Plot the confusion matrix</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">        given an estimator, the data, and the label.</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">    ConfusionMatrixDisplay.from_predictions : Plot the confusion matrix</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">        given the true and predicted labels.</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">    ConfusionMatrixDisplay : Confusion Matrix visualization.</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">    .. [1] `Wikipedia entry for the Confusion matrix</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/Confusion_matrix&gt;`_</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">           (Wikipedia and other references may use a different</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">           convention for axes).</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import confusion_matrix</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [2, 0, 2, 2, 0, 1]</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 0, 2, 2, 0, 2]</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">    &gt;&gt;&gt; confusion_matrix(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">    array([[2, 0, 0],</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">           [0, 0, 1],</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">           [1, 0, 2]])</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [&quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;bird&quot;]</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [&quot;ant&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;]</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    &gt;&gt;&gt; confusion_matrix(y_true, y_pred, labels=[&quot;ant&quot;, &quot;bird&quot;, &quot;cat&quot;])</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">    array([[2, 0, 0],</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">           [0, 0, 1],</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">           [1, 0, 2]])</span></div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">    In the binary case, we can extract true positives, etc as follows:</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">    &gt;&gt;&gt; tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral">    &gt;&gt;&gt; (tn, fp, fn, tp)</span></div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">    (0, 2, 1, 1)</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  317</span>    y_type, y_true, y_pred = _check_targets(y_true, y_pred)</div>
<div class="line"><span class="lineno">  318</span>    <span class="keywordflow">if</span> y_type <span class="keywordflow">not</span> <span class="keywordflow">in</span> (<span class="stringliteral">&quot;binary&quot;</span>, <span class="stringliteral">&quot;multiclass&quot;</span>):</div>
<div class="line"><span class="lineno">  319</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;%s is not supported&quot;</span> % y_type)</div>
<div class="line"><span class="lineno">  320</span> </div>
<div class="line"><span class="lineno">  321</span>    <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  322</span>        labels = unique_labels(y_true, y_pred)</div>
<div class="line"><span class="lineno">  323</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  324</span>        labels = np.asarray(labels)</div>
<div class="line"><span class="lineno">  325</span>        n_labels = labels.size</div>
<div class="line"><span class="lineno">  326</span>        <span class="keywordflow">if</span> n_labels == 0:</div>
<div class="line"><span class="lineno">  327</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;&#39;labels&#39; should contains at least one label.&quot;</span>)</div>
<div class="line"><span class="lineno">  328</span>        <span class="keywordflow">elif</span> y_true.size == 0:</div>
<div class="line"><span class="lineno">  329</span>            <span class="keywordflow">return</span> np.zeros((n_labels, n_labels), dtype=int)</div>
<div class="line"><span class="lineno">  330</span>        <span class="keywordflow">elif</span> len(np.intersect1d(y_true, labels)) == 0:</div>
<div class="line"><span class="lineno">  331</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;At least one label specified must be in y_true&quot;</span>)</div>
<div class="line"><span class="lineno">  332</span> </div>
<div class="line"><span class="lineno">  333</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  334</span>        sample_weight = np.ones(y_true.shape[0], dtype=np.int64)</div>
<div class="line"><span class="lineno">  335</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  336</span>        sample_weight = np.asarray(sample_weight)</div>
<div class="line"><span class="lineno">  337</span> </div>
<div class="line"><span class="lineno">  338</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  339</span> </div>
<div class="line"><span class="lineno">  340</span>    <span class="keywordflow">if</span> normalize <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&quot;true&quot;</span>, <span class="stringliteral">&quot;pred&quot;</span>, <span class="stringliteral">&quot;all&quot;</span>, <span class="keywordtype">None</span>]:</div>
<div class="line"><span class="lineno">  341</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;normalize must be one of {&#39;true&#39;, &#39;pred&#39;, &#39;all&#39;, None}&quot;</span>)</div>
<div class="line"><span class="lineno">  342</span> </div>
<div class="line"><span class="lineno">  343</span>    n_labels = labels.size</div>
<div class="line"><span class="lineno">  344</span>    <span class="comment"># If labels are not consecutive integers starting from zero, then</span></div>
<div class="line"><span class="lineno">  345</span>    <span class="comment"># y_true and y_pred must be converted into index form</span></div>
<div class="line"><span class="lineno">  346</span>    need_index_conversion = <span class="keywordflow">not</span> (</div>
<div class="line"><span class="lineno">  347</span>        labels.dtype.kind <span class="keywordflow">in</span> {<span class="stringliteral">&quot;i&quot;</span>, <span class="stringliteral">&quot;u&quot;</span>, <span class="stringliteral">&quot;b&quot;</span>}</div>
<div class="line"><span class="lineno">  348</span>        <span class="keywordflow">and</span> np.all(labels == np.arange(n_labels))</div>
<div class="line"><span class="lineno">  349</span>        <span class="keywordflow">and</span> y_true.min() &gt;= 0</div>
<div class="line"><span class="lineno">  350</span>        <span class="keywordflow">and</span> y_pred.min() &gt;= 0</div>
<div class="line"><span class="lineno">  351</span>    )</div>
<div class="line"><span class="lineno">  352</span>    <span class="keywordflow">if</span> need_index_conversion:</div>
<div class="line"><span class="lineno">  353</span>        label_to_ind = {y: x <span class="keywordflow">for</span> x, y <span class="keywordflow">in</span> enumerate(labels)}</div>
<div class="line"><span class="lineno">  354</span>        y_pred = np.array([label_to_ind.get(x, n_labels + 1) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> y_pred])</div>
<div class="line"><span class="lineno">  355</span>        y_true = np.array([label_to_ind.get(x, n_labels + 1) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> y_true])</div>
<div class="line"><span class="lineno">  356</span> </div>
<div class="line"><span class="lineno">  357</span>    <span class="comment"># intersect y_pred, y_true with labels, eliminate items not in labels</span></div>
<div class="line"><span class="lineno">  358</span>    ind = np.logical_and(y_pred &lt; n_labels, y_true &lt; n_labels)</div>
<div class="line"><span class="lineno">  359</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.all(ind):</div>
<div class="line"><span class="lineno">  360</span>        y_pred = y_pred[ind]</div>
<div class="line"><span class="lineno">  361</span>        y_true = y_true[ind]</div>
<div class="line"><span class="lineno">  362</span>        <span class="comment"># also eliminate weights of eliminated items</span></div>
<div class="line"><span class="lineno">  363</span>        sample_weight = sample_weight[ind]</div>
<div class="line"><span class="lineno">  364</span> </div>
<div class="line"><span class="lineno">  365</span>    <span class="comment"># Choose the accumulator dtype to always have high precision</span></div>
<div class="line"><span class="lineno">  366</span>    <span class="keywordflow">if</span> sample_weight.dtype.kind <span class="keywordflow">in</span> {<span class="stringliteral">&quot;i&quot;</span>, <span class="stringliteral">&quot;u&quot;</span>, <span class="stringliteral">&quot;b&quot;</span>}:</div>
<div class="line"><span class="lineno">  367</span>        dtype = np.int64</div>
<div class="line"><span class="lineno">  368</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  369</span>        dtype = np.float64</div>
<div class="line"><span class="lineno">  370</span> </div>
<div class="line"><span class="lineno">  371</span>    cm = coo_matrix(</div>
<div class="line"><span class="lineno">  372</span>        (sample_weight, (y_true, y_pred)),</div>
<div class="line"><span class="lineno">  373</span>        shape=(n_labels, n_labels),</div>
<div class="line"><span class="lineno">  374</span>        dtype=dtype,</div>
<div class="line"><span class="lineno">  375</span>    ).toarray()</div>
<div class="line"><span class="lineno">  376</span> </div>
<div class="line"><span class="lineno">  377</span>    <span class="keyword">with</span> np.errstate(all=<span class="stringliteral">&quot;ignore&quot;</span>):</div>
<div class="line"><span class="lineno">  378</span>        <span class="keywordflow">if</span> normalize == <span class="stringliteral">&quot;true&quot;</span>:</div>
<div class="line"><span class="lineno">  379</span>            cm = cm / cm.sum(axis=1, keepdims=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  380</span>        <span class="keywordflow">elif</span> normalize == <span class="stringliteral">&quot;pred&quot;</span>:</div>
<div class="line"><span class="lineno">  381</span>            cm = cm / cm.sum(axis=0, keepdims=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  382</span>        <span class="keywordflow">elif</span> normalize == <span class="stringliteral">&quot;all&quot;</span>:</div>
<div class="line"><span class="lineno">  383</span>            cm = cm / cm.sum()</div>
<div class="line"><span class="lineno">  384</span>        cm = np.nan_to_num(cm)</div>
<div class="line"><span class="lineno">  385</span> </div>
<div class="line"><span class="lineno">  386</span>    <span class="keywordflow">return</span> cm</div>
<div class="line"><span class="lineno">  387</span> </div>
<div class="line"><span class="lineno">  388</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8907858d9147ef9e0b71391e04e04904" name="a8907858d9147ef9e0b71391e04e04904"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8907858d9147ef9e0b71391e04e04904">&#9670;&#160;</a></span>f1_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.f1_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average</em> = <code>&quot;binary&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zero_division</em> = <code>&quot;warn&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the F1 score, also known as balanced F-score or F-measure.

The F1 score can be interpreted as a harmonic mean of the precision and
recall, where an F1 score reaches its best value at 1 and worst score at 0.
The relative contribution of precision and recall to the F1 score are
equal. The formula for the F1 score is::

    F1 = 2 * (precision * recall) / (precision + recall)

In the multi-class and multi-label case, this is the average of
the F1 score of each class with weighting depending on the ``average``
parameter.

Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) target values.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Estimated targets as returned by a classifier.

labels : array-like, default=None
    The set of labels to include when ``average != 'binary'``, and their
    order if ``average is None``. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in ``y_true`` and
    ``y_pred`` are used in sorted order.

    .. versionchanged:: 0.17
       Parameter `labels` improved for multiclass problem.

pos_label : str or int, default=1
    The class to report if ``average='binary'`` and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting ``labels=[pos_label]`` and ``average != 'binary'`` will report
    scores for that label only.

average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None, \
        default='binary'
    This parameter is required for multiclass/multilabel targets.
    If ``None``, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:

    ``'binary'``:
        Only report results for the class specified by ``pos_label``.
        This is applicable only if targets (``y_{true,pred}``) are binary.
    ``'micro'``:
        Calculate metrics globally by counting the total true positives,
        false negatives and false positives.
    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    ``'weighted'``:
        Calculate metrics for each label, and find their average weighted
        by support (the number of true instances for each label). This
        alters 'macro' to account for label imbalance; it can result in an
        F-score that is not between precision and recall.
    ``'samples'``:
        Calculate metrics for each instance, and find their average (only
        meaningful for multilabel classification where this differs from
        :func:`accuracy_score`).

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

zero_division : "warn", 0 or 1, default="warn"
    Sets the value to return when there is a zero division, i.e. when all
    predictions and labels are negative. If set to "warn", this acts as 0,
    but warnings are also raised.

Returns
-------
f1_score : float or array of float, shape = [n_unique_labels]
    F1 score of the positive class in binary classification or weighted
    average of the F1 scores of each class for the multiclass task.

See Also
--------
fbeta_score : Compute the F-beta score.
precision_recall_fscore_support : Compute the precision, recall, F-score,
    and support.
jaccard_score : Compute the Jaccard similarity coefficient score.
multilabel_confusion_matrix : Compute a confusion matrix for each class or
    sample.

Notes
-----
When ``true positive + false positive == 0``, precision is undefined.
When ``true positive + false negative == 0``, recall is undefined.
In such cases, by default the metric will be set to 0, as will f-score,
and ``UndefinedMetricWarning`` will be raised. This behavior can be
modified with ``zero_division``.

References
----------
.. [1] `Wikipedia entry for the F1-score
       &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import f1_score
&gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]
&gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]
&gt;&gt;&gt; f1_score(y_true, y_pred, average='macro')
0.26...
&gt;&gt;&gt; f1_score(y_true, y_pred, average='micro')
0.33...
&gt;&gt;&gt; f1_score(y_true, y_pred, average='weighted')
0.26...
&gt;&gt;&gt; f1_score(y_true, y_pred, average=None)
array([0.8, 0. , 0. ])
&gt;&gt;&gt; y_true = [0, 0, 0, 0, 0, 0]
&gt;&gt;&gt; y_pred = [0, 0, 0, 0, 0, 0]
&gt;&gt;&gt; f1_score(y_true, y_pred, zero_division=1)
1.0...
&gt;&gt;&gt; # multilabel classification
&gt;&gt;&gt; y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]
&gt;&gt;&gt; y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]
&gt;&gt;&gt; f1_score(y_true, y_pred, average=None)
array([0.66666667, 1.        , 0.66666667])
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1020</span>):</div>
<div class="line"><span class="lineno"> 1021</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the F1 score, also known as balanced F-score or F-measure.</span></div>
<div class="line"><span class="lineno"> 1022</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1023</span><span class="stringliteral">    The F1 score can be interpreted as a harmonic mean of the precision and</span></div>
<div class="line"><span class="lineno"> 1024</span><span class="stringliteral">    recall, where an F1 score reaches its best value at 1 and worst score at 0.</span></div>
<div class="line"><span class="lineno"> 1025</span><span class="stringliteral">    The relative contribution of precision and recall to the F1 score are</span></div>
<div class="line"><span class="lineno"> 1026</span><span class="stringliteral">    equal. The formula for the F1 score is::</span></div>
<div class="line"><span class="lineno"> 1027</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1028</span><span class="stringliteral">        F1 = 2 * (precision * recall) / (precision + recall)</span></div>
<div class="line"><span class="lineno"> 1029</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1030</span><span class="stringliteral">    In the multi-class and multi-label case, this is the average of</span></div>
<div class="line"><span class="lineno"> 1031</span><span class="stringliteral">    the F1 score of each class with weighting depending on the ``average``</span></div>
<div class="line"><span class="lineno"> 1032</span><span class="stringliteral">    parameter.</span></div>
<div class="line"><span class="lineno"> 1033</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1034</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span></div>
<div class="line"><span class="lineno"> 1035</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1036</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1037</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1038</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1039</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 1040</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1041</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1042</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno"> 1043</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1044</span><span class="stringliteral">    labels : array-like, default=None</span></div>
<div class="line"><span class="lineno"> 1045</span><span class="stringliteral">        The set of labels to include when ``average != &#39;binary&#39;``, and their</span></div>
<div class="line"><span class="lineno"> 1046</span><span class="stringliteral">        order if ``average is None``. Labels present in the data can be</span></div>
<div class="line"><span class="lineno"> 1047</span><span class="stringliteral">        excluded, for example to calculate a multiclass average ignoring a</span></div>
<div class="line"><span class="lineno"> 1048</span><span class="stringliteral">        majority negative class, while labels not present in the data will</span></div>
<div class="line"><span class="lineno"> 1049</span><span class="stringliteral">        result in 0 components in a macro average. For multilabel targets,</span></div>
<div class="line"><span class="lineno"> 1050</span><span class="stringliteral">        labels are column indices. By default, all labels in ``y_true`` and</span></div>
<div class="line"><span class="lineno"> 1051</span><span class="stringliteral">        ``y_pred`` are used in sorted order.</span></div>
<div class="line"><span class="lineno"> 1052</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1053</span><span class="stringliteral">        .. versionchanged:: 0.17</span></div>
<div class="line"><span class="lineno"> 1054</span><span class="stringliteral">           Parameter `labels` improved for multiclass problem.</span></div>
<div class="line"><span class="lineno"> 1055</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1056</span><span class="stringliteral">    pos_label : str or int, default=1</span></div>
<div class="line"><span class="lineno"> 1057</span><span class="stringliteral">        The class to report if ``average=&#39;binary&#39;`` and the data is binary.</span></div>
<div class="line"><span class="lineno"> 1058</span><span class="stringliteral">        If the data are multiclass or multilabel, this will be ignored;</span></div>
<div class="line"><span class="lineno"> 1059</span><span class="stringliteral">        setting ``labels=[pos_label]`` and ``average != &#39;binary&#39;`` will report</span></div>
<div class="line"><span class="lineno"> 1060</span><span class="stringliteral">        scores for that label only.</span></div>
<div class="line"><span class="lineno"> 1061</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1062</span><span class="stringliteral">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;, &#39;binary&#39;} or None, \</span></div>
<div class="line"><span class="lineno"> 1063</span><span class="stringliteral">            default=&#39;binary&#39;</span></div>
<div class="line"><span class="lineno"> 1064</span><span class="stringliteral">        This parameter is required for multiclass/multilabel targets.</span></div>
<div class="line"><span class="lineno"> 1065</span><span class="stringliteral">        If ``None``, the scores for each class are returned. Otherwise, this</span></div>
<div class="line"><span class="lineno"> 1066</span><span class="stringliteral">        determines the type of averaging performed on the data:</span></div>
<div class="line"><span class="lineno"> 1067</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1068</span><span class="stringliteral">        ``&#39;binary&#39;``:</span></div>
<div class="line"><span class="lineno"> 1069</span><span class="stringliteral">            Only report results for the class specified by ``pos_label``.</span></div>
<div class="line"><span class="lineno"> 1070</span><span class="stringliteral">            This is applicable only if targets (``y_{true,pred}``) are binary.</span></div>
<div class="line"><span class="lineno"> 1071</span><span class="stringliteral">        ``&#39;micro&#39;``:</span></div>
<div class="line"><span class="lineno"> 1072</span><span class="stringliteral">            Calculate metrics globally by counting the total true positives,</span></div>
<div class="line"><span class="lineno"> 1073</span><span class="stringliteral">            false negatives and false positives.</span></div>
<div class="line"><span class="lineno"> 1074</span><span class="stringliteral">        ``&#39;macro&#39;``:</span></div>
<div class="line"><span class="lineno"> 1075</span><span class="stringliteral">            Calculate metrics for each label, and find their unweighted</span></div>
<div class="line"><span class="lineno"> 1076</span><span class="stringliteral">            mean.  This does not take label imbalance into account.</span></div>
<div class="line"><span class="lineno"> 1077</span><span class="stringliteral">        ``&#39;weighted&#39;``:</span></div>
<div class="line"><span class="lineno"> 1078</span><span class="stringliteral">            Calculate metrics for each label, and find their average weighted</span></div>
<div class="line"><span class="lineno"> 1079</span><span class="stringliteral">            by support (the number of true instances for each label). This</span></div>
<div class="line"><span class="lineno"> 1080</span><span class="stringliteral">            alters &#39;macro&#39; to account for label imbalance; it can result in an</span></div>
<div class="line"><span class="lineno"> 1081</span><span class="stringliteral">            F-score that is not between precision and recall.</span></div>
<div class="line"><span class="lineno"> 1082</span><span class="stringliteral">        ``&#39;samples&#39;``:</span></div>
<div class="line"><span class="lineno"> 1083</span><span class="stringliteral">            Calculate metrics for each instance, and find their average (only</span></div>
<div class="line"><span class="lineno"> 1084</span><span class="stringliteral">            meaningful for multilabel classification where this differs from</span></div>
<div class="line"><span class="lineno"> 1085</span><span class="stringliteral">            :func:`accuracy_score`).</span></div>
<div class="line"><span class="lineno"> 1086</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1087</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1088</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1089</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1090</span><span class="stringliteral">    zero_division : &quot;warn&quot;, 0 or 1, default=&quot;warn&quot;</span></div>
<div class="line"><span class="lineno"> 1091</span><span class="stringliteral">        Sets the value to return when there is a zero division, i.e. when all</span></div>
<div class="line"><span class="lineno"> 1092</span><span class="stringliteral">        predictions and labels are negative. If set to &quot;warn&quot;, this acts as 0,</span></div>
<div class="line"><span class="lineno"> 1093</span><span class="stringliteral">        but warnings are also raised.</span></div>
<div class="line"><span class="lineno"> 1094</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1095</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1096</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1097</span><span class="stringliteral">    f1_score : float or array of float, shape = [n_unique_labels]</span></div>
<div class="line"><span class="lineno"> 1098</span><span class="stringliteral">        F1 score of the positive class in binary classification or weighted</span></div>
<div class="line"><span class="lineno"> 1099</span><span class="stringliteral">        average of the F1 scores of each class for the multiclass task.</span></div>
<div class="line"><span class="lineno"> 1100</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1101</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 1102</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1103</span><span class="stringliteral">    fbeta_score : Compute the F-beta score.</span></div>
<div class="line"><span class="lineno"> 1104</span><span class="stringliteral">    precision_recall_fscore_support : Compute the precision, recall, F-score,</span></div>
<div class="line"><span class="lineno"> 1105</span><span class="stringliteral">        and support.</span></div>
<div class="line"><span class="lineno"> 1106</span><span class="stringliteral">    jaccard_score : Compute the Jaccard similarity coefficient score.</span></div>
<div class="line"><span class="lineno"> 1107</span><span class="stringliteral">    multilabel_confusion_matrix : Compute a confusion matrix for each class or</span></div>
<div class="line"><span class="lineno"> 1108</span><span class="stringliteral">        sample.</span></div>
<div class="line"><span class="lineno"> 1109</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1110</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1111</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1112</span><span class="stringliteral">    When ``true positive + false positive == 0``, precision is undefined.</span></div>
<div class="line"><span class="lineno"> 1113</span><span class="stringliteral">    When ``true positive + false negative == 0``, recall is undefined.</span></div>
<div class="line"><span class="lineno"> 1114</span><span class="stringliteral">    In such cases, by default the metric will be set to 0, as will f-score,</span></div>
<div class="line"><span class="lineno"> 1115</span><span class="stringliteral">    and ``UndefinedMetricWarning`` will be raised. This behavior can be</span></div>
<div class="line"><span class="lineno"> 1116</span><span class="stringliteral">    modified with ``zero_division``.</span></div>
<div class="line"><span class="lineno"> 1117</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1118</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1119</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1120</span><span class="stringliteral">    .. [1] `Wikipedia entry for the F1-score</span></div>
<div class="line"><span class="lineno"> 1121</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.</span></div>
<div class="line"><span class="lineno"> 1122</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1123</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1124</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1125</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import f1_score</span></div>
<div class="line"><span class="lineno"> 1126</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]</span></div>
<div class="line"><span class="lineno"> 1127</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]</span></div>
<div class="line"><span class="lineno"> 1128</span><span class="stringliteral">    &gt;&gt;&gt; f1_score(y_true, y_pred, average=&#39;macro&#39;)</span></div>
<div class="line"><span class="lineno"> 1129</span><span class="stringliteral">    0.26...</span></div>
<div class="line"><span class="lineno"> 1130</span><span class="stringliteral">    &gt;&gt;&gt; f1_score(y_true, y_pred, average=&#39;micro&#39;)</span></div>
<div class="line"><span class="lineno"> 1131</span><span class="stringliteral">    0.33...</span></div>
<div class="line"><span class="lineno"> 1132</span><span class="stringliteral">    &gt;&gt;&gt; f1_score(y_true, y_pred, average=&#39;weighted&#39;)</span></div>
<div class="line"><span class="lineno"> 1133</span><span class="stringliteral">    0.26...</span></div>
<div class="line"><span class="lineno"> 1134</span><span class="stringliteral">    &gt;&gt;&gt; f1_score(y_true, y_pred, average=None)</span></div>
<div class="line"><span class="lineno"> 1135</span><span class="stringliteral">    array([0.8, 0. , 0. ])</span></div>
<div class="line"><span class="lineno"> 1136</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 0, 0, 0, 0, 0]</span></div>
<div class="line"><span class="lineno"> 1137</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 0, 0, 0, 0, 0]</span></div>
<div class="line"><span class="lineno"> 1138</span><span class="stringliteral">    &gt;&gt;&gt; f1_score(y_true, y_pred, zero_division=1)</span></div>
<div class="line"><span class="lineno"> 1139</span><span class="stringliteral">    1.0...</span></div>
<div class="line"><span class="lineno"> 1140</span><span class="stringliteral">    &gt;&gt;&gt; # multilabel classification</span></div>
<div class="line"><span class="lineno"> 1141</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]</span></div>
<div class="line"><span class="lineno"> 1142</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]</span></div>
<div class="line"><span class="lineno"> 1143</span><span class="stringliteral">    &gt;&gt;&gt; f1_score(y_true, y_pred, average=None)</span></div>
<div class="line"><span class="lineno"> 1144</span><span class="stringliteral">    array([0.66666667, 1.        , 0.66666667])</span></div>
<div class="line"><span class="lineno"> 1145</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1146</span>    <span class="keywordflow">return</span> fbeta_score(</div>
<div class="line"><span class="lineno"> 1147</span>        y_true,</div>
<div class="line"><span class="lineno"> 1148</span>        y_pred,</div>
<div class="line"><span class="lineno"> 1149</span>        beta=1,</div>
<div class="line"><span class="lineno"> 1150</span>        labels=labels,</div>
<div class="line"><span class="lineno"> 1151</span>        pos_label=pos_label,</div>
<div class="line"><span class="lineno"> 1152</span>        average=average,</div>
<div class="line"><span class="lineno"> 1153</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno"> 1154</span>        zero_division=zero_division,</div>
<div class="line"><span class="lineno"> 1155</span>    )</div>
<div class="line"><span class="lineno"> 1156</span> </div>
<div class="line"><span class="lineno"> 1157</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa014456eb6be5e0e51a83a59bd4c8fa1" name="aa014456eb6be5e0e51a83a59bd4c8fa1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa014456eb6be5e0e51a83a59bd4c8fa1">&#9670;&#160;</a></span>fbeta_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.fbeta_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average</em> = <code>&quot;binary&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zero_division</em> = <code>&quot;warn&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the F-beta score.

The F-beta score is the weighted harmonic mean of precision and recall,
reaching its optimal value at 1 and its worst value at 0.

The `beta` parameter determines the weight of recall in the combined
score. ``beta &lt; 1`` lends more weight to precision, while ``beta &gt; 1``
favors recall (``beta -&gt; 0`` considers only precision, ``beta -&gt; +inf``
only recall).

Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) target values.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Estimated targets as returned by a classifier.

beta : float
    Determines the weight of recall in the combined score.

labels : array-like, default=None
    The set of labels to include when ``average != 'binary'``, and their
    order if ``average is None``. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in ``y_true`` and
    ``y_pred`` are used in sorted order.

    .. versionchanged:: 0.17
       Parameter `labels` improved for multiclass problem.

pos_label : str or int, default=1
    The class to report if ``average='binary'`` and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting ``labels=[pos_label]`` and ``average != 'binary'`` will report
    scores for that label only.

average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None, \
        default='binary'
    This parameter is required for multiclass/multilabel targets.
    If ``None``, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:

    ``'binary'``:
        Only report results for the class specified by ``pos_label``.
        This is applicable only if targets (``y_{true,pred}``) are binary.
    ``'micro'``:
        Calculate metrics globally by counting the total true positives,
        false negatives and false positives.
    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    ``'weighted'``:
        Calculate metrics for each label, and find their average weighted
        by support (the number of true instances for each label). This
        alters 'macro' to account for label imbalance; it can result in an
        F-score that is not between precision and recall.
    ``'samples'``:
        Calculate metrics for each instance, and find their average (only
        meaningful for multilabel classification where this differs from
        :func:`accuracy_score`).

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

zero_division : "warn", 0 or 1, default="warn"
    Sets the value to return when there is a zero division, i.e. when all
    predictions and labels are negative. If set to "warn", this acts as 0,
    but warnings are also raised.

Returns
-------
fbeta_score : float (if average is not None) or array of float, shape =\
    [n_unique_labels]
    F-beta score of the positive class in binary classification or weighted
    average of the F-beta score of each class for the multiclass task.

See Also
--------
precision_recall_fscore_support : Compute the precision, recall, F-score,
    and support.
multilabel_confusion_matrix : Compute a confusion matrix for each class or
    sample.

Notes
-----
When ``true positive + false positive == 0`` or
``true positive + false negative == 0``, f-score returns 0 and raises
``UndefinedMetricWarning``. This behavior can be
modified with ``zero_division``.

References
----------
.. [1] R. Baeza-Yates and B. Ribeiro-Neto (2011).
       Modern Information Retrieval. Addison Wesley, pp. 327-328.

.. [2] `Wikipedia entry for the F1-score
       &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import fbeta_score
&gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]
&gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]
&gt;&gt;&gt; fbeta_score(y_true, y_pred, average='macro', beta=0.5)
0.23...
&gt;&gt;&gt; fbeta_score(y_true, y_pred, average='micro', beta=0.5)
0.33...
&gt;&gt;&gt; fbeta_score(y_true, y_pred, average='weighted', beta=0.5)
0.23...
&gt;&gt;&gt; fbeta_score(y_true, y_pred, average=None, beta=0.5)
array([0.71..., 0.        , 0.        ])
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1168</span>):</div>
<div class="line"><span class="lineno"> 1169</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the F-beta score.</span></div>
<div class="line"><span class="lineno"> 1170</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1171</span><span class="stringliteral">    The F-beta score is the weighted harmonic mean of precision and recall,</span></div>
<div class="line"><span class="lineno"> 1172</span><span class="stringliteral">    reaching its optimal value at 1 and its worst value at 0.</span></div>
<div class="line"><span class="lineno"> 1173</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1174</span><span class="stringliteral">    The `beta` parameter determines the weight of recall in the combined</span></div>
<div class="line"><span class="lineno"> 1175</span><span class="stringliteral">    score. ``beta &lt; 1`` lends more weight to precision, while ``beta &gt; 1``</span></div>
<div class="line"><span class="lineno"> 1176</span><span class="stringliteral">    favors recall (``beta -&gt; 0`` considers only precision, ``beta -&gt; +inf``</span></div>
<div class="line"><span class="lineno"> 1177</span><span class="stringliteral">    only recall).</span></div>
<div class="line"><span class="lineno"> 1178</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1179</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span></div>
<div class="line"><span class="lineno"> 1180</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1181</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1182</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1183</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1184</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 1185</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1186</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1187</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno"> 1188</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1189</span><span class="stringliteral">    beta : float</span></div>
<div class="line"><span class="lineno"> 1190</span><span class="stringliteral">        Determines the weight of recall in the combined score.</span></div>
<div class="line"><span class="lineno"> 1191</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1192</span><span class="stringliteral">    labels : array-like, default=None</span></div>
<div class="line"><span class="lineno"> 1193</span><span class="stringliteral">        The set of labels to include when ``average != &#39;binary&#39;``, and their</span></div>
<div class="line"><span class="lineno"> 1194</span><span class="stringliteral">        order if ``average is None``. Labels present in the data can be</span></div>
<div class="line"><span class="lineno"> 1195</span><span class="stringliteral">        excluded, for example to calculate a multiclass average ignoring a</span></div>
<div class="line"><span class="lineno"> 1196</span><span class="stringliteral">        majority negative class, while labels not present in the data will</span></div>
<div class="line"><span class="lineno"> 1197</span><span class="stringliteral">        result in 0 components in a macro average. For multilabel targets,</span></div>
<div class="line"><span class="lineno"> 1198</span><span class="stringliteral">        labels are column indices. By default, all labels in ``y_true`` and</span></div>
<div class="line"><span class="lineno"> 1199</span><span class="stringliteral">        ``y_pred`` are used in sorted order.</span></div>
<div class="line"><span class="lineno"> 1200</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1201</span><span class="stringliteral">        .. versionchanged:: 0.17</span></div>
<div class="line"><span class="lineno"> 1202</span><span class="stringliteral">           Parameter `labels` improved for multiclass problem.</span></div>
<div class="line"><span class="lineno"> 1203</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1204</span><span class="stringliteral">    pos_label : str or int, default=1</span></div>
<div class="line"><span class="lineno"> 1205</span><span class="stringliteral">        The class to report if ``average=&#39;binary&#39;`` and the data is binary.</span></div>
<div class="line"><span class="lineno"> 1206</span><span class="stringliteral">        If the data are multiclass or multilabel, this will be ignored;</span></div>
<div class="line"><span class="lineno"> 1207</span><span class="stringliteral">        setting ``labels=[pos_label]`` and ``average != &#39;binary&#39;`` will report</span></div>
<div class="line"><span class="lineno"> 1208</span><span class="stringliteral">        scores for that label only.</span></div>
<div class="line"><span class="lineno"> 1209</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1210</span><span class="stringliteral">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;, &#39;binary&#39;} or None, \</span></div>
<div class="line"><span class="lineno"> 1211</span><span class="stringliteral">            default=&#39;binary&#39;</span></div>
<div class="line"><span class="lineno"> 1212</span><span class="stringliteral">        This parameter is required for multiclass/multilabel targets.</span></div>
<div class="line"><span class="lineno"> 1213</span><span class="stringliteral">        If ``None``, the scores for each class are returned. Otherwise, this</span></div>
<div class="line"><span class="lineno"> 1214</span><span class="stringliteral">        determines the type of averaging performed on the data:</span></div>
<div class="line"><span class="lineno"> 1215</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1216</span><span class="stringliteral">        ``&#39;binary&#39;``:</span></div>
<div class="line"><span class="lineno"> 1217</span><span class="stringliteral">            Only report results for the class specified by ``pos_label``.</span></div>
<div class="line"><span class="lineno"> 1218</span><span class="stringliteral">            This is applicable only if targets (``y_{true,pred}``) are binary.</span></div>
<div class="line"><span class="lineno"> 1219</span><span class="stringliteral">        ``&#39;micro&#39;``:</span></div>
<div class="line"><span class="lineno"> 1220</span><span class="stringliteral">            Calculate metrics globally by counting the total true positives,</span></div>
<div class="line"><span class="lineno"> 1221</span><span class="stringliteral">            false negatives and false positives.</span></div>
<div class="line"><span class="lineno"> 1222</span><span class="stringliteral">        ``&#39;macro&#39;``:</span></div>
<div class="line"><span class="lineno"> 1223</span><span class="stringliteral">            Calculate metrics for each label, and find their unweighted</span></div>
<div class="line"><span class="lineno"> 1224</span><span class="stringliteral">            mean.  This does not take label imbalance into account.</span></div>
<div class="line"><span class="lineno"> 1225</span><span class="stringliteral">        ``&#39;weighted&#39;``:</span></div>
<div class="line"><span class="lineno"> 1226</span><span class="stringliteral">            Calculate metrics for each label, and find their average weighted</span></div>
<div class="line"><span class="lineno"> 1227</span><span class="stringliteral">            by support (the number of true instances for each label). This</span></div>
<div class="line"><span class="lineno"> 1228</span><span class="stringliteral">            alters &#39;macro&#39; to account for label imbalance; it can result in an</span></div>
<div class="line"><span class="lineno"> 1229</span><span class="stringliteral">            F-score that is not between precision and recall.</span></div>
<div class="line"><span class="lineno"> 1230</span><span class="stringliteral">        ``&#39;samples&#39;``:</span></div>
<div class="line"><span class="lineno"> 1231</span><span class="stringliteral">            Calculate metrics for each instance, and find their average (only</span></div>
<div class="line"><span class="lineno"> 1232</span><span class="stringliteral">            meaningful for multilabel classification where this differs from</span></div>
<div class="line"><span class="lineno"> 1233</span><span class="stringliteral">            :func:`accuracy_score`).</span></div>
<div class="line"><span class="lineno"> 1234</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1235</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1236</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1237</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1238</span><span class="stringliteral">    zero_division : &quot;warn&quot;, 0 or 1, default=&quot;warn&quot;</span></div>
<div class="line"><span class="lineno"> 1239</span><span class="stringliteral">        Sets the value to return when there is a zero division, i.e. when all</span></div>
<div class="line"><span class="lineno"> 1240</span><span class="stringliteral">        predictions and labels are negative. If set to &quot;warn&quot;, this acts as 0,</span></div>
<div class="line"><span class="lineno"> 1241</span><span class="stringliteral">        but warnings are also raised.</span></div>
<div class="line"><span class="lineno"> 1242</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1243</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1244</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1245</span><span class="stringliteral">    fbeta_score : float (if average is not None) or array of float, shape =\</span></div>
<div class="line"><span class="lineno"> 1246</span><span class="stringliteral">        [n_unique_labels]</span></div>
<div class="line"><span class="lineno"> 1247</span><span class="stringliteral">        F-beta score of the positive class in binary classification or weighted</span></div>
<div class="line"><span class="lineno"> 1248</span><span class="stringliteral">        average of the F-beta score of each class for the multiclass task.</span></div>
<div class="line"><span class="lineno"> 1249</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1250</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 1251</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1252</span><span class="stringliteral">    precision_recall_fscore_support : Compute the precision, recall, F-score,</span></div>
<div class="line"><span class="lineno"> 1253</span><span class="stringliteral">        and support.</span></div>
<div class="line"><span class="lineno"> 1254</span><span class="stringliteral">    multilabel_confusion_matrix : Compute a confusion matrix for each class or</span></div>
<div class="line"><span class="lineno"> 1255</span><span class="stringliteral">        sample.</span></div>
<div class="line"><span class="lineno"> 1256</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1257</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1258</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1259</span><span class="stringliteral">    When ``true positive + false positive == 0`` or</span></div>
<div class="line"><span class="lineno"> 1260</span><span class="stringliteral">    ``true positive + false negative == 0``, f-score returns 0 and raises</span></div>
<div class="line"><span class="lineno"> 1261</span><span class="stringliteral">    ``UndefinedMetricWarning``. This behavior can be</span></div>
<div class="line"><span class="lineno"> 1262</span><span class="stringliteral">    modified with ``zero_division``.</span></div>
<div class="line"><span class="lineno"> 1263</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1264</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1265</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1266</span><span class="stringliteral">    .. [1] R. Baeza-Yates and B. Ribeiro-Neto (2011).</span></div>
<div class="line"><span class="lineno"> 1267</span><span class="stringliteral">           Modern Information Retrieval. Addison Wesley, pp. 327-328.</span></div>
<div class="line"><span class="lineno"> 1268</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1269</span><span class="stringliteral">    .. [2] `Wikipedia entry for the F1-score</span></div>
<div class="line"><span class="lineno"> 1270</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.</span></div>
<div class="line"><span class="lineno"> 1271</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1272</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1273</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1274</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import fbeta_score</span></div>
<div class="line"><span class="lineno"> 1275</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]</span></div>
<div class="line"><span class="lineno"> 1276</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]</span></div>
<div class="line"><span class="lineno"> 1277</span><span class="stringliteral">    &gt;&gt;&gt; fbeta_score(y_true, y_pred, average=&#39;macro&#39;, beta=0.5)</span></div>
<div class="line"><span class="lineno"> 1278</span><span class="stringliteral">    0.23...</span></div>
<div class="line"><span class="lineno"> 1279</span><span class="stringliteral">    &gt;&gt;&gt; fbeta_score(y_true, y_pred, average=&#39;micro&#39;, beta=0.5)</span></div>
<div class="line"><span class="lineno"> 1280</span><span class="stringliteral">    0.33...</span></div>
<div class="line"><span class="lineno"> 1281</span><span class="stringliteral">    &gt;&gt;&gt; fbeta_score(y_true, y_pred, average=&#39;weighted&#39;, beta=0.5)</span></div>
<div class="line"><span class="lineno"> 1282</span><span class="stringliteral">    0.23...</span></div>
<div class="line"><span class="lineno"> 1283</span><span class="stringliteral">    &gt;&gt;&gt; fbeta_score(y_true, y_pred, average=None, beta=0.5)</span></div>
<div class="line"><span class="lineno"> 1284</span><span class="stringliteral">    array([0.71..., 0.        , 0.        ])</span></div>
<div class="line"><span class="lineno"> 1285</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1286</span> </div>
<div class="line"><span class="lineno"> 1287</span>    _, _, f, _ = precision_recall_fscore_support(</div>
<div class="line"><span class="lineno"> 1288</span>        y_true,</div>
<div class="line"><span class="lineno"> 1289</span>        y_pred,</div>
<div class="line"><span class="lineno"> 1290</span>        beta=beta,</div>
<div class="line"><span class="lineno"> 1291</span>        labels=labels,</div>
<div class="line"><span class="lineno"> 1292</span>        pos_label=pos_label,</div>
<div class="line"><span class="lineno"> 1293</span>        average=average,</div>
<div class="line"><span class="lineno"> 1294</span>        warn_for=(<span class="stringliteral">&quot;f-score&quot;</span>,),</div>
<div class="line"><span class="lineno"> 1295</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno"> 1296</span>        zero_division=zero_division,</div>
<div class="line"><span class="lineno"> 1297</span>    )</div>
<div class="line"><span class="lineno"> 1298</span>    <span class="keywordflow">return</span> f</div>
<div class="line"><span class="lineno"> 1299</span> </div>
<div class="line"><span class="lineno"> 1300</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a67ff64fc973d76f925985cdc2ab3b2f9" name="a67ff64fc973d76f925985cdc2ab3b2f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a67ff64fc973d76f925985cdc2ab3b2f9">&#9670;&#160;</a></span>hamming_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.hamming_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the average Hamming loss.

The Hamming loss is the fraction of labels that are incorrectly predicted.

Read more in the :ref:`User Guide &lt;hamming_loss&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) labels.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Predicted labels, as returned by a classifier.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

    .. versionadded:: 0.18

Returns
-------
loss : float or int
    Return the average Hamming loss between element of ``y_true`` and
    ``y_pred``.

See Also
--------
accuracy_score : Compute the accuracy score. By default, the function will
    return the fraction of correct predictions divided by the total number
    of predictions.
jaccard_score : Compute the Jaccard similarity coefficient score.
zero_one_loss : Compute the Zero-one classification loss. By default, the
    function will return the percentage of imperfectly predicted subsets.

Notes
-----
In multiclass classification, the Hamming loss corresponds to the Hamming
distance between ``y_true`` and ``y_pred`` which is equivalent to the
subset ``zero_one_loss`` function, when `normalize` parameter is set to
True.

In multilabel classification, the Hamming loss is different from the
subset zero-one loss. The zero-one loss considers the entire set of labels
for a given sample incorrect if it does not entirely match the true set of
labels. Hamming loss is more forgiving in that it penalizes only the
individual labels.

The Hamming loss is upperbounded by the subset zero-one loss, when
`normalize` parameter is set to True. It is always between 0 and 1,
lower being better.

References
----------
.. [1] Grigorios Tsoumakas, Ioannis Katakis. Multi-Label Classification:
       An Overview. International Journal of Data Warehousing &amp; Mining,
       3(3), 1-13, July-September 2007.

.. [2] `Wikipedia entry on the Hamming distance
       &lt;https://en.wikipedia.org/wiki/Hamming_distance&gt;`_.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import hamming_loss
&gt;&gt;&gt; y_pred = [1, 2, 3, 4]
&gt;&gt;&gt; y_true = [2, 2, 3, 4]
&gt;&gt;&gt; hamming_loss(y_true, y_pred)
0.25

In the multilabel case with binary label indicators:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; hamming_loss(np.array([[0, 1], [1, 1]]), np.zeros((2, 2)))
0.75
</pre> <div class="fragment"><div class="line"><span class="lineno"> 2415</span><span class="keyword">def </span>hamming_loss(y_true, y_pred, *, sample_weight=None):</div>
<div class="line"><span class="lineno"> 2416</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the average Hamming loss.</span></div>
<div class="line"><span class="lineno"> 2417</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2418</span><span class="stringliteral">    The Hamming loss is the fraction of labels that are incorrectly predicted.</span></div>
<div class="line"><span class="lineno"> 2419</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2420</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;hamming_loss&gt;`.</span></div>
<div class="line"><span class="lineno"> 2421</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2422</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 2423</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2424</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 2425</span><span class="stringliteral">        Ground truth (correct) labels.</span></div>
<div class="line"><span class="lineno"> 2426</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2427</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 2428</span><span class="stringliteral">        Predicted labels, as returned by a classifier.</span></div>
<div class="line"><span class="lineno"> 2429</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2430</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 2431</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 2432</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2433</span><span class="stringliteral">        .. versionadded:: 0.18</span></div>
<div class="line"><span class="lineno"> 2434</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2435</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 2436</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 2437</span><span class="stringliteral">    loss : float or int</span></div>
<div class="line"><span class="lineno"> 2438</span><span class="stringliteral">        Return the average Hamming loss between element of ``y_true`` and</span></div>
<div class="line"><span class="lineno"> 2439</span><span class="stringliteral">        ``y_pred``.</span></div>
<div class="line"><span class="lineno"> 2440</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2441</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 2442</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2443</span><span class="stringliteral">    accuracy_score : Compute the accuracy score. By default, the function will</span></div>
<div class="line"><span class="lineno"> 2444</span><span class="stringliteral">        return the fraction of correct predictions divided by the total number</span></div>
<div class="line"><span class="lineno"> 2445</span><span class="stringliteral">        of predictions.</span></div>
<div class="line"><span class="lineno"> 2446</span><span class="stringliteral">    jaccard_score : Compute the Jaccard similarity coefficient score.</span></div>
<div class="line"><span class="lineno"> 2447</span><span class="stringliteral">    zero_one_loss : Compute the Zero-one classification loss. By default, the</span></div>
<div class="line"><span class="lineno"> 2448</span><span class="stringliteral">        function will return the percentage of imperfectly predicted subsets.</span></div>
<div class="line"><span class="lineno"> 2449</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2450</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 2451</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 2452</span><span class="stringliteral">    In multiclass classification, the Hamming loss corresponds to the Hamming</span></div>
<div class="line"><span class="lineno"> 2453</span><span class="stringliteral">    distance between ``y_true`` and ``y_pred`` which is equivalent to the</span></div>
<div class="line"><span class="lineno"> 2454</span><span class="stringliteral">    subset ``zero_one_loss`` function, when `normalize` parameter is set to</span></div>
<div class="line"><span class="lineno"> 2455</span><span class="stringliteral">    True.</span></div>
<div class="line"><span class="lineno"> 2456</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2457</span><span class="stringliteral">    In multilabel classification, the Hamming loss is different from the</span></div>
<div class="line"><span class="lineno"> 2458</span><span class="stringliteral">    subset zero-one loss. The zero-one loss considers the entire set of labels</span></div>
<div class="line"><span class="lineno"> 2459</span><span class="stringliteral">    for a given sample incorrect if it does not entirely match the true set of</span></div>
<div class="line"><span class="lineno"> 2460</span><span class="stringliteral">    labels. Hamming loss is more forgiving in that it penalizes only the</span></div>
<div class="line"><span class="lineno"> 2461</span><span class="stringliteral">    individual labels.</span></div>
<div class="line"><span class="lineno"> 2462</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2463</span><span class="stringliteral">    The Hamming loss is upperbounded by the subset zero-one loss, when</span></div>
<div class="line"><span class="lineno"> 2464</span><span class="stringliteral">    `normalize` parameter is set to True. It is always between 0 and 1,</span></div>
<div class="line"><span class="lineno"> 2465</span><span class="stringliteral">    lower being better.</span></div>
<div class="line"><span class="lineno"> 2466</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2467</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 2468</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2469</span><span class="stringliteral">    .. [1] Grigorios Tsoumakas, Ioannis Katakis. Multi-Label Classification:</span></div>
<div class="line"><span class="lineno"> 2470</span><span class="stringliteral">           An Overview. International Journal of Data Warehousing &amp; Mining,</span></div>
<div class="line"><span class="lineno"> 2471</span><span class="stringliteral">           3(3), 1-13, July-September 2007.</span></div>
<div class="line"><span class="lineno"> 2472</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2473</span><span class="stringliteral">    .. [2] `Wikipedia entry on the Hamming distance</span></div>
<div class="line"><span class="lineno"> 2474</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/Hamming_distance&gt;`_.</span></div>
<div class="line"><span class="lineno"> 2475</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2476</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 2477</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2478</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import hamming_loss</span></div>
<div class="line"><span class="lineno"> 2479</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [1, 2, 3, 4]</span></div>
<div class="line"><span class="lineno"> 2480</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [2, 2, 3, 4]</span></div>
<div class="line"><span class="lineno"> 2481</span><span class="stringliteral">    &gt;&gt;&gt; hamming_loss(y_true, y_pred)</span></div>
<div class="line"><span class="lineno"> 2482</span><span class="stringliteral">    0.25</span></div>
<div class="line"><span class="lineno"> 2483</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2484</span><span class="stringliteral">    In the multilabel case with binary label indicators:</span></div>
<div class="line"><span class="lineno"> 2485</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2486</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno"> 2487</span><span class="stringliteral">    &gt;&gt;&gt; hamming_loss(np.array([[0, 1], [1, 1]]), np.zeros((2, 2)))</span></div>
<div class="line"><span class="lineno"> 2488</span><span class="stringliteral">    0.75</span></div>
<div class="line"><span class="lineno"> 2489</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 2490</span> </div>
<div class="line"><span class="lineno"> 2491</span>    y_type, y_true, y_pred = _check_targets(y_true, y_pred)</div>
<div class="line"><span class="lineno"> 2492</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno"> 2493</span> </div>
<div class="line"><span class="lineno"> 2494</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 2495</span>        weight_average = 1.0</div>
<div class="line"><span class="lineno"> 2496</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2497</span>        weight_average = np.mean(sample_weight)</div>
<div class="line"><span class="lineno"> 2498</span> </div>
<div class="line"><span class="lineno"> 2499</span>    <span class="keywordflow">if</span> y_type.startswith(<span class="stringliteral">&quot;multilabel&quot;</span>):</div>
<div class="line"><span class="lineno"> 2500</span>        n_differences = count_nonzero(y_true - y_pred, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 2501</span>        <span class="keywordflow">return</span> n_differences / (y_true.shape[0] * y_true.shape[1] * weight_average)</div>
<div class="line"><span class="lineno"> 2502</span> </div>
<div class="line"><span class="lineno"> 2503</span>    <span class="keywordflow">elif</span> y_type <span class="keywordflow">in</span> [<span class="stringliteral">&quot;binary&quot;</span>, <span class="stringliteral">&quot;multiclass&quot;</span>]:</div>
<div class="line"><span class="lineno"> 2504</span>        <span class="keywordflow">return</span> _weighted_sum(y_true != y_pred, sample_weight, normalize=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 2505</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2506</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;{0} is not supported&quot;</span>.format(y_type))</div>
<div class="line"><span class="lineno"> 2507</span> </div>
<div class="line"><span class="lineno"> 2508</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4c5755dc95b64fb760a15fa07a71e22e" name="a4c5755dc95b64fb760a15fa07a71e22e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c5755dc95b64fb760a15fa07a71e22e">&#9670;&#160;</a></span>hinge_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.hinge_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pred_decision</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Average hinge loss (non-regularized).

In binary class case, assuming labels in y_true are encoded with +1 and -1,
when a prediction mistake is made, ``margin = y_true * pred_decision`` is
always negative (since the signs disagree), implying ``1 - margin`` is
always greater than 1.  The cumulated hinge loss is therefore an upper
bound of the number of mistakes made by the classifier.

In multiclass case, the function expects that either all the labels are
included in y_true or an optional labels argument is provided which
contains all the labels. The multilabel margin is calculated according
to Crammer-Singer's method. As in the binary case, the cumulated hinge loss
is an upper bound of the number of mistakes made by the classifier.

Read more in the :ref:`User Guide &lt;hinge_loss&gt;`.

Parameters
----------
y_true : array of shape (n_samples,)
    True target, consisting of integers of two values. The positive label
    must be greater than the negative label.

pred_decision : array of shape (n_samples,) or (n_samples, n_classes)
    Predicted decisions, as output by decision_function (floats).

labels : array-like, default=None
    Contains all the labels for the problem. Used in multiclass hinge loss.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
loss : float
    Average hinge loss.

References
----------
.. [1] `Wikipedia entry on the Hinge loss
       &lt;https://en.wikipedia.org/wiki/Hinge_loss&gt;`_.

.. [2] Koby Crammer, Yoram Singer. On the Algorithmic
       Implementation of Multiclass Kernel-based Vector
       Machines. Journal of Machine Learning Research 2,
       (2001), 265-292.

.. [3] `L1 AND L2 Regularization for Multiclass Hinge Loss Models
       by Robert C. Moore, John DeNero
       &lt;https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37362.pdf&gt;`_.

Examples
--------
&gt;&gt;&gt; from sklearn import svm
&gt;&gt;&gt; from sklearn.metrics import hinge_loss
&gt;&gt;&gt; X = [[0], [1]]
&gt;&gt;&gt; y = [-1, 1]
&gt;&gt;&gt; est = svm.LinearSVC(random_state=0)
&gt;&gt;&gt; est.fit(X, y)
LinearSVC(random_state=0)
&gt;&gt;&gt; pred_decision = est.decision_function([[-2], [3], [0.5]])
&gt;&gt;&gt; pred_decision
array([-2.18...,  2.36...,  0.09...])
&gt;&gt;&gt; hinge_loss([-1, 1, 1], pred_decision)
0.30...

In the multiclass case:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; X = np.array([[0], [1], [2], [3]])
&gt;&gt;&gt; Y = np.array([0, 1, 2, 3])
&gt;&gt;&gt; labels = np.array([0, 1, 2, 3])
&gt;&gt;&gt; est = svm.LinearSVC()
&gt;&gt;&gt; est.fit(X, Y)
LinearSVC()
&gt;&gt;&gt; pred_decision = est.decision_function([[-1], [2], [3]])
&gt;&gt;&gt; y_true = [0, 2, 3]
&gt;&gt;&gt; hinge_loss(y_true, pred_decision, labels=labels)
0.56...
</pre> <div class="fragment"><div class="line"><span class="lineno"> 2659</span><span class="keyword">def </span>hinge_loss(y_true, pred_decision, *, labels=None, sample_weight=None):</div>
<div class="line"><span class="lineno"> 2660</span>    <span class="stringliteral">&quot;&quot;&quot;Average hinge loss (non-regularized).</span></div>
<div class="line"><span class="lineno"> 2661</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2662</span><span class="stringliteral">    In binary class case, assuming labels in y_true are encoded with +1 and -1,</span></div>
<div class="line"><span class="lineno"> 2663</span><span class="stringliteral">    when a prediction mistake is made, ``margin = y_true * pred_decision`` is</span></div>
<div class="line"><span class="lineno"> 2664</span><span class="stringliteral">    always negative (since the signs disagree), implying ``1 - margin`` is</span></div>
<div class="line"><span class="lineno"> 2665</span><span class="stringliteral">    always greater than 1.  The cumulated hinge loss is therefore an upper</span></div>
<div class="line"><span class="lineno"> 2666</span><span class="stringliteral">    bound of the number of mistakes made by the classifier.</span></div>
<div class="line"><span class="lineno"> 2667</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2668</span><span class="stringliteral">    In multiclass case, the function expects that either all the labels are</span></div>
<div class="line"><span class="lineno"> 2669</span><span class="stringliteral">    included in y_true or an optional labels argument is provided which</span></div>
<div class="line"><span class="lineno"> 2670</span><span class="stringliteral">    contains all the labels. The multilabel margin is calculated according</span></div>
<div class="line"><span class="lineno"> 2671</span><span class="stringliteral">    to Crammer-Singer&#39;s method. As in the binary case, the cumulated hinge loss</span></div>
<div class="line"><span class="lineno"> 2672</span><span class="stringliteral">    is an upper bound of the number of mistakes made by the classifier.</span></div>
<div class="line"><span class="lineno"> 2673</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2674</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;hinge_loss&gt;`.</span></div>
<div class="line"><span class="lineno"> 2675</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2676</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 2677</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2678</span><span class="stringliteral">    y_true : array of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 2679</span><span class="stringliteral">        True target, consisting of integers of two values. The positive label</span></div>
<div class="line"><span class="lineno"> 2680</span><span class="stringliteral">        must be greater than the negative label.</span></div>
<div class="line"><span class="lineno"> 2681</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2682</span><span class="stringliteral">    pred_decision : array of shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno"> 2683</span><span class="stringliteral">        Predicted decisions, as output by decision_function (floats).</span></div>
<div class="line"><span class="lineno"> 2684</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2685</span><span class="stringliteral">    labels : array-like, default=None</span></div>
<div class="line"><span class="lineno"> 2686</span><span class="stringliteral">        Contains all the labels for the problem. Used in multiclass hinge loss.</span></div>
<div class="line"><span class="lineno"> 2687</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2688</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 2689</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 2690</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2691</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 2692</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 2693</span><span class="stringliteral">    loss : float</span></div>
<div class="line"><span class="lineno"> 2694</span><span class="stringliteral">        Average hinge loss.</span></div>
<div class="line"><span class="lineno"> 2695</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2696</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 2697</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2698</span><span class="stringliteral">    .. [1] `Wikipedia entry on the Hinge loss</span></div>
<div class="line"><span class="lineno"> 2699</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/Hinge_loss&gt;`_.</span></div>
<div class="line"><span class="lineno"> 2700</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2701</span><span class="stringliteral">    .. [2] Koby Crammer, Yoram Singer. On the Algorithmic</span></div>
<div class="line"><span class="lineno"> 2702</span><span class="stringliteral">           Implementation of Multiclass Kernel-based Vector</span></div>
<div class="line"><span class="lineno"> 2703</span><span class="stringliteral">           Machines. Journal of Machine Learning Research 2,</span></div>
<div class="line"><span class="lineno"> 2704</span><span class="stringliteral">           (2001), 265-292.</span></div>
<div class="line"><span class="lineno"> 2705</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2706</span><span class="stringliteral">    .. [3] `L1 AND L2 Regularization for Multiclass Hinge Loss Models</span></div>
<div class="line"><span class="lineno"> 2707</span><span class="stringliteral">           by Robert C. Moore, John DeNero</span></div>
<div class="line"><span class="lineno"> 2708</span><span class="stringliteral">           &lt;https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37362.pdf&gt;`_.</span></div>
<div class="line"><span class="lineno"> 2709</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2710</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 2711</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2712</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn import svm</span></div>
<div class="line"><span class="lineno"> 2713</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import hinge_loss</span></div>
<div class="line"><span class="lineno"> 2714</span><span class="stringliteral">    &gt;&gt;&gt; X = [[0], [1]]</span></div>
<div class="line"><span class="lineno"> 2715</span><span class="stringliteral">    &gt;&gt;&gt; y = [-1, 1]</span></div>
<div class="line"><span class="lineno"> 2716</span><span class="stringliteral">    &gt;&gt;&gt; est = svm.LinearSVC(random_state=0)</span></div>
<div class="line"><span class="lineno"> 2717</span><span class="stringliteral">    &gt;&gt;&gt; est.fit(X, y)</span></div>
<div class="line"><span class="lineno"> 2718</span><span class="stringliteral">    LinearSVC(random_state=0)</span></div>
<div class="line"><span class="lineno"> 2719</span><span class="stringliteral">    &gt;&gt;&gt; pred_decision = est.decision_function([[-2], [3], [0.5]])</span></div>
<div class="line"><span class="lineno"> 2720</span><span class="stringliteral">    &gt;&gt;&gt; pred_decision</span></div>
<div class="line"><span class="lineno"> 2721</span><span class="stringliteral">    array([-2.18...,  2.36...,  0.09...])</span></div>
<div class="line"><span class="lineno"> 2722</span><span class="stringliteral">    &gt;&gt;&gt; hinge_loss([-1, 1, 1], pred_decision)</span></div>
<div class="line"><span class="lineno"> 2723</span><span class="stringliteral">    0.30...</span></div>
<div class="line"><span class="lineno"> 2724</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2725</span><span class="stringliteral">    In the multiclass case:</span></div>
<div class="line"><span class="lineno"> 2726</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2727</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno"> 2728</span><span class="stringliteral">    &gt;&gt;&gt; X = np.array([[0], [1], [2], [3]])</span></div>
<div class="line"><span class="lineno"> 2729</span><span class="stringliteral">    &gt;&gt;&gt; Y = np.array([0, 1, 2, 3])</span></div>
<div class="line"><span class="lineno"> 2730</span><span class="stringliteral">    &gt;&gt;&gt; labels = np.array([0, 1, 2, 3])</span></div>
<div class="line"><span class="lineno"> 2731</span><span class="stringliteral">    &gt;&gt;&gt; est = svm.LinearSVC()</span></div>
<div class="line"><span class="lineno"> 2732</span><span class="stringliteral">    &gt;&gt;&gt; est.fit(X, Y)</span></div>
<div class="line"><span class="lineno"> 2733</span><span class="stringliteral">    LinearSVC()</span></div>
<div class="line"><span class="lineno"> 2734</span><span class="stringliteral">    &gt;&gt;&gt; pred_decision = est.decision_function([[-1], [2], [3]])</span></div>
<div class="line"><span class="lineno"> 2735</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 2, 3]</span></div>
<div class="line"><span class="lineno"> 2736</span><span class="stringliteral">    &gt;&gt;&gt; hinge_loss(y_true, pred_decision, labels=labels)</span></div>
<div class="line"><span class="lineno"> 2737</span><span class="stringliteral">    0.56...</span></div>
<div class="line"><span class="lineno"> 2738</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 2739</span>    check_consistent_length(y_true, pred_decision, sample_weight)</div>
<div class="line"><span class="lineno"> 2740</span>    pred_decision = check_array(pred_decision, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 2741</span>    y_true = column_or_1d(y_true)</div>
<div class="line"><span class="lineno"> 2742</span>    y_true_unique = np.unique(labels <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> y_true)</div>
<div class="line"><span class="lineno"> 2743</span> </div>
<div class="line"><span class="lineno"> 2744</span>    <span class="keywordflow">if</span> y_true_unique.size &gt; 2:</div>
<div class="line"><span class="lineno"> 2745</span> </div>
<div class="line"><span class="lineno"> 2746</span>        <span class="keywordflow">if</span> pred_decision.ndim &lt;= 1:</div>
<div class="line"><span class="lineno"> 2747</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 2748</span>                <span class="stringliteral">&quot;The shape of pred_decision cannot be 1d array&quot;</span></div>
<div class="line"><span class="lineno"> 2749</span>                <span class="stringliteral">&quot;with a multiclass target. pred_decision shape &quot;</span></div>
<div class="line"><span class="lineno"> 2750</span>                <span class="stringliteral">&quot;must be (n_samples, n_classes), that is &quot;</span></div>
<div class="line"><span class="lineno"> 2751</span>                f<span class="stringliteral">&quot;({y_true.shape[0]}, {y_true_unique.size}).&quot;</span></div>
<div class="line"><span class="lineno"> 2752</span>                f<span class="stringliteral">&quot; Got: {pred_decision.shape}&quot;</span></div>
<div class="line"><span class="lineno"> 2753</span>            )</div>
<div class="line"><span class="lineno"> 2754</span> </div>
<div class="line"><span class="lineno"> 2755</span>        <span class="comment"># pred_decision.ndim &gt; 1 is true</span></div>
<div class="line"><span class="lineno"> 2756</span>        <span class="keywordflow">if</span> y_true_unique.size != pred_decision.shape[1]:</div>
<div class="line"><span class="lineno"> 2757</span>            <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 2758</span>                <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 2759</span>                    <span class="stringliteral">&quot;Please include all labels in y_true &quot;</span></div>
<div class="line"><span class="lineno"> 2760</span>                    <span class="stringliteral">&quot;or pass labels as third argument&quot;</span></div>
<div class="line"><span class="lineno"> 2761</span>                )</div>
<div class="line"><span class="lineno"> 2762</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2763</span>                <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 2764</span>                    <span class="stringliteral">&quot;The shape of pred_decision is not &quot;</span></div>
<div class="line"><span class="lineno"> 2765</span>                    <span class="stringliteral">&quot;consistent with the number of classes. &quot;</span></div>
<div class="line"><span class="lineno"> 2766</span>                    <span class="stringliteral">&quot;With a multiclass target, pred_decision &quot;</span></div>
<div class="line"><span class="lineno"> 2767</span>                    <span class="stringliteral">&quot;shape must be &quot;</span></div>
<div class="line"><span class="lineno"> 2768</span>                    <span class="stringliteral">&quot;(n_samples, n_classes), that is &quot;</span></div>
<div class="line"><span class="lineno"> 2769</span>                    f<span class="stringliteral">&quot;({y_true.shape[0]}, {y_true_unique.size}). &quot;</span></div>
<div class="line"><span class="lineno"> 2770</span>                    f<span class="stringliteral">&quot;Got: {pred_decision.shape}&quot;</span></div>
<div class="line"><span class="lineno"> 2771</span>                )</div>
<div class="line"><span class="lineno"> 2772</span>        <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 2773</span>            labels = y_true_unique</div>
<div class="line"><span class="lineno"> 2774</span>        le = LabelEncoder()</div>
<div class="line"><span class="lineno"> 2775</span>        le.fit(labels)</div>
<div class="line"><span class="lineno"> 2776</span>        y_true = le.transform(y_true)</div>
<div class="line"><span class="lineno"> 2777</span>        mask = np.ones_like(pred_decision, dtype=bool)</div>
<div class="line"><span class="lineno"> 2778</span>        mask[np.arange(y_true.shape[0]), y_true] = <span class="keyword">False</span></div>
<div class="line"><span class="lineno"> 2779</span>        margin = pred_decision[~mask]</div>
<div class="line"><span class="lineno"> 2780</span>        margin -= np.max(pred_decision[mask].reshape(y_true.shape[0], -1), axis=1)</div>
<div class="line"><span class="lineno"> 2781</span> </div>
<div class="line"><span class="lineno"> 2782</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2783</span>        <span class="comment"># Handles binary class case</span></div>
<div class="line"><span class="lineno"> 2784</span>        <span class="comment"># this code assumes that positive and negative labels</span></div>
<div class="line"><span class="lineno"> 2785</span>        <span class="comment"># are encoded as +1 and -1 respectively</span></div>
<div class="line"><span class="lineno"> 2786</span>        pred_decision = column_or_1d(pred_decision)</div>
<div class="line"><span class="lineno"> 2787</span>        pred_decision = np.ravel(pred_decision)</div>
<div class="line"><span class="lineno"> 2788</span> </div>
<div class="line"><span class="lineno"> 2789</span>        lbin = LabelBinarizer(neg_label=-1)</div>
<div class="line"><span class="lineno"> 2790</span>        y_true = lbin.fit_transform(y_true)[:, 0]</div>
<div class="line"><span class="lineno"> 2791</span> </div>
<div class="line"><span class="lineno"> 2792</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno"> 2793</span>            margin = y_true * pred_decision</div>
<div class="line"><span class="lineno"> 2794</span>        <span class="keywordflow">except</span> TypeError:</div>
<div class="line"><span class="lineno"> 2795</span>            <span class="keywordflow">raise</span> TypeError(<span class="stringliteral">&quot;pred_decision should be an array of floats.&quot;</span>)</div>
<div class="line"><span class="lineno"> 2796</span> </div>
<div class="line"><span class="lineno"> 2797</span>    losses = 1 - margin</div>
<div class="line"><span class="lineno"> 2798</span>    <span class="comment"># The hinge_loss doesn&#39;t penalize good enough predictions.</span></div>
<div class="line"><span class="lineno"> 2799</span>    np.clip(losses, 0, <span class="keywordtype">None</span>, out=losses)</div>
<div class="line"><span class="lineno"> 2800</span>    <span class="keywordflow">return</span> np.average(losses, weights=sample_weight)</div>
<div class="line"><span class="lineno"> 2801</span> </div>
<div class="line"><span class="lineno"> 2802</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab2d31021335d26ff38be78b103785ebf" name="ab2d31021335d26ff38be78b103785ebf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab2d31021335d26ff38be78b103785ebf">&#9670;&#160;</a></span>jaccard_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.jaccard_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average</em> = <code>&quot;binary&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zero_division</em> = <code>&quot;warn&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Jaccard similarity coefficient score.

The Jaccard index [1], or Jaccard similarity coefficient, defined as
the size of the intersection divided by the size of the union of two label
sets, is used to compare set of predicted labels for a sample to the
corresponding set of labels in ``y_true``.

Read more in the :ref:`User Guide &lt;jaccard_similarity_score&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) labels.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Predicted labels, as returned by a classifier.

labels : array-like of shape (n_classes,), default=None
    The set of labels to include when ``average != 'binary'``, and their
    order if ``average is None``. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in ``y_true`` and
    ``y_pred`` are used in sorted order.

pos_label : str or int, default=1
    The class to report if ``average='binary'`` and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting ``labels=[pos_label]`` and ``average != 'binary'`` will report
    scores for that label only.

average : {'micro', 'macro', 'samples', 'weighted', \
        'binary'} or None, default='binary'
    If ``None``, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:

    ``'binary'``:
        Only report results for the class specified by ``pos_label``.
        This is applicable only if targets (``y_{true,pred}``) are binary.
    ``'micro'``:
        Calculate metrics globally by counting the total true positives,
        false negatives and false positives.
    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    ``'weighted'``:
        Calculate metrics for each label, and find their average, weighted
        by support (the number of true instances for each label). This
        alters 'macro' to account for label imbalance.
    ``'samples'``:
        Calculate metrics for each instance, and find their average (only
        meaningful for multilabel classification).

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

zero_division : "warn", {0.0, 1.0}, default="warn"
    Sets the value to return when there is a zero division, i.e. when there
    there are no negative values in predictions and labels. If set to
    "warn", this acts like 0, but a warning is also raised.

Returns
-------
score : float or ndarray of shape (n_unique_labels,), dtype=np.float64
    The Jaccard score. When `average` is not `None`, a single scalar is
    returned.

See Also
--------
accuracy_score : Function for calculating the accuracy score.
f1_score : Function for calculating the F1 score.
multilabel_confusion_matrix : Function for computing a confusion matrix\
                              for each class or sample.

Notes
-----
:func:`jaccard_score` may be a poor metric if there are no
positives for some samples or classes. Jaccard is undefined if there are
no true or predicted labels, and our implementation will return a score
of 0 with a warning.

References
----------
.. [1] `Wikipedia entry for the Jaccard index
       &lt;https://en.wikipedia.org/wiki/Jaccard_index&gt;`_.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import jaccard_score
&gt;&gt;&gt; y_true = np.array([[0, 1, 1],
...                    [1, 1, 0]])
&gt;&gt;&gt; y_pred = np.array([[1, 1, 1],
...                    [1, 0, 0]])

In the binary case:

&gt;&gt;&gt; jaccard_score(y_true[0], y_pred[0])
0.6666...

In the 2D comparison case (e.g. image similarity):

&gt;&gt;&gt; jaccard_score(y_true, y_pred, average="micro")
0.6

In the multilabel case:

&gt;&gt;&gt; jaccard_score(y_true, y_pred, average='samples')
0.5833...
&gt;&gt;&gt; jaccard_score(y_true, y_pred, average='macro')
0.6666...
&gt;&gt;&gt; jaccard_score(y_true, y_pred, average=None)
array([0.5, 0.5, 1. ])

In the multiclass case:

&gt;&gt;&gt; y_pred = [0, 2, 1, 2]
&gt;&gt;&gt; y_true = [0, 1, 2, 2]
&gt;&gt;&gt; jaccard_score(y_true, y_pred, average=None)
array([1. , 0. , 0.33...])
</pre> <div class="fragment"><div class="line"><span class="lineno">  686</span>):</div>
<div class="line"><span class="lineno">  687</span>    <span class="stringliteral">&quot;&quot;&quot;Jaccard similarity coefficient score.</span></div>
<div class="line"><span class="lineno">  688</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  689</span><span class="stringliteral">    The Jaccard index [1], or Jaccard similarity coefficient, defined as</span></div>
<div class="line"><span class="lineno">  690</span><span class="stringliteral">    the size of the intersection divided by the size of the union of two label</span></div>
<div class="line"><span class="lineno">  691</span><span class="stringliteral">    sets, is used to compare set of predicted labels for a sample to the</span></div>
<div class="line"><span class="lineno">  692</span><span class="stringliteral">    corresponding set of labels in ``y_true``.</span></div>
<div class="line"><span class="lineno">  693</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  694</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;jaccard_similarity_score&gt;`.</span></div>
<div class="line"><span class="lineno">  695</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  696</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  697</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  698</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno">  699</span><span class="stringliteral">        Ground truth (correct) labels.</span></div>
<div class="line"><span class="lineno">  700</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  701</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno">  702</span><span class="stringliteral">        Predicted labels, as returned by a classifier.</span></div>
<div class="line"><span class="lineno">  703</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  704</span><span class="stringliteral">    labels : array-like of shape (n_classes,), default=None</span></div>
<div class="line"><span class="lineno">  705</span><span class="stringliteral">        The set of labels to include when ``average != &#39;binary&#39;``, and their</span></div>
<div class="line"><span class="lineno">  706</span><span class="stringliteral">        order if ``average is None``. Labels present in the data can be</span></div>
<div class="line"><span class="lineno">  707</span><span class="stringliteral">        excluded, for example to calculate a multiclass average ignoring a</span></div>
<div class="line"><span class="lineno">  708</span><span class="stringliteral">        majority negative class, while labels not present in the data will</span></div>
<div class="line"><span class="lineno">  709</span><span class="stringliteral">        result in 0 components in a macro average. For multilabel targets,</span></div>
<div class="line"><span class="lineno">  710</span><span class="stringliteral">        labels are column indices. By default, all labels in ``y_true`` and</span></div>
<div class="line"><span class="lineno">  711</span><span class="stringliteral">        ``y_pred`` are used in sorted order.</span></div>
<div class="line"><span class="lineno">  712</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  713</span><span class="stringliteral">    pos_label : str or int, default=1</span></div>
<div class="line"><span class="lineno">  714</span><span class="stringliteral">        The class to report if ``average=&#39;binary&#39;`` and the data is binary.</span></div>
<div class="line"><span class="lineno">  715</span><span class="stringliteral">        If the data are multiclass or multilabel, this will be ignored;</span></div>
<div class="line"><span class="lineno">  716</span><span class="stringliteral">        setting ``labels=[pos_label]`` and ``average != &#39;binary&#39;`` will report</span></div>
<div class="line"><span class="lineno">  717</span><span class="stringliteral">        scores for that label only.</span></div>
<div class="line"><span class="lineno">  718</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  719</span><span class="stringliteral">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;, \</span></div>
<div class="line"><span class="lineno">  720</span><span class="stringliteral">            &#39;binary&#39;} or None, default=&#39;binary&#39;</span></div>
<div class="line"><span class="lineno">  721</span><span class="stringliteral">        If ``None``, the scores for each class are returned. Otherwise, this</span></div>
<div class="line"><span class="lineno">  722</span><span class="stringliteral">        determines the type of averaging performed on the data:</span></div>
<div class="line"><span class="lineno">  723</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  724</span><span class="stringliteral">        ``&#39;binary&#39;``:</span></div>
<div class="line"><span class="lineno">  725</span><span class="stringliteral">            Only report results for the class specified by ``pos_label``.</span></div>
<div class="line"><span class="lineno">  726</span><span class="stringliteral">            This is applicable only if targets (``y_{true,pred}``) are binary.</span></div>
<div class="line"><span class="lineno">  727</span><span class="stringliteral">        ``&#39;micro&#39;``:</span></div>
<div class="line"><span class="lineno">  728</span><span class="stringliteral">            Calculate metrics globally by counting the total true positives,</span></div>
<div class="line"><span class="lineno">  729</span><span class="stringliteral">            false negatives and false positives.</span></div>
<div class="line"><span class="lineno">  730</span><span class="stringliteral">        ``&#39;macro&#39;``:</span></div>
<div class="line"><span class="lineno">  731</span><span class="stringliteral">            Calculate metrics for each label, and find their unweighted</span></div>
<div class="line"><span class="lineno">  732</span><span class="stringliteral">            mean.  This does not take label imbalance into account.</span></div>
<div class="line"><span class="lineno">  733</span><span class="stringliteral">        ``&#39;weighted&#39;``:</span></div>
<div class="line"><span class="lineno">  734</span><span class="stringliteral">            Calculate metrics for each label, and find their average, weighted</span></div>
<div class="line"><span class="lineno">  735</span><span class="stringliteral">            by support (the number of true instances for each label). This</span></div>
<div class="line"><span class="lineno">  736</span><span class="stringliteral">            alters &#39;macro&#39; to account for label imbalance.</span></div>
<div class="line"><span class="lineno">  737</span><span class="stringliteral">        ``&#39;samples&#39;``:</span></div>
<div class="line"><span class="lineno">  738</span><span class="stringliteral">            Calculate metrics for each instance, and find their average (only</span></div>
<div class="line"><span class="lineno">  739</span><span class="stringliteral">            meaningful for multilabel classification).</span></div>
<div class="line"><span class="lineno">  740</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  741</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  742</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  743</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  744</span><span class="stringliteral">    zero_division : &quot;warn&quot;, {0.0, 1.0}, default=&quot;warn&quot;</span></div>
<div class="line"><span class="lineno">  745</span><span class="stringliteral">        Sets the value to return when there is a zero division, i.e. when there</span></div>
<div class="line"><span class="lineno">  746</span><span class="stringliteral">        there are no negative values in predictions and labels. If set to</span></div>
<div class="line"><span class="lineno">  747</span><span class="stringliteral">        &quot;warn&quot;, this acts like 0, but a warning is also raised.</span></div>
<div class="line"><span class="lineno">  748</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  749</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  750</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  751</span><span class="stringliteral">    score : float or ndarray of shape (n_unique_labels,), dtype=np.float64</span></div>
<div class="line"><span class="lineno">  752</span><span class="stringliteral">        The Jaccard score. When `average` is not `None`, a single scalar is</span></div>
<div class="line"><span class="lineno">  753</span><span class="stringliteral">        returned.</span></div>
<div class="line"><span class="lineno">  754</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  755</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  756</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  757</span><span class="stringliteral">    accuracy_score : Function for calculating the accuracy score.</span></div>
<div class="line"><span class="lineno">  758</span><span class="stringliteral">    f1_score : Function for calculating the F1 score.</span></div>
<div class="line"><span class="lineno">  759</span><span class="stringliteral">    multilabel_confusion_matrix : Function for computing a confusion matrix\</span></div>
<div class="line"><span class="lineno">  760</span><span class="stringliteral">                                  for each class or sample.</span></div>
<div class="line"><span class="lineno">  761</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  762</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  763</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  764</span><span class="stringliteral">    :func:`jaccard_score` may be a poor metric if there are no</span></div>
<div class="line"><span class="lineno">  765</span><span class="stringliteral">    positives for some samples or classes. Jaccard is undefined if there are</span></div>
<div class="line"><span class="lineno">  766</span><span class="stringliteral">    no true or predicted labels, and our implementation will return a score</span></div>
<div class="line"><span class="lineno">  767</span><span class="stringliteral">    of 0 with a warning.</span></div>
<div class="line"><span class="lineno">  768</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  769</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  770</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  771</span><span class="stringliteral">    .. [1] `Wikipedia entry for the Jaccard index</span></div>
<div class="line"><span class="lineno">  772</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/Jaccard_index&gt;`_.</span></div>
<div class="line"><span class="lineno">  773</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  774</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  775</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  776</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  777</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import jaccard_score</span></div>
<div class="line"><span class="lineno">  778</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([[0, 1, 1],</span></div>
<div class="line"><span class="lineno">  779</span><span class="stringliteral">    ...                    [1, 1, 0]])</span></div>
<div class="line"><span class="lineno">  780</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = np.array([[1, 1, 1],</span></div>
<div class="line"><span class="lineno">  781</span><span class="stringliteral">    ...                    [1, 0, 0]])</span></div>
<div class="line"><span class="lineno">  782</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  783</span><span class="stringliteral">    In the binary case:</span></div>
<div class="line"><span class="lineno">  784</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  785</span><span class="stringliteral">    &gt;&gt;&gt; jaccard_score(y_true[0], y_pred[0])</span></div>
<div class="line"><span class="lineno">  786</span><span class="stringliteral">    0.6666...</span></div>
<div class="line"><span class="lineno">  787</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  788</span><span class="stringliteral">    In the 2D comparison case (e.g. image similarity):</span></div>
<div class="line"><span class="lineno">  789</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  790</span><span class="stringliteral">    &gt;&gt;&gt; jaccard_score(y_true, y_pred, average=&quot;micro&quot;)</span></div>
<div class="line"><span class="lineno">  791</span><span class="stringliteral">    0.6</span></div>
<div class="line"><span class="lineno">  792</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  793</span><span class="stringliteral">    In the multilabel case:</span></div>
<div class="line"><span class="lineno">  794</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  795</span><span class="stringliteral">    &gt;&gt;&gt; jaccard_score(y_true, y_pred, average=&#39;samples&#39;)</span></div>
<div class="line"><span class="lineno">  796</span><span class="stringliteral">    0.5833...</span></div>
<div class="line"><span class="lineno">  797</span><span class="stringliteral">    &gt;&gt;&gt; jaccard_score(y_true, y_pred, average=&#39;macro&#39;)</span></div>
<div class="line"><span class="lineno">  798</span><span class="stringliteral">    0.6666...</span></div>
<div class="line"><span class="lineno">  799</span><span class="stringliteral">    &gt;&gt;&gt; jaccard_score(y_true, y_pred, average=None)</span></div>
<div class="line"><span class="lineno">  800</span><span class="stringliteral">    array([0.5, 0.5, 1. ])</span></div>
<div class="line"><span class="lineno">  801</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  802</span><span class="stringliteral">    In the multiclass case:</span></div>
<div class="line"><span class="lineno">  803</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  804</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 2, 1, 2]</span></div>
<div class="line"><span class="lineno">  805</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 1, 2, 2]</span></div>
<div class="line"><span class="lineno">  806</span><span class="stringliteral">    &gt;&gt;&gt; jaccard_score(y_true, y_pred, average=None)</span></div>
<div class="line"><span class="lineno">  807</span><span class="stringliteral">    array([1. , 0. , 0.33...])</span></div>
<div class="line"><span class="lineno">  808</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  809</span>    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)</div>
<div class="line"><span class="lineno">  810</span>    samplewise = average == <span class="stringliteral">&quot;samples&quot;</span></div>
<div class="line"><span class="lineno">  811</span>    MCM = multilabel_confusion_matrix(</div>
<div class="line"><span class="lineno">  812</span>        y_true,</div>
<div class="line"><span class="lineno">  813</span>        y_pred,</div>
<div class="line"><span class="lineno">  814</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  815</span>        labels=labels,</div>
<div class="line"><span class="lineno">  816</span>        samplewise=samplewise,</div>
<div class="line"><span class="lineno">  817</span>    )</div>
<div class="line"><span class="lineno">  818</span>    numerator = MCM[:, 1, 1]</div>
<div class="line"><span class="lineno">  819</span>    denominator = MCM[:, 1, 1] + MCM[:, 0, 1] + MCM[:, 1, 0]</div>
<div class="line"><span class="lineno">  820</span> </div>
<div class="line"><span class="lineno">  821</span>    <span class="keywordflow">if</span> average == <span class="stringliteral">&quot;micro&quot;</span>:</div>
<div class="line"><span class="lineno">  822</span>        numerator = np.array([numerator.sum()])</div>
<div class="line"><span class="lineno">  823</span>        denominator = np.array([denominator.sum()])</div>
<div class="line"><span class="lineno">  824</span> </div>
<div class="line"><span class="lineno">  825</span>    jaccard = _prf_divide(</div>
<div class="line"><span class="lineno">  826</span>        numerator,</div>
<div class="line"><span class="lineno">  827</span>        denominator,</div>
<div class="line"><span class="lineno">  828</span>        <span class="stringliteral">&quot;jaccard&quot;</span>,</div>
<div class="line"><span class="lineno">  829</span>        <span class="stringliteral">&quot;true or predicted&quot;</span>,</div>
<div class="line"><span class="lineno">  830</span>        average,</div>
<div class="line"><span class="lineno">  831</span>        (<span class="stringliteral">&quot;jaccard&quot;</span>,),</div>
<div class="line"><span class="lineno">  832</span>        zero_division=zero_division,</div>
<div class="line"><span class="lineno">  833</span>    )</div>
<div class="line"><span class="lineno">  834</span>    <span class="keywordflow">if</span> average <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  835</span>        <span class="keywordflow">return</span> jaccard</div>
<div class="line"><span class="lineno">  836</span>    <span class="keywordflow">if</span> average == <span class="stringliteral">&quot;weighted&quot;</span>:</div>
<div class="line"><span class="lineno">  837</span>        weights = MCM[:, 1, 0] + MCM[:, 1, 1]</div>
<div class="line"><span class="lineno">  838</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.any(weights):</div>
<div class="line"><span class="lineno">  839</span>            <span class="comment"># numerator is 0, and warning should have already been issued</span></div>
<div class="line"><span class="lineno">  840</span>            weights = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  841</span>    <span class="keywordflow">elif</span> average == <span class="stringliteral">&quot;samples&quot;</span> <span class="keywordflow">and</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  842</span>        weights = sample_weight</div>
<div class="line"><span class="lineno">  843</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  844</span>        weights = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  845</span>    <span class="keywordflow">return</span> np.average(jaccard, weights=weights)</div>
<div class="line"><span class="lineno">  846</span> </div>
<div class="line"><span class="lineno">  847</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a060a52ebda7e5eef61bf94a6c444acb7" name="a060a52ebda7e5eef61bf94a6c444acb7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a060a52ebda7e5eef61bf94a6c444acb7">&#9670;&#160;</a></span>log_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.log_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>eps</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Log loss, aka logistic loss or cross-entropy loss.

This is the loss function used in (multinomial) logistic regression
and extensions of it such as neural networks, defined as the negative
log-likelihood of a logistic model that returns ``y_pred`` probabilities
for its training data ``y_true``.
The log loss is only defined for two or more labels.
For a single sample with true label :math:`y \in \{0,1\}` and
a probability estimate :math:`p = \operatorname{Pr}(y = 1)`, the log
loss is:

.. math::
    L_{\log}(y, p) = -(y \log (p) + (1 - y) \log (1 - p))

Read more in the :ref:`User Guide &lt;log_loss&gt;`.

Parameters
----------
y_true : array-like or label indicator matrix
    Ground truth (correct) labels for n_samples samples.

y_pred : array-like of float, shape = (n_samples, n_classes) or (n_samples,)
    Predicted probabilities, as returned by a classifier's
    predict_proba method. If ``y_pred.shape = (n_samples,)``
    the probabilities provided are assumed to be that of the
    positive class. The labels in ``y_pred`` are assumed to be
    ordered alphabetically, as done by
    :class:`preprocessing.LabelBinarizer`.

eps : float or "auto", default="auto"
    Log loss is undefined for p=0 or p=1, so probabilities are
    clipped to `max(eps, min(1 - eps, p))`. The default will depend on the
    data type of `y_pred` and is set to `np.finfo(y_pred.dtype).eps`.

    .. versionadded:: 1.2

    .. versionchanged:: 1.2
       The default value changed from `1e-15` to `"auto"` that is
       equivalent to `np.finfo(y_pred.dtype).eps`.

normalize : bool, default=True
    If true, return the mean loss per sample.
    Otherwise, return the sum of the per-sample losses.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

labels : array-like, default=None
    If not provided, labels will be inferred from y_true. If ``labels``
    is ``None`` and ``y_pred`` has shape (n_samples,) the labels are
    assumed to be binary and are inferred from ``y_true``.

    .. versionadded:: 0.18

Returns
-------
loss : float
    Log loss, aka logistic loss or cross-entropy loss.

Notes
-----
The logarithm used is the natural logarithm (base-e).

References
----------
C.M. Bishop (2006). Pattern Recognition and Machine Learning. Springer,
p. 209.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import log_loss
&gt;&gt;&gt; log_loss(["spam", "ham", "ham", "spam"],
...          [[.1, .9], [.9, .1], [.8, .2], [.35, .65]])
0.21616...
</pre> <div class="fragment"><div class="line"><span class="lineno"> 2511</span>):</div>
<div class="line"><span class="lineno"> 2512</span>    <span class="stringliteral">r&quot;&quot;&quot;Log loss, aka logistic loss or cross-entropy loss.</span></div>
<div class="line"><span class="lineno"> 2513</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2514</span><span class="stringliteral">    This is the loss function used in (multinomial) logistic regression</span></div>
<div class="line"><span class="lineno"> 2515</span><span class="stringliteral">    and extensions of it such as neural networks, defined as the negative</span></div>
<div class="line"><span class="lineno"> 2516</span><span class="stringliteral">    log-likelihood of a logistic model that returns ``y_pred`` probabilities</span></div>
<div class="line"><span class="lineno"> 2517</span><span class="stringliteral">    for its training data ``y_true``.</span></div>
<div class="line"><span class="lineno"> 2518</span><span class="stringliteral">    The log loss is only defined for two or more labels.</span></div>
<div class="line"><span class="lineno"> 2519</span><span class="stringliteral">    For a single sample with true label :math:`y \in \{0,1\}` and</span></div>
<div class="line"><span class="lineno"> 2520</span><span class="stringliteral">    a probability estimate :math:`p = \operatorname{Pr}(y = 1)`, the log</span></div>
<div class="line"><span class="lineno"> 2521</span><span class="stringliteral">    loss is:</span></div>
<div class="line"><span class="lineno"> 2522</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2523</span><span class="stringliteral">    .. math::</span></div>
<div class="line"><span class="lineno"> 2524</span><span class="stringliteral">        L_{\log}(y, p) = -(y \log (p) + (1 - y) \log (1 - p))</span></div>
<div class="line"><span class="lineno"> 2525</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2526</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;log_loss&gt;`.</span></div>
<div class="line"><span class="lineno"> 2527</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2528</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 2529</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2530</span><span class="stringliteral">    y_true : array-like or label indicator matrix</span></div>
<div class="line"><span class="lineno"> 2531</span><span class="stringliteral">        Ground truth (correct) labels for n_samples samples.</span></div>
<div class="line"><span class="lineno"> 2532</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2533</span><span class="stringliteral">    y_pred : array-like of float, shape = (n_samples, n_classes) or (n_samples,)</span></div>
<div class="line"><span class="lineno"> 2534</span><span class="stringliteral">        Predicted probabilities, as returned by a classifier&#39;s</span></div>
<div class="line"><span class="lineno"> 2535</span><span class="stringliteral">        predict_proba method. If ``y_pred.shape = (n_samples,)``</span></div>
<div class="line"><span class="lineno"> 2536</span><span class="stringliteral">        the probabilities provided are assumed to be that of the</span></div>
<div class="line"><span class="lineno"> 2537</span><span class="stringliteral">        positive class. The labels in ``y_pred`` are assumed to be</span></div>
<div class="line"><span class="lineno"> 2538</span><span class="stringliteral">        ordered alphabetically, as done by</span></div>
<div class="line"><span class="lineno"> 2539</span><span class="stringliteral">        :class:`preprocessing.LabelBinarizer`.</span></div>
<div class="line"><span class="lineno"> 2540</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2541</span><span class="stringliteral">    eps : float or &quot;auto&quot;, default=&quot;auto&quot;</span></div>
<div class="line"><span class="lineno"> 2542</span><span class="stringliteral">        Log loss is undefined for p=0 or p=1, so probabilities are</span></div>
<div class="line"><span class="lineno"> 2543</span><span class="stringliteral">        clipped to `max(eps, min(1 - eps, p))`. The default will depend on the</span></div>
<div class="line"><span class="lineno"> 2544</span><span class="stringliteral">        data type of `y_pred` and is set to `np.finfo(y_pred.dtype).eps`.</span></div>
<div class="line"><span class="lineno"> 2545</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2546</span><span class="stringliteral">        .. versionadded:: 1.2</span></div>
<div class="line"><span class="lineno"> 2547</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2548</span><span class="stringliteral">        .. versionchanged:: 1.2</span></div>
<div class="line"><span class="lineno"> 2549</span><span class="stringliteral">           The default value changed from `1e-15` to `&quot;auto&quot;` that is</span></div>
<div class="line"><span class="lineno"> 2550</span><span class="stringliteral">           equivalent to `np.finfo(y_pred.dtype).eps`.</span></div>
<div class="line"><span class="lineno"> 2551</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2552</span><span class="stringliteral">    normalize : bool, default=True</span></div>
<div class="line"><span class="lineno"> 2553</span><span class="stringliteral">        If true, return the mean loss per sample.</span></div>
<div class="line"><span class="lineno"> 2554</span><span class="stringliteral">        Otherwise, return the sum of the per-sample losses.</span></div>
<div class="line"><span class="lineno"> 2555</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2556</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 2557</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 2558</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2559</span><span class="stringliteral">    labels : array-like, default=None</span></div>
<div class="line"><span class="lineno"> 2560</span><span class="stringliteral">        If not provided, labels will be inferred from y_true. If ``labels``</span></div>
<div class="line"><span class="lineno"> 2561</span><span class="stringliteral">        is ``None`` and ``y_pred`` has shape (n_samples,) the labels are</span></div>
<div class="line"><span class="lineno"> 2562</span><span class="stringliteral">        assumed to be binary and are inferred from ``y_true``.</span></div>
<div class="line"><span class="lineno"> 2563</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2564</span><span class="stringliteral">        .. versionadded:: 0.18</span></div>
<div class="line"><span class="lineno"> 2565</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2566</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 2567</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 2568</span><span class="stringliteral">    loss : float</span></div>
<div class="line"><span class="lineno"> 2569</span><span class="stringliteral">        Log loss, aka logistic loss or cross-entropy loss.</span></div>
<div class="line"><span class="lineno"> 2570</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2571</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 2572</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 2573</span><span class="stringliteral">    The logarithm used is the natural logarithm (base-e).</span></div>
<div class="line"><span class="lineno"> 2574</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2575</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 2576</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 2577</span><span class="stringliteral">    C.M. Bishop (2006). Pattern Recognition and Machine Learning. Springer,</span></div>
<div class="line"><span class="lineno"> 2578</span><span class="stringliteral">    p. 209.</span></div>
<div class="line"><span class="lineno"> 2579</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2580</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 2581</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2582</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import log_loss</span></div>
<div class="line"><span class="lineno"> 2583</span><span class="stringliteral">    &gt;&gt;&gt; log_loss([&quot;spam&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;spam&quot;],</span></div>
<div class="line"><span class="lineno"> 2584</span><span class="stringliteral">    ...          [[.1, .9], [.9, .1], [.8, .2], [.35, .65]])</span></div>
<div class="line"><span class="lineno"> 2585</span><span class="stringliteral">    0.21616...</span></div>
<div class="line"><span class="lineno"> 2586</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 2587</span>    y_pred = check_array(</div>
<div class="line"><span class="lineno"> 2588</span>        y_pred, ensure_2d=<span class="keyword">False</span>, dtype=[np.float64, np.float32, np.float16]</div>
<div class="line"><span class="lineno"> 2589</span>    )</div>
<div class="line"><span class="lineno"> 2590</span>    eps = np.finfo(y_pred.dtype).eps <span class="keywordflow">if</span> eps == <span class="stringliteral">&quot;auto&quot;</span> <span class="keywordflow">else</span> eps</div>
<div class="line"><span class="lineno"> 2591</span> </div>
<div class="line"><span class="lineno"> 2592</span>    check_consistent_length(y_pred, y_true, sample_weight)</div>
<div class="line"><span class="lineno"> 2593</span>    lb = LabelBinarizer()</div>
<div class="line"><span class="lineno"> 2594</span> </div>
<div class="line"><span class="lineno"> 2595</span>    <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 2596</span>        lb.fit(labels)</div>
<div class="line"><span class="lineno"> 2597</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2598</span>        lb.fit(y_true)</div>
<div class="line"><span class="lineno"> 2599</span> </div>
<div class="line"><span class="lineno"> 2600</span>    <span class="keywordflow">if</span> len(lb.classes_) == 1:</div>
<div class="line"><span class="lineno"> 2601</span>        <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 2602</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 2603</span>                <span class="stringliteral">&quot;y_true contains only one label ({0}). Please &quot;</span></div>
<div class="line"><span class="lineno"> 2604</span>                <span class="stringliteral">&quot;provide the true labels explicitly through the &quot;</span></div>
<div class="line"><span class="lineno"> 2605</span>                <span class="stringliteral">&quot;labels argument.&quot;</span>.format(lb.classes_[0])</div>
<div class="line"><span class="lineno"> 2606</span>            )</div>
<div class="line"><span class="lineno"> 2607</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2608</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 2609</span>                <span class="stringliteral">&quot;The labels array needs to contain at least two &quot;</span></div>
<div class="line"><span class="lineno"> 2610</span>                <span class="stringliteral">&quot;labels for log_loss, &quot;</span></div>
<div class="line"><span class="lineno"> 2611</span>                <span class="stringliteral">&quot;got {0}.&quot;</span>.format(lb.classes_)</div>
<div class="line"><span class="lineno"> 2612</span>            )</div>
<div class="line"><span class="lineno"> 2613</span> </div>
<div class="line"><span class="lineno"> 2614</span>    transformed_labels = lb.transform(y_true)</div>
<div class="line"><span class="lineno"> 2615</span> </div>
<div class="line"><span class="lineno"> 2616</span>    <span class="keywordflow">if</span> transformed_labels.shape[1] == 1:</div>
<div class="line"><span class="lineno"> 2617</span>        transformed_labels = np.append(</div>
<div class="line"><span class="lineno"> 2618</span>            1 - transformed_labels, transformed_labels, axis=1</div>
<div class="line"><span class="lineno"> 2619</span>        )</div>
<div class="line"><span class="lineno"> 2620</span> </div>
<div class="line"><span class="lineno"> 2621</span>    <span class="comment"># Clipping</span></div>
<div class="line"><span class="lineno"> 2622</span>    y_pred = np.clip(y_pred, eps, 1 - eps)</div>
<div class="line"><span class="lineno"> 2623</span> </div>
<div class="line"><span class="lineno"> 2624</span>    <span class="comment"># If y_pred is of single dimension, assume y_true to be binary</span></div>
<div class="line"><span class="lineno"> 2625</span>    <span class="comment"># and then check.</span></div>
<div class="line"><span class="lineno"> 2626</span>    <span class="keywordflow">if</span> y_pred.ndim == 1:</div>
<div class="line"><span class="lineno"> 2627</span>        y_pred = y_pred[:, np.newaxis]</div>
<div class="line"><span class="lineno"> 2628</span>    <span class="keywordflow">if</span> y_pred.shape[1] == 1:</div>
<div class="line"><span class="lineno"> 2629</span>        y_pred = np.append(1 - y_pred, y_pred, axis=1)</div>
<div class="line"><span class="lineno"> 2630</span> </div>
<div class="line"><span class="lineno"> 2631</span>    <span class="comment"># Check if dimensions are consistent.</span></div>
<div class="line"><span class="lineno"> 2632</span>    transformed_labels = check_array(transformed_labels)</div>
<div class="line"><span class="lineno"> 2633</span>    <span class="keywordflow">if</span> len(lb.classes_) != y_pred.shape[1]:</div>
<div class="line"><span class="lineno"> 2634</span>        <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 2635</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 2636</span>                <span class="stringliteral">&quot;y_true and y_pred contain different number of &quot;</span></div>
<div class="line"><span class="lineno"> 2637</span>                <span class="stringliteral">&quot;classes {0}, {1}. Please provide the true &quot;</span></div>
<div class="line"><span class="lineno"> 2638</span>                <span class="stringliteral">&quot;labels explicitly through the labels argument. &quot;</span></div>
<div class="line"><span class="lineno"> 2639</span>                <span class="stringliteral">&quot;Classes found in &quot;</span></div>
<div class="line"><span class="lineno"> 2640</span>                <span class="stringliteral">&quot;y_true: {2}&quot;</span>.format(</div>
<div class="line"><span class="lineno"> 2641</span>                    transformed_labels.shape[1], y_pred.shape[1], lb.classes_</div>
<div class="line"><span class="lineno"> 2642</span>                )</div>
<div class="line"><span class="lineno"> 2643</span>            )</div>
<div class="line"><span class="lineno"> 2644</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 2645</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 2646</span>                <span class="stringliteral">&quot;The number of classes in labels is different &quot;</span></div>
<div class="line"><span class="lineno"> 2647</span>                <span class="stringliteral">&quot;from that in y_pred. Classes found in &quot;</span></div>
<div class="line"><span class="lineno"> 2648</span>                <span class="stringliteral">&quot;labels: {0}&quot;</span>.format(lb.classes_)</div>
<div class="line"><span class="lineno"> 2649</span>            )</div>
<div class="line"><span class="lineno"> 2650</span> </div>
<div class="line"><span class="lineno"> 2651</span>    <span class="comment"># Renormalize</span></div>
<div class="line"><span class="lineno"> 2652</span>    y_pred_sum = y_pred.sum(axis=1)</div>
<div class="line"><span class="lineno"> 2653</span>    y_pred = y_pred / y_pred_sum[:, np.newaxis]</div>
<div class="line"><span class="lineno"> 2654</span>    loss = -xlogy(transformed_labels, y_pred).sum(axis=1)</div>
<div class="line"><span class="lineno"> 2655</span> </div>
<div class="line"><span class="lineno"> 2656</span>    <span class="keywordflow">return</span> _weighted_sum(loss, sample_weight, normalize)</div>
<div class="line"><span class="lineno"> 2657</span> </div>
<div class="line"><span class="lineno"> 2658</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac935fbac0b7b6eb7d9a7bc52ecb750c0" name="ac935fbac0b7b6eb7d9a7bc52ecb750c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac935fbac0b7b6eb7d9a7bc52ecb750c0">&#9670;&#160;</a></span>matthews_corrcoef()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.matthews_corrcoef </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the Matthews correlation coefficient (MCC).

The Matthews correlation coefficient is used in machine learning as a
measure of the quality of binary and multiclass classifications. It takes
into account true and false positives and negatives and is generally
regarded as a balanced measure which can be used even if the classes are of
very different sizes. The MCC is in essence a correlation coefficient value
between -1 and +1. A coefficient of +1 represents a perfect prediction, 0
an average random prediction and -1 an inverse prediction.  The statistic
is also known as the phi coefficient. [source: Wikipedia]

Binary and multiclass labels are supported.  Only in the binary case does
this relate to information about true and false positives and negatives.
See references below.

Read more in the :ref:`User Guide &lt;matthews_corrcoef&gt;`.

Parameters
----------
y_true : array, shape = [n_samples]
    Ground truth (correct) target values.

y_pred : array, shape = [n_samples]
    Estimated targets as returned by a classifier.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

    .. versionadded:: 0.18

Returns
-------
mcc : float
    The Matthews correlation coefficient (+1 represents a perfect
    prediction, 0 an average random prediction and -1 and inverse
    prediction).

References
----------
.. [1] :doi:`Baldi, Brunak, Chauvin, Andersen and Nielsen, (2000). Assessing the
   accuracy of prediction algorithms for classification: an overview.
   &lt;10.1093/bioinformatics/16.5.412&gt;`

.. [2] `Wikipedia entry for the Matthews Correlation Coefficient
   &lt;https://en.wikipedia.org/wiki/Matthews_correlation_coefficient&gt;`_.

.. [3] `Gorodkin, (2004). Comparing two K-category assignments by a
    K-category correlation coefficient
    &lt;https://www.sciencedirect.com/science/article/pii/S1476927104000799&gt;`_.

.. [4] `Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC and CEN
    Error Measures in MultiClass Prediction
    &lt;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0041882&gt;`_.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import matthews_corrcoef
&gt;&gt;&gt; y_true = [+1, +1, +1, -1]
&gt;&gt;&gt; y_pred = [+1, -1, +1, +1]
&gt;&gt;&gt; matthews_corrcoef(y_true, y_pred)
-0.33...
</pre> <div class="fragment"><div class="line"><span class="lineno">  848</span><span class="keyword">def </span>matthews_corrcoef(y_true, y_pred, *, sample_weight=None):</div>
<div class="line"><span class="lineno">  849</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the Matthews correlation coefficient (MCC).</span></div>
<div class="line"><span class="lineno">  850</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  851</span><span class="stringliteral">    The Matthews correlation coefficient is used in machine learning as a</span></div>
<div class="line"><span class="lineno">  852</span><span class="stringliteral">    measure of the quality of binary and multiclass classifications. It takes</span></div>
<div class="line"><span class="lineno">  853</span><span class="stringliteral">    into account true and false positives and negatives and is generally</span></div>
<div class="line"><span class="lineno">  854</span><span class="stringliteral">    regarded as a balanced measure which can be used even if the classes are of</span></div>
<div class="line"><span class="lineno">  855</span><span class="stringliteral">    very different sizes. The MCC is in essence a correlation coefficient value</span></div>
<div class="line"><span class="lineno">  856</span><span class="stringliteral">    between -1 and +1. A coefficient of +1 represents a perfect prediction, 0</span></div>
<div class="line"><span class="lineno">  857</span><span class="stringliteral">    an average random prediction and -1 an inverse prediction.  The statistic</span></div>
<div class="line"><span class="lineno">  858</span><span class="stringliteral">    is also known as the phi coefficient. [source: Wikipedia]</span></div>
<div class="line"><span class="lineno">  859</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  860</span><span class="stringliteral">    Binary and multiclass labels are supported.  Only in the binary case does</span></div>
<div class="line"><span class="lineno">  861</span><span class="stringliteral">    this relate to information about true and false positives and negatives.</span></div>
<div class="line"><span class="lineno">  862</span><span class="stringliteral">    See references below.</span></div>
<div class="line"><span class="lineno">  863</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  864</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;matthews_corrcoef&gt;`.</span></div>
<div class="line"><span class="lineno">  865</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  866</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  867</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  868</span><span class="stringliteral">    y_true : array, shape = [n_samples]</span></div>
<div class="line"><span class="lineno">  869</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  870</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  871</span><span class="stringliteral">    y_pred : array, shape = [n_samples]</span></div>
<div class="line"><span class="lineno">  872</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno">  873</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  874</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  875</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  876</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  877</span><span class="stringliteral">        .. versionadded:: 0.18</span></div>
<div class="line"><span class="lineno">  878</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  879</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  880</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  881</span><span class="stringliteral">    mcc : float</span></div>
<div class="line"><span class="lineno">  882</span><span class="stringliteral">        The Matthews correlation coefficient (+1 represents a perfect</span></div>
<div class="line"><span class="lineno">  883</span><span class="stringliteral">        prediction, 0 an average random prediction and -1 and inverse</span></div>
<div class="line"><span class="lineno">  884</span><span class="stringliteral">        prediction).</span></div>
<div class="line"><span class="lineno">  885</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  886</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  887</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  888</span><span class="stringliteral">    .. [1] :doi:`Baldi, Brunak, Chauvin, Andersen and Nielsen, (2000). Assessing the</span></div>
<div class="line"><span class="lineno">  889</span><span class="stringliteral">       accuracy of prediction algorithms for classification: an overview.</span></div>
<div class="line"><span class="lineno">  890</span><span class="stringliteral">       &lt;10.1093/bioinformatics/16.5.412&gt;`</span></div>
<div class="line"><span class="lineno">  891</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  892</span><span class="stringliteral">    .. [2] `Wikipedia entry for the Matthews Correlation Coefficient</span></div>
<div class="line"><span class="lineno">  893</span><span class="stringliteral">       &lt;https://en.wikipedia.org/wiki/Matthews_correlation_coefficient&gt;`_.</span></div>
<div class="line"><span class="lineno">  894</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  895</span><span class="stringliteral">    .. [3] `Gorodkin, (2004). Comparing two K-category assignments by a</span></div>
<div class="line"><span class="lineno">  896</span><span class="stringliteral">        K-category correlation coefficient</span></div>
<div class="line"><span class="lineno">  897</span><span class="stringliteral">        &lt;https://www.sciencedirect.com/science/article/pii/S1476927104000799&gt;`_.</span></div>
<div class="line"><span class="lineno">  898</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  899</span><span class="stringliteral">    .. [4] `Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC and CEN</span></div>
<div class="line"><span class="lineno">  900</span><span class="stringliteral">        Error Measures in MultiClass Prediction</span></div>
<div class="line"><span class="lineno">  901</span><span class="stringliteral">        &lt;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0041882&gt;`_.</span></div>
<div class="line"><span class="lineno">  902</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  903</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  904</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  905</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import matthews_corrcoef</span></div>
<div class="line"><span class="lineno">  906</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [+1, +1, +1, -1]</span></div>
<div class="line"><span class="lineno">  907</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [+1, -1, +1, +1]</span></div>
<div class="line"><span class="lineno">  908</span><span class="stringliteral">    &gt;&gt;&gt; matthews_corrcoef(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  909</span><span class="stringliteral">    -0.33...</span></div>
<div class="line"><span class="lineno">  910</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  911</span>    y_type, y_true, y_pred = _check_targets(y_true, y_pred)</div>
<div class="line"><span class="lineno">  912</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  913</span>    <span class="keywordflow">if</span> y_type <span class="keywordflow">not</span> <span class="keywordflow">in</span> {<span class="stringliteral">&quot;binary&quot;</span>, <span class="stringliteral">&quot;multiclass&quot;</span>}:</div>
<div class="line"><span class="lineno">  914</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;%s is not supported&quot;</span> % y_type)</div>
<div class="line"><span class="lineno">  915</span> </div>
<div class="line"><span class="lineno">  916</span>    lb = LabelEncoder()</div>
<div class="line"><span class="lineno">  917</span>    lb.fit(np.hstack([y_true, y_pred]))</div>
<div class="line"><span class="lineno">  918</span>    y_true = lb.transform(y_true)</div>
<div class="line"><span class="lineno">  919</span>    y_pred = lb.transform(y_pred)</div>
<div class="line"><span class="lineno">  920</span> </div>
<div class="line"><span class="lineno">  921</span>    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  922</span>    t_sum = C.sum(axis=1, dtype=np.float64)</div>
<div class="line"><span class="lineno">  923</span>    p_sum = C.sum(axis=0, dtype=np.float64)</div>
<div class="line"><span class="lineno">  924</span>    n_correct = np.trace(C, dtype=np.float64)</div>
<div class="line"><span class="lineno">  925</span>    n_samples = p_sum.sum()</div>
<div class="line"><span class="lineno">  926</span>    cov_ytyp = n_correct * n_samples - np.dot(t_sum, p_sum)</div>
<div class="line"><span class="lineno">  927</span>    cov_ypyp = n_samples**2 - np.dot(p_sum, p_sum)</div>
<div class="line"><span class="lineno">  928</span>    cov_ytyt = n_samples**2 - np.dot(t_sum, t_sum)</div>
<div class="line"><span class="lineno">  929</span> </div>
<div class="line"><span class="lineno">  930</span>    <span class="keywordflow">if</span> cov_ypyp * cov_ytyt == 0:</div>
<div class="line"><span class="lineno">  931</span>        <span class="keywordflow">return</span> 0.0</div>
<div class="line"><span class="lineno">  932</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  933</span>        <span class="keywordflow">return</span> cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)</div>
<div class="line"><span class="lineno">  934</span> </div>
<div class="line"><span class="lineno">  935</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1358dfb90c80aab40483bc7f2effa9c1" name="a1358dfb90c80aab40483bc7f2effa9c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1358dfb90c80aab40483bc7f2effa9c1">&#9670;&#160;</a></span>multilabel_confusion_matrix()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.multilabel_confusion_matrix </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>samplewise</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute a confusion matrix for each class or sample.

.. versionadded:: 0.21

Compute class-wise (default) or sample-wise (samplewise=True) multilabel
confusion matrix to evaluate the accuracy of a classification, and output
confusion matrices for each class or sample.

In multilabel confusion matrix :math:`MCM`, the count of true negatives
is :math:`MCM_{:,0,0}`, false negatives is :math:`MCM_{:,1,0}`,
true positives is :math:`MCM_{:,1,1}` and false positives is
:math:`MCM_{:,0,1}`.

Multiclass data will be treated as if binarized under a one-vs-rest
transformation. Returned confusion matrices will be in the order of
sorted unique labels in the union of (y_true, y_pred).

Read more in the :ref:`User Guide &lt;multilabel_confusion_matrix&gt;`.

Parameters
----------
y_true : {array-like, sparse matrix} of shape (n_samples, n_outputs) or \
        (n_samples,)
    Ground truth (correct) target values.

y_pred : {array-like, sparse matrix} of shape (n_samples, n_outputs) or \
        (n_samples,)
    Estimated targets as returned by a classifier.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

labels : array-like of shape (n_classes,), default=None
    A list of classes or column indices to select some (or to force
    inclusion of classes absent from the data).

samplewise : bool, default=False
    In the multilabel case, this calculates a confusion matrix per sample.

Returns
-------
multi_confusion : ndarray of shape (n_outputs, 2, 2)
    A 2x2 confusion matrix corresponding to each output in the input.
    When calculating class-wise multi_confusion (default), then
    n_outputs = n_labels; when calculating sample-wise multi_confusion
    (samplewise=True), n_outputs = n_samples. If ``labels`` is defined,
    the results will be returned in the order specified in ``labels``,
    otherwise the results will be returned in sorted order by default.

See Also
--------
confusion_matrix : Compute confusion matrix to evaluate the accuracy of a
    classifier.

Notes
-----
The `multilabel_confusion_matrix` calculates class-wise or sample-wise
multilabel confusion matrices, and in multiclass tasks, labels are
binarized under a one-vs-rest way; while
:func:`~sklearn.metrics.confusion_matrix` calculates one confusion matrix
for confusion between every two classes.

Examples
--------
Multilabel-indicator case:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import multilabel_confusion_matrix
&gt;&gt;&gt; y_true = np.array([[1, 0, 1],
...                    [0, 1, 0]])
&gt;&gt;&gt; y_pred = np.array([[1, 0, 0],
...                    [0, 1, 1]])
&gt;&gt;&gt; multilabel_confusion_matrix(y_true, y_pred)
array([[[1, 0],
        [0, 1]],
&lt;BLANKLINE&gt;
       [[1, 0],
        [0, 1]],
&lt;BLANKLINE&gt;
       [[0, 1],
        [1, 0]]])

Multiclass case:

&gt;&gt;&gt; y_true = ["cat", "ant", "cat", "cat", "ant", "bird"]
&gt;&gt;&gt; y_pred = ["ant", "ant", "cat", "cat", "ant", "cat"]
&gt;&gt;&gt; multilabel_confusion_matrix(y_true, y_pred,
...                             labels=["ant", "bird", "cat"])
array([[[3, 1],
        [0, 2]],
&lt;BLANKLINE&gt;
       [[5, 0],
        [1, 0]],
&lt;BLANKLINE&gt;
       [[2, 1],
        [1, 2]]])
</pre> <div class="fragment"><div class="line"><span class="lineno">  391</span>):</div>
<div class="line"><span class="lineno">  392</span>    <span class="stringliteral">&quot;&quot;&quot;Compute a confusion matrix for each class or sample.</span></div>
<div class="line"><span class="lineno">  393</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  394</span><span class="stringliteral">    .. versionadded:: 0.21</span></div>
<div class="line"><span class="lineno">  395</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  396</span><span class="stringliteral">    Compute class-wise (default) or sample-wise (samplewise=True) multilabel</span></div>
<div class="line"><span class="lineno">  397</span><span class="stringliteral">    confusion matrix to evaluate the accuracy of a classification, and output</span></div>
<div class="line"><span class="lineno">  398</span><span class="stringliteral">    confusion matrices for each class or sample.</span></div>
<div class="line"><span class="lineno">  399</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  400</span><span class="stringliteral">    In multilabel confusion matrix :math:`MCM`, the count of true negatives</span></div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral">    is :math:`MCM_{:,0,0}`, false negatives is :math:`MCM_{:,1,0}`,</span></div>
<div class="line"><span class="lineno">  402</span><span class="stringliteral">    true positives is :math:`MCM_{:,1,1}` and false positives is</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral">    :math:`MCM_{:,0,1}`.</span></div>
<div class="line"><span class="lineno">  404</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral">    Multiclass data will be treated as if binarized under a one-vs-rest</span></div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">    transformation. Returned confusion matrices will be in the order of</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral">    sorted unique labels in the union of (y_true, y_pred).</span></div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;multilabel_confusion_matrix&gt;`.</span></div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral">    y_true : {array-like, sparse matrix} of shape (n_samples, n_outputs) or \</span></div>
<div class="line"><span class="lineno">  414</span><span class="stringliteral">            (n_samples,)</span></div>
<div class="line"><span class="lineno">  415</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral">    y_pred : {array-like, sparse matrix} of shape (n_samples, n_outputs) or \</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">            (n_samples,)</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  421</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  422</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  423</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  424</span><span class="stringliteral">    labels : array-like of shape (n_classes,), default=None</span></div>
<div class="line"><span class="lineno">  425</span><span class="stringliteral">        A list of classes or column indices to select some (or to force</span></div>
<div class="line"><span class="lineno">  426</span><span class="stringliteral">        inclusion of classes absent from the data).</span></div>
<div class="line"><span class="lineno">  427</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  428</span><span class="stringliteral">    samplewise : bool, default=False</span></div>
<div class="line"><span class="lineno">  429</span><span class="stringliteral">        In the multilabel case, this calculates a confusion matrix per sample.</span></div>
<div class="line"><span class="lineno">  430</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  431</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  432</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  433</span><span class="stringliteral">    multi_confusion : ndarray of shape (n_outputs, 2, 2)</span></div>
<div class="line"><span class="lineno">  434</span><span class="stringliteral">        A 2x2 confusion matrix corresponding to each output in the input.</span></div>
<div class="line"><span class="lineno">  435</span><span class="stringliteral">        When calculating class-wise multi_confusion (default), then</span></div>
<div class="line"><span class="lineno">  436</span><span class="stringliteral">        n_outputs = n_labels; when calculating sample-wise multi_confusion</span></div>
<div class="line"><span class="lineno">  437</span><span class="stringliteral">        (samplewise=True), n_outputs = n_samples. If ``labels`` is defined,</span></div>
<div class="line"><span class="lineno">  438</span><span class="stringliteral">        the results will be returned in the order specified in ``labels``,</span></div>
<div class="line"><span class="lineno">  439</span><span class="stringliteral">        otherwise the results will be returned in sorted order by default.</span></div>
<div class="line"><span class="lineno">  440</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  441</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  442</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  443</span><span class="stringliteral">    confusion_matrix : Compute confusion matrix to evaluate the accuracy of a</span></div>
<div class="line"><span class="lineno">  444</span><span class="stringliteral">        classifier.</span></div>
<div class="line"><span class="lineno">  445</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  446</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  447</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  448</span><span class="stringliteral">    The `multilabel_confusion_matrix` calculates class-wise or sample-wise</span></div>
<div class="line"><span class="lineno">  449</span><span class="stringliteral">    multilabel confusion matrices, and in multiclass tasks, labels are</span></div>
<div class="line"><span class="lineno">  450</span><span class="stringliteral">    binarized under a one-vs-rest way; while</span></div>
<div class="line"><span class="lineno">  451</span><span class="stringliteral">    :func:`~sklearn.metrics.confusion_matrix` calculates one confusion matrix</span></div>
<div class="line"><span class="lineno">  452</span><span class="stringliteral">    for confusion between every two classes.</span></div>
<div class="line"><span class="lineno">  453</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  454</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  455</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  456</span><span class="stringliteral">    Multilabel-indicator case:</span></div>
<div class="line"><span class="lineno">  457</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  458</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  459</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import multilabel_confusion_matrix</span></div>
<div class="line"><span class="lineno">  460</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([[1, 0, 1],</span></div>
<div class="line"><span class="lineno">  461</span><span class="stringliteral">    ...                    [0, 1, 0]])</span></div>
<div class="line"><span class="lineno">  462</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = np.array([[1, 0, 0],</span></div>
<div class="line"><span class="lineno">  463</span><span class="stringliteral">    ...                    [0, 1, 1]])</span></div>
<div class="line"><span class="lineno">  464</span><span class="stringliteral">    &gt;&gt;&gt; multilabel_confusion_matrix(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  465</span><span class="stringliteral">    array([[[1, 0],</span></div>
<div class="line"><span class="lineno">  466</span><span class="stringliteral">            [0, 1]],</span></div>
<div class="line"><span class="lineno">  467</span><span class="stringliteral">    &lt;BLANKLINE&gt;</span></div>
<div class="line"><span class="lineno">  468</span><span class="stringliteral">           [[1, 0],</span></div>
<div class="line"><span class="lineno">  469</span><span class="stringliteral">            [0, 1]],</span></div>
<div class="line"><span class="lineno">  470</span><span class="stringliteral">    &lt;BLANKLINE&gt;</span></div>
<div class="line"><span class="lineno">  471</span><span class="stringliteral">           [[0, 1],</span></div>
<div class="line"><span class="lineno">  472</span><span class="stringliteral">            [1, 0]]])</span></div>
<div class="line"><span class="lineno">  473</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  474</span><span class="stringliteral">    Multiclass case:</span></div>
<div class="line"><span class="lineno">  475</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  476</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [&quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;bird&quot;]</span></div>
<div class="line"><span class="lineno">  477</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [&quot;ant&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;]</span></div>
<div class="line"><span class="lineno">  478</span><span class="stringliteral">    &gt;&gt;&gt; multilabel_confusion_matrix(y_true, y_pred,</span></div>
<div class="line"><span class="lineno">  479</span><span class="stringliteral">    ...                             labels=[&quot;ant&quot;, &quot;bird&quot;, &quot;cat&quot;])</span></div>
<div class="line"><span class="lineno">  480</span><span class="stringliteral">    array([[[3, 1],</span></div>
<div class="line"><span class="lineno">  481</span><span class="stringliteral">            [0, 2]],</span></div>
<div class="line"><span class="lineno">  482</span><span class="stringliteral">    &lt;BLANKLINE&gt;</span></div>
<div class="line"><span class="lineno">  483</span><span class="stringliteral">           [[5, 0],</span></div>
<div class="line"><span class="lineno">  484</span><span class="stringliteral">            [1, 0]],</span></div>
<div class="line"><span class="lineno">  485</span><span class="stringliteral">    &lt;BLANKLINE&gt;</span></div>
<div class="line"><span class="lineno">  486</span><span class="stringliteral">           [[2, 1],</span></div>
<div class="line"><span class="lineno">  487</span><span class="stringliteral">            [1, 2]]])</span></div>
<div class="line"><span class="lineno">  488</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  489</span>    y_type, y_true, y_pred = _check_targets(y_true, y_pred)</div>
<div class="line"><span class="lineno">  490</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  491</span>        sample_weight = column_or_1d(sample_weight)</div>
<div class="line"><span class="lineno">  492</span>    check_consistent_length(y_true, y_pred, sample_weight)</div>
<div class="line"><span class="lineno">  493</span> </div>
<div class="line"><span class="lineno">  494</span>    <span class="keywordflow">if</span> y_type <span class="keywordflow">not</span> <span class="keywordflow">in</span> (<span class="stringliteral">&quot;binary&quot;</span>, <span class="stringliteral">&quot;multiclass&quot;</span>, <span class="stringliteral">&quot;multilabel-indicator&quot;</span>):</div>
<div class="line"><span class="lineno">  495</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;%s is not supported&quot;</span> % y_type)</div>
<div class="line"><span class="lineno">  496</span> </div>
<div class="line"><span class="lineno">  497</span>    present_labels = unique_labels(y_true, y_pred)</div>
<div class="line"><span class="lineno">  498</span>    <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  499</span>        labels = present_labels</div>
<div class="line"><span class="lineno">  500</span>        n_labels = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  501</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  502</span>        n_labels = len(labels)</div>
<div class="line"><span class="lineno">  503</span>        labels = np.hstack(</div>
<div class="line"><span class="lineno">  504</span>            [labels, np.setdiff1d(present_labels, labels, assume_unique=<span class="keyword">True</span>)]</div>
<div class="line"><span class="lineno">  505</span>        )</div>
<div class="line"><span class="lineno">  506</span> </div>
<div class="line"><span class="lineno">  507</span>    <span class="keywordflow">if</span> y_true.ndim == 1:</div>
<div class="line"><span class="lineno">  508</span>        <span class="keywordflow">if</span> samplewise:</div>
<div class="line"><span class="lineno">  509</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  510</span>                <span class="stringliteral">&quot;Samplewise metrics are not available outside of &quot;</span></div>
<div class="line"><span class="lineno">  511</span>                <span class="stringliteral">&quot;multilabel classification.&quot;</span></div>
<div class="line"><span class="lineno">  512</span>            )</div>
<div class="line"><span class="lineno">  513</span> </div>
<div class="line"><span class="lineno">  514</span>        le = LabelEncoder()</div>
<div class="line"><span class="lineno">  515</span>        le.fit(labels)</div>
<div class="line"><span class="lineno">  516</span>        y_true = le.transform(y_true)</div>
<div class="line"><span class="lineno">  517</span>        y_pred = le.transform(y_pred)</div>
<div class="line"><span class="lineno">  518</span>        sorted_labels = le.classes_</div>
<div class="line"><span class="lineno">  519</span> </div>
<div class="line"><span class="lineno">  520</span>        <span class="comment"># labels are now from 0 to len(labels) - 1 -&gt; use bincount</span></div>
<div class="line"><span class="lineno">  521</span>        tp = y_true == y_pred</div>
<div class="line"><span class="lineno">  522</span>        tp_bins = y_true[tp]</div>
<div class="line"><span class="lineno">  523</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  524</span>            tp_bins_weights = np.asarray(sample_weight)[tp]</div>
<div class="line"><span class="lineno">  525</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  526</span>            tp_bins_weights = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  527</span> </div>
<div class="line"><span class="lineno">  528</span>        <span class="keywordflow">if</span> len(tp_bins):</div>
<div class="line"><span class="lineno">  529</span>            tp_sum = np.bincount(</div>
<div class="line"><span class="lineno">  530</span>                tp_bins, weights=tp_bins_weights, minlength=len(labels)</div>
<div class="line"><span class="lineno">  531</span>            )</div>
<div class="line"><span class="lineno">  532</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  533</span>            <span class="comment"># Pathological case</span></div>
<div class="line"><span class="lineno">  534</span>            true_sum = pred_sum = tp_sum = np.zeros(len(labels))</div>
<div class="line"><span class="lineno">  535</span>        <span class="keywordflow">if</span> len(y_pred):</div>
<div class="line"><span class="lineno">  536</span>            pred_sum = np.bincount(y_pred, weights=sample_weight, minlength=len(labels))</div>
<div class="line"><span class="lineno">  537</span>        <span class="keywordflow">if</span> len(y_true):</div>
<div class="line"><span class="lineno">  538</span>            true_sum = np.bincount(y_true, weights=sample_weight, minlength=len(labels))</div>
<div class="line"><span class="lineno">  539</span> </div>
<div class="line"><span class="lineno">  540</span>        <span class="comment"># Retain only selected labels</span></div>
<div class="line"><span class="lineno">  541</span>        indices = np.searchsorted(sorted_labels, labels[:n_labels])</div>
<div class="line"><span class="lineno">  542</span>        tp_sum = tp_sum[indices]</div>
<div class="line"><span class="lineno">  543</span>        true_sum = true_sum[indices]</div>
<div class="line"><span class="lineno">  544</span>        pred_sum = pred_sum[indices]</div>
<div class="line"><span class="lineno">  545</span> </div>
<div class="line"><span class="lineno">  546</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  547</span>        sum_axis = 1 <span class="keywordflow">if</span> samplewise <span class="keywordflow">else</span> 0</div>
<div class="line"><span class="lineno">  548</span> </div>
<div class="line"><span class="lineno">  549</span>        <span class="comment"># All labels are index integers for multilabel.</span></div>
<div class="line"><span class="lineno">  550</span>        <span class="comment"># Select labels:</span></div>
<div class="line"><span class="lineno">  551</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.array_equal(labels, present_labels):</div>
<div class="line"><span class="lineno">  552</span>            <span class="keywordflow">if</span> np.max(labels) &gt; np.max(present_labels):</div>
<div class="line"><span class="lineno">  553</span>                <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  554</span>                    <span class="stringliteral">&quot;All labels must be in [0, n labels) for &quot;</span></div>
<div class="line"><span class="lineno">  555</span>                    <span class="stringliteral">&quot;multilabel targets. &quot;</span></div>
<div class="line"><span class="lineno">  556</span>                    <span class="stringliteral">&quot;Got %d &gt; %d&quot;</span> % (np.max(labels), np.max(present_labels))</div>
<div class="line"><span class="lineno">  557</span>                )</div>
<div class="line"><span class="lineno">  558</span>            <span class="keywordflow">if</span> np.min(labels) &lt; 0:</div>
<div class="line"><span class="lineno">  559</span>                <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  560</span>                    <span class="stringliteral">&quot;All labels must be in [0, n labels) for &quot;</span></div>
<div class="line"><span class="lineno">  561</span>                    <span class="stringliteral">&quot;multilabel targets. &quot;</span></div>
<div class="line"><span class="lineno">  562</span>                    <span class="stringliteral">&quot;Got %d &lt; 0&quot;</span></div>
<div class="line"><span class="lineno">  563</span>                    % np.min(labels)</div>
<div class="line"><span class="lineno">  564</span>                )</div>
<div class="line"><span class="lineno">  565</span> </div>
<div class="line"><span class="lineno">  566</span>        <span class="keywordflow">if</span> n_labels <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  567</span>            y_true = y_true[:, labels[:n_labels]]</div>
<div class="line"><span class="lineno">  568</span>            y_pred = y_pred[:, labels[:n_labels]]</div>
<div class="line"><span class="lineno">  569</span> </div>
<div class="line"><span class="lineno">  570</span>        <span class="comment"># calculate weighted counts</span></div>
<div class="line"><span class="lineno">  571</span>        true_and_pred = y_true.multiply(y_pred)</div>
<div class="line"><span class="lineno">  572</span>        tp_sum = count_nonzero(</div>
<div class="line"><span class="lineno">  573</span>            true_and_pred, axis=sum_axis, sample_weight=sample_weight</div>
<div class="line"><span class="lineno">  574</span>        )</div>
<div class="line"><span class="lineno">  575</span>        pred_sum = count_nonzero(y_pred, axis=sum_axis, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  576</span>        true_sum = count_nonzero(y_true, axis=sum_axis, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  577</span> </div>
<div class="line"><span class="lineno">  578</span>    fp = pred_sum - tp_sum</div>
<div class="line"><span class="lineno">  579</span>    fn = true_sum - tp_sum</div>
<div class="line"><span class="lineno">  580</span>    tp = tp_sum</div>
<div class="line"><span class="lineno">  581</span> </div>
<div class="line"><span class="lineno">  582</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> samplewise:</div>
<div class="line"><span class="lineno">  583</span>        sample_weight = np.array(sample_weight)</div>
<div class="line"><span class="lineno">  584</span>        tp = np.array(tp)</div>
<div class="line"><span class="lineno">  585</span>        fp = np.array(fp)</div>
<div class="line"><span class="lineno">  586</span>        fn = np.array(fn)</div>
<div class="line"><span class="lineno">  587</span>        tn = sample_weight * y_true.shape[1] - tp - fp - fn</div>
<div class="line"><span class="lineno">  588</span>    <span class="keywordflow">elif</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  589</span>        tn = sum(sample_weight) - tp - fp - fn</div>
<div class="line"><span class="lineno">  590</span>    <span class="keywordflow">elif</span> samplewise:</div>
<div class="line"><span class="lineno">  591</span>        tn = y_true.shape[1] - tp - fp - fn</div>
<div class="line"><span class="lineno">  592</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  593</span>        tn = y_true.shape[0] - tp - fp - fn</div>
<div class="line"><span class="lineno">  594</span> </div>
<div class="line"><span class="lineno">  595</span>    <span class="keywordflow">return</span> np.array([tn, fp, fn, tp]).T.reshape(-1, 2, 2)</div>
<div class="line"><span class="lineno">  596</span> </div>
<div class="line"><span class="lineno">  597</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7abca91902c61236fccfb9f6610b2cfc" name="a7abca91902c61236fccfb9f6610b2cfc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7abca91902c61236fccfb9f6610b2cfc">&#9670;&#160;</a></span>precision_recall_fscore_support()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.precision_recall_fscore_support </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>beta</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>warn_for</em> = <code>(&quot;precision&quot;,&#160;&quot;recall&quot;,&#160;&quot;f-score&quot;)</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zero_division</em> = <code>&quot;warn&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute precision, recall, F-measure and support for each class.

The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of
true positives and ``fp`` the number of false positives. The precision is
intuitively the ability of the classifier not to label a negative sample as
positive.

The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of
true positives and ``fn`` the number of false negatives. The recall is
intuitively the ability of the classifier to find all the positive samples.

The F-beta score can be interpreted as a weighted harmonic mean of
the precision and recall, where an F-beta score reaches its best
value at 1 and worst score at 0.

The F-beta score weights recall more than precision by a factor of
``beta``. ``beta == 1.0`` means recall and precision are equally important.

The support is the number of occurrences of each class in ``y_true``.

If ``pos_label is None`` and in binary classification, this function
returns the average precision, recall and F-measure if ``average``
is one of ``'micro'``, ``'macro'``, ``'weighted'`` or ``'samples'``.

Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) target values.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Estimated targets as returned by a classifier.

beta : float, default=1.0
    The strength of recall versus precision in the F-score.

labels : array-like, default=None
    The set of labels to include when ``average != 'binary'``, and their
    order if ``average is None``. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in ``y_true`` and
    ``y_pred`` are used in sorted order.

pos_label : str or int, default=1
    The class to report if ``average='binary'`` and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting ``labels=[pos_label]`` and ``average != 'binary'`` will report
    scores for that label only.

average : {'binary', 'micro', 'macro', 'samples', 'weighted'}, \
        default=None
    If ``None``, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:

    ``'binary'``:
        Only report results for the class specified by ``pos_label``.
        This is applicable only if targets (``y_{true,pred}``) are binary.
    ``'micro'``:
        Calculate metrics globally by counting the total true positives,
        false negatives and false positives.
    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    ``'weighted'``:
        Calculate metrics for each label, and find their average weighted
        by support (the number of true instances for each label). This
        alters 'macro' to account for label imbalance; it can result in an
        F-score that is not between precision and recall.
    ``'samples'``:
        Calculate metrics for each instance, and find their average (only
        meaningful for multilabel classification where this differs from
        :func:`accuracy_score`).

warn_for : tuple or set, for internal use
    This determines which warnings will be made in the case that this
    function is being used to return only one of its metrics.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

zero_division : "warn", 0 or 1, default="warn"
    Sets the value to return when there is a zero division:
       - recall: when there are no positive labels
       - precision: when there are no positive predictions
       - f-score: both

    If set to "warn", this acts as 0, but warnings are also raised.

Returns
-------
precision : float (if average is not None) or array of float, shape =\
    [n_unique_labels]
    Precision score.

recall : float (if average is not None) or array of float, shape =\
    [n_unique_labels]
    Recall score.

fbeta_score : float (if average is not None) or array of float, shape =\
    [n_unique_labels]
    F-beta score.

support : None (if average is not None) or array of int, shape =\
    [n_unique_labels]
    The number of occurrences of each label in ``y_true``.

Notes
-----
When ``true positive + false positive == 0``, precision is undefined.
When ``true positive + false negative == 0``, recall is undefined.
In such cases, by default the metric will be set to 0, as will f-score,
and ``UndefinedMetricWarning`` will be raised. This behavior can be
modified with ``zero_division``.

References
----------
.. [1] `Wikipedia entry for the Precision and recall
       &lt;https://en.wikipedia.org/wiki/Precision_and_recall&gt;`_.

.. [2] `Wikipedia entry for the F1-score
       &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.

.. [3] `Discriminative Methods for Multi-labeled Classification Advances
       in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu
       Godbole, Sunita Sarawagi
       &lt;http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf&gt;`_.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import precision_recall_fscore_support
&gt;&gt;&gt; y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])
&gt;&gt;&gt; y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])
&gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average='macro')
(0.22..., 0.33..., 0.26..., None)
&gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average='micro')
(0.33..., 0.33..., 0.33..., None)
&gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average='weighted')
(0.22..., 0.33..., 0.26..., None)

It is possible to compute per-label precisions, recalls, F1-scores and
supports instead of averaging:

&gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average=None,
... labels=['pig', 'dog', 'cat'])
(array([0.        , 0.        , 0.66...]),
 array([0., 0., 1.]), array([0. , 0. , 0.8]),
 array([2, 2, 2]))
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1417</span>):</div>
<div class="line"><span class="lineno"> 1418</span>    <span class="stringliteral">&quot;&quot;&quot;Compute precision, recall, F-measure and support for each class.</span></div>
<div class="line"><span class="lineno"> 1419</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1420</span><span class="stringliteral">    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of</span></div>
<div class="line"><span class="lineno"> 1421</span><span class="stringliteral">    true positives and ``fp`` the number of false positives. The precision is</span></div>
<div class="line"><span class="lineno"> 1422</span><span class="stringliteral">    intuitively the ability of the classifier not to label a negative sample as</span></div>
<div class="line"><span class="lineno"> 1423</span><span class="stringliteral">    positive.</span></div>
<div class="line"><span class="lineno"> 1424</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1425</span><span class="stringliteral">    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of</span></div>
<div class="line"><span class="lineno"> 1426</span><span class="stringliteral">    true positives and ``fn`` the number of false negatives. The recall is</span></div>
<div class="line"><span class="lineno"> 1427</span><span class="stringliteral">    intuitively the ability of the classifier to find all the positive samples.</span></div>
<div class="line"><span class="lineno"> 1428</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1429</span><span class="stringliteral">    The F-beta score can be interpreted as a weighted harmonic mean of</span></div>
<div class="line"><span class="lineno"> 1430</span><span class="stringliteral">    the precision and recall, where an F-beta score reaches its best</span></div>
<div class="line"><span class="lineno"> 1431</span><span class="stringliteral">    value at 1 and worst score at 0.</span></div>
<div class="line"><span class="lineno"> 1432</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1433</span><span class="stringliteral">    The F-beta score weights recall more than precision by a factor of</span></div>
<div class="line"><span class="lineno"> 1434</span><span class="stringliteral">    ``beta``. ``beta == 1.0`` means recall and precision are equally important.</span></div>
<div class="line"><span class="lineno"> 1435</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1436</span><span class="stringliteral">    The support is the number of occurrences of each class in ``y_true``.</span></div>
<div class="line"><span class="lineno"> 1437</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1438</span><span class="stringliteral">    If ``pos_label is None`` and in binary classification, this function</span></div>
<div class="line"><span class="lineno"> 1439</span><span class="stringliteral">    returns the average precision, recall and F-measure if ``average``</span></div>
<div class="line"><span class="lineno"> 1440</span><span class="stringliteral">    is one of ``&#39;micro&#39;``, ``&#39;macro&#39;``, ``&#39;weighted&#39;`` or ``&#39;samples&#39;``.</span></div>
<div class="line"><span class="lineno"> 1441</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1442</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span></div>
<div class="line"><span class="lineno"> 1443</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1444</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1445</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1446</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1447</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 1448</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1449</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1450</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno"> 1451</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1452</span><span class="stringliteral">    beta : float, default=1.0</span></div>
<div class="line"><span class="lineno"> 1453</span><span class="stringliteral">        The strength of recall versus precision in the F-score.</span></div>
<div class="line"><span class="lineno"> 1454</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1455</span><span class="stringliteral">    labels : array-like, default=None</span></div>
<div class="line"><span class="lineno"> 1456</span><span class="stringliteral">        The set of labels to include when ``average != &#39;binary&#39;``, and their</span></div>
<div class="line"><span class="lineno"> 1457</span><span class="stringliteral">        order if ``average is None``. Labels present in the data can be</span></div>
<div class="line"><span class="lineno"> 1458</span><span class="stringliteral">        excluded, for example to calculate a multiclass average ignoring a</span></div>
<div class="line"><span class="lineno"> 1459</span><span class="stringliteral">        majority negative class, while labels not present in the data will</span></div>
<div class="line"><span class="lineno"> 1460</span><span class="stringliteral">        result in 0 components in a macro average. For multilabel targets,</span></div>
<div class="line"><span class="lineno"> 1461</span><span class="stringliteral">        labels are column indices. By default, all labels in ``y_true`` and</span></div>
<div class="line"><span class="lineno"> 1462</span><span class="stringliteral">        ``y_pred`` are used in sorted order.</span></div>
<div class="line"><span class="lineno"> 1463</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1464</span><span class="stringliteral">    pos_label : str or int, default=1</span></div>
<div class="line"><span class="lineno"> 1465</span><span class="stringliteral">        The class to report if ``average=&#39;binary&#39;`` and the data is binary.</span></div>
<div class="line"><span class="lineno"> 1466</span><span class="stringliteral">        If the data are multiclass or multilabel, this will be ignored;</span></div>
<div class="line"><span class="lineno"> 1467</span><span class="stringliteral">        setting ``labels=[pos_label]`` and ``average != &#39;binary&#39;`` will report</span></div>
<div class="line"><span class="lineno"> 1468</span><span class="stringliteral">        scores for that label only.</span></div>
<div class="line"><span class="lineno"> 1469</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1470</span><span class="stringliteral">    average : {&#39;binary&#39;, &#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;}, \</span></div>
<div class="line"><span class="lineno"> 1471</span><span class="stringliteral">            default=None</span></div>
<div class="line"><span class="lineno"> 1472</span><span class="stringliteral">        If ``None``, the scores for each class are returned. Otherwise, this</span></div>
<div class="line"><span class="lineno"> 1473</span><span class="stringliteral">        determines the type of averaging performed on the data:</span></div>
<div class="line"><span class="lineno"> 1474</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1475</span><span class="stringliteral">        ``&#39;binary&#39;``:</span></div>
<div class="line"><span class="lineno"> 1476</span><span class="stringliteral">            Only report results for the class specified by ``pos_label``.</span></div>
<div class="line"><span class="lineno"> 1477</span><span class="stringliteral">            This is applicable only if targets (``y_{true,pred}``) are binary.</span></div>
<div class="line"><span class="lineno"> 1478</span><span class="stringliteral">        ``&#39;micro&#39;``:</span></div>
<div class="line"><span class="lineno"> 1479</span><span class="stringliteral">            Calculate metrics globally by counting the total true positives,</span></div>
<div class="line"><span class="lineno"> 1480</span><span class="stringliteral">            false negatives and false positives.</span></div>
<div class="line"><span class="lineno"> 1481</span><span class="stringliteral">        ``&#39;macro&#39;``:</span></div>
<div class="line"><span class="lineno"> 1482</span><span class="stringliteral">            Calculate metrics for each label, and find their unweighted</span></div>
<div class="line"><span class="lineno"> 1483</span><span class="stringliteral">            mean.  This does not take label imbalance into account.</span></div>
<div class="line"><span class="lineno"> 1484</span><span class="stringliteral">        ``&#39;weighted&#39;``:</span></div>
<div class="line"><span class="lineno"> 1485</span><span class="stringliteral">            Calculate metrics for each label, and find their average weighted</span></div>
<div class="line"><span class="lineno"> 1486</span><span class="stringliteral">            by support (the number of true instances for each label). This</span></div>
<div class="line"><span class="lineno"> 1487</span><span class="stringliteral">            alters &#39;macro&#39; to account for label imbalance; it can result in an</span></div>
<div class="line"><span class="lineno"> 1488</span><span class="stringliteral">            F-score that is not between precision and recall.</span></div>
<div class="line"><span class="lineno"> 1489</span><span class="stringliteral">        ``&#39;samples&#39;``:</span></div>
<div class="line"><span class="lineno"> 1490</span><span class="stringliteral">            Calculate metrics for each instance, and find their average (only</span></div>
<div class="line"><span class="lineno"> 1491</span><span class="stringliteral">            meaningful for multilabel classification where this differs from</span></div>
<div class="line"><span class="lineno"> 1492</span><span class="stringliteral">            :func:`accuracy_score`).</span></div>
<div class="line"><span class="lineno"> 1493</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1494</span><span class="stringliteral">    warn_for : tuple or set, for internal use</span></div>
<div class="line"><span class="lineno"> 1495</span><span class="stringliteral">        This determines which warnings will be made in the case that this</span></div>
<div class="line"><span class="lineno"> 1496</span><span class="stringliteral">        function is being used to return only one of its metrics.</span></div>
<div class="line"><span class="lineno"> 1497</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1498</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1499</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1500</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1501</span><span class="stringliteral">    zero_division : &quot;warn&quot;, 0 or 1, default=&quot;warn&quot;</span></div>
<div class="line"><span class="lineno"> 1502</span><span class="stringliteral">        Sets the value to return when there is a zero division:</span></div>
<div class="line"><span class="lineno"> 1503</span><span class="stringliteral">           - recall: when there are no positive labels</span></div>
<div class="line"><span class="lineno"> 1504</span><span class="stringliteral">           - precision: when there are no positive predictions</span></div>
<div class="line"><span class="lineno"> 1505</span><span class="stringliteral">           - f-score: both</span></div>
<div class="line"><span class="lineno"> 1506</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1507</span><span class="stringliteral">        If set to &quot;warn&quot;, this acts as 0, but warnings are also raised.</span></div>
<div class="line"><span class="lineno"> 1508</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1509</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1510</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1511</span><span class="stringliteral">    precision : float (if average is not None) or array of float, shape =\</span></div>
<div class="line"><span class="lineno"> 1512</span><span class="stringliteral">        [n_unique_labels]</span></div>
<div class="line"><span class="lineno"> 1513</span><span class="stringliteral">        Precision score.</span></div>
<div class="line"><span class="lineno"> 1514</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1515</span><span class="stringliteral">    recall : float (if average is not None) or array of float, shape =\</span></div>
<div class="line"><span class="lineno"> 1516</span><span class="stringliteral">        [n_unique_labels]</span></div>
<div class="line"><span class="lineno"> 1517</span><span class="stringliteral">        Recall score.</span></div>
<div class="line"><span class="lineno"> 1518</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1519</span><span class="stringliteral">    fbeta_score : float (if average is not None) or array of float, shape =\</span></div>
<div class="line"><span class="lineno"> 1520</span><span class="stringliteral">        [n_unique_labels]</span></div>
<div class="line"><span class="lineno"> 1521</span><span class="stringliteral">        F-beta score.</span></div>
<div class="line"><span class="lineno"> 1522</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1523</span><span class="stringliteral">    support : None (if average is not None) or array of int, shape =\</span></div>
<div class="line"><span class="lineno"> 1524</span><span class="stringliteral">        [n_unique_labels]</span></div>
<div class="line"><span class="lineno"> 1525</span><span class="stringliteral">        The number of occurrences of each label in ``y_true``.</span></div>
<div class="line"><span class="lineno"> 1526</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1527</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1528</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1529</span><span class="stringliteral">    When ``true positive + false positive == 0``, precision is undefined.</span></div>
<div class="line"><span class="lineno"> 1530</span><span class="stringliteral">    When ``true positive + false negative == 0``, recall is undefined.</span></div>
<div class="line"><span class="lineno"> 1531</span><span class="stringliteral">    In such cases, by default the metric will be set to 0, as will f-score,</span></div>
<div class="line"><span class="lineno"> 1532</span><span class="stringliteral">    and ``UndefinedMetricWarning`` will be raised. This behavior can be</span></div>
<div class="line"><span class="lineno"> 1533</span><span class="stringliteral">    modified with ``zero_division``.</span></div>
<div class="line"><span class="lineno"> 1534</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1535</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1536</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1537</span><span class="stringliteral">    .. [1] `Wikipedia entry for the Precision and recall</span></div>
<div class="line"><span class="lineno"> 1538</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/Precision_and_recall&gt;`_.</span></div>
<div class="line"><span class="lineno"> 1539</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1540</span><span class="stringliteral">    .. [2] `Wikipedia entry for the F1-score</span></div>
<div class="line"><span class="lineno"> 1541</span><span class="stringliteral">           &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.</span></div>
<div class="line"><span class="lineno"> 1542</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1543</span><span class="stringliteral">    .. [3] `Discriminative Methods for Multi-labeled Classification Advances</span></div>
<div class="line"><span class="lineno"> 1544</span><span class="stringliteral">           in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu</span></div>
<div class="line"><span class="lineno"> 1545</span><span class="stringliteral">           Godbole, Sunita Sarawagi</span></div>
<div class="line"><span class="lineno"> 1546</span><span class="stringliteral">           &lt;http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf&gt;`_.</span></div>
<div class="line"><span class="lineno"> 1547</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1548</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1549</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1550</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno"> 1551</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import precision_recall_fscore_support</span></div>
<div class="line"><span class="lineno"> 1552</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([&#39;cat&#39;, &#39;dog&#39;, &#39;pig&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;pig&#39;])</span></div>
<div class="line"><span class="lineno"> 1553</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = np.array([&#39;cat&#39;, &#39;pig&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;cat&#39;, &#39;dog&#39;])</span></div>
<div class="line"><span class="lineno"> 1554</span><span class="stringliteral">    &gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average=&#39;macro&#39;)</span></div>
<div class="line"><span class="lineno"> 1555</span><span class="stringliteral">    (0.22..., 0.33..., 0.26..., None)</span></div>
<div class="line"><span class="lineno"> 1556</span><span class="stringliteral">    &gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average=&#39;micro&#39;)</span></div>
<div class="line"><span class="lineno"> 1557</span><span class="stringliteral">    (0.33..., 0.33..., 0.33..., None)</span></div>
<div class="line"><span class="lineno"> 1558</span><span class="stringliteral">    &gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average=&#39;weighted&#39;)</span></div>
<div class="line"><span class="lineno"> 1559</span><span class="stringliteral">    (0.22..., 0.33..., 0.26..., None)</span></div>
<div class="line"><span class="lineno"> 1560</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1561</span><span class="stringliteral">    It is possible to compute per-label precisions, recalls, F1-scores and</span></div>
<div class="line"><span class="lineno"> 1562</span><span class="stringliteral">    supports instead of averaging:</span></div>
<div class="line"><span class="lineno"> 1563</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1564</span><span class="stringliteral">    &gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average=None,</span></div>
<div class="line"><span class="lineno"> 1565</span><span class="stringliteral">    ... labels=[&#39;pig&#39;, &#39;dog&#39;, &#39;cat&#39;])</span></div>
<div class="line"><span class="lineno"> 1566</span><span class="stringliteral">    (array([0.        , 0.        , 0.66...]),</span></div>
<div class="line"><span class="lineno"> 1567</span><span class="stringliteral">     array([0., 0., 1.]), array([0. , 0. , 0.8]),</span></div>
<div class="line"><span class="lineno"> 1568</span><span class="stringliteral">     array([2, 2, 2]))</span></div>
<div class="line"><span class="lineno"> 1569</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1570</span>    _check_zero_division(zero_division)</div>
<div class="line"><span class="lineno"> 1571</span>    <span class="keywordflow">if</span> beta &lt; 0:</div>
<div class="line"><span class="lineno"> 1572</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;beta should be &gt;=0 in the F-beta score&quot;</span>)</div>
<div class="line"><span class="lineno"> 1573</span>    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)</div>
<div class="line"><span class="lineno"> 1574</span> </div>
<div class="line"><span class="lineno"> 1575</span>    <span class="comment"># Calculate tp_sum, pred_sum, true_sum ###</span></div>
<div class="line"><span class="lineno"> 1576</span>    samplewise = average == <span class="stringliteral">&quot;samples&quot;</span></div>
<div class="line"><span class="lineno"> 1577</span>    MCM = multilabel_confusion_matrix(</div>
<div class="line"><span class="lineno"> 1578</span>        y_true,</div>
<div class="line"><span class="lineno"> 1579</span>        y_pred,</div>
<div class="line"><span class="lineno"> 1580</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno"> 1581</span>        labels=labels,</div>
<div class="line"><span class="lineno"> 1582</span>        samplewise=samplewise,</div>
<div class="line"><span class="lineno"> 1583</span>    )</div>
<div class="line"><span class="lineno"> 1584</span>    tp_sum = MCM[:, 1, 1]</div>
<div class="line"><span class="lineno"> 1585</span>    pred_sum = tp_sum + MCM[:, 0, 1]</div>
<div class="line"><span class="lineno"> 1586</span>    true_sum = tp_sum + MCM[:, 1, 0]</div>
<div class="line"><span class="lineno"> 1587</span> </div>
<div class="line"><span class="lineno"> 1588</span>    <span class="keywordflow">if</span> average == <span class="stringliteral">&quot;micro&quot;</span>:</div>
<div class="line"><span class="lineno"> 1589</span>        tp_sum = np.array([tp_sum.sum()])</div>
<div class="line"><span class="lineno"> 1590</span>        pred_sum = np.array([pred_sum.sum()])</div>
<div class="line"><span class="lineno"> 1591</span>        true_sum = np.array([true_sum.sum()])</div>
<div class="line"><span class="lineno"> 1592</span> </div>
<div class="line"><span class="lineno"> 1593</span>    <span class="comment"># Finally, we have all our sufficient statistics. Divide! #</span></div>
<div class="line"><span class="lineno"> 1594</span>    beta2 = beta**2</div>
<div class="line"><span class="lineno"> 1595</span> </div>
<div class="line"><span class="lineno"> 1596</span>    <span class="comment"># Divide, and on zero-division, set scores and/or warn according to</span></div>
<div class="line"><span class="lineno"> 1597</span>    <span class="comment"># zero_division:</span></div>
<div class="line"><span class="lineno"> 1598</span>    precision = _prf_divide(</div>
<div class="line"><span class="lineno"> 1599</span>        tp_sum, pred_sum, <span class="stringliteral">&quot;precision&quot;</span>, <span class="stringliteral">&quot;predicted&quot;</span>, average, warn_for, zero_division</div>
<div class="line"><span class="lineno"> 1600</span>    )</div>
<div class="line"><span class="lineno"> 1601</span>    recall = _prf_divide(</div>
<div class="line"><span class="lineno"> 1602</span>        tp_sum, true_sum, <span class="stringliteral">&quot;recall&quot;</span>, <span class="stringliteral">&quot;true&quot;</span>, average, warn_for, zero_division</div>
<div class="line"><span class="lineno"> 1603</span>    )</div>
<div class="line"><span class="lineno"> 1604</span> </div>
<div class="line"><span class="lineno"> 1605</span>    <span class="comment"># warn for f-score only if zero_division is warn, it is in warn_for</span></div>
<div class="line"><span class="lineno"> 1606</span>    <span class="comment"># and BOTH prec and rec are ill-defined</span></div>
<div class="line"><span class="lineno"> 1607</span>    <span class="keywordflow">if</span> zero_division == <span class="stringliteral">&quot;warn&quot;</span> <span class="keywordflow">and</span> (<span class="stringliteral">&quot;f-score&quot;</span>,) == warn_for:</div>
<div class="line"><span class="lineno"> 1608</span>        <span class="keywordflow">if</span> (pred_sum[true_sum == 0] == 0).any():</div>
<div class="line"><span class="lineno"> 1609</span>            _warn_prf(average, <span class="stringliteral">&quot;true nor predicted&quot;</span>, <span class="stringliteral">&quot;F-score is&quot;</span>, len(true_sum))</div>
<div class="line"><span class="lineno"> 1610</span> </div>
<div class="line"><span class="lineno"> 1611</span>    <span class="comment"># if tp == 0 F will be 1 only if all predictions are zero, all labels are</span></div>
<div class="line"><span class="lineno"> 1612</span>    <span class="comment"># zero, and zero_division=1. In all other case, 0</span></div>
<div class="line"><span class="lineno"> 1613</span>    <span class="keywordflow">if</span> np.isposinf(beta):</div>
<div class="line"><span class="lineno"> 1614</span>        f_score = recall</div>
<div class="line"><span class="lineno"> 1615</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1616</span>        denom = beta2 * precision + recall</div>
<div class="line"><span class="lineno"> 1617</span> </div>
<div class="line"><span class="lineno"> 1618</span>        denom[denom == 0.0] = 1  <span class="comment"># avoid division by 0</span></div>
<div class="line"><span class="lineno"> 1619</span>        f_score = (1 + beta2) * precision * recall / denom</div>
<div class="line"><span class="lineno"> 1620</span> </div>
<div class="line"><span class="lineno"> 1621</span>    <span class="comment"># Average the results</span></div>
<div class="line"><span class="lineno"> 1622</span>    <span class="keywordflow">if</span> average == <span class="stringliteral">&quot;weighted&quot;</span>:</div>
<div class="line"><span class="lineno"> 1623</span>        weights = true_sum</div>
<div class="line"><span class="lineno"> 1624</span>        <span class="keywordflow">if</span> weights.sum() == 0:</div>
<div class="line"><span class="lineno"> 1625</span>            zero_division_value = np.float64(1.0)</div>
<div class="line"><span class="lineno"> 1626</span>            <span class="keywordflow">if</span> zero_division <span class="keywordflow">in</span> [<span class="stringliteral">&quot;warn&quot;</span>, 0]:</div>
<div class="line"><span class="lineno"> 1627</span>                zero_division_value = np.float64(0.0)</div>
<div class="line"><span class="lineno"> 1628</span>            <span class="comment"># precision is zero_division if there are no positive predictions</span></div>
<div class="line"><span class="lineno"> 1629</span>            <span class="comment"># recall is zero_division if there are no positive labels</span></div>
<div class="line"><span class="lineno"> 1630</span>            <span class="comment"># fscore is zero_division if all labels AND predictions are</span></div>
<div class="line"><span class="lineno"> 1631</span>            <span class="comment"># negative</span></div>
<div class="line"><span class="lineno"> 1632</span>            <span class="keywordflow">if</span> pred_sum.sum() == 0:</div>
<div class="line"><span class="lineno"> 1633</span>                <span class="keywordflow">return</span> (</div>
<div class="line"><span class="lineno"> 1634</span>                    zero_division_value,</div>
<div class="line"><span class="lineno"> 1635</span>                    zero_division_value,</div>
<div class="line"><span class="lineno"> 1636</span>                    zero_division_value,</div>
<div class="line"><span class="lineno"> 1637</span>                    <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno"> 1638</span>                )</div>
<div class="line"><span class="lineno"> 1639</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1640</span>                <span class="keywordflow">return</span> (np.float64(0.0), zero_division_value, np.float64(0.0), <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno"> 1641</span> </div>
<div class="line"><span class="lineno"> 1642</span>    <span class="keywordflow">elif</span> average == <span class="stringliteral">&quot;samples&quot;</span>:</div>
<div class="line"><span class="lineno"> 1643</span>        weights = sample_weight</div>
<div class="line"><span class="lineno"> 1644</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1645</span>        weights = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1646</span> </div>
<div class="line"><span class="lineno"> 1647</span>    <span class="keywordflow">if</span> average <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1648</span>        <span class="keyword">assert</span> average != <span class="stringliteral">&quot;binary&quot;</span> <span class="keywordflow">or</span> len(precision) == 1</div>
<div class="line"><span class="lineno"> 1649</span>        precision = np.average(precision, weights=weights)</div>
<div class="line"><span class="lineno"> 1650</span>        recall = np.average(recall, weights=weights)</div>
<div class="line"><span class="lineno"> 1651</span>        f_score = np.average(f_score, weights=weights)</div>
<div class="line"><span class="lineno"> 1652</span>        true_sum = <span class="keywordtype">None</span>  <span class="comment"># return no support</span></div>
<div class="line"><span class="lineno"> 1653</span> </div>
<div class="line"><span class="lineno"> 1654</span>    <span class="keywordflow">return</span> precision, recall, f_score, true_sum</div>
<div class="line"><span class="lineno"> 1655</span> </div>
<div class="line"><span class="lineno"> 1656</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aae96317cbd7ecabc2f028cf89a82f048" name="aae96317cbd7ecabc2f028cf89a82f048"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae96317cbd7ecabc2f028cf89a82f048">&#9670;&#160;</a></span>precision_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.precision_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average</em> = <code>&quot;binary&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zero_division</em> = <code>&quot;warn&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the precision.

The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of
true positives and ``fp`` the number of false positives. The precision is
intuitively the ability of the classifier not to label as positive a sample
that is negative.

The best value is 1 and the worst value is 0.

Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) target values.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Estimated targets as returned by a classifier.

labels : array-like, default=None
    The set of labels to include when ``average != 'binary'``, and their
    order if ``average is None``. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in ``y_true`` and
    ``y_pred`` are used in sorted order.

    .. versionchanged:: 0.17
       Parameter `labels` improved for multiclass problem.

pos_label : str or int, default=1
    The class to report if ``average='binary'`` and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting ``labels=[pos_label]`` and ``average != 'binary'`` will report
    scores for that label only.

average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None, \
        default='binary'
    This parameter is required for multiclass/multilabel targets.
    If ``None``, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:

    ``'binary'``:
        Only report results for the class specified by ``pos_label``.
        This is applicable only if targets (``y_{true,pred}``) are binary.
    ``'micro'``:
        Calculate metrics globally by counting the total true positives,
        false negatives and false positives.
    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    ``'weighted'``:
        Calculate metrics for each label, and find their average weighted
        by support (the number of true instances for each label). This
        alters 'macro' to account for label imbalance; it can result in an
        F-score that is not between precision and recall.
    ``'samples'``:
        Calculate metrics for each instance, and find their average (only
        meaningful for multilabel classification where this differs from
        :func:`accuracy_score`).

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

zero_division : "warn", 0 or 1, default="warn"
    Sets the value to return when there is a zero division. If set to
    "warn", this acts as 0, but warnings are also raised.

Returns
-------
precision : float (if average is not None) or array of float of shape \
            (n_unique_labels,)
    Precision of the positive class in binary classification or weighted
    average of the precision of each class for the multiclass task.

See Also
--------
precision_recall_fscore_support : Compute precision, recall, F-measure and
    support for each class.
recall_score :  Compute the ratio ``tp / (tp + fn)`` where ``tp`` is the
    number of true positives and ``fn`` the number of false negatives.
PrecisionRecallDisplay.from_estimator : Plot precision-recall curve given
    an estimator and some data.
PrecisionRecallDisplay.from_predictions : Plot precision-recall curve given
    binary class predictions.
multilabel_confusion_matrix : Compute a confusion matrix for each class or
    sample.

Notes
-----
When ``true positive + false positive == 0``, precision returns 0 and
raises ``UndefinedMetricWarning``. This behavior can be
modified with ``zero_division``.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import precision_score
&gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]
&gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]
&gt;&gt;&gt; precision_score(y_true, y_pred, average='macro')
0.22...
&gt;&gt;&gt; precision_score(y_true, y_pred, average='micro')
0.33...
&gt;&gt;&gt; precision_score(y_true, y_pred, average='weighted')
0.22...
&gt;&gt;&gt; precision_score(y_true, y_pred, average=None)
array([0.66..., 0.        , 0.        ])
&gt;&gt;&gt; y_pred = [0, 0, 0, 0, 0, 0]
&gt;&gt;&gt; precision_score(y_true, y_pred, average=None)
array([0.33..., 0.        , 0.        ])
&gt;&gt;&gt; precision_score(y_true, y_pred, average=None, zero_division=1)
array([0.33..., 1.        , 1.        ])
&gt;&gt;&gt; # multilabel classification
&gt;&gt;&gt; y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]
&gt;&gt;&gt; y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]
&gt;&gt;&gt; precision_score(y_true, y_pred, average=None)
array([0.5, 1. , 1. ])
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1834</span>):</div>
<div class="line"><span class="lineno"> 1835</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the precision.</span></div>
<div class="line"><span class="lineno"> 1836</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1837</span><span class="stringliteral">    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of</span></div>
<div class="line"><span class="lineno"> 1838</span><span class="stringliteral">    true positives and ``fp`` the number of false positives. The precision is</span></div>
<div class="line"><span class="lineno"> 1839</span><span class="stringliteral">    intuitively the ability of the classifier not to label as positive a sample</span></div>
<div class="line"><span class="lineno"> 1840</span><span class="stringliteral">    that is negative.</span></div>
<div class="line"><span class="lineno"> 1841</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1842</span><span class="stringliteral">    The best value is 1 and the worst value is 0.</span></div>
<div class="line"><span class="lineno"> 1843</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1844</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span></div>
<div class="line"><span class="lineno"> 1845</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1846</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1847</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1848</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1849</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 1850</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1851</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1852</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno"> 1853</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1854</span><span class="stringliteral">    labels : array-like, default=None</span></div>
<div class="line"><span class="lineno"> 1855</span><span class="stringliteral">        The set of labels to include when ``average != &#39;binary&#39;``, and their</span></div>
<div class="line"><span class="lineno"> 1856</span><span class="stringliteral">        order if ``average is None``. Labels present in the data can be</span></div>
<div class="line"><span class="lineno"> 1857</span><span class="stringliteral">        excluded, for example to calculate a multiclass average ignoring a</span></div>
<div class="line"><span class="lineno"> 1858</span><span class="stringliteral">        majority negative class, while labels not present in the data will</span></div>
<div class="line"><span class="lineno"> 1859</span><span class="stringliteral">        result in 0 components in a macro average. For multilabel targets,</span></div>
<div class="line"><span class="lineno"> 1860</span><span class="stringliteral">        labels are column indices. By default, all labels in ``y_true`` and</span></div>
<div class="line"><span class="lineno"> 1861</span><span class="stringliteral">        ``y_pred`` are used in sorted order.</span></div>
<div class="line"><span class="lineno"> 1862</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1863</span><span class="stringliteral">        .. versionchanged:: 0.17</span></div>
<div class="line"><span class="lineno"> 1864</span><span class="stringliteral">           Parameter `labels` improved for multiclass problem.</span></div>
<div class="line"><span class="lineno"> 1865</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1866</span><span class="stringliteral">    pos_label : str or int, default=1</span></div>
<div class="line"><span class="lineno"> 1867</span><span class="stringliteral">        The class to report if ``average=&#39;binary&#39;`` and the data is binary.</span></div>
<div class="line"><span class="lineno"> 1868</span><span class="stringliteral">        If the data are multiclass or multilabel, this will be ignored;</span></div>
<div class="line"><span class="lineno"> 1869</span><span class="stringliteral">        setting ``labels=[pos_label]`` and ``average != &#39;binary&#39;`` will report</span></div>
<div class="line"><span class="lineno"> 1870</span><span class="stringliteral">        scores for that label only.</span></div>
<div class="line"><span class="lineno"> 1871</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1872</span><span class="stringliteral">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;, &#39;binary&#39;} or None, \</span></div>
<div class="line"><span class="lineno"> 1873</span><span class="stringliteral">            default=&#39;binary&#39;</span></div>
<div class="line"><span class="lineno"> 1874</span><span class="stringliteral">        This parameter is required for multiclass/multilabel targets.</span></div>
<div class="line"><span class="lineno"> 1875</span><span class="stringliteral">        If ``None``, the scores for each class are returned. Otherwise, this</span></div>
<div class="line"><span class="lineno"> 1876</span><span class="stringliteral">        determines the type of averaging performed on the data:</span></div>
<div class="line"><span class="lineno"> 1877</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1878</span><span class="stringliteral">        ``&#39;binary&#39;``:</span></div>
<div class="line"><span class="lineno"> 1879</span><span class="stringliteral">            Only report results for the class specified by ``pos_label``.</span></div>
<div class="line"><span class="lineno"> 1880</span><span class="stringliteral">            This is applicable only if targets (``y_{true,pred}``) are binary.</span></div>
<div class="line"><span class="lineno"> 1881</span><span class="stringliteral">        ``&#39;micro&#39;``:</span></div>
<div class="line"><span class="lineno"> 1882</span><span class="stringliteral">            Calculate metrics globally by counting the total true positives,</span></div>
<div class="line"><span class="lineno"> 1883</span><span class="stringliteral">            false negatives and false positives.</span></div>
<div class="line"><span class="lineno"> 1884</span><span class="stringliteral">        ``&#39;macro&#39;``:</span></div>
<div class="line"><span class="lineno"> 1885</span><span class="stringliteral">            Calculate metrics for each label, and find their unweighted</span></div>
<div class="line"><span class="lineno"> 1886</span><span class="stringliteral">            mean.  This does not take label imbalance into account.</span></div>
<div class="line"><span class="lineno"> 1887</span><span class="stringliteral">        ``&#39;weighted&#39;``:</span></div>
<div class="line"><span class="lineno"> 1888</span><span class="stringliteral">            Calculate metrics for each label, and find their average weighted</span></div>
<div class="line"><span class="lineno"> 1889</span><span class="stringliteral">            by support (the number of true instances for each label). This</span></div>
<div class="line"><span class="lineno"> 1890</span><span class="stringliteral">            alters &#39;macro&#39; to account for label imbalance; it can result in an</span></div>
<div class="line"><span class="lineno"> 1891</span><span class="stringliteral">            F-score that is not between precision and recall.</span></div>
<div class="line"><span class="lineno"> 1892</span><span class="stringliteral">        ``&#39;samples&#39;``:</span></div>
<div class="line"><span class="lineno"> 1893</span><span class="stringliteral">            Calculate metrics for each instance, and find their average (only</span></div>
<div class="line"><span class="lineno"> 1894</span><span class="stringliteral">            meaningful for multilabel classification where this differs from</span></div>
<div class="line"><span class="lineno"> 1895</span><span class="stringliteral">            :func:`accuracy_score`).</span></div>
<div class="line"><span class="lineno"> 1896</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1897</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1898</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1899</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1900</span><span class="stringliteral">    zero_division : &quot;warn&quot;, 0 or 1, default=&quot;warn&quot;</span></div>
<div class="line"><span class="lineno"> 1901</span><span class="stringliteral">        Sets the value to return when there is a zero division. If set to</span></div>
<div class="line"><span class="lineno"> 1902</span><span class="stringliteral">        &quot;warn&quot;, this acts as 0, but warnings are also raised.</span></div>
<div class="line"><span class="lineno"> 1903</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1904</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1905</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1906</span><span class="stringliteral">    precision : float (if average is not None) or array of float of shape \</span></div>
<div class="line"><span class="lineno"> 1907</span><span class="stringliteral">                (n_unique_labels,)</span></div>
<div class="line"><span class="lineno"> 1908</span><span class="stringliteral">        Precision of the positive class in binary classification or weighted</span></div>
<div class="line"><span class="lineno"> 1909</span><span class="stringliteral">        average of the precision of each class for the multiclass task.</span></div>
<div class="line"><span class="lineno"> 1910</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1911</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 1912</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1913</span><span class="stringliteral">    precision_recall_fscore_support : Compute precision, recall, F-measure and</span></div>
<div class="line"><span class="lineno"> 1914</span><span class="stringliteral">        support for each class.</span></div>
<div class="line"><span class="lineno"> 1915</span><span class="stringliteral">    recall_score :  Compute the ratio ``tp / (tp + fn)`` where ``tp`` is the</span></div>
<div class="line"><span class="lineno"> 1916</span><span class="stringliteral">        number of true positives and ``fn`` the number of false negatives.</span></div>
<div class="line"><span class="lineno"> 1917</span><span class="stringliteral">    PrecisionRecallDisplay.from_estimator : Plot precision-recall curve given</span></div>
<div class="line"><span class="lineno"> 1918</span><span class="stringliteral">        an estimator and some data.</span></div>
<div class="line"><span class="lineno"> 1919</span><span class="stringliteral">    PrecisionRecallDisplay.from_predictions : Plot precision-recall curve given</span></div>
<div class="line"><span class="lineno"> 1920</span><span class="stringliteral">        binary class predictions.</span></div>
<div class="line"><span class="lineno"> 1921</span><span class="stringliteral">    multilabel_confusion_matrix : Compute a confusion matrix for each class or</span></div>
<div class="line"><span class="lineno"> 1922</span><span class="stringliteral">        sample.</span></div>
<div class="line"><span class="lineno"> 1923</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1924</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1925</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1926</span><span class="stringliteral">    When ``true positive + false positive == 0``, precision returns 0 and</span></div>
<div class="line"><span class="lineno"> 1927</span><span class="stringliteral">    raises ``UndefinedMetricWarning``. This behavior can be</span></div>
<div class="line"><span class="lineno"> 1928</span><span class="stringliteral">    modified with ``zero_division``.</span></div>
<div class="line"><span class="lineno"> 1929</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1930</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1931</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1932</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import precision_score</span></div>
<div class="line"><span class="lineno"> 1933</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]</span></div>
<div class="line"><span class="lineno"> 1934</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]</span></div>
<div class="line"><span class="lineno"> 1935</span><span class="stringliteral">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=&#39;macro&#39;)</span></div>
<div class="line"><span class="lineno"> 1936</span><span class="stringliteral">    0.22...</span></div>
<div class="line"><span class="lineno"> 1937</span><span class="stringliteral">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=&#39;micro&#39;)</span></div>
<div class="line"><span class="lineno"> 1938</span><span class="stringliteral">    0.33...</span></div>
<div class="line"><span class="lineno"> 1939</span><span class="stringliteral">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=&#39;weighted&#39;)</span></div>
<div class="line"><span class="lineno"> 1940</span><span class="stringliteral">    0.22...</span></div>
<div class="line"><span class="lineno"> 1941</span><span class="stringliteral">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=None)</span></div>
<div class="line"><span class="lineno"> 1942</span><span class="stringliteral">    array([0.66..., 0.        , 0.        ])</span></div>
<div class="line"><span class="lineno"> 1943</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 0, 0, 0, 0, 0]</span></div>
<div class="line"><span class="lineno"> 1944</span><span class="stringliteral">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=None)</span></div>
<div class="line"><span class="lineno"> 1945</span><span class="stringliteral">    array([0.33..., 0.        , 0.        ])</span></div>
<div class="line"><span class="lineno"> 1946</span><span class="stringliteral">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=None, zero_division=1)</span></div>
<div class="line"><span class="lineno"> 1947</span><span class="stringliteral">    array([0.33..., 1.        , 1.        ])</span></div>
<div class="line"><span class="lineno"> 1948</span><span class="stringliteral">    &gt;&gt;&gt; # multilabel classification</span></div>
<div class="line"><span class="lineno"> 1949</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]</span></div>
<div class="line"><span class="lineno"> 1950</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]</span></div>
<div class="line"><span class="lineno"> 1951</span><span class="stringliteral">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=None)</span></div>
<div class="line"><span class="lineno"> 1952</span><span class="stringliteral">    array([0.5, 1. , 1. ])</span></div>
<div class="line"><span class="lineno"> 1953</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1954</span>    p, _, _, _ = precision_recall_fscore_support(</div>
<div class="line"><span class="lineno"> 1955</span>        y_true,</div>
<div class="line"><span class="lineno"> 1956</span>        y_pred,</div>
<div class="line"><span class="lineno"> 1957</span>        labels=labels,</div>
<div class="line"><span class="lineno"> 1958</span>        pos_label=pos_label,</div>
<div class="line"><span class="lineno"> 1959</span>        average=average,</div>
<div class="line"><span class="lineno"> 1960</span>        warn_for=(<span class="stringliteral">&quot;precision&quot;</span>,),</div>
<div class="line"><span class="lineno"> 1961</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno"> 1962</span>        zero_division=zero_division,</div>
<div class="line"><span class="lineno"> 1963</span>    )</div>
<div class="line"><span class="lineno"> 1964</span>    <span class="keywordflow">return</span> p</div>
<div class="line"><span class="lineno"> 1965</span> </div>
<div class="line"><span class="lineno"> 1966</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab2ee2077fbf603931b794ddf7e84c641" name="ab2ee2077fbf603931b794ddf7e84c641"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab2ee2077fbf603931b794ddf7e84c641">&#9670;&#160;</a></span>recall_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.recall_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average</em> = <code>&quot;binary&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zero_division</em> = <code>&quot;warn&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the recall.

The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of
true positives and ``fn`` the number of false negatives. The recall is
intuitively the ability of the classifier to find all the positive samples.

The best value is 1 and the worst value is 0.

Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) target values.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Estimated targets as returned by a classifier.

labels : array-like, default=None
    The set of labels to include when ``average != 'binary'``, and their
    order if ``average is None``. Labels present in the data can be
    excluded, for example to calculate a multiclass average ignoring a
    majority negative class, while labels not present in the data will
    result in 0 components in a macro average. For multilabel targets,
    labels are column indices. By default, all labels in ``y_true`` and
    ``y_pred`` are used in sorted order.

    .. versionchanged:: 0.17
       Parameter `labels` improved for multiclass problem.

pos_label : str or int, default=1
    The class to report if ``average='binary'`` and the data is binary.
    If the data are multiclass or multilabel, this will be ignored;
    setting ``labels=[pos_label]`` and ``average != 'binary'`` will report
    scores for that label only.

average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None, \
        default='binary'
    This parameter is required for multiclass/multilabel targets.
    If ``None``, the scores for each class are returned. Otherwise, this
    determines the type of averaging performed on the data:

    ``'binary'``:
        Only report results for the class specified by ``pos_label``.
        This is applicable only if targets (``y_{true,pred}``) are binary.
    ``'micro'``:
        Calculate metrics globally by counting the total true positives,
        false negatives and false positives.
    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    ``'weighted'``:
        Calculate metrics for each label, and find their average weighted
        by support (the number of true instances for each label). This
        alters 'macro' to account for label imbalance; it can result in an
        F-score that is not between precision and recall. Weighted recall
        is equal to accuracy.
    ``'samples'``:
        Calculate metrics for each instance, and find their average (only
        meaningful for multilabel classification where this differs from
        :func:`accuracy_score`).

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

zero_division : "warn", 0 or 1, default="warn"
    Sets the value to return when there is a zero division. If set to
    "warn", this acts as 0, but warnings are also raised.

Returns
-------
recall : float (if average is not None) or array of float of shape \
         (n_unique_labels,)
    Recall of the positive class in binary classification or weighted
    average of the recall of each class for the multiclass task.

See Also
--------
precision_recall_fscore_support : Compute precision, recall, F-measure and
    support for each class.
precision_score : Compute the ratio ``tp / (tp + fp)`` where ``tp`` is the
    number of true positives and ``fp`` the number of false positives.
balanced_accuracy_score : Compute balanced accuracy to deal with imbalanced
    datasets.
multilabel_confusion_matrix : Compute a confusion matrix for each class or
    sample.
PrecisionRecallDisplay.from_estimator : Plot precision-recall curve given
    an estimator and some data.
PrecisionRecallDisplay.from_predictions : Plot precision-recall curve given
    binary class predictions.

Notes
-----
When ``true positive + false negative == 0``, recall returns 0 and raises
``UndefinedMetricWarning``. This behavior can be modified with
``zero_division``.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import recall_score
&gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]
&gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]
&gt;&gt;&gt; recall_score(y_true, y_pred, average='macro')
0.33...
&gt;&gt;&gt; recall_score(y_true, y_pred, average='micro')
0.33...
&gt;&gt;&gt; recall_score(y_true, y_pred, average='weighted')
0.33...
&gt;&gt;&gt; recall_score(y_true, y_pred, average=None)
array([1., 0., 0.])
&gt;&gt;&gt; y_true = [0, 0, 0, 0, 0, 0]
&gt;&gt;&gt; recall_score(y_true, y_pred, average=None)
array([0.5, 0. , 0. ])
&gt;&gt;&gt; recall_score(y_true, y_pred, average=None, zero_division=1)
array([0.5, 1. , 1. ])
&gt;&gt;&gt; # multilabel classification
&gt;&gt;&gt; y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]
&gt;&gt;&gt; y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]
&gt;&gt;&gt; recall_score(y_true, y_pred, average=None)
array([1. , 1. , 0.5])
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1976</span>):</div>
<div class="line"><span class="lineno"> 1977</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the recall.</span></div>
<div class="line"><span class="lineno"> 1978</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1979</span><span class="stringliteral">    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of</span></div>
<div class="line"><span class="lineno"> 1980</span><span class="stringliteral">    true positives and ``fn`` the number of false negatives. The recall is</span></div>
<div class="line"><span class="lineno"> 1981</span><span class="stringliteral">    intuitively the ability of the classifier to find all the positive samples.</span></div>
<div class="line"><span class="lineno"> 1982</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1983</span><span class="stringliteral">    The best value is 1 and the worst value is 0.</span></div>
<div class="line"><span class="lineno"> 1984</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1985</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span></div>
<div class="line"><span class="lineno"> 1986</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1987</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1988</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1989</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1990</span><span class="stringliteral">        Ground truth (correct) target values.</span></div>
<div class="line"><span class="lineno"> 1991</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1992</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno"> 1993</span><span class="stringliteral">        Estimated targets as returned by a classifier.</span></div>
<div class="line"><span class="lineno"> 1994</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1995</span><span class="stringliteral">    labels : array-like, default=None</span></div>
<div class="line"><span class="lineno"> 1996</span><span class="stringliteral">        The set of labels to include when ``average != &#39;binary&#39;``, and their</span></div>
<div class="line"><span class="lineno"> 1997</span><span class="stringliteral">        order if ``average is None``. Labels present in the data can be</span></div>
<div class="line"><span class="lineno"> 1998</span><span class="stringliteral">        excluded, for example to calculate a multiclass average ignoring a</span></div>
<div class="line"><span class="lineno"> 1999</span><span class="stringliteral">        majority negative class, while labels not present in the data will</span></div>
<div class="line"><span class="lineno"> 2000</span><span class="stringliteral">        result in 0 components in a macro average. For multilabel targets,</span></div>
<div class="line"><span class="lineno"> 2001</span><span class="stringliteral">        labels are column indices. By default, all labels in ``y_true`` and</span></div>
<div class="line"><span class="lineno"> 2002</span><span class="stringliteral">        ``y_pred`` are used in sorted order.</span></div>
<div class="line"><span class="lineno"> 2003</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2004</span><span class="stringliteral">        .. versionchanged:: 0.17</span></div>
<div class="line"><span class="lineno"> 2005</span><span class="stringliteral">           Parameter `labels` improved for multiclass problem.</span></div>
<div class="line"><span class="lineno"> 2006</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2007</span><span class="stringliteral">    pos_label : str or int, default=1</span></div>
<div class="line"><span class="lineno"> 2008</span><span class="stringliteral">        The class to report if ``average=&#39;binary&#39;`` and the data is binary.</span></div>
<div class="line"><span class="lineno"> 2009</span><span class="stringliteral">        If the data are multiclass or multilabel, this will be ignored;</span></div>
<div class="line"><span class="lineno"> 2010</span><span class="stringliteral">        setting ``labels=[pos_label]`` and ``average != &#39;binary&#39;`` will report</span></div>
<div class="line"><span class="lineno"> 2011</span><span class="stringliteral">        scores for that label only.</span></div>
<div class="line"><span class="lineno"> 2012</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2013</span><span class="stringliteral">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;, &#39;binary&#39;} or None, \</span></div>
<div class="line"><span class="lineno"> 2014</span><span class="stringliteral">            default=&#39;binary&#39;</span></div>
<div class="line"><span class="lineno"> 2015</span><span class="stringliteral">        This parameter is required for multiclass/multilabel targets.</span></div>
<div class="line"><span class="lineno"> 2016</span><span class="stringliteral">        If ``None``, the scores for each class are returned. Otherwise, this</span></div>
<div class="line"><span class="lineno"> 2017</span><span class="stringliteral">        determines the type of averaging performed on the data:</span></div>
<div class="line"><span class="lineno"> 2018</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2019</span><span class="stringliteral">        ``&#39;binary&#39;``:</span></div>
<div class="line"><span class="lineno"> 2020</span><span class="stringliteral">            Only report results for the class specified by ``pos_label``.</span></div>
<div class="line"><span class="lineno"> 2021</span><span class="stringliteral">            This is applicable only if targets (``y_{true,pred}``) are binary.</span></div>
<div class="line"><span class="lineno"> 2022</span><span class="stringliteral">        ``&#39;micro&#39;``:</span></div>
<div class="line"><span class="lineno"> 2023</span><span class="stringliteral">            Calculate metrics globally by counting the total true positives,</span></div>
<div class="line"><span class="lineno"> 2024</span><span class="stringliteral">            false negatives and false positives.</span></div>
<div class="line"><span class="lineno"> 2025</span><span class="stringliteral">        ``&#39;macro&#39;``:</span></div>
<div class="line"><span class="lineno"> 2026</span><span class="stringliteral">            Calculate metrics for each label, and find their unweighted</span></div>
<div class="line"><span class="lineno"> 2027</span><span class="stringliteral">            mean.  This does not take label imbalance into account.</span></div>
<div class="line"><span class="lineno"> 2028</span><span class="stringliteral">        ``&#39;weighted&#39;``:</span></div>
<div class="line"><span class="lineno"> 2029</span><span class="stringliteral">            Calculate metrics for each label, and find their average weighted</span></div>
<div class="line"><span class="lineno"> 2030</span><span class="stringliteral">            by support (the number of true instances for each label). This</span></div>
<div class="line"><span class="lineno"> 2031</span><span class="stringliteral">            alters &#39;macro&#39; to account for label imbalance; it can result in an</span></div>
<div class="line"><span class="lineno"> 2032</span><span class="stringliteral">            F-score that is not between precision and recall. Weighted recall</span></div>
<div class="line"><span class="lineno"> 2033</span><span class="stringliteral">            is equal to accuracy.</span></div>
<div class="line"><span class="lineno"> 2034</span><span class="stringliteral">        ``&#39;samples&#39;``:</span></div>
<div class="line"><span class="lineno"> 2035</span><span class="stringliteral">            Calculate metrics for each instance, and find their average (only</span></div>
<div class="line"><span class="lineno"> 2036</span><span class="stringliteral">            meaningful for multilabel classification where this differs from</span></div>
<div class="line"><span class="lineno"> 2037</span><span class="stringliteral">            :func:`accuracy_score`).</span></div>
<div class="line"><span class="lineno"> 2038</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2039</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 2040</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 2041</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2042</span><span class="stringliteral">    zero_division : &quot;warn&quot;, 0 or 1, default=&quot;warn&quot;</span></div>
<div class="line"><span class="lineno"> 2043</span><span class="stringliteral">        Sets the value to return when there is a zero division. If set to</span></div>
<div class="line"><span class="lineno"> 2044</span><span class="stringliteral">        &quot;warn&quot;, this acts as 0, but warnings are also raised.</span></div>
<div class="line"><span class="lineno"> 2045</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2046</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 2047</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 2048</span><span class="stringliteral">    recall : float (if average is not None) or array of float of shape \</span></div>
<div class="line"><span class="lineno"> 2049</span><span class="stringliteral">             (n_unique_labels,)</span></div>
<div class="line"><span class="lineno"> 2050</span><span class="stringliteral">        Recall of the positive class in binary classification or weighted</span></div>
<div class="line"><span class="lineno"> 2051</span><span class="stringliteral">        average of the recall of each class for the multiclass task.</span></div>
<div class="line"><span class="lineno"> 2052</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2053</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 2054</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2055</span><span class="stringliteral">    precision_recall_fscore_support : Compute precision, recall, F-measure and</span></div>
<div class="line"><span class="lineno"> 2056</span><span class="stringliteral">        support for each class.</span></div>
<div class="line"><span class="lineno"> 2057</span><span class="stringliteral">    precision_score : Compute the ratio ``tp / (tp + fp)`` where ``tp`` is the</span></div>
<div class="line"><span class="lineno"> 2058</span><span class="stringliteral">        number of true positives and ``fp`` the number of false positives.</span></div>
<div class="line"><span class="lineno"> 2059</span><span class="stringliteral">    balanced_accuracy_score : Compute balanced accuracy to deal with imbalanced</span></div>
<div class="line"><span class="lineno"> 2060</span><span class="stringliteral">        datasets.</span></div>
<div class="line"><span class="lineno"> 2061</span><span class="stringliteral">    multilabel_confusion_matrix : Compute a confusion matrix for each class or</span></div>
<div class="line"><span class="lineno"> 2062</span><span class="stringliteral">        sample.</span></div>
<div class="line"><span class="lineno"> 2063</span><span class="stringliteral">    PrecisionRecallDisplay.from_estimator : Plot precision-recall curve given</span></div>
<div class="line"><span class="lineno"> 2064</span><span class="stringliteral">        an estimator and some data.</span></div>
<div class="line"><span class="lineno"> 2065</span><span class="stringliteral">    PrecisionRecallDisplay.from_predictions : Plot precision-recall curve given</span></div>
<div class="line"><span class="lineno"> 2066</span><span class="stringliteral">        binary class predictions.</span></div>
<div class="line"><span class="lineno"> 2067</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2068</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 2069</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 2070</span><span class="stringliteral">    When ``true positive + false negative == 0``, recall returns 0 and raises</span></div>
<div class="line"><span class="lineno"> 2071</span><span class="stringliteral">    ``UndefinedMetricWarning``. This behavior can be modified with</span></div>
<div class="line"><span class="lineno"> 2072</span><span class="stringliteral">    ``zero_division``.</span></div>
<div class="line"><span class="lineno"> 2073</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 2074</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 2075</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 2076</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import recall_score</span></div>
<div class="line"><span class="lineno"> 2077</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]</span></div>
<div class="line"><span class="lineno"> 2078</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]</span></div>
<div class="line"><span class="lineno"> 2079</span><span class="stringliteral">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=&#39;macro&#39;)</span></div>
<div class="line"><span class="lineno"> 2080</span><span class="stringliteral">    0.33...</span></div>
<div class="line"><span class="lineno"> 2081</span><span class="stringliteral">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=&#39;micro&#39;)</span></div>
<div class="line"><span class="lineno"> 2082</span><span class="stringliteral">    0.33...</span></div>
<div class="line"><span class="lineno"> 2083</span><span class="stringliteral">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=&#39;weighted&#39;)</span></div>
<div class="line"><span class="lineno"> 2084</span><span class="stringliteral">    0.33...</span></div>
<div class="line"><span class="lineno"> 2085</span><span class="stringliteral">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=None)</span></div>
<div class="line"><span class="lineno"> 2086</span><span class="stringliteral">    array([1., 0., 0.])</span></div>
<div class="line"><span class="lineno"> 2087</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [0, 0, 0, 0, 0, 0]</span></div>
<div class="line"><span class="lineno"> 2088</span><span class="stringliteral">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=None)</span></div>
<div class="line"><span class="lineno"> 2089</span><span class="stringliteral">    array([0.5, 0. , 0. ])</span></div>
<div class="line"><span class="lineno"> 2090</span><span class="stringliteral">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=None, zero_division=1)</span></div>
<div class="line"><span class="lineno"> 2091</span><span class="stringliteral">    array([0.5, 1. , 1. ])</span></div>
<div class="line"><span class="lineno"> 2092</span><span class="stringliteral">    &gt;&gt;&gt; # multilabel classification</span></div>
<div class="line"><span class="lineno"> 2093</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]</span></div>
<div class="line"><span class="lineno"> 2094</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]</span></div>
<div class="line"><span class="lineno"> 2095</span><span class="stringliteral">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=None)</span></div>
<div class="line"><span class="lineno"> 2096</span><span class="stringliteral">    array([1. , 1. , 0.5])</span></div>
<div class="line"><span class="lineno"> 2097</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 2098</span>    _, r, _, _ = precision_recall_fscore_support(</div>
<div class="line"><span class="lineno"> 2099</span>        y_true,</div>
<div class="line"><span class="lineno"> 2100</span>        y_pred,</div>
<div class="line"><span class="lineno"> 2101</span>        labels=labels,</div>
<div class="line"><span class="lineno"> 2102</span>        pos_label=pos_label,</div>
<div class="line"><span class="lineno"> 2103</span>        average=average,</div>
<div class="line"><span class="lineno"> 2104</span>        warn_for=(<span class="stringliteral">&quot;recall&quot;</span>,),</div>
<div class="line"><span class="lineno"> 2105</span>        sample_weight=sample_weight,</div>
<div class="line"><span class="lineno"> 2106</span>        zero_division=zero_division,</div>
<div class="line"><span class="lineno"> 2107</span>    )</div>
<div class="line"><span class="lineno"> 2108</span>    <span class="keywordflow">return</span> r</div>
<div class="line"><span class="lineno"> 2109</span> </div>
<div class="line"><span class="lineno"> 2110</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aba3dbfc2fa006a79a93786b039a7cf47" name="aba3dbfc2fa006a79a93786b039a7cf47"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba3dbfc2fa006a79a93786b039a7cf47">&#9670;&#160;</a></span>zero_one_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._classification.zero_one_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>normalize</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Zero-one classification loss.

If normalize is ``True``, return the fraction of misclassifications
(float), else it returns the number of misclassifications (int). The best
performance is 0.

Read more in the :ref:`User Guide &lt;zero_one_loss&gt;`.

Parameters
----------
y_true : 1d array-like, or label indicator array / sparse matrix
    Ground truth (correct) labels.

y_pred : 1d array-like, or label indicator array / sparse matrix
    Predicted labels, as returned by a classifier.

normalize : bool, default=True
    If ``False``, return the number of misclassifications.
    Otherwise, return the fraction of misclassifications.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
loss : float or int,
    If ``normalize == True``, return the fraction of misclassifications
    (float), else it returns the number of misclassifications (int).

See Also
--------
accuracy_score : Compute the accuracy score. By default, the function will
    return the fraction of correct predictions divided by the total number
    of predictions.
hamming_loss : Compute the average Hamming loss or Hamming distance between
    two sets of samples.
jaccard_score : Compute the Jaccard similarity coefficient score.

Notes
-----
In multilabel classification, the zero_one_loss function corresponds to
the subset zero-one loss: for each sample, the entire set of labels must be
correctly predicted, otherwise the loss for that sample is equal to one.

Examples
--------
&gt;&gt;&gt; from sklearn.metrics import zero_one_loss
&gt;&gt;&gt; y_pred = [1, 2, 3, 4]
&gt;&gt;&gt; y_true = [2, 2, 3, 4]
&gt;&gt;&gt; zero_one_loss(y_true, y_pred)
0.25
&gt;&gt;&gt; zero_one_loss(y_true, y_pred, normalize=False)
1

In the multilabel case with binary label indicators:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; zero_one_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))
0.5
</pre> <div class="fragment"><div class="line"><span class="lineno">  936</span><span class="keyword">def </span>zero_one_loss(y_true, y_pred, *, normalize=True, sample_weight=None):</div>
<div class="line"><span class="lineno">  937</span>    <span class="stringliteral">&quot;&quot;&quot;Zero-one classification loss.</span></div>
<div class="line"><span class="lineno">  938</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  939</span><span class="stringliteral">    If normalize is ``True``, return the fraction of misclassifications</span></div>
<div class="line"><span class="lineno">  940</span><span class="stringliteral">    (float), else it returns the number of misclassifications (int). The best</span></div>
<div class="line"><span class="lineno">  941</span><span class="stringliteral">    performance is 0.</span></div>
<div class="line"><span class="lineno">  942</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  943</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;zero_one_loss&gt;`.</span></div>
<div class="line"><span class="lineno">  944</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  945</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  946</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  947</span><span class="stringliteral">    y_true : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno">  948</span><span class="stringliteral">        Ground truth (correct) labels.</span></div>
<div class="line"><span class="lineno">  949</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  950</span><span class="stringliteral">    y_pred : 1d array-like, or label indicator array / sparse matrix</span></div>
<div class="line"><span class="lineno">  951</span><span class="stringliteral">        Predicted labels, as returned by a classifier.</span></div>
<div class="line"><span class="lineno">  952</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  953</span><span class="stringliteral">    normalize : bool, default=True</span></div>
<div class="line"><span class="lineno">  954</span><span class="stringliteral">        If ``False``, return the number of misclassifications.</span></div>
<div class="line"><span class="lineno">  955</span><span class="stringliteral">        Otherwise, return the fraction of misclassifications.</span></div>
<div class="line"><span class="lineno">  956</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  957</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  958</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  959</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  960</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  961</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  962</span><span class="stringliteral">    loss : float or int,</span></div>
<div class="line"><span class="lineno">  963</span><span class="stringliteral">        If ``normalize == True``, return the fraction of misclassifications</span></div>
<div class="line"><span class="lineno">  964</span><span class="stringliteral">        (float), else it returns the number of misclassifications (int).</span></div>
<div class="line"><span class="lineno">  965</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  966</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  967</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  968</span><span class="stringliteral">    accuracy_score : Compute the accuracy score. By default, the function will</span></div>
<div class="line"><span class="lineno">  969</span><span class="stringliteral">        return the fraction of correct predictions divided by the total number</span></div>
<div class="line"><span class="lineno">  970</span><span class="stringliteral">        of predictions.</span></div>
<div class="line"><span class="lineno">  971</span><span class="stringliteral">    hamming_loss : Compute the average Hamming loss or Hamming distance between</span></div>
<div class="line"><span class="lineno">  972</span><span class="stringliteral">        two sets of samples.</span></div>
<div class="line"><span class="lineno">  973</span><span class="stringliteral">    jaccard_score : Compute the Jaccard similarity coefficient score.</span></div>
<div class="line"><span class="lineno">  974</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  975</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  976</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  977</span><span class="stringliteral">    In multilabel classification, the zero_one_loss function corresponds to</span></div>
<div class="line"><span class="lineno">  978</span><span class="stringliteral">    the subset zero-one loss: for each sample, the entire set of labels must be</span></div>
<div class="line"><span class="lineno">  979</span><span class="stringliteral">    correctly predicted, otherwise the loss for that sample is equal to one.</span></div>
<div class="line"><span class="lineno">  980</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  981</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  982</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  983</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import zero_one_loss</span></div>
<div class="line"><span class="lineno">  984</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = [1, 2, 3, 4]</span></div>
<div class="line"><span class="lineno">  985</span><span class="stringliteral">    &gt;&gt;&gt; y_true = [2, 2, 3, 4]</span></div>
<div class="line"><span class="lineno">  986</span><span class="stringliteral">    &gt;&gt;&gt; zero_one_loss(y_true, y_pred)</span></div>
<div class="line"><span class="lineno">  987</span><span class="stringliteral">    0.25</span></div>
<div class="line"><span class="lineno">  988</span><span class="stringliteral">    &gt;&gt;&gt; zero_one_loss(y_true, y_pred, normalize=False)</span></div>
<div class="line"><span class="lineno">  989</span><span class="stringliteral">    1</span></div>
<div class="line"><span class="lineno">  990</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  991</span><span class="stringliteral">    In the multilabel case with binary label indicators:</span></div>
<div class="line"><span class="lineno">  992</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  993</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  994</span><span class="stringliteral">    &gt;&gt;&gt; zero_one_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))</span></div>
<div class="line"><span class="lineno">  995</span><span class="stringliteral">    0.5</span></div>
<div class="line"><span class="lineno">  996</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  997</span>    score = accuracy_score(</div>
<div class="line"><span class="lineno">  998</span>        y_true, y_pred, normalize=normalize, sample_weight=sample_weight</div>
<div class="line"><span class="lineno">  999</span>    )</div>
<div class="line"><span class="lineno"> 1000</span> </div>
<div class="line"><span class="lineno"> 1001</span>    <span class="keywordflow">if</span> normalize:</div>
<div class="line"><span class="lineno"> 1002</span>        <span class="keywordflow">return</span> 1 - score</div>
<div class="line"><span class="lineno"> 1003</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1004</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1005</span>            n_samples = np.sum(sample_weight)</div>
<div class="line"><span class="lineno"> 1006</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1007</span>            n_samples = _num_samples(y_true)</div>
<div class="line"><span class="lineno"> 1008</span>        <span class="keywordflow">return</span> n_samples - score</div>
<div class="line"><span class="lineno"> 1009</span> </div>
<div class="line"><span class="lineno"> 1010</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
