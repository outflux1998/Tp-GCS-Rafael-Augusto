<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.covariance._graph_lasso Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1covariance.html">covariance</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1covariance_1_1__graph__lasso.html">_graph_lasso</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.covariance._graph_lasso Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1covariance_1_1__graph__lasso_1_1_base_graphical_lasso.html">BaseGraphicalLasso</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1covariance_1_1__graph__lasso_1_1_graphical_lasso.html">GraphicalLasso</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1covariance_1_1__graph__lasso_1_1_graphical_lasso_c_v.html">GraphicalLassoCV</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a479effa92e34e45bc6fc9557f9fdf210" id="r_a479effa92e34e45bc6fc9557f9fdf210"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1covariance_1_1__graph__lasso.html#a479effa92e34e45bc6fc9557f9fdf210">_objective</a> (mle, precision_, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>)</td></tr>
<tr class="separator:a479effa92e34e45bc6fc9557f9fdf210"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4cc33c46e6b035c177fa505d0bd05a6" id="r_ac4cc33c46e6b035c177fa505d0bd05a6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1covariance_1_1__graph__lasso.html#ac4cc33c46e6b035c177fa505d0bd05a6">_dual_gap</a> (emp_cov, precision_, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>)</td></tr>
<tr class="separator:ac4cc33c46e6b035c177fa505d0bd05a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc81dbef2f3f49c902b1b137ba86266f" id="r_adc81dbef2f3f49c902b1b137ba86266f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1covariance_1_1__graph__lasso.html#adc81dbef2f3f49c902b1b137ba86266f">alpha_max</a> (emp_cov)</td></tr>
<tr class="separator:adc81dbef2f3f49c902b1b137ba86266f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a983f3ea04e37ef973d95c06709a028d9" id="r_a983f3ea04e37ef973d95c06709a028d9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1covariance_1_1__graph__lasso.html#a983f3ea04e37ef973d95c06709a028d9">graphical_lasso</a> (emp_cov, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, *cov_init=None, mode=&quot;cd&quot;, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-4, enet_tol=1e-4, max_iter=100, verbose=False, return_costs=False, <a class="el" href="__lapack__subroutines_8h.html#a57833d05f43fd1408080af6eec88fc43">eps</a>=np.finfo(np.float64).<a class="el" href="__lapack__subroutines_8h.html#a57833d05f43fd1408080af6eec88fc43">eps</a>, return_n_iter=False)</td></tr>
<tr class="separator:a983f3ea04e37ef973d95c06709a028d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a121efbf0aeb7245b6181dfabec2bba2a" id="r_a121efbf0aeb7245b6181dfabec2bba2a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1covariance_1_1__graph__lasso.html#a121efbf0aeb7245b6181dfabec2bba2a">graphical_lasso_path</a> (X, alphas, cov_init=None, X_test=None, mode=&quot;cd&quot;, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-4, enet_tol=1e-4, max_iter=100, verbose=False)</td></tr>
<tr class="separator:a121efbf0aeb7245b6181dfabec2bba2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">GraphicalLasso: sparse inverse covariance estimation with an l1-penalized
estimator.
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="ac4cc33c46e6b035c177fa505d0bd05a6" name="ac4cc33c46e6b035c177fa505d0bd05a6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac4cc33c46e6b035c177fa505d0bd05a6">&#9670;&#160;</a></span>_dual_gap()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.covariance._graph_lasso._dual_gap </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>emp_cov</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>precision_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Expression of the dual gap convergence criterion

The specific definition is given in Duchi "Projected Subgradient Methods
for Learning Sparse Gaussians".
</pre> <div class="fragment"><div class="line"><span class="lineno">   50</span><span class="keyword">def </span>_dual_gap(emp_cov, precision_, alpha):</div>
<div class="line"><span class="lineno">   51</span>    <span class="stringliteral">&quot;&quot;&quot;Expression of the dual gap convergence criterion</span></div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">    The specific definition is given in Duchi &quot;Projected Subgradient Methods</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral">    for Learning Sparse Gaussians&quot;.</span></div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   56</span>    gap = np.sum(emp_cov * precision_)</div>
<div class="line"><span class="lineno">   57</span>    gap -= precision_.shape[0]</div>
<div class="line"><span class="lineno">   58</span>    gap += alpha * (np.abs(precision_).sum() - np.abs(np.diag(precision_)).sum())</div>
<div class="line"><span class="lineno">   59</span>    <span class="keywordflow">return</span> gap</div>
<div class="line"><span class="lineno">   60</span> </div>
<div class="line"><span class="lineno">   61</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a479effa92e34e45bc6fc9557f9fdf210" name="a479effa92e34e45bc6fc9557f9fdf210"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a479effa92e34e45bc6fc9557f9fdf210">&#9670;&#160;</a></span>_objective()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.covariance._graph_lasso._objective </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>precision_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Evaluation of the graphical-lasso objective function

the objective function is made of a shifted scaled version of the
normalized log-likelihood (i.e. its empirical mean over the samples) and a
penalisation term to promote sparsity
</pre> <div class="fragment"><div class="line"><span class="lineno">   37</span><span class="keyword">def </span>_objective(mle, precision_, alpha):</div>
<div class="line"><span class="lineno">   38</span>    <span class="stringliteral">&quot;&quot;&quot;Evaluation of the graphical-lasso objective function</span></div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">    the objective function is made of a shifted scaled version of the</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">    normalized log-likelihood (i.e. its empirical mean over the samples) and a</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral">    penalisation term to promote sparsity</span></div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   44</span>    p = precision_.shape[0]</div>
<div class="line"><span class="lineno">   45</span>    cost = -2.0 * log_likelihood(mle, precision_) + p * np.log(2 * np.pi)</div>
<div class="line"><span class="lineno">   46</span>    cost += alpha * (np.abs(precision_).sum() - np.abs(np.diag(precision_)).sum())</div>
<div class="line"><span class="lineno">   47</span>    <span class="keywordflow">return</span> cost</div>
<div class="line"><span class="lineno">   48</span> </div>
<div class="line"><span class="lineno">   49</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="adc81dbef2f3f49c902b1b137ba86266f" name="adc81dbef2f3f49c902b1b137ba86266f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc81dbef2f3f49c902b1b137ba86266f">&#9670;&#160;</a></span>alpha_max()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.covariance._graph_lasso.alpha_max </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>emp_cov</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Find the maximum alpha for which there are some non-zeros off-diagonal.

Parameters
----------
emp_cov : ndarray of shape (n_features, n_features)
    The sample covariance matrix.

Notes
-----
This results from the bound for the all the Lasso that are solved
in GraphicalLasso: each time, the row of cov corresponds to Xy. As the
bound for alpha is given by `max(abs(Xy))`, the result follows.
</pre> <div class="fragment"><div class="line"><span class="lineno">   62</span><span class="keyword">def </span>alpha_max(emp_cov):</div>
<div class="line"><span class="lineno">   63</span>    <span class="stringliteral">&quot;&quot;&quot;Find the maximum alpha for which there are some non-zeros off-diagonal.</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    emp_cov : ndarray of shape (n_features, n_features)</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">        The sample covariance matrix.</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">    This results from the bound for the all the Lasso that are solved</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">    in GraphicalLasso: each time, the row of cov corresponds to Xy. As the</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">    bound for alpha is given by `max(abs(Xy))`, the result follows.</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   76</span>    A = np.copy(emp_cov)</div>
<div class="line"><span class="lineno">   77</span>    A.flat[:: A.shape[0] + 1] = 0</div>
<div class="line"><span class="lineno">   78</span>    <span class="keywordflow">return</span> np.max(np.abs(A))</div>
<div class="line"><span class="lineno">   79</span> </div>
<div class="line"><span class="lineno">   80</span> </div>
<div class="line"><span class="lineno">   81</span><span class="comment"># The g-lasso algorithm</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a983f3ea04e37ef973d95c06709a028d9" name="a983f3ea04e37ef973d95c06709a028d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a983f3ea04e37ef973d95c06709a028d9">&#9670;&#160;</a></span>graphical_lasso()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.covariance._graph_lasso.graphical_lasso </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>emp_cov</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>cov_init</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mode</em> = <code>&quot;cd&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>enet_tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_costs</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>eps</em> = <code>np.finfo(np.float64).<a class="el" href="__lapack__subroutines_8h.html#a57833d05f43fd1408080af6eec88fc43">eps</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_n_iter</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">L1-penalized covariance estimator.

Read more in the :ref:`User Guide &lt;sparse_inverse_covariance&gt;`.

.. versionchanged:: v0.20
    graph_lasso has been renamed to graphical_lasso

Parameters
----------
emp_cov : ndarray of shape (n_features, n_features)
    Empirical covariance from which to compute the covariance estimate.

alpha : float
    The regularization parameter: the higher alpha, the more
    regularization, the sparser the inverse covariance.
    Range is (0, inf].

cov_init : array of shape (n_features, n_features), default=None
    The initial guess for the covariance. If None, then the empirical
    covariance is used.

mode : {'cd', 'lars'}, default='cd'
    The Lasso solver to use: coordinate descent or LARS. Use LARS for
    very sparse underlying graphs, where p &gt; n. Elsewhere prefer cd
    which is more numerically stable.

tol : float, default=1e-4
    The tolerance to declare convergence: if the dual gap goes below
    this value, iterations are stopped. Range is (0, inf].

enet_tol : float, default=1e-4
    The tolerance for the elastic net solver used to calculate the descent
    direction. This parameter controls the accuracy of the search direction
    for a given column update, not of the overall parameter estimate. Only
    used for mode='cd'. Range is (0, inf].

max_iter : int, default=100
    The maximum number of iterations.

verbose : bool, default=False
    If verbose is True, the objective function and dual gap are
    printed at each iteration.

return_costs : bool, default=Flase
    If return_costs is True, the objective function and dual gap
    at each iteration are returned.

eps : float, default=eps
    The machine-precision regularization in the computation of the
    Cholesky diagonal factors. Increase this for very ill-conditioned
    systems. Default is `np.finfo(np.float64).eps`.

return_n_iter : bool, default=False
    Whether or not to return the number of iterations.

Returns
-------
covariance : ndarray of shape (n_features, n_features)
    The estimated covariance matrix.

precision : ndarray of shape (n_features, n_features)
    The estimated (sparse) precision matrix.

costs : list of (objective, dual_gap) pairs
    The list of values of the objective function and the dual gap at
    each iteration. Returned only if return_costs is True.

n_iter : int
    Number of iterations. Returned only if `return_n_iter` is set to True.

See Also
--------
GraphicalLasso : Sparse inverse covariance estimation
    with an l1-penalized estimator.
GraphicalLassoCV : Sparse inverse covariance with
    cross-validated choice of the l1 penalty.

Notes
-----
The algorithm employed to solve this problem is the GLasso algorithm,
from the Friedman 2008 Biostatistics paper. It is the same algorithm
as in the R `glasso` package.

One possible difference with the `glasso` R package is that the
diagonal coefficients are not penalized.
</pre> <div class="fragment"><div class="line"><span class="lineno">   95</span>):</div>
<div class="line"><span class="lineno">   96</span>    <span class="stringliteral">&quot;&quot;&quot;L1-penalized covariance estimator.</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;sparse_inverse_covariance&gt;`.</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">    .. versionchanged:: v0.20</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">        graph_lasso has been renamed to graphical_lasso</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral">    emp_cov : ndarray of shape (n_features, n_features)</span></div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral">        Empirical covariance from which to compute the covariance estimate.</span></div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">    alpha : float</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">        The regularization parameter: the higher alpha, the more</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral">        regularization, the sparser the inverse covariance.</span></div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral">        Range is (0, inf].</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral">    cov_init : array of shape (n_features, n_features), default=None</span></div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">        The initial guess for the covariance. If None, then the empirical</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">        covariance is used.</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">    mode : {&#39;cd&#39;, &#39;lars&#39;}, default=&#39;cd&#39;</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">        The Lasso solver to use: coordinate descent or LARS. Use LARS for</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral">        very sparse underlying graphs, where p &gt; n. Elsewhere prefer cd</span></div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral">        which is more numerically stable.</span></div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">    tol : float, default=1e-4</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">        The tolerance to declare convergence: if the dual gap goes below</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">        this value, iterations are stopped. Range is (0, inf].</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral">    enet_tol : float, default=1e-4</span></div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral">        The tolerance for the elastic net solver used to calculate the descent</span></div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral">        direction. This parameter controls the accuracy of the search direction</span></div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral">        for a given column update, not of the overall parameter estimate. Only</span></div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral">        used for mode=&#39;cd&#39;. Range is (0, inf].</span></div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral">    max_iter : int, default=100</span></div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">        The maximum number of iterations.</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">    verbose : bool, default=False</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">        If verbose is True, the objective function and dual gap are</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">        printed at each iteration.</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral">    return_costs : bool, default=Flase</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">        If return_costs is True, the objective function and dual gap</span></div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">        at each iteration are returned.</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">    eps : float, default=eps</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">        The machine-precision regularization in the computation of the</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">        Cholesky diagonal factors. Increase this for very ill-conditioned</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">        systems. Default is `np.finfo(np.float64).eps`.</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">    return_n_iter : bool, default=False</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">        Whether or not to return the number of iterations.</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">    covariance : ndarray of shape (n_features, n_features)</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">        The estimated covariance matrix.</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">    precision : ndarray of shape (n_features, n_features)</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">        The estimated (sparse) precision matrix.</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">    costs : list of (objective, dual_gap) pairs</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">        The list of values of the objective function and the dual gap at</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">        each iteration. Returned only if return_costs is True.</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">    n_iter : int</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        Number of iterations. Returned only if `return_n_iter` is set to True.</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">    GraphicalLasso : Sparse inverse covariance estimation</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral">        with an l1-penalized estimator.</span></div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">    GraphicalLassoCV : Sparse inverse covariance with</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">        cross-validated choice of the l1 penalty.</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">    The algorithm employed to solve this problem is the GLasso algorithm,</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">    from the Friedman 2008 Biostatistics paper. It is the same algorithm</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">    as in the R `glasso` package.</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">    One possible difference with the `glasso` R package is that the</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">    diagonal coefficients are not penalized.</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  182</span>    _, n_features = emp_cov.shape</div>
<div class="line"><span class="lineno">  183</span>    <span class="keywordflow">if</span> alpha == 0:</div>
<div class="line"><span class="lineno">  184</span>        <span class="keywordflow">if</span> return_costs:</div>
<div class="line"><span class="lineno">  185</span>            precision_ = linalg.inv(emp_cov)</div>
<div class="line"><span class="lineno">  186</span>            cost = -2.0 * log_likelihood(emp_cov, precision_)</div>
<div class="line"><span class="lineno">  187</span>            cost += n_features * np.log(2 * np.pi)</div>
<div class="line"><span class="lineno">  188</span>            d_gap = np.sum(emp_cov * precision_) - n_features</div>
<div class="line"><span class="lineno">  189</span>            <span class="keywordflow">if</span> return_n_iter:</div>
<div class="line"><span class="lineno">  190</span>                <span class="keywordflow">return</span> emp_cov, precision_, (cost, d_gap), 0</div>
<div class="line"><span class="lineno">  191</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  192</span>                <span class="keywordflow">return</span> emp_cov, precision_, (cost, d_gap)</div>
<div class="line"><span class="lineno">  193</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  194</span>            <span class="keywordflow">if</span> return_n_iter:</div>
<div class="line"><span class="lineno">  195</span>                <span class="keywordflow">return</span> emp_cov, linalg.inv(emp_cov), 0</div>
<div class="line"><span class="lineno">  196</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  197</span>                <span class="keywordflow">return</span> emp_cov, linalg.inv(emp_cov)</div>
<div class="line"><span class="lineno">  198</span>    <span class="keywordflow">if</span> cov_init <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  199</span>        covariance_ = emp_cov.copy()</div>
<div class="line"><span class="lineno">  200</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  201</span>        covariance_ = cov_init.copy()</div>
<div class="line"><span class="lineno">  202</span>    <span class="comment"># As a trivial regularization (Tikhonov like), we scale down the</span></div>
<div class="line"><span class="lineno">  203</span>    <span class="comment"># off-diagonal coefficients of our starting point: This is needed, as</span></div>
<div class="line"><span class="lineno">  204</span>    <span class="comment"># in the cross-validation the cov_init can easily be</span></div>
<div class="line"><span class="lineno">  205</span>    <span class="comment"># ill-conditioned, and the CV loop blows. Beside, this takes</span></div>
<div class="line"><span class="lineno">  206</span>    <span class="comment"># conservative stand-point on the initial conditions, and it tends to</span></div>
<div class="line"><span class="lineno">  207</span>    <span class="comment"># make the convergence go faster.</span></div>
<div class="line"><span class="lineno">  208</span>    covariance_ *= 0.95</div>
<div class="line"><span class="lineno">  209</span>    diagonal = emp_cov.flat[:: n_features + 1]</div>
<div class="line"><span class="lineno">  210</span>    covariance_.flat[:: n_features + 1] = diagonal</div>
<div class="line"><span class="lineno">  211</span>    precision_ = linalg.pinvh(covariance_)</div>
<div class="line"><span class="lineno">  212</span> </div>
<div class="line"><span class="lineno">  213</span>    indices = np.arange(n_features)</div>
<div class="line"><span class="lineno">  214</span>    costs = list()</div>
<div class="line"><span class="lineno">  215</span>    <span class="comment"># The different l1 regression solver have different numerical errors</span></div>
<div class="line"><span class="lineno">  216</span>    <span class="keywordflow">if</span> mode == <span class="stringliteral">&quot;cd&quot;</span>:</div>
<div class="line"><span class="lineno">  217</span>        errors = dict(over=<span class="stringliteral">&quot;raise&quot;</span>, invalid=<span class="stringliteral">&quot;ignore&quot;</span>)</div>
<div class="line"><span class="lineno">  218</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  219</span>        errors = dict(invalid=<span class="stringliteral">&quot;raise&quot;</span>)</div>
<div class="line"><span class="lineno">  220</span>    <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  221</span>        <span class="comment"># be robust to the max_iter=0 edge case, see:</span></div>
<div class="line"><span class="lineno">  222</span>        <span class="comment"># https://github.com/scikit-learn/scikit-learn/issues/4134</span></div>
<div class="line"><span class="lineno">  223</span>        d_gap = np.inf</div>
<div class="line"><span class="lineno">  224</span>        <span class="comment"># set a sub_covariance buffer</span></div>
<div class="line"><span class="lineno">  225</span>        sub_covariance = np.copy(covariance_[1:, 1:], order=<span class="stringliteral">&quot;C&quot;</span>)</div>
<div class="line"><span class="lineno">  226</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(max_iter):</div>
<div class="line"><span class="lineno">  227</span>            <span class="keywordflow">for</span> idx <span class="keywordflow">in</span> range(n_features):</div>
<div class="line"><span class="lineno">  228</span>                <span class="comment"># To keep the contiguous matrix `sub_covariance` equal to</span></div>
<div class="line"><span class="lineno">  229</span>                <span class="comment"># covariance_[indices != idx].T[indices != idx]</span></div>
<div class="line"><span class="lineno">  230</span>                <span class="comment"># we only need to update 1 column and 1 line when idx changes</span></div>
<div class="line"><span class="lineno">  231</span>                <span class="keywordflow">if</span> idx &gt; 0:</div>
<div class="line"><span class="lineno">  232</span>                    di = idx - 1</div>
<div class="line"><span class="lineno">  233</span>                    sub_covariance[di] = covariance_[di][indices != idx]</div>
<div class="line"><span class="lineno">  234</span>                    sub_covariance[:, di] = covariance_[:, di][indices != idx]</div>
<div class="line"><span class="lineno">  235</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  236</span>                    sub_covariance[:] = covariance_[1:, 1:]</div>
<div class="line"><span class="lineno">  237</span>                row = emp_cov[idx, indices != idx]</div>
<div class="line"><span class="lineno">  238</span>                <span class="keyword">with</span> np.errstate(**errors):</div>
<div class="line"><span class="lineno">  239</span>                    <span class="keywordflow">if</span> mode == <span class="stringliteral">&quot;cd&quot;</span>:</div>
<div class="line"><span class="lineno">  240</span>                        <span class="comment"># Use coordinate descent</span></div>
<div class="line"><span class="lineno">  241</span>                        coefs = -(</div>
<div class="line"><span class="lineno">  242</span>                            precision_[indices != idx, idx]</div>
<div class="line"><span class="lineno">  243</span>                            / (precision_[idx, idx] + 1000 * eps)</div>
<div class="line"><span class="lineno">  244</span>                        )</div>
<div class="line"><span class="lineno">  245</span>                        coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(</div>
<div class="line"><span class="lineno">  246</span>                            coefs,</div>
<div class="line"><span class="lineno">  247</span>                            alpha,</div>
<div class="line"><span class="lineno">  248</span>                            0,</div>
<div class="line"><span class="lineno">  249</span>                            sub_covariance,</div>
<div class="line"><span class="lineno">  250</span>                            row,</div>
<div class="line"><span class="lineno">  251</span>                            row,</div>
<div class="line"><span class="lineno">  252</span>                            max_iter,</div>
<div class="line"><span class="lineno">  253</span>                            enet_tol,</div>
<div class="line"><span class="lineno">  254</span>                            check_random_state(<span class="keywordtype">None</span>),</div>
<div class="line"><span class="lineno">  255</span>                            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  256</span>                        )</div>
<div class="line"><span class="lineno">  257</span>                    <span class="keywordflow">else</span>:  <span class="comment"># mode == &quot;lars&quot;</span></div>
<div class="line"><span class="lineno">  258</span>                        _, _, coefs = lars_path_gram(</div>
<div class="line"><span class="lineno">  259</span>                            Xy=row,</div>
<div class="line"><span class="lineno">  260</span>                            Gram=sub_covariance,</div>
<div class="line"><span class="lineno">  261</span>                            n_samples=row.size,</div>
<div class="line"><span class="lineno">  262</span>                            alpha_min=alpha / (n_features - 1),</div>
<div class="line"><span class="lineno">  263</span>                            copy_Gram=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  264</span>                            eps=eps,</div>
<div class="line"><span class="lineno">  265</span>                            method=<span class="stringliteral">&quot;lars&quot;</span>,</div>
<div class="line"><span class="lineno">  266</span>                            return_path=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  267</span>                        )</div>
<div class="line"><span class="lineno">  268</span>                <span class="comment"># Update the precision matrix</span></div>
<div class="line"><span class="lineno">  269</span>                precision_[idx, idx] = 1.0 / (</div>
<div class="line"><span class="lineno">  270</span>                    covariance_[idx, idx]</div>
<div class="line"><span class="lineno">  271</span>                    - np.dot(covariance_[indices != idx, idx], coefs)</div>
<div class="line"><span class="lineno">  272</span>                )</div>
<div class="line"><span class="lineno">  273</span>                precision_[indices != idx, idx] = -precision_[idx, idx] * coefs</div>
<div class="line"><span class="lineno">  274</span>                precision_[idx, indices != idx] = -precision_[idx, idx] * coefs</div>
<div class="line"><span class="lineno">  275</span>                coefs = np.dot(sub_covariance, coefs)</div>
<div class="line"><span class="lineno">  276</span>                covariance_[idx, indices != idx] = coefs</div>
<div class="line"><span class="lineno">  277</span>                covariance_[indices != idx, idx] = coefs</div>
<div class="line"><span class="lineno">  278</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.isfinite(precision_.sum()):</div>
<div class="line"><span class="lineno">  279</span>                <span class="keywordflow">raise</span> FloatingPointError(</div>
<div class="line"><span class="lineno">  280</span>                    <span class="stringliteral">&quot;The system is too ill-conditioned for this solver&quot;</span></div>
<div class="line"><span class="lineno">  281</span>                )</div>
<div class="line"><span class="lineno">  282</span>            d_gap = _dual_gap(emp_cov, precision_, alpha)</div>
<div class="line"><span class="lineno">  283</span>            cost = _objective(emp_cov, precision_, alpha)</div>
<div class="line"><span class="lineno">  284</span>            <span class="keywordflow">if</span> verbose:</div>
<div class="line"><span class="lineno">  285</span>                print(</div>
<div class="line"><span class="lineno">  286</span>                    <span class="stringliteral">&quot;[graphical_lasso] Iteration % 3i, cost % 3.2e, dual gap %.3e&quot;</span></div>
<div class="line"><span class="lineno">  287</span>                    % (i, cost, d_gap)</div>
<div class="line"><span class="lineno">  288</span>                )</div>
<div class="line"><span class="lineno">  289</span>            <span class="keywordflow">if</span> return_costs:</div>
<div class="line"><span class="lineno">  290</span>                costs.append((cost, d_gap))</div>
<div class="line"><span class="lineno">  291</span>            <span class="keywordflow">if</span> np.abs(d_gap) &lt; tol:</div>
<div class="line"><span class="lineno">  292</span>                <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  293</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.isfinite(cost) <span class="keywordflow">and</span> i &gt; 0:</div>
<div class="line"><span class="lineno">  294</span>                <span class="keywordflow">raise</span> FloatingPointError(</div>
<div class="line"><span class="lineno">  295</span>                    <span class="stringliteral">&quot;Non SPD result: the system is too ill-conditioned for this solver&quot;</span></div>
<div class="line"><span class="lineno">  296</span>                )</div>
<div class="line"><span class="lineno">  297</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  298</span>            warnings.warn(</div>
<div class="line"><span class="lineno">  299</span>                <span class="stringliteral">&quot;graphical_lasso: did not converge after %i iteration: dual gap: %.3e&quot;</span></div>
<div class="line"><span class="lineno">  300</span>                % (max_iter, d_gap),</div>
<div class="line"><span class="lineno">  301</span>                ConvergenceWarning,</div>
<div class="line"><span class="lineno">  302</span>            )</div>
<div class="line"><span class="lineno">  303</span>    <span class="keywordflow">except</span> FloatingPointError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  304</span>        e.args = (e.args[0] + <span class="stringliteral">&quot;. The system is too ill-conditioned for this solver&quot;</span>,)</div>
<div class="line"><span class="lineno">  305</span>        <span class="keywordflow">raise</span> e</div>
<div class="line"><span class="lineno">  306</span> </div>
<div class="line"><span class="lineno">  307</span>    <span class="keywordflow">if</span> return_costs:</div>
<div class="line"><span class="lineno">  308</span>        <span class="keywordflow">if</span> return_n_iter:</div>
<div class="line"><span class="lineno">  309</span>            <span class="keywordflow">return</span> covariance_, precision_, costs, i + 1</div>
<div class="line"><span class="lineno">  310</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  311</span>            <span class="keywordflow">return</span> covariance_, precision_, costs</div>
<div class="line"><span class="lineno">  312</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  313</span>        <span class="keywordflow">if</span> return_n_iter:</div>
<div class="line"><span class="lineno">  314</span>            <span class="keywordflow">return</span> covariance_, precision_, i + 1</div>
<div class="line"><span class="lineno">  315</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  316</span>            <span class="keywordflow">return</span> covariance_, precision_</div>
<div class="line"><span class="lineno">  317</span> </div>
<div class="line"><span class="lineno">  318</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a121efbf0aeb7245b6181dfabec2bba2a" name="a121efbf0aeb7245b6181dfabec2bba2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a121efbf0aeb7245b6181dfabec2bba2a">&#9670;&#160;</a></span>graphical_lasso_path()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.covariance._graph_lasso.graphical_lasso_path </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alphas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cov_init</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_test</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mode</em> = <code>&quot;cd&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>enet_tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">l1-penalized covariance estimator along a path of decreasing alphas

Read more in the :ref:`User Guide &lt;sparse_inverse_covariance&gt;`.

Parameters
----------
X : ndarray of shape (n_samples, n_features)
    Data from which to compute the covariance estimate.

alphas : array-like of shape (n_alphas,)
    The list of regularization parameters, decreasing order.

cov_init : array of shape (n_features, n_features), default=None
    The initial guess for the covariance.

X_test : array of shape (n_test_samples, n_features), default=None
    Optional test matrix to measure generalisation error.

mode : {'cd', 'lars'}, default='cd'
    The Lasso solver to use: coordinate descent or LARS. Use LARS for
    very sparse underlying graphs, where p &gt; n. Elsewhere prefer cd
    which is more numerically stable.

tol : float, default=1e-4
    The tolerance to declare convergence: if the dual gap goes below
    this value, iterations are stopped. The tolerance must be a positive
    number.

enet_tol : float, default=1e-4
    The tolerance for the elastic net solver used to calculate the descent
    direction. This parameter controls the accuracy of the search direction
    for a given column update, not of the overall parameter estimate. Only
    used for mode='cd'. The tolerance must be a positive number.

max_iter : int, default=100
    The maximum number of iterations. This parameter should be a strictly
    positive integer.

verbose : int or bool, default=False
    The higher the verbosity flag, the more information is printed
    during the fitting.

Returns
-------
covariances_ : list of shape (n_alphas,) of ndarray of shape \
        (n_features, n_features)
    The estimated covariance matrices.

precisions_ : list of shape (n_alphas,) of ndarray of shape \
        (n_features, n_features)
    The estimated (sparse) precision matrices.

scores_ : list of shape (n_alphas,), dtype=float
    The generalisation error (log-likelihood) on the test data.
    Returned only if test data is passed.
</pre> <div class="fragment"><div class="line"><span class="lineno">  518</span>):</div>
<div class="line"><span class="lineno">  519</span>    <span class="stringliteral">&quot;&quot;&quot;l1-penalized covariance estimator along a path of decreasing alphas</span></div>
<div class="line"><span class="lineno">  520</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  521</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;sparse_inverse_covariance&gt;`.</span></div>
<div class="line"><span class="lineno">  522</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  523</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  524</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  525</span><span class="stringliteral">    X : ndarray of shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  526</span><span class="stringliteral">        Data from which to compute the covariance estimate.</span></div>
<div class="line"><span class="lineno">  527</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  528</span><span class="stringliteral">    alphas : array-like of shape (n_alphas,)</span></div>
<div class="line"><span class="lineno">  529</span><span class="stringliteral">        The list of regularization parameters, decreasing order.</span></div>
<div class="line"><span class="lineno">  530</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  531</span><span class="stringliteral">    cov_init : array of shape (n_features, n_features), default=None</span></div>
<div class="line"><span class="lineno">  532</span><span class="stringliteral">        The initial guess for the covariance.</span></div>
<div class="line"><span class="lineno">  533</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  534</span><span class="stringliteral">    X_test : array of shape (n_test_samples, n_features), default=None</span></div>
<div class="line"><span class="lineno">  535</span><span class="stringliteral">        Optional test matrix to measure generalisation error.</span></div>
<div class="line"><span class="lineno">  536</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  537</span><span class="stringliteral">    mode : {&#39;cd&#39;, &#39;lars&#39;}, default=&#39;cd&#39;</span></div>
<div class="line"><span class="lineno">  538</span><span class="stringliteral">        The Lasso solver to use: coordinate descent or LARS. Use LARS for</span></div>
<div class="line"><span class="lineno">  539</span><span class="stringliteral">        very sparse underlying graphs, where p &gt; n. Elsewhere prefer cd</span></div>
<div class="line"><span class="lineno">  540</span><span class="stringliteral">        which is more numerically stable.</span></div>
<div class="line"><span class="lineno">  541</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  542</span><span class="stringliteral">    tol : float, default=1e-4</span></div>
<div class="line"><span class="lineno">  543</span><span class="stringliteral">        The tolerance to declare convergence: if the dual gap goes below</span></div>
<div class="line"><span class="lineno">  544</span><span class="stringliteral">        this value, iterations are stopped. The tolerance must be a positive</span></div>
<div class="line"><span class="lineno">  545</span><span class="stringliteral">        number.</span></div>
<div class="line"><span class="lineno">  546</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  547</span><span class="stringliteral">    enet_tol : float, default=1e-4</span></div>
<div class="line"><span class="lineno">  548</span><span class="stringliteral">        The tolerance for the elastic net solver used to calculate the descent</span></div>
<div class="line"><span class="lineno">  549</span><span class="stringliteral">        direction. This parameter controls the accuracy of the search direction</span></div>
<div class="line"><span class="lineno">  550</span><span class="stringliteral">        for a given column update, not of the overall parameter estimate. Only</span></div>
<div class="line"><span class="lineno">  551</span><span class="stringliteral">        used for mode=&#39;cd&#39;. The tolerance must be a positive number.</span></div>
<div class="line"><span class="lineno">  552</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  553</span><span class="stringliteral">    max_iter : int, default=100</span></div>
<div class="line"><span class="lineno">  554</span><span class="stringliteral">        The maximum number of iterations. This parameter should be a strictly</span></div>
<div class="line"><span class="lineno">  555</span><span class="stringliteral">        positive integer.</span></div>
<div class="line"><span class="lineno">  556</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  557</span><span class="stringliteral">    verbose : int or bool, default=False</span></div>
<div class="line"><span class="lineno">  558</span><span class="stringliteral">        The higher the verbosity flag, the more information is printed</span></div>
<div class="line"><span class="lineno">  559</span><span class="stringliteral">        during the fitting.</span></div>
<div class="line"><span class="lineno">  560</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  561</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  562</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  563</span><span class="stringliteral">    covariances_ : list of shape (n_alphas,) of ndarray of shape \</span></div>
<div class="line"><span class="lineno">  564</span><span class="stringliteral">            (n_features, n_features)</span></div>
<div class="line"><span class="lineno">  565</span><span class="stringliteral">        The estimated covariance matrices.</span></div>
<div class="line"><span class="lineno">  566</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  567</span><span class="stringliteral">    precisions_ : list of shape (n_alphas,) of ndarray of shape \</span></div>
<div class="line"><span class="lineno">  568</span><span class="stringliteral">            (n_features, n_features)</span></div>
<div class="line"><span class="lineno">  569</span><span class="stringliteral">        The estimated (sparse) precision matrices.</span></div>
<div class="line"><span class="lineno">  570</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  571</span><span class="stringliteral">    scores_ : list of shape (n_alphas,), dtype=float</span></div>
<div class="line"><span class="lineno">  572</span><span class="stringliteral">        The generalisation error (log-likelihood) on the test data.</span></div>
<div class="line"><span class="lineno">  573</span><span class="stringliteral">        Returned only if test data is passed.</span></div>
<div class="line"><span class="lineno">  574</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  575</span>    inner_verbose = max(0, verbose - 1)</div>
<div class="line"><span class="lineno">  576</span>    emp_cov = empirical_covariance(X)</div>
<div class="line"><span class="lineno">  577</span>    <span class="keywordflow">if</span> cov_init <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  578</span>        covariance_ = emp_cov.copy()</div>
<div class="line"><span class="lineno">  579</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  580</span>        covariance_ = cov_init</div>
<div class="line"><span class="lineno">  581</span>    covariances_ = list()</div>
<div class="line"><span class="lineno">  582</span>    precisions_ = list()</div>
<div class="line"><span class="lineno">  583</span>    scores_ = list()</div>
<div class="line"><span class="lineno">  584</span>    <span class="keywordflow">if</span> X_test <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  585</span>        test_emp_cov = empirical_covariance(X_test)</div>
<div class="line"><span class="lineno">  586</span> </div>
<div class="line"><span class="lineno">  587</span>    <span class="keywordflow">for</span> alpha <span class="keywordflow">in</span> alphas:</div>
<div class="line"><span class="lineno">  588</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  589</span>            <span class="comment"># Capture the errors, and move on</span></div>
<div class="line"><span class="lineno">  590</span>            covariance_, precision_ = graphical_lasso(</div>
<div class="line"><span class="lineno">  591</span>                emp_cov,</div>
<div class="line"><span class="lineno">  592</span>                alpha=alpha,</div>
<div class="line"><span class="lineno">  593</span>                cov_init=covariance_,</div>
<div class="line"><span class="lineno">  594</span>                mode=mode,</div>
<div class="line"><span class="lineno">  595</span>                tol=tol,</div>
<div class="line"><span class="lineno">  596</span>                enet_tol=enet_tol,</div>
<div class="line"><span class="lineno">  597</span>                max_iter=max_iter,</div>
<div class="line"><span class="lineno">  598</span>                verbose=inner_verbose,</div>
<div class="line"><span class="lineno">  599</span>            )</div>
<div class="line"><span class="lineno">  600</span>            covariances_.append(covariance_)</div>
<div class="line"><span class="lineno">  601</span>            precisions_.append(precision_)</div>
<div class="line"><span class="lineno">  602</span>            <span class="keywordflow">if</span> X_test <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  603</span>                this_score = log_likelihood(test_emp_cov, precision_)</div>
<div class="line"><span class="lineno">  604</span>        <span class="keywordflow">except</span> FloatingPointError:</div>
<div class="line"><span class="lineno">  605</span>            this_score = -np.inf</div>
<div class="line"><span class="lineno">  606</span>            covariances_.append(np.nan)</div>
<div class="line"><span class="lineno">  607</span>            precisions_.append(np.nan)</div>
<div class="line"><span class="lineno">  608</span>        <span class="keywordflow">if</span> X_test <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  609</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.isfinite(this_score):</div>
<div class="line"><span class="lineno">  610</span>                this_score = -np.inf</div>
<div class="line"><span class="lineno">  611</span>            scores_.append(this_score)</div>
<div class="line"><span class="lineno">  612</span>        <span class="keywordflow">if</span> verbose == 1:</div>
<div class="line"><span class="lineno">  613</span>            sys.stderr.write(<span class="stringliteral">&quot;.&quot;</span>)</div>
<div class="line"><span class="lineno">  614</span>        <span class="keywordflow">elif</span> verbose &gt; 1:</div>
<div class="line"><span class="lineno">  615</span>            <span class="keywordflow">if</span> X_test <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  616</span>                print(</div>
<div class="line"><span class="lineno">  617</span>                    <span class="stringliteral">&quot;[graphical_lasso_path] alpha: %.2e, score: %.2e&quot;</span></div>
<div class="line"><span class="lineno">  618</span>                    % (alpha, this_score)</div>
<div class="line"><span class="lineno">  619</span>                )</div>
<div class="line"><span class="lineno">  620</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  621</span>                print(<span class="stringliteral">&quot;[graphical_lasso_path] alpha: %.2e&quot;</span> % alpha)</div>
<div class="line"><span class="lineno">  622</span>    <span class="keywordflow">if</span> X_test <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  623</span>        <span class="keywordflow">return</span> covariances_, precisions_, scores_</div>
<div class="line"><span class="lineno">  624</span>    <span class="keywordflow">return</span> covariances_, precisions_</div>
<div class="line"><span class="lineno">  625</span> </div>
<div class="line"><span class="lineno">  626</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
