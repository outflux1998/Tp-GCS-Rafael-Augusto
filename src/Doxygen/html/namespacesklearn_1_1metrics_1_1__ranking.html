<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.metrics._ranking Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1metrics.html">metrics</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html">_ranking</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.metrics._ranking Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a2c4c6b34503f6764ceeec4034849e554" id="r_a2c4c6b34503f6764ceeec4034849e554"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a2c4c6b34503f6764ceeec4034849e554">auc</a> (x, y)</td></tr>
<tr class="separator:a2c4c6b34503f6764ceeec4034849e554"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ec8c184525183e3f42d7fcbcbf53ce5" id="r_a2ec8c184525183e3f42d7fcbcbf53ce5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a2ec8c184525183e3f42d7fcbcbf53ce5">average_precision_score</a> (y_true, y_score, *average=&quot;macro&quot;, pos_label=1, sample_weight=None)</td></tr>
<tr class="separator:a2ec8c184525183e3f42d7fcbcbf53ce5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a907ac7a1d46c9224c6eb531eb653f9" id="r_a5a907ac7a1d46c9224c6eb531eb653f9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a5a907ac7a1d46c9224c6eb531eb653f9">det_curve</a> (y_true, y_score, pos_label=None, sample_weight=None)</td></tr>
<tr class="separator:a5a907ac7a1d46c9224c6eb531eb653f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89b9a489b7f321836031936bd3d4d264" id="r_a89b9a489b7f321836031936bd3d4d264"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a89b9a489b7f321836031936bd3d4d264">_binary_roc_auc_score</a> (y_true, y_score, sample_weight=None, max_fpr=None)</td></tr>
<tr class="separator:a89b9a489b7f321836031936bd3d4d264"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d99ca10e2fbc9c27128ba2d1744d22d" id="r_a5d99ca10e2fbc9c27128ba2d1744d22d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a5d99ca10e2fbc9c27128ba2d1744d22d">roc_auc_score</a> (y_true, y_score, *average=&quot;macro&quot;, sample_weight=None, max_fpr=None, multi_class=&quot;raise&quot;, labels=None)</td></tr>
<tr class="separator:a5d99ca10e2fbc9c27128ba2d1744d22d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a481e66d29470d53eaa0b7352e0d025c1" id="r_a481e66d29470d53eaa0b7352e0d025c1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a481e66d29470d53eaa0b7352e0d025c1">_multiclass_roc_auc_score</a> (y_true, y_score, labels, multi_class, average, sample_weight)</td></tr>
<tr class="separator:a481e66d29470d53eaa0b7352e0d025c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afada87a91fffb2d93831604094745dd5" id="r_afada87a91fffb2d93831604094745dd5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#afada87a91fffb2d93831604094745dd5">_binary_clf_curve</a> (y_true, y_score, pos_label=None, sample_weight=None)</td></tr>
<tr class="separator:afada87a91fffb2d93831604094745dd5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef84ebd79b282432f70f0b7a347f3055" id="r_aef84ebd79b282432f70f0b7a347f3055"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#aef84ebd79b282432f70f0b7a347f3055">precision_recall_curve</a> (y_true, probas_pred, *pos_label=None, sample_weight=None)</td></tr>
<tr class="separator:aef84ebd79b282432f70f0b7a347f3055"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8290dcf9bd98dc304d10d4cf92feb0f" id="r_ab8290dcf9bd98dc304d10d4cf92feb0f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#ab8290dcf9bd98dc304d10d4cf92feb0f">roc_curve</a> (y_true, y_score, *pos_label=None, sample_weight=None, drop_intermediate=True)</td></tr>
<tr class="separator:ab8290dcf9bd98dc304d10d4cf92feb0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a823afe2acdab3fa238632e261e107a1c" id="r_a823afe2acdab3fa238632e261e107a1c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a823afe2acdab3fa238632e261e107a1c">label_ranking_average_precision_score</a> (y_true, y_score, *sample_weight=None)</td></tr>
<tr class="separator:a823afe2acdab3fa238632e261e107a1c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa36e8f5c1f464a3913d18b6f5375ef9c" id="r_aa36e8f5c1f464a3913d18b6f5375ef9c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#aa36e8f5c1f464a3913d18b6f5375ef9c">coverage_error</a> (y_true, y_score, *sample_weight=None)</td></tr>
<tr class="separator:aa36e8f5c1f464a3913d18b6f5375ef9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b6692d3f97515bece867d5a03013a6a" id="r_a0b6692d3f97515bece867d5a03013a6a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a0b6692d3f97515bece867d5a03013a6a">label_ranking_loss</a> (y_true, y_score, *sample_weight=None)</td></tr>
<tr class="separator:a0b6692d3f97515bece867d5a03013a6a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9935a178be1e93eafee4b0424311228a" id="r_a9935a178be1e93eafee4b0424311228a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a9935a178be1e93eafee4b0424311228a">_dcg_sample_scores</a> (y_true, y_score, <a class="el" href="__blas__subroutines_8h.html#afa8f30d4cfebc7d1efb06e7d245eff5a">k</a>=None, log_base=2, ignore_ties=False)</td></tr>
<tr class="separator:a9935a178be1e93eafee4b0424311228a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f450180af70ebb947a8851e749f4769" id="r_a1f450180af70ebb947a8851e749f4769"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a1f450180af70ebb947a8851e749f4769">_tie_averaged_dcg</a> (y_true, y_score, discount_cumsum)</td></tr>
<tr class="separator:a1f450180af70ebb947a8851e749f4769"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b09653e8b1b4d29ca4787533a43c83d" id="r_a6b09653e8b1b4d29ca4787533a43c83d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a6b09653e8b1b4d29ca4787533a43c83d">_check_dcg_target_type</a> (y_true)</td></tr>
<tr class="separator:a6b09653e8b1b4d29ca4787533a43c83d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34ff8c6be112f2758e73808a718ebc07" id="r_a34ff8c6be112f2758e73808a718ebc07"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a34ff8c6be112f2758e73808a718ebc07">dcg_score</a> (y_true, y_score, *<a class="el" href="__blas__subroutines_8h.html#afa8f30d4cfebc7d1efb06e7d245eff5a">k</a>=None, log_base=2, sample_weight=None, ignore_ties=False)</td></tr>
<tr class="separator:a34ff8c6be112f2758e73808a718ebc07"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe101238e730ad16a031adc79bcbcfd1" id="r_afe101238e730ad16a031adc79bcbcfd1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#afe101238e730ad16a031adc79bcbcfd1">_ndcg_sample_scores</a> (y_true, y_score, <a class="el" href="__blas__subroutines_8h.html#afa8f30d4cfebc7d1efb06e7d245eff5a">k</a>=None, ignore_ties=False)</td></tr>
<tr class="separator:afe101238e730ad16a031adc79bcbcfd1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84a9a92b4b94ddd8962415fc5faf2fa8" id="r_a84a9a92b4b94ddd8962415fc5faf2fa8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#a84a9a92b4b94ddd8962415fc5faf2fa8">ndcg_score</a> (y_true, y_score, *<a class="el" href="__blas__subroutines_8h.html#afa8f30d4cfebc7d1efb06e7d245eff5a">k</a>=None, sample_weight=None, ignore_ties=False)</td></tr>
<tr class="separator:a84a9a92b4b94ddd8962415fc5faf2fa8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5e5b89cf08cfa61301a1c204023ea54" id="r_ad5e5b89cf08cfa61301a1c204023ea54"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1metrics_1_1__ranking.html#ad5e5b89cf08cfa61301a1c204023ea54">top_k_accuracy_score</a> (y_true, y_score, *<a class="el" href="__blas__subroutines_8h.html#afa8f30d4cfebc7d1efb06e7d245eff5a">k</a>=2, normalize=True, sample_weight=None, labels=None)</td></tr>
<tr class="separator:ad5e5b89cf08cfa61301a1c204023ea54"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Metrics to assess performance on classification task given scores.

Functions named as ``*_score`` return a scalar value to maximize: the higher
the better.

Function named as ``*_error`` or ``*_loss`` return a scalar value to minimize:
the lower the better.
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="afada87a91fffb2d93831604094745dd5" name="afada87a91fffb2d93831604094745dd5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afada87a91fffb2d93831604094745dd5">&#9670;&#160;</a></span>_binary_clf_curve()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking._binary_clf_curve </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Calculate true and false positives per binary classification threshold.

Parameters
----------
y_true : ndarray of shape (n_samples,)
    True targets of binary classification.

y_score : ndarray of shape (n_samples,)
    Estimated probabilities or output of a decision function.

pos_label : int or str, default=None
    The label of the positive class.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
fps : ndarray of shape (n_thresholds,)
    A count of false positives, at index i being the number of negative
    samples assigned a score &gt;= thresholds[i]. The total number of
    negative samples is equal to fps[-1] (thus true negatives are given by
    fps[-1] - fps).

tps : ndarray of shape (n_thresholds,)
    An increasing count of true positives, at index i being the number
    of positive samples assigned a score &gt;= thresholds[i]. The total
    number of positive samples is equal to tps[-1] (thus false negatives
    are given by tps[-1] - tps).

thresholds : ndarray of shape (n_thresholds,)
    Decreasing score values.
</pre> <div class="fragment"><div class="line"><span class="lineno">  712</span><span class="keyword">def </span>_binary_clf_curve(y_true, y_score, pos_label=None, sample_weight=None):</div>
<div class="line"><span class="lineno">  713</span>    <span class="stringliteral">&quot;&quot;&quot;Calculate true and false positives per binary classification threshold.</span></div>
<div class="line"><span class="lineno">  714</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  715</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  716</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  717</span><span class="stringliteral">    y_true : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  718</span><span class="stringliteral">        True targets of binary classification.</span></div>
<div class="line"><span class="lineno">  719</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  720</span><span class="stringliteral">    y_score : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  721</span><span class="stringliteral">        Estimated probabilities or output of a decision function.</span></div>
<div class="line"><span class="lineno">  722</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  723</span><span class="stringliteral">    pos_label : int or str, default=None</span></div>
<div class="line"><span class="lineno">  724</span><span class="stringliteral">        The label of the positive class.</span></div>
<div class="line"><span class="lineno">  725</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  726</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  727</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  728</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  729</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  730</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  731</span><span class="stringliteral">    fps : ndarray of shape (n_thresholds,)</span></div>
<div class="line"><span class="lineno">  732</span><span class="stringliteral">        A count of false positives, at index i being the number of negative</span></div>
<div class="line"><span class="lineno">  733</span><span class="stringliteral">        samples assigned a score &gt;= thresholds[i]. The total number of</span></div>
<div class="line"><span class="lineno">  734</span><span class="stringliteral">        negative samples is equal to fps[-1] (thus true negatives are given by</span></div>
<div class="line"><span class="lineno">  735</span><span class="stringliteral">        fps[-1] - fps).</span></div>
<div class="line"><span class="lineno">  736</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  737</span><span class="stringliteral">    tps : ndarray of shape (n_thresholds,)</span></div>
<div class="line"><span class="lineno">  738</span><span class="stringliteral">        An increasing count of true positives, at index i being the number</span></div>
<div class="line"><span class="lineno">  739</span><span class="stringliteral">        of positive samples assigned a score &gt;= thresholds[i]. The total</span></div>
<div class="line"><span class="lineno">  740</span><span class="stringliteral">        number of positive samples is equal to tps[-1] (thus false negatives</span></div>
<div class="line"><span class="lineno">  741</span><span class="stringliteral">        are given by tps[-1] - tps).</span></div>
<div class="line"><span class="lineno">  742</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  743</span><span class="stringliteral">    thresholds : ndarray of shape (n_thresholds,)</span></div>
<div class="line"><span class="lineno">  744</span><span class="stringliteral">        Decreasing score values.</span></div>
<div class="line"><span class="lineno">  745</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  746</span>    <span class="comment"># Check to make sure y_true is valid</span></div>
<div class="line"><span class="lineno">  747</span>    y_type = type_of_target(y_true, input_name=<span class="stringliteral">&quot;y_true&quot;</span>)</div>
<div class="line"><span class="lineno">  748</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> (y_type == <span class="stringliteral">&quot;binary&quot;</span> <span class="keywordflow">or</span> (y_type == <span class="stringliteral">&quot;multiclass&quot;</span> <span class="keywordflow">and</span> pos_label <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>)):</div>
<div class="line"><span class="lineno">  749</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;{0} format is not supported&quot;</span>.format(y_type))</div>
<div class="line"><span class="lineno">  750</span> </div>
<div class="line"><span class="lineno">  751</span>    check_consistent_length(y_true, y_score, sample_weight)</div>
<div class="line"><span class="lineno">  752</span>    y_true = column_or_1d(y_true)</div>
<div class="line"><span class="lineno">  753</span>    y_score = column_or_1d(y_score)</div>
<div class="line"><span class="lineno">  754</span>    assert_all_finite(y_true)</div>
<div class="line"><span class="lineno">  755</span>    assert_all_finite(y_score)</div>
<div class="line"><span class="lineno">  756</span> </div>
<div class="line"><span class="lineno">  757</span>    <span class="comment"># Filter out zero-weighted samples, as they should not impact the result</span></div>
<div class="line"><span class="lineno">  758</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  759</span>        sample_weight = column_or_1d(sample_weight)</div>
<div class="line"><span class="lineno">  760</span>        sample_weight = _check_sample_weight(sample_weight, y_true)</div>
<div class="line"><span class="lineno">  761</span>        nonzero_weight_mask = sample_weight != 0</div>
<div class="line"><span class="lineno">  762</span>        y_true = y_true[nonzero_weight_mask]</div>
<div class="line"><span class="lineno">  763</span>        y_score = y_score[nonzero_weight_mask]</div>
<div class="line"><span class="lineno">  764</span>        sample_weight = sample_weight[nonzero_weight_mask]</div>
<div class="line"><span class="lineno">  765</span> </div>
<div class="line"><span class="lineno">  766</span>    pos_label = _check_pos_label_consistency(pos_label, y_true)</div>
<div class="line"><span class="lineno">  767</span> </div>
<div class="line"><span class="lineno">  768</span>    <span class="comment"># make y_true a boolean vector</span></div>
<div class="line"><span class="lineno">  769</span>    y_true = y_true == pos_label</div>
<div class="line"><span class="lineno">  770</span> </div>
<div class="line"><span class="lineno">  771</span>    <span class="comment"># sort scores and corresponding truth values</span></div>
<div class="line"><span class="lineno">  772</span>    desc_score_indices = np.argsort(y_score, kind=<span class="stringliteral">&quot;mergesort&quot;</span>)[::-1]</div>
<div class="line"><span class="lineno">  773</span>    y_score = y_score[desc_score_indices]</div>
<div class="line"><span class="lineno">  774</span>    y_true = y_true[desc_score_indices]</div>
<div class="line"><span class="lineno">  775</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  776</span>        weight = sample_weight[desc_score_indices]</div>
<div class="line"><span class="lineno">  777</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  778</span>        weight = 1.0</div>
<div class="line"><span class="lineno">  779</span> </div>
<div class="line"><span class="lineno">  780</span>    <span class="comment"># y_score typically has many tied values. Here we extract</span></div>
<div class="line"><span class="lineno">  781</span>    <span class="comment"># the indices associated with the distinct values. We also</span></div>
<div class="line"><span class="lineno">  782</span>    <span class="comment"># concatenate a value for the end of the curve.</span></div>
<div class="line"><span class="lineno">  783</span>    distinct_value_indices = np.where(np.diff(y_score))[0]</div>
<div class="line"><span class="lineno">  784</span>    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]</div>
<div class="line"><span class="lineno">  785</span> </div>
<div class="line"><span class="lineno">  786</span>    <span class="comment"># accumulate the true positives with decreasing threshold</span></div>
<div class="line"><span class="lineno">  787</span>    tps = stable_cumsum(y_true * weight)[threshold_idxs]</div>
<div class="line"><span class="lineno">  788</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  789</span>        <span class="comment"># express fps as a cumsum to ensure fps is increasing even in</span></div>
<div class="line"><span class="lineno">  790</span>        <span class="comment"># the presence of floating point errors</span></div>
<div class="line"><span class="lineno">  791</span>        fps = stable_cumsum((1 - y_true) * weight)[threshold_idxs]</div>
<div class="line"><span class="lineno">  792</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  793</span>        fps = 1 + threshold_idxs - tps</div>
<div class="line"><span class="lineno">  794</span>    <span class="keywordflow">return</span> fps, tps, y_score[threshold_idxs]</div>
<div class="line"><span class="lineno">  795</span> </div>
<div class="line"><span class="lineno">  796</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a89b9a489b7f321836031936bd3d4d264" name="a89b9a489b7f321836031936bd3d4d264"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a89b9a489b7f321836031936bd3d4d264">&#9670;&#160;</a></span>_binary_roc_auc_score()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking._binary_roc_auc_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_fpr</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Binary roc auc score.</pre> <div class="fragment"><div class="line"><span class="lineno">  336</span><span class="keyword">def </span>_binary_roc_auc_score(y_true, y_score, sample_weight=None, max_fpr=None):</div>
<div class="line"><span class="lineno">  337</span>    <span class="stringliteral">&quot;&quot;&quot;Binary roc auc score.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  338</span>    <span class="keywordflow">if</span> len(np.unique(y_true)) != 2:</div>
<div class="line"><span class="lineno">  339</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  340</span>            <span class="stringliteral">&quot;Only one class present in y_true. ROC AUC score &quot;</span></div>
<div class="line"><span class="lineno">  341</span>            <span class="stringliteral">&quot;is not defined in that case.&quot;</span></div>
<div class="line"><span class="lineno">  342</span>        )</div>
<div class="line"><span class="lineno">  343</span> </div>
<div class="line"><span class="lineno">  344</span>    fpr, tpr, _ = roc_curve(y_true, y_score, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  345</span>    <span class="keywordflow">if</span> max_fpr <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">or</span> max_fpr == 1:</div>
<div class="line"><span class="lineno">  346</span>        <span class="keywordflow">return</span> auc(fpr, tpr)</div>
<div class="line"><span class="lineno">  347</span>    <span class="keywordflow">if</span> max_fpr &lt;= 0 <span class="keywordflow">or</span> max_fpr &gt; 1:</div>
<div class="line"><span class="lineno">  348</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Expected max_fpr in range (0, 1], got: %r&quot;</span> % max_fpr)</div>
<div class="line"><span class="lineno">  349</span> </div>
<div class="line"><span class="lineno">  350</span>    <span class="comment"># Add a single point at max_fpr by linear interpolation</span></div>
<div class="line"><span class="lineno">  351</span>    stop = np.searchsorted(fpr, max_fpr, <span class="stringliteral">&quot;right&quot;</span>)</div>
<div class="line"><span class="lineno">  352</span>    x_interp = [fpr[stop - 1], fpr[stop]]</div>
<div class="line"><span class="lineno">  353</span>    y_interp = [tpr[stop - 1], tpr[stop]]</div>
<div class="line"><span class="lineno">  354</span>    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))</div>
<div class="line"><span class="lineno">  355</span>    fpr = np.append(fpr[:stop], max_fpr)</div>
<div class="line"><span class="lineno">  356</span>    partial_auc = auc(fpr, tpr)</div>
<div class="line"><span class="lineno">  357</span> </div>
<div class="line"><span class="lineno">  358</span>    <span class="comment"># McClish correction: standardize result to be 0.5 if non-discriminant</span></div>
<div class="line"><span class="lineno">  359</span>    <span class="comment"># and 1 if maximal</span></div>
<div class="line"><span class="lineno">  360</span>    min_area = 0.5 * max_fpr**2</div>
<div class="line"><span class="lineno">  361</span>    max_area = max_fpr</div>
<div class="line"><span class="lineno">  362</span>    <span class="keywordflow">return</span> 0.5 * (1 + (partial_auc - min_area) / (max_area - min_area))</div>
<div class="line"><span class="lineno">  363</span> </div>
<div class="line"><span class="lineno">  364</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6b09653e8b1b4d29ca4787533a43c83d" name="a6b09653e8b1b4d29ca4787533a43c83d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b09653e8b1b4d29ca4787533a43c83d">&#9670;&#160;</a></span>_check_dcg_target_type()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking._check_dcg_target_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1382</span><span class="keyword">def </span>_check_dcg_target_type(y_true):</div>
<div class="line"><span class="lineno"> 1383</span>    y_type = type_of_target(y_true, input_name=<span class="stringliteral">&quot;y_true&quot;</span>)</div>
<div class="line"><span class="lineno"> 1384</span>    supported_fmt = (</div>
<div class="line"><span class="lineno"> 1385</span>        <span class="stringliteral">&quot;multilabel-indicator&quot;</span>,</div>
<div class="line"><span class="lineno"> 1386</span>        <span class="stringliteral">&quot;continuous-multioutput&quot;</span>,</div>
<div class="line"><span class="lineno"> 1387</span>        <span class="stringliteral">&quot;multiclass-multioutput&quot;</span>,</div>
<div class="line"><span class="lineno"> 1388</span>    )</div>
<div class="line"><span class="lineno"> 1389</span>    <span class="keywordflow">if</span> y_type <span class="keywordflow">not</span> <span class="keywordflow">in</span> supported_fmt:</div>
<div class="line"><span class="lineno"> 1390</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1391</span>            <span class="stringliteral">&quot;Only {} formats are supported. Got {} instead&quot;</span>.format(</div>
<div class="line"><span class="lineno"> 1392</span>                supported_fmt, y_type</div>
<div class="line"><span class="lineno"> 1393</span>            )</div>
<div class="line"><span class="lineno"> 1394</span>        )</div>
<div class="line"><span class="lineno"> 1395</span> </div>
<div class="line"><span class="lineno"> 1396</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9935a178be1e93eafee4b0424311228a" name="a9935a178be1e93eafee4b0424311228a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9935a178be1e93eafee4b0424311228a">&#9670;&#160;</a></span>_dcg_sample_scores()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking._dcg_sample_scores </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>k</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>log_base</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ignore_ties</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute Discounted Cumulative Gain.

Sum the true scores ranked in the order induced by the predicted scores,
after applying a logarithmic discount.

This ranking metric yields a high value if true labels are ranked high by
``y_score``.

Parameters
----------
y_true : ndarray of shape (n_samples, n_labels)
    True targets of multilabel classification, or true scores of entities
    to be ranked.

y_score : ndarray of shape (n_samples, n_labels)
    Target scores, can either be probability estimates, confidence values,
    or non-thresholded measure of decisions (as returned by
    "decision_function" on some classifiers).

k : int, default=None
    Only consider the highest k scores in the ranking. If `None`, use all
    outputs.

log_base : float, default=2
    Base of the logarithm used for the discount. A low value means a
    sharper discount (top results are more important).

ignore_ties : bool, default=False
    Assume that there are no ties in y_score (which is likely to be the
    case if y_score is continuous) for efficiency gains.

Returns
-------
discounted_cumulative_gain : ndarray of shape (n_samples,)
    The DCG score for each sample.

See Also
--------
ndcg_score : The Discounted Cumulative Gain divided by the Ideal Discounted
    Cumulative Gain (the DCG obtained for a perfect ranking), in order to
    have a score between 0 and 1.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1274</span><span class="keyword">def </span>_dcg_sample_scores(y_true, y_score, k=None, log_base=2, ignore_ties=False):</div>
<div class="line"><span class="lineno"> 1275</span>    <span class="stringliteral">&quot;&quot;&quot;Compute Discounted Cumulative Gain.</span></div>
<div class="line"><span class="lineno"> 1276</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1277</span><span class="stringliteral">    Sum the true scores ranked in the order induced by the predicted scores,</span></div>
<div class="line"><span class="lineno"> 1278</span><span class="stringliteral">    after applying a logarithmic discount.</span></div>
<div class="line"><span class="lineno"> 1279</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1280</span><span class="stringliteral">    This ranking metric yields a high value if true labels are ranked high by</span></div>
<div class="line"><span class="lineno"> 1281</span><span class="stringliteral">    ``y_score``.</span></div>
<div class="line"><span class="lineno"> 1282</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1283</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1284</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1285</span><span class="stringliteral">    y_true : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1286</span><span class="stringliteral">        True targets of multilabel classification, or true scores of entities</span></div>
<div class="line"><span class="lineno"> 1287</span><span class="stringliteral">        to be ranked.</span></div>
<div class="line"><span class="lineno"> 1288</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1289</span><span class="stringliteral">    y_score : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1290</span><span class="stringliteral">        Target scores, can either be probability estimates, confidence values,</span></div>
<div class="line"><span class="lineno"> 1291</span><span class="stringliteral">        or non-thresholded measure of decisions (as returned by</span></div>
<div class="line"><span class="lineno"> 1292</span><span class="stringliteral">        &quot;decision_function&quot; on some classifiers).</span></div>
<div class="line"><span class="lineno"> 1293</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1294</span><span class="stringliteral">    k : int, default=None</span></div>
<div class="line"><span class="lineno"> 1295</span><span class="stringliteral">        Only consider the highest k scores in the ranking. If `None`, use all</span></div>
<div class="line"><span class="lineno"> 1296</span><span class="stringliteral">        outputs.</span></div>
<div class="line"><span class="lineno"> 1297</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1298</span><span class="stringliteral">    log_base : float, default=2</span></div>
<div class="line"><span class="lineno"> 1299</span><span class="stringliteral">        Base of the logarithm used for the discount. A low value means a</span></div>
<div class="line"><span class="lineno"> 1300</span><span class="stringliteral">        sharper discount (top results are more important).</span></div>
<div class="line"><span class="lineno"> 1301</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1302</span><span class="stringliteral">    ignore_ties : bool, default=False</span></div>
<div class="line"><span class="lineno"> 1303</span><span class="stringliteral">        Assume that there are no ties in y_score (which is likely to be the</span></div>
<div class="line"><span class="lineno"> 1304</span><span class="stringliteral">        case if y_score is continuous) for efficiency gains.</span></div>
<div class="line"><span class="lineno"> 1305</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1306</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1307</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1308</span><span class="stringliteral">    discounted_cumulative_gain : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1309</span><span class="stringliteral">        The DCG score for each sample.</span></div>
<div class="line"><span class="lineno"> 1310</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1311</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 1312</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1313</span><span class="stringliteral">    ndcg_score : The Discounted Cumulative Gain divided by the Ideal Discounted</span></div>
<div class="line"><span class="lineno"> 1314</span><span class="stringliteral">        Cumulative Gain (the DCG obtained for a perfect ranking), in order to</span></div>
<div class="line"><span class="lineno"> 1315</span><span class="stringliteral">        have a score between 0 and 1.</span></div>
<div class="line"><span class="lineno"> 1316</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1317</span>    discount = 1 / (np.log(np.arange(y_true.shape[1]) + 2) / np.log(log_base))</div>
<div class="line"><span class="lineno"> 1318</span>    <span class="keywordflow">if</span> k <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1319</span>        discount[k:] = 0</div>
<div class="line"><span class="lineno"> 1320</span>    <span class="keywordflow">if</span> ignore_ties:</div>
<div class="line"><span class="lineno"> 1321</span>        ranking = np.argsort(y_score)[:, ::-1]</div>
<div class="line"><span class="lineno"> 1322</span>        ranked = y_true[np.arange(ranking.shape[0])[:, np.newaxis], ranking]</div>
<div class="line"><span class="lineno"> 1323</span>        cumulative_gains = discount.dot(ranked.T)</div>
<div class="line"><span class="lineno"> 1324</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1325</span>        discount_cumsum = np.cumsum(discount)</div>
<div class="line"><span class="lineno"> 1326</span>        cumulative_gains = [</div>
<div class="line"><span class="lineno"> 1327</span>            _tie_averaged_dcg(y_t, y_s, discount_cumsum)</div>
<div class="line"><span class="lineno"> 1328</span>            <span class="keywordflow">for</span> y_t, y_s <span class="keywordflow">in</span> zip(y_true, y_score)</div>
<div class="line"><span class="lineno"> 1329</span>        ]</div>
<div class="line"><span class="lineno"> 1330</span>        cumulative_gains = np.asarray(cumulative_gains)</div>
<div class="line"><span class="lineno"> 1331</span>    <span class="keywordflow">return</span> cumulative_gains</div>
<div class="line"><span class="lineno"> 1332</span> </div>
<div class="line"><span class="lineno"> 1333</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a481e66d29470d53eaa0b7352e0d025c1" name="a481e66d29470d53eaa0b7352e0d025c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a481e66d29470d53eaa0b7352e0d025c1">&#9670;&#160;</a></span>_multiclass_roc_auc_score()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking._multiclass_roc_auc_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>labels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Multiclass roc auc score.

Parameters
----------
y_true : array-like of shape (n_samples,)
    True multiclass labels.

y_score : array-like of shape (n_samples, n_classes)
    Target scores corresponding to probability estimates of a sample
    belonging to a particular class

labels : array-like of shape (n_classes,) or None
    List of labels to index ``y_score`` used for multiclass. If ``None``,
    the lexical order of ``y_true`` is used to index ``y_score``.

multi_class : {'ovr', 'ovo'}
    Determines the type of multiclass configuration to use.
    ``'ovr'``:
        Calculate metrics for the multiclass case using the one-vs-rest
        approach.
    ``'ovo'``:
        Calculate metrics for the multiclass case using the one-vs-one
        approach.

average : {'micro', 'macro', 'weighted'}
    Determines the type of averaging performed on the pairwise binary
    metric scores
    ``'micro'``:
        Calculate metrics for the binarized-raveled classes. Only supported
        for `multi_class='ovr'`.

    .. versionadded:: 1.2

    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean. This does not take label imbalance into account. Classes
        are assumed to be uniformly distributed.
    ``'weighted'``:
        Calculate metrics for each label, taking into account the
        prevalence of the classes.

sample_weight : array-like of shape (n_samples,) or None
    Sample weights.</pre> <div class="fragment"><div class="line"><span class="lineno">  591</span>):</div>
<div class="line"><span class="lineno">  592</span>    <span class="stringliteral">&quot;&quot;&quot;Multiclass roc auc score.</span></div>
<div class="line"><span class="lineno">  593</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  594</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  595</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  596</span><span class="stringliteral">    y_true : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  597</span><span class="stringliteral">        True multiclass labels.</span></div>
<div class="line"><span class="lineno">  598</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  599</span><span class="stringliteral">    y_score : array-like of shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  600</span><span class="stringliteral">        Target scores corresponding to probability estimates of a sample</span></div>
<div class="line"><span class="lineno">  601</span><span class="stringliteral">        belonging to a particular class</span></div>
<div class="line"><span class="lineno">  602</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  603</span><span class="stringliteral">    labels : array-like of shape (n_classes,) or None</span></div>
<div class="line"><span class="lineno">  604</span><span class="stringliteral">        List of labels to index ``y_score`` used for multiclass. If ``None``,</span></div>
<div class="line"><span class="lineno">  605</span><span class="stringliteral">        the lexical order of ``y_true`` is used to index ``y_score``.</span></div>
<div class="line"><span class="lineno">  606</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  607</span><span class="stringliteral">    multi_class : {&#39;ovr&#39;, &#39;ovo&#39;}</span></div>
<div class="line"><span class="lineno">  608</span><span class="stringliteral">        Determines the type of multiclass configuration to use.</span></div>
<div class="line"><span class="lineno">  609</span><span class="stringliteral">        ``&#39;ovr&#39;``:</span></div>
<div class="line"><span class="lineno">  610</span><span class="stringliteral">            Calculate metrics for the multiclass case using the one-vs-rest</span></div>
<div class="line"><span class="lineno">  611</span><span class="stringliteral">            approach.</span></div>
<div class="line"><span class="lineno">  612</span><span class="stringliteral">        ``&#39;ovo&#39;``:</span></div>
<div class="line"><span class="lineno">  613</span><span class="stringliteral">            Calculate metrics for the multiclass case using the one-vs-one</span></div>
<div class="line"><span class="lineno">  614</span><span class="stringliteral">            approach.</span></div>
<div class="line"><span class="lineno">  615</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  616</span><span class="stringliteral">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;weighted&#39;}</span></div>
<div class="line"><span class="lineno">  617</span><span class="stringliteral">        Determines the type of averaging performed on the pairwise binary</span></div>
<div class="line"><span class="lineno">  618</span><span class="stringliteral">        metric scores</span></div>
<div class="line"><span class="lineno">  619</span><span class="stringliteral">        ``&#39;micro&#39;``:</span></div>
<div class="line"><span class="lineno">  620</span><span class="stringliteral">            Calculate metrics for the binarized-raveled classes. Only supported</span></div>
<div class="line"><span class="lineno">  621</span><span class="stringliteral">            for `multi_class=&#39;ovr&#39;`.</span></div>
<div class="line"><span class="lineno">  622</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  623</span><span class="stringliteral">        .. versionadded:: 1.2</span></div>
<div class="line"><span class="lineno">  624</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  625</span><span class="stringliteral">        ``&#39;macro&#39;``:</span></div>
<div class="line"><span class="lineno">  626</span><span class="stringliteral">            Calculate metrics for each label, and find their unweighted</span></div>
<div class="line"><span class="lineno">  627</span><span class="stringliteral">            mean. This does not take label imbalance into account. Classes</span></div>
<div class="line"><span class="lineno">  628</span><span class="stringliteral">            are assumed to be uniformly distributed.</span></div>
<div class="line"><span class="lineno">  629</span><span class="stringliteral">        ``&#39;weighted&#39;``:</span></div>
<div class="line"><span class="lineno">  630</span><span class="stringliteral">            Calculate metrics for each label, taking into account the</span></div>
<div class="line"><span class="lineno">  631</span><span class="stringliteral">            prevalence of the classes.</span></div>
<div class="line"><span class="lineno">  632</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  633</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,) or None</span></div>
<div class="line"><span class="lineno">  634</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  635</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  636</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  637</span>    <span class="comment"># validation of the input y_score</span></div>
<div class="line"><span class="lineno">  638</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.allclose(1, y_score.sum(axis=1)):</div>
<div class="line"><span class="lineno">  639</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  640</span>            <span class="stringliteral">&quot;Target scores need to be probabilities for multiclass &quot;</span></div>
<div class="line"><span class="lineno">  641</span>            <span class="stringliteral">&quot;roc_auc, i.e. they should sum up to 1.0 over classes&quot;</span></div>
<div class="line"><span class="lineno">  642</span>        )</div>
<div class="line"><span class="lineno">  643</span> </div>
<div class="line"><span class="lineno">  644</span>    <span class="comment"># validation for multiclass parameter specifications</span></div>
<div class="line"><span class="lineno">  645</span>    average_options = (<span class="stringliteral">&quot;macro&quot;</span>, <span class="stringliteral">&quot;weighted&quot;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  646</span>    <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;ovr&quot;</span>:</div>
<div class="line"><span class="lineno">  647</span>        average_options = (<span class="stringliteral">&quot;micro&quot;</span>,) + average_options</div>
<div class="line"><span class="lineno">  648</span>    <span class="keywordflow">if</span> average <span class="keywordflow">not</span> <span class="keywordflow">in</span> average_options:</div>
<div class="line"><span class="lineno">  649</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  650</span>            <span class="stringliteral">&quot;average must be one of {0} for multiclass problems&quot;</span>.format(average_options)</div>
<div class="line"><span class="lineno">  651</span>        )</div>
<div class="line"><span class="lineno">  652</span> </div>
<div class="line"><span class="lineno">  653</span>    multiclass_options = (<span class="stringliteral">&quot;ovo&quot;</span>, <span class="stringliteral">&quot;ovr&quot;</span>)</div>
<div class="line"><span class="lineno">  654</span>    <span class="keywordflow">if</span> multi_class <span class="keywordflow">not</span> <span class="keywordflow">in</span> multiclass_options:</div>
<div class="line"><span class="lineno">  655</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  656</span>            <span class="stringliteral">&quot;multi_class=&#39;{0}&#39; is not supported &quot;</span></div>
<div class="line"><span class="lineno">  657</span>            <span class="stringliteral">&quot;for multiclass ROC AUC, multi_class must be &quot;</span></div>
<div class="line"><span class="lineno">  658</span>            <span class="stringliteral">&quot;in {1}&quot;</span>.format(multi_class, multiclass_options)</div>
<div class="line"><span class="lineno">  659</span>        )</div>
<div class="line"><span class="lineno">  660</span> </div>
<div class="line"><span class="lineno">  661</span>    <span class="keywordflow">if</span> average <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> multi_class == <span class="stringliteral">&quot;ovo&quot;</span>:</div>
<div class="line"><span class="lineno">  662</span>        <span class="keywordflow">raise</span> NotImplementedError(</div>
<div class="line"><span class="lineno">  663</span>            <span class="stringliteral">&quot;average=None is not implemented for multi_class=&#39;ovo&#39;.&quot;</span></div>
<div class="line"><span class="lineno">  664</span>        )</div>
<div class="line"><span class="lineno">  665</span> </div>
<div class="line"><span class="lineno">  666</span>    <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  667</span>        labels = column_or_1d(labels)</div>
<div class="line"><span class="lineno">  668</span>        classes = _unique(labels)</div>
<div class="line"><span class="lineno">  669</span>        <span class="keywordflow">if</span> len(classes) != len(labels):</div>
<div class="line"><span class="lineno">  670</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Parameter &#39;labels&#39; must be unique&quot;</span>)</div>
<div class="line"><span class="lineno">  671</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.array_equal(classes, labels):</div>
<div class="line"><span class="lineno">  672</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Parameter &#39;labels&#39; must be ordered&quot;</span>)</div>
<div class="line"><span class="lineno">  673</span>        <span class="keywordflow">if</span> len(classes) != y_score.shape[1]:</div>
<div class="line"><span class="lineno">  674</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  675</span>                <span class="stringliteral">&quot;Number of given labels, {0}, not equal to the number &quot;</span></div>
<div class="line"><span class="lineno">  676</span>                <span class="stringliteral">&quot;of columns in &#39;y_score&#39;, {1}&quot;</span>.format(len(classes), y_score.shape[1])</div>
<div class="line"><span class="lineno">  677</span>            )</div>
<div class="line"><span class="lineno">  678</span>        <span class="keywordflow">if</span> len(np.setdiff1d(y_true, classes)):</div>
<div class="line"><span class="lineno">  679</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;&#39;y_true&#39; contains labels not in parameter &#39;labels&#39;&quot;</span>)</div>
<div class="line"><span class="lineno">  680</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  681</span>        classes = _unique(y_true)</div>
<div class="line"><span class="lineno">  682</span>        <span class="keywordflow">if</span> len(classes) != y_score.shape[1]:</div>
<div class="line"><span class="lineno">  683</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  684</span>                <span class="stringliteral">&quot;Number of classes in y_true not equal to the number of &quot;</span></div>
<div class="line"><span class="lineno">  685</span>                <span class="stringliteral">&quot;columns in &#39;y_score&#39;&quot;</span></div>
<div class="line"><span class="lineno">  686</span>            )</div>
<div class="line"><span class="lineno">  687</span> </div>
<div class="line"><span class="lineno">  688</span>    <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;ovo&quot;</span>:</div>
<div class="line"><span class="lineno">  689</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  690</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  691</span>                <span class="stringliteral">&quot;sample_weight is not supported &quot;</span></div>
<div class="line"><span class="lineno">  692</span>                <span class="stringliteral">&quot;for multiclass one-vs-one ROC AUC, &quot;</span></div>
<div class="line"><span class="lineno">  693</span>                <span class="stringliteral">&quot;&#39;sample_weight&#39; must be None in this case.&quot;</span></div>
<div class="line"><span class="lineno">  694</span>            )</div>
<div class="line"><span class="lineno">  695</span>        y_true_encoded = _encode(y_true, uniques=classes)</div>
<div class="line"><span class="lineno">  696</span>        <span class="comment"># Hand &amp; Till (2001) implementation (ovo)</span></div>
<div class="line"><span class="lineno">  697</span>        <span class="keywordflow">return</span> _average_multiclass_ovo_score(</div>
<div class="line"><span class="lineno">  698</span>            _binary_roc_auc_score, y_true_encoded, y_score, average=average</div>
<div class="line"><span class="lineno">  699</span>        )</div>
<div class="line"><span class="lineno">  700</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  701</span>        <span class="comment"># ovr is same as multi-label</span></div>
<div class="line"><span class="lineno">  702</span>        y_true_multilabel = label_binarize(y_true, classes=classes)</div>
<div class="line"><span class="lineno">  703</span>        <span class="keywordflow">return</span> _average_binary_score(</div>
<div class="line"><span class="lineno">  704</span>            _binary_roc_auc_score,</div>
<div class="line"><span class="lineno">  705</span>            y_true_multilabel,</div>
<div class="line"><span class="lineno">  706</span>            y_score,</div>
<div class="line"><span class="lineno">  707</span>            average,</div>
<div class="line"><span class="lineno">  708</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  709</span>        )</div>
<div class="line"><span class="lineno">  710</span> </div>
<div class="line"><span class="lineno">  711</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afe101238e730ad16a031adc79bcbcfd1" name="afe101238e730ad16a031adc79bcbcfd1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe101238e730ad16a031adc79bcbcfd1">&#9670;&#160;</a></span>_ndcg_sample_scores()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking._ndcg_sample_scores </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>k</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ignore_ties</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute Normalized Discounted Cumulative Gain.

Sum the true scores ranked in the order induced by the predicted scores,
after applying a logarithmic discount. Then divide by the best possible
score (Ideal DCG, obtained for a perfect ranking) to obtain a score between
0 and 1.

This ranking metric yields a high value if true labels are ranked high by
``y_score``.

Parameters
----------
y_true : ndarray of shape (n_samples, n_labels)
    True targets of multilabel classification, or true scores of entities
    to be ranked.

y_score : ndarray of shape (n_samples, n_labels)
    Target scores, can either be probability estimates, confidence values,
    or non-thresholded measure of decisions (as returned by
    "decision_function" on some classifiers).

k : int, default=None
    Only consider the highest k scores in the ranking. If None, use all
    outputs.

ignore_ties : bool, default=False
    Assume that there are no ties in y_score (which is likely to be the
    case if y_score is continuous) for efficiency gains.

Returns
-------
normalized_discounted_cumulative_gain : ndarray of shape (n_samples,)
    The NDCG score for each sample (float in [0., 1.]).

See Also
--------
dcg_score : Discounted Cumulative Gain (not normalized).</pre> <div class="fragment"><div class="line"><span class="lineno"> 1504</span><span class="keyword">def </span>_ndcg_sample_scores(y_true, y_score, k=None, ignore_ties=False):</div>
<div class="line"><span class="lineno"> 1505</span>    <span class="stringliteral">&quot;&quot;&quot;Compute Normalized Discounted Cumulative Gain.</span></div>
<div class="line"><span class="lineno"> 1506</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1507</span><span class="stringliteral">    Sum the true scores ranked in the order induced by the predicted scores,</span></div>
<div class="line"><span class="lineno"> 1508</span><span class="stringliteral">    after applying a logarithmic discount. Then divide by the best possible</span></div>
<div class="line"><span class="lineno"> 1509</span><span class="stringliteral">    score (Ideal DCG, obtained for a perfect ranking) to obtain a score between</span></div>
<div class="line"><span class="lineno"> 1510</span><span class="stringliteral">    0 and 1.</span></div>
<div class="line"><span class="lineno"> 1511</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1512</span><span class="stringliteral">    This ranking metric yields a high value if true labels are ranked high by</span></div>
<div class="line"><span class="lineno"> 1513</span><span class="stringliteral">    ``y_score``.</span></div>
<div class="line"><span class="lineno"> 1514</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1515</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1516</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1517</span><span class="stringliteral">    y_true : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1518</span><span class="stringliteral">        True targets of multilabel classification, or true scores of entities</span></div>
<div class="line"><span class="lineno"> 1519</span><span class="stringliteral">        to be ranked.</span></div>
<div class="line"><span class="lineno"> 1520</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1521</span><span class="stringliteral">    y_score : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1522</span><span class="stringliteral">        Target scores, can either be probability estimates, confidence values,</span></div>
<div class="line"><span class="lineno"> 1523</span><span class="stringliteral">        or non-thresholded measure of decisions (as returned by</span></div>
<div class="line"><span class="lineno"> 1524</span><span class="stringliteral">        &quot;decision_function&quot; on some classifiers).</span></div>
<div class="line"><span class="lineno"> 1525</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1526</span><span class="stringliteral">    k : int, default=None</span></div>
<div class="line"><span class="lineno"> 1527</span><span class="stringliteral">        Only consider the highest k scores in the ranking. If None, use all</span></div>
<div class="line"><span class="lineno"> 1528</span><span class="stringliteral">        outputs.</span></div>
<div class="line"><span class="lineno"> 1529</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1530</span><span class="stringliteral">    ignore_ties : bool, default=False</span></div>
<div class="line"><span class="lineno"> 1531</span><span class="stringliteral">        Assume that there are no ties in y_score (which is likely to be the</span></div>
<div class="line"><span class="lineno"> 1532</span><span class="stringliteral">        case if y_score is continuous) for efficiency gains.</span></div>
<div class="line"><span class="lineno"> 1533</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1534</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1535</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1536</span><span class="stringliteral">    normalized_discounted_cumulative_gain : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1537</span><span class="stringliteral">        The NDCG score for each sample (float in [0., 1.]).</span></div>
<div class="line"><span class="lineno"> 1538</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1539</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 1540</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1541</span><span class="stringliteral">    dcg_score : Discounted Cumulative Gain (not normalized).</span></div>
<div class="line"><span class="lineno"> 1542</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1543</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1544</span>    gain = _dcg_sample_scores(y_true, y_score, k, ignore_ties=ignore_ties)</div>
<div class="line"><span class="lineno"> 1545</span>    <span class="comment"># Here we use the order induced by y_true so we can ignore ties since</span></div>
<div class="line"><span class="lineno"> 1546</span>    <span class="comment"># the gain associated to tied indices is the same (permuting ties doesn&#39;t</span></div>
<div class="line"><span class="lineno"> 1547</span>    <span class="comment"># change the value of the re-ordered y_true)</span></div>
<div class="line"><span class="lineno"> 1548</span>    normalizing_gain = _dcg_sample_scores(y_true, y_true, k, ignore_ties=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1549</span>    all_irrelevant = normalizing_gain == 0</div>
<div class="line"><span class="lineno"> 1550</span>    gain[all_irrelevant] = 0</div>
<div class="line"><span class="lineno"> 1551</span>    gain[~all_irrelevant] /= normalizing_gain[~all_irrelevant]</div>
<div class="line"><span class="lineno"> 1552</span>    <span class="keywordflow">return</span> gain</div>
<div class="line"><span class="lineno"> 1553</span> </div>
<div class="line"><span class="lineno"> 1554</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1f450180af70ebb947a8851e749f4769" name="a1f450180af70ebb947a8851e749f4769"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f450180af70ebb947a8851e749f4769">&#9670;&#160;</a></span>_tie_averaged_dcg()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking._tie_averaged_dcg </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>discount_cumsum</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute DCG by averaging over possible permutations of ties.

The gain (`y_true`) of an index falling inside a tied group (in the order
induced by `y_score`) is replaced by the average gain within this group.
The discounted gain for a tied group is then the average `y_true` within
this group times the sum of discounts of the corresponding ranks.

This amounts to averaging scores for all possible orderings of the tied
groups.

(note in the case of dcg@k the discount is 0 after index k)

Parameters
----------
y_true : ndarray
    The true relevance scores.

y_score : ndarray
    Predicted scores.

discount_cumsum : ndarray
    Precomputed cumulative sum of the discounts.

Returns
-------
discounted_cumulative_gain : float
    The discounted cumulative gain.

References
----------
McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval
performance measures efficiently in the presence of tied scores. In
European conference on information retrieval (pp. 414-421). Springer,
Berlin, Heidelberg.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1334</span><span class="keyword">def </span>_tie_averaged_dcg(y_true, y_score, discount_cumsum):</div>
<div class="line"><span class="lineno"> 1335</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1336</span><span class="stringliteral">    Compute DCG by averaging over possible permutations of ties.</span></div>
<div class="line"><span class="lineno"> 1337</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1338</span><span class="stringliteral">    The gain (`y_true`) of an index falling inside a tied group (in the order</span></div>
<div class="line"><span class="lineno"> 1339</span><span class="stringliteral">    induced by `y_score`) is replaced by the average gain within this group.</span></div>
<div class="line"><span class="lineno"> 1340</span><span class="stringliteral">    The discounted gain for a tied group is then the average `y_true` within</span></div>
<div class="line"><span class="lineno"> 1341</span><span class="stringliteral">    this group times the sum of discounts of the corresponding ranks.</span></div>
<div class="line"><span class="lineno"> 1342</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1343</span><span class="stringliteral">    This amounts to averaging scores for all possible orderings of the tied</span></div>
<div class="line"><span class="lineno"> 1344</span><span class="stringliteral">    groups.</span></div>
<div class="line"><span class="lineno"> 1345</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1346</span><span class="stringliteral">    (note in the case of dcg@k the discount is 0 after index k)</span></div>
<div class="line"><span class="lineno"> 1347</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1348</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1349</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1350</span><span class="stringliteral">    y_true : ndarray</span></div>
<div class="line"><span class="lineno"> 1351</span><span class="stringliteral">        The true relevance scores.</span></div>
<div class="line"><span class="lineno"> 1352</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1353</span><span class="stringliteral">    y_score : ndarray</span></div>
<div class="line"><span class="lineno"> 1354</span><span class="stringliteral">        Predicted scores.</span></div>
<div class="line"><span class="lineno"> 1355</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1356</span><span class="stringliteral">    discount_cumsum : ndarray</span></div>
<div class="line"><span class="lineno"> 1357</span><span class="stringliteral">        Precomputed cumulative sum of the discounts.</span></div>
<div class="line"><span class="lineno"> 1358</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1359</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1360</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1361</span><span class="stringliteral">    discounted_cumulative_gain : float</span></div>
<div class="line"><span class="lineno"> 1362</span><span class="stringliteral">        The discounted cumulative gain.</span></div>
<div class="line"><span class="lineno"> 1363</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1364</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1365</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1366</span><span class="stringliteral">    McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval</span></div>
<div class="line"><span class="lineno"> 1367</span><span class="stringliteral">    performance measures efficiently in the presence of tied scores. In</span></div>
<div class="line"><span class="lineno"> 1368</span><span class="stringliteral">    European conference on information retrieval (pp. 414-421). Springer,</span></div>
<div class="line"><span class="lineno"> 1369</span><span class="stringliteral">    Berlin, Heidelberg.</span></div>
<div class="line"><span class="lineno"> 1370</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1371</span>    _, inv, counts = np.unique(-y_score, return_inverse=<span class="keyword">True</span>, return_counts=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1372</span>    ranked = np.zeros(len(counts))</div>
<div class="line"><span class="lineno"> 1373</span>    np.add.at(ranked, inv, y_true)</div>
<div class="line"><span class="lineno"> 1374</span>    ranked /= counts</div>
<div class="line"><span class="lineno"> 1375</span>    groups = np.cumsum(counts) - 1</div>
<div class="line"><span class="lineno"> 1376</span>    discount_sums = np.empty(len(counts))</div>
<div class="line"><span class="lineno"> 1377</span>    discount_sums[0] = discount_cumsum[groups[0]]</div>
<div class="line"><span class="lineno"> 1378</span>    discount_sums[1:] = np.diff(discount_cumsum[groups])</div>
<div class="line"><span class="lineno"> 1379</span>    <span class="keywordflow">return</span> (ranked * discount_sums).sum()</div>
<div class="line"><span class="lineno"> 1380</span> </div>
<div class="line"><span class="lineno"> 1381</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2c4c6b34503f6764ceeec4034849e554" name="a2c4c6b34503f6764ceeec4034849e554"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2c4c6b34503f6764ceeec4034849e554">&#9670;&#160;</a></span>auc()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.auc </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute Area Under the Curve (AUC) using the trapezoidal rule.

This is a general function, given points on a curve.  For computing the
area under the ROC-curve, see :func:`roc_auc_score`.  For an alternative
way to summarize a precision-recall curve, see
:func:`average_precision_score`.

Parameters
----------
x : ndarray of shape (n,)
    X coordinates. These must be either monotonic increasing or monotonic
    decreasing.
y : ndarray of shape, (n,)
    Y coordinates.

Returns
-------
auc : float
    Area Under the Curve.

See Also
--------
roc_auc_score : Compute the area under the ROC curve.
average_precision_score : Compute average precision from prediction scores.
precision_recall_curve : Compute precision-recall pairs for different
    probability thresholds.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn import metrics
&gt;&gt;&gt; y = np.array([1, 1, 2, 2])
&gt;&gt;&gt; pred = np.array([0.1, 0.4, 0.35, 0.8])
&gt;&gt;&gt; fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)
&gt;&gt;&gt; metrics.auc(fpr, tpr)
0.75
</pre> <div class="fragment"><div class="line"><span class="lineno">   47</span><span class="keyword">def </span>auc(x, y):</div>
<div class="line"><span class="lineno">   48</span>    <span class="stringliteral">&quot;&quot;&quot;Compute Area Under the Curve (AUC) using the trapezoidal rule.</span></div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">    This is a general function, given points on a curve.  For computing the</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral">    area under the ROC-curve, see :func:`roc_auc_score`.  For an alternative</span></div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">    way to summarize a precision-recall curve, see</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">    :func:`average_precision_score`.</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral">    x : ndarray of shape (n,)</span></div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral">        X coordinates. These must be either monotonic increasing or monotonic</span></div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">        decreasing.</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">    y : ndarray of shape, (n,)</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral">        Y coordinates.</span></div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">    auc : float</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">        Area Under the Curve.</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    roc_auc_score : Compute the area under the ROC curve.</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">    average_precision_score : Compute average precision from prediction scores.</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">    precision_recall_curve : Compute precision-recall pairs for different</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">        probability thresholds.</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn import metrics</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">    &gt;&gt;&gt; y = np.array([1, 1, 2, 2])</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">    &gt;&gt;&gt; pred = np.array([0.1, 0.4, 0.35, 0.8])</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral">    &gt;&gt;&gt; fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)</span></div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">    &gt;&gt;&gt; metrics.auc(fpr, tpr)</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">    0.75</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   85</span>    check_consistent_length(x, y)</div>
<div class="line"><span class="lineno">   86</span>    x = column_or_1d(x)</div>
<div class="line"><span class="lineno">   87</span>    y = column_or_1d(y)</div>
<div class="line"><span class="lineno">   88</span> </div>
<div class="line"><span class="lineno">   89</span>    <span class="keywordflow">if</span> x.shape[0] &lt; 2:</div>
<div class="line"><span class="lineno">   90</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">   91</span>            <span class="stringliteral">&quot;At least 2 points are needed to compute area under curve, but x.shape = %s&quot;</span></div>
<div class="line"><span class="lineno">   92</span>            % x.shape</div>
<div class="line"><span class="lineno">   93</span>        )</div>
<div class="line"><span class="lineno">   94</span> </div>
<div class="line"><span class="lineno">   95</span>    direction = 1</div>
<div class="line"><span class="lineno">   96</span>    dx = np.diff(x)</div>
<div class="line"><span class="lineno">   97</span>    <span class="keywordflow">if</span> np.any(dx &lt; 0):</div>
<div class="line"><span class="lineno">   98</span>        <span class="keywordflow">if</span> np.all(dx &lt;= 0):</div>
<div class="line"><span class="lineno">   99</span>            direction = -1</div>
<div class="line"><span class="lineno">  100</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  101</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;x is neither increasing nor decreasing : {}.&quot;</span>.format(x))</div>
<div class="line"><span class="lineno">  102</span> </div>
<div class="line"><span class="lineno">  103</span>    area = direction * np.trapz(y, x)</div>
<div class="line"><span class="lineno">  104</span>    <span class="keywordflow">if</span> isinstance(area, np.memmap):</div>
<div class="line"><span class="lineno">  105</span>        <span class="comment"># Reductions such as .sum used internally in np.trapz do not return a</span></div>
<div class="line"><span class="lineno">  106</span>        <span class="comment"># scalar by default for numpy.memmap instances contrary to</span></div>
<div class="line"><span class="lineno">  107</span>        <span class="comment"># regular numpy.ndarray instances.</span></div>
<div class="line"><span class="lineno">  108</span>        area = area.dtype.type(area)</div>
<div class="line"><span class="lineno">  109</span>    <span class="keywordflow">return</span> area</div>
<div class="line"><span class="lineno">  110</span> </div>
<div class="line"><span class="lineno">  111</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2ec8c184525183e3f42d7fcbcbf53ce5" name="a2ec8c184525183e3f42d7fcbcbf53ce5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2ec8c184525183e3f42d7fcbcbf53ce5">&#9670;&#160;</a></span>average_precision_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.average_precision_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>average</em> = <code>&quot;macro&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute average precision (AP) from prediction scores.

AP summarizes a precision-recall curve as the weighted mean of precisions
achieved at each threshold, with the increase in recall from the previous
threshold used as the weight:

.. math::
    \\text{AP} = \\sum_n (R_n - R_{n-1}) P_n

where :math:`P_n` and :math:`R_n` are the precision and recall at the nth
threshold [1]_. This implementation is not interpolated and is different
from computing the area under the precision-recall curve with the
trapezoidal rule, which uses linear interpolation and can be too
optimistic.

Note: this implementation is restricted to the binary classification task
or multilabel classification task.

Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.

Parameters
----------
y_true : ndarray of shape (n_samples,) or (n_samples, n_classes)
    True binary labels or binary label indicators.

y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by :term:`decision_function` on some classifiers).

average : {'micro', 'samples', 'weighted', 'macro'} or None, \
        default='macro'
    If ``None``, the scores for each class are returned. Otherwise,
    this determines the type of averaging performed on the data:

    ``'micro'``:
        Calculate metrics globally by considering each element of the label
        indicator matrix as a label.
    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    ``'weighted'``:
        Calculate metrics for each label, and find their average, weighted
        by support (the number of true instances for each label).
    ``'samples'``:
        Calculate metrics for each instance, and find their average.

    Will be ignored when ``y_true`` is binary.

pos_label : int or str, default=1
    The label of the positive class. Only applied to binary ``y_true``.
    For multilabel-indicator ``y_true``, ``pos_label`` is fixed to 1.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
average_precision : float
    Average precision score.

See Also
--------
roc_auc_score : Compute the area under the ROC curve.
precision_recall_curve : Compute precision-recall pairs for different
    probability thresholds.

Notes
-----
.. versionchanged:: 0.19
  Instead of linearly interpolating between operating points, precisions
  are weighted by the change in recall since the last operating point.

References
----------
.. [1] `Wikipedia entry for the Average precision
       &lt;https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;
       oldid=793358396#Average_precision&gt;`_

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import average_precision_score
&gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])
&gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])
&gt;&gt;&gt; average_precision_score(y_true, y_scores)
0.83...
</pre> <div class="fragment"><div class="line"><span class="lineno">  114</span>):</div>
<div class="line"><span class="lineno">  115</span>    <span class="stringliteral">&quot;&quot;&quot;Compute average precision (AP) from prediction scores.</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">    AP summarizes a precision-recall curve as the weighted mean of precisions</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">    achieved at each threshold, with the increase in recall from the previous</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral">    threshold used as the weight:</span></div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral">    .. math::</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">        \\text{AP} = \\sum_n (R_n - R_{n-1}) P_n</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">    where :math:`P_n` and :math:`R_n` are the precision and recall at the nth</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral">    threshold [1]_. This implementation is not interpolated and is different</span></div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral">    from computing the area under the precision-recall curve with the</span></div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral">    trapezoidal rule, which uses linear interpolation and can be too</span></div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral">    optimistic.</span></div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral">    Note: this implementation is restricted to the binary classification task</span></div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">    or multilabel classification task.</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">    y_true : ndarray of shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">        True binary labels or binary label indicators.</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">    y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">        Target scores, can either be probability estimates of the positive</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">        class, confidence values, or non-thresholded measure of decisions</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">        (as returned by :term:`decision_function` on some classifiers).</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">    average : {&#39;micro&#39;, &#39;samples&#39;, &#39;weighted&#39;, &#39;macro&#39;} or None, \</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">            default=&#39;macro&#39;</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">        If ``None``, the scores for each class are returned. Otherwise,</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">        this determines the type of averaging performed on the data:</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">        ``&#39;micro&#39;``:</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">            Calculate metrics globally by considering each element of the label</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">            indicator matrix as a label.</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">        ``&#39;macro&#39;``:</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">            Calculate metrics for each label, and find their unweighted</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">            mean.  This does not take label imbalance into account.</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">        ``&#39;weighted&#39;``:</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">            Calculate metrics for each label, and find their average, weighted</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">            by support (the number of true instances for each label).</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">        ``&#39;samples&#39;``:</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">            Calculate metrics for each instance, and find their average.</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">        Will be ignored when ``y_true`` is binary.</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">    pos_label : int or str, default=1</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">        The label of the positive class. Only applied to binary ``y_true``.</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">        For multilabel-indicator ``y_true``, ``pos_label`` is fixed to 1.</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">    average_precision : float</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">        Average precision score.</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral">    roc_auc_score : Compute the area under the ROC curve.</span></div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">    precision_recall_curve : Compute precision-recall pairs for different</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">        probability thresholds.</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral">    .. versionchanged:: 0.19</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">      Instead of linearly interpolating between operating points, precisions</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">      are weighted by the change in recall since the last operating point.</span></div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral">    .. [1] `Wikipedia entry for the Average precision</span></div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral">           &lt;https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;</span></div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">           oldid=793358396#Average_precision&gt;`_</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import average_precision_score</span></div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])</span></div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">    &gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral">    &gt;&gt;&gt; average_precision_score(y_true, y_scores)</span></div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral">    0.83...</span></div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  203</span> </div>
<div class="line"><span class="lineno">  204</span>    <span class="keyword">def </span>_binary_uninterpolated_average_precision(</div>
<div class="line"><span class="lineno">  205</span>        y_true, y_score, pos_label=1, sample_weight=None</div>
<div class="line"><span class="lineno">  206</span>    ):</div>
<div class="line"><span class="lineno">  207</span>        precision, recall, _ = precision_recall_curve(</div>
<div class="line"><span class="lineno">  208</span>            y_true, y_score, pos_label=pos_label, sample_weight=sample_weight</div>
<div class="line"><span class="lineno">  209</span>        )</div>
<div class="line"><span class="lineno">  210</span>        <span class="comment"># Return the step function integral</span></div>
<div class="line"><span class="lineno">  211</span>        <span class="comment"># The following works because the last entry of precision is</span></div>
<div class="line"><span class="lineno">  212</span>        <span class="comment"># guaranteed to be 1, as returned by precision_recall_curve</span></div>
<div class="line"><span class="lineno">  213</span>        <span class="keywordflow">return</span> -np.sum(np.diff(recall) * np.array(precision)[:-1])</div>
<div class="line"><span class="lineno">  214</span> </div>
<div class="line"><span class="lineno">  215</span>    y_type = type_of_target(y_true, input_name=<span class="stringliteral">&quot;y_true&quot;</span>)</div>
<div class="line"><span class="lineno">  216</span>    <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;multilabel-indicator&quot;</span> <span class="keywordflow">and</span> pos_label != 1:</div>
<div class="line"><span class="lineno">  217</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  218</span>            <span class="stringliteral">&quot;Parameter pos_label is fixed to 1 for &quot;</span></div>
<div class="line"><span class="lineno">  219</span>            <span class="stringliteral">&quot;multilabel-indicator y_true. Do not set &quot;</span></div>
<div class="line"><span class="lineno">  220</span>            <span class="stringliteral">&quot;pos_label or set pos_label to 1.&quot;</span></div>
<div class="line"><span class="lineno">  221</span>        )</div>
<div class="line"><span class="lineno">  222</span>    <span class="keywordflow">elif</span> y_type == <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno">  223</span>        <span class="comment"># Convert to Python primitive type to avoid NumPy type / Python str</span></div>
<div class="line"><span class="lineno">  224</span>        <span class="comment"># comparison. See https://github.com/numpy/numpy/issues/6784</span></div>
<div class="line"><span class="lineno">  225</span>        present_labels = np.unique(y_true).tolist()</div>
<div class="line"><span class="lineno">  226</span>        <span class="keywordflow">if</span> len(present_labels) == 2 <span class="keywordflow">and</span> pos_label <span class="keywordflow">not</span> <span class="keywordflow">in</span> present_labels:</div>
<div class="line"><span class="lineno">  227</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  228</span>                f<span class="stringliteral">&quot;pos_label={pos_label} is not a valid label. It should be &quot;</span></div>
<div class="line"><span class="lineno">  229</span>                f<span class="stringliteral">&quot;one of {present_labels}&quot;</span></div>
<div class="line"><span class="lineno">  230</span>            )</div>
<div class="line"><span class="lineno">  231</span>    average_precision = partial(</div>
<div class="line"><span class="lineno">  232</span>        _binary_uninterpolated_average_precision, pos_label=pos_label</div>
<div class="line"><span class="lineno">  233</span>    )</div>
<div class="line"><span class="lineno">  234</span>    <span class="keywordflow">return</span> _average_binary_score(</div>
<div class="line"><span class="lineno">  235</span>        average_precision, y_true, y_score, average, sample_weight=sample_weight</div>
<div class="line"><span class="lineno">  236</span>    )</div>
<div class="line"><span class="lineno">  237</span> </div>
<div class="line"><span class="lineno">  238</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa36e8f5c1f464a3913d18b6f5375ef9c" name="aa36e8f5c1f464a3913d18b6f5375ef9c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa36e8f5c1f464a3913d18b6f5375ef9c">&#9670;&#160;</a></span>coverage_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.coverage_error </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Coverage error measure.

Compute how far we need to go through the ranked scores to cover all
true labels. The best value is equal to the average number
of labels in ``y_true`` per sample.

Ties in ``y_scores`` are broken by giving maximal rank that would have
been assigned to all tied values.

Note: Our implementation's score is 1 greater than the one given in
Tsoumakas et al., 2010. This extends it to handle the degenerate case
in which an instance has 0 true labels.

Read more in the :ref:`User Guide &lt;coverage_error&gt;`.

Parameters
----------
y_true : ndarray of shape (n_samples, n_labels)
    True binary labels in binary indicator format.

y_score : ndarray of shape (n_samples, n_labels)
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by "decision_function" on some classifiers).

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
coverage_error : float
    The coverage error.

References
----------
.. [1] Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2010).
       Mining multi-label data. In Data mining and knowledge discovery
       handbook (pp. 667-685). Springer US.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1131</span><span class="keyword">def </span>coverage_error(y_true, y_score, *, sample_weight=None):</div>
<div class="line"><span class="lineno"> 1132</span>    <span class="stringliteral">&quot;&quot;&quot;Coverage error measure.</span></div>
<div class="line"><span class="lineno"> 1133</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1134</span><span class="stringliteral">    Compute how far we need to go through the ranked scores to cover all</span></div>
<div class="line"><span class="lineno"> 1135</span><span class="stringliteral">    true labels. The best value is equal to the average number</span></div>
<div class="line"><span class="lineno"> 1136</span><span class="stringliteral">    of labels in ``y_true`` per sample.</span></div>
<div class="line"><span class="lineno"> 1137</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1138</span><span class="stringliteral">    Ties in ``y_scores`` are broken by giving maximal rank that would have</span></div>
<div class="line"><span class="lineno"> 1139</span><span class="stringliteral">    been assigned to all tied values.</span></div>
<div class="line"><span class="lineno"> 1140</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1141</span><span class="stringliteral">    Note: Our implementation&#39;s score is 1 greater than the one given in</span></div>
<div class="line"><span class="lineno"> 1142</span><span class="stringliteral">    Tsoumakas et al., 2010. This extends it to handle the degenerate case</span></div>
<div class="line"><span class="lineno"> 1143</span><span class="stringliteral">    in which an instance has 0 true labels.</span></div>
<div class="line"><span class="lineno"> 1144</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1145</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;coverage_error&gt;`.</span></div>
<div class="line"><span class="lineno"> 1146</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1147</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1148</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1149</span><span class="stringliteral">    y_true : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1150</span><span class="stringliteral">        True binary labels in binary indicator format.</span></div>
<div class="line"><span class="lineno"> 1151</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1152</span><span class="stringliteral">    y_score : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1153</span><span class="stringliteral">        Target scores, can either be probability estimates of the positive</span></div>
<div class="line"><span class="lineno"> 1154</span><span class="stringliteral">        class, confidence values, or non-thresholded measure of decisions</span></div>
<div class="line"><span class="lineno"> 1155</span><span class="stringliteral">        (as returned by &quot;decision_function&quot; on some classifiers).</span></div>
<div class="line"><span class="lineno"> 1156</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1157</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1158</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1159</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1160</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1161</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1162</span><span class="stringliteral">    coverage_error : float</span></div>
<div class="line"><span class="lineno"> 1163</span><span class="stringliteral">        The coverage error.</span></div>
<div class="line"><span class="lineno"> 1164</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1165</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1166</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1167</span><span class="stringliteral">    .. [1] Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2010).</span></div>
<div class="line"><span class="lineno"> 1168</span><span class="stringliteral">           Mining multi-label data. In Data mining and knowledge discovery</span></div>
<div class="line"><span class="lineno"> 1169</span><span class="stringliteral">           handbook (pp. 667-685). Springer US.</span></div>
<div class="line"><span class="lineno"> 1170</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1171</span>    y_true = check_array(y_true, ensure_2d=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1172</span>    y_score = check_array(y_score, ensure_2d=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1173</span>    check_consistent_length(y_true, y_score, sample_weight)</div>
<div class="line"><span class="lineno"> 1174</span> </div>
<div class="line"><span class="lineno"> 1175</span>    y_type = type_of_target(y_true, input_name=<span class="stringliteral">&quot;y_true&quot;</span>)</div>
<div class="line"><span class="lineno"> 1176</span>    <span class="keywordflow">if</span> y_type != <span class="stringliteral">&quot;multilabel-indicator&quot;</span>:</div>
<div class="line"><span class="lineno"> 1177</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;{0} format is not supported&quot;</span>.format(y_type))</div>
<div class="line"><span class="lineno"> 1178</span> </div>
<div class="line"><span class="lineno"> 1179</span>    <span class="keywordflow">if</span> y_true.shape != y_score.shape:</div>
<div class="line"><span class="lineno"> 1180</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;y_true and y_score have different shape&quot;</span>)</div>
<div class="line"><span class="lineno"> 1181</span> </div>
<div class="line"><span class="lineno"> 1182</span>    y_score_mask = np.ma.masked_array(y_score, mask=np.logical_not(y_true))</div>
<div class="line"><span class="lineno"> 1183</span>    y_min_relevant = y_score_mask.min(axis=1).reshape((-1, 1))</div>
<div class="line"><span class="lineno"> 1184</span>    coverage = (y_score &gt;= y_min_relevant).sum(axis=1)</div>
<div class="line"><span class="lineno"> 1185</span>    coverage = coverage.filled(0)</div>
<div class="line"><span class="lineno"> 1186</span> </div>
<div class="line"><span class="lineno"> 1187</span>    <span class="keywordflow">return</span> np.average(coverage, weights=sample_weight)</div>
<div class="line"><span class="lineno"> 1188</span> </div>
<div class="line"><span class="lineno"> 1189</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a34ff8c6be112f2758e73808a718ebc07" name="a34ff8c6be112f2758e73808a718ebc07"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34ff8c6be112f2758e73808a718ebc07">&#9670;&#160;</a></span>dcg_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.dcg_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>k</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>log_base</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ignore_ties</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute Discounted Cumulative Gain.

Sum the true scores ranked in the order induced by the predicted scores,
after applying a logarithmic discount.

This ranking metric yields a high value if true labels are ranked high by
``y_score``.

Usually the Normalized Discounted Cumulative Gain (NDCG, computed by
ndcg_score) is preferred.

Parameters
----------
y_true : ndarray of shape (n_samples, n_labels)
    True targets of multilabel classification, or true scores of entities
    to be ranked.

y_score : ndarray of shape (n_samples, n_labels)
    Target scores, can either be probability estimates, confidence values,
    or non-thresholded measure of decisions (as returned by
    "decision_function" on some classifiers).

k : int, default=None
    Only consider the highest k scores in the ranking. If None, use all
    outputs.

log_base : float, default=2
    Base of the logarithm used for the discount. A low value means a
    sharper discount (top results are more important).

sample_weight : ndarray of shape (n_samples,), default=None
    Sample weights. If `None`, all samples are given the same weight.

ignore_ties : bool, default=False
    Assume that there are no ties in y_score (which is likely to be the
    case if y_score is continuous) for efficiency gains.

Returns
-------
discounted_cumulative_gain : float
    The averaged sample DCG scores.

See Also
--------
ndcg_score : The Discounted Cumulative Gain divided by the Ideal Discounted
    Cumulative Gain (the DCG obtained for a perfect ranking), in order to
    have a score between 0 and 1.

References
----------
`Wikipedia entry for Discounted Cumulative Gain
&lt;https://en.wikipedia.org/wiki/Discounted_cumulative_gain&gt;`_.

Jarvelin, K., &amp; Kekalainen, J. (2002).
Cumulated gain-based evaluation of IR techniques. ACM Transactions on
Information Systems (TOIS), 20(4), 422-446.

Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp; Liu, T. Y. (2013, May).
A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th
Annual Conference on Learning Theory (COLT 2013).

McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval
performance measures efficiently in the presence of tied scores. In
European conference on information retrieval (pp. 414-421). Springer,
Berlin, Heidelberg.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import dcg_score
&gt;&gt;&gt; # we have groud-truth relevance of some answers to a query:
&gt;&gt;&gt; true_relevance = np.asarray([[10, 0, 0, 1, 5]])
&gt;&gt;&gt; # we predict scores for the answers
&gt;&gt;&gt; scores = np.asarray([[.1, .2, .3, 4, 70]])
&gt;&gt;&gt; dcg_score(true_relevance, scores)
9.49...
&gt;&gt;&gt; # we can set k to truncate the sum; only top k answers contribute
&gt;&gt;&gt; dcg_score(true_relevance, scores, k=2)
5.63...
&gt;&gt;&gt; # now we have some ties in our prediction
&gt;&gt;&gt; scores = np.asarray([[1, 0, 0, 0, 1]])
&gt;&gt;&gt; # by default ties are averaged, so here we get the average true
&gt;&gt;&gt; # relevance of our top predictions: (10 + 5) / 2 = 7.5
&gt;&gt;&gt; dcg_score(true_relevance, scores, k=1)
7.5
&gt;&gt;&gt; # we can choose to ignore ties for faster results, but only
&gt;&gt;&gt; # if we know there aren't ties in our scores, otherwise we get
&gt;&gt;&gt; # wrong results:
&gt;&gt;&gt; dcg_score(true_relevance,
...           scores, k=1, ignore_ties=True)
5.0
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1399</span>):</div>
<div class="line"><span class="lineno"> 1400</span>    <span class="stringliteral">&quot;&quot;&quot;Compute Discounted Cumulative Gain.</span></div>
<div class="line"><span class="lineno"> 1401</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1402</span><span class="stringliteral">    Sum the true scores ranked in the order induced by the predicted scores,</span></div>
<div class="line"><span class="lineno"> 1403</span><span class="stringliteral">    after applying a logarithmic discount.</span></div>
<div class="line"><span class="lineno"> 1404</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1405</span><span class="stringliteral">    This ranking metric yields a high value if true labels are ranked high by</span></div>
<div class="line"><span class="lineno"> 1406</span><span class="stringliteral">    ``y_score``.</span></div>
<div class="line"><span class="lineno"> 1407</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1408</span><span class="stringliteral">    Usually the Normalized Discounted Cumulative Gain (NDCG, computed by</span></div>
<div class="line"><span class="lineno"> 1409</span><span class="stringliteral">    ndcg_score) is preferred.</span></div>
<div class="line"><span class="lineno"> 1410</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1411</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1412</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1413</span><span class="stringliteral">    y_true : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1414</span><span class="stringliteral">        True targets of multilabel classification, or true scores of entities</span></div>
<div class="line"><span class="lineno"> 1415</span><span class="stringliteral">        to be ranked.</span></div>
<div class="line"><span class="lineno"> 1416</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1417</span><span class="stringliteral">    y_score : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1418</span><span class="stringliteral">        Target scores, can either be probability estimates, confidence values,</span></div>
<div class="line"><span class="lineno"> 1419</span><span class="stringliteral">        or non-thresholded measure of decisions (as returned by</span></div>
<div class="line"><span class="lineno"> 1420</span><span class="stringliteral">        &quot;decision_function&quot; on some classifiers).</span></div>
<div class="line"><span class="lineno"> 1421</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1422</span><span class="stringliteral">    k : int, default=None</span></div>
<div class="line"><span class="lineno"> 1423</span><span class="stringliteral">        Only consider the highest k scores in the ranking. If None, use all</span></div>
<div class="line"><span class="lineno"> 1424</span><span class="stringliteral">        outputs.</span></div>
<div class="line"><span class="lineno"> 1425</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1426</span><span class="stringliteral">    log_base : float, default=2</span></div>
<div class="line"><span class="lineno"> 1427</span><span class="stringliteral">        Base of the logarithm used for the discount. A low value means a</span></div>
<div class="line"><span class="lineno"> 1428</span><span class="stringliteral">        sharper discount (top results are more important).</span></div>
<div class="line"><span class="lineno"> 1429</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1430</span><span class="stringliteral">    sample_weight : ndarray of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1431</span><span class="stringliteral">        Sample weights. If `None`, all samples are given the same weight.</span></div>
<div class="line"><span class="lineno"> 1432</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1433</span><span class="stringliteral">    ignore_ties : bool, default=False</span></div>
<div class="line"><span class="lineno"> 1434</span><span class="stringliteral">        Assume that there are no ties in y_score (which is likely to be the</span></div>
<div class="line"><span class="lineno"> 1435</span><span class="stringliteral">        case if y_score is continuous) for efficiency gains.</span></div>
<div class="line"><span class="lineno"> 1436</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1437</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1438</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1439</span><span class="stringliteral">    discounted_cumulative_gain : float</span></div>
<div class="line"><span class="lineno"> 1440</span><span class="stringliteral">        The averaged sample DCG scores.</span></div>
<div class="line"><span class="lineno"> 1441</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1442</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 1443</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1444</span><span class="stringliteral">    ndcg_score : The Discounted Cumulative Gain divided by the Ideal Discounted</span></div>
<div class="line"><span class="lineno"> 1445</span><span class="stringliteral">        Cumulative Gain (the DCG obtained for a perfect ranking), in order to</span></div>
<div class="line"><span class="lineno"> 1446</span><span class="stringliteral">        have a score between 0 and 1.</span></div>
<div class="line"><span class="lineno"> 1447</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1448</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1449</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1450</span><span class="stringliteral">    `Wikipedia entry for Discounted Cumulative Gain</span></div>
<div class="line"><span class="lineno"> 1451</span><span class="stringliteral">    &lt;https://en.wikipedia.org/wiki/Discounted_cumulative_gain&gt;`_.</span></div>
<div class="line"><span class="lineno"> 1452</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1453</span><span class="stringliteral">    Jarvelin, K., &amp; Kekalainen, J. (2002).</span></div>
<div class="line"><span class="lineno"> 1454</span><span class="stringliteral">    Cumulated gain-based evaluation of IR techniques. ACM Transactions on</span></div>
<div class="line"><span class="lineno"> 1455</span><span class="stringliteral">    Information Systems (TOIS), 20(4), 422-446.</span></div>
<div class="line"><span class="lineno"> 1456</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1457</span><span class="stringliteral">    Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp; Liu, T. Y. (2013, May).</span></div>
<div class="line"><span class="lineno"> 1458</span><span class="stringliteral">    A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th</span></div>
<div class="line"><span class="lineno"> 1459</span><span class="stringliteral">    Annual Conference on Learning Theory (COLT 2013).</span></div>
<div class="line"><span class="lineno"> 1460</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1461</span><span class="stringliteral">    McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval</span></div>
<div class="line"><span class="lineno"> 1462</span><span class="stringliteral">    performance measures efficiently in the presence of tied scores. In</span></div>
<div class="line"><span class="lineno"> 1463</span><span class="stringliteral">    European conference on information retrieval (pp. 414-421). Springer,</span></div>
<div class="line"><span class="lineno"> 1464</span><span class="stringliteral">    Berlin, Heidelberg.</span></div>
<div class="line"><span class="lineno"> 1465</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1466</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1467</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1468</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno"> 1469</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import dcg_score</span></div>
<div class="line"><span class="lineno"> 1470</span><span class="stringliteral">    &gt;&gt;&gt; # we have groud-truth relevance of some answers to a query:</span></div>
<div class="line"><span class="lineno"> 1471</span><span class="stringliteral">    &gt;&gt;&gt; true_relevance = np.asarray([[10, 0, 0, 1, 5]])</span></div>
<div class="line"><span class="lineno"> 1472</span><span class="stringliteral">    &gt;&gt;&gt; # we predict scores for the answers</span></div>
<div class="line"><span class="lineno"> 1473</span><span class="stringliteral">    &gt;&gt;&gt; scores = np.asarray([[.1, .2, .3, 4, 70]])</span></div>
<div class="line"><span class="lineno"> 1474</span><span class="stringliteral">    &gt;&gt;&gt; dcg_score(true_relevance, scores)</span></div>
<div class="line"><span class="lineno"> 1475</span><span class="stringliteral">    9.49...</span></div>
<div class="line"><span class="lineno"> 1476</span><span class="stringliteral">    &gt;&gt;&gt; # we can set k to truncate the sum; only top k answers contribute</span></div>
<div class="line"><span class="lineno"> 1477</span><span class="stringliteral">    &gt;&gt;&gt; dcg_score(true_relevance, scores, k=2)</span></div>
<div class="line"><span class="lineno"> 1478</span><span class="stringliteral">    5.63...</span></div>
<div class="line"><span class="lineno"> 1479</span><span class="stringliteral">    &gt;&gt;&gt; # now we have some ties in our prediction</span></div>
<div class="line"><span class="lineno"> 1480</span><span class="stringliteral">    &gt;&gt;&gt; scores = np.asarray([[1, 0, 0, 0, 1]])</span></div>
<div class="line"><span class="lineno"> 1481</span><span class="stringliteral">    &gt;&gt;&gt; # by default ties are averaged, so here we get the average true</span></div>
<div class="line"><span class="lineno"> 1482</span><span class="stringliteral">    &gt;&gt;&gt; # relevance of our top predictions: (10 + 5) / 2 = 7.5</span></div>
<div class="line"><span class="lineno"> 1483</span><span class="stringliteral">    &gt;&gt;&gt; dcg_score(true_relevance, scores, k=1)</span></div>
<div class="line"><span class="lineno"> 1484</span><span class="stringliteral">    7.5</span></div>
<div class="line"><span class="lineno"> 1485</span><span class="stringliteral">    &gt;&gt;&gt; # we can choose to ignore ties for faster results, but only</span></div>
<div class="line"><span class="lineno"> 1486</span><span class="stringliteral">    &gt;&gt;&gt; # if we know there aren&#39;t ties in our scores, otherwise we get</span></div>
<div class="line"><span class="lineno"> 1487</span><span class="stringliteral">    &gt;&gt;&gt; # wrong results:</span></div>
<div class="line"><span class="lineno"> 1488</span><span class="stringliteral">    &gt;&gt;&gt; dcg_score(true_relevance,</span></div>
<div class="line"><span class="lineno"> 1489</span><span class="stringliteral">    ...           scores, k=1, ignore_ties=True)</span></div>
<div class="line"><span class="lineno"> 1490</span><span class="stringliteral">    5.0</span></div>
<div class="line"><span class="lineno"> 1491</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1492</span>    y_true = check_array(y_true, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1493</span>    y_score = check_array(y_score, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1494</span>    check_consistent_length(y_true, y_score, sample_weight)</div>
<div class="line"><span class="lineno"> 1495</span>    _check_dcg_target_type(y_true)</div>
<div class="line"><span class="lineno"> 1496</span>    <span class="keywordflow">return</span> np.average(</div>
<div class="line"><span class="lineno"> 1497</span>        _dcg_sample_scores(</div>
<div class="line"><span class="lineno"> 1498</span>            y_true, y_score, k=k, log_base=log_base, ignore_ties=ignore_ties</div>
<div class="line"><span class="lineno"> 1499</span>        ),</div>
<div class="line"><span class="lineno"> 1500</span>        weights=sample_weight,</div>
<div class="line"><span class="lineno"> 1501</span>    )</div>
<div class="line"><span class="lineno"> 1502</span> </div>
<div class="line"><span class="lineno"> 1503</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5a907ac7a1d46c9224c6eb531eb653f9" name="a5a907ac7a1d46c9224c6eb531eb653f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5a907ac7a1d46c9224c6eb531eb653f9">&#9670;&#160;</a></span>det_curve()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.det_curve </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute error rates for different probability thresholds.

.. note::
   This metric is used for evaluation of ranking and error tradeoffs of
   a binary classification task.

Read more in the :ref:`User Guide &lt;det_curve&gt;`.

.. versionadded:: 0.24

Parameters
----------
y_true : ndarray of shape (n_samples,)
    True binary labels. If labels are not either {-1, 1} or {0, 1}, then
    pos_label should be explicitly given.

y_score : ndarray of shape of (n_samples,)
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by "decision_function" on some classifiers).

pos_label : int or str, default=None
    The label of the positive class.
    When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},
    ``pos_label`` is set to 1, otherwise an error will be raised.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
fpr : ndarray of shape (n_thresholds,)
    False positive rate (FPR) such that element i is the false positive
    rate of predictions with score &gt;= thresholds[i]. This is occasionally
    referred to as false acceptance propability or fall-out.

fnr : ndarray of shape (n_thresholds,)
    False negative rate (FNR) such that element i is the false negative
    rate of predictions with score &gt;= thresholds[i]. This is occasionally
    referred to as false rejection or miss rate.

thresholds : ndarray of shape (n_thresholds,)
    Decreasing score values.

See Also
--------
DetCurveDisplay.from_estimator : Plot DET curve given an estimator and
    some data.
DetCurveDisplay.from_predictions : Plot DET curve given the true and
    predicted labels.
DetCurveDisplay : DET curve visualization.
roc_curve : Compute Receiver operating characteristic (ROC) curve.
precision_recall_curve : Compute precision-recall curve.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import det_curve
&gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])
&gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])
&gt;&gt;&gt; fpr, fnr, thresholds = det_curve(y_true, y_scores)
&gt;&gt;&gt; fpr
array([0.5, 0.5, 0. ])
&gt;&gt;&gt; fnr
array([0. , 0.5, 0.5])
&gt;&gt;&gt; thresholds
array([0.35, 0.4 , 0.8 ])
</pre> <div class="fragment"><div class="line"><span class="lineno">  239</span><span class="keyword">def </span>det_curve(y_true, y_score, pos_label=None, sample_weight=None):</div>
<div class="line"><span class="lineno">  240</span>    <span class="stringliteral">&quot;&quot;&quot;Compute error rates for different probability thresholds.</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">    .. note::</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">       This metric is used for evaluation of ranking and error tradeoffs of</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">       a binary classification task.</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;det_curve&gt;`.</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">    .. versionadded:: 0.24</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">    y_true : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">        True binary labels. If labels are not either {-1, 1} or {0, 1}, then</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">        pos_label should be explicitly given.</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">    y_score : ndarray of shape of (n_samples,)</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">        Target scores, can either be probability estimates of the positive</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">        class, confidence values, or non-thresholded measure of decisions</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">        (as returned by &quot;decision_function&quot; on some classifiers).</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">    pos_label : int or str, default=None</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">        The label of the positive class.</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">        When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">        ``pos_label`` is set to 1, otherwise an error will be raised.</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">    fpr : ndarray of shape (n_thresholds,)</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral">        False positive rate (FPR) such that element i is the false positive</span></div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">        rate of predictions with score &gt;= thresholds[i]. This is occasionally</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral">        referred to as false acceptance propability or fall-out.</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">    fnr : ndarray of shape (n_thresholds,)</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral">        False negative rate (FNR) such that element i is the false negative</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">        rate of predictions with score &gt;= thresholds[i]. This is occasionally</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">        referred to as false rejection or miss rate.</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    thresholds : ndarray of shape (n_thresholds,)</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">        Decreasing score values.</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">    DetCurveDisplay.from_estimator : Plot DET curve given an estimator and</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">        some data.</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">    DetCurveDisplay.from_predictions : Plot DET curve given the true and</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">        predicted labels.</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">    DetCurveDisplay : DET curve visualization.</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">    roc_curve : Compute Receiver operating characteristic (ROC) curve.</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">    precision_recall_curve : Compute precision-recall curve.</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import det_curve</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">    &gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">    &gt;&gt;&gt; fpr, fnr, thresholds = det_curve(y_true, y_scores)</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">    &gt;&gt;&gt; fpr</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">    array([0.5, 0.5, 0. ])</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">    &gt;&gt;&gt; fnr</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">    array([0. , 0.5, 0.5])</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    &gt;&gt;&gt; thresholds</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    array([0.35, 0.4 , 0.8 ])</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  308</span>    fps, tps, thresholds = _binary_clf_curve(</div>
<div class="line"><span class="lineno">  309</span>        y_true, y_score, pos_label=pos_label, sample_weight=sample_weight</div>
<div class="line"><span class="lineno">  310</span>    )</div>
<div class="line"><span class="lineno">  311</span> </div>
<div class="line"><span class="lineno">  312</span>    <span class="keywordflow">if</span> len(np.unique(y_true)) != 2:</div>
<div class="line"><span class="lineno">  313</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  314</span>            <span class="stringliteral">&quot;Only one class present in y_true. Detection error &quot;</span></div>
<div class="line"><span class="lineno">  315</span>            <span class="stringliteral">&quot;tradeoff curve is not defined in that case.&quot;</span></div>
<div class="line"><span class="lineno">  316</span>        )</div>
<div class="line"><span class="lineno">  317</span> </div>
<div class="line"><span class="lineno">  318</span>    fns = tps[-1] - tps</div>
<div class="line"><span class="lineno">  319</span>    p_count = tps[-1]</div>
<div class="line"><span class="lineno">  320</span>    n_count = fps[-1]</div>
<div class="line"><span class="lineno">  321</span> </div>
<div class="line"><span class="lineno">  322</span>    <span class="comment"># start with false positives zero</span></div>
<div class="line"><span class="lineno">  323</span>    first_ind = (</div>
<div class="line"><span class="lineno">  324</span>        fps.searchsorted(fps[0], side=<span class="stringliteral">&quot;right&quot;</span>) - 1</div>
<div class="line"><span class="lineno">  325</span>        <span class="keywordflow">if</span> fps.searchsorted(fps[0], side=<span class="stringliteral">&quot;right&quot;</span>) &gt; 0</div>
<div class="line"><span class="lineno">  326</span>        <span class="keywordflow">else</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  327</span>    )</div>
<div class="line"><span class="lineno">  328</span>    <span class="comment"># stop with false negatives zero</span></div>
<div class="line"><span class="lineno">  329</span>    last_ind = tps.searchsorted(tps[-1]) + 1</div>
<div class="line"><span class="lineno">  330</span>    sl = slice(first_ind, last_ind)</div>
<div class="line"><span class="lineno">  331</span> </div>
<div class="line"><span class="lineno">  332</span>    <span class="comment"># reverse the output such that list of false positives is decreasing</span></div>
<div class="line"><span class="lineno">  333</span>    <span class="keywordflow">return</span> (fps[sl][::-1] / n_count, fns[sl][::-1] / p_count, thresholds[sl][::-1])</div>
<div class="line"><span class="lineno">  334</span> </div>
<div class="line"><span class="lineno">  335</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a823afe2acdab3fa238632e261e107a1c" name="a823afe2acdab3fa238632e261e107a1c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a823afe2acdab3fa238632e261e107a1c">&#9670;&#160;</a></span>label_ranking_average_precision_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.label_ranking_average_precision_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute ranking-based average precision.

Label ranking average precision (LRAP) is the average over each ground
truth label assigned to each sample, of the ratio of true vs. total
labels with lower score.

This metric is used in multilabel ranking problem, where the goal
is to give better rank to the labels associated to each sample.

The obtained score is always strictly greater than 0 and
the best value is 1.

Read more in the :ref:`User Guide &lt;label_ranking_average_precision&gt;`.

Parameters
----------
y_true : {ndarray, sparse matrix} of shape (n_samples, n_labels)
    True binary labels in binary indicator format.

y_score : ndarray of shape (n_samples, n_labels)
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by "decision_function" on some classifiers).

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

    .. versionadded:: 0.20

Returns
-------
score : float
    Ranking-based average precision score.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import label_ranking_average_precision_score
&gt;&gt;&gt; y_true = np.array([[1, 0, 0], [0, 0, 1]])
&gt;&gt;&gt; y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])
&gt;&gt;&gt; label_ranking_average_precision_score(y_true, y_score)
0.416...
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1040</span><span class="keyword">def </span>label_ranking_average_precision_score(y_true, y_score, *, sample_weight=None):</div>
<div class="line"><span class="lineno"> 1041</span>    <span class="stringliteral">&quot;&quot;&quot;Compute ranking-based average precision.</span></div>
<div class="line"><span class="lineno"> 1042</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1043</span><span class="stringliteral">    Label ranking average precision (LRAP) is the average over each ground</span></div>
<div class="line"><span class="lineno"> 1044</span><span class="stringliteral">    truth label assigned to each sample, of the ratio of true vs. total</span></div>
<div class="line"><span class="lineno"> 1045</span><span class="stringliteral">    labels with lower score.</span></div>
<div class="line"><span class="lineno"> 1046</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1047</span><span class="stringliteral">    This metric is used in multilabel ranking problem, where the goal</span></div>
<div class="line"><span class="lineno"> 1048</span><span class="stringliteral">    is to give better rank to the labels associated to each sample.</span></div>
<div class="line"><span class="lineno"> 1049</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1050</span><span class="stringliteral">    The obtained score is always strictly greater than 0 and</span></div>
<div class="line"><span class="lineno"> 1051</span><span class="stringliteral">    the best value is 1.</span></div>
<div class="line"><span class="lineno"> 1052</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1053</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;label_ranking_average_precision&gt;`.</span></div>
<div class="line"><span class="lineno"> 1054</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1055</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1056</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1057</span><span class="stringliteral">    y_true : {ndarray, sparse matrix} of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1058</span><span class="stringliteral">        True binary labels in binary indicator format.</span></div>
<div class="line"><span class="lineno"> 1059</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1060</span><span class="stringliteral">    y_score : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1061</span><span class="stringliteral">        Target scores, can either be probability estimates of the positive</span></div>
<div class="line"><span class="lineno"> 1062</span><span class="stringliteral">        class, confidence values, or non-thresholded measure of decisions</span></div>
<div class="line"><span class="lineno"> 1063</span><span class="stringliteral">        (as returned by &quot;decision_function&quot; on some classifiers).</span></div>
<div class="line"><span class="lineno"> 1064</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1065</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1066</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1067</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1068</span><span class="stringliteral">        .. versionadded:: 0.20</span></div>
<div class="line"><span class="lineno"> 1069</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1070</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1071</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1072</span><span class="stringliteral">    score : float</span></div>
<div class="line"><span class="lineno"> 1073</span><span class="stringliteral">        Ranking-based average precision score.</span></div>
<div class="line"><span class="lineno"> 1074</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1075</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1076</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1077</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno"> 1078</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import label_ranking_average_precision_score</span></div>
<div class="line"><span class="lineno"> 1079</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([[1, 0, 0], [0, 0, 1]])</span></div>
<div class="line"><span class="lineno"> 1080</span><span class="stringliteral">    &gt;&gt;&gt; y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])</span></div>
<div class="line"><span class="lineno"> 1081</span><span class="stringliteral">    &gt;&gt;&gt; label_ranking_average_precision_score(y_true, y_score)</span></div>
<div class="line"><span class="lineno"> 1082</span><span class="stringliteral">    0.416...</span></div>
<div class="line"><span class="lineno"> 1083</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1084</span>    check_consistent_length(y_true, y_score, sample_weight)</div>
<div class="line"><span class="lineno"> 1085</span>    y_true = check_array(y_true, ensure_2d=<span class="keyword">False</span>, accept_sparse=<span class="stringliteral">&quot;csr&quot;</span>)</div>
<div class="line"><span class="lineno"> 1086</span>    y_score = check_array(y_score, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1087</span> </div>
<div class="line"><span class="lineno"> 1088</span>    <span class="keywordflow">if</span> y_true.shape != y_score.shape:</div>
<div class="line"><span class="lineno"> 1089</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;y_true and y_score have different shape&quot;</span>)</div>
<div class="line"><span class="lineno"> 1090</span> </div>
<div class="line"><span class="lineno"> 1091</span>    <span class="comment"># Handle badly formatted array and the degenerate case with one label</span></div>
<div class="line"><span class="lineno"> 1092</span>    y_type = type_of_target(y_true, input_name=<span class="stringliteral">&quot;y_true&quot;</span>)</div>
<div class="line"><span class="lineno"> 1093</span>    <span class="keywordflow">if</span> y_type != <span class="stringliteral">&quot;multilabel-indicator&quot;</span> <span class="keywordflow">and</span> <span class="keywordflow">not</span> (</div>
<div class="line"><span class="lineno"> 1094</span>        y_type == <span class="stringliteral">&quot;binary&quot;</span> <span class="keywordflow">and</span> y_true.ndim == 2</div>
<div class="line"><span class="lineno"> 1095</span>    ):</div>
<div class="line"><span class="lineno"> 1096</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;{0} format is not supported&quot;</span>.format(y_type))</div>
<div class="line"><span class="lineno"> 1097</span> </div>
<div class="line"><span class="lineno"> 1098</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> issparse(y_true):</div>
<div class="line"><span class="lineno"> 1099</span>        y_true = csr_matrix(y_true)</div>
<div class="line"><span class="lineno"> 1100</span> </div>
<div class="line"><span class="lineno"> 1101</span>    y_score = -y_score</div>
<div class="line"><span class="lineno"> 1102</span> </div>
<div class="line"><span class="lineno"> 1103</span>    n_samples, n_labels = y_true.shape</div>
<div class="line"><span class="lineno"> 1104</span> </div>
<div class="line"><span class="lineno"> 1105</span>    out = 0.0</div>
<div class="line"><span class="lineno"> 1106</span>    <span class="keywordflow">for</span> i, (start, stop) <span class="keywordflow">in</span> enumerate(zip(y_true.indptr, y_true.indptr[1:])):</div>
<div class="line"><span class="lineno"> 1107</span>        relevant = y_true.indices[start:stop]</div>
<div class="line"><span class="lineno"> 1108</span> </div>
<div class="line"><span class="lineno"> 1109</span>        <span class="keywordflow">if</span> relevant.size == 0 <span class="keywordflow">or</span> relevant.size == n_labels:</div>
<div class="line"><span class="lineno"> 1110</span>            <span class="comment"># If all labels are relevant or unrelevant, the score is also</span></div>
<div class="line"><span class="lineno"> 1111</span>            <span class="comment"># equal to 1. The label ranking has no meaning.</span></div>
<div class="line"><span class="lineno"> 1112</span>            aux = 1.0</div>
<div class="line"><span class="lineno"> 1113</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1114</span>            scores_i = y_score[i]</div>
<div class="line"><span class="lineno"> 1115</span>            rank = rankdata(scores_i, <span class="stringliteral">&quot;max&quot;</span>)[relevant]</div>
<div class="line"><span class="lineno"> 1116</span>            L = rankdata(scores_i[relevant], <span class="stringliteral">&quot;max&quot;</span>)</div>
<div class="line"><span class="lineno"> 1117</span>            aux = (L / rank).mean()</div>
<div class="line"><span class="lineno"> 1118</span> </div>
<div class="line"><span class="lineno"> 1119</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1120</span>            aux = aux * sample_weight[i]</div>
<div class="line"><span class="lineno"> 1121</span>        out += aux</div>
<div class="line"><span class="lineno"> 1122</span> </div>
<div class="line"><span class="lineno"> 1123</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1124</span>        out /= n_samples</div>
<div class="line"><span class="lineno"> 1125</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1126</span>        out /= np.sum(sample_weight)</div>
<div class="line"><span class="lineno"> 1127</span> </div>
<div class="line"><span class="lineno"> 1128</span>    <span class="keywordflow">return</span> out</div>
<div class="line"><span class="lineno"> 1129</span> </div>
<div class="line"><span class="lineno"> 1130</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0b6692d3f97515bece867d5a03013a6a" name="a0b6692d3f97515bece867d5a03013a6a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b6692d3f97515bece867d5a03013a6a">&#9670;&#160;</a></span>label_ranking_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.label_ranking_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute Ranking loss measure.

Compute the average number of label pairs that are incorrectly ordered
given y_score weighted by the size of the label set and the number of
labels not in the label set.

This is similar to the error set size, but weighted by the number of
relevant and irrelevant labels. The best performance is achieved with
a ranking loss of zero.

Read more in the :ref:`User Guide &lt;label_ranking_loss&gt;`.

.. versionadded:: 0.17
   A function *label_ranking_loss*

Parameters
----------
y_true : {ndarray, sparse matrix} of shape (n_samples, n_labels)
    True binary labels in binary indicator format.

y_score : ndarray of shape (n_samples, n_labels)
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by "decision_function" on some classifiers).

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
loss : float
    Average number of label pairs that are incorrectly ordered given
    y_score weighted by the size of the label set and the number of labels not
    in the label set.

References
----------
.. [1] Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2010).
       Mining multi-label data. In Data mining and knowledge discovery
       handbook (pp. 667-685). Springer US.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1190</span><span class="keyword">def </span>label_ranking_loss(y_true, y_score, *, sample_weight=None):</div>
<div class="line"><span class="lineno"> 1191</span>    <span class="stringliteral">&quot;&quot;&quot;Compute Ranking loss measure.</span></div>
<div class="line"><span class="lineno"> 1192</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1193</span><span class="stringliteral">    Compute the average number of label pairs that are incorrectly ordered</span></div>
<div class="line"><span class="lineno"> 1194</span><span class="stringliteral">    given y_score weighted by the size of the label set and the number of</span></div>
<div class="line"><span class="lineno"> 1195</span><span class="stringliteral">    labels not in the label set.</span></div>
<div class="line"><span class="lineno"> 1196</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1197</span><span class="stringliteral">    This is similar to the error set size, but weighted by the number of</span></div>
<div class="line"><span class="lineno"> 1198</span><span class="stringliteral">    relevant and irrelevant labels. The best performance is achieved with</span></div>
<div class="line"><span class="lineno"> 1199</span><span class="stringliteral">    a ranking loss of zero.</span></div>
<div class="line"><span class="lineno"> 1200</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1201</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;label_ranking_loss&gt;`.</span></div>
<div class="line"><span class="lineno"> 1202</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1203</span><span class="stringliteral">    .. versionadded:: 0.17</span></div>
<div class="line"><span class="lineno"> 1204</span><span class="stringliteral">       A function *label_ranking_loss*</span></div>
<div class="line"><span class="lineno"> 1205</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1206</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1207</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1208</span><span class="stringliteral">    y_true : {ndarray, sparse matrix} of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1209</span><span class="stringliteral">        True binary labels in binary indicator format.</span></div>
<div class="line"><span class="lineno"> 1210</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1211</span><span class="stringliteral">    y_score : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1212</span><span class="stringliteral">        Target scores, can either be probability estimates of the positive</span></div>
<div class="line"><span class="lineno"> 1213</span><span class="stringliteral">        class, confidence values, or non-thresholded measure of decisions</span></div>
<div class="line"><span class="lineno"> 1214</span><span class="stringliteral">        (as returned by &quot;decision_function&quot; on some classifiers).</span></div>
<div class="line"><span class="lineno"> 1215</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1216</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1217</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno"> 1218</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1219</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1220</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1221</span><span class="stringliteral">    loss : float</span></div>
<div class="line"><span class="lineno"> 1222</span><span class="stringliteral">        Average number of label pairs that are incorrectly ordered given</span></div>
<div class="line"><span class="lineno"> 1223</span><span class="stringliteral">        y_score weighted by the size of the label set and the number of labels not</span></div>
<div class="line"><span class="lineno"> 1224</span><span class="stringliteral">        in the label set.</span></div>
<div class="line"><span class="lineno"> 1225</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1226</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1227</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1228</span><span class="stringliteral">    .. [1] Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2010).</span></div>
<div class="line"><span class="lineno"> 1229</span><span class="stringliteral">           Mining multi-label data. In Data mining and knowledge discovery</span></div>
<div class="line"><span class="lineno"> 1230</span><span class="stringliteral">           handbook (pp. 667-685). Springer US.</span></div>
<div class="line"><span class="lineno"> 1231</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1232</span>    y_true = check_array(y_true, ensure_2d=<span class="keyword">False</span>, accept_sparse=<span class="stringliteral">&quot;csr&quot;</span>)</div>
<div class="line"><span class="lineno"> 1233</span>    y_score = check_array(y_score, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1234</span>    check_consistent_length(y_true, y_score, sample_weight)</div>
<div class="line"><span class="lineno"> 1235</span> </div>
<div class="line"><span class="lineno"> 1236</span>    y_type = type_of_target(y_true, input_name=<span class="stringliteral">&quot;y_true&quot;</span>)</div>
<div class="line"><span class="lineno"> 1237</span>    <span class="keywordflow">if</span> y_type <span class="keywordflow">not</span> <span class="keywordflow">in</span> (<span class="stringliteral">&quot;multilabel-indicator&quot;</span>,):</div>
<div class="line"><span class="lineno"> 1238</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;{0} format is not supported&quot;</span>.format(y_type))</div>
<div class="line"><span class="lineno"> 1239</span> </div>
<div class="line"><span class="lineno"> 1240</span>    <span class="keywordflow">if</span> y_true.shape != y_score.shape:</div>
<div class="line"><span class="lineno"> 1241</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;y_true and y_score have different shape&quot;</span>)</div>
<div class="line"><span class="lineno"> 1242</span> </div>
<div class="line"><span class="lineno"> 1243</span>    n_samples, n_labels = y_true.shape</div>
<div class="line"><span class="lineno"> 1244</span> </div>
<div class="line"><span class="lineno"> 1245</span>    y_true = csr_matrix(y_true)</div>
<div class="line"><span class="lineno"> 1246</span> </div>
<div class="line"><span class="lineno"> 1247</span>    loss = np.zeros(n_samples)</div>
<div class="line"><span class="lineno"> 1248</span>    <span class="keywordflow">for</span> i, (start, stop) <span class="keywordflow">in</span> enumerate(zip(y_true.indptr, y_true.indptr[1:])):</div>
<div class="line"><span class="lineno"> 1249</span>        <span class="comment"># Sort and bin the label scores</span></div>
<div class="line"><span class="lineno"> 1250</span>        unique_scores, unique_inverse = np.unique(y_score[i], return_inverse=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1251</span>        true_at_reversed_rank = np.bincount(</div>
<div class="line"><span class="lineno"> 1252</span>            unique_inverse[y_true.indices[start:stop]], minlength=len(unique_scores)</div>
<div class="line"><span class="lineno"> 1253</span>        )</div>
<div class="line"><span class="lineno"> 1254</span>        all_at_reversed_rank = np.bincount(unique_inverse, minlength=len(unique_scores))</div>
<div class="line"><span class="lineno"> 1255</span>        false_at_reversed_rank = all_at_reversed_rank - true_at_reversed_rank</div>
<div class="line"><span class="lineno"> 1256</span> </div>
<div class="line"><span class="lineno"> 1257</span>        <span class="comment"># if the scores are ordered, it&#39;s possible to count the number of</span></div>
<div class="line"><span class="lineno"> 1258</span>        <span class="comment"># incorrectly ordered paires in linear time by cumulatively counting</span></div>
<div class="line"><span class="lineno"> 1259</span>        <span class="comment"># how many false labels of a given score have a score higher than the</span></div>
<div class="line"><span class="lineno"> 1260</span>        <span class="comment"># accumulated true labels with lower score.</span></div>
<div class="line"><span class="lineno"> 1261</span>        loss[i] = np.dot(true_at_reversed_rank.cumsum(), false_at_reversed_rank)</div>
<div class="line"><span class="lineno"> 1262</span> </div>
<div class="line"><span class="lineno"> 1263</span>    n_positives = count_nonzero(y_true, axis=1)</div>
<div class="line"><span class="lineno"> 1264</span>    <span class="keyword">with</span> np.errstate(divide=<span class="stringliteral">&quot;ignore&quot;</span>, invalid=<span class="stringliteral">&quot;ignore&quot;</span>):</div>
<div class="line"><span class="lineno"> 1265</span>        loss /= (n_labels - n_positives) * n_positives</div>
<div class="line"><span class="lineno"> 1266</span> </div>
<div class="line"><span class="lineno"> 1267</span>    <span class="comment"># When there is no positive or no negative labels, those values should</span></div>
<div class="line"><span class="lineno"> 1268</span>    <span class="comment"># be consider as correct, i.e. the ranking doesn&#39;t matter.</span></div>
<div class="line"><span class="lineno"> 1269</span>    loss[np.logical_or(n_positives == 0, n_positives == n_labels)] = 0.0</div>
<div class="line"><span class="lineno"> 1270</span> </div>
<div class="line"><span class="lineno"> 1271</span>    <span class="keywordflow">return</span> np.average(loss, weights=sample_weight)</div>
<div class="line"><span class="lineno"> 1272</span> </div>
<div class="line"><span class="lineno"> 1273</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a84a9a92b4b94ddd8962415fc5faf2fa8" name="a84a9a92b4b94ddd8962415fc5faf2fa8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a84a9a92b4b94ddd8962415fc5faf2fa8">&#9670;&#160;</a></span>ndcg_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.ndcg_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>k</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ignore_ties</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute Normalized Discounted Cumulative Gain.

Sum the true scores ranked in the order induced by the predicted scores,
after applying a logarithmic discount. Then divide by the best possible
score (Ideal DCG, obtained for a perfect ranking) to obtain a score between
0 and 1.

This ranking metric returns a high value if true labels are ranked high by
``y_score``.

Parameters
----------
y_true : ndarray of shape (n_samples, n_labels)
    True targets of multilabel classification, or true scores of entities
    to be ranked. Negative values in `y_true` may result in an output
    that is not between 0 and 1.

    .. versionchanged:: 1.2
        These negative values are deprecated, and will raise an error in v1.4.

y_score : ndarray of shape (n_samples, n_labels)
    Target scores, can either be probability estimates, confidence values,
    or non-thresholded measure of decisions (as returned by
    "decision_function" on some classifiers).

k : int, default=None
    Only consider the highest k scores in the ranking. If `None`, use all
    outputs.

sample_weight : ndarray of shape (n_samples,), default=None
    Sample weights. If `None`, all samples are given the same weight.

ignore_ties : bool, default=False
    Assume that there are no ties in y_score (which is likely to be the
    case if y_score is continuous) for efficiency gains.

Returns
-------
normalized_discounted_cumulative_gain : float in [0., 1.]
    The averaged NDCG scores for all samples.

See Also
--------
dcg_score : Discounted Cumulative Gain (not normalized).

References
----------
`Wikipedia entry for Discounted Cumulative Gain
&lt;https://en.wikipedia.org/wiki/Discounted_cumulative_gain&gt;`_

Jarvelin, K., &amp; Kekalainen, J. (2002).
Cumulated gain-based evaluation of IR techniques. ACM Transactions on
Information Systems (TOIS), 20(4), 422-446.

Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp; Liu, T. Y. (2013, May).
A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th
Annual Conference on Learning Theory (COLT 2013)

McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval
performance measures efficiently in the presence of tied scores. In
European conference on information retrieval (pp. 414-421). Springer,
Berlin, Heidelberg.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import ndcg_score
&gt;&gt;&gt; # we have groud-truth relevance of some answers to a query:
&gt;&gt;&gt; true_relevance = np.asarray([[10, 0, 0, 1, 5]])
&gt;&gt;&gt; # we predict some scores (relevance) for the answers
&gt;&gt;&gt; scores = np.asarray([[.1, .2, .3, 4, 70]])
&gt;&gt;&gt; ndcg_score(true_relevance, scores)
0.69...
&gt;&gt;&gt; scores = np.asarray([[.05, 1.1, 1., .5, .0]])
&gt;&gt;&gt; ndcg_score(true_relevance, scores)
0.49...
&gt;&gt;&gt; # we can set k to truncate the sum; only top k answers contribute.
&gt;&gt;&gt; ndcg_score(true_relevance, scores, k=4)
0.35...
&gt;&gt;&gt; # the normalization takes k into account so a perfect answer
&gt;&gt;&gt; # would still get 1.0
&gt;&gt;&gt; ndcg_score(true_relevance, true_relevance, k=4)
1.0...
&gt;&gt;&gt; # now we have some ties in our prediction
&gt;&gt;&gt; scores = np.asarray([[1, 0, 0, 0, 1]])
&gt;&gt;&gt; # by default ties are averaged, so here we get the average (normalized)
&gt;&gt;&gt; # true relevance of our top predictions: (10 / 10 + 5 / 10) / 2 = .75
&gt;&gt;&gt; ndcg_score(true_relevance, scores, k=1)
0.75...
&gt;&gt;&gt; # we can choose to ignore ties for faster results, but only
&gt;&gt;&gt; # if we know there aren't ties in our scores, otherwise we get
&gt;&gt;&gt; # wrong results:
&gt;&gt;&gt; ndcg_score(true_relevance,
...           scores, k=1, ignore_ties=True)
0.5...
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1555</span><span class="keyword">def </span>ndcg_score(y_true, y_score, *, k=None, sample_weight=None, ignore_ties=False):</div>
<div class="line"><span class="lineno"> 1556</span>    <span class="stringliteral">&quot;&quot;&quot;Compute Normalized Discounted Cumulative Gain.</span></div>
<div class="line"><span class="lineno"> 1557</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1558</span><span class="stringliteral">    Sum the true scores ranked in the order induced by the predicted scores,</span></div>
<div class="line"><span class="lineno"> 1559</span><span class="stringliteral">    after applying a logarithmic discount. Then divide by the best possible</span></div>
<div class="line"><span class="lineno"> 1560</span><span class="stringliteral">    score (Ideal DCG, obtained for a perfect ranking) to obtain a score between</span></div>
<div class="line"><span class="lineno"> 1561</span><span class="stringliteral">    0 and 1.</span></div>
<div class="line"><span class="lineno"> 1562</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1563</span><span class="stringliteral">    This ranking metric returns a high value if true labels are ranked high by</span></div>
<div class="line"><span class="lineno"> 1564</span><span class="stringliteral">    ``y_score``.</span></div>
<div class="line"><span class="lineno"> 1565</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1566</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1567</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1568</span><span class="stringliteral">    y_true : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1569</span><span class="stringliteral">        True targets of multilabel classification, or true scores of entities</span></div>
<div class="line"><span class="lineno"> 1570</span><span class="stringliteral">        to be ranked. Negative values in `y_true` may result in an output</span></div>
<div class="line"><span class="lineno"> 1571</span><span class="stringliteral">        that is not between 0 and 1.</span></div>
<div class="line"><span class="lineno"> 1572</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1573</span><span class="stringliteral">        .. versionchanged:: 1.2</span></div>
<div class="line"><span class="lineno"> 1574</span><span class="stringliteral">            These negative values are deprecated, and will raise an error in v1.4.</span></div>
<div class="line"><span class="lineno"> 1575</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1576</span><span class="stringliteral">    y_score : ndarray of shape (n_samples, n_labels)</span></div>
<div class="line"><span class="lineno"> 1577</span><span class="stringliteral">        Target scores, can either be probability estimates, confidence values,</span></div>
<div class="line"><span class="lineno"> 1578</span><span class="stringliteral">        or non-thresholded measure of decisions (as returned by</span></div>
<div class="line"><span class="lineno"> 1579</span><span class="stringliteral">        &quot;decision_function&quot; on some classifiers).</span></div>
<div class="line"><span class="lineno"> 1580</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1581</span><span class="stringliteral">    k : int, default=None</span></div>
<div class="line"><span class="lineno"> 1582</span><span class="stringliteral">        Only consider the highest k scores in the ranking. If `None`, use all</span></div>
<div class="line"><span class="lineno"> 1583</span><span class="stringliteral">        outputs.</span></div>
<div class="line"><span class="lineno"> 1584</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1585</span><span class="stringliteral">    sample_weight : ndarray of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1586</span><span class="stringliteral">        Sample weights. If `None`, all samples are given the same weight.</span></div>
<div class="line"><span class="lineno"> 1587</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1588</span><span class="stringliteral">    ignore_ties : bool, default=False</span></div>
<div class="line"><span class="lineno"> 1589</span><span class="stringliteral">        Assume that there are no ties in y_score (which is likely to be the</span></div>
<div class="line"><span class="lineno"> 1590</span><span class="stringliteral">        case if y_score is continuous) for efficiency gains.</span></div>
<div class="line"><span class="lineno"> 1591</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1592</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1593</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1594</span><span class="stringliteral">    normalized_discounted_cumulative_gain : float in [0., 1.]</span></div>
<div class="line"><span class="lineno"> 1595</span><span class="stringliteral">        The averaged NDCG scores for all samples.</span></div>
<div class="line"><span class="lineno"> 1596</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1597</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 1598</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1599</span><span class="stringliteral">    dcg_score : Discounted Cumulative Gain (not normalized).</span></div>
<div class="line"><span class="lineno"> 1600</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1601</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno"> 1602</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1603</span><span class="stringliteral">    `Wikipedia entry for Discounted Cumulative Gain</span></div>
<div class="line"><span class="lineno"> 1604</span><span class="stringliteral">    &lt;https://en.wikipedia.org/wiki/Discounted_cumulative_gain&gt;`_</span></div>
<div class="line"><span class="lineno"> 1605</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1606</span><span class="stringliteral">    Jarvelin, K., &amp; Kekalainen, J. (2002).</span></div>
<div class="line"><span class="lineno"> 1607</span><span class="stringliteral">    Cumulated gain-based evaluation of IR techniques. ACM Transactions on</span></div>
<div class="line"><span class="lineno"> 1608</span><span class="stringliteral">    Information Systems (TOIS), 20(4), 422-446.</span></div>
<div class="line"><span class="lineno"> 1609</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1610</span><span class="stringliteral">    Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp; Liu, T. Y. (2013, May).</span></div>
<div class="line"><span class="lineno"> 1611</span><span class="stringliteral">    A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th</span></div>
<div class="line"><span class="lineno"> 1612</span><span class="stringliteral">    Annual Conference on Learning Theory (COLT 2013)</span></div>
<div class="line"><span class="lineno"> 1613</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1614</span><span class="stringliteral">    McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval</span></div>
<div class="line"><span class="lineno"> 1615</span><span class="stringliteral">    performance measures efficiently in the presence of tied scores. In</span></div>
<div class="line"><span class="lineno"> 1616</span><span class="stringliteral">    European conference on information retrieval (pp. 414-421). Springer,</span></div>
<div class="line"><span class="lineno"> 1617</span><span class="stringliteral">    Berlin, Heidelberg.</span></div>
<div class="line"><span class="lineno"> 1618</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1619</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1620</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1621</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno"> 1622</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import ndcg_score</span></div>
<div class="line"><span class="lineno"> 1623</span><span class="stringliteral">    &gt;&gt;&gt; # we have groud-truth relevance of some answers to a query:</span></div>
<div class="line"><span class="lineno"> 1624</span><span class="stringliteral">    &gt;&gt;&gt; true_relevance = np.asarray([[10, 0, 0, 1, 5]])</span></div>
<div class="line"><span class="lineno"> 1625</span><span class="stringliteral">    &gt;&gt;&gt; # we predict some scores (relevance) for the answers</span></div>
<div class="line"><span class="lineno"> 1626</span><span class="stringliteral">    &gt;&gt;&gt; scores = np.asarray([[.1, .2, .3, 4, 70]])</span></div>
<div class="line"><span class="lineno"> 1627</span><span class="stringliteral">    &gt;&gt;&gt; ndcg_score(true_relevance, scores)</span></div>
<div class="line"><span class="lineno"> 1628</span><span class="stringliteral">    0.69...</span></div>
<div class="line"><span class="lineno"> 1629</span><span class="stringliteral">    &gt;&gt;&gt; scores = np.asarray([[.05, 1.1, 1., .5, .0]])</span></div>
<div class="line"><span class="lineno"> 1630</span><span class="stringliteral">    &gt;&gt;&gt; ndcg_score(true_relevance, scores)</span></div>
<div class="line"><span class="lineno"> 1631</span><span class="stringliteral">    0.49...</span></div>
<div class="line"><span class="lineno"> 1632</span><span class="stringliteral">    &gt;&gt;&gt; # we can set k to truncate the sum; only top k answers contribute.</span></div>
<div class="line"><span class="lineno"> 1633</span><span class="stringliteral">    &gt;&gt;&gt; ndcg_score(true_relevance, scores, k=4)</span></div>
<div class="line"><span class="lineno"> 1634</span><span class="stringliteral">    0.35...</span></div>
<div class="line"><span class="lineno"> 1635</span><span class="stringliteral">    &gt;&gt;&gt; # the normalization takes k into account so a perfect answer</span></div>
<div class="line"><span class="lineno"> 1636</span><span class="stringliteral">    &gt;&gt;&gt; # would still get 1.0</span></div>
<div class="line"><span class="lineno"> 1637</span><span class="stringliteral">    &gt;&gt;&gt; ndcg_score(true_relevance, true_relevance, k=4)</span></div>
<div class="line"><span class="lineno"> 1638</span><span class="stringliteral">    1.0...</span></div>
<div class="line"><span class="lineno"> 1639</span><span class="stringliteral">    &gt;&gt;&gt; # now we have some ties in our prediction</span></div>
<div class="line"><span class="lineno"> 1640</span><span class="stringliteral">    &gt;&gt;&gt; scores = np.asarray([[1, 0, 0, 0, 1]])</span></div>
<div class="line"><span class="lineno"> 1641</span><span class="stringliteral">    &gt;&gt;&gt; # by default ties are averaged, so here we get the average (normalized)</span></div>
<div class="line"><span class="lineno"> 1642</span><span class="stringliteral">    &gt;&gt;&gt; # true relevance of our top predictions: (10 / 10 + 5 / 10) / 2 = .75</span></div>
<div class="line"><span class="lineno"> 1643</span><span class="stringliteral">    &gt;&gt;&gt; ndcg_score(true_relevance, scores, k=1)</span></div>
<div class="line"><span class="lineno"> 1644</span><span class="stringliteral">    0.75...</span></div>
<div class="line"><span class="lineno"> 1645</span><span class="stringliteral">    &gt;&gt;&gt; # we can choose to ignore ties for faster results, but only</span></div>
<div class="line"><span class="lineno"> 1646</span><span class="stringliteral">    &gt;&gt;&gt; # if we know there aren&#39;t ties in our scores, otherwise we get</span></div>
<div class="line"><span class="lineno"> 1647</span><span class="stringliteral">    &gt;&gt;&gt; # wrong results:</span></div>
<div class="line"><span class="lineno"> 1648</span><span class="stringliteral">    &gt;&gt;&gt; ndcg_score(true_relevance,</span></div>
<div class="line"><span class="lineno"> 1649</span><span class="stringliteral">    ...           scores, k=1, ignore_ties=True)</span></div>
<div class="line"><span class="lineno"> 1650</span><span class="stringliteral">    0.5...</span></div>
<div class="line"><span class="lineno"> 1651</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1652</span>    y_true = check_array(y_true, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1653</span>    y_score = check_array(y_score, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1654</span>    check_consistent_length(y_true, y_score, sample_weight)</div>
<div class="line"><span class="lineno"> 1655</span> </div>
<div class="line"><span class="lineno"> 1656</span>    <span class="keywordflow">if</span> y_true.min() &lt; 0:</div>
<div class="line"><span class="lineno"> 1657</span>        <span class="comment"># TODO(1.4): Replace warning w/ ValueError</span></div>
<div class="line"><span class="lineno"> 1658</span>        warnings.warn(</div>
<div class="line"><span class="lineno"> 1659</span>            <span class="stringliteral">&quot;ndcg_score should not be used on negative y_true values. ndcg_score will&quot;</span></div>
<div class="line"><span class="lineno"> 1660</span>            <span class="stringliteral">&quot; raise a ValueError on negative y_true values starting from version 1.4.&quot;</span>,</div>
<div class="line"><span class="lineno"> 1661</span>            FutureWarning,</div>
<div class="line"><span class="lineno"> 1662</span>        )</div>
<div class="line"><span class="lineno"> 1663</span>    _check_dcg_target_type(y_true)</div>
<div class="line"><span class="lineno"> 1664</span>    gain = _ndcg_sample_scores(y_true, y_score, k=k, ignore_ties=ignore_ties)</div>
<div class="line"><span class="lineno"> 1665</span>    <span class="keywordflow">return</span> np.average(gain, weights=sample_weight)</div>
<div class="line"><span class="lineno"> 1666</span> </div>
<div class="line"><span class="lineno"> 1667</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aef84ebd79b282432f70f0b7a347f3055" name="aef84ebd79b282432f70f0b7a347f3055"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef84ebd79b282432f70f0b7a347f3055">&#9670;&#160;</a></span>precision_recall_curve()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.precision_recall_curve </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>probas_pred</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute precision-recall pairs for different probability thresholds.

Note: this implementation is restricted to the binary classification task.

The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of
true positives and ``fp`` the number of false positives. The precision is
intuitively the ability of the classifier not to label as positive a sample
that is negative.

The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of
true positives and ``fn`` the number of false negatives. The recall is
intuitively the ability of the classifier to find all the positive samples.

The last precision and recall values are 1. and 0. respectively and do not
have a corresponding threshold. This ensures that the graph starts on the
y axis.

The first precision and recall values are precision=class balance and recall=1.0
which corresponds to a classifier that always predicts the positive class.

Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.

Parameters
----------
y_true : ndarray of shape (n_samples,)
    True binary labels. If labels are not either {-1, 1} or {0, 1}, then
    pos_label should be explicitly given.

probas_pred : ndarray of shape (n_samples,)
    Target scores, can either be probability estimates of the positive
    class, or non-thresholded measure of decisions (as returned by
    `decision_function` on some classifiers).

pos_label : int or str, default=None
    The label of the positive class.
    When ``pos_label=None``, if y_true is in {-1, 1} or {0, 1},
    ``pos_label`` is set to 1, otherwise an error will be raised.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
precision : ndarray of shape (n_thresholds + 1,)
    Precision values such that element i is the precision of
    predictions with score &gt;= thresholds[i] and the last element is 1.

recall : ndarray of shape (n_thresholds + 1,)
    Decreasing recall values such that element i is the recall of
    predictions with score &gt;= thresholds[i] and the last element is 0.

thresholds : ndarray of shape (n_thresholds,)
    Increasing thresholds on the decision function used to compute
    precision and recall where `n_thresholds = len(np.unique(probas_pred))`.

See Also
--------
PrecisionRecallDisplay.from_estimator : Plot Precision Recall Curve given
    a binary classifier.
PrecisionRecallDisplay.from_predictions : Plot Precision Recall Curve
    using predictions from a binary classifier.
average_precision_score : Compute average precision from prediction scores.
det_curve: Compute error rates for different probability thresholds.
roc_curve : Compute Receiver operating characteristic (ROC) curve.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import precision_recall_curve
&gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])
&gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])
&gt;&gt;&gt; precision, recall, thresholds = precision_recall_curve(
...     y_true, y_scores)
&gt;&gt;&gt; precision
array([0.5       , 0.66666667, 0.5       , 1.        , 1.        ])
&gt;&gt;&gt; recall
array([1. , 1. , 0.5, 0.5, 0. ])
&gt;&gt;&gt; thresholds
array([0.1 , 0.35, 0.4 , 0.8 ])
</pre> <div class="fragment"><div class="line"><span class="lineno">  797</span><span class="keyword">def </span>precision_recall_curve(y_true, probas_pred, *, pos_label=None, sample_weight=None):</div>
<div class="line"><span class="lineno">  798</span>    <span class="stringliteral">&quot;&quot;&quot;Compute precision-recall pairs for different probability thresholds.</span></div>
<div class="line"><span class="lineno">  799</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  800</span><span class="stringliteral">    Note: this implementation is restricted to the binary classification task.</span></div>
<div class="line"><span class="lineno">  801</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  802</span><span class="stringliteral">    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of</span></div>
<div class="line"><span class="lineno">  803</span><span class="stringliteral">    true positives and ``fp`` the number of false positives. The precision is</span></div>
<div class="line"><span class="lineno">  804</span><span class="stringliteral">    intuitively the ability of the classifier not to label as positive a sample</span></div>
<div class="line"><span class="lineno">  805</span><span class="stringliteral">    that is negative.</span></div>
<div class="line"><span class="lineno">  806</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  807</span><span class="stringliteral">    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of</span></div>
<div class="line"><span class="lineno">  808</span><span class="stringliteral">    true positives and ``fn`` the number of false negatives. The recall is</span></div>
<div class="line"><span class="lineno">  809</span><span class="stringliteral">    intuitively the ability of the classifier to find all the positive samples.</span></div>
<div class="line"><span class="lineno">  810</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  811</span><span class="stringliteral">    The last precision and recall values are 1. and 0. respectively and do not</span></div>
<div class="line"><span class="lineno">  812</span><span class="stringliteral">    have a corresponding threshold. This ensures that the graph starts on the</span></div>
<div class="line"><span class="lineno">  813</span><span class="stringliteral">    y axis.</span></div>
<div class="line"><span class="lineno">  814</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  815</span><span class="stringliteral">    The first precision and recall values are precision=class balance and recall=1.0</span></div>
<div class="line"><span class="lineno">  816</span><span class="stringliteral">    which corresponds to a classifier that always predicts the positive class.</span></div>
<div class="line"><span class="lineno">  817</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  818</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span></div>
<div class="line"><span class="lineno">  819</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  820</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  821</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  822</span><span class="stringliteral">    y_true : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  823</span><span class="stringliteral">        True binary labels. If labels are not either {-1, 1} or {0, 1}, then</span></div>
<div class="line"><span class="lineno">  824</span><span class="stringliteral">        pos_label should be explicitly given.</span></div>
<div class="line"><span class="lineno">  825</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  826</span><span class="stringliteral">    probas_pred : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  827</span><span class="stringliteral">        Target scores, can either be probability estimates of the positive</span></div>
<div class="line"><span class="lineno">  828</span><span class="stringliteral">        class, or non-thresholded measure of decisions (as returned by</span></div>
<div class="line"><span class="lineno">  829</span><span class="stringliteral">        `decision_function` on some classifiers).</span></div>
<div class="line"><span class="lineno">  830</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  831</span><span class="stringliteral">    pos_label : int or str, default=None</span></div>
<div class="line"><span class="lineno">  832</span><span class="stringliteral">        The label of the positive class.</span></div>
<div class="line"><span class="lineno">  833</span><span class="stringliteral">        When ``pos_label=None``, if y_true is in {-1, 1} or {0, 1},</span></div>
<div class="line"><span class="lineno">  834</span><span class="stringliteral">        ``pos_label`` is set to 1, otherwise an error will be raised.</span></div>
<div class="line"><span class="lineno">  835</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  836</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  837</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  838</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  839</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  840</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  841</span><span class="stringliteral">    precision : ndarray of shape (n_thresholds + 1,)</span></div>
<div class="line"><span class="lineno">  842</span><span class="stringliteral">        Precision values such that element i is the precision of</span></div>
<div class="line"><span class="lineno">  843</span><span class="stringliteral">        predictions with score &gt;= thresholds[i] and the last element is 1.</span></div>
<div class="line"><span class="lineno">  844</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  845</span><span class="stringliteral">    recall : ndarray of shape (n_thresholds + 1,)</span></div>
<div class="line"><span class="lineno">  846</span><span class="stringliteral">        Decreasing recall values such that element i is the recall of</span></div>
<div class="line"><span class="lineno">  847</span><span class="stringliteral">        predictions with score &gt;= thresholds[i] and the last element is 0.</span></div>
<div class="line"><span class="lineno">  848</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  849</span><span class="stringliteral">    thresholds : ndarray of shape (n_thresholds,)</span></div>
<div class="line"><span class="lineno">  850</span><span class="stringliteral">        Increasing thresholds on the decision function used to compute</span></div>
<div class="line"><span class="lineno">  851</span><span class="stringliteral">        precision and recall where `n_thresholds = len(np.unique(probas_pred))`.</span></div>
<div class="line"><span class="lineno">  852</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  853</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  854</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  855</span><span class="stringliteral">    PrecisionRecallDisplay.from_estimator : Plot Precision Recall Curve given</span></div>
<div class="line"><span class="lineno">  856</span><span class="stringliteral">        a binary classifier.</span></div>
<div class="line"><span class="lineno">  857</span><span class="stringliteral">    PrecisionRecallDisplay.from_predictions : Plot Precision Recall Curve</span></div>
<div class="line"><span class="lineno">  858</span><span class="stringliteral">        using predictions from a binary classifier.</span></div>
<div class="line"><span class="lineno">  859</span><span class="stringliteral">    average_precision_score : Compute average precision from prediction scores.</span></div>
<div class="line"><span class="lineno">  860</span><span class="stringliteral">    det_curve: Compute error rates for different probability thresholds.</span></div>
<div class="line"><span class="lineno">  861</span><span class="stringliteral">    roc_curve : Compute Receiver operating characteristic (ROC) curve.</span></div>
<div class="line"><span class="lineno">  862</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  863</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  864</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  865</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  866</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import precision_recall_curve</span></div>
<div class="line"><span class="lineno">  867</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])</span></div>
<div class="line"><span class="lineno">  868</span><span class="stringliteral">    &gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])</span></div>
<div class="line"><span class="lineno">  869</span><span class="stringliteral">    &gt;&gt;&gt; precision, recall, thresholds = precision_recall_curve(</span></div>
<div class="line"><span class="lineno">  870</span><span class="stringliteral">    ...     y_true, y_scores)</span></div>
<div class="line"><span class="lineno">  871</span><span class="stringliteral">    &gt;&gt;&gt; precision</span></div>
<div class="line"><span class="lineno">  872</span><span class="stringliteral">    array([0.5       , 0.66666667, 0.5       , 1.        , 1.        ])</span></div>
<div class="line"><span class="lineno">  873</span><span class="stringliteral">    &gt;&gt;&gt; recall</span></div>
<div class="line"><span class="lineno">  874</span><span class="stringliteral">    array([1. , 1. , 0.5, 0.5, 0. ])</span></div>
<div class="line"><span class="lineno">  875</span><span class="stringliteral">    &gt;&gt;&gt; thresholds</span></div>
<div class="line"><span class="lineno">  876</span><span class="stringliteral">    array([0.1 , 0.35, 0.4 , 0.8 ])</span></div>
<div class="line"><span class="lineno">  877</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  878</span>    fps, tps, thresholds = _binary_clf_curve(</div>
<div class="line"><span class="lineno">  879</span>        y_true, probas_pred, pos_label=pos_label, sample_weight=sample_weight</div>
<div class="line"><span class="lineno">  880</span>    )</div>
<div class="line"><span class="lineno">  881</span> </div>
<div class="line"><span class="lineno">  882</span>    ps = tps + fps</div>
<div class="line"><span class="lineno">  883</span>    <span class="comment"># Initialize the result array with zeros to make sure that precision[ps == 0]</span></div>
<div class="line"><span class="lineno">  884</span>    <span class="comment"># does not contain uninitialized values.</span></div>
<div class="line"><span class="lineno">  885</span>    precision = np.zeros_like(tps)</div>
<div class="line"><span class="lineno">  886</span>    np.divide(tps, ps, out=precision, where=(ps != 0))</div>
<div class="line"><span class="lineno">  887</span> </div>
<div class="line"><span class="lineno">  888</span>    <span class="comment"># When no positive label in y_true, recall is set to 1 for all thresholds</span></div>
<div class="line"><span class="lineno">  889</span>    <span class="comment"># tps[-1] == 0 &lt;=&gt; y_true == all negative labels</span></div>
<div class="line"><span class="lineno">  890</span>    <span class="keywordflow">if</span> tps[-1] == 0:</div>
<div class="line"><span class="lineno">  891</span>        warnings.warn(</div>
<div class="line"><span class="lineno">  892</span>            <span class="stringliteral">&quot;No positive class found in y_true, &quot;</span></div>
<div class="line"><span class="lineno">  893</span>            <span class="stringliteral">&quot;recall is set to one for all thresholds.&quot;</span></div>
<div class="line"><span class="lineno">  894</span>        )</div>
<div class="line"><span class="lineno">  895</span>        recall = np.ones_like(tps)</div>
<div class="line"><span class="lineno">  896</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  897</span>        recall = tps / tps[-1]</div>
<div class="line"><span class="lineno">  898</span> </div>
<div class="line"><span class="lineno">  899</span>    <span class="comment"># reverse the outputs so recall is decreasing</span></div>
<div class="line"><span class="lineno">  900</span>    sl = slice(<span class="keywordtype">None</span>, <span class="keywordtype">None</span>, -1)</div>
<div class="line"><span class="lineno">  901</span>    <span class="keywordflow">return</span> np.hstack((precision[sl], 1)), np.hstack((recall[sl], 0)), thresholds[sl]</div>
<div class="line"><span class="lineno">  902</span> </div>
<div class="line"><span class="lineno">  903</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5d99ca10e2fbc9c27128ba2d1744d22d" name="a5d99ca10e2fbc9c27128ba2d1744d22d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5d99ca10e2fbc9c27128ba2d1744d22d">&#9670;&#160;</a></span>roc_auc_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.roc_auc_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>average</em> = <code>&quot;macro&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_fpr</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multi_class</em> = <code>&quot;raise&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \
from prediction scores.

Note: this implementation can be used with binary, multiclass and
multilabel classification, but some restrictions apply (see Parameters).

Read more in the :ref:`User Guide &lt;roc_metrics&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,) or (n_samples, n_classes)
    True labels or binary label indicators. The binary and multiclass cases
    expect labels with shape (n_samples,) while the multilabel case expects
    binary label indicators with shape (n_samples, n_classes).

y_score : array-like of shape (n_samples,) or (n_samples, n_classes)
    Target scores.

    * In the binary case, it corresponds to an array of shape
      `(n_samples,)`. Both probability estimates and non-thresholded
      decision values can be provided. The probability estimates correspond
      to the **probability of the class with the greater label**,
      i.e. `estimator.classes_[1]` and thus
      `estimator.predict_proba(X, y)[:, 1]`. The decision values
      corresponds to the output of `estimator.decision_function(X, y)`.
      See more information in the :ref:`User guide &lt;roc_auc_binary&gt;`;
    * In the multiclass case, it corresponds to an array of shape
      `(n_samples, n_classes)` of probability estimates provided by the
      `predict_proba` method. The probability estimates **must**
      sum to 1 across the possible classes. In addition, the order of the
      class scores must correspond to the order of ``labels``,
      if provided, or else to the numerical or lexicographical order of
      the labels in ``y_true``. See more information in the
      :ref:`User guide &lt;roc_auc_multiclass&gt;`;
    * In the multilabel case, it corresponds to an array of shape
      `(n_samples, n_classes)`. Probability estimates are provided by the
      `predict_proba` method and the non-thresholded decision values by
      the `decision_function` method. The probability estimates correspond
      to the **probability of the class with the greater label for each
      output** of the classifier. See more information in the
      :ref:`User guide &lt;roc_auc_multilabel&gt;`.

average : {'micro', 'macro', 'samples', 'weighted'} or None, \
        default='macro'
    If ``None``, the scores for each class are returned.
    Otherwise, this determines the type of averaging performed on the data.
    Note: multiclass ROC AUC currently only handles the 'macro' and
    'weighted' averages. For multiclass targets, `average=None` is only
    implemented for `multi_class='ovo'` and `average='micro'` is only
    implemented for `multi_class='ovr'`.

    ``'micro'``:
        Calculate metrics globally by considering each element of the label
        indicator matrix as a label.
    ``'macro'``:
        Calculate metrics for each label, and find their unweighted
        mean.  This does not take label imbalance into account.
    ``'weighted'``:
        Calculate metrics for each label, and find their average, weighted
        by support (the number of true instances for each label).
    ``'samples'``:
        Calculate metrics for each instance, and find their average.

    Will be ignored when ``y_true`` is binary.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

max_fpr : float &gt; 0 and &lt;= 1, default=None
    If not ``None``, the standardized partial AUC [2]_ over the range
    [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,
    should be either equal to ``None`` or ``1.0`` as AUC ROC partial
    computation currently is not supported for multiclass.

multi_class : {'raise', 'ovr', 'ovo'}, default='raise'
    Only used for multiclass targets. Determines the type of configuration
    to use. The default value raises an error, so either
    ``'ovr'`` or ``'ovo'`` must be passed explicitly.

    ``'ovr'``:
        Stands for One-vs-rest. Computes the AUC of each class
        against the rest [3]_ [4]_. This
        treats the multiclass case in the same way as the multilabel case.
        Sensitive to class imbalance even when ``average == 'macro'``,
        because class imbalance affects the composition of each of the
        'rest' groupings.
    ``'ovo'``:
        Stands for One-vs-one. Computes the average AUC of all
        possible pairwise combinations of classes [5]_.
        Insensitive to class imbalance when
        ``average == 'macro'``.

labels : array-like of shape (n_classes,), default=None
    Only used for multiclass targets. List of labels that index the
    classes in ``y_score``. If ``None``, the numerical or lexicographical
    order of the labels in ``y_true`` is used.

Returns
-------
auc : float
    Area Under the Curve score.

See Also
--------
average_precision_score : Area under the precision-recall curve.
roc_curve : Compute Receiver operating characteristic (ROC) curve.
RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic
    (ROC) curve given an estimator and some data.
RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic
    (ROC) curve given the true and predicted values.

References
----------
.. [1] `Wikipedia entry for the Receiver operating characteristic
        &lt;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&gt;`_

.. [2] `Analyzing a portion of the ROC curve. McClish, 1989
        &lt;https://www.ncbi.nlm.nih.gov/pubmed/2668680&gt;`_

.. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving
       probability estimation trees (Section 6.2), CeDER Working Paper
       #IS-00-04, Stern School of Business, New York University.

.. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern
        Recognition Letters, 27(8), 861-874.
        &lt;https://www.sciencedirect.com/science/article/pii/S016786550500303X&gt;`_

.. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area
        Under the ROC Curve for Multiple Class Classification Problems.
        Machine Learning, 45(2), 171-186.
        &lt;http://link.springer.com/article/10.1023/A:1010920819831&gt;`_

Examples
--------
Binary case:

&gt;&gt;&gt; from sklearn.datasets import load_breast_cancer
&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression
&gt;&gt;&gt; from sklearn.metrics import roc_auc_score
&gt;&gt;&gt; X, y = load_breast_cancer(return_X_y=True)
&gt;&gt;&gt; clf = LogisticRegression(solver="liblinear", random_state=0).fit(X, y)
&gt;&gt;&gt; roc_auc_score(y, clf.predict_proba(X)[:, 1])
0.99...
&gt;&gt;&gt; roc_auc_score(y, clf.decision_function(X))
0.99...

Multiclass case:

&gt;&gt;&gt; from sklearn.datasets import load_iris
&gt;&gt;&gt; X, y = load_iris(return_X_y=True)
&gt;&gt;&gt; clf = LogisticRegression(solver="liblinear").fit(X, y)
&gt;&gt;&gt; roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')
0.99...

Multilabel case:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.datasets import make_multilabel_classification
&gt;&gt;&gt; from sklearn.multioutput import MultiOutputClassifier
&gt;&gt;&gt; X, y = make_multilabel_classification(random_state=0)
&gt;&gt;&gt; clf = MultiOutputClassifier(clf).fit(X, y)
&gt;&gt;&gt; # get a list of n_output containing probability arrays of shape
&gt;&gt;&gt; # (n_samples, n_classes)
&gt;&gt;&gt; y_pred = clf.predict_proba(X)
&gt;&gt;&gt; # extract the positive columns for each output
&gt;&gt;&gt; y_pred = np.transpose([pred[:, 1] for pred in y_pred])
&gt;&gt;&gt; roc_auc_score(y, y_pred, average=None)
array([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])
&gt;&gt;&gt; from sklearn.linear_model import RidgeClassifierCV
&gt;&gt;&gt; clf = RidgeClassifierCV().fit(X, y)
&gt;&gt;&gt; roc_auc_score(y, clf.decision_function(X), average=None)
array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])
</pre> <div class="fragment"><div class="line"><span class="lineno">  374</span>):</div>
<div class="line"><span class="lineno">  375</span>    <span class="stringliteral">&quot;&quot;&quot;Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \</span></div>
<div class="line"><span class="lineno">  376</span><span class="stringliteral">    from prediction scores.</span></div>
<div class="line"><span class="lineno">  377</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  378</span><span class="stringliteral">    Note: this implementation can be used with binary, multiclass and</span></div>
<div class="line"><span class="lineno">  379</span><span class="stringliteral">    multilabel classification, but some restrictions apply (see Parameters).</span></div>
<div class="line"><span class="lineno">  380</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  381</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;roc_metrics&gt;`.</span></div>
<div class="line"><span class="lineno">  382</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  383</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  384</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  385</span><span class="stringliteral">    y_true : array-like of shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  386</span><span class="stringliteral">        True labels or binary label indicators. The binary and multiclass cases</span></div>
<div class="line"><span class="lineno">  387</span><span class="stringliteral">        expect labels with shape (n_samples,) while the multilabel case expects</span></div>
<div class="line"><span class="lineno">  388</span><span class="stringliteral">        binary label indicators with shape (n_samples, n_classes).</span></div>
<div class="line"><span class="lineno">  389</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  390</span><span class="stringliteral">    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  391</span><span class="stringliteral">        Target scores.</span></div>
<div class="line"><span class="lineno">  392</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  393</span><span class="stringliteral">        * In the binary case, it corresponds to an array of shape</span></div>
<div class="line"><span class="lineno">  394</span><span class="stringliteral">          `(n_samples,)`. Both probability estimates and non-thresholded</span></div>
<div class="line"><span class="lineno">  395</span><span class="stringliteral">          decision values can be provided. The probability estimates correspond</span></div>
<div class="line"><span class="lineno">  396</span><span class="stringliteral">          to the **probability of the class with the greater label**,</span></div>
<div class="line"><span class="lineno">  397</span><span class="stringliteral">          i.e. `estimator.classes_[1]` and thus</span></div>
<div class="line"><span class="lineno">  398</span><span class="stringliteral">          `estimator.predict_proba(X, y)[:, 1]`. The decision values</span></div>
<div class="line"><span class="lineno">  399</span><span class="stringliteral">          corresponds to the output of `estimator.decision_function(X, y)`.</span></div>
<div class="line"><span class="lineno">  400</span><span class="stringliteral">          See more information in the :ref:`User guide &lt;roc_auc_binary&gt;`;</span></div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral">        * In the multiclass case, it corresponds to an array of shape</span></div>
<div class="line"><span class="lineno">  402</span><span class="stringliteral">          `(n_samples, n_classes)` of probability estimates provided by the</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral">          `predict_proba` method. The probability estimates **must**</span></div>
<div class="line"><span class="lineno">  404</span><span class="stringliteral">          sum to 1 across the possible classes. In addition, the order of the</span></div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral">          class scores must correspond to the order of ``labels``,</span></div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">          if provided, or else to the numerical or lexicographical order of</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral">          the labels in ``y_true``. See more information in the</span></div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral">          :ref:`User guide &lt;roc_auc_multiclass&gt;`;</span></div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral">        * In the multilabel case, it corresponds to an array of shape</span></div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral">          `(n_samples, n_classes)`. Probability estimates are provided by the</span></div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral">          `predict_proba` method and the non-thresholded decision values by</span></div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral">          the `decision_function` method. The probability estimates correspond</span></div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral">          to the **probability of the class with the greater label for each</span></div>
<div class="line"><span class="lineno">  414</span><span class="stringliteral">          output** of the classifier. See more information in the</span></div>
<div class="line"><span class="lineno">  415</span><span class="stringliteral">          :ref:`User guide &lt;roc_auc_multilabel&gt;`.</span></div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;} or None, \</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">            default=&#39;macro&#39;</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">        If ``None``, the scores for each class are returned.</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral">        Otherwise, this determines the type of averaging performed on the data.</span></div>
<div class="line"><span class="lineno">  421</span><span class="stringliteral">        Note: multiclass ROC AUC currently only handles the &#39;macro&#39; and</span></div>
<div class="line"><span class="lineno">  422</span><span class="stringliteral">        &#39;weighted&#39; averages. For multiclass targets, `average=None` is only</span></div>
<div class="line"><span class="lineno">  423</span><span class="stringliteral">        implemented for `multi_class=&#39;ovo&#39;` and `average=&#39;micro&#39;` is only</span></div>
<div class="line"><span class="lineno">  424</span><span class="stringliteral">        implemented for `multi_class=&#39;ovr&#39;`.</span></div>
<div class="line"><span class="lineno">  425</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  426</span><span class="stringliteral">        ``&#39;micro&#39;``:</span></div>
<div class="line"><span class="lineno">  427</span><span class="stringliteral">            Calculate metrics globally by considering each element of the label</span></div>
<div class="line"><span class="lineno">  428</span><span class="stringliteral">            indicator matrix as a label.</span></div>
<div class="line"><span class="lineno">  429</span><span class="stringliteral">        ``&#39;macro&#39;``:</span></div>
<div class="line"><span class="lineno">  430</span><span class="stringliteral">            Calculate metrics for each label, and find their unweighted</span></div>
<div class="line"><span class="lineno">  431</span><span class="stringliteral">            mean.  This does not take label imbalance into account.</span></div>
<div class="line"><span class="lineno">  432</span><span class="stringliteral">        ``&#39;weighted&#39;``:</span></div>
<div class="line"><span class="lineno">  433</span><span class="stringliteral">            Calculate metrics for each label, and find their average, weighted</span></div>
<div class="line"><span class="lineno">  434</span><span class="stringliteral">            by support (the number of true instances for each label).</span></div>
<div class="line"><span class="lineno">  435</span><span class="stringliteral">        ``&#39;samples&#39;``:</span></div>
<div class="line"><span class="lineno">  436</span><span class="stringliteral">            Calculate metrics for each instance, and find their average.</span></div>
<div class="line"><span class="lineno">  437</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  438</span><span class="stringliteral">        Will be ignored when ``y_true`` is binary.</span></div>
<div class="line"><span class="lineno">  439</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  440</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  441</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  442</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  443</span><span class="stringliteral">    max_fpr : float &gt; 0 and &lt;= 1, default=None</span></div>
<div class="line"><span class="lineno">  444</span><span class="stringliteral">        If not ``None``, the standardized partial AUC [2]_ over the range</span></div>
<div class="line"><span class="lineno">  445</span><span class="stringliteral">        [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,</span></div>
<div class="line"><span class="lineno">  446</span><span class="stringliteral">        should be either equal to ``None`` or ``1.0`` as AUC ROC partial</span></div>
<div class="line"><span class="lineno">  447</span><span class="stringliteral">        computation currently is not supported for multiclass.</span></div>
<div class="line"><span class="lineno">  448</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  449</span><span class="stringliteral">    multi_class : {&#39;raise&#39;, &#39;ovr&#39;, &#39;ovo&#39;}, default=&#39;raise&#39;</span></div>
<div class="line"><span class="lineno">  450</span><span class="stringliteral">        Only used for multiclass targets. Determines the type of configuration</span></div>
<div class="line"><span class="lineno">  451</span><span class="stringliteral">        to use. The default value raises an error, so either</span></div>
<div class="line"><span class="lineno">  452</span><span class="stringliteral">        ``&#39;ovr&#39;`` or ``&#39;ovo&#39;`` must be passed explicitly.</span></div>
<div class="line"><span class="lineno">  453</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  454</span><span class="stringliteral">        ``&#39;ovr&#39;``:</span></div>
<div class="line"><span class="lineno">  455</span><span class="stringliteral">            Stands for One-vs-rest. Computes the AUC of each class</span></div>
<div class="line"><span class="lineno">  456</span><span class="stringliteral">            against the rest [3]_ [4]_. This</span></div>
<div class="line"><span class="lineno">  457</span><span class="stringliteral">            treats the multiclass case in the same way as the multilabel case.</span></div>
<div class="line"><span class="lineno">  458</span><span class="stringliteral">            Sensitive to class imbalance even when ``average == &#39;macro&#39;``,</span></div>
<div class="line"><span class="lineno">  459</span><span class="stringliteral">            because class imbalance affects the composition of each of the</span></div>
<div class="line"><span class="lineno">  460</span><span class="stringliteral">            &#39;rest&#39; groupings.</span></div>
<div class="line"><span class="lineno">  461</span><span class="stringliteral">        ``&#39;ovo&#39;``:</span></div>
<div class="line"><span class="lineno">  462</span><span class="stringliteral">            Stands for One-vs-one. Computes the average AUC of all</span></div>
<div class="line"><span class="lineno">  463</span><span class="stringliteral">            possible pairwise combinations of classes [5]_.</span></div>
<div class="line"><span class="lineno">  464</span><span class="stringliteral">            Insensitive to class imbalance when</span></div>
<div class="line"><span class="lineno">  465</span><span class="stringliteral">            ``average == &#39;macro&#39;``.</span></div>
<div class="line"><span class="lineno">  466</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  467</span><span class="stringliteral">    labels : array-like of shape (n_classes,), default=None</span></div>
<div class="line"><span class="lineno">  468</span><span class="stringliteral">        Only used for multiclass targets. List of labels that index the</span></div>
<div class="line"><span class="lineno">  469</span><span class="stringliteral">        classes in ``y_score``. If ``None``, the numerical or lexicographical</span></div>
<div class="line"><span class="lineno">  470</span><span class="stringliteral">        order of the labels in ``y_true`` is used.</span></div>
<div class="line"><span class="lineno">  471</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  472</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  473</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  474</span><span class="stringliteral">    auc : float</span></div>
<div class="line"><span class="lineno">  475</span><span class="stringliteral">        Area Under the Curve score.</span></div>
<div class="line"><span class="lineno">  476</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  477</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  478</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  479</span><span class="stringliteral">    average_precision_score : Area under the precision-recall curve.</span></div>
<div class="line"><span class="lineno">  480</span><span class="stringliteral">    roc_curve : Compute Receiver operating characteristic (ROC) curve.</span></div>
<div class="line"><span class="lineno">  481</span><span class="stringliteral">    RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic</span></div>
<div class="line"><span class="lineno">  482</span><span class="stringliteral">        (ROC) curve given an estimator and some data.</span></div>
<div class="line"><span class="lineno">  483</span><span class="stringliteral">    RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic</span></div>
<div class="line"><span class="lineno">  484</span><span class="stringliteral">        (ROC) curve given the true and predicted values.</span></div>
<div class="line"><span class="lineno">  485</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  486</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  487</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  488</span><span class="stringliteral">    .. [1] `Wikipedia entry for the Receiver operating characteristic</span></div>
<div class="line"><span class="lineno">  489</span><span class="stringliteral">            &lt;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&gt;`_</span></div>
<div class="line"><span class="lineno">  490</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  491</span><span class="stringliteral">    .. [2] `Analyzing a portion of the ROC curve. McClish, 1989</span></div>
<div class="line"><span class="lineno">  492</span><span class="stringliteral">            &lt;https://www.ncbi.nlm.nih.gov/pubmed/2668680&gt;`_</span></div>
<div class="line"><span class="lineno">  493</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  494</span><span class="stringliteral">    .. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving</span></div>
<div class="line"><span class="lineno">  495</span><span class="stringliteral">           probability estimation trees (Section 6.2), CeDER Working Paper</span></div>
<div class="line"><span class="lineno">  496</span><span class="stringliteral">           #IS-00-04, Stern School of Business, New York University.</span></div>
<div class="line"><span class="lineno">  497</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  498</span><span class="stringliteral">    .. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern</span></div>
<div class="line"><span class="lineno">  499</span><span class="stringliteral">            Recognition Letters, 27(8), 861-874.</span></div>
<div class="line"><span class="lineno">  500</span><span class="stringliteral">            &lt;https://www.sciencedirect.com/science/article/pii/S016786550500303X&gt;`_</span></div>
<div class="line"><span class="lineno">  501</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  502</span><span class="stringliteral">    .. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area</span></div>
<div class="line"><span class="lineno">  503</span><span class="stringliteral">            Under the ROC Curve for Multiple Class Classification Problems.</span></div>
<div class="line"><span class="lineno">  504</span><span class="stringliteral">            Machine Learning, 45(2), 171-186.</span></div>
<div class="line"><span class="lineno">  505</span><span class="stringliteral">            &lt;http://link.springer.com/article/10.1023/A:1010920819831&gt;`_</span></div>
<div class="line"><span class="lineno">  506</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  507</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  508</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  509</span><span class="stringliteral">    Binary case:</span></div>
<div class="line"><span class="lineno">  510</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  511</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.datasets import load_breast_cancer</span></div>
<div class="line"><span class="lineno">  512</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression</span></div>
<div class="line"><span class="lineno">  513</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import roc_auc_score</span></div>
<div class="line"><span class="lineno">  514</span><span class="stringliteral">    &gt;&gt;&gt; X, y = load_breast_cancer(return_X_y=True)</span></div>
<div class="line"><span class="lineno">  515</span><span class="stringliteral">    &gt;&gt;&gt; clf = LogisticRegression(solver=&quot;liblinear&quot;, random_state=0).fit(X, y)</span></div>
<div class="line"><span class="lineno">  516</span><span class="stringliteral">    &gt;&gt;&gt; roc_auc_score(y, clf.predict_proba(X)[:, 1])</span></div>
<div class="line"><span class="lineno">  517</span><span class="stringliteral">    0.99...</span></div>
<div class="line"><span class="lineno">  518</span><span class="stringliteral">    &gt;&gt;&gt; roc_auc_score(y, clf.decision_function(X))</span></div>
<div class="line"><span class="lineno">  519</span><span class="stringliteral">    0.99...</span></div>
<div class="line"><span class="lineno">  520</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  521</span><span class="stringliteral">    Multiclass case:</span></div>
<div class="line"><span class="lineno">  522</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  523</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.datasets import load_iris</span></div>
<div class="line"><span class="lineno">  524</span><span class="stringliteral">    &gt;&gt;&gt; X, y = load_iris(return_X_y=True)</span></div>
<div class="line"><span class="lineno">  525</span><span class="stringliteral">    &gt;&gt;&gt; clf = LogisticRegression(solver=&quot;liblinear&quot;).fit(X, y)</span></div>
<div class="line"><span class="lineno">  526</span><span class="stringliteral">    &gt;&gt;&gt; roc_auc_score(y, clf.predict_proba(X), multi_class=&#39;ovr&#39;)</span></div>
<div class="line"><span class="lineno">  527</span><span class="stringliteral">    0.99...</span></div>
<div class="line"><span class="lineno">  528</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  529</span><span class="stringliteral">    Multilabel case:</span></div>
<div class="line"><span class="lineno">  530</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  531</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  532</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.datasets import make_multilabel_classification</span></div>
<div class="line"><span class="lineno">  533</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.multioutput import MultiOutputClassifier</span></div>
<div class="line"><span class="lineno">  534</span><span class="stringliteral">    &gt;&gt;&gt; X, y = make_multilabel_classification(random_state=0)</span></div>
<div class="line"><span class="lineno">  535</span><span class="stringliteral">    &gt;&gt;&gt; clf = MultiOutputClassifier(clf).fit(X, y)</span></div>
<div class="line"><span class="lineno">  536</span><span class="stringliteral">    &gt;&gt;&gt; # get a list of n_output containing probability arrays of shape</span></div>
<div class="line"><span class="lineno">  537</span><span class="stringliteral">    &gt;&gt;&gt; # (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  538</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = clf.predict_proba(X)</span></div>
<div class="line"><span class="lineno">  539</span><span class="stringliteral">    &gt;&gt;&gt; # extract the positive columns for each output</span></div>
<div class="line"><span class="lineno">  540</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = np.transpose([pred[:, 1] for pred in y_pred])</span></div>
<div class="line"><span class="lineno">  541</span><span class="stringliteral">    &gt;&gt;&gt; roc_auc_score(y, y_pred, average=None)</span></div>
<div class="line"><span class="lineno">  542</span><span class="stringliteral">    array([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])</span></div>
<div class="line"><span class="lineno">  543</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.linear_model import RidgeClassifierCV</span></div>
<div class="line"><span class="lineno">  544</span><span class="stringliteral">    &gt;&gt;&gt; clf = RidgeClassifierCV().fit(X, y)</span></div>
<div class="line"><span class="lineno">  545</span><span class="stringliteral">    &gt;&gt;&gt; roc_auc_score(y, clf.decision_function(X), average=None)</span></div>
<div class="line"><span class="lineno">  546</span><span class="stringliteral">    array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])</span></div>
<div class="line"><span class="lineno">  547</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  548</span> </div>
<div class="line"><span class="lineno">  549</span>    y_type = type_of_target(y_true, input_name=<span class="stringliteral">&quot;y_true&quot;</span>)</div>
<div class="line"><span class="lineno">  550</span>    y_true = check_array(y_true, ensure_2d=<span class="keyword">False</span>, dtype=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  551</span>    y_score = check_array(y_score, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  552</span> </div>
<div class="line"><span class="lineno">  553</span>    <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;multiclass&quot;</span> <span class="keywordflow">or</span> (</div>
<div class="line"><span class="lineno">  554</span>        y_type == <span class="stringliteral">&quot;binary&quot;</span> <span class="keywordflow">and</span> y_score.ndim == 2 <span class="keywordflow">and</span> y_score.shape[1] &gt; 2</div>
<div class="line"><span class="lineno">  555</span>    ):</div>
<div class="line"><span class="lineno">  556</span>        <span class="comment"># do not support partial ROC computation for multiclass</span></div>
<div class="line"><span class="lineno">  557</span>        <span class="keywordflow">if</span> max_fpr <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> max_fpr != 1.0:</div>
<div class="line"><span class="lineno">  558</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  559</span>                <span class="stringliteral">&quot;Partial AUC computation not available in &quot;</span></div>
<div class="line"><span class="lineno">  560</span>                <span class="stringliteral">&quot;multiclass setting, &#39;max_fpr&#39; must be&quot;</span></div>
<div class="line"><span class="lineno">  561</span>                <span class="stringliteral">&quot; set to `None`, received `max_fpr={0}` &quot;</span></div>
<div class="line"><span class="lineno">  562</span>                <span class="stringliteral">&quot;instead&quot;</span>.format(max_fpr)</div>
<div class="line"><span class="lineno">  563</span>            )</div>
<div class="line"><span class="lineno">  564</span>        <span class="keywordflow">if</span> multi_class == <span class="stringliteral">&quot;raise&quot;</span>:</div>
<div class="line"><span class="lineno">  565</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;multi_class must be in (&#39;ovo&#39;, &#39;ovr&#39;)&quot;</span>)</div>
<div class="line"><span class="lineno">  566</span>        <span class="keywordflow">return</span> _multiclass_roc_auc_score(</div>
<div class="line"><span class="lineno">  567</span>            y_true, y_score, labels, multi_class, average, sample_weight</div>
<div class="line"><span class="lineno">  568</span>        )</div>
<div class="line"><span class="lineno">  569</span>    <span class="keywordflow">elif</span> y_type == <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno">  570</span>        labels = np.unique(y_true)</div>
<div class="line"><span class="lineno">  571</span>        y_true = label_binarize(y_true, classes=labels)[:, 0]</div>
<div class="line"><span class="lineno">  572</span>        <span class="keywordflow">return</span> _average_binary_score(</div>
<div class="line"><span class="lineno">  573</span>            partial(_binary_roc_auc_score, max_fpr=max_fpr),</div>
<div class="line"><span class="lineno">  574</span>            y_true,</div>
<div class="line"><span class="lineno">  575</span>            y_score,</div>
<div class="line"><span class="lineno">  576</span>            average,</div>
<div class="line"><span class="lineno">  577</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  578</span>        )</div>
<div class="line"><span class="lineno">  579</span>    <span class="keywordflow">else</span>:  <span class="comment"># multilabel-indicator</span></div>
<div class="line"><span class="lineno">  580</span>        <span class="keywordflow">return</span> _average_binary_score(</div>
<div class="line"><span class="lineno">  581</span>            partial(_binary_roc_auc_score, max_fpr=max_fpr),</div>
<div class="line"><span class="lineno">  582</span>            y_true,</div>
<div class="line"><span class="lineno">  583</span>            y_score,</div>
<div class="line"><span class="lineno">  584</span>            average,</div>
<div class="line"><span class="lineno">  585</span>            sample_weight=sample_weight,</div>
<div class="line"><span class="lineno">  586</span>        )</div>
<div class="line"><span class="lineno">  587</span> </div>
<div class="line"><span class="lineno">  588</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab8290dcf9bd98dc304d10d4cf92feb0f" name="ab8290dcf9bd98dc304d10d4cf92feb0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab8290dcf9bd98dc304d10d4cf92feb0f">&#9670;&#160;</a></span>roc_curve()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.roc_curve </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>drop_intermediate</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute Receiver operating characteristic (ROC).

Note: this implementation is restricted to the binary classification task.

Read more in the :ref:`User Guide &lt;roc_metrics&gt;`.

Parameters
----------
y_true : ndarray of shape (n_samples,)
    True binary labels. If labels are not either {-1, 1} or {0, 1}, then
    pos_label should be explicitly given.

y_score : ndarray of shape (n_samples,)
    Target scores, can either be probability estimates of the positive
    class, confidence values, or non-thresholded measure of decisions
    (as returned by "decision_function" on some classifiers).

pos_label : int or str, default=None
    The label of the positive class.
    When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},
    ``pos_label`` is set to 1, otherwise an error will be raised.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

drop_intermediate : bool, default=True
    Whether to drop some suboptimal thresholds which would not appear
    on a plotted ROC curve. This is useful in order to create lighter
    ROC curves.

    .. versionadded:: 0.17
       parameter *drop_intermediate*.

Returns
-------
fpr : ndarray of shape (&gt;2,)
    Increasing false positive rates such that element i is the false
    positive rate of predictions with score &gt;= `thresholds[i]`.

tpr : ndarray of shape (&gt;2,)
    Increasing true positive rates such that element `i` is the true
    positive rate of predictions with score &gt;= `thresholds[i]`.

thresholds : ndarray of shape = (n_thresholds,)
    Decreasing thresholds on the decision function used to compute
    fpr and tpr. `thresholds[0]` represents no instances being predicted
    and is arbitrarily set to `max(y_score) + 1`.

See Also
--------
RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic
    (ROC) curve given an estimator and some data.
RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic
    (ROC) curve given the true and predicted values.
det_curve: Compute error rates for different probability thresholds.
roc_auc_score : Compute the area under the ROC curve.

Notes
-----
Since the thresholds are sorted from low to high values, they
are reversed upon returning them to ensure they correspond to both ``fpr``
and ``tpr``, which are sorted in reversed order during their calculation.

References
----------
.. [1] `Wikipedia entry for the Receiver operating characteristic
        &lt;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&gt;`_

.. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition
       Letters, 2006, 27(8):861-874.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn import metrics
&gt;&gt;&gt; y = np.array([1, 1, 2, 2])
&gt;&gt;&gt; scores = np.array([0.1, 0.4, 0.35, 0.8])
&gt;&gt;&gt; fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)
&gt;&gt;&gt; fpr
array([0. , 0. , 0.5, 0.5, 1. ])
&gt;&gt;&gt; tpr
array([0. , 0.5, 0.5, 1. , 1. ])
&gt;&gt;&gt; thresholds
array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])
</pre> <div class="fragment"><div class="line"><span class="lineno">  906</span>):</div>
<div class="line"><span class="lineno">  907</span>    <span class="stringliteral">&quot;&quot;&quot;Compute Receiver operating characteristic (ROC).</span></div>
<div class="line"><span class="lineno">  908</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  909</span><span class="stringliteral">    Note: this implementation is restricted to the binary classification task.</span></div>
<div class="line"><span class="lineno">  910</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  911</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;roc_metrics&gt;`.</span></div>
<div class="line"><span class="lineno">  912</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  913</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  914</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  915</span><span class="stringliteral">    y_true : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  916</span><span class="stringliteral">        True binary labels. If labels are not either {-1, 1} or {0, 1}, then</span></div>
<div class="line"><span class="lineno">  917</span><span class="stringliteral">        pos_label should be explicitly given.</span></div>
<div class="line"><span class="lineno">  918</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  919</span><span class="stringliteral">    y_score : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  920</span><span class="stringliteral">        Target scores, can either be probability estimates of the positive</span></div>
<div class="line"><span class="lineno">  921</span><span class="stringliteral">        class, confidence values, or non-thresholded measure of decisions</span></div>
<div class="line"><span class="lineno">  922</span><span class="stringliteral">        (as returned by &quot;decision_function&quot; on some classifiers).</span></div>
<div class="line"><span class="lineno">  923</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  924</span><span class="stringliteral">    pos_label : int or str, default=None</span></div>
<div class="line"><span class="lineno">  925</span><span class="stringliteral">        The label of the positive class.</span></div>
<div class="line"><span class="lineno">  926</span><span class="stringliteral">        When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},</span></div>
<div class="line"><span class="lineno">  927</span><span class="stringliteral">        ``pos_label`` is set to 1, otherwise an error will be raised.</span></div>
<div class="line"><span class="lineno">  928</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  929</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  930</span><span class="stringliteral">        Sample weights.</span></div>
<div class="line"><span class="lineno">  931</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  932</span><span class="stringliteral">    drop_intermediate : bool, default=True</span></div>
<div class="line"><span class="lineno">  933</span><span class="stringliteral">        Whether to drop some suboptimal thresholds which would not appear</span></div>
<div class="line"><span class="lineno">  934</span><span class="stringliteral">        on a plotted ROC curve. This is useful in order to create lighter</span></div>
<div class="line"><span class="lineno">  935</span><span class="stringliteral">        ROC curves.</span></div>
<div class="line"><span class="lineno">  936</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  937</span><span class="stringliteral">        .. versionadded:: 0.17</span></div>
<div class="line"><span class="lineno">  938</span><span class="stringliteral">           parameter *drop_intermediate*.</span></div>
<div class="line"><span class="lineno">  939</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  940</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  941</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  942</span><span class="stringliteral">    fpr : ndarray of shape (&gt;2,)</span></div>
<div class="line"><span class="lineno">  943</span><span class="stringliteral">        Increasing false positive rates such that element i is the false</span></div>
<div class="line"><span class="lineno">  944</span><span class="stringliteral">        positive rate of predictions with score &gt;= `thresholds[i]`.</span></div>
<div class="line"><span class="lineno">  945</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  946</span><span class="stringliteral">    tpr : ndarray of shape (&gt;2,)</span></div>
<div class="line"><span class="lineno">  947</span><span class="stringliteral">        Increasing true positive rates such that element `i` is the true</span></div>
<div class="line"><span class="lineno">  948</span><span class="stringliteral">        positive rate of predictions with score &gt;= `thresholds[i]`.</span></div>
<div class="line"><span class="lineno">  949</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  950</span><span class="stringliteral">    thresholds : ndarray of shape = (n_thresholds,)</span></div>
<div class="line"><span class="lineno">  951</span><span class="stringliteral">        Decreasing thresholds on the decision function used to compute</span></div>
<div class="line"><span class="lineno">  952</span><span class="stringliteral">        fpr and tpr. `thresholds[0]` represents no instances being predicted</span></div>
<div class="line"><span class="lineno">  953</span><span class="stringliteral">        and is arbitrarily set to `max(y_score) + 1`.</span></div>
<div class="line"><span class="lineno">  954</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  955</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  956</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  957</span><span class="stringliteral">    RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic</span></div>
<div class="line"><span class="lineno">  958</span><span class="stringliteral">        (ROC) curve given an estimator and some data.</span></div>
<div class="line"><span class="lineno">  959</span><span class="stringliteral">    RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic</span></div>
<div class="line"><span class="lineno">  960</span><span class="stringliteral">        (ROC) curve given the true and predicted values.</span></div>
<div class="line"><span class="lineno">  961</span><span class="stringliteral">    det_curve: Compute error rates for different probability thresholds.</span></div>
<div class="line"><span class="lineno">  962</span><span class="stringliteral">    roc_auc_score : Compute the area under the ROC curve.</span></div>
<div class="line"><span class="lineno">  963</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  964</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  965</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  966</span><span class="stringliteral">    Since the thresholds are sorted from low to high values, they</span></div>
<div class="line"><span class="lineno">  967</span><span class="stringliteral">    are reversed upon returning them to ensure they correspond to both ``fpr``</span></div>
<div class="line"><span class="lineno">  968</span><span class="stringliteral">    and ``tpr``, which are sorted in reversed order during their calculation.</span></div>
<div class="line"><span class="lineno">  969</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  970</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  971</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  972</span><span class="stringliteral">    .. [1] `Wikipedia entry for the Receiver operating characteristic</span></div>
<div class="line"><span class="lineno">  973</span><span class="stringliteral">            &lt;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&gt;`_</span></div>
<div class="line"><span class="lineno">  974</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  975</span><span class="stringliteral">    .. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition</span></div>
<div class="line"><span class="lineno">  976</span><span class="stringliteral">           Letters, 2006, 27(8):861-874.</span></div>
<div class="line"><span class="lineno">  977</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  978</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  979</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  980</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  981</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn import metrics</span></div>
<div class="line"><span class="lineno">  982</span><span class="stringliteral">    &gt;&gt;&gt; y = np.array([1, 1, 2, 2])</span></div>
<div class="line"><span class="lineno">  983</span><span class="stringliteral">    &gt;&gt;&gt; scores = np.array([0.1, 0.4, 0.35, 0.8])</span></div>
<div class="line"><span class="lineno">  984</span><span class="stringliteral">    &gt;&gt;&gt; fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)</span></div>
<div class="line"><span class="lineno">  985</span><span class="stringliteral">    &gt;&gt;&gt; fpr</span></div>
<div class="line"><span class="lineno">  986</span><span class="stringliteral">    array([0. , 0. , 0.5, 0.5, 1. ])</span></div>
<div class="line"><span class="lineno">  987</span><span class="stringliteral">    &gt;&gt;&gt; tpr</span></div>
<div class="line"><span class="lineno">  988</span><span class="stringliteral">    array([0. , 0.5, 0.5, 1. , 1. ])</span></div>
<div class="line"><span class="lineno">  989</span><span class="stringliteral">    &gt;&gt;&gt; thresholds</span></div>
<div class="line"><span class="lineno">  990</span><span class="stringliteral">    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])</span></div>
<div class="line"><span class="lineno">  991</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  992</span>    fps, tps, thresholds = _binary_clf_curve(</div>
<div class="line"><span class="lineno">  993</span>        y_true, y_score, pos_label=pos_label, sample_weight=sample_weight</div>
<div class="line"><span class="lineno">  994</span>    )</div>
<div class="line"><span class="lineno">  995</span> </div>
<div class="line"><span class="lineno">  996</span>    <span class="comment"># Attempt to drop thresholds corresponding to points in between and</span></div>
<div class="line"><span class="lineno">  997</span>    <span class="comment"># collinear with other points. These are always suboptimal and do not</span></div>
<div class="line"><span class="lineno">  998</span>    <span class="comment"># appear on a plotted ROC curve (and thus do not affect the AUC).</span></div>
<div class="line"><span class="lineno">  999</span>    <span class="comment"># Here np.diff(_, 2) is used as a &quot;second derivative&quot; to tell if there</span></div>
<div class="line"><span class="lineno"> 1000</span>    <span class="comment"># is a corner at the point. Both fps and tps must be tested to handle</span></div>
<div class="line"><span class="lineno"> 1001</span>    <span class="comment"># thresholds with multiple data points (which are combined in</span></div>
<div class="line"><span class="lineno"> 1002</span>    <span class="comment"># _binary_clf_curve). This keeps all cases where the point should be kept,</span></div>
<div class="line"><span class="lineno"> 1003</span>    <span class="comment"># but does not drop more complicated cases like fps = [1, 3, 7],</span></div>
<div class="line"><span class="lineno"> 1004</span>    <span class="comment"># tps = [1, 2, 4]; there is no harm in keeping too many thresholds.</span></div>
<div class="line"><span class="lineno"> 1005</span>    <span class="keywordflow">if</span> drop_intermediate <span class="keywordflow">and</span> len(fps) &gt; 2:</div>
<div class="line"><span class="lineno"> 1006</span>        optimal_idxs = np.where(</div>
<div class="line"><span class="lineno"> 1007</span>            np.r_[<span class="keyword">True</span>, np.logical_or(np.diff(fps, 2), np.diff(tps, 2)), <span class="keyword">True</span>]</div>
<div class="line"><span class="lineno"> 1008</span>        )[0]</div>
<div class="line"><span class="lineno"> 1009</span>        fps = fps[optimal_idxs]</div>
<div class="line"><span class="lineno"> 1010</span>        tps = tps[optimal_idxs]</div>
<div class="line"><span class="lineno"> 1011</span>        thresholds = thresholds[optimal_idxs]</div>
<div class="line"><span class="lineno"> 1012</span> </div>
<div class="line"><span class="lineno"> 1013</span>    <span class="comment"># Add an extra threshold position</span></div>
<div class="line"><span class="lineno"> 1014</span>    <span class="comment"># to make sure that the curve starts at (0, 0)</span></div>
<div class="line"><span class="lineno"> 1015</span>    tps = np.r_[0, tps]</div>
<div class="line"><span class="lineno"> 1016</span>    fps = np.r_[0, fps]</div>
<div class="line"><span class="lineno"> 1017</span>    thresholds = np.r_[thresholds[0] + 1, thresholds]</div>
<div class="line"><span class="lineno"> 1018</span> </div>
<div class="line"><span class="lineno"> 1019</span>    <span class="keywordflow">if</span> fps[-1] &lt;= 0:</div>
<div class="line"><span class="lineno"> 1020</span>        warnings.warn(</div>
<div class="line"><span class="lineno"> 1021</span>            <span class="stringliteral">&quot;No negative samples in y_true, false positive value should be meaningless&quot;</span>,</div>
<div class="line"><span class="lineno"> 1022</span>            UndefinedMetricWarning,</div>
<div class="line"><span class="lineno"> 1023</span>        )</div>
<div class="line"><span class="lineno"> 1024</span>        fpr = np.repeat(np.nan, fps.shape)</div>
<div class="line"><span class="lineno"> 1025</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1026</span>        fpr = fps / fps[-1]</div>
<div class="line"><span class="lineno"> 1027</span> </div>
<div class="line"><span class="lineno"> 1028</span>    <span class="keywordflow">if</span> tps[-1] &lt;= 0:</div>
<div class="line"><span class="lineno"> 1029</span>        warnings.warn(</div>
<div class="line"><span class="lineno"> 1030</span>            <span class="stringliteral">&quot;No positive samples in y_true, true positive value should be meaningless&quot;</span>,</div>
<div class="line"><span class="lineno"> 1031</span>            UndefinedMetricWarning,</div>
<div class="line"><span class="lineno"> 1032</span>        )</div>
<div class="line"><span class="lineno"> 1033</span>        tpr = np.repeat(np.nan, tps.shape)</div>
<div class="line"><span class="lineno"> 1034</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1035</span>        tpr = tps / tps[-1]</div>
<div class="line"><span class="lineno"> 1036</span> </div>
<div class="line"><span class="lineno"> 1037</span>    <span class="keywordflow">return</span> fpr, tpr, thresholds</div>
<div class="line"><span class="lineno"> 1038</span> </div>
<div class="line"><span class="lineno"> 1039</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad5e5b89cf08cfa61301a1c204023ea54" name="ad5e5b89cf08cfa61301a1c204023ea54"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad5e5b89cf08cfa61301a1c204023ea54">&#9670;&#160;</a></span>top_k_accuracy_score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.metrics._ranking.top_k_accuracy_score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>k</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>labels</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Top-k Accuracy classification score.

This metric computes the number of times where the correct label is among
the top `k` labels predicted (ranked by predicted scores). Note that the
multilabel case isn't covered here.

Read more in the :ref:`User Guide &lt;top_k_accuracy_score&gt;`

Parameters
----------
y_true : array-like of shape (n_samples,)
    True labels.

y_score : array-like of shape (n_samples,) or (n_samples, n_classes)
    Target scores. These can be either probability estimates or
    non-thresholded decision values (as returned by
    :term:`decision_function` on some classifiers).
    The binary case expects scores with shape (n_samples,) while the
    multiclass case expects scores with shape (n_samples, n_classes).
    In the multiclass case, the order of the class scores must
    correspond to the order of ``labels``, if provided, or else to
    the numerical or lexicographical order of the labels in ``y_true``.
    If ``y_true`` does not contain all the labels, ``labels`` must be
    provided.

k : int, default=2
    Number of most likely outcomes considered to find the correct label.

normalize : bool, default=True
    If `True`, return the fraction of correctly classified samples.
    Otherwise, return the number of correctly classified samples.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights. If `None`, all samples are given the same weight.

labels : array-like of shape (n_classes,), default=None
    Multiclass only. List of labels that index the classes in ``y_score``.
    If ``None``, the numerical or lexicographical order of the labels in
    ``y_true`` is used. If ``y_true`` does not contain all the labels,
    ``labels`` must be provided.

Returns
-------
score : float
    The top-k accuracy score. The best performance is 1 with
    `normalize == True` and the number of samples with
    `normalize == False`.

See Also
--------
accuracy_score : Compute the accuracy score. By default, the function will
    return the fraction of correct predictions divided by the total number
    of predictions.

Notes
-----
In cases where two or more labels are assigned equal predicted scores,
the labels with the highest indices will be chosen first. This might
impact the result if the correct label falls after the threshold because
of that.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import top_k_accuracy_score
&gt;&gt;&gt; y_true = np.array([0, 1, 2, 2])
&gt;&gt;&gt; y_score = np.array([[0.5, 0.2, 0.2],  # 0 is in top 2
...                     [0.3, 0.4, 0.2],  # 1 is in top 2
...                     [0.2, 0.4, 0.3],  # 2 is in top 2
...                     [0.7, 0.2, 0.1]]) # 2 isn't in top 2
&gt;&gt;&gt; top_k_accuracy_score(y_true, y_score, k=2)
0.75
&gt;&gt;&gt; # Not normalizing gives the number of "correctly" classified samples
&gt;&gt;&gt; top_k_accuracy_score(y_true, y_score, k=2, normalize=False)
3
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1670</span>):</div>
<div class="line"><span class="lineno"> 1671</span>    <span class="stringliteral">&quot;&quot;&quot;Top-k Accuracy classification score.</span></div>
<div class="line"><span class="lineno"> 1672</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1673</span><span class="stringliteral">    This metric computes the number of times where the correct label is among</span></div>
<div class="line"><span class="lineno"> 1674</span><span class="stringliteral">    the top `k` labels predicted (ranked by predicted scores). Note that the</span></div>
<div class="line"><span class="lineno"> 1675</span><span class="stringliteral">    multilabel case isn&#39;t covered here.</span></div>
<div class="line"><span class="lineno"> 1676</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1677</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;top_k_accuracy_score&gt;`</span></div>
<div class="line"><span class="lineno"> 1678</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1679</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno"> 1680</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno"> 1681</span><span class="stringliteral">    y_true : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno"> 1682</span><span class="stringliteral">        True labels.</span></div>
<div class="line"><span class="lineno"> 1683</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1684</span><span class="stringliteral">    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno"> 1685</span><span class="stringliteral">        Target scores. These can be either probability estimates or</span></div>
<div class="line"><span class="lineno"> 1686</span><span class="stringliteral">        non-thresholded decision values (as returned by</span></div>
<div class="line"><span class="lineno"> 1687</span><span class="stringliteral">        :term:`decision_function` on some classifiers).</span></div>
<div class="line"><span class="lineno"> 1688</span><span class="stringliteral">        The binary case expects scores with shape (n_samples,) while the</span></div>
<div class="line"><span class="lineno"> 1689</span><span class="stringliteral">        multiclass case expects scores with shape (n_samples, n_classes).</span></div>
<div class="line"><span class="lineno"> 1690</span><span class="stringliteral">        In the multiclass case, the order of the class scores must</span></div>
<div class="line"><span class="lineno"> 1691</span><span class="stringliteral">        correspond to the order of ``labels``, if provided, or else to</span></div>
<div class="line"><span class="lineno"> 1692</span><span class="stringliteral">        the numerical or lexicographical order of the labels in ``y_true``.</span></div>
<div class="line"><span class="lineno"> 1693</span><span class="stringliteral">        If ``y_true`` does not contain all the labels, ``labels`` must be</span></div>
<div class="line"><span class="lineno"> 1694</span><span class="stringliteral">        provided.</span></div>
<div class="line"><span class="lineno"> 1695</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1696</span><span class="stringliteral">    k : int, default=2</span></div>
<div class="line"><span class="lineno"> 1697</span><span class="stringliteral">        Number of most likely outcomes considered to find the correct label.</span></div>
<div class="line"><span class="lineno"> 1698</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1699</span><span class="stringliteral">    normalize : bool, default=True</span></div>
<div class="line"><span class="lineno"> 1700</span><span class="stringliteral">        If `True`, return the fraction of correctly classified samples.</span></div>
<div class="line"><span class="lineno"> 1701</span><span class="stringliteral">        Otherwise, return the number of correctly classified samples.</span></div>
<div class="line"><span class="lineno"> 1702</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1703</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno"> 1704</span><span class="stringliteral">        Sample weights. If `None`, all samples are given the same weight.</span></div>
<div class="line"><span class="lineno"> 1705</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1706</span><span class="stringliteral">    labels : array-like of shape (n_classes,), default=None</span></div>
<div class="line"><span class="lineno"> 1707</span><span class="stringliteral">        Multiclass only. List of labels that index the classes in ``y_score``.</span></div>
<div class="line"><span class="lineno"> 1708</span><span class="stringliteral">        If ``None``, the numerical or lexicographical order of the labels in</span></div>
<div class="line"><span class="lineno"> 1709</span><span class="stringliteral">        ``y_true`` is used. If ``y_true`` does not contain all the labels,</span></div>
<div class="line"><span class="lineno"> 1710</span><span class="stringliteral">        ``labels`` must be provided.</span></div>
<div class="line"><span class="lineno"> 1711</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1712</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno"> 1713</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno"> 1714</span><span class="stringliteral">    score : float</span></div>
<div class="line"><span class="lineno"> 1715</span><span class="stringliteral">        The top-k accuracy score. The best performance is 1 with</span></div>
<div class="line"><span class="lineno"> 1716</span><span class="stringliteral">        `normalize == True` and the number of samples with</span></div>
<div class="line"><span class="lineno"> 1717</span><span class="stringliteral">        `normalize == False`.</span></div>
<div class="line"><span class="lineno"> 1718</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1719</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno"> 1720</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1721</span><span class="stringliteral">    accuracy_score : Compute the accuracy score. By default, the function will</span></div>
<div class="line"><span class="lineno"> 1722</span><span class="stringliteral">        return the fraction of correct predictions divided by the total number</span></div>
<div class="line"><span class="lineno"> 1723</span><span class="stringliteral">        of predictions.</span></div>
<div class="line"><span class="lineno"> 1724</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1725</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno"> 1726</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno"> 1727</span><span class="stringliteral">    In cases where two or more labels are assigned equal predicted scores,</span></div>
<div class="line"><span class="lineno"> 1728</span><span class="stringliteral">    the labels with the highest indices will be chosen first. This might</span></div>
<div class="line"><span class="lineno"> 1729</span><span class="stringliteral">    impact the result if the correct label falls after the threshold because</span></div>
<div class="line"><span class="lineno"> 1730</span><span class="stringliteral">    of that.</span></div>
<div class="line"><span class="lineno"> 1731</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1732</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno"> 1733</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno"> 1734</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno"> 1735</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.metrics import top_k_accuracy_score</span></div>
<div class="line"><span class="lineno"> 1736</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([0, 1, 2, 2])</span></div>
<div class="line"><span class="lineno"> 1737</span><span class="stringliteral">    &gt;&gt;&gt; y_score = np.array([[0.5, 0.2, 0.2],  # 0 is in top 2</span></div>
<div class="line"><span class="lineno"> 1738</span><span class="stringliteral">    ...                     [0.3, 0.4, 0.2],  # 1 is in top 2</span></div>
<div class="line"><span class="lineno"> 1739</span><span class="stringliteral">    ...                     [0.2, 0.4, 0.3],  # 2 is in top 2</span></div>
<div class="line"><span class="lineno"> 1740</span><span class="stringliteral">    ...                     [0.7, 0.2, 0.1]]) # 2 isn&#39;t in top 2</span></div>
<div class="line"><span class="lineno"> 1741</span><span class="stringliteral">    &gt;&gt;&gt; top_k_accuracy_score(y_true, y_score, k=2)</span></div>
<div class="line"><span class="lineno"> 1742</span><span class="stringliteral">    0.75</span></div>
<div class="line"><span class="lineno"> 1743</span><span class="stringliteral">    &gt;&gt;&gt; # Not normalizing gives the number of &quot;correctly&quot; classified samples</span></div>
<div class="line"><span class="lineno"> 1744</span><span class="stringliteral">    &gt;&gt;&gt; top_k_accuracy_score(y_true, y_score, k=2, normalize=False)</span></div>
<div class="line"><span class="lineno"> 1745</span><span class="stringliteral">    3</span></div>
<div class="line"><span class="lineno"> 1746</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1747</span>    y_true = check_array(y_true, ensure_2d=<span class="keyword">False</span>, dtype=<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno"> 1748</span>    y_true = column_or_1d(y_true)</div>
<div class="line"><span class="lineno"> 1749</span>    y_type = type_of_target(y_true, input_name=<span class="stringliteral">&quot;y_true&quot;</span>)</div>
<div class="line"><span class="lineno"> 1750</span>    <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;binary&quot;</span> <span class="keywordflow">and</span> labels <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> len(labels) &gt; 2:</div>
<div class="line"><span class="lineno"> 1751</span>        y_type = <span class="stringliteral">&quot;multiclass&quot;</span></div>
<div class="line"><span class="lineno"> 1752</span>    <span class="keywordflow">if</span> y_type <span class="keywordflow">not</span> <span class="keywordflow">in</span> {<span class="stringliteral">&quot;binary&quot;</span>, <span class="stringliteral">&quot;multiclass&quot;</span>}:</div>
<div class="line"><span class="lineno"> 1753</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1754</span>            f<span class="stringliteral">&quot;y type must be &#39;binary&#39; or &#39;multiclass&#39;, got &#39;{y_type}&#39; instead.&quot;</span></div>
<div class="line"><span class="lineno"> 1755</span>        )</div>
<div class="line"><span class="lineno"> 1756</span>    y_score = check_array(y_score, ensure_2d=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno"> 1757</span>    <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno"> 1758</span>        <span class="keywordflow">if</span> y_score.ndim == 2 <span class="keywordflow">and</span> y_score.shape[1] != 1:</div>
<div class="line"><span class="lineno"> 1759</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1760</span>                <span class="stringliteral">&quot;`y_true` is binary while y_score is 2d with&quot;</span></div>
<div class="line"><span class="lineno"> 1761</span>                f<span class="stringliteral">&quot; {y_score.shape[1]} classes. If `y_true` does not contain all the&quot;</span></div>
<div class="line"><span class="lineno"> 1762</span>                <span class="stringliteral">&quot; labels, `labels` must be provided.&quot;</span></div>
<div class="line"><span class="lineno"> 1763</span>            )</div>
<div class="line"><span class="lineno"> 1764</span>        y_score = column_or_1d(y_score)</div>
<div class="line"><span class="lineno"> 1765</span> </div>
<div class="line"><span class="lineno"> 1766</span>    check_consistent_length(y_true, y_score, sample_weight)</div>
<div class="line"><span class="lineno"> 1767</span>    y_score_n_classes = y_score.shape[1] <span class="keywordflow">if</span> y_score.ndim == 2 <span class="keywordflow">else</span> 2</div>
<div class="line"><span class="lineno"> 1768</span> </div>
<div class="line"><span class="lineno"> 1769</span>    <span class="keywordflow">if</span> labels <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1770</span>        classes = _unique(y_true)</div>
<div class="line"><span class="lineno"> 1771</span>        n_classes = len(classes)</div>
<div class="line"><span class="lineno"> 1772</span> </div>
<div class="line"><span class="lineno"> 1773</span>        <span class="keywordflow">if</span> n_classes != y_score_n_classes:</div>
<div class="line"><span class="lineno"> 1774</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1775</span>                f<span class="stringliteral">&quot;Number of classes in &#39;y_true&#39; ({n_classes}) not equal &quot;</span></div>
<div class="line"><span class="lineno"> 1776</span>                f<span class="stringliteral">&quot;to the number of classes in &#39;y_score&#39; ({y_score_n_classes}).&quot;</span></div>
<div class="line"><span class="lineno"> 1777</span>                <span class="stringliteral">&quot;You can provide a list of all known classes by assigning it &quot;</span></div>
<div class="line"><span class="lineno"> 1778</span>                <span class="stringliteral">&quot;to the `labels` parameter.&quot;</span></div>
<div class="line"><span class="lineno"> 1779</span>            )</div>
<div class="line"><span class="lineno"> 1780</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1781</span>        labels = column_or_1d(labels)</div>
<div class="line"><span class="lineno"> 1782</span>        classes = _unique(labels)</div>
<div class="line"><span class="lineno"> 1783</span>        n_labels = len(labels)</div>
<div class="line"><span class="lineno"> 1784</span>        n_classes = len(classes)</div>
<div class="line"><span class="lineno"> 1785</span> </div>
<div class="line"><span class="lineno"> 1786</span>        <span class="keywordflow">if</span> n_classes != n_labels:</div>
<div class="line"><span class="lineno"> 1787</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Parameter &#39;labels&#39; must be unique.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1788</span> </div>
<div class="line"><span class="lineno"> 1789</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.array_equal(classes, labels):</div>
<div class="line"><span class="lineno"> 1790</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Parameter &#39;labels&#39; must be ordered.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1791</span> </div>
<div class="line"><span class="lineno"> 1792</span>        <span class="keywordflow">if</span> n_classes != y_score_n_classes:</div>
<div class="line"><span class="lineno"> 1793</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1794</span>                f<span class="stringliteral">&quot;Number of given labels ({n_classes}) not equal to the &quot;</span></div>
<div class="line"><span class="lineno"> 1795</span>                f<span class="stringliteral">&quot;number of classes in &#39;y_score&#39; ({y_score_n_classes}).&quot;</span></div>
<div class="line"><span class="lineno"> 1796</span>            )</div>
<div class="line"><span class="lineno"> 1797</span> </div>
<div class="line"><span class="lineno"> 1798</span>        <span class="keywordflow">if</span> len(np.setdiff1d(y_true, classes)):</div>
<div class="line"><span class="lineno"> 1799</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;&#39;y_true&#39; contains labels not in parameter &#39;labels&#39;.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1800</span> </div>
<div class="line"><span class="lineno"> 1801</span>    <span class="keywordflow">if</span> k &gt;= n_classes:</div>
<div class="line"><span class="lineno"> 1802</span>        warnings.warn(</div>
<div class="line"><span class="lineno"> 1803</span>            f<span class="stringliteral">&quot;&#39;k&#39; ({k}) greater than or equal to &#39;n_classes&#39; ({n_classes}) &quot;</span></div>
<div class="line"><span class="lineno"> 1804</span>            <span class="stringliteral">&quot;will result in a perfect score and is therefore meaningless.&quot;</span>,</div>
<div class="line"><span class="lineno"> 1805</span>            UndefinedMetricWarning,</div>
<div class="line"><span class="lineno"> 1806</span>        )</div>
<div class="line"><span class="lineno"> 1807</span> </div>
<div class="line"><span class="lineno"> 1808</span>    y_true_encoded = _encode(y_true, uniques=classes)</div>
<div class="line"><span class="lineno"> 1809</span> </div>
<div class="line"><span class="lineno"> 1810</span>    <span class="keywordflow">if</span> y_type == <span class="stringliteral">&quot;binary&quot;</span>:</div>
<div class="line"><span class="lineno"> 1811</span>        <span class="keywordflow">if</span> k == 1:</div>
<div class="line"><span class="lineno"> 1812</span>            threshold = 0.5 <span class="keywordflow">if</span> y_score.min() &gt;= 0 <span class="keywordflow">and</span> y_score.max() &lt;= 1 <span class="keywordflow">else</span> 0</div>
<div class="line"><span class="lineno"> 1813</span>            y_pred = (y_score &gt; threshold).astype(np.int64)</div>
<div class="line"><span class="lineno"> 1814</span>            hits = y_pred == y_true_encoded</div>
<div class="line"><span class="lineno"> 1815</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1816</span>            hits = np.ones_like(y_score, dtype=np.bool_)</div>
<div class="line"><span class="lineno"> 1817</span>    <span class="keywordflow">elif</span> y_type == <span class="stringliteral">&quot;multiclass&quot;</span>:</div>
<div class="line"><span class="lineno"> 1818</span>        sorted_pred = np.argsort(y_score, axis=1, kind=<span class="stringliteral">&quot;mergesort&quot;</span>)[:, ::-1]</div>
<div class="line"><span class="lineno"> 1819</span>        hits = (y_true_encoded == sorted_pred[:, :k].T).any(axis=0)</div>
<div class="line"><span class="lineno"> 1820</span> </div>
<div class="line"><span class="lineno"> 1821</span>    <span class="keywordflow">if</span> normalize:</div>
<div class="line"><span class="lineno"> 1822</span>        <span class="keywordflow">return</span> np.average(hits, weights=sample_weight)</div>
<div class="line"><span class="lineno"> 1823</span>    <span class="keywordflow">elif</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1824</span>        <span class="keywordflow">return</span> np.sum(hits)</div>
<div class="line"><span class="lineno"> 1825</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1826</span>        <span class="keywordflow">return</span> np.dot(hits, sample_weight)</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
