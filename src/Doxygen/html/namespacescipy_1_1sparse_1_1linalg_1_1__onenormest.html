<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: scipy.sparse.linalg._onenormest Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacescipy.html">scipy</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1sparse.html">sparse</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1sparse_1_1linalg.html">linalg</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html">_onenormest</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">scipy.sparse.linalg._onenormest Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a487451f8984fbd4f827e30122f6193fa" id="r_a487451f8984fbd4f827e30122f6193fa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a487451f8984fbd4f827e30122f6193fa">onenormest</a> (A, t=2, itmax=5, compute_v=False, compute_w=False)</td></tr>
<tr class="separator:a487451f8984fbd4f827e30122f6193fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c59e34b7f20089be1dbbb3dd1e74cd9" id="r_a6c59e34b7f20089be1dbbb3dd1e74cd9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a6c59e34b7f20089be1dbbb3dd1e74cd9">_blocked_elementwise</a> (<a class="el" href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a>)</td></tr>
<tr class="separator:a6c59e34b7f20089be1dbbb3dd1e74cd9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2786ba99350ad48c3f19b6ca13753407" id="r_a2786ba99350ad48c3f19b6ca13753407"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a2786ba99350ad48c3f19b6ca13753407">sign_round_up</a> (X)</td></tr>
<tr class="separator:a2786ba99350ad48c3f19b6ca13753407"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a375effb6d188d4f55d442c22c6040de1" id="r_a375effb6d188d4f55d442c22c6040de1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a375effb6d188d4f55d442c22c6040de1">_max_abs_axis1</a> (X)</td></tr>
<tr class="separator:a375effb6d188d4f55d442c22c6040de1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bc32c24d62abec07d76d2a72d0df146" id="r_a5bc32c24d62abec07d76d2a72d0df146"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a5bc32c24d62abec07d76d2a72d0df146">_sum_abs_axis0</a> (X)</td></tr>
<tr class="separator:a5bc32c24d62abec07d76d2a72d0df146"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe1c1007213f990620901314a4fa1861" id="r_abe1c1007213f990620901314a4fa1861"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#abe1c1007213f990620901314a4fa1861">elementary_vector</a> (<a class="el" href="__blas__subroutines_8h.html#a25eafceb38c8e75bc60701fea6623f71">n</a>, <a class="el" href="__lapack__subroutines_8h.html#a5325f1842789194c441b272cbf424674">i</a>)</td></tr>
<tr class="separator:abe1c1007213f990620901314a4fa1861"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43955773facab0542365aa81a0a9dec7" id="r_a43955773facab0542365aa81a0a9dec7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a43955773facab0542365aa81a0a9dec7">vectors_are_parallel</a> (v, <a class="el" href="__lapack__subroutines_8h.html#a817b85d82af73ef273fafbec623bb90b">w</a>)</td></tr>
<tr class="separator:a43955773facab0542365aa81a0a9dec7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2f3abf778690880d59a28c585fa82fd" id="r_ae2f3abf778690880d59a28c585fa82fd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#ae2f3abf778690880d59a28c585fa82fd">every_col_of_X_is_parallel_to_a_col_of_Y</a> (X, Y)</td></tr>
<tr class="separator:ae2f3abf778690880d59a28c585fa82fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c75efbe7421f805628a56af35bd4db4" id="r_a4c75efbe7421f805628a56af35bd4db4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a4c75efbe7421f805628a56af35bd4db4">column_needs_resampling</a> (<a class="el" href="__lapack__subroutines_8h.html#a5325f1842789194c441b272cbf424674">i</a>, X, Y=None)</td></tr>
<tr class="separator:a4c75efbe7421f805628a56af35bd4db4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90c93ccb94570f5d60945e26d4eb14a9" id="r_a90c93ccb94570f5d60945e26d4eb14a9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a90c93ccb94570f5d60945e26d4eb14a9">resample_column</a> (<a class="el" href="__lapack__subroutines_8h.html#a5325f1842789194c441b272cbf424674">i</a>, X)</td></tr>
<tr class="separator:a90c93ccb94570f5d60945e26d4eb14a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bdd1e4cd7d67752794864524ee86567" id="r_a8bdd1e4cd7d67752794864524ee86567"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a8bdd1e4cd7d67752794864524ee86567">less_than_or_close</a> (<a class="el" href="__blas__subroutines_8h.html#a4da0a64c77789ca4c8115aef76120fd2">a</a>, b)</td></tr>
<tr class="separator:a8bdd1e4cd7d67752794864524ee86567"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a375dfbe12bf612a77d4a7a12668fbc9e" id="r_a375dfbe12bf612a77d4a7a12668fbc9e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a375dfbe12bf612a77d4a7a12668fbc9e">_algorithm_2_2</a> (A, AT, t)</td></tr>
<tr class="separator:a375dfbe12bf612a77d4a7a12668fbc9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a089465a28b0c8de211665a22ca119bda" id="r_a089465a28b0c8de211665a22ca119bda"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__onenormest.html#a089465a28b0c8de211665a22ca119bda">_onenormest_core</a> (A, AT, t, itmax)</td></tr>
<tr class="separator:a089465a28b0c8de211665a22ca119bda"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Sparse block 1-norm estimator.
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a375dfbe12bf612a77d4a7a12668fbc9e" name="a375dfbe12bf612a77d4a7a12668fbc9e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a375dfbe12bf612a77d4a7a12668fbc9e">&#9670;&#160;</a></span>_algorithm_2_2()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest._algorithm_2_2 </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>AT</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>t</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">This is Algorithm 2.2.

Parameters
----------
A : ndarray or other linear operator
    A linear operator that can produce matrix products.
AT : ndarray or other linear operator
    The transpose of A.
t : int, optional
    A positive parameter controlling the tradeoff between
    accuracy versus time and memory usage.

Returns
-------
g : sequence
    A non-negative decreasing vector
    such that g[j] is a lower bound for the 1-norm
    of the column of A of jth largest 1-norm.
    The first entry of this vector is therefore a lower bound
    on the 1-norm of the linear operator A.
    This sequence has length t.
ind : sequence
    The ith entry of ind is the index of the column A whose 1-norm
    is given by g[i].
    This sequence of indices has length t, and its entries are
    chosen from range(n), possibly with repetition,
    where n is the order of the operator A.

Notes
-----
This algorithm is mainly for testing.
It uses the 'ind' array in a way that is similar to
its usage in algorithm 2.4. This algorithm 2.2 may be easier to test,
so it gives a chance of uncovering bugs related to indexing
which could have propagated less noticeably to algorithm 2.4.</pre> <div class="fragment"><div class="line"><span class="lineno">  220</span><span class="keyword">def </span>_algorithm_2_2(A, AT, t):</div>
<div class="line"><span class="lineno">  221</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">    This is Algorithm 2.2.</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">    A : ndarray or other linear operator</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">        A linear operator that can produce matrix products.</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">    AT : ndarray or other linear operator</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">        The transpose of A.</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">    t : int, optional</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">        A positive parameter controlling the tradeoff between</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">        accuracy versus time and memory usage.</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">    g : sequence</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">        A non-negative decreasing vector</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral">        such that g[j] is a lower bound for the 1-norm</span></div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        of the column of A of jth largest 1-norm.</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">        The first entry of this vector is therefore a lower bound</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">        on the 1-norm of the linear operator A.</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">        This sequence has length t.</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">    ind : sequence</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">        The ith entry of ind is the index of the column A whose 1-norm</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">        is given by g[i].</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">        This sequence of indices has length t, and its entries are</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">        chosen from range(n), possibly with repetition,</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">        where n is the order of the operator A.</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">    This algorithm is mainly for testing.</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">    It uses the &#39;ind&#39; array in a way that is similar to</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">    its usage in algorithm 2.4. This algorithm 2.2 may be easier to test,</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">    so it gives a chance of uncovering bugs related to indexing</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">    which could have propagated less noticeably to algorithm 2.4.</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  259</span>    A_linear_operator = aslinearoperator(A)</div>
<div class="line"><span class="lineno">  260</span>    AT_linear_operator = aslinearoperator(AT)</div>
<div class="line"><span class="lineno">  261</span>    n = A_linear_operator.shape[0]</div>
<div class="line"><span class="lineno">  262</span> </div>
<div class="line"><span class="lineno">  263</span>    <span class="comment"># Initialize the X block with columns of unit 1-norm.</span></div>
<div class="line"><span class="lineno">  264</span>    X = np.ones((n, t))</div>
<div class="line"><span class="lineno">  265</span>    <span class="keywordflow">if</span> t &gt; 1:</div>
<div class="line"><span class="lineno">  266</span>        X[:, 1:] = np.random.randint(0, 2, size=(n, t-1))*2 - 1</div>
<div class="line"><span class="lineno">  267</span>    X /= float(n)</div>
<div class="line"><span class="lineno">  268</span> </div>
<div class="line"><span class="lineno">  269</span>    <span class="comment"># Iteratively improve the lower bounds.</span></div>
<div class="line"><span class="lineno">  270</span>    <span class="comment"># Track extra things, to assert invariants for debugging.</span></div>
<div class="line"><span class="lineno">  271</span>    g_prev = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  272</span>    h_prev = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  273</span>    k = 1</div>
<div class="line"><span class="lineno">  274</span>    ind = range(t)</div>
<div class="line"><span class="lineno">  275</span>    <span class="keywordflow">while</span> <span class="keyword">True</span>:</div>
<div class="line"><span class="lineno">  276</span>        Y = np.asarray(A_linear_operator.matmat(X))</div>
<div class="line"><span class="lineno">  277</span>        g = _sum_abs_axis0(Y)</div>
<div class="line"><span class="lineno">  278</span>        best_j = np.argmax(g)</div>
<div class="line"><span class="lineno">  279</span>        g.sort()</div>
<div class="line"><span class="lineno">  280</span>        g = g[::-1]</div>
<div class="line"><span class="lineno">  281</span>        S = sign_round_up(Y)</div>
<div class="line"><span class="lineno">  282</span>        Z = np.asarray(AT_linear_operator.matmat(S))</div>
<div class="line"><span class="lineno">  283</span>        h = _max_abs_axis1(Z)</div>
<div class="line"><span class="lineno">  284</span> </div>
<div class="line"><span class="lineno">  285</span>        <span class="comment"># If this algorithm runs for fewer than two iterations,</span></div>
<div class="line"><span class="lineno">  286</span>        <span class="comment"># then its return values do not have the properties indicated</span></div>
<div class="line"><span class="lineno">  287</span>        <span class="comment"># in the description of the algorithm.</span></div>
<div class="line"><span class="lineno">  288</span>        <span class="comment"># In particular, the entries of g are not 1-norms of any</span></div>
<div class="line"><span class="lineno">  289</span>        <span class="comment"># column of A until the second iteration.</span></div>
<div class="line"><span class="lineno">  290</span>        <span class="comment"># Therefore we will require the algorithm to run for at least</span></div>
<div class="line"><span class="lineno">  291</span>        <span class="comment"># two iterations, even though this requirement is not stated</span></div>
<div class="line"><span class="lineno">  292</span>        <span class="comment"># in the description of the algorithm.</span></div>
<div class="line"><span class="lineno">  293</span>        <span class="keywordflow">if</span> k &gt;= 2:</div>
<div class="line"><span class="lineno">  294</span>            <span class="keywordflow">if</span> less_than_or_close(max(h), np.dot(Z[:, best_j], X[:, best_j])):</div>
<div class="line"><span class="lineno">  295</span>                <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  296</span>        ind = np.argsort(h)[::-1][:t]</div>
<div class="line"><span class="lineno">  297</span>        h = h[ind]</div>
<div class="line"><span class="lineno">  298</span>        <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(t):</div>
<div class="line"><span class="lineno">  299</span>            X[:, j] = elementary_vector(n, ind[j])</div>
<div class="line"><span class="lineno">  300</span> </div>
<div class="line"><span class="lineno">  301</span>        <span class="comment"># Check invariant (2.2).</span></div>
<div class="line"><span class="lineno">  302</span>        <span class="keywordflow">if</span> k &gt;= 2:</div>
<div class="line"><span class="lineno">  303</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> less_than_or_close(g_prev[0], h_prev[0]):</div>
<div class="line"><span class="lineno">  304</span>                <span class="keywordflow">raise</span> Exception(<span class="stringliteral">&#39;invariant (2.2) is violated&#39;</span>)</div>
<div class="line"><span class="lineno">  305</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> less_than_or_close(h_prev[0], g[0]):</div>
<div class="line"><span class="lineno">  306</span>                <span class="keywordflow">raise</span> Exception(<span class="stringliteral">&#39;invariant (2.2) is violated&#39;</span>)</div>
<div class="line"><span class="lineno">  307</span> </div>
<div class="line"><span class="lineno">  308</span>        <span class="comment"># Check invariant (2.3).</span></div>
<div class="line"><span class="lineno">  309</span>        <span class="keywordflow">if</span> k &gt;= 3:</div>
<div class="line"><span class="lineno">  310</span>            <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(t):</div>
<div class="line"><span class="lineno">  311</span>                <span class="keywordflow">if</span> <span class="keywordflow">not</span> less_than_or_close(g[j], g_prev[j]):</div>
<div class="line"><span class="lineno">  312</span>                    <span class="keywordflow">raise</span> Exception(<span class="stringliteral">&#39;invariant (2.3) is violated&#39;</span>)</div>
<div class="line"><span class="lineno">  313</span> </div>
<div class="line"><span class="lineno">  314</span>        <span class="comment"># Update for the next iteration.</span></div>
<div class="line"><span class="lineno">  315</span>        g_prev = g</div>
<div class="line"><span class="lineno">  316</span>        h_prev = h</div>
<div class="line"><span class="lineno">  317</span>        k += 1</div>
<div class="line"><span class="lineno">  318</span> </div>
<div class="line"><span class="lineno">  319</span>    <span class="comment"># Return the lower bounds and the corresponding column indices.</span></div>
<div class="line"><span class="lineno">  320</span>    <span class="keywordflow">return</span> g, ind</div>
<div class="line"><span class="lineno">  321</span> </div>
<div class="line"><span class="lineno">  322</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6c59e34b7f20089be1dbbb3dd1e74cd9" name="a6c59e34b7f20089be1dbbb3dd1e74cd9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c59e34b7f20089be1dbbb3dd1e74cd9">&#9670;&#160;</a></span>_blocked_elementwise()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest._blocked_elementwise </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>func</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Decorator for an elementwise function, to apply it blockwise along
first dimension, to avoid excessive memory usage in temporaries.
</pre> <div class="fragment"><div class="line"><span class="lineno">  120</span><span class="keyword">def </span>_blocked_elementwise(func):</div>
<div class="line"><span class="lineno">  121</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">    Decorator for an elementwise function, to apply it blockwise along</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">    first dimension, to avoid excessive memory usage in temporaries.</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  125</span>    block_size = 2**20</div>
<div class="line"><span class="lineno">  126</span> </div>
<div class="line"><span class="lineno">  127</span>    <span class="keyword">def </span>wrapper(x):</div>
<div class="line"><span class="lineno">  128</span>        <span class="keywordflow">if</span> x.shape[0] &lt; block_size:</div>
<div class="line"><span class="lineno">  129</span>            <span class="keywordflow">return</span> <a class="code hl_function" href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a>(x)</div>
<div class="line"><span class="lineno">  130</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  131</span>            y0 = <a class="code hl_function" href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a>(x[:block_size])</div>
<div class="line"><span class="lineno">  132</span>            y = np.zeros((x.shape[0],) + y0.shape[1:], dtype=y0.dtype)</div>
<div class="line"><span class="lineno">  133</span>            y[:block_size] = y0</div>
<div class="line"><span class="lineno">  134</span>            del y0</div>
<div class="line"><span class="lineno">  135</span>            <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(block_size, x.shape[0], block_size):</div>
<div class="line"><span class="lineno">  136</span>                y[j:j+block_size] = <a class="code hl_function" href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a>(x[j:j+block_size])</div>
<div class="line"><span class="lineno">  137</span>            <span class="keywordflow">return</span> y</div>
<div class="line"><span class="lineno">  138</span>    <span class="keywordflow">return</span> wrapper</div>
<div class="line"><span class="lineno">  139</span> </div>
<div class="line"><span class="lineno">  140</span> </div>
<div class="line"><span class="lineno">  141</span><span class="preprocessor">@_blocked_elementwise</span></div>
<div class="ttc" id="acallback_2foo_8f_html_a565fe2cc583df102f120752b0011c330"><div class="ttname"><a href="callback_2foo_8f.html#a565fe2cc583df102f120752b0011c330">func</a></div><div class="ttdeci">subroutine func(a)</div><div class="ttdef"><b>Definition</b> foo.f:9</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a375effb6d188d4f55d442c22c6040de1" name="a375effb6d188d4f55d442c22c6040de1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a375effb6d188d4f55d442c22c6040de1">&#9670;&#160;</a></span>_max_abs_axis1()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest._max_abs_axis1 </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  159</span><span class="keyword">def </span>_max_abs_axis1(X):</div>
<div class="line"><span class="lineno">  160</span>    <span class="keywordflow">return</span> np.max(np.abs(X), axis=1)</div>
<div class="line"><span class="lineno">  161</span> </div>
<div class="line"><span class="lineno">  162</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a089465a28b0c8de211665a22ca119bda" name="a089465a28b0c8de211665a22ca119bda"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a089465a28b0c8de211665a22ca119bda">&#9670;&#160;</a></span>_onenormest_core()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest._onenormest_core </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>AT</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>itmax</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute a lower bound of the 1-norm of a sparse matrix.

Parameters
----------
A : ndarray or other linear operator
    A linear operator that can produce matrix products.
AT : ndarray or other linear operator
    The transpose of A.
t : int, optional
    A positive parameter controlling the tradeoff between
    accuracy versus time and memory usage.
itmax : int, optional
    Use at most this many iterations.

Returns
-------
est : float
    An underestimate of the 1-norm of the sparse matrix.
v : ndarray, optional
    The vector such that ||Av||_1 == est*||v||_1.
    It can be thought of as an input to the linear operator
    that gives an output with particularly large norm.
w : ndarray, optional
    The vector Av which has relatively large 1-norm.
    It can be thought of as an output of the linear operator
    that is relatively large in norm compared to the input.
nmults : int, optional
    The number of matrix products that were computed.
nresamples : int, optional
    The number of times a parallel column was observed,
    necessitating a re-randomization of the column.

Notes
-----
This is algorithm 2.4.</pre> <div class="fragment"><div class="line"><span class="lineno">  323</span><span class="keyword">def </span>_onenormest_core(A, AT, t, itmax):</div>
<div class="line"><span class="lineno">  324</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  325</span><span class="stringliteral">    Compute a lower bound of the 1-norm of a sparse matrix.</span></div>
<div class="line"><span class="lineno">  326</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  327</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">    A : ndarray or other linear operator</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">        A linear operator that can produce matrix products.</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral">    AT : ndarray or other linear operator</span></div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">        The transpose of A.</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral">    t : int, optional</span></div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral">        A positive parameter controlling the tradeoff between</span></div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">        accuracy versus time and memory usage.</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral">    itmax : int, optional</span></div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral">        Use at most this many iterations.</span></div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral">    est : float</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral">        An underestimate of the 1-norm of the sparse matrix.</span></div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral">    v : ndarray, optional</span></div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">        The vector such that ||Av||_1 == est*||v||_1.</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral">        It can be thought of as an input to the linear operator</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">        that gives an output with particularly large norm.</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">    w : ndarray, optional</span></div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral">        The vector Av which has relatively large 1-norm.</span></div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">        It can be thought of as an output of the linear operator</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">        that is relatively large in norm compared to the input.</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">    nmults : int, optional</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral">        The number of matrix products that were computed.</span></div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral">    nresamples : int, optional</span></div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">        The number of times a parallel column was observed,</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">        necessitating a re-randomization of the column.</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral">    This is algorithm 2.4.</span></div>
<div class="line"><span class="lineno">  360</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  361</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  362</span>    <span class="comment"># This function is a more or less direct translation</span></div>
<div class="line"><span class="lineno">  363</span>    <span class="comment"># of Algorithm 2.4 from the Higham and Tisseur (2000) paper.</span></div>
<div class="line"><span class="lineno">  364</span>    A_linear_operator = aslinearoperator(A)</div>
<div class="line"><span class="lineno">  365</span>    AT_linear_operator = aslinearoperator(AT)</div>
<div class="line"><span class="lineno">  366</span>    <span class="keywordflow">if</span> itmax &lt; 2:</div>
<div class="line"><span class="lineno">  367</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;at least two iterations are required&#39;</span>)</div>
<div class="line"><span class="lineno">  368</span>    <span class="keywordflow">if</span> t &lt; 1:</div>
<div class="line"><span class="lineno">  369</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;at least one column is required&#39;</span>)</div>
<div class="line"><span class="lineno">  370</span>    n = A.shape[0]</div>
<div class="line"><span class="lineno">  371</span>    <span class="keywordflow">if</span> t &gt;= n:</div>
<div class="line"><span class="lineno">  372</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;t should be smaller than the order of A&#39;</span>)</div>
<div class="line"><span class="lineno">  373</span>    <span class="comment"># Track the number of big*small matrix multiplications</span></div>
<div class="line"><span class="lineno">  374</span>    <span class="comment"># and the number of resamplings.</span></div>
<div class="line"><span class="lineno">  375</span>    nmults = 0</div>
<div class="line"><span class="lineno">  376</span>    nresamples = 0</div>
<div class="line"><span class="lineno">  377</span>    <span class="comment"># &quot;We now explain our choice of starting matrix.  We take the first</span></div>
<div class="line"><span class="lineno">  378</span>    <span class="comment"># column of X to be the vector of 1s [...] This has the advantage that</span></div>
<div class="line"><span class="lineno">  379</span>    <span class="comment"># for a matrix with nonnegative elements the algorithm converges</span></div>
<div class="line"><span class="lineno">  380</span>    <span class="comment"># with an exact estimate on the second iteration, and such matrices</span></div>
<div class="line"><span class="lineno">  381</span>    <span class="comment"># arise in applications [...]&quot;</span></div>
<div class="line"><span class="lineno">  382</span>    X = np.ones((n, t), dtype=float)</div>
<div class="line"><span class="lineno">  383</span>    <span class="comment"># &quot;The remaining columns are chosen as rand{-1,1},</span></div>
<div class="line"><span class="lineno">  384</span>    <span class="comment"># with a check for and correction of parallel columns,</span></div>
<div class="line"><span class="lineno">  385</span>    <span class="comment"># exactly as for S in the body of the algorithm.&quot;</span></div>
<div class="line"><span class="lineno">  386</span>    <span class="keywordflow">if</span> t &gt; 1:</div>
<div class="line"><span class="lineno">  387</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(1, t):</div>
<div class="line"><span class="lineno">  388</span>            <span class="comment"># These are technically initial samples, not resamples,</span></div>
<div class="line"><span class="lineno">  389</span>            <span class="comment"># so the resampling count is not incremented.</span></div>
<div class="line"><span class="lineno">  390</span>            resample_column(i, X)</div>
<div class="line"><span class="lineno">  391</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(t):</div>
<div class="line"><span class="lineno">  392</span>            <span class="keywordflow">while</span> column_needs_resampling(i, X):</div>
<div class="line"><span class="lineno">  393</span>                resample_column(i, X)</div>
<div class="line"><span class="lineno">  394</span>                nresamples += 1</div>
<div class="line"><span class="lineno">  395</span>    <span class="comment"># &quot;Choose starting matrix X with columns of unit 1-norm.&quot;</span></div>
<div class="line"><span class="lineno">  396</span>    X /= float(n)</div>
<div class="line"><span class="lineno">  397</span>    <span class="comment"># &quot;indices of used unit vectors e_j&quot;</span></div>
<div class="line"><span class="lineno">  398</span>    ind_hist = np.zeros(0, dtype=np.intp)</div>
<div class="line"><span class="lineno">  399</span>    est_old = 0</div>
<div class="line"><span class="lineno">  400</span>    S = np.zeros((n, t), dtype=float)</div>
<div class="line"><span class="lineno">  401</span>    k = 1</div>
<div class="line"><span class="lineno">  402</span>    ind = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  403</span>    <span class="keywordflow">while</span> <span class="keyword">True</span>:</div>
<div class="line"><span class="lineno">  404</span>        Y = np.asarray(A_linear_operator.matmat(X))</div>
<div class="line"><span class="lineno">  405</span>        nmults += 1</div>
<div class="line"><span class="lineno">  406</span>        mags = _sum_abs_axis0(Y)</div>
<div class="line"><span class="lineno">  407</span>        est = np.max(mags)</div>
<div class="line"><span class="lineno">  408</span>        best_j = np.argmax(mags)</div>
<div class="line"><span class="lineno">  409</span>        <span class="keywordflow">if</span> est &gt; est_old <span class="keywordflow">or</span> k == 2:</div>
<div class="line"><span class="lineno">  410</span>            <span class="keywordflow">if</span> k &gt;= 2:</div>
<div class="line"><span class="lineno">  411</span>                ind_best = ind[best_j]</div>
<div class="line"><span class="lineno">  412</span>            w = Y[:, best_j]</div>
<div class="line"><span class="lineno">  413</span>        <span class="comment"># (1)</span></div>
<div class="line"><span class="lineno">  414</span>        <span class="keywordflow">if</span> k &gt;= 2 <span class="keywordflow">and</span> est &lt;= est_old:</div>
<div class="line"><span class="lineno">  415</span>            est = est_old</div>
<div class="line"><span class="lineno">  416</span>            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  417</span>        est_old = est</div>
<div class="line"><span class="lineno">  418</span>        S_old = S</div>
<div class="line"><span class="lineno">  419</span>        <span class="keywordflow">if</span> k &gt; itmax:</div>
<div class="line"><span class="lineno">  420</span>            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  421</span>        S = sign_round_up(Y)</div>
<div class="line"><span class="lineno">  422</span>        del Y</div>
<div class="line"><span class="lineno">  423</span>        <span class="comment"># (2)</span></div>
<div class="line"><span class="lineno">  424</span>        <span class="keywordflow">if</span> every_col_of_X_is_parallel_to_a_col_of_Y(S, S_old):</div>
<div class="line"><span class="lineno">  425</span>            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  426</span>        <span class="keywordflow">if</span> t &gt; 1:</div>
<div class="line"><span class="lineno">  427</span>            <span class="comment"># &quot;Ensure that no column of S is parallel to another column of S</span></div>
<div class="line"><span class="lineno">  428</span>            <span class="comment"># or to a column of S_old by replacing columns of S by rand{-1,1}.&quot;</span></div>
<div class="line"><span class="lineno">  429</span>            <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(t):</div>
<div class="line"><span class="lineno">  430</span>                <span class="keywordflow">while</span> column_needs_resampling(i, S, S_old):</div>
<div class="line"><span class="lineno">  431</span>                    resample_column(i, S)</div>
<div class="line"><span class="lineno">  432</span>                    nresamples += 1</div>
<div class="line"><span class="lineno">  433</span>        del S_old</div>
<div class="line"><span class="lineno">  434</span>        <span class="comment"># (3)</span></div>
<div class="line"><span class="lineno">  435</span>        Z = np.asarray(AT_linear_operator.matmat(S))</div>
<div class="line"><span class="lineno">  436</span>        nmults += 1</div>
<div class="line"><span class="lineno">  437</span>        h = _max_abs_axis1(Z)</div>
<div class="line"><span class="lineno">  438</span>        del Z</div>
<div class="line"><span class="lineno">  439</span>        <span class="comment"># (4)</span></div>
<div class="line"><span class="lineno">  440</span>        <span class="keywordflow">if</span> k &gt;= 2 <span class="keywordflow">and</span> max(h) == h[ind_best]:</div>
<div class="line"><span class="lineno">  441</span>            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  442</span>        <span class="comment"># &quot;Sort h so that h_first &gt;= ... &gt;= h_last</span></div>
<div class="line"><span class="lineno">  443</span>        <span class="comment"># and re-order ind correspondingly.&quot;</span></div>
<div class="line"><span class="lineno">  444</span>        <span class="comment">#</span></div>
<div class="line"><span class="lineno">  445</span>        <span class="comment"># Later on, we will need at most t+len(ind_hist) largest</span></div>
<div class="line"><span class="lineno">  446</span>        <span class="comment"># entries, so drop the rest</span></div>
<div class="line"><span class="lineno">  447</span>        ind = np.argsort(h)[::-1][:t+len(ind_hist)].copy()</div>
<div class="line"><span class="lineno">  448</span>        del h</div>
<div class="line"><span class="lineno">  449</span>        <span class="keywordflow">if</span> t &gt; 1:</div>
<div class="line"><span class="lineno">  450</span>            <span class="comment"># (5)</span></div>
<div class="line"><span class="lineno">  451</span>            <span class="comment"># Break if the most promising t vectors have been visited already.</span></div>
<div class="line"><span class="lineno">  452</span>            <span class="keywordflow">if</span> np.in1d(ind[:t], ind_hist).all():</div>
<div class="line"><span class="lineno">  453</span>                <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  454</span>            <span class="comment"># Put the most promising unvisited vectors at the front of the list</span></div>
<div class="line"><span class="lineno">  455</span>            <span class="comment"># and put the visited vectors at the end of the list.</span></div>
<div class="line"><span class="lineno">  456</span>            <span class="comment"># Preserve the order of the indices induced by the ordering of h.</span></div>
<div class="line"><span class="lineno">  457</span>            seen = np.in1d(ind, ind_hist)</div>
<div class="line"><span class="lineno">  458</span>            ind = np.concatenate((ind[~seen], ind[seen]))</div>
<div class="line"><span class="lineno">  459</span>        <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(t):</div>
<div class="line"><span class="lineno">  460</span>            X[:, j] = elementary_vector(n, ind[j])</div>
<div class="line"><span class="lineno">  461</span> </div>
<div class="line"><span class="lineno">  462</span>        new_ind = ind[:t][~np.in1d(ind[:t], ind_hist)]</div>
<div class="line"><span class="lineno">  463</span>        ind_hist = np.concatenate((ind_hist, new_ind))</div>
<div class="line"><span class="lineno">  464</span>        k += 1</div>
<div class="line"><span class="lineno">  465</span>    v = elementary_vector(n, ind_best)</div>
<div class="line"><span class="lineno">  466</span>    <span class="keywordflow">return</span> est, v, w, nmults, nresamples</div>
</div><!-- fragment -->
</div>
</div>
<a id="a5bc32c24d62abec07d76d2a72d0df146" name="a5bc32c24d62abec07d76d2a72d0df146"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5bc32c24d62abec07d76d2a72d0df146">&#9670;&#160;</a></span>_sum_abs_axis0()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest._sum_abs_axis0 </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  163</span><span class="keyword">def </span>_sum_abs_axis0(X):</div>
<div class="line"><span class="lineno">  164</span>    block_size = 2**20</div>
<div class="line"><span class="lineno">  165</span>    r = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  166</span>    <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(0, X.shape[0], block_size):</div>
<div class="line"><span class="lineno">  167</span>        y = np.sum(np.abs(X[j:j+block_size]), axis=0)</div>
<div class="line"><span class="lineno">  168</span>        <span class="keywordflow">if</span> r <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  169</span>            r = y</div>
<div class="line"><span class="lineno">  170</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  171</span>            r += y</div>
<div class="line"><span class="lineno">  172</span>    <span class="keywordflow">return</span> r</div>
<div class="line"><span class="lineno">  173</span> </div>
<div class="line"><span class="lineno">  174</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4c75efbe7421f805628a56af35bd4db4" name="a4c75efbe7421f805628a56af35bd4db4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c75efbe7421f805628a56af35bd4db4">&#9670;&#160;</a></span>column_needs_resampling()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest.column_needs_resampling </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>i</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Y</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  198</span><span class="keyword">def </span>column_needs_resampling(i, X, Y=None):</div>
<div class="line"><span class="lineno">  199</span>    <span class="comment"># column i of X needs resampling if either</span></div>
<div class="line"><span class="lineno">  200</span>    <span class="comment"># it is parallel to a previous column of X or</span></div>
<div class="line"><span class="lineno">  201</span>    <span class="comment"># it is parallel to a column of Y</span></div>
<div class="line"><span class="lineno">  202</span>    n, t = X.shape</div>
<div class="line"><span class="lineno">  203</span>    v = X[:, i]</div>
<div class="line"><span class="lineno">  204</span>    <span class="keywordflow">if</span> any(vectors_are_parallel(v, X[:, j]) <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(i)):</div>
<div class="line"><span class="lineno">  205</span>        <span class="keywordflow">return</span> <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  206</span>    <span class="keywordflow">if</span> Y <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  207</span>        <span class="keywordflow">if</span> any(vectors_are_parallel(v, w) <span class="keywordflow">for</span> w <span class="keywordflow">in</span> Y.T):</div>
<div class="line"><span class="lineno">  208</span>            <span class="keywordflow">return</span> <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  209</span>    <span class="keywordflow">return</span> <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  210</span> </div>
<div class="line"><span class="lineno">  211</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abe1c1007213f990620901314a4fa1861" name="abe1c1007213f990620901314a4fa1861"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe1c1007213f990620901314a4fa1861">&#9670;&#160;</a></span>elementary_vector()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest.elementary_vector </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>i</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  175</span><span class="keyword">def </span>elementary_vector(n, i):</div>
<div class="line"><span class="lineno">  176</span>    v = np.zeros(n, dtype=float)</div>
<div class="line"><span class="lineno">  177</span>    v[i] = 1</div>
<div class="line"><span class="lineno">  178</span>    <span class="keywordflow">return</span> v</div>
<div class="line"><span class="lineno">  179</span> </div>
<div class="line"><span class="lineno">  180</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae2f3abf778690880d59a28c585fa82fd" name="ae2f3abf778690880d59a28c585fa82fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae2f3abf778690880d59a28c585fa82fd">&#9670;&#160;</a></span>every_col_of_X_is_parallel_to_a_col_of_Y()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest.every_col_of_X_is_parallel_to_a_col_of_Y </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  191</span><span class="keyword">def </span>every_col_of_X_is_parallel_to_a_col_of_Y(X, Y):</div>
<div class="line"><span class="lineno">  192</span>    <span class="keywordflow">for</span> v <span class="keywordflow">in</span> X.T:</div>
<div class="line"><span class="lineno">  193</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> any(vectors_are_parallel(v, w) <span class="keywordflow">for</span> w <span class="keywordflow">in</span> Y.T):</div>
<div class="line"><span class="lineno">  194</span>            <span class="keywordflow">return</span> <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  195</span>    <span class="keywordflow">return</span> <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  196</span> </div>
<div class="line"><span class="lineno">  197</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8bdd1e4cd7d67752794864524ee86567" name="a8bdd1e4cd7d67752794864524ee86567"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8bdd1e4cd7d67752794864524ee86567">&#9670;&#160;</a></span>less_than_or_close()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest.less_than_or_close </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  216</span><span class="keyword">def </span>less_than_or_close(a, b):</div>
<div class="line"><span class="lineno">  217</span>    <span class="keywordflow">return</span> np.allclose(a, b) <span class="keywordflow">or</span> (a &lt; b)</div>
<div class="line"><span class="lineno">  218</span> </div>
<div class="line"><span class="lineno">  219</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a487451f8984fbd4f827e30122f6193fa" name="a487451f8984fbd4f827e30122f6193fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a487451f8984fbd4f827e30122f6193fa">&#9670;&#160;</a></span>onenormest()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest.onenormest </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>t</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>itmax</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>compute_v</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>compute_w</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute a lower bound of the 1-norm of a sparse matrix.

Parameters
----------
A : ndarray or other linear operator
    A linear operator that can be transposed and that can
    produce matrix products.
t : int, optional
    A positive parameter controlling the tradeoff between
    accuracy versus time and memory usage.
    Larger values take longer and use more memory
    but give more accurate output.
itmax : int, optional
    Use at most this many iterations.
compute_v : bool, optional
    Request a norm-maximizing linear operator input vector if True.
compute_w : bool, optional
    Request a norm-maximizing linear operator output vector if True.

Returns
-------
est : float
    An underestimate of the 1-norm of the sparse matrix.
v : ndarray, optional
    The vector such that ||Av||_1 == est*||v||_1.
    It can be thought of as an input to the linear operator
    that gives an output with particularly large norm.
w : ndarray, optional
    The vector Av which has relatively large 1-norm.
    It can be thought of as an output of the linear operator
    that is relatively large in norm compared to the input.

Notes
-----
This is algorithm 2.4 of [1].

In [2] it is described as follows.
"This algorithm typically requires the evaluation of
about 4t matrix-vector products and almost invariably
produces a norm estimate (which is, in fact, a lower
bound on the norm) correct to within a factor 3."

.. versionadded:: 0.13.0

References
----------
.. [1] Nicholas J. Higham and Francoise Tisseur (2000),
       "A Block Algorithm for Matrix 1-Norm Estimation,
       with an Application to 1-Norm Pseudospectra."
       SIAM J. Matrix Anal. Appl. Vol. 21, No. 4, pp. 1185-1201.

.. [2] Awad H. Al-Mohy and Nicholas J. Higham (2009),
       "A new scaling and squaring algorithm for the matrix exponential."
       SIAM J. Matrix Anal. Appl. Vol. 31, No. 3, pp. 970-989.

Examples
--------
&gt;&gt;&gt; from scipy.sparse import csc_matrix
&gt;&gt;&gt; from scipy.sparse.linalg import onenormest
&gt;&gt;&gt; A = csc_matrix([[1., 0., 0.], [5., 8., 2.], [0., -1., 0.]], dtype=float)
&gt;&gt;&gt; A.toarray()
array([[ 1.,  0.,  0.],
       [ 5.,  8.,  2.],
       [ 0., -1.,  0.]])
&gt;&gt;&gt; onenormest(A)
9.0
&gt;&gt;&gt; np.linalg.norm(A.toarray(), ord=1)
9.0
</pre> <div class="fragment"><div class="line"><span class="lineno">   11</span><span class="keyword">def </span>onenormest(A, t=2, itmax=5, compute_v=False, compute_w=False):</div>
<div class="line"><span class="lineno">   12</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   13</span><span class="stringliteral">    Compute a lower bound of the 1-norm of a sparse matrix.</span></div>
<div class="line"><span class="lineno">   14</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   15</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   16</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   17</span><span class="stringliteral">    A : ndarray or other linear operator</span></div>
<div class="line"><span class="lineno">   18</span><span class="stringliteral">        A linear operator that can be transposed and that can</span></div>
<div class="line"><span class="lineno">   19</span><span class="stringliteral">        produce matrix products.</span></div>
<div class="line"><span class="lineno">   20</span><span class="stringliteral">    t : int, optional</span></div>
<div class="line"><span class="lineno">   21</span><span class="stringliteral">        A positive parameter controlling the tradeoff between</span></div>
<div class="line"><span class="lineno">   22</span><span class="stringliteral">        accuracy versus time and memory usage.</span></div>
<div class="line"><span class="lineno">   23</span><span class="stringliteral">        Larger values take longer and use more memory</span></div>
<div class="line"><span class="lineno">   24</span><span class="stringliteral">        but give more accurate output.</span></div>
<div class="line"><span class="lineno">   25</span><span class="stringliteral">    itmax : int, optional</span></div>
<div class="line"><span class="lineno">   26</span><span class="stringliteral">        Use at most this many iterations.</span></div>
<div class="line"><span class="lineno">   27</span><span class="stringliteral">    compute_v : bool, optional</span></div>
<div class="line"><span class="lineno">   28</span><span class="stringliteral">        Request a norm-maximizing linear operator input vector if True.</span></div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">    compute_w : bool, optional</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral">        Request a norm-maximizing linear operator output vector if True.</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">    est : float</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">        An underestimate of the 1-norm of the sparse matrix.</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">    v : ndarray, optional</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral">        The vector such that ||Av||_1 == est*||v||_1.</span></div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral">        It can be thought of as an input to the linear operator</span></div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">        that gives an output with particularly large norm.</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">    w : ndarray, optional</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">        The vector Av which has relatively large 1-norm.</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral">        It can be thought of as an output of the linear operator</span></div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">        that is relatively large in norm compared to the input.</span></div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">    This is algorithm 2.4 of [1].</span></div>
<div class="line"><span class="lineno">   48</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral">    In [2] it is described as follows.</span></div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">    &quot;This algorithm typically requires the evaluation of</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral">    about 4t matrix-vector products and almost invariably</span></div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">    produces a norm estimate (which is, in fact, a lower</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">    bound on the norm) correct to within a factor 3.&quot;</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">    .. versionadded:: 0.13.0</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">    .. [1] Nicholas J. Higham and Francoise Tisseur (2000),</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">           &quot;A Block Algorithm for Matrix 1-Norm Estimation,</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral">           with an Application to 1-Norm Pseudospectra.&quot;</span></div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">           SIAM J. Matrix Anal. Appl. Vol. 21, No. 4, pp. 1185-1201.</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    .. [2] Awad H. Al-Mohy and Nicholas J. Higham (2009),</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">           &quot;A new scaling and squaring algorithm for the matrix exponential.&quot;</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">           SIAM J. Matrix Anal. Appl. Vol. 31, No. 3, pp. 970-989.</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.sparse import csc_matrix</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.sparse.linalg import onenormest</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">    &gt;&gt;&gt; A = csc_matrix([[1., 0., 0.], [5., 8., 2.], [0., -1., 0.]], dtype=float)</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">    &gt;&gt;&gt; A.toarray()</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">    array([[ 1.,  0.,  0.],</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">           [ 5.,  8.,  2.],</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">           [ 0., -1.,  0.]])</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    &gt;&gt;&gt; onenormest(A)</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">    9.0</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">    &gt;&gt;&gt; np.linalg.norm(A.toarray(), ord=1)</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">    9.0</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   82</span> </div>
<div class="line"><span class="lineno">   83</span>    <span class="comment"># Check the input.</span></div>
<div class="line"><span class="lineno">   84</span>    A = aslinearoperator(A)</div>
<div class="line"><span class="lineno">   85</span>    <span class="keywordflow">if</span> A.shape[0] != A.shape[1]:</div>
<div class="line"><span class="lineno">   86</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;expected the operator to act like a square matrix&#39;</span>)</div>
<div class="line"><span class="lineno">   87</span> </div>
<div class="line"><span class="lineno">   88</span>    <span class="comment"># If the operator size is small compared to t,</span></div>
<div class="line"><span class="lineno">   89</span>    <span class="comment"># then it is easier to compute the exact norm.</span></div>
<div class="line"><span class="lineno">   90</span>    <span class="comment"># Otherwise estimate the norm.</span></div>
<div class="line"><span class="lineno">   91</span>    n = A.shape[1]</div>
<div class="line"><span class="lineno">   92</span>    <span class="keywordflow">if</span> t &gt;= n:</div>
<div class="line"><span class="lineno">   93</span>        A_explicit = np.asarray(aslinearoperator(A).matmat(np.identity(n)))</div>
<div class="line"><span class="lineno">   94</span>        <span class="keywordflow">if</span> A_explicit.shape != (n, n):</div>
<div class="line"><span class="lineno">   95</span>            <span class="keywordflow">raise</span> Exception(<span class="stringliteral">&#39;internal error: &#39;</span>,</div>
<div class="line"><span class="lineno">   96</span>                    <span class="stringliteral">&#39;unexpected shape &#39;</span> + str(A_explicit.shape))</div>
<div class="line"><span class="lineno">   97</span>        col_abs_sums = abs(A_explicit).sum(axis=0)</div>
<div class="line"><span class="lineno">   98</span>        <span class="keywordflow">if</span> col_abs_sums.shape != (n, ):</div>
<div class="line"><span class="lineno">   99</span>            <span class="keywordflow">raise</span> Exception(<span class="stringliteral">&#39;internal error: &#39;</span>,</div>
<div class="line"><span class="lineno">  100</span>                    <span class="stringliteral">&#39;unexpected shape &#39;</span> + str(col_abs_sums.shape))</div>
<div class="line"><span class="lineno">  101</span>        argmax_j = np.argmax(col_abs_sums)</div>
<div class="line"><span class="lineno">  102</span>        v = elementary_vector(n, argmax_j)</div>
<div class="line"><span class="lineno">  103</span>        w = A_explicit[:, argmax_j]</div>
<div class="line"><span class="lineno">  104</span>        est = col_abs_sums[argmax_j]</div>
<div class="line"><span class="lineno">  105</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  106</span>        est, v, w, nmults, nresamples = _onenormest_core(A, A.H, t, itmax)</div>
<div class="line"><span class="lineno">  107</span> </div>
<div class="line"><span class="lineno">  108</span>    <span class="comment"># Report the norm estimate along with some certificates of the estimate.</span></div>
<div class="line"><span class="lineno">  109</span>    <span class="keywordflow">if</span> compute_v <span class="keywordflow">or</span> compute_w:</div>
<div class="line"><span class="lineno">  110</span>        result = (est,)</div>
<div class="line"><span class="lineno">  111</span>        <span class="keywordflow">if</span> compute_v:</div>
<div class="line"><span class="lineno">  112</span>            result += (v,)</div>
<div class="line"><span class="lineno">  113</span>        <span class="keywordflow">if</span> compute_w:</div>
<div class="line"><span class="lineno">  114</span>            result += (w,)</div>
<div class="line"><span class="lineno">  115</span>        <span class="keywordflow">return</span> result</div>
<div class="line"><span class="lineno">  116</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  117</span>        <span class="keywordflow">return</span> est</div>
<div class="line"><span class="lineno">  118</span> </div>
<div class="line"><span class="lineno">  119</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a90c93ccb94570f5d60945e26d4eb14a9" name="a90c93ccb94570f5d60945e26d4eb14a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a90c93ccb94570f5d60945e26d4eb14a9">&#9670;&#160;</a></span>resample_column()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest.resample_column </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>i</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  212</span><span class="keyword">def </span>resample_column(i, X):</div>
<div class="line"><span class="lineno">  213</span>    X[:, i] = np.random.randint(0, 2, size=X.shape[0])*2 - 1</div>
<div class="line"><span class="lineno">  214</span> </div>
<div class="line"><span class="lineno">  215</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2786ba99350ad48c3f19b6ca13753407" name="a2786ba99350ad48c3f19b6ca13753407"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2786ba99350ad48c3f19b6ca13753407">&#9670;&#160;</a></span>sign_round_up()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest.sign_round_up </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">This should do the right thing for both real and complex matrices.

From Higham and Tisseur:
"Everything in this section remains valid for complex matrices
provided that sign(A) is redefined as the matrix (aij / |aij|)
(and sign(0) = 1) transposes are replaced by conjugate transposes."</pre> <div class="fragment"><div class="line"><span class="lineno">  142</span><span class="keyword">def </span>sign_round_up(X):</div>
<div class="line"><span class="lineno">  143</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">    This should do the right thing for both real and complex matrices.</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">    From Higham and Tisseur:</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">    &quot;Everything in this section remains valid for complex matrices</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">    provided that sign(A) is redefined as the matrix (aij / |aij|)</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">    (and sign(0) = 1) transposes are replaced by conjugate transposes.&quot;</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  152</span>    Y = X.copy()</div>
<div class="line"><span class="lineno">  153</span>    Y[Y == 0] = 1</div>
<div class="line"><span class="lineno">  154</span>    Y /= np.abs(Y)</div>
<div class="line"><span class="lineno">  155</span>    <span class="keywordflow">return</span> Y</div>
<div class="line"><span class="lineno">  156</span> </div>
<div class="line"><span class="lineno">  157</span> </div>
<div class="line"><span class="lineno">  158</span><span class="preprocessor">@_blocked_elementwise</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a43955773facab0542365aa81a0a9dec7" name="a43955773facab0542365aa81a0a9dec7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a43955773facab0542365aa81a0a9dec7">&#9670;&#160;</a></span>vectors_are_parallel()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._onenormest.vectors_are_parallel </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>v</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  181</span><span class="keyword">def </span>vectors_are_parallel(v, w):</div>
<div class="line"><span class="lineno">  182</span>    <span class="comment"># Columns are considered parallel when they are equal or negative.</span></div>
<div class="line"><span class="lineno">  183</span>    <span class="comment"># Entries are required to be in {-1, 1},</span></div>
<div class="line"><span class="lineno">  184</span>    <span class="comment"># which guarantees that the magnitudes of the vectors are identical.</span></div>
<div class="line"><span class="lineno">  185</span>    <span class="keywordflow">if</span> v.ndim != 1 <span class="keywordflow">or</span> v.shape != w.shape:</div>
<div class="line"><span class="lineno">  186</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;expected conformant vectors with entries in {-1,1}&#39;</span>)</div>
<div class="line"><span class="lineno">  187</span>    n = v.shape[0]</div>
<div class="line"><span class="lineno">  188</span>    <span class="keywordflow">return</span> np.dot(v, w) == n</div>
<div class="line"><span class="lineno">  189</span> </div>
<div class="line"><span class="lineno">  190</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
