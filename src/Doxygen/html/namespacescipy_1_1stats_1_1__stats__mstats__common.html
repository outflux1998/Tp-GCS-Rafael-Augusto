<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: scipy.stats._stats_mstats_common Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacescipy.html">scipy</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1stats.html">stats</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1stats_1_1__stats__mstats__common.html">_stats_mstats_common</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">scipy.stats._stats_mstats_common Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a9702428d290c487add4bbbef402430a1" id="r_a9702428d290c487add4bbbef402430a1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__stats__mstats__common.html#a9702428d290c487add4bbbef402430a1">linregress</a> (x, y=None, alternative='two-sided')</td></tr>
<tr class="separator:a9702428d290c487add4bbbef402430a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5681db74b7a6921b68a36f60ecd0cf9c" id="r_a5681db74b7a6921b68a36f60ecd0cf9c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__stats__mstats__common.html#a5681db74b7a6921b68a36f60ecd0cf9c">theilslopes</a> (y, x=None, <a class="el" href="namespacescipy_1_1stats_1_1__continuous__distns.html#ace85b1427e9d22fa1c4faa15812b747d">alpha</a>=0.95, <a class="el" href="namespacescipy_1_1stats_1_1__multivariate.html#ad5850caf3faceef835b3baacc93038ee">method</a>='separate')</td></tr>
<tr class="separator:a5681db74b7a6921b68a36f60ecd0cf9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace343683fb3d0a224bc462b957cf0b70" id="r_ace343683fb3d0a224bc462b957cf0b70"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__stats__mstats__common.html#ace343683fb3d0a224bc462b957cf0b70">_find_repeats</a> (arr)</td></tr>
<tr class="separator:ace343683fb3d0a224bc462b957cf0b70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4e2e037d97b3c2ef35a13763e61a046" id="r_af4e2e037d97b3c2ef35a13763e61a046"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__stats__mstats__common.html#af4e2e037d97b3c2ef35a13763e61a046">siegelslopes</a> (y, x=None, <a class="el" href="namespacescipy_1_1stats_1_1__multivariate.html#ad5850caf3faceef835b3baacc93038ee">method</a>=&quot;hierarchical&quot;)</td></tr>
<tr class="separator:af4e2e037d97b3c2ef35a13763e61a046"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a06fb02725769ed1d8ca61b62ac2b4343" id="r_a06fb02725769ed1d8ca61b62ac2b4343"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__stats__mstats__common.html#a06fb02725769ed1d8ca61b62ac2b4343">LinregressResult</a></td></tr>
<tr class="separator:a06fb02725769ed1d8ca61b62ac2b4343"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a1b0913761ae145354e4648bbef73f1" id="r_a8a1b0913761ae145354e4648bbef73f1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__stats__mstats__common.html#a8a1b0913761ae145354e4648bbef73f1">TheilslopesResult</a></td></tr>
<tr class="separator:a8a1b0913761ae145354e4648bbef73f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ce4666a9c5db89dcc69ec7f7607881a" id="r_a0ce4666a9c5db89dcc69ec7f7607881a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__stats__mstats__common.html#a0ce4666a9c5db89dcc69ec7f7607881a">SiegelslopesResult</a></td></tr>
<tr class="separator:a0ce4666a9c5db89dcc69ec7f7607881a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="ace343683fb3d0a224bc462b957cf0b70" name="ace343683fb3d0a224bc462b957cf0b70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace343683fb3d0a224bc462b957cf0b70">&#9670;&#160;</a></span>_find_repeats()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._stats_mstats_common._find_repeats </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>arr</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  371</span><span class="keyword">def </span>_find_repeats(arr):</div>
<div class="line"><span class="lineno">  372</span>    <span class="comment"># This function assumes it may clobber its input.</span></div>
<div class="line"><span class="lineno">  373</span>    <span class="keywordflow">if</span> len(arr) == 0:</div>
<div class="line"><span class="lineno">  374</span>        <span class="keywordflow">return</span> np.array(0, np.float64), np.array(0, np.intp)</div>
<div class="line"><span class="lineno">  375</span> </div>
<div class="line"><span class="lineno">  376</span>    <span class="comment"># XXX This cast was previously needed for the Fortran implementation,</span></div>
<div class="line"><span class="lineno">  377</span>    <span class="comment"># should we ditch it?</span></div>
<div class="line"><span class="lineno">  378</span>    arr = np.asarray(arr, np.float64).ravel()</div>
<div class="line"><span class="lineno">  379</span>    arr.sort()</div>
<div class="line"><span class="lineno">  380</span> </div>
<div class="line"><span class="lineno">  381</span>    <span class="comment"># Taken from NumPy 1.9&#39;s np.unique.</span></div>
<div class="line"><span class="lineno">  382</span>    change = np.concatenate(([<span class="keyword">True</span>], arr[1:] != arr[:-1]))</div>
<div class="line"><span class="lineno">  383</span>    unique = arr[change]</div>
<div class="line"><span class="lineno">  384</span>    change_idx = np.concatenate(np.nonzero(change) + ([arr.size],))</div>
<div class="line"><span class="lineno">  385</span>    freq = np.diff(change_idx)</div>
<div class="line"><span class="lineno">  386</span>    atleast2 = freq &gt; 1</div>
<div class="line"><span class="lineno">  387</span>    <span class="keywordflow">return</span> unique[atleast2], freq[atleast2]</div>
<div class="line"><span class="lineno">  388</span> </div>
<div class="line"><span class="lineno">  389</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9702428d290c487add4bbbef402430a1" name="a9702428d290c487add4bbbef402430a1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9702428d290c487add4bbbef402430a1">&#9670;&#160;</a></span>linregress()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._stats_mstats_common.linregress </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alternative</em> = <code>'two-sided'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Calculate a linear least-squares regression for two sets of measurements.

Parameters
----------
x, y : array_like
    Two sets of measurements.  Both arrays should have the same length.  If
    only `x` is given (and ``y=None``), then it must be a two-dimensional
    array where one dimension has length 2.  The two sets of measurements
    are then found by splitting the array along the length-2 dimension. In
    the case where ``y=None`` and `x` is a 2x2 array, ``linregress(x)`` is
    equivalent to ``linregress(x[0], x[1])``.
alternative : {'two-sided', 'less', 'greater'}, optional
    Defines the alternative hypothesis. Default is 'two-sided'.
    The following options are available:

    * 'two-sided': the slope of the regression line is nonzero
    * 'less': the slope of the regression line is less than zero
    * 'greater':  the slope of the regression line is greater than zero

    .. versionadded:: 1.7.0

Returns
-------
result : ``LinregressResult`` instance
    The return value is an object with the following attributes:

    slope : float
        Slope of the regression line.
    intercept : float
        Intercept of the regression line.
    rvalue : float
        The Pearson correlation coefficient. The square of ``rvalue``
        is equal to the coefficient of determination.
    pvalue : float
        The p-value for a hypothesis test whose null hypothesis is
        that the slope is zero, using Wald Test with t-distribution of
        the test statistic. See `alternative` above for alternative
        hypotheses.
    stderr : float
        Standard error of the estimated slope (gradient), under the
        assumption of residual normality.
    intercept_stderr : float
        Standard error of the estimated intercept, under the assumption
        of residual normality.

See Also
--------
scipy.optimize.curve_fit :
    Use non-linear least squares to fit a function to data.
scipy.optimize.leastsq :
    Minimize the sum of squares of a set of equations.

Notes
-----
Missing values are considered pair-wise: if a value is missing in `x`,
the corresponding value in `y` is masked.

For compatibility with older versions of SciPy, the return value acts
like a ``namedtuple`` of length 5, with fields ``slope``, ``intercept``,
``rvalue``, ``pvalue`` and ``stderr``, so one can continue to write::

    slope, intercept, r, p, se = linregress(x, y)

With that style, however, the standard error of the intercept is not
available.  To have access to all the computed values, including the
standard error of the intercept, use the return value as an object
with attributes, e.g.::

    result = linregress(x, y)
    print(result.intercept, result.intercept_stderr)

Examples
--------
&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; from scipy import stats
&gt;&gt;&gt; rng = np.random.default_rng()

Generate some data:

&gt;&gt;&gt; x = rng.random(10)
&gt;&gt;&gt; y = 1.6*x + rng.random(10)

Perform the linear regression:

&gt;&gt;&gt; res = stats.linregress(x, y)

Coefficient of determination (R-squared):

&gt;&gt;&gt; print(f"R-squared: {res.rvalue**2:.6f}")
R-squared: 0.717533

Plot the data along with the fitted line:

&gt;&gt;&gt; plt.plot(x, y, 'o', label='original data')
&gt;&gt;&gt; plt.plot(x, res.intercept + res.slope*x, 'r', label='fitted line')
&gt;&gt;&gt; plt.legend()
&gt;&gt;&gt; plt.show()

Calculate 95% confidence interval on slope and intercept:

&gt;&gt;&gt; # Two-sided inverse Students t-distribution
&gt;&gt;&gt; # p - probability, df - degrees of freedom
&gt;&gt;&gt; from scipy.stats import t
&gt;&gt;&gt; tinv = lambda p, df: abs(t.ppf(p/2, df))

&gt;&gt;&gt; ts = tinv(0.05, len(x)-2)
&gt;&gt;&gt; print(f"slope (95%): {res.slope:.6f} +/- {ts*res.stderr:.6f}")
slope (95%): 1.453392 +/- 0.743465
&gt;&gt;&gt; print(f"intercept (95%): {res.intercept:.6f}"
...       f" +/- {ts*res.intercept_stderr:.6f}")
intercept (95%): 0.616950 +/- 0.544475</pre> <div class="fragment"><div class="line"><span class="lineno">   22</span><span class="keyword">def </span>linregress(x, y=None, alternative=&#39;two-sided&#39;):</div>
<div class="line"><span class="lineno">   23</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   24</span><span class="stringliteral">    Calculate a linear least-squares regression for two sets of measurements.</span></div>
<div class="line"><span class="lineno">   25</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   26</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   27</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   28</span><span class="stringliteral">    x, y : array_like</span></div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">        Two sets of measurements.  Both arrays should have the same length.  If</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral">        only `x` is given (and ``y=None``), then it must be a two-dimensional</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral">        array where one dimension has length 2.  The two sets of measurements</span></div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">        are then found by splitting the array along the length-2 dimension. In</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">        the case where ``y=None`` and `x` is a 2x2 array, ``linregress(x)`` is</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">        equivalent to ``linregress(x[0], x[1])``.</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">        Defines the alternative hypothesis. Default is &#39;two-sided&#39;.</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral">        The following options are available:</span></div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">        * &#39;two-sided&#39;: the slope of the regression line is nonzero</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">        * &#39;less&#39;: the slope of the regression line is less than zero</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">        * &#39;greater&#39;:  the slope of the regression line is greater than zero</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">        .. versionadded:: 1.7.0</span></div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">    result : ``LinregressResult`` instance</span></div>
<div class="line"><span class="lineno">   48</span><span class="stringliteral">        The return value is an object with the following attributes:</span></div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">        slope : float</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral">            Slope of the regression line.</span></div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">        intercept : float</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">            Intercept of the regression line.</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral">        rvalue : float</span></div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">            The Pearson correlation coefficient. The square of ``rvalue``</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral">            is equal to the coefficient of determination.</span></div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral">        pvalue : float</span></div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral">            The p-value for a hypothesis test whose null hypothesis is</span></div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">            that the slope is zero, using Wald Test with t-distribution of</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral">            the test statistic. See `alternative` above for alternative</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral">            hypotheses.</span></div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">        stderr : float</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">            Standard error of the estimated slope (gradient), under the</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">            assumption of residual normality.</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">        intercept_stderr : float</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">            Standard error of the estimated intercept, under the assumption</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">            of residual normality.</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral">    scipy.optimize.curve_fit :</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">        Use non-linear least squares to fit a function to data.</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">    scipy.optimize.leastsq :</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">        Minimize the sum of squares of a set of equations.</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">    Missing values are considered pair-wise: if a value is missing in `x`,</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">    the corresponding value in `y` is masked.</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral">    For compatibility with older versions of SciPy, the return value acts</span></div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral">    like a ``namedtuple`` of length 5, with fields ``slope``, ``intercept``,</span></div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">    ``rvalue``, ``pvalue`` and ``stderr``, so one can continue to write::</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">        slope, intercept, r, p, se = linregress(x, y)</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">    With that style, however, the standard error of the intercept is not</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">    available.  To have access to all the computed values, including the</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">    standard error of the intercept, use the return value as an object</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">    with attributes, e.g.::</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral">        result = linregress(x, y)</span></div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral">        print(result.intercept, result.intercept_stderr)</span></div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">    &gt;&gt;&gt; from scipy import stats</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">    &gt;&gt;&gt; rng = np.random.default_rng()</span></div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">    Generate some data:</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">    &gt;&gt;&gt; x = rng.random(10)</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">    &gt;&gt;&gt; y = 1.6*x + rng.random(10)</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral">    Perform the linear regression:</span></div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.linregress(x, y)</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral">    Coefficient of determination (R-squared):</span></div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral">    &gt;&gt;&gt; print(f&quot;R-squared: {res.rvalue**2:.6f}&quot;)</span></div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral">    R-squared: 0.717533</span></div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">    Plot the data along with the fitted line:</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">    &gt;&gt;&gt; plt.plot(x, y, &#39;o&#39;, label=&#39;original data&#39;)</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">    &gt;&gt;&gt; plt.plot(x, res.intercept + res.slope*x, &#39;r&#39;, label=&#39;fitted line&#39;)</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral">    &gt;&gt;&gt; plt.legend()</span></div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral">    &gt;&gt;&gt; plt.show()</span></div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">    Calculate 95% confidence interval on slope and intercept:</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">    &gt;&gt;&gt; # Two-sided inverse Students t-distribution</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral">    &gt;&gt;&gt; # p - probability, df - degrees of freedom</span></div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.stats import t</span></div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral">    &gt;&gt;&gt; tinv = lambda p, df: abs(t.ppf(p/2, df))</span></div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral">    &gt;&gt;&gt; ts = tinv(0.05, len(x)-2)</span></div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral">    &gt;&gt;&gt; print(f&quot;slope (95%): {res.slope:.6f} +/- {ts*res.stderr:.6f}&quot;)</span></div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">    slope (95%): 1.453392 +/- 0.743465</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral">    &gt;&gt;&gt; print(f&quot;intercept (95%): {res.intercept:.6f}&quot;</span></div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">    ...       f&quot; +/- {ts*res.intercept_stderr:.6f}&quot;)</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">    intercept (95%): 0.616950 +/- 0.544475</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  137</span>    TINY = 1.0e-20</div>
<div class="line"><span class="lineno">  138</span>    <span class="keywordflow">if</span> y <span class="keywordflow">is</span> <span class="keywordtype">None</span>:  <span class="comment"># x is a (2, N) or (N, 2) shaped array_like</span></div>
<div class="line"><span class="lineno">  139</span>        x = np.asarray(x)</div>
<div class="line"><span class="lineno">  140</span>        <span class="keywordflow">if</span> x.shape[0] == 2:</div>
<div class="line"><span class="lineno">  141</span>            x, y = x</div>
<div class="line"><span class="lineno">  142</span>        <span class="keywordflow">elif</span> x.shape[1] == 2:</div>
<div class="line"><span class="lineno">  143</span>            x, y = x.T</div>
<div class="line"><span class="lineno">  144</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  145</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;If only `x` is given as input, it has to &quot;</span></div>
<div class="line"><span class="lineno">  146</span>                             <span class="stringliteral">&quot;be of shape (2, N) or (N, 2); provided shape &quot;</span></div>
<div class="line"><span class="lineno">  147</span>                             f<span class="stringliteral">&quot;was {x.shape}.&quot;</span>)</div>
<div class="line"><span class="lineno">  148</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  149</span>        x = np.asarray(x)</div>
<div class="line"><span class="lineno">  150</span>        y = np.asarray(y)</div>
<div class="line"><span class="lineno">  151</span> </div>
<div class="line"><span class="lineno">  152</span>    <span class="keywordflow">if</span> x.size == 0 <span class="keywordflow">or</span> y.size == 0:</div>
<div class="line"><span class="lineno">  153</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Inputs must not be empty.&quot;</span>)</div>
<div class="line"><span class="lineno">  154</span> </div>
<div class="line"><span class="lineno">  155</span>    <span class="keywordflow">if</span> np.amax(x) == np.amin(x) <span class="keywordflow">and</span> len(x) &gt; 1:</div>
<div class="line"><span class="lineno">  156</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Cannot calculate a linear regression &quot;</span></div>
<div class="line"><span class="lineno">  157</span>                         <span class="stringliteral">&quot;if all x values are identical&quot;</span>)</div>
<div class="line"><span class="lineno">  158</span> </div>
<div class="line"><span class="lineno">  159</span>    n = len(x)</div>
<div class="line"><span class="lineno">  160</span>    xmean = np.mean(x, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  161</span>    ymean = np.mean(y, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  162</span> </div>
<div class="line"><span class="lineno">  163</span>    <span class="comment"># Average sums of square differences from the mean</span></div>
<div class="line"><span class="lineno">  164</span>    <span class="comment">#   ssxm = mean( (x-mean(x))^2 )</span></div>
<div class="line"><span class="lineno">  165</span>    <span class="comment">#   ssxym = mean( (x-mean(x)) * (y-mean(y)) )</span></div>
<div class="line"><span class="lineno">  166</span>    ssxm, ssxym, _, ssym = np.cov(x, y, bias=1).flat</div>
<div class="line"><span class="lineno">  167</span> </div>
<div class="line"><span class="lineno">  168</span>    <span class="comment"># R-value</span></div>
<div class="line"><span class="lineno">  169</span>    <span class="comment">#   r = ssxym / sqrt( ssxm * ssym )</span></div>
<div class="line"><span class="lineno">  170</span>    <span class="keywordflow">if</span> ssxm == 0.0 <span class="keywordflow">or</span> ssym == 0.0:</div>
<div class="line"><span class="lineno">  171</span>        <span class="comment"># If the denominator was going to be 0</span></div>
<div class="line"><span class="lineno">  172</span>        r = 0.0</div>
<div class="line"><span class="lineno">  173</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  174</span>        r = ssxym / np.sqrt(ssxm * ssym)</div>
<div class="line"><span class="lineno">  175</span>        <span class="comment"># Test for numerical error propagation (make sure -1 &lt; r &lt; 1)</span></div>
<div class="line"><span class="lineno">  176</span>        <span class="keywordflow">if</span> r &gt; 1.0:</div>
<div class="line"><span class="lineno">  177</span>            r = 1.0</div>
<div class="line"><span class="lineno">  178</span>        <span class="keywordflow">elif</span> r &lt; -1.0:</div>
<div class="line"><span class="lineno">  179</span>            r = -1.0</div>
<div class="line"><span class="lineno">  180</span> </div>
<div class="line"><span class="lineno">  181</span>    slope = ssxym / ssxm</div>
<div class="line"><span class="lineno">  182</span>    intercept = ymean - slope*xmean</div>
<div class="line"><span class="lineno">  183</span>    <span class="keywordflow">if</span> n == 2:</div>
<div class="line"><span class="lineno">  184</span>        <span class="comment"># handle case when only two points are passed in</span></div>
<div class="line"><span class="lineno">  185</span>        <span class="keywordflow">if</span> y[0] == y[1]:</div>
<div class="line"><span class="lineno">  186</span>            prob = 1.0</div>
<div class="line"><span class="lineno">  187</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  188</span>            prob = 0.0</div>
<div class="line"><span class="lineno">  189</span>        slope_stderr = 0.0</div>
<div class="line"><span class="lineno">  190</span>        intercept_stderr = 0.0</div>
<div class="line"><span class="lineno">  191</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  192</span>        df = n - 2  <span class="comment"># Number of degrees of freedom</span></div>
<div class="line"><span class="lineno">  193</span>        <span class="comment"># n-2 degrees of freedom because 2 has been used up</span></div>
<div class="line"><span class="lineno">  194</span>        <span class="comment"># to estimate the mean and standard deviation</span></div>
<div class="line"><span class="lineno">  195</span>        t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))</div>
<div class="line"><span class="lineno">  196</span>        t, prob = <a class="code hl_function" href="namespacescipy_1_1stats_1_1__stats__py.html#a068fc003ca0623460250659b9421b133">scipy.stats._stats_py._ttest_finish</a>(df, t, alternative)</div>
<div class="line"><span class="lineno">  197</span> </div>
<div class="line"><span class="lineno">  198</span>        slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)</div>
<div class="line"><span class="lineno">  199</span> </div>
<div class="line"><span class="lineno">  200</span>        <span class="comment"># Also calculate the standard error of the intercept</span></div>
<div class="line"><span class="lineno">  201</span>        <span class="comment"># The following relationship is used:</span></div>
<div class="line"><span class="lineno">  202</span>        <span class="comment">#   ssxm = mean( (x-mean(x))^2 )</span></div>
<div class="line"><span class="lineno">  203</span>        <span class="comment">#        = ssx - sx*sx</span></div>
<div class="line"><span class="lineno">  204</span>        <span class="comment">#        = mean( x^2 ) - mean(x)^2</span></div>
<div class="line"><span class="lineno">  205</span>        intercept_stderr = slope_stderr * np.sqrt(ssxm + xmean**2)</div>
<div class="line"><span class="lineno">  206</span> </div>
<div class="line"><span class="lineno">  207</span>    <span class="keywordflow">return</span> LinregressResult(slope=slope, intercept=intercept, rvalue=r,</div>
<div class="line"><span class="lineno">  208</span>                            pvalue=prob, stderr=slope_stderr,</div>
<div class="line"><span class="lineno">  209</span>                            intercept_stderr=intercept_stderr)</div>
<div class="line"><span class="lineno">  210</span> </div>
<div class="line"><span class="lineno">  211</span> </div>
<div class="ttc" id="anamespacescipy_1_1stats_1_1__stats__py_html_a068fc003ca0623460250659b9421b133"><div class="ttname"><a href="namespacescipy_1_1stats_1_1__stats__py.html#a068fc003ca0623460250659b9421b133">scipy.stats._stats_py._ttest_finish</a></div><div class="ttdeci">_ttest_finish(df, t, alternative)</div><div class="ttdef"><b>Definition</b> _stats_py.py:6087</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="af4e2e037d97b3c2ef35a13763e61a046" name="af4e2e037d97b3c2ef35a13763e61a046"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4e2e037d97b3c2ef35a13763e61a046">&#9670;&#160;</a></span>siegelslopes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._stats_mstats_common.siegelslopes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em> = <code>&quot;hierarchical&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Computes the Siegel estimator for a set of points (x, y).

`siegelslopes` implements a method for robust linear regression
using repeated medians (see [1]_) to fit a line to the points (x, y).
The method is robust to outliers with an asymptotic breakdown point
of 50%.

Parameters
----------
y : array_like
    Dependent variable.
x : array_like or None, optional
    Independent variable. If None, use ``arange(len(y))`` instead.
method : {'hierarchical', 'separate'}
    If 'hierarchical', estimate the intercept using the estimated
    slope ``slope`` (default option).
    If 'separate', estimate the intercept independent of the estimated
    slope. See Notes for details.

Returns
-------
result : ``SiegelslopesResult`` instance
    The return value is an object with the following attributes:

    slope : float
        Estimate of the slope of the regression line.
    intercept : float
        Estimate of the intercept of the regression line.

See Also
--------
theilslopes : a similar technique without repeated medians

Notes
-----
With ``n = len(y)``, compute ``m_j`` as the median of
the slopes from the point ``(x[j], y[j])`` to all other `n-1` points.
``slope`` is then the median of all slopes ``m_j``.
Two ways are given to estimate the intercept in [1]_ which can be chosen
via the parameter ``method``.
The hierarchical approach uses the estimated slope ``slope``
and computes ``intercept`` as the median of ``y - slope*x``.
The other approach estimates the intercept separately as follows: for
each point ``(x[j], y[j])``, compute the intercepts of all the `n-1`
lines through the remaining points and take the median ``i_j``.
``intercept`` is the median of the ``i_j``.

The implementation computes `n` times the median of a vector of size `n`
which can be slow for large vectors. There are more efficient algorithms
(see [2]_) which are not implemented here.

For compatibility with older versions of SciPy, the return value acts
like a ``namedtuple`` of length 2, with fields ``slope`` and
``intercept``, so one can continue to write::

    slope, intercept = siegelslopes(y, x)

References
----------
.. [1] A. Siegel, "Robust Regression Using Repeated Medians",
       Biometrika, Vol. 69, pp. 242-244, 1982.

.. [2] A. Stein and M. Werman, "Finding the repeated median regression
       line", Proceedings of the Third Annual ACM-SIAM Symposium on
       Discrete Algorithms, pp. 409-413, 1992.

Examples
--------
&gt;&gt;&gt; from scipy import stats
&gt;&gt;&gt; import matplotlib.pyplot as plt

&gt;&gt;&gt; x = np.linspace(-5, 5, num=150)
&gt;&gt;&gt; y = x + np.random.normal(size=x.size)
&gt;&gt;&gt; y[11:15] += 10  # add outliers
&gt;&gt;&gt; y[-5:] -= 7

Compute the slope and intercept.  For comparison, also compute the
least-squares fit with `linregress`:

&gt;&gt;&gt; res = stats.siegelslopes(y, x)
&gt;&gt;&gt; lsq_res = stats.linregress(x, y)

Plot the results. The Siegel regression line is shown in red. The green
line shows the least-squares fit for comparison.

&gt;&gt;&gt; fig = plt.figure()
&gt;&gt;&gt; ax = fig.add_subplot(111)
&gt;&gt;&gt; ax.plot(x, y, 'b.')
&gt;&gt;&gt; ax.plot(x, res[1] + res[0] * x, 'r-')
&gt;&gt;&gt; ax.plot(x, lsq_res[1] + lsq_res[0] * x, 'g-')
&gt;&gt;&gt; plt.show()</pre> <div class="fragment"><div class="line"><span class="lineno">  390</span><span class="keyword">def </span>siegelslopes(y, x=None, method=&quot;hierarchical&quot;):</div>
<div class="line"><span class="lineno">  391</span>    <span class="stringliteral">r&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  392</span><span class="stringliteral">    Computes the Siegel estimator for a set of points (x, y).</span></div>
<div class="line"><span class="lineno">  393</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  394</span><span class="stringliteral">    `siegelslopes` implements a method for robust linear regression</span></div>
<div class="line"><span class="lineno">  395</span><span class="stringliteral">    using repeated medians (see [1]_) to fit a line to the points (x, y).</span></div>
<div class="line"><span class="lineno">  396</span><span class="stringliteral">    The method is robust to outliers with an asymptotic breakdown point</span></div>
<div class="line"><span class="lineno">  397</span><span class="stringliteral">    of 50%.</span></div>
<div class="line"><span class="lineno">  398</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  399</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  400</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral">    y : array_like</span></div>
<div class="line"><span class="lineno">  402</span><span class="stringliteral">        Dependent variable.</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral">    x : array_like or None, optional</span></div>
<div class="line"><span class="lineno">  404</span><span class="stringliteral">        Independent variable. If None, use ``arange(len(y))`` instead.</span></div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral">    method : {&#39;hierarchical&#39;, &#39;separate&#39;}</span></div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">        If &#39;hierarchical&#39;, estimate the intercept using the estimated</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral">        slope ``slope`` (default option).</span></div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral">        If &#39;separate&#39;, estimate the intercept independent of the estimated</span></div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral">        slope. See Notes for details.</span></div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral">    result : ``SiegelslopesResult`` instance</span></div>
<div class="line"><span class="lineno">  414</span><span class="stringliteral">        The return value is an object with the following attributes:</span></div>
<div class="line"><span class="lineno">  415</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral">        slope : float</span></div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral">            Estimate of the slope of the regression line.</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">        intercept : float</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">            Estimate of the intercept of the regression line.</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  421</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  422</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  423</span><span class="stringliteral">    theilslopes : a similar technique without repeated medians</span></div>
<div class="line"><span class="lineno">  424</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  425</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  426</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  427</span><span class="stringliteral">    With ``n = len(y)``, compute ``m_j`` as the median of</span></div>
<div class="line"><span class="lineno">  428</span><span class="stringliteral">    the slopes from the point ``(x[j], y[j])`` to all other `n-1` points.</span></div>
<div class="line"><span class="lineno">  429</span><span class="stringliteral">    ``slope`` is then the median of all slopes ``m_j``.</span></div>
<div class="line"><span class="lineno">  430</span><span class="stringliteral">    Two ways are given to estimate the intercept in [1]_ which can be chosen</span></div>
<div class="line"><span class="lineno">  431</span><span class="stringliteral">    via the parameter ``method``.</span></div>
<div class="line"><span class="lineno">  432</span><span class="stringliteral">    The hierarchical approach uses the estimated slope ``slope``</span></div>
<div class="line"><span class="lineno">  433</span><span class="stringliteral">    and computes ``intercept`` as the median of ``y - slope*x``.</span></div>
<div class="line"><span class="lineno">  434</span><span class="stringliteral">    The other approach estimates the intercept separately as follows: for</span></div>
<div class="line"><span class="lineno">  435</span><span class="stringliteral">    each point ``(x[j], y[j])``, compute the intercepts of all the `n-1`</span></div>
<div class="line"><span class="lineno">  436</span><span class="stringliteral">    lines through the remaining points and take the median ``i_j``.</span></div>
<div class="line"><span class="lineno">  437</span><span class="stringliteral">    ``intercept`` is the median of the ``i_j``.</span></div>
<div class="line"><span class="lineno">  438</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  439</span><span class="stringliteral">    The implementation computes `n` times the median of a vector of size `n`</span></div>
<div class="line"><span class="lineno">  440</span><span class="stringliteral">    which can be slow for large vectors. There are more efficient algorithms</span></div>
<div class="line"><span class="lineno">  441</span><span class="stringliteral">    (see [2]_) which are not implemented here.</span></div>
<div class="line"><span class="lineno">  442</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  443</span><span class="stringliteral">    For compatibility with older versions of SciPy, the return value acts</span></div>
<div class="line"><span class="lineno">  444</span><span class="stringliteral">    like a ``namedtuple`` of length 2, with fields ``slope`` and</span></div>
<div class="line"><span class="lineno">  445</span><span class="stringliteral">    ``intercept``, so one can continue to write::</span></div>
<div class="line"><span class="lineno">  446</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  447</span><span class="stringliteral">        slope, intercept = siegelslopes(y, x)</span></div>
<div class="line"><span class="lineno">  448</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  449</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  450</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  451</span><span class="stringliteral">    .. [1] A. Siegel, &quot;Robust Regression Using Repeated Medians&quot;,</span></div>
<div class="line"><span class="lineno">  452</span><span class="stringliteral">           Biometrika, Vol. 69, pp. 242-244, 1982.</span></div>
<div class="line"><span class="lineno">  453</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  454</span><span class="stringliteral">    .. [2] A. Stein and M. Werman, &quot;Finding the repeated median regression</span></div>
<div class="line"><span class="lineno">  455</span><span class="stringliteral">           line&quot;, Proceedings of the Third Annual ACM-SIAM Symposium on</span></div>
<div class="line"><span class="lineno">  456</span><span class="stringliteral">           Discrete Algorithms, pp. 409-413, 1992.</span></div>
<div class="line"><span class="lineno">  457</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  458</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  459</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  460</span><span class="stringliteral">    &gt;&gt;&gt; from scipy import stats</span></div>
<div class="line"><span class="lineno">  461</span><span class="stringliteral">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span></div>
<div class="line"><span class="lineno">  462</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  463</span><span class="stringliteral">    &gt;&gt;&gt; x = np.linspace(-5, 5, num=150)</span></div>
<div class="line"><span class="lineno">  464</span><span class="stringliteral">    &gt;&gt;&gt; y = x + np.random.normal(size=x.size)</span></div>
<div class="line"><span class="lineno">  465</span><span class="stringliteral">    &gt;&gt;&gt; y[11:15] += 10  # add outliers</span></div>
<div class="line"><span class="lineno">  466</span><span class="stringliteral">    &gt;&gt;&gt; y[-5:] -= 7</span></div>
<div class="line"><span class="lineno">  467</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  468</span><span class="stringliteral">    Compute the slope and intercept.  For comparison, also compute the</span></div>
<div class="line"><span class="lineno">  469</span><span class="stringliteral">    least-squares fit with `linregress`:</span></div>
<div class="line"><span class="lineno">  470</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  471</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.siegelslopes(y, x)</span></div>
<div class="line"><span class="lineno">  472</span><span class="stringliteral">    &gt;&gt;&gt; lsq_res = stats.linregress(x, y)</span></div>
<div class="line"><span class="lineno">  473</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  474</span><span class="stringliteral">    Plot the results. The Siegel regression line is shown in red. The green</span></div>
<div class="line"><span class="lineno">  475</span><span class="stringliteral">    line shows the least-squares fit for comparison.</span></div>
<div class="line"><span class="lineno">  476</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  477</span><span class="stringliteral">    &gt;&gt;&gt; fig = plt.figure()</span></div>
<div class="line"><span class="lineno">  478</span><span class="stringliteral">    &gt;&gt;&gt; ax = fig.add_subplot(111)</span></div>
<div class="line"><span class="lineno">  479</span><span class="stringliteral">    &gt;&gt;&gt; ax.plot(x, y, &#39;b.&#39;)</span></div>
<div class="line"><span class="lineno">  480</span><span class="stringliteral">    &gt;&gt;&gt; ax.plot(x, res[1] + res[0] * x, &#39;r-&#39;)</span></div>
<div class="line"><span class="lineno">  481</span><span class="stringliteral">    &gt;&gt;&gt; ax.plot(x, lsq_res[1] + lsq_res[0] * x, &#39;g-&#39;)</span></div>
<div class="line"><span class="lineno">  482</span><span class="stringliteral">    &gt;&gt;&gt; plt.show()</span></div>
<div class="line"><span class="lineno">  483</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  484</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  485</span>    <span class="keywordflow">if</span> method <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&#39;hierarchical&#39;</span>, <span class="stringliteral">&#39;separate&#39;</span>]:</div>
<div class="line"><span class="lineno">  486</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;method can only be &#39;hierarchical&#39; or &#39;separate&#39;&quot;</span>)</div>
<div class="line"><span class="lineno">  487</span>    y = np.asarray(y).ravel()</div>
<div class="line"><span class="lineno">  488</span>    <span class="keywordflow">if</span> x <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  489</span>        x = np.arange(len(y), dtype=float)</div>
<div class="line"><span class="lineno">  490</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  491</span>        x = np.asarray(x, dtype=float).ravel()</div>
<div class="line"><span class="lineno">  492</span>        <span class="keywordflow">if</span> len(x) != len(y):</div>
<div class="line"><span class="lineno">  493</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Incompatible lengths ! (%s&lt;&gt;%s)&quot;</span> %</div>
<div class="line"><span class="lineno">  494</span>                             (len(y), len(x)))</div>
<div class="line"><span class="lineno">  495</span> </div>
<div class="line"><span class="lineno">  496</span>    deltax = x[:, np.newaxis] - x</div>
<div class="line"><span class="lineno">  497</span>    deltay = y[:, np.newaxis] - y</div>
<div class="line"><span class="lineno">  498</span>    slopes, intercepts = [], []</div>
<div class="line"><span class="lineno">  499</span> </div>
<div class="line"><span class="lineno">  500</span>    <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(len(x)):</div>
<div class="line"><span class="lineno">  501</span>        id_nonzero = deltax[j, :] != 0</div>
<div class="line"><span class="lineno">  502</span>        slopes_j = deltay[j, id_nonzero] / deltax[j, id_nonzero]</div>
<div class="line"><span class="lineno">  503</span>        medslope_j = np.median(slopes_j)</div>
<div class="line"><span class="lineno">  504</span>        slopes.append(medslope_j)</div>
<div class="line"><span class="lineno">  505</span>        <span class="keywordflow">if</span> method == <span class="stringliteral">&#39;separate&#39;</span>:</div>
<div class="line"><span class="lineno">  506</span>            z = y*x[j] - y[j]*x</div>
<div class="line"><span class="lineno">  507</span>            medintercept_j = np.median(z[id_nonzero] / deltax[j, id_nonzero])</div>
<div class="line"><span class="lineno">  508</span>            intercepts.append(medintercept_j)</div>
<div class="line"><span class="lineno">  509</span> </div>
<div class="line"><span class="lineno">  510</span>    medslope = np.median(np.asarray(slopes))</div>
<div class="line"><span class="lineno">  511</span>    <span class="keywordflow">if</span> method == <span class="stringliteral">&quot;separate&quot;</span>:</div>
<div class="line"><span class="lineno">  512</span>        medinter = np.median(np.asarray(intercepts))</div>
<div class="line"><span class="lineno">  513</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  514</span>        medinter = np.median(y - medslope*x)</div>
<div class="line"><span class="lineno">  515</span> </div>
<div class="line"><span class="lineno">  516</span>    <span class="keywordflow">return</span> SiegelslopesResult(slope=medslope, intercept=medinter)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a5681db74b7a6921b68a36f60ecd0cf9c" name="a5681db74b7a6921b68a36f60ecd0cf9c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5681db74b7a6921b68a36f60ecd0cf9c">&#9670;&#160;</a></span>theilslopes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._stats_mstats_common.theilslopes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.95</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em> = <code>'separate'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Computes the Theil-Sen estimator for a set of points (x, y).

`theilslopes` implements a method for robust linear regression.  It
computes the slope as the median of all slopes between paired values.

Parameters
----------
y : array_like
Dependent variable.
x : array_like or None, optional
Independent variable. If None, use ``arange(len(y))`` instead.
alpha : float, optional
Confidence degree between 0 and 1. Default is 95% confidence.
Note that `alpha` is symmetric around 0.5, i.e. both 0.1 and 0.9 are
interpreted as "find the 90% confidence interval".
method : {'joint', 'separate'}, optional
Method to be used for computing estimate for intercept.
Following methods are supported,

    * 'joint': Uses np.median(y - slope * x) as intercept.
    * 'separate': Uses np.median(y) - slope * np.median(x)
                  as intercept.

The default is 'separate'.

.. versionadded:: 1.8.0

Returns
-------
result : ``TheilslopesResult`` instance
The return value is an object with the following attributes:

slope : float
    Theil slope.
intercept : float
    Intercept of the Theil line.
low_slope : float
    Lower bound of the confidence interval on `slope`.
high_slope : float
    Upper bound of the confidence interval on `slope`.

See Also
--------
siegelslopes : a similar technique using repeated medians

Notes
-----
The implementation of `theilslopes` follows [1]_. The intercept is
not defined in [1]_, and here it is defined as ``median(y) -
slope*median(x)``, which is given in [3]_. Other definitions of
the intercept exist in the literature such as  ``median(y - slope*x)``
in [4]_. The approach to compute the intercept can be determined by the
parameter ``method``. A confidence interval for the intercept is not
given as this question is not addressed in [1]_.

For compatibility with older versions of SciPy, the return value acts
like a ``namedtuple`` of length 4, with fields ``slope``, ``intercept``,
``low_slope``, and ``high_slope``, so one can continue to write::

slope, intercept, low_slope, high_slope = theilslopes(y, x)

References
----------
.. [1] P.K. Sen, "Estimates of the regression coefficient based on
   Kendall's tau", J. Am. Stat. Assoc., Vol. 63, pp. 1379-1389, 1968.
.. [2] H. Theil, "A rank-invariant method of linear and polynomial
   regression analysis I, II and III",  Nederl. Akad. Wetensch., Proc.
   53:, pp. 386-392, pp. 521-525, pp. 1397-1412, 1950.
.. [3] W.L. Conover, "Practical nonparametric statistics", 2nd ed.,
   John Wiley and Sons, New York, pp. 493.
.. [4] https://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator

Examples
--------
&gt;&gt;&gt; from scipy import stats
&gt;&gt;&gt; import matplotlib.pyplot as plt

&gt;&gt;&gt; x = np.linspace(-5, 5, num=150)
&gt;&gt;&gt; y = x + np.random.normal(size=x.size)
&gt;&gt;&gt; y[11:15] += 10  # add outliers
&gt;&gt;&gt; y[-5:] -= 7

Compute the slope, intercept and 90% confidence interval.  For comparison,
also compute the least-squares fit with `linregress`:

&gt;&gt;&gt; res = stats.theilslopes(y, x, 0.90, method='separate')
&gt;&gt;&gt; lsq_res = stats.linregress(x, y)

Plot the results. The Theil-Sen regression line is shown in red, with the
dashed red lines illustrating the confidence interval of the slope (note
that the dashed red lines are not the confidence interval of the regression
as the confidence interval of the intercept is not included). The green
line shows the least-squares fit for comparison.

&gt;&gt;&gt; fig = plt.figure()
&gt;&gt;&gt; ax = fig.add_subplot(111)
&gt;&gt;&gt; ax.plot(x, y, 'b.')
&gt;&gt;&gt; ax.plot(x, res[1] + res[0] * x, 'r-')
&gt;&gt;&gt; ax.plot(x, res[1] + res[2] * x, 'r--')
&gt;&gt;&gt; ax.plot(x, res[1] + res[3] * x, 'r--')
&gt;&gt;&gt; ax.plot(x, lsq_res[1] + lsq_res[0] * x, 'g-')
&gt;&gt;&gt; plt.show()</pre> <div class="fragment"><div class="line"><span class="lineno">  212</span><span class="keyword">def </span>theilslopes(y, x=None, alpha=0.95, method=&#39;separate&#39;):</div>
<div class="line"><span class="lineno">  213</span>    <span class="stringliteral">r&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">    Computes the Theil-Sen estimator for a set of points (x, y).</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">    `theilslopes` implements a method for robust linear regression.  It</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">    computes the slope as the median of all slopes between paired values.</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">    y : array_like</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">        Dependent variable.</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">    x : array_like or None, optional</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">        Independent variable. If None, use ``arange(len(y))`` instead.</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">    alpha : float, optional</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">        Confidence degree between 0 and 1. Default is 95% confidence.</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">        Note that `alpha` is symmetric around 0.5, i.e. both 0.1 and 0.9 are</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">        interpreted as &quot;find the 90% confidence interval&quot;.</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">    method : {&#39;joint&#39;, &#39;separate&#39;}, optional</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">        Method to be used for computing estimate for intercept.</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">        Following methods are supported,</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">            * &#39;joint&#39;: Uses np.median(y - slope * x) as intercept.</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">            * &#39;separate&#39;: Uses np.median(y) - slope * np.median(x)</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">                          as intercept.</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">        The default is &#39;separate&#39;.</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        .. versionadded:: 1.8.0</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">    result : ``TheilslopesResult`` instance</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">        The return value is an object with the following attributes:</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">        slope : float</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">            Theil slope.</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">        intercept : float</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">            Intercept of the Theil line.</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">        low_slope : float</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">            Lower bound of the confidence interval on `slope`.</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">        high_slope : float</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">            Upper bound of the confidence interval on `slope`.</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">    siegelslopes : a similar technique using repeated medians</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">    The implementation of `theilslopes` follows [1]_. The intercept is</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">    not defined in [1]_, and here it is defined as ``median(y) -</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">    slope*median(x)``, which is given in [3]_. Other definitions of</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">    the intercept exist in the literature such as  ``median(y - slope*x)``</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">    in [4]_. The approach to compute the intercept can be determined by the</span></div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">    parameter ``method``. A confidence interval for the intercept is not</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">    given as this question is not addressed in [1]_.</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral">    For compatibility with older versions of SciPy, the return value acts</span></div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">    like a ``namedtuple`` of length 4, with fields ``slope``, ``intercept``,</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">    ``low_slope``, and ``high_slope``, so one can continue to write::</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">        slope, intercept, low_slope, high_slope = theilslopes(y, x)</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral">    .. [1] P.K. Sen, &quot;Estimates of the regression coefficient based on</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">           Kendall&#39;s tau&quot;, J. Am. Stat. Assoc., Vol. 63, pp. 1379-1389, 1968.</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">    .. [2] H. Theil, &quot;A rank-invariant method of linear and polynomial</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">           regression analysis I, II and III&quot;,  Nederl. Akad. Wetensch., Proc.</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">           53:, pp. 386-392, pp. 521-525, pp. 1397-1412, 1950.</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">    .. [3] W.L. Conover, &quot;Practical nonparametric statistics&quot;, 2nd ed.,</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">           John Wiley and Sons, New York, pp. 493.</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">    .. [4] https://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">    &gt;&gt;&gt; from scipy import stats</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">    &gt;&gt;&gt; x = np.linspace(-5, 5, num=150)</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">    &gt;&gt;&gt; y = x + np.random.normal(size=x.size)</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">    &gt;&gt;&gt; y[11:15] += 10  # add outliers</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">    &gt;&gt;&gt; y[-5:] -= 7</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">    Compute the slope, intercept and 90% confidence interval.  For comparison,</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">    also compute the least-squares fit with `linregress`:</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.theilslopes(y, x, 0.90, method=&#39;separate&#39;)</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">    &gt;&gt;&gt; lsq_res = stats.linregress(x, y)</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">    Plot the results. The Theil-Sen regression line is shown in red, with the</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">    dashed red lines illustrating the confidence interval of the slope (note</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">    that the dashed red lines are not the confidence interval of the regression</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    as the confidence interval of the intercept is not included). The green</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    line shows the least-squares fit for comparison.</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">    &gt;&gt;&gt; fig = plt.figure()</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">    &gt;&gt;&gt; ax = fig.add_subplot(111)</span></div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">    &gt;&gt;&gt; ax.plot(x, y, &#39;b.&#39;)</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">    &gt;&gt;&gt; ax.plot(x, res[1] + res[0] * x, &#39;r-&#39;)</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">    &gt;&gt;&gt; ax.plot(x, res[1] + res[2] * x, &#39;r--&#39;)</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">    &gt;&gt;&gt; ax.plot(x, res[1] + res[3] * x, &#39;r--&#39;)</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral">    &gt;&gt;&gt; ax.plot(x, lsq_res[1] + lsq_res[0] * x, &#39;g-&#39;)</span></div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">    &gt;&gt;&gt; plt.show()</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  318</span>    <span class="keywordflow">if</span> method <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&#39;joint&#39;</span>, <span class="stringliteral">&#39;separate&#39;</span>]:</div>
<div class="line"><span class="lineno">  319</span>        <span class="keywordflow">raise</span> ValueError((<span class="stringliteral">&quot;method must be either &#39;joint&#39; or &#39;separate&#39;.&quot;</span></div>
<div class="line"><span class="lineno">  320</span>                          <span class="stringliteral">&quot;&#39;{}&#39; is invalid.&quot;</span>.format(method)))</div>
<div class="line"><span class="lineno">  321</span>    <span class="comment"># We copy both x and y so we can use _find_repeats.</span></div>
<div class="line"><span class="lineno">  322</span>    y = np.array(y).flatten()</div>
<div class="line"><span class="lineno">  323</span>    <span class="keywordflow">if</span> x <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  324</span>        x = np.arange(len(y), dtype=float)</div>
<div class="line"><span class="lineno">  325</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  326</span>        x = np.array(x, dtype=float).flatten()</div>
<div class="line"><span class="lineno">  327</span>        <span class="keywordflow">if</span> len(x) != len(y):</div>
<div class="line"><span class="lineno">  328</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Incompatible lengths ! (%s&lt;&gt;%s)&quot;</span> %</div>
<div class="line"><span class="lineno">  329</span>                             (len(y), len(x)))</div>
<div class="line"><span class="lineno">  330</span> </div>
<div class="line"><span class="lineno">  331</span>    <span class="comment"># Compute sorted slopes only when deltax &gt; 0</span></div>
<div class="line"><span class="lineno">  332</span>    deltax = x[:, np.newaxis] - x</div>
<div class="line"><span class="lineno">  333</span>    deltay = y[:, np.newaxis] - y</div>
<div class="line"><span class="lineno">  334</span>    slopes = deltay[deltax &gt; 0] / deltax[deltax &gt; 0]</div>
<div class="line"><span class="lineno">  335</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> slopes.size:</div>
<div class="line"><span class="lineno">  336</span>        msg = <span class="stringliteral">&quot;All `x` coordinates are identical.&quot;</span></div>
<div class="line"><span class="lineno">  337</span>        warnings.warn(msg, RuntimeWarning, stacklevel=2)</div>
<div class="line"><span class="lineno">  338</span>    slopes.sort()</div>
<div class="line"><span class="lineno">  339</span>    medslope = np.median(slopes)</div>
<div class="line"><span class="lineno">  340</span>    <span class="keywordflow">if</span> method == <span class="stringliteral">&#39;joint&#39;</span>:</div>
<div class="line"><span class="lineno">  341</span>        medinter = np.median(y - medslope * x)</div>
<div class="line"><span class="lineno">  342</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  343</span>        medinter = np.median(y) - medslope * np.median(x)</div>
<div class="line"><span class="lineno">  344</span>    <span class="comment"># Now compute confidence intervals</span></div>
<div class="line"><span class="lineno">  345</span>    <span class="keywordflow">if</span> alpha &gt; 0.5:</div>
<div class="line"><span class="lineno">  346</span>        alpha = 1. - alpha</div>
<div class="line"><span class="lineno">  347</span> </div>
<div class="line"><span class="lineno">  348</span>    z = distributions.norm.ppf(alpha / 2.)</div>
<div class="line"><span class="lineno">  349</span>    <span class="comment"># This implements (2.6) from Sen (1968)</span></div>
<div class="line"><span class="lineno">  350</span>    _, nxreps = _find_repeats(x)</div>
<div class="line"><span class="lineno">  351</span>    _, nyreps = _find_repeats(y)</div>
<div class="line"><span class="lineno">  352</span>    nt = len(slopes)       <span class="comment"># N in Sen (1968)</span></div>
<div class="line"><span class="lineno">  353</span>    ny = len(y)            <span class="comment"># n in Sen (1968)</span></div>
<div class="line"><span class="lineno">  354</span>    <span class="comment"># Equation 2.6 in Sen (1968):</span></div>
<div class="line"><span class="lineno">  355</span>    sigsq = 1/18. * (ny * (ny-1) * (2*ny+5) -</div>
<div class="line"><span class="lineno">  356</span>                     sum(k * (k-1) * (2*k + 5) <span class="keywordflow">for</span> k <span class="keywordflow">in</span> nxreps) -</div>
<div class="line"><span class="lineno">  357</span>                     sum(k * (k-1) * (2*k + 5) <span class="keywordflow">for</span> k <span class="keywordflow">in</span> nyreps))</div>
<div class="line"><span class="lineno">  358</span>    <span class="comment"># Find the confidence interval indices in `slopes`</span></div>
<div class="line"><span class="lineno">  359</span>    <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  360</span>        sigma = np.sqrt(sigsq)</div>
<div class="line"><span class="lineno">  361</span>        Ru = min(int(np.round((nt - z*sigma)/2.)), len(slopes)-1)</div>
<div class="line"><span class="lineno">  362</span>        Rl = max(int(np.round((nt + z*sigma)/2.)) - 1, 0)</div>
<div class="line"><span class="lineno">  363</span>        delta = slopes[[Rl, Ru]]</div>
<div class="line"><span class="lineno">  364</span>    <span class="keywordflow">except</span> (ValueError, IndexError):</div>
<div class="line"><span class="lineno">  365</span>        delta = (np.nan, np.nan)</div>
<div class="line"><span class="lineno">  366</span> </div>
<div class="line"><span class="lineno">  367</span>    <span class="keywordflow">return</span> TheilslopesResult(slope=medslope, intercept=medinter,</div>
<div class="line"><span class="lineno">  368</span>                             low_slope=delta[0], high_slope=delta[1])</div>
<div class="line"><span class="lineno">  369</span> </div>
<div class="line"><span class="lineno">  370</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a06fb02725769ed1d8ca61b62ac2b4343" name="a06fb02725769ed1d8ca61b62ac2b4343"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06fb02725769ed1d8ca61b62ac2b4343">&#9670;&#160;</a></span>LinregressResult</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._stats_mstats_common.LinregressResult</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  _make_tuple_bunch(<span class="stringliteral">&#39;LinregressResult&#39;</span>,</div>
<div class="line"><span class="lineno">    2</span>                                     [<span class="stringliteral">&#39;slope&#39;</span>, <span class="stringliteral">&#39;intercept&#39;</span>, <span class="stringliteral">&#39;rvalue&#39;</span>,</div>
<div class="line"><span class="lineno">    3</span>                                      <span class="stringliteral">&#39;pvalue&#39;</span>, <span class="stringliteral">&#39;stderr&#39;</span>],</div>
<div class="line"><span class="lineno">    4</span>                                     extra_field_names=[<span class="stringliteral">&#39;intercept_stderr&#39;</span>])</div>
</div><!-- fragment -->
</div>
</div>
<a id="a0ce4666a9c5db89dcc69ec7f7607881a" name="a0ce4666a9c5db89dcc69ec7f7607881a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0ce4666a9c5db89dcc69ec7f7607881a">&#9670;&#160;</a></span>SiegelslopesResult</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._stats_mstats_common.SiegelslopesResult</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  _make_tuple_bunch(<span class="stringliteral">&#39;SiegelslopesResult&#39;</span>,</div>
<div class="line"><span class="lineno">    2</span>                                       [<span class="stringliteral">&#39;slope&#39;</span>, <span class="stringliteral">&#39;intercept&#39;</span>])</div>
</div><!-- fragment -->
</div>
</div>
<a id="a8a1b0913761ae145354e4648bbef73f1" name="a8a1b0913761ae145354e4648bbef73f1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a1b0913761ae145354e4648bbef73f1">&#9670;&#160;</a></span>TheilslopesResult</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._stats_mstats_common.TheilslopesResult</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  _make_tuple_bunch(<span class="stringliteral">&#39;TheilslopesResult&#39;</span>,</div>
<div class="line"><span class="lineno">    2</span>                                      [<span class="stringliteral">&#39;slope&#39;</span>, <span class="stringliteral">&#39;intercept&#39;</span>,</div>
<div class="line"><span class="lineno">    3</span>                                       <span class="stringliteral">&#39;low_slope&#39;</span>, <span class="stringliteral">&#39;high_slope&#39;</span>])</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
