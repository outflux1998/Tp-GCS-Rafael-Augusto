<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: scipy.sparse.linalg._eigen.lobpcg.lobpcg Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacescipy.html">scipy</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1sparse.html">sparse</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1sparse_1_1linalg.html">linalg</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__eigen.html">_eigen</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__eigen_1_1lobpcg.html">lobpcg</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__eigen_1_1lobpcg_1_1lobpcg.html">lobpcg</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">scipy.sparse.linalg._eigen.lobpcg.lobpcg Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a05b8200564699f6ef4260662cc4db5d7" id="r_a05b8200564699f6ef4260662cc4db5d7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__eigen_1_1lobpcg_1_1lobpcg.html#a05b8200564699f6ef4260662cc4db5d7">_report_nonhermitian</a> (M, name)</td></tr>
<tr class="separator:a05b8200564699f6ef4260662cc4db5d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45da5af0300b422573e93c0e672122a1" id="r_a45da5af0300b422573e93c0e672122a1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__eigen_1_1lobpcg_1_1lobpcg.html#a45da5af0300b422573e93c0e672122a1">_as2d</a> (ar)</td></tr>
<tr class="separator:a45da5af0300b422573e93c0e672122a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1693e69c408fa5b3c78569bcd39c3583" id="r_a1693e69c408fa5b3c78569bcd39c3583"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__eigen_1_1lobpcg_1_1lobpcg.html#a1693e69c408fa5b3c78569bcd39c3583">_makeOperator</a> (operatorInput, expectedShape)</td></tr>
<tr class="separator:a1693e69c408fa5b3c78569bcd39c3583"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf8b63bf56bf883a19b831c0a041ad80" id="r_aaf8b63bf56bf883a19b831c0a041ad80"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__eigen_1_1lobpcg_1_1lobpcg.html#aaf8b63bf56bf883a19b831c0a041ad80">_applyConstraints</a> (blockVectorV, factYBY, blockVectorBY, blockVectorY)</td></tr>
<tr class="separator:aaf8b63bf56bf883a19b831c0a041ad80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89a8a55ac8fee2bbee37835e9da25d8a" id="r_a89a8a55ac8fee2bbee37835e9da25d8a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__eigen_1_1lobpcg_1_1lobpcg.html#a89a8a55ac8fee2bbee37835e9da25d8a">_b_orthonormalize</a> (B, blockVectorV, blockVectorBV=None, retInvR=False)</td></tr>
<tr class="separator:a89a8a55ac8fee2bbee37835e9da25d8a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5682a27b0eb65c08ffbd8d285fe59b53" id="r_a5682a27b0eb65c08ffbd8d285fe59b53"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__eigen_1_1lobpcg_1_1lobpcg.html#a5682a27b0eb65c08ffbd8d285fe59b53">_get_indx</a> (_lambda, num, largest)</td></tr>
<tr class="separator:a5682a27b0eb65c08ffbd8d285fe59b53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0401e2f3400e6b2745c1fcb4c87f1a3f" id="r_a0401e2f3400e6b2745c1fcb4c87f1a3f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1sparse_1_1linalg_1_1__eigen_1_1lobpcg_1_1lobpcg.html#a0401e2f3400e6b2745c1fcb4c87f1a3f">lobpcg</a> (A, X, B=None, M=None, Y=None, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=None, maxiter=None, largest=True, verbosityLevel=0, retLambdaHistory=False, retResidualNormsHistory=False)</td></tr>
<tr class="memdesc:a0401e2f3400e6b2745c1fcb4c87f1a3f"><td class="mdescLeft">&#160;</td><td class="mdescRight">B-orthonormalize X.  <br /></td></tr>
<tr class="separator:a0401e2f3400e6b2745c1fcb4c87f1a3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Locally Optimal Block Preconditioned Conjugate Gradient Method (LOBPCG).

References
----------
.. [1] A. V. Knyazev (2001),
       Toward the Optimal Preconditioned Eigensolver: Locally Optimal
       Block Preconditioned Conjugate Gradient Method.
       SIAM Journal on Scientific Computing 23, no. 2,
       pp. 517-541. :doi:`10.1137/S1064827500366124`

.. [2] A. V. Knyazev, I. Lashuk, M. E. Argentati, and E. Ovchinnikov (2007),
       Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX)
       in hypre and PETSc.  :arxiv:`0705.2626`

.. [3] A. V. Knyazev's C and MATLAB implementations:
       https://github.com/lobpcg/blopex
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="aaf8b63bf56bf883a19b831c0a041ad80" name="aaf8b63bf56bf883a19b831c0a041ad80"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf8b63bf56bf883a19b831c0a041ad80">&#9670;&#160;</a></span>_applyConstraints()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._eigen.lobpcg.lobpcg._applyConstraints </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>blockVectorV</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>factYBY</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>blockVectorBY</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>blockVectorY</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Changes blockVectorV in place.</pre> <div class="fragment"><div class="line"><span class="lineno">   76</span><span class="keyword">def </span>_applyConstraints(blockVectorV, factYBY, blockVectorBY, blockVectorY):</div>
<div class="line"><span class="lineno">   77</span>    <span class="stringliteral">&quot;&quot;&quot;Changes blockVectorV in place.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   78</span>    YBV = np.dot(blockVectorBY.T.conj(), blockVectorV)</div>
<div class="line"><span class="lineno">   79</span>    tmp = cho_solve(factYBY, YBV)</div>
<div class="line"><span class="lineno">   80</span>    blockVectorV -= np.dot(blockVectorY, tmp)</div>
<div class="line"><span class="lineno">   81</span> </div>
<div class="line"><span class="lineno">   82</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a45da5af0300b422573e93c0e672122a1" name="a45da5af0300b422573e93c0e672122a1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45da5af0300b422573e93c0e672122a1">&#9670;&#160;</a></span>_as2d()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._eigen.lobpcg.lobpcg._as2d </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ar</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">If the input array is 2D return it, if it is 1D, append a dimension,
making it a column vector.
</pre> <div class="fragment"><div class="line"><span class="lineno">   48</span><span class="keyword">def </span>_as2d(ar):</div>
<div class="line"><span class="lineno">   49</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">    If the input array is 2D return it, if it is 1D, append a dimension,</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral">    making it a column vector.</span></div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   53</span>    <span class="keywordflow">if</span> ar.ndim == 2:</div>
<div class="line"><span class="lineno">   54</span>        <span class="keywordflow">return</span> ar</div>
<div class="line"><span class="lineno">   55</span>    <span class="keywordflow">else</span>:  <span class="comment"># Assume 1!</span></div>
<div class="line"><span class="lineno">   56</span>        aux = np.array(ar, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">   57</span>        aux.shape = (ar.shape[0], 1)</div>
<div class="line"><span class="lineno">   58</span>        <span class="keywordflow">return</span> aux</div>
<div class="line"><span class="lineno">   59</span> </div>
<div class="line"><span class="lineno">   60</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a89a8a55ac8fee2bbee37835e9da25d8a" name="a89a8a55ac8fee2bbee37835e9da25d8a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a89a8a55ac8fee2bbee37835e9da25d8a">&#9670;&#160;</a></span>_b_orthonormalize()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._eigen.lobpcg.lobpcg._b_orthonormalize </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>blockVectorV</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>blockVectorBV</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>retInvR</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">B-orthonormalize the given block vector using Cholesky.</pre> <div class="fragment"><div class="line"><span class="lineno">   83</span><span class="keyword">def </span>_b_orthonormalize(B, blockVectorV, blockVectorBV=None, retInvR=False):</div>
<div class="line"><span class="lineno">   84</span>    <span class="stringliteral">&quot;&quot;&quot;B-orthonormalize the given block vector using Cholesky.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   85</span>    normalization = blockVectorV.max(axis=0) + np.finfo(blockVectorV.dtype).eps</div>
<div class="line"><span class="lineno">   86</span>    blockVectorV = blockVectorV / normalization</div>
<div class="line"><span class="lineno">   87</span>    <span class="keywordflow">if</span> blockVectorBV <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">   88</span>        <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">   89</span>            blockVectorBV = B(blockVectorV)</div>
<div class="line"><span class="lineno">   90</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   91</span>            blockVectorBV = blockVectorV  <span class="comment"># Shared data!!!</span></div>
<div class="line"><span class="lineno">   92</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   93</span>        blockVectorBV = blockVectorBV / normalization</div>
<div class="line"><span class="lineno">   94</span>    VBV = blockVectorV.T.conj() @ blockVectorBV</div>
<div class="line"><span class="lineno">   95</span>    <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">   96</span>        <span class="comment"># VBV is a Cholesky factor from now on...</span></div>
<div class="line"><span class="lineno">   97</span>        VBV = cholesky(VBV, overwrite_a=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">   98</span>        VBV = inv(VBV, overwrite_a=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">   99</span>        blockVectorV = blockVectorV @ VBV</div>
<div class="line"><span class="lineno">  100</span>        <span class="comment"># blockVectorV = (cho_solve((VBV.T, True), blockVectorV.T)).T</span></div>
<div class="line"><span class="lineno">  101</span>        <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  102</span>            blockVectorBV = blockVectorBV @ VBV</div>
<div class="line"><span class="lineno">  103</span>            <span class="comment"># blockVectorBV = (cho_solve((VBV.T, True), blockVectorBV.T)).T</span></div>
<div class="line"><span class="lineno">  104</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  105</span>            blockVectorBV = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  106</span>    <span class="keywordflow">except</span> LinAlgError:</div>
<div class="line"><span class="lineno">  107</span>        <span class="comment"># raise ValueError(&#39;Cholesky has failed&#39;)</span></div>
<div class="line"><span class="lineno">  108</span>        blockVectorV = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  109</span>        blockVectorBV = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  110</span>        VBV = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  111</span> </div>
<div class="line"><span class="lineno">  112</span>    <span class="keywordflow">if</span> retInvR:</div>
<div class="line"><span class="lineno">  113</span>        <span class="keywordflow">return</span> blockVectorV, blockVectorBV, VBV, normalization</div>
<div class="line"><span class="lineno">  114</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  115</span>        <span class="keywordflow">return</span> blockVectorV, blockVectorBV</div>
<div class="line"><span class="lineno">  116</span> </div>
<div class="line"><span class="lineno">  117</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5682a27b0eb65c08ffbd8d285fe59b53" name="a5682a27b0eb65c08ffbd8d285fe59b53"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5682a27b0eb65c08ffbd8d285fe59b53">&#9670;&#160;</a></span>_get_indx()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._eigen.lobpcg.lobpcg._get_indx </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>_lambda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>largest</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Get `num` indices into `_lambda` depending on `largest` option.</pre> <div class="fragment"><div class="line"><span class="lineno">  118</span><span class="keyword">def </span>_get_indx(_lambda, num, largest):</div>
<div class="line"><span class="lineno">  119</span>    <span class="stringliteral">&quot;&quot;&quot;Get `num` indices into `_lambda` depending on `largest` option.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  120</span>    ii = np.argsort(_lambda)</div>
<div class="line"><span class="lineno">  121</span>    <span class="keywordflow">if</span> largest:</div>
<div class="line"><span class="lineno">  122</span>        ii = ii[:-num - 1:-1]</div>
<div class="line"><span class="lineno">  123</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  124</span>        ii = ii[:num]</div>
<div class="line"><span class="lineno">  125</span> </div>
<div class="line"><span class="lineno">  126</span>    <span class="keywordflow">return</span> ii</div>
<div class="line"><span class="lineno">  127</span> </div>
<div class="line"><span class="lineno">  128</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1693e69c408fa5b3c78569bcd39c3583" name="a1693e69c408fa5b3c78569bcd39c3583"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1693e69c408fa5b3c78569bcd39c3583">&#9670;&#160;</a></span>_makeOperator()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._eigen.lobpcg.lobpcg._makeOperator </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>operatorInput</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>expectedShape</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Takes a dense numpy array or a sparse matrix or
a function and makes an operator performing matrix * blockvector
products.</pre> <div class="fragment"><div class="line"><span class="lineno">   61</span><span class="keyword">def </span>_makeOperator(operatorInput, expectedShape):</div>
<div class="line"><span class="lineno">   62</span>    <span class="stringliteral">&quot;&quot;&quot;Takes a dense numpy array or a sparse matrix or</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">    a function and makes an operator performing matrix * blockvector</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    products.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   65</span>    <span class="keywordflow">if</span> operatorInput <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">   66</span>        <span class="keywordflow">return</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">   67</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   68</span>        operator = aslinearoperator(operatorInput)</div>
<div class="line"><span class="lineno">   69</span> </div>
<div class="line"><span class="lineno">   70</span>    <span class="keywordflow">if</span> operator.shape != expectedShape:</div>
<div class="line"><span class="lineno">   71</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;operator has invalid shape&quot;</span>)</div>
<div class="line"><span class="lineno">   72</span> </div>
<div class="line"><span class="lineno">   73</span>    <span class="keywordflow">return</span> operator</div>
<div class="line"><span class="lineno">   74</span> </div>
<div class="line"><span class="lineno">   75</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a05b8200564699f6ef4260662cc4db5d7" name="a05b8200564699f6ef4260662cc4db5d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a05b8200564699f6ef4260662cc4db5d7">&#9670;&#160;</a></span>_report_nonhermitian()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._eigen.lobpcg.lobpcg._report_nonhermitian </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>M</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Report if `M` is not a Hermitian matrix given its type.
</pre> <div class="fragment"><div class="line"><span class="lineno">   31</span><span class="keyword">def </span>_report_nonhermitian(M, name):</div>
<div class="line"><span class="lineno">   32</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">    Report if `M` is not a Hermitian matrix given its type.</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   35</span>    <span class="keyword">from</span> <a class="code hl_namespace" href="namespacescipy_1_1linalg.html">scipy.linalg</a> <span class="keyword">import</span> norm</div>
<div class="line"><span class="lineno">   36</span> </div>
<div class="line"><span class="lineno">   37</span>    md = M - M.T.conj()</div>
<div class="line"><span class="lineno">   38</span>    nmd = norm(md, 1)</div>
<div class="line"><span class="lineno">   39</span>    tol = 10 * np.finfo(M.dtype).eps</div>
<div class="line"><span class="lineno">   40</span>    tol = max(tol, tol * norm(M, 1))</div>
<div class="line"><span class="lineno">   41</span>    <span class="keywordflow">if</span> nmd &gt; tol:</div>
<div class="line"><span class="lineno">   42</span>        warnings.warn(</div>
<div class="line"><span class="lineno">   43</span>              f<span class="stringliteral">&quot;Matrix {name} of the type {M.dtype} is not Hermitian: &quot;</span></div>
<div class="line"><span class="lineno">   44</span>              f<span class="stringliteral">&quot;condition: {nmd} &lt; {tol} fails.&quot;</span>,</div>
<div class="line"><span class="lineno">   45</span>              UserWarning, stacklevel=4</div>
<div class="line"><span class="lineno">   46</span>         )</div>
<div class="line"><span class="lineno">   47</span> </div>
<div class="ttc" id="anamespacescipy_1_1linalg_html"><div class="ttname"><a href="namespacescipy_1_1linalg.html">scipy.linalg</a></div><div class="ttdef"><b>Definition</b> __init__.py:1</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a0401e2f3400e6b2745c1fcb4c87f1a3f" name="a0401e2f3400e6b2745c1fcb4c87f1a3f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0401e2f3400e6b2745c1fcb4c87f1a3f">&#9670;&#160;</a></span>lobpcg()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.sparse.linalg._eigen.lobpcg.lobpcg.lobpcg </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>B</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>M</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Y</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>maxiter</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>largest</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbosityLevel</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>retLambdaHistory</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>retResidualNormsHistory</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>B-orthonormalize X. </p>
<pre class="fragment">Locally Optimal Block Preconditioned Conjugate Gradient Method (LOBPCG)

LOBPCG is a preconditioned eigensolver for large symmetric positive
definite (SPD) generalized eigenproblems.

Parameters
----------
A : {sparse matrix, dense matrix, LinearOperator}
    The symmetric linear operator of the problem, usually a
    sparse matrix.  Often called the "stiffness matrix".
X : ndarray, float32 or float64
    Initial approximation to the ``k`` eigenvectors (non-sparse). If `A`
    has ``shape=(n,n)`` then `X` should have shape ``shape=(n,k)``.
B : {dense matrix, sparse matrix, LinearOperator}, optional
    The right hand side operator in a generalized eigenproblem.
    By default, ``B = Identity``.  Often called the "mass matrix".
M : {dense matrix, sparse matrix, LinearOperator}, optional
    Preconditioner to `A`; by default ``M = Identity``.
    `M` should approximate the inverse of `A`.
Y : ndarray, float32 or float64, optional
    n-by-sizeY matrix of constraints (non-sparse), sizeY &lt; n
    The iterations will be performed in the B-orthogonal complement
    of the column-space of Y. Y must be full rank.
tol : scalar, optional
    Solver tolerance (stopping criterion).
    The default is ``tol=n*sqrt(eps)``.
maxiter : int, optional
    Maximum number of iterations.  The default is ``maxiter = 20``.
largest : bool, optional
    When True, solve for the largest eigenvalues, otherwise the smallest.
verbosityLevel : int, optional
    Controls solver output.  The default is ``verbosityLevel=0``.
retLambdaHistory : bool, optional
    Whether to return eigenvalue history.  Default is False.
retResidualNormsHistory : bool, optional
    Whether to return history of residual norms.  Default is False.

Returns
-------
w : ndarray
    Array of ``k`` eigenvalues
v : ndarray
    An array of ``k`` eigenvectors.  `v` has the same shape as `X`.
lambdas : list of ndarray, optional
    The eigenvalue history, if `retLambdaHistory` is True.
rnorms : list of ndarray, optional
    The history of residual norms, if `retResidualNormsHistory` is True.

Notes
-----
If both ``retLambdaHistory`` and ``retResidualNormsHistory`` are True,
the return tuple has the following format
``(lambda, V, lambda history, residual norms history)``.

In the following ``n`` denotes the matrix size and ``k`` the number
of required eigenvalues (smallest or largest).

The LOBPCG code internally solves eigenproblems of the size ``3k`` on every
iteration by calling the "standard" dense eigensolver, so if ``k`` is not
small enough compared to ``n``, it does not make sense to call the LOBPCG
code, but rather one should use the "standard" eigensolver, e.g. numpy or
scipy function in this case.
If one calls the LOBPCG algorithm for ``5k &gt; n``, it will most likely break
internally, so the code tries to call the standard function instead.

It is not that ``n`` should be large for the LOBPCG to work, but rather the
ratio ``n / k`` should be large. It you call LOBPCG with ``k=1``
and ``n=10``, it works though ``n`` is small. The method is intended
for extremely large ``n / k``.

The convergence speed depends basically on two factors:

1. Relative separation of the seeking eigenvalues from the rest
   of the eigenvalues. One can vary ``k`` to improve the absolute
   separation and use proper preconditioning to shrink the spectral spread.
   For example, a rod vibration test problem (under tests
   directory) is ill-conditioned for large ``n``, so convergence will be
   slow, unless efficient preconditioning is used. For this specific
   problem, a good simple preconditioner function would be a linear solve
   for `A`, which is easy to code since `A` is tridiagonal.

2. Quality of the initial approximations `X` to the seeking eigenvectors.
   Randomly distributed around the origin vectors work well if no better
   choice is known.

References
----------
.. [1] A. V. Knyazev (2001),
       Toward the Optimal Preconditioned Eigensolver: Locally Optimal
       Block Preconditioned Conjugate Gradient Method.
       SIAM Journal on Scientific Computing 23, no. 2,
       pp. 517-541. :doi:`10.1137/S1064827500366124`

.. [2] A. V. Knyazev, I. Lashuk, M. E. Argentati, and E. Ovchinnikov
       (2007), Block Locally Optimal Preconditioned Eigenvalue Xolvers
       (BLOPEX) in hypre and PETSc. :arxiv:`0705.2626`

.. [3] A. V. Knyazev's C and MATLAB implementations:
       https://github.com/lobpcg/blopex

Examples
--------

Solve ``A x = lambda x`` with constraints and preconditioning.

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from scipy.sparse import spdiags, issparse
&gt;&gt;&gt; from scipy.sparse.linalg import lobpcg, LinearOperator

The square matrix size:

&gt;&gt;&gt; n = 100
&gt;&gt;&gt; vals = np.arange(1, n + 1)

The first mandatory input parameter, in this test
a sparse 2D array representing the square matrix
of the eigenvalue problem to solve:

&gt;&gt;&gt; A = spdiags(vals, 0, n, n)
&gt;&gt;&gt; A.toarray()
array([[  1.,   0.,   0., ...,   0.,   0.,   0.],
       [  0.,   2.,   0., ...,   0.,   0.,   0.],
       [  0.,   0.,   3., ...,   0.,   0.,   0.],
       ...,
       [  0.,   0.,   0., ...,  98.,   0.,   0.],
       [  0.,   0.,   0., ...,   0.,  99.,   0.],
       [  0.,   0.,   0., ...,   0.,   0., 100.]])

Initial guess for eigenvectors, should have linearly independent
columns. The second mandatory input parameter, a 2D array with the
row dimension determining the number of requested eigenvalues.
If no initial approximations available, randomly oriented vectors
commonly work best, e.g., with components normally disrtibuted
around zero or uniformly distributed on the interval [-1 1].

&gt;&gt;&gt; rng = np.random.default_rng()
&gt;&gt;&gt; X = rng.normal(size=(n, 3))

Constraints - an optional input parameter is a 2D array comprising
of column vectors that the eigenvectors must be orthogonal to:

&gt;&gt;&gt; Y = np.eye(n, 3)

Preconditioner in the inverse of A in this example:

&gt;&gt;&gt; invA = spdiags([1./vals], 0, n, n)

The preconditiner must be defined by a function:

&gt;&gt;&gt; def precond( x ):
...     return invA @ x

The argument x of the preconditioner function is a matrix inside `lobpcg`,
thus the use of matrix-matrix product ``@``.

The preconditioner function is passed to lobpcg as a `LinearOperator`:

&gt;&gt;&gt; M = LinearOperator(matvec=precond, matmat=precond,
...                    shape=(n, n), dtype=np.float64)

Let us now solve the eigenvalue problem for the matrix A:

&gt;&gt;&gt; eigenvalues, _ = lobpcg(A, X, Y=Y, M=M, largest=False)
&gt;&gt;&gt; eigenvalues
array([4., 5., 6.])

Note that the vectors passed in Y are the eigenvectors of the 3 smallest
eigenvalues. The results returned are orthogonal to those.</pre><p>Compute the initial Ritz vectors: solve the eigenproblem.</p>
<p>Active index set.</p>
<p>Main iteration loop.</p>
<p>Apply constraints to the preconditioned residuals.</p>
<p>B-orthogonalize the preconditioned residuals to X.</p>
<p>B-orthonormalize the preconditioned residuals.</p>
<p>Perform the Rayleigh Ritz Procedure: Compute symmetric Gram matrices: </p>
<div class="fragment"><div class="line"><span class="lineno">  141</span>):</div>
<div class="line"><span class="lineno">  142</span>    <span class="stringliteral">&quot;&quot;&quot;Locally Optimal Block Preconditioned Conjugate Gradient Method (LOBPCG)</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">    LOBPCG is a preconditioned eigensolver for large symmetric positive</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">    definite (SPD) generalized eigenproblems.</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">    A : {sparse matrix, dense matrix, LinearOperator}</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">        The symmetric linear operator of the problem, usually a</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">        sparse matrix.  Often called the &quot;stiffness matrix&quot;.</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">    X : ndarray, float32 or float64</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">        Initial approximation to the ``k`` eigenvectors (non-sparse). If `A`</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">        has ``shape=(n,n)`` then `X` should have shape ``shape=(n,k)``.</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">    B : {dense matrix, sparse matrix, LinearOperator}, optional</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">        The right hand side operator in a generalized eigenproblem.</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">        By default, ``B = Identity``.  Often called the &quot;mass matrix&quot;.</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">    M : {dense matrix, sparse matrix, LinearOperator}, optional</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">        Preconditioner to `A`; by default ``M = Identity``.</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">        `M` should approximate the inverse of `A`.</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">    Y : ndarray, float32 or float64, optional</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">        n-by-sizeY matrix of constraints (non-sparse), sizeY &lt; n</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">        The iterations will be performed in the B-orthogonal complement</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        of the column-space of Y. Y must be full rank.</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">    tol : scalar, optional</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">        Solver tolerance (stopping criterion).</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">        The default is ``tol=n*sqrt(eps)``.</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">    maxiter : int, optional</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral">        Maximum number of iterations.  The default is ``maxiter = 20``.</span></div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">    largest : bool, optional</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">        When True, solve for the largest eigenvalues, otherwise the smallest.</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral">    verbosityLevel : int, optional</span></div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">        Controls solver output.  The default is ``verbosityLevel=0``.</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">    retLambdaHistory : bool, optional</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">        Whether to return eigenvalue history.  Default is False.</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">    retResidualNormsHistory : bool, optional</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">        Whether to return history of residual norms.  Default is False.</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">    w : ndarray</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">        Array of ``k`` eigenvalues</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">    v : ndarray</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral">        An array of ``k`` eigenvectors.  `v` has the same shape as `X`.</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">    lambdas : list of ndarray, optional</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">        The eigenvalue history, if `retLambdaHistory` is True.</span></div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">    rnorms : list of ndarray, optional</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral">        The history of residual norms, if `retResidualNormsHistory` is True.</span></div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">    If both ``retLambdaHistory`` and ``retResidualNormsHistory`` are True,</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral">    the return tuple has the following format</span></div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">    ``(lambda, V, lambda history, residual norms history)``.</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral">    In the following ``n`` denotes the matrix size and ``k`` the number</span></div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral">    of required eigenvalues (smallest or largest).</span></div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">    The LOBPCG code internally solves eigenproblems of the size ``3k`` on every</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral">    iteration by calling the &quot;standard&quot; dense eigensolver, so if ``k`` is not</span></div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral">    small enough compared to ``n``, it does not make sense to call the LOBPCG</span></div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral">    code, but rather one should use the &quot;standard&quot; eigensolver, e.g. numpy or</span></div>
<div class="line"><span class="lineno">  203</span><span class="stringliteral">    scipy function in this case.</span></div>
<div class="line"><span class="lineno">  204</span><span class="stringliteral">    If one calls the LOBPCG algorithm for ``5k &gt; n``, it will most likely break</span></div>
<div class="line"><span class="lineno">  205</span><span class="stringliteral">    internally, so the code tries to call the standard function instead.</span></div>
<div class="line"><span class="lineno">  206</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral">    It is not that ``n`` should be large for the LOBPCG to work, but rather the</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">    ratio ``n / k`` should be large. It you call LOBPCG with ``k=1``</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">    and ``n=10``, it works though ``n`` is small. The method is intended</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">    for extremely large ``n / k``.</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">    The convergence speed depends basically on two factors:</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">    1. Relative separation of the seeking eigenvalues from the rest</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">       of the eigenvalues. One can vary ``k`` to improve the absolute</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">       separation and use proper preconditioning to shrink the spectral spread.</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">       For example, a rod vibration test problem (under tests</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">       directory) is ill-conditioned for large ``n``, so convergence will be</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">       slow, unless efficient preconditioning is used. For this specific</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">       problem, a good simple preconditioner function would be a linear solve</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">       for `A`, which is easy to code since `A` is tridiagonal.</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">    2. Quality of the initial approximations `X` to the seeking eigenvectors.</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">       Randomly distributed around the origin vectors work well if no better</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">       choice is known.</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">    .. [1] A. V. Knyazev (2001),</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">           Toward the Optimal Preconditioned Eigensolver: Locally Optimal</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">           Block Preconditioned Conjugate Gradient Method.</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">           SIAM Journal on Scientific Computing 23, no. 2,</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">           pp. 517-541. :doi:`10.1137/S1064827500366124`</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">    .. [2] A. V. Knyazev, I. Lashuk, M. E. Argentati, and E. Ovchinnikov</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">           (2007), Block Locally Optimal Preconditioned Eigenvalue Xolvers</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">           (BLOPEX) in hypre and PETSc. :arxiv:`0705.2626`</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">    .. [3] A. V. Knyazev&#39;s C and MATLAB implementations:</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">           https://github.com/lobpcg/blopex</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">    Solve ``A x = lambda x`` with constraints and preconditioning.</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.sparse import spdiags, issparse</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.sparse.linalg import lobpcg, LinearOperator</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">    The square matrix size:</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">    &gt;&gt;&gt; n = 100</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">    &gt;&gt;&gt; vals = np.arange(1, n + 1)</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">    The first mandatory input parameter, in this test</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">    a sparse 2D array representing the square matrix</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">    of the eigenvalue problem to solve:</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">    &gt;&gt;&gt; A = spdiags(vals, 0, n, n)</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">    &gt;&gt;&gt; A.toarray()</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">    array([[  1.,   0.,   0., ...,   0.,   0.,   0.],</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">           [  0.,   2.,   0., ...,   0.,   0.,   0.],</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">           [  0.,   0.,   3., ...,   0.,   0.,   0.],</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">           ...,</span></div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">           [  0.,   0.,   0., ...,  98.,   0.,   0.],</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">           [  0.,   0.,   0., ...,   0.,  99.,   0.],</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">           [  0.,   0.,   0., ...,   0.,   0., 100.]])</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">    Initial guess for eigenvectors, should have linearly independent</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">    columns. The second mandatory input parameter, a 2D array with the</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral">    row dimension determining the number of requested eigenvalues.</span></div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">    If no initial approximations available, randomly oriented vectors</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral">    commonly work best, e.g., with components normally disrtibuted</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">    around zero or uniformly distributed on the interval [-1 1].</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral">    &gt;&gt;&gt; rng = np.random.default_rng()</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">    &gt;&gt;&gt; X = rng.normal(size=(n, 3))</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">    Constraints - an optional input parameter is a 2D array comprising</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    of column vectors that the eigenvectors must be orthogonal to:</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">    &gt;&gt;&gt; Y = np.eye(n, 3)</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">    Preconditioner in the inverse of A in this example:</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">    &gt;&gt;&gt; invA = spdiags([1./vals], 0, n, n)</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">    The preconditiner must be defined by a function:</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">    &gt;&gt;&gt; def precond( x ):</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">    ...     return invA @ x</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">    The argument x of the preconditioner function is a matrix inside `lobpcg`,</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral">    thus the use of matrix-matrix product ``@``.</span></div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">    The preconditioner function is passed to lobpcg as a `LinearOperator`:</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">    &gt;&gt;&gt; M = LinearOperator(matvec=precond, matmat=precond,</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">    ...                    shape=(n, n), dtype=np.float64)</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">    Let us now solve the eigenvalue problem for the matrix A:</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">    &gt;&gt;&gt; eigenvalues, _ = lobpcg(A, X, Y=Y, M=M, largest=False)</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    &gt;&gt;&gt; eigenvalues</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    array([4., 5., 6.])</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">    Note that the vectors passed in Y are the eigenvectors of the 3 smallest</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">    eigenvalues. The results returned are orthogonal to those.</span></div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  312</span>    blockVectorX = X</div>
<div class="line"><span class="lineno">  313</span>    blockVectorY = Y</div>
<div class="line"><span class="lineno">  314</span>    residualTolerance = tol</div>
<div class="line"><span class="lineno">  315</span>    <span class="keywordflow">if</span> maxiter <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  316</span>        maxiter = 20</div>
<div class="line"><span class="lineno">  317</span> </div>
<div class="line"><span class="lineno">  318</span>    <span class="keywordflow">if</span> blockVectorY <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  319</span>        sizeY = blockVectorY.shape[1]</div>
<div class="line"><span class="lineno">  320</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  321</span>        sizeY = 0</div>
<div class="line"><span class="lineno">  322</span> </div>
<div class="line"><span class="lineno">  323</span>    <span class="comment"># Block size.</span></div>
<div class="line"><span class="lineno">  324</span>    <span class="keywordflow">if</span> len(blockVectorX.shape) != 2:</div>
<div class="line"><span class="lineno">  325</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;expected rank-2 array for argument X&quot;</span>)</div>
<div class="line"><span class="lineno">  326</span> </div>
<div class="line"><span class="lineno">  327</span>    n, sizeX = blockVectorX.shape</div>
<div class="line"><span class="lineno">  328</span> </div>
<div class="line"><span class="lineno">  329</span>    <span class="keywordflow">if</span> verbosityLevel:</div>
<div class="line"><span class="lineno">  330</span>        aux = <span class="stringliteral">&quot;Solving &quot;</span></div>
<div class="line"><span class="lineno">  331</span>        <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  332</span>            aux += <span class="stringliteral">&quot;standard&quot;</span></div>
<div class="line"><span class="lineno">  333</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  334</span>            aux += <span class="stringliteral">&quot;generalized&quot;</span></div>
<div class="line"><span class="lineno">  335</span>        aux += <span class="stringliteral">&quot; eigenvalue problem with&quot;</span></div>
<div class="line"><span class="lineno">  336</span>        <span class="keywordflow">if</span> M <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  337</span>            aux += <span class="stringliteral">&quot;out&quot;</span></div>
<div class="line"><span class="lineno">  338</span>        aux += <span class="stringliteral">&quot; preconditioning\n\n&quot;</span></div>
<div class="line"><span class="lineno">  339</span>        aux += <span class="stringliteral">&quot;matrix size %d\n&quot;</span> % n</div>
<div class="line"><span class="lineno">  340</span>        aux += <span class="stringliteral">&quot;block size %d\n\n&quot;</span> % sizeX</div>
<div class="line"><span class="lineno">  341</span>        <span class="keywordflow">if</span> blockVectorY <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  342</span>            aux += <span class="stringliteral">&quot;No constraints\n\n&quot;</span></div>
<div class="line"><span class="lineno">  343</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  344</span>            <span class="keywordflow">if</span> sizeY &gt; 1:</div>
<div class="line"><span class="lineno">  345</span>                aux += <span class="stringliteral">&quot;%d constraints\n\n&quot;</span> % sizeY</div>
<div class="line"><span class="lineno">  346</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  347</span>                aux += <span class="stringliteral">&quot;%d constraint\n\n&quot;</span> % sizeY</div>
<div class="line"><span class="lineno">  348</span>        print(aux)</div>
<div class="line"><span class="lineno">  349</span> </div>
<div class="line"><span class="lineno">  350</span>    <span class="keywordflow">if</span> (n - sizeY) &lt; (5 * sizeX):</div>
<div class="line"><span class="lineno">  351</span>        warnings.warn(</div>
<div class="line"><span class="lineno">  352</span>            f<span class="stringliteral">&quot;The problem size {n} minus the constraints size {sizeY} &quot;</span></div>
<div class="line"><span class="lineno">  353</span>            f<span class="stringliteral">&quot;is too small relative to the block size {sizeX}. &quot;</span></div>
<div class="line"><span class="lineno">  354</span>            f<span class="stringliteral">&quot;Using a dense eigensolver instead of LOBPCG.&quot;</span>,</div>
<div class="line"><span class="lineno">  355</span>            UserWarning, stacklevel=2</div>
<div class="line"><span class="lineno">  356</span>        )</div>
<div class="line"><span class="lineno">  357</span> </div>
<div class="line"><span class="lineno">  358</span>        sizeX = min(sizeX, n)</div>
<div class="line"><span class="lineno">  359</span> </div>
<div class="line"><span class="lineno">  360</span>        <span class="keywordflow">if</span> blockVectorY <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  361</span>            <span class="keywordflow">raise</span> NotImplementedError(</div>
<div class="line"><span class="lineno">  362</span>                <span class="stringliteral">&quot;The dense eigensolver does not support constraints.&quot;</span></div>
<div class="line"><span class="lineno">  363</span>            )</div>
<div class="line"><span class="lineno">  364</span> </div>
<div class="line"><span class="lineno">  365</span>        <span class="comment"># Define the closed range of indices of eigenvalues to return.</span></div>
<div class="line"><span class="lineno">  366</span>        <span class="keywordflow">if</span> largest:</div>
<div class="line"><span class="lineno">  367</span>            eigvals = (n - sizeX, n - 1)</div>
<div class="line"><span class="lineno">  368</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  369</span>            eigvals = (0, sizeX - 1)</div>
<div class="line"><span class="lineno">  370</span> </div>
<div class="line"><span class="lineno">  371</span>        <span class="keywordflow">if</span> isinstance(A, LinearOperator):</div>
<div class="line"><span class="lineno">  372</span>            A = A(np.eye(n, dtype=A.dtype))</div>
<div class="line"><span class="lineno">  373</span>        <span class="keywordflow">elif</span> isspmatrix(A):</div>
<div class="line"><span class="lineno">  374</span>            A = A.toarray()</div>
<div class="line"><span class="lineno">  375</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  376</span>            A = np.asarray(A)</div>
<div class="line"><span class="lineno">  377</span> </div>
<div class="line"><span class="lineno">  378</span>        <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  379</span>            <span class="keywordflow">if</span> isinstance(B, LinearOperator):</div>
<div class="line"><span class="lineno">  380</span>                B = B(np.eye(n, dtype=B.dtype))</div>
<div class="line"><span class="lineno">  381</span>            <span class="keywordflow">elif</span> isspmatrix(B):</div>
<div class="line"><span class="lineno">  382</span>                B = B.toarray()</div>
<div class="line"><span class="lineno">  383</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  384</span>                B = np.asarray(B)</div>
<div class="line"><span class="lineno">  385</span> </div>
<div class="line"><span class="lineno">  386</span>        vals, vecs = eigh(A,</div>
<div class="line"><span class="lineno">  387</span>                          B,</div>
<div class="line"><span class="lineno">  388</span>                          eigvals=eigvals,</div>
<div class="line"><span class="lineno">  389</span>                          check_finite=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  390</span>        <span class="keywordflow">if</span> largest:</div>
<div class="line"><span class="lineno">  391</span>            <span class="comment"># Reverse order to be compatible with eigs() in &#39;LM&#39; mode.</span></div>
<div class="line"><span class="lineno">  392</span>            vals = vals[::-1]</div>
<div class="line"><span class="lineno">  393</span>            vecs = vecs[:, ::-1]</div>
<div class="line"><span class="lineno">  394</span> </div>
<div class="line"><span class="lineno">  395</span>        <span class="keywordflow">return</span> vals, vecs</div>
<div class="line"><span class="lineno">  396</span> </div>
<div class="line"><span class="lineno">  397</span>    <span class="keywordflow">if</span> (residualTolerance <span class="keywordflow">is</span> <span class="keywordtype">None</span>) <span class="keywordflow">or</span> (residualTolerance &lt;= 0.0):</div>
<div class="line"><span class="lineno">  398</span>        residualTolerance = np.sqrt(1e-15) * n</div>
<div class="line"><span class="lineno">  399</span> </div>
<div class="line"><span class="lineno">  400</span>    A = _makeOperator(A, (n, n))</div>
<div class="line"><span class="lineno">  401</span>    B = _makeOperator(B, (n, n))</div>
<div class="line"><span class="lineno">  402</span>    M = _makeOperator(M, (n, n))</div>
<div class="line"><span class="lineno">  403</span> </div>
<div class="line"><span class="lineno">  404</span>    <span class="comment"># Apply constraints to X.</span></div>
<div class="line"><span class="lineno">  405</span>    <span class="keywordflow">if</span> blockVectorY <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  406</span> </div>
<div class="line"><span class="lineno">  407</span>        <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  408</span>            blockVectorBY = B(blockVectorY)</div>
<div class="line"><span class="lineno">  409</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  410</span>            blockVectorBY = blockVectorY</div>
<div class="line"><span class="lineno">  411</span> </div>
<div class="line"><span class="lineno">  412</span>        <span class="comment"># gramYBY is a dense array.</span></div>
<div class="line"><span class="lineno">  413</span>        gramYBY = np.dot(blockVectorY.T.conj(), blockVectorBY)</div>
<div class="line"><span class="lineno">  414</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  415</span>            <span class="comment"># gramYBY is a Cholesky factor from now on...</span></div>
<div class="line"><span class="lineno">  416</span>            gramYBY = cho_factor(gramYBY)</div>
<div class="line"><span class="lineno">  417</span>        <span class="keywordflow">except</span> LinAlgError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  418</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Linearly dependent constraints&quot;</span>) <span class="keyword">from</span> e</div>
<div class="line"><span class="lineno">  419</span> </div>
<div class="line"><span class="lineno">  420</span>        _applyConstraints(blockVectorX, gramYBY, blockVectorBY, blockVectorY)</div>
<div class="line"><span class="lineno">  421</span> </div>
<div class="line"><span class="lineno">  422</span>    </div>
<div class="line"><span class="lineno">  424</span>    blockVectorX, blockVectorBX = _b_orthonormalize(B, blockVectorX)</div>
<div class="line"><span class="lineno">  425</span>    <span class="keywordflow">if</span> blockVectorX <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  426</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Linearly dependent initial approximations&quot;</span>)</div>
<div class="line"><span class="lineno">  427</span> </div>
<div class="line"><span class="lineno">  428</span>    </div>
<div class="line"><span class="lineno">  430</span>    blockVectorAX = A(blockVectorX)</div>
<div class="line"><span class="lineno">  431</span>    gramXAX = np.dot(blockVectorX.T.conj(), blockVectorAX)</div>
<div class="line"><span class="lineno">  432</span> </div>
<div class="line"><span class="lineno">  433</span>    _lambda, eigBlockVector = eigh(gramXAX, check_finite=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  434</span>    ii = _get_indx(_lambda, sizeX, largest)</div>
<div class="line"><span class="lineno">  435</span>    _lambda = _lambda[ii]</div>
<div class="line"><span class="lineno">  436</span> </div>
<div class="line"><span class="lineno">  437</span>    eigBlockVector = np.asarray(eigBlockVector[:, ii])</div>
<div class="line"><span class="lineno">  438</span>    blockVectorX = np.dot(blockVectorX, eigBlockVector)</div>
<div class="line"><span class="lineno">  439</span>    blockVectorAX = np.dot(blockVectorAX, eigBlockVector)</div>
<div class="line"><span class="lineno">  440</span>    <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  441</span>        blockVectorBX = np.dot(blockVectorBX, eigBlockVector)</div>
<div class="line"><span class="lineno">  442</span> </div>
<div class="line"><span class="lineno">  443</span>    </div>
<div class="line"><span class="lineno">  445</span>    activeMask = np.ones((sizeX,), dtype=bool)</div>
<div class="line"><span class="lineno">  446</span> </div>
<div class="line"><span class="lineno">  447</span>    lambdaHistory = [_lambda]</div>
<div class="line"><span class="lineno">  448</span>    residualNormsHistory = []</div>
<div class="line"><span class="lineno">  449</span> </div>
<div class="line"><span class="lineno">  450</span>    previousBlockSize = sizeX</div>
<div class="line"><span class="lineno">  451</span>    ident = np.eye(sizeX, dtype=A.dtype)</div>
<div class="line"><span class="lineno">  452</span>    ident0 = np.eye(sizeX, dtype=A.dtype)</div>
<div class="line"><span class="lineno">  453</span> </div>
<div class="line"><span class="lineno">  454</span>    </div>
<div class="line"><span class="lineno">  456</span> </div>
<div class="line"><span class="lineno">  457</span>    blockVectorP = <span class="keywordtype">None</span>  <span class="comment"># set during iteration</span></div>
<div class="line"><span class="lineno">  458</span>    blockVectorAP = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  459</span>    blockVectorBP = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  460</span> </div>
<div class="line"><span class="lineno">  461</span>    iterationNumber = -1</div>
<div class="line"><span class="lineno">  462</span>    restart = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  463</span>    explicitGramFlag = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  464</span>    <span class="keywordflow">while</span> iterationNumber &lt; maxiter:</div>
<div class="line"><span class="lineno">  465</span>        iterationNumber += 1</div>
<div class="line"><span class="lineno">  466</span>        <span class="keywordflow">if</span> verbosityLevel &gt; 0:</div>
<div class="line"><span class="lineno">  467</span>            print(<span class="stringliteral">&quot;-&quot;</span>*50)</div>
<div class="line"><span class="lineno">  468</span>            print(f<span class="stringliteral">&quot;iteration {iterationNumber}&quot;</span>)</div>
<div class="line"><span class="lineno">  469</span> </div>
<div class="line"><span class="lineno">  470</span>        <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  471</span>            aux = blockVectorBX * _lambda[np.newaxis, :]</div>
<div class="line"><span class="lineno">  472</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  473</span>            aux = blockVectorX * _lambda[np.newaxis, :]</div>
<div class="line"><span class="lineno">  474</span> </div>
<div class="line"><span class="lineno">  475</span>        blockVectorR = blockVectorAX - aux</div>
<div class="line"><span class="lineno">  476</span> </div>
<div class="line"><span class="lineno">  477</span>        aux = np.sum(blockVectorR.conj() * blockVectorR, 0)</div>
<div class="line"><span class="lineno">  478</span>        residualNorms = np.sqrt(aux)</div>
<div class="line"><span class="lineno">  479</span> </div>
<div class="line"><span class="lineno">  480</span>        residualNormsHistory.append(residualNorms)</div>
<div class="line"><span class="lineno">  481</span> </div>
<div class="line"><span class="lineno">  482</span>        ii = np.where(residualNorms &gt; residualTolerance, <span class="keyword">True</span>, <span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  483</span>        activeMask = activeMask &amp; ii</div>
<div class="line"><span class="lineno">  484</span>        <span class="keywordflow">if</span> verbosityLevel &gt; 2:</div>
<div class="line"><span class="lineno">  485</span>            print(activeMask)</div>
<div class="line"><span class="lineno">  486</span> </div>
<div class="line"><span class="lineno">  487</span>        currentBlockSize = activeMask.sum()</div>
<div class="line"><span class="lineno">  488</span>        <span class="keywordflow">if</span> currentBlockSize != previousBlockSize:</div>
<div class="line"><span class="lineno">  489</span>            previousBlockSize = currentBlockSize</div>
<div class="line"><span class="lineno">  490</span>            ident = np.eye(currentBlockSize, dtype=A.dtype)</div>
<div class="line"><span class="lineno">  491</span> </div>
<div class="line"><span class="lineno">  492</span>        <span class="keywordflow">if</span> currentBlockSize == 0:</div>
<div class="line"><span class="lineno">  493</span>            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  494</span> </div>
<div class="line"><span class="lineno">  495</span>        <span class="keywordflow">if</span> verbosityLevel &gt; 0:</div>
<div class="line"><span class="lineno">  496</span>            print(f<span class="stringliteral">&quot;current block size: {currentBlockSize}&quot;</span>)</div>
<div class="line"><span class="lineno">  497</span>            print(f<span class="stringliteral">&quot;eigenvalue(s):\n{_lambda}&quot;</span>)</div>
<div class="line"><span class="lineno">  498</span>            print(f<span class="stringliteral">&quot;residual norm(s):\n{residualNorms}&quot;</span>)</div>
<div class="line"><span class="lineno">  499</span>        <span class="keywordflow">if</span> verbosityLevel &gt; 10:</div>
<div class="line"><span class="lineno">  500</span>            print(eigBlockVector)</div>
<div class="line"><span class="lineno">  501</span> </div>
<div class="line"><span class="lineno">  502</span>        activeBlockVectorR = _as2d(blockVectorR[:, activeMask])</div>
<div class="line"><span class="lineno">  503</span> </div>
<div class="line"><span class="lineno">  504</span>        <span class="keywordflow">if</span> iterationNumber &gt; 0:</div>
<div class="line"><span class="lineno">  505</span>            activeBlockVectorP = _as2d(blockVectorP[:, activeMask])</div>
<div class="line"><span class="lineno">  506</span>            activeBlockVectorAP = _as2d(blockVectorAP[:, activeMask])</div>
<div class="line"><span class="lineno">  507</span>            <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  508</span>                activeBlockVectorBP = _as2d(blockVectorBP[:, activeMask])</div>
<div class="line"><span class="lineno">  509</span> </div>
<div class="line"><span class="lineno">  510</span>        <span class="keywordflow">if</span> M <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  511</span>            <span class="comment"># Apply preconditioner T to the active residuals.</span></div>
<div class="line"><span class="lineno">  512</span>            activeBlockVectorR = M(activeBlockVectorR)</div>
<div class="line"><span class="lineno">  513</span> </div>
<div class="line"><span class="lineno">  514</span>        </div>
<div class="line"><span class="lineno">  516</span>        <span class="keywordflow">if</span> blockVectorY <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  517</span>            _applyConstraints(activeBlockVectorR,</div>
<div class="line"><span class="lineno">  518</span>                              gramYBY,</div>
<div class="line"><span class="lineno">  519</span>                              blockVectorBY,</div>
<div class="line"><span class="lineno">  520</span>                              blockVectorY)</div>
<div class="line"><span class="lineno">  521</span> </div>
<div class="line"><span class="lineno">  522</span>        </div>
<div class="line"><span class="lineno">  524</span>        <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  525</span>            activeBlockVectorR = activeBlockVectorR - (</div>
<div class="line"><span class="lineno">  526</span>                blockVectorX @</div>
<div class="line"><span class="lineno">  527</span>                (blockVectorBX.T.conj() @ activeBlockVectorR)</div>
<div class="line"><span class="lineno">  528</span>            )</div>
<div class="line"><span class="lineno">  529</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  530</span>            activeBlockVectorR = activeBlockVectorR - (</div>
<div class="line"><span class="lineno">  531</span>                blockVectorX @</div>
<div class="line"><span class="lineno">  532</span>                (blockVectorX.T.conj() @ activeBlockVectorR)</div>
<div class="line"><span class="lineno">  533</span>            )</div>
<div class="line"><span class="lineno">  534</span> </div>
<div class="line"><span class="lineno">  535</span>        </div>
<div class="line"><span class="lineno">  537</span>        aux = _b_orthonormalize(B, activeBlockVectorR)</div>
<div class="line"><span class="lineno">  538</span>        activeBlockVectorR, activeBlockVectorBR = aux</div>
<div class="line"><span class="lineno">  539</span> </div>
<div class="line"><span class="lineno">  540</span>        <span class="keywordflow">if</span> activeBlockVectorR <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  541</span>            warnings.warn(</div>
<div class="line"><span class="lineno">  542</span>                f<span class="stringliteral">&quot;Failed at iteration {iterationNumber} with accuracies &quot;</span></div>
<div class="line"><span class="lineno">  543</span>                f<span class="stringliteral">&quot;{residualNorms}\n not reaching the requested &quot;</span></div>
<div class="line"><span class="lineno">  544</span>                f<span class="stringliteral">&quot;tolerance {residualTolerance}.&quot;</span>,</div>
<div class="line"><span class="lineno">  545</span>                UserWarning, stacklevel=2</div>
<div class="line"><span class="lineno">  546</span>            )</div>
<div class="line"><span class="lineno">  547</span>            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  548</span>        activeBlockVectorAR = A(activeBlockVectorR)</div>
<div class="line"><span class="lineno">  549</span> </div>
<div class="line"><span class="lineno">  550</span>        <span class="keywordflow">if</span> iterationNumber &gt; 0:</div>
<div class="line"><span class="lineno">  551</span>            <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  552</span>                aux = _b_orthonormalize(</div>
<div class="line"><span class="lineno">  553</span>                    B, activeBlockVectorP, activeBlockVectorBP, retInvR=<span class="keyword">True</span></div>
<div class="line"><span class="lineno">  554</span>                )</div>
<div class="line"><span class="lineno">  555</span>                activeBlockVectorP, activeBlockVectorBP, invR, normal = aux</div>
<div class="line"><span class="lineno">  556</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  557</span>                aux = _b_orthonormalize(B, activeBlockVectorP, retInvR=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  558</span>                activeBlockVectorP, _, invR, normal = aux</div>
<div class="line"><span class="lineno">  559</span>            <span class="comment"># Function _b_orthonormalize returns None if Cholesky fails</span></div>
<div class="line"><span class="lineno">  560</span>            <span class="keywordflow">if</span> activeBlockVectorP <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  561</span>                activeBlockVectorAP = activeBlockVectorAP / normal</div>
<div class="line"><span class="lineno">  562</span>                activeBlockVectorAP = np.dot(activeBlockVectorAP, invR)</div>
<div class="line"><span class="lineno">  563</span>                restart = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  564</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  565</span>                restart = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  566</span> </div>
<div class="line"><span class="lineno">  567</span>        </div>
<div class="line"><span class="lineno">  570</span> </div>
<div class="line"><span class="lineno">  571</span>        <span class="keywordflow">if</span> activeBlockVectorAR.dtype == <span class="stringliteral">&quot;float32&quot;</span>:</div>
<div class="line"><span class="lineno">  572</span>            myeps = 1</div>
<div class="line"><span class="lineno">  573</span>        <span class="keywordflow">elif</span> activeBlockVectorR.dtype == <span class="stringliteral">&quot;float32&quot;</span>:</div>
<div class="line"><span class="lineno">  574</span>            myeps = 1e-4</div>
<div class="line"><span class="lineno">  575</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  576</span>            myeps = 1e-8</div>
<div class="line"><span class="lineno">  577</span> </div>
<div class="line"><span class="lineno">  578</span>        <span class="keywordflow">if</span> residualNorms.max() &gt; myeps <span class="keywordflow">and</span> <span class="keywordflow">not</span> explicitGramFlag:</div>
<div class="line"><span class="lineno">  579</span>            explicitGramFlag = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  580</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  581</span>            <span class="comment"># Once explicitGramFlag, forever explicitGramFlag.</span></div>
<div class="line"><span class="lineno">  582</span>            explicitGramFlag = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  583</span> </div>
<div class="line"><span class="lineno">  584</span>        <span class="comment"># Shared memory assingments to simplify the code</span></div>
<div class="line"><span class="lineno">  585</span>        <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  586</span>            blockVectorBX = blockVectorX</div>
<div class="line"><span class="lineno">  587</span>            activeBlockVectorBR = activeBlockVectorR</div>
<div class="line"><span class="lineno">  588</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> restart:</div>
<div class="line"><span class="lineno">  589</span>                activeBlockVectorBP = activeBlockVectorP</div>
<div class="line"><span class="lineno">  590</span> </div>
<div class="line"><span class="lineno">  591</span>        <span class="comment"># Common submatrices:</span></div>
<div class="line"><span class="lineno">  592</span>        gramXAR = np.dot(blockVectorX.T.conj(), activeBlockVectorAR)</div>
<div class="line"><span class="lineno">  593</span>        gramRAR = np.dot(activeBlockVectorR.T.conj(), activeBlockVectorAR)</div>
<div class="line"><span class="lineno">  594</span> </div>
<div class="line"><span class="lineno">  595</span>        <span class="keywordflow">if</span> explicitGramFlag:</div>
<div class="line"><span class="lineno">  596</span>            gramRAR = (gramRAR + gramRAR.T.conj()) / 2</div>
<div class="line"><span class="lineno">  597</span>            gramXAX = np.dot(blockVectorX.T.conj(), blockVectorAX)</div>
<div class="line"><span class="lineno">  598</span>            gramXAX = (gramXAX + gramXAX.T.conj()) / 2</div>
<div class="line"><span class="lineno">  599</span>            gramXBX = np.dot(blockVectorX.T.conj(), blockVectorBX)</div>
<div class="line"><span class="lineno">  600</span>            gramRBR = np.dot(activeBlockVectorR.T.conj(), activeBlockVectorBR)</div>
<div class="line"><span class="lineno">  601</span>            gramXBR = np.dot(blockVectorX.T.conj(), activeBlockVectorBR)</div>
<div class="line"><span class="lineno">  602</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  603</span>            gramXAX = np.diag(_lambda)</div>
<div class="line"><span class="lineno">  604</span>            gramXBX = ident0</div>
<div class="line"><span class="lineno">  605</span>            gramRBR = ident</div>
<div class="line"><span class="lineno">  606</span>            gramXBR = np.zeros((sizeX, currentBlockSize), dtype=A.dtype)</div>
<div class="line"><span class="lineno">  607</span> </div>
<div class="line"><span class="lineno">  608</span>        <span class="keyword">def </span>_handle_gramA_gramB_verbosity(gramA, gramB):</div>
<div class="line"><span class="lineno">  609</span>            <span class="keywordflow">if</span> verbosityLevel &gt; 0:</div>
<div class="line"><span class="lineno">  610</span>                _report_nonhermitian(gramA, <span class="stringliteral">&quot;gramA&quot;</span>)</div>
<div class="line"><span class="lineno">  611</span>                _report_nonhermitian(gramB, <span class="stringliteral">&quot;gramB&quot;</span>)</div>
<div class="line"><span class="lineno">  612</span>            <span class="keywordflow">if</span> verbosityLevel &gt; 10:</div>
<div class="line"><span class="lineno">  613</span>                <span class="comment"># Note: not documented, but leave it in here for now</span></div>
<div class="line"><span class="lineno">  614</span>                np.savetxt(<span class="stringliteral">&quot;gramA.txt&quot;</span>, gramA)</div>
<div class="line"><span class="lineno">  615</span>                np.savetxt(<span class="stringliteral">&quot;gramB.txt&quot;</span>, gramB)</div>
<div class="line"><span class="lineno">  616</span> </div>
<div class="line"><span class="lineno">  617</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> restart:</div>
<div class="line"><span class="lineno">  618</span>            gramXAP = np.dot(blockVectorX.T.conj(), activeBlockVectorAP)</div>
<div class="line"><span class="lineno">  619</span>            gramRAP = np.dot(activeBlockVectorR.T.conj(), activeBlockVectorAP)</div>
<div class="line"><span class="lineno">  620</span>            gramPAP = np.dot(activeBlockVectorP.T.conj(), activeBlockVectorAP)</div>
<div class="line"><span class="lineno">  621</span>            gramXBP = np.dot(blockVectorX.T.conj(), activeBlockVectorBP)</div>
<div class="line"><span class="lineno">  622</span>            gramRBP = np.dot(activeBlockVectorR.T.conj(), activeBlockVectorBP)</div>
<div class="line"><span class="lineno">  623</span>            <span class="keywordflow">if</span> explicitGramFlag:</div>
<div class="line"><span class="lineno">  624</span>                gramPAP = (gramPAP + gramPAP.T.conj()) / 2</div>
<div class="line"><span class="lineno">  625</span>                gramPBP = np.dot(activeBlockVectorP.T.conj(),</div>
<div class="line"><span class="lineno">  626</span>                                 activeBlockVectorBP)</div>
<div class="line"><span class="lineno">  627</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  628</span>                gramPBP = ident</div>
<div class="line"><span class="lineno">  629</span> </div>
<div class="line"><span class="lineno">  630</span>            gramA = bmat(</div>
<div class="line"><span class="lineno">  631</span>                [</div>
<div class="line"><span class="lineno">  632</span>                    [gramXAX, gramXAR, gramXAP],</div>
<div class="line"><span class="lineno">  633</span>                    [gramXAR.T.conj(), gramRAR, gramRAP],</div>
<div class="line"><span class="lineno">  634</span>                    [gramXAP.T.conj(), gramRAP.T.conj(), gramPAP],</div>
<div class="line"><span class="lineno">  635</span>                ]</div>
<div class="line"><span class="lineno">  636</span>            )</div>
<div class="line"><span class="lineno">  637</span>            gramB = bmat(</div>
<div class="line"><span class="lineno">  638</span>                [</div>
<div class="line"><span class="lineno">  639</span>                    [gramXBX, gramXBR, gramXBP],</div>
<div class="line"><span class="lineno">  640</span>                    [gramXBR.T.conj(), gramRBR, gramRBP],</div>
<div class="line"><span class="lineno">  641</span>                    [gramXBP.T.conj(), gramRBP.T.conj(), gramPBP],</div>
<div class="line"><span class="lineno">  642</span>                ]</div>
<div class="line"><span class="lineno">  643</span>            )</div>
<div class="line"><span class="lineno">  644</span> </div>
<div class="line"><span class="lineno">  645</span>            _handle_gramA_gramB_verbosity(gramA, gramB)</div>
<div class="line"><span class="lineno">  646</span> </div>
<div class="line"><span class="lineno">  647</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  648</span>                _lambda, eigBlockVector = eigh(gramA,</div>
<div class="line"><span class="lineno">  649</span>                                               gramB,</div>
<div class="line"><span class="lineno">  650</span>                                               check_finite=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  651</span>            <span class="keywordflow">except</span> LinAlgError:</div>
<div class="line"><span class="lineno">  652</span>                <span class="comment"># try again after dropping the direction vectors P from RR</span></div>
<div class="line"><span class="lineno">  653</span>                restart = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  654</span> </div>
<div class="line"><span class="lineno">  655</span>        <span class="keywordflow">if</span> restart:</div>
<div class="line"><span class="lineno">  656</span>            gramA = bmat([[gramXAX, gramXAR], [gramXAR.T.conj(), gramRAR]])</div>
<div class="line"><span class="lineno">  657</span>            gramB = bmat([[gramXBX, gramXBR], [gramXBR.T.conj(), gramRBR]])</div>
<div class="line"><span class="lineno">  658</span> </div>
<div class="line"><span class="lineno">  659</span>            _handle_gramA_gramB_verbosity(gramA, gramB)</div>
<div class="line"><span class="lineno">  660</span> </div>
<div class="line"><span class="lineno">  661</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  662</span>                _lambda, eigBlockVector = eigh(gramA,</div>
<div class="line"><span class="lineno">  663</span>                                               gramB,</div>
<div class="line"><span class="lineno">  664</span>                                               check_finite=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  665</span>            <span class="keywordflow">except</span> LinAlgError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  666</span>                <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;eigh has failed in lobpcg iterations&quot;</span>) <span class="keyword">from</span> e</div>
<div class="line"><span class="lineno">  667</span> </div>
<div class="line"><span class="lineno">  668</span>        ii = _get_indx(_lambda, sizeX, largest)</div>
<div class="line"><span class="lineno">  669</span>        <span class="keywordflow">if</span> verbosityLevel &gt; 10:</div>
<div class="line"><span class="lineno">  670</span>            print(ii)</div>
<div class="line"><span class="lineno">  671</span>            print(f<span class="stringliteral">&quot;lambda:\n{_lambda}&quot;</span>)</div>
<div class="line"><span class="lineno">  672</span> </div>
<div class="line"><span class="lineno">  673</span>        _lambda = _lambda[ii]</div>
<div class="line"><span class="lineno">  674</span>        eigBlockVector = eigBlockVector[:, ii]</div>
<div class="line"><span class="lineno">  675</span> </div>
<div class="line"><span class="lineno">  676</span>        lambdaHistory.append(_lambda)</div>
<div class="line"><span class="lineno">  677</span> </div>
<div class="line"><span class="lineno">  678</span>        <span class="keywordflow">if</span> verbosityLevel &gt; 10:</div>
<div class="line"><span class="lineno">  679</span>            print(f<span class="stringliteral">&quot;lambda:\n{_lambda}&quot;</span>)</div>
<div class="line"><span class="lineno">  680</span>        <span class="comment">#         # Normalize eigenvectors!</span></div>
<div class="line"><span class="lineno">  681</span>        <span class="comment">#         aux = np.sum( eigBlockVector.conj() * eigBlockVector, 0 )</span></div>
<div class="line"><span class="lineno">  682</span>        <span class="comment">#         eigVecNorms = np.sqrt( aux )</span></div>
<div class="line"><span class="lineno">  683</span>        <span class="comment">#         eigBlockVector = eigBlockVector / eigVecNorms[np.newaxis, :]</span></div>
<div class="line"><span class="lineno">  684</span>        <span class="comment">#         eigBlockVector, aux = _b_orthonormalize( B, eigBlockVector )</span></div>
<div class="line"><span class="lineno">  685</span> </div>
<div class="line"><span class="lineno">  686</span>        <span class="keywordflow">if</span> verbosityLevel &gt; 10:</div>
<div class="line"><span class="lineno">  687</span>            print(eigBlockVector)</div>
<div class="line"><span class="lineno">  688</span> </div>
<div class="line"><span class="lineno">  689</span>        <span class="comment"># Compute Ritz vectors.</span></div>
<div class="line"><span class="lineno">  690</span>        <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  691</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> restart:</div>
<div class="line"><span class="lineno">  692</span>                eigBlockVectorX = eigBlockVector[:sizeX]</div>
<div class="line"><span class="lineno">  693</span>                eigBlockVectorR = eigBlockVector[sizeX:</div>
<div class="line"><span class="lineno">  694</span>                                                 sizeX + currentBlockSize]</div>
<div class="line"><span class="lineno">  695</span>                eigBlockVectorP = eigBlockVector[sizeX + currentBlockSize:]</div>
<div class="line"><span class="lineno">  696</span> </div>
<div class="line"><span class="lineno">  697</span>                pp = np.dot(activeBlockVectorR, eigBlockVectorR)</div>
<div class="line"><span class="lineno">  698</span>                pp += np.dot(activeBlockVectorP, eigBlockVectorP)</div>
<div class="line"><span class="lineno">  699</span> </div>
<div class="line"><span class="lineno">  700</span>                app = np.dot(activeBlockVectorAR, eigBlockVectorR)</div>
<div class="line"><span class="lineno">  701</span>                app += np.dot(activeBlockVectorAP, eigBlockVectorP)</div>
<div class="line"><span class="lineno">  702</span> </div>
<div class="line"><span class="lineno">  703</span>                bpp = np.dot(activeBlockVectorBR, eigBlockVectorR)</div>
<div class="line"><span class="lineno">  704</span>                bpp += np.dot(activeBlockVectorBP, eigBlockVectorP)</div>
<div class="line"><span class="lineno">  705</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  706</span>                eigBlockVectorX = eigBlockVector[:sizeX]</div>
<div class="line"><span class="lineno">  707</span>                eigBlockVectorR = eigBlockVector[sizeX:]</div>
<div class="line"><span class="lineno">  708</span> </div>
<div class="line"><span class="lineno">  709</span>                pp = np.dot(activeBlockVectorR, eigBlockVectorR)</div>
<div class="line"><span class="lineno">  710</span>                app = np.dot(activeBlockVectorAR, eigBlockVectorR)</div>
<div class="line"><span class="lineno">  711</span>                bpp = np.dot(activeBlockVectorBR, eigBlockVectorR)</div>
<div class="line"><span class="lineno">  712</span> </div>
<div class="line"><span class="lineno">  713</span>            <span class="keywordflow">if</span> verbosityLevel &gt; 10:</div>
<div class="line"><span class="lineno">  714</span>                print(pp)</div>
<div class="line"><span class="lineno">  715</span>                print(app)</div>
<div class="line"><span class="lineno">  716</span>                print(bpp)</div>
<div class="line"><span class="lineno">  717</span> </div>
<div class="line"><span class="lineno">  718</span>            blockVectorX = np.dot(blockVectorX, eigBlockVectorX) + pp</div>
<div class="line"><span class="lineno">  719</span>            blockVectorAX = np.dot(blockVectorAX, eigBlockVectorX) + app</div>
<div class="line"><span class="lineno">  720</span>            blockVectorBX = np.dot(blockVectorBX, eigBlockVectorX) + bpp</div>
<div class="line"><span class="lineno">  721</span> </div>
<div class="line"><span class="lineno">  722</span>            blockVectorP, blockVectorAP, blockVectorBP = pp, app, bpp</div>
<div class="line"><span class="lineno">  723</span> </div>
<div class="line"><span class="lineno">  724</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  725</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> restart:</div>
<div class="line"><span class="lineno">  726</span>                eigBlockVectorX = eigBlockVector[:sizeX]</div>
<div class="line"><span class="lineno">  727</span>                eigBlockVectorR = eigBlockVector[sizeX:</div>
<div class="line"><span class="lineno">  728</span>                                                 sizeX + currentBlockSize]</div>
<div class="line"><span class="lineno">  729</span>                eigBlockVectorP = eigBlockVector[sizeX + currentBlockSize:]</div>
<div class="line"><span class="lineno">  730</span> </div>
<div class="line"><span class="lineno">  731</span>                pp = np.dot(activeBlockVectorR, eigBlockVectorR)</div>
<div class="line"><span class="lineno">  732</span>                pp += np.dot(activeBlockVectorP, eigBlockVectorP)</div>
<div class="line"><span class="lineno">  733</span> </div>
<div class="line"><span class="lineno">  734</span>                app = np.dot(activeBlockVectorAR, eigBlockVectorR)</div>
<div class="line"><span class="lineno">  735</span>                app += np.dot(activeBlockVectorAP, eigBlockVectorP)</div>
<div class="line"><span class="lineno">  736</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  737</span>                eigBlockVectorX = eigBlockVector[:sizeX]</div>
<div class="line"><span class="lineno">  738</span>                eigBlockVectorR = eigBlockVector[sizeX:]</div>
<div class="line"><span class="lineno">  739</span> </div>
<div class="line"><span class="lineno">  740</span>                pp = np.dot(activeBlockVectorR, eigBlockVectorR)</div>
<div class="line"><span class="lineno">  741</span>                app = np.dot(activeBlockVectorAR, eigBlockVectorR)</div>
<div class="line"><span class="lineno">  742</span> </div>
<div class="line"><span class="lineno">  743</span>            <span class="keywordflow">if</span> verbosityLevel &gt; 10:</div>
<div class="line"><span class="lineno">  744</span>                print(pp)</div>
<div class="line"><span class="lineno">  745</span>                print(app)</div>
<div class="line"><span class="lineno">  746</span> </div>
<div class="line"><span class="lineno">  747</span>            blockVectorX = np.dot(blockVectorX, eigBlockVectorX) + pp</div>
<div class="line"><span class="lineno">  748</span>            blockVectorAX = np.dot(blockVectorAX, eigBlockVectorX) + app</div>
<div class="line"><span class="lineno">  749</span> </div>
<div class="line"><span class="lineno">  750</span>            blockVectorP, blockVectorAP = pp, app</div>
<div class="line"><span class="lineno">  751</span> </div>
<div class="line"><span class="lineno">  752</span>    <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  753</span>        aux = blockVectorBX * _lambda[np.newaxis, :]</div>
<div class="line"><span class="lineno">  754</span> </div>
<div class="line"><span class="lineno">  755</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  756</span>        aux = blockVectorX * _lambda[np.newaxis, :]</div>
<div class="line"><span class="lineno">  757</span> </div>
<div class="line"><span class="lineno">  758</span>    blockVectorR = blockVectorAX - aux</div>
<div class="line"><span class="lineno">  759</span> </div>
<div class="line"><span class="lineno">  760</span>    aux = np.sum(blockVectorR.conj() * blockVectorR, 0)</div>
<div class="line"><span class="lineno">  761</span>    residualNorms = np.sqrt(aux)</div>
<div class="line"><span class="lineno">  762</span> </div>
<div class="line"><span class="lineno">  763</span>    <span class="keywordflow">if</span> np.max(residualNorms) &gt; residualTolerance:</div>
<div class="line"><span class="lineno">  764</span>        warnings.warn(</div>
<div class="line"><span class="lineno">  765</span>            f<span class="stringliteral">&quot;Exited at iteration {iterationNumber} with accuracies \n&quot;</span></div>
<div class="line"><span class="lineno">  766</span>            f<span class="stringliteral">&quot;{residualNorms}\n&quot;</span></div>
<div class="line"><span class="lineno">  767</span>            f<span class="stringliteral">&quot;not reaching the requested tolerance {residualTolerance}.&quot;</span>,</div>
<div class="line"><span class="lineno">  768</span>            UserWarning, stacklevel=2</div>
<div class="line"><span class="lineno">  769</span>        )</div>
<div class="line"><span class="lineno">  770</span> </div>
<div class="line"><span class="lineno">  771</span>    <span class="comment"># Future work: Need to add Postprocessing here:</span></div>
<div class="line"><span class="lineno">  772</span>    <span class="comment"># Making sure eigenvectors &quot;exactly&quot; satisfy the blockVectorY constrains?</span></div>
<div class="line"><span class="lineno">  773</span>    <span class="comment"># Making sure eigenvecotrs are &quot;exactly&quot; othonormalized by final &quot;exact&quot; RR</span></div>
<div class="line"><span class="lineno">  774</span>    <span class="comment"># Keeping the best iterates in case of divergence</span></div>
<div class="line"><span class="lineno">  775</span> </div>
<div class="line"><span class="lineno">  776</span>    <span class="keywordflow">if</span> verbosityLevel &gt; 0:</div>
<div class="line"><span class="lineno">  777</span>        print(f<span class="stringliteral">&quot;Final eigenvalue(s):\n{_lambda}&quot;</span>)</div>
<div class="line"><span class="lineno">  778</span>        print(f<span class="stringliteral">&quot;Final residual norm(s):\n{residualNorms}&quot;</span>)</div>
<div class="line"><span class="lineno">  779</span> </div>
<div class="line"><span class="lineno">  780</span>    <span class="keywordflow">if</span> retLambdaHistory:</div>
<div class="line"><span class="lineno">  781</span>        <span class="keywordflow">if</span> retResidualNormsHistory:</div>
<div class="line"><span class="lineno">  782</span>            <span class="keywordflow">return</span> _lambda, blockVectorX, lambdaHistory, residualNormsHistory</div>
<div class="line"><span class="lineno">  783</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  784</span>            <span class="keywordflow">return</span> _lambda, blockVectorX, lambdaHistory</div>
<div class="line"><span class="lineno">  785</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  786</span>        <span class="keywordflow">if</span> retResidualNormsHistory:</div>
<div class="line"><span class="lineno">  787</span>            <span class="keywordflow">return</span> _lambda, blockVectorX, residualNormsHistory</div>
<div class="line"><span class="lineno">  788</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  789</span>            <span class="keywordflow">return</span> _lambda, blockVectorX</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
