<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: gensim.models.deprecated.fasttext Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacegensim.html">gensim</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models.html">models</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1deprecated.html">deprecated</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1fasttext.html">fasttext</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">gensim.models.deprecated.fasttext Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext_1_1_fast_text.html">FastText</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a3a09e5af73506ececfcefdec46a62f73" id="r_a3a09e5af73506ececfcefdec46a62f73"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1fasttext.html#a3a09e5af73506ececfcefdec46a62f73">load_old_fasttext</a> (*args, **kwargs)</td></tr>
<tr class="separator:a3a09e5af73506ececfcefdec46a62f73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a954f5fac94acf84946d5dbce8a3339f6" id="r_a954f5fac94acf84946d5dbce8a3339f6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1fasttext.html#a954f5fac94acf84946d5dbce8a3339f6">train_batch_cbow</a> (model, sentences, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, <a class="el" href="__lapack__subroutines_8h.html#ad2e2a6e930388ddee2f5afb58c5bf8ad">work</a>=None, neu1=None)</td></tr>
<tr class="separator:a954f5fac94acf84946d5dbce8a3339f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25ecd467c26572027dfb292242f1b84f" id="r_a25ecd467c26572027dfb292242f1b84f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1fasttext.html#a25ecd467c26572027dfb292242f1b84f">train_batch_sg</a> (model, sentences, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, <a class="el" href="__lapack__subroutines_8h.html#ad2e2a6e930388ddee2f5afb58c5bf8ad">work</a>=None, neu1=None)</td></tr>
<tr class="separator:a25ecd467c26572027dfb292242f1b84f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a2d45dfe1d6f5696ffc387ba15fe6bccd" id="r_a2d45dfe1d6f5696ffc387ba15fe6bccd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1fasttext.html#a2d45dfe1d6f5696ffc387ba15fe6bccd">logger</a> = logging.getLogger(__name__)</td></tr>
<tr class="separator:a2d45dfe1d6f5696ffc387ba15fe6bccd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41cd5460df788b06985a2a007662afe5" id="r_a41cd5460df788b06985a2a007662afe5"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1fasttext.html#a41cd5460df788b06985a2a007662afe5">MAX_WORDS_IN_BATCH</a> = 10000</td></tr>
<tr class="separator:a41cd5460df788b06985a2a007662afe5"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Warnings
--------
.. deprecated:: 3.3.0
   Use :mod:`gensim.models.fasttext` instead.


Learn word representations via fasttext's "skip-gram and CBOW models", using either
hierarchical softmax or negative sampling [1]_.

Notes
-----
There are more ways to get word vectors in Gensim than just FastText.
See wrappers for VarEmbed and WordRank or Word2Vec

This module allows training a word embedding from a training corpus with the additional ability
to obtain word vectors for out-of-vocabulary words.

For a tutorial on gensim's native fasttext, refer to the noteboook -- [2]_

**Make sure you have a C compiler before installing gensim, to use optimized (compiled) fasttext training**

.. [1] P. Bojanowski, E. Grave, A. Joulin, T. Mikolov
       Enriching Word Vectors with Subword Information. In arXiv preprint arXiv:1607.04606.
       https://arxiv.org/abs/1607.04606

.. [2] https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a3a09e5af73506ececfcefdec46a62f73" name="a3a09e5af73506ececfcefdec46a62f73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3a09e5af73506ececfcefdec46a62f73">&#9670;&#160;</a></span>load_old_fasttext()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.fasttext.load_old_fasttext </td>
          <td>(</td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   51</span><span class="keyword">def </span>load_old_fasttext(*args, **kwargs):</div>
<div class="line"><span class="lineno">   52</span>    old_model = FastText.load(*args, **kwargs)</div>
<div class="line"><span class="lineno">   53</span>    params = {</div>
<div class="line"><span class="lineno">   54</span>        <span class="stringliteral">&#39;size&#39;</span>: old_model.vector_size,</div>
<div class="line"><span class="lineno">   55</span>        <span class="stringliteral">&#39;alpha&#39;</span>: old_model.alpha,</div>
<div class="line"><span class="lineno">   56</span>        <span class="stringliteral">&#39;window&#39;</span>: old_model.window,</div>
<div class="line"><span class="lineno">   57</span>        <span class="stringliteral">&#39;min_count&#39;</span>: old_model.min_count,</div>
<div class="line"><span class="lineno">   58</span>        <span class="stringliteral">&#39;max_vocab_size&#39;</span>: old_model.__dict__.get(<span class="stringliteral">&#39;max_vocab_size&#39;</span>, <span class="keywordtype">None</span>),</div>
<div class="line"><span class="lineno">   59</span>        <span class="stringliteral">&#39;sample&#39;</span>: old_model.sample,</div>
<div class="line"><span class="lineno">   60</span>        <span class="stringliteral">&#39;seed&#39;</span>: old_model.seed,</div>
<div class="line"><span class="lineno">   61</span>        <span class="stringliteral">&#39;workers&#39;</span>: old_model.workers,</div>
<div class="line"><span class="lineno">   62</span>        <span class="stringliteral">&#39;min_alpha&#39;</span>: old_model.min_alpha,</div>
<div class="line"><span class="lineno">   63</span>        <span class="stringliteral">&#39;sg&#39;</span>: old_model.sg,</div>
<div class="line"><span class="lineno">   64</span>        <span class="stringliteral">&#39;hs&#39;</span>: old_model.hs,</div>
<div class="line"><span class="lineno">   65</span>        <span class="stringliteral">&#39;negative&#39;</span>: old_model.negative,</div>
<div class="line"><span class="lineno">   66</span>        <span class="stringliteral">&#39;cbow_mean&#39;</span>: old_model.cbow_mean,</div>
<div class="line"><span class="lineno">   67</span>        <span class="stringliteral">&#39;hashfxn&#39;</span>: old_model.hashfxn,</div>
<div class="line"><span class="lineno">   68</span>        <span class="stringliteral">&#39;iter&#39;</span>: old_model.iter,</div>
<div class="line"><span class="lineno">   69</span>        <span class="stringliteral">&#39;null_word&#39;</span>: old_model.null_word,</div>
<div class="line"><span class="lineno">   70</span>        <span class="stringliteral">&#39;sorted_vocab&#39;</span>: old_model.sorted_vocab,</div>
<div class="line"><span class="lineno">   71</span>        <span class="stringliteral">&#39;batch_words&#39;</span>: old_model.batch_words,</div>
<div class="line"><span class="lineno">   72</span>        <span class="stringliteral">&#39;min_n&#39;</span>: old_model.min_n,</div>
<div class="line"><span class="lineno">   73</span>        <span class="stringliteral">&#39;max_n&#39;</span>: old_model.max_n,</div>
<div class="line"><span class="lineno">   74</span>        <span class="stringliteral">&#39;word_ngrams&#39;</span>: old_model.word_ngrams,</div>
<div class="line"><span class="lineno">   75</span>        <span class="stringliteral">&#39;bucket&#39;</span>: old_model.bucket</div>
<div class="line"><span class="lineno">   76</span>    }</div>
<div class="line"><span class="lineno">   77</span>    new_model = NewFastText(**params)</div>
<div class="line"><span class="lineno">   78</span>    <span class="comment"># set trainables attributes</span></div>
<div class="line"><span class="lineno">   79</span>    new_model.wv.vectors = old_model.wv.syn0</div>
<div class="line"><span class="lineno">   80</span>    new_model.wv.vectors_vocab = old_model.wv.syn0_vocab</div>
<div class="line"><span class="lineno">   81</span>    new_model.wv.vectors_ngrams = old_model.wv.syn0_ngrams</div>
<div class="line"><span class="lineno">   82</span>    <span class="keywordflow">if</span> hasattr(old_model.wv, <span class="stringliteral">&#39;syn0norm&#39;</span>):</div>
<div class="line"><span class="lineno">   83</span>        new_model.wv.vectors_norm = old_model.wv.syn0norm</div>
<div class="line"><span class="lineno">   84</span>    <span class="keywordflow">if</span> hasattr(old_model, <span class="stringliteral">&#39;syn1&#39;</span>):</div>
<div class="line"><span class="lineno">   85</span>        new_model.trainables.syn1 = old_model.syn1</div>
<div class="line"><span class="lineno">   86</span>    <span class="keywordflow">if</span> hasattr(old_model, <span class="stringliteral">&#39;syn1neg&#39;</span>):</div>
<div class="line"><span class="lineno">   87</span>        new_model.trainables.syn1neg = old_model.syn1neg</div>
<div class="line"><span class="lineno">   88</span>    <span class="keywordflow">if</span> hasattr(old_model, <span class="stringliteral">&#39;syn0_lockf&#39;</span>):</div>
<div class="line"><span class="lineno">   89</span>        new_model.trainables.vectors_lockf = old_model.syn0_lockf</div>
<div class="line"><span class="lineno">   90</span> </div>
<div class="line"><span class="lineno">   91</span>    <span class="keywordflow">if</span> hasattr(old_model, <span class="stringliteral">&#39;syn0_vocab_lockf&#39;</span>):</div>
<div class="line"><span class="lineno">   92</span>        new_model.trainables.vectors_vocab_lockf = old_model.syn0_vocab_lockf</div>
<div class="line"><span class="lineno">   93</span>    <span class="keywordflow">if</span> hasattr(old_model, <span class="stringliteral">&#39;syn0_ngrams_lockf&#39;</span>):</div>
<div class="line"><span class="lineno">   94</span>        new_model.trainables.vectors_ngrams_lockf = old_model.syn0_ngrams_lockf</div>
<div class="line"><span class="lineno">   95</span>    <span class="keywordflow">if</span> hasattr(old_model.wv, <span class="stringliteral">&#39;syn0_vocab_norm&#39;</span>):</div>
<div class="line"><span class="lineno">   96</span>        new_model.trainables.vectors_vocab_norm = old_model.wv.syn0_vocab_norm</div>
<div class="line"><span class="lineno">   97</span>    <span class="keywordflow">if</span> hasattr(old_model.wv, <span class="stringliteral">&#39;syn0_ngrams_norm&#39;</span>):</div>
<div class="line"><span class="lineno">   98</span>        new_model.trainables.vectors_ngrams_norm = old_model.wv.syn0_ngrams_norm</div>
<div class="line"><span class="lineno">   99</span> </div>
<div class="line"><span class="lineno">  100</span>    <span class="comment"># set vocabulary attributes</span></div>
<div class="line"><span class="lineno">  101</span>    new_model.wv.vocab = old_model.wv.vocab</div>
<div class="line"><span class="lineno">  102</span>    new_model.wv.index2word = old_model.wv.index2word</div>
<div class="line"><span class="lineno">  103</span>    new_model.vocabulary.cum_table = old_model.cum_table</div>
<div class="line"><span class="lineno">  104</span> </div>
<div class="line"><span class="lineno">  105</span>    new_model.wv.hash2index = old_model.wv.hash2index</div>
<div class="line"><span class="lineno">  106</span> </div>
<div class="line"><span class="lineno">  107</span>    new_model.train_count = old_model.train_count</div>
<div class="line"><span class="lineno">  108</span>    new_model.corpus_count = old_model.corpus_count</div>
<div class="line"><span class="lineno">  109</span>    new_model.corpus_total_words = old_model.corpus_total_words</div>
<div class="line"><span class="lineno">  110</span>    new_model.running_training_loss = old_model.running_training_loss</div>
<div class="line"><span class="lineno">  111</span>    new_model.total_train_time = old_model.total_train_time</div>
<div class="line"><span class="lineno">  112</span>    new_model.min_alpha_yet_reached = old_model.min_alpha_yet_reached</div>
<div class="line"><span class="lineno">  113</span>    new_model.model_trimmed_post_training = old_model.model_trimmed_post_training</div>
<div class="line"><span class="lineno">  114</span> </div>
<div class="line"><span class="lineno">  115</span>    new_model.trainables.num_ngram_vectors = old_model.num_ngram_vectors</div>
<div class="line"><span class="lineno">  116</span> </div>
<div class="line"><span class="lineno">  117</span>    <span class="keywordflow">return</span> new_model</div>
<div class="line"><span class="lineno">  118</span> </div>
<div class="line"><span class="lineno">  119</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a954f5fac94acf84946d5dbce8a3339f6" name="a954f5fac94acf84946d5dbce8a3339f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a954f5fac94acf84946d5dbce8a3339f6">&#9670;&#160;</a></span>train_batch_cbow()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.fasttext.train_batch_cbow </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>work</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>neu1</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update CBOW model by training on a sequence of sentences.

Each sentence is a list of string tokens, which are looked up in the model's
vocab dictionary. Called internally from :meth:`gensim.models.fasttext.FastText.train()`.

This is the non-optimized, Python version. If you have cython installed, gensim
will use the optimized version from fasttext_inner instead.

Parameters
----------
model : :class:`~gensim.models.fasttext.FastText`
    `FastText` instance.
sentences : iterable of iterables
    Iterable of the sentences directly from disk/network.
alpha : float
    Learning rate.
work : :class:`numpy.ndarray`
    Private working memory for each worker.
neu1 : :class:`numpy.ndarray`
    Private working memory for each worker.

Returns
-------
int
    Effective number of words trained.</pre> <div class="fragment"><div class="line"><span class="lineno">  120</span><span class="keyword">def </span>train_batch_cbow(model, sentences, alpha, work=None, neu1=None):</div>
<div class="line"><span class="lineno">  121</span>    <span class="stringliteral">&quot;&quot;&quot;Update CBOW model by training on a sequence of sentences.</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">    Each sentence is a list of string tokens, which are looked up in the model&#39;s</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">    vocab dictionary. Called internally from :meth:`gensim.models.fasttext.FastText.train()`.</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral">    This is the non-optimized, Python version. If you have cython installed, gensim</span></div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral">    will use the optimized version from fasttext_inner instead.</span></div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">    model : :class:`~gensim.models.fasttext.FastText`</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral">        `FastText` instance.</span></div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">    sentences : iterable of iterables</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">        Iterable of the sentences directly from disk/network.</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">    alpha : float</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">        Learning rate.</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">    work : :class:`numpy.ndarray`</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">        Private working memory for each worker.</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral">    neu1 : :class:`numpy.ndarray`</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">        Private working memory for each worker.</span></div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">    int</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">        Effective number of words trained.</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  148</span>    result = 0</div>
<div class="line"><span class="lineno">  149</span>    <span class="keywordflow">for</span> sentence <span class="keywordflow">in</span> sentences:</div>
<div class="line"><span class="lineno">  150</span>        word_vocabs = [model.wv.vocab[w] <span class="keywordflow">for</span> w <span class="keywordflow">in</span> sentence <span class="keywordflow">if</span> w <span class="keywordflow">in</span> model.wv.vocab</div>
<div class="line"><span class="lineno">  151</span>                       <span class="keywordflow">and</span> model.wv.vocab[w].sample_int &gt; model.random.rand() * 2**32]</div>
<div class="line"><span class="lineno">  152</span>        <span class="keywordflow">for</span> pos, word <span class="keywordflow">in</span> enumerate(word_vocabs):</div>
<div class="line"><span class="lineno">  153</span>            reduced_window = model.random.randint(model.window)</div>
<div class="line"><span class="lineno">  154</span>            start = max(0, pos - model.window + reduced_window)</div>
<div class="line"><span class="lineno">  155</span>            window_pos = enumerate(word_vocabs[start:(pos + model.window + 1 - reduced_window)], start)</div>
<div class="line"><span class="lineno">  156</span>            word2_indices = [word2.index <span class="keywordflow">for</span> pos2, word2 <span class="keywordflow">in</span> window_pos <span class="keywordflow">if</span> (word2 <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> pos2 != pos)]</div>
<div class="line"><span class="lineno">  157</span> </div>
<div class="line"><span class="lineno">  158</span>            word2_subwords = []</div>
<div class="line"><span class="lineno">  159</span>            vocab_subwords_indices = []</div>
<div class="line"><span class="lineno">  160</span>            ngrams_subwords_indices = []</div>
<div class="line"><span class="lineno">  161</span> </div>
<div class="line"><span class="lineno">  162</span>            <span class="keywordflow">for</span> index <span class="keywordflow">in</span> word2_indices:</div>
<div class="line"><span class="lineno">  163</span>                vocab_subwords_indices += [index]</div>
<div class="line"><span class="lineno">  164</span>                word2_subwords += model.wv.ngrams_word[model.wv.index2word[index]]</div>
<div class="line"><span class="lineno">  165</span> </div>
<div class="line"><span class="lineno">  166</span>            <span class="keywordflow">for</span> subword <span class="keywordflow">in</span> word2_subwords:</div>
<div class="line"><span class="lineno">  167</span>                ngrams_subwords_indices.append(model.wv.ngrams[subword])</div>
<div class="line"><span class="lineno">  168</span> </div>
<div class="line"><span class="lineno">  169</span>            l1_vocab = np_sum(model.wv.syn0_vocab[vocab_subwords_indices], axis=0)  <span class="comment"># 1 x vector_size</span></div>
<div class="line"><span class="lineno">  170</span>            l1_ngrams = np_sum(model.wv.syn0_ngrams[ngrams_subwords_indices], axis=0)  <span class="comment"># 1 x vector_size</span></div>
<div class="line"><span class="lineno">  171</span> </div>
<div class="line"><span class="lineno">  172</span>            l1 = np_sum([l1_vocab, l1_ngrams], axis=0)</div>
<div class="line"><span class="lineno">  173</span>            subwords_indices = [vocab_subwords_indices] + [ngrams_subwords_indices]</div>
<div class="line"><span class="lineno">  174</span>            <span class="keywordflow">if</span> (subwords_indices[0] <span class="keywordflow">or</span> subwords_indices[1]) <span class="keywordflow">and</span> model.cbow_mean:</div>
<div class="line"><span class="lineno">  175</span>                l1 /= (len(subwords_indices[0]) + len(subwords_indices[1]))</div>
<div class="line"><span class="lineno">  176</span> </div>
<div class="line"><span class="lineno">  177</span>            <span class="comment"># train on the sliding window for target word</span></div>
<div class="line"><span class="lineno">  178</span>            train_cbow_pair(model, word, subwords_indices, l1, alpha, is_ft=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  179</span>        result += len(word_vocabs)</div>
<div class="line"><span class="lineno">  180</span>    <span class="keywordflow">return</span> result</div>
<div class="line"><span class="lineno">  181</span> </div>
<div class="line"><span class="lineno">  182</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a25ecd467c26572027dfb292242f1b84f" name="a25ecd467c26572027dfb292242f1b84f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25ecd467c26572027dfb292242f1b84f">&#9670;&#160;</a></span>train_batch_sg()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.fasttext.train_batch_sg </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>work</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>neu1</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update skip-gram model by training on a sequence of sentences.

Each sentence is a list of string tokens, which are looked up in the model's
vocab dictionary. Called internally from :meth:`gensim.models.fasttext.FastText.train()`.

This is the non-optimized, Python version. If you have cython installed, gensim
will use the optimized version from fasttext_inner instead.

Parameters
----------
model : :class:`~gensim.models.fasttext.FastText`
    `FastText` instance.
sentences : iterable of iterables
    Iterable of the sentences directly from disk/network.
alpha : float
    Learning rate.
work : :class:`numpy.ndarray`
    Private working memory for each worker.
neu1 : :class:`numpy.ndarray`
    Private working memory for each worker.

Returns
-------
int
    Effective number of words trained.</pre> <div class="fragment"><div class="line"><span class="lineno">  183</span><span class="keyword">def </span>train_batch_sg(model, sentences, alpha, work=None, neu1=None):</div>
<div class="line"><span class="lineno">  184</span>    <span class="stringliteral">&quot;&quot;&quot;Update skip-gram model by training on a sequence of sentences.</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">    Each sentence is a list of string tokens, which are looked up in the model&#39;s</span></div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">    vocab dictionary. Called internally from :meth:`gensim.models.fasttext.FastText.train()`.</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">    This is the non-optimized, Python version. If you have cython installed, gensim</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral">    will use the optimized version from fasttext_inner instead.</span></div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">    model : :class:`~gensim.models.fasttext.FastText`</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">        `FastText` instance.</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral">    sentences : iterable of iterables</span></div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral">        Iterable of the sentences directly from disk/network.</span></div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral">    alpha : float</span></div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">        Learning rate.</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral">    work : :class:`numpy.ndarray`</span></div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral">        Private working memory for each worker.</span></div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral">    neu1 : :class:`numpy.ndarray`</span></div>
<div class="line"><span class="lineno">  203</span><span class="stringliteral">        Private working memory for each worker.</span></div>
<div class="line"><span class="lineno">  204</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  205</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  206</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral">    int</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">        Effective number of words trained.</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  211</span>    result = 0</div>
<div class="line"><span class="lineno">  212</span>    <span class="keywordflow">for</span> sentence <span class="keywordflow">in</span> sentences:</div>
<div class="line"><span class="lineno">  213</span>        word_vocabs = [model.wv.vocab[w] <span class="keywordflow">for</span> w <span class="keywordflow">in</span> sentence <span class="keywordflow">if</span> w <span class="keywordflow">in</span> model.wv.vocab</div>
<div class="line"><span class="lineno">  214</span>                       <span class="keywordflow">and</span> model.wv.vocab[w].sample_int &gt; model.random.rand() * 2**32]</div>
<div class="line"><span class="lineno">  215</span>        <span class="keywordflow">for</span> pos, word <span class="keywordflow">in</span> enumerate(word_vocabs):</div>
<div class="line"><span class="lineno">  216</span>            reduced_window = model.random.randint(model.window)  <span class="comment"># `b` in the original word2vec code</span></div>
<div class="line"><span class="lineno">  217</span>            <span class="comment"># now go over all words from the (reduced) window, predicting each one in turn</span></div>
<div class="line"><span class="lineno">  218</span>            start = max(0, pos - model.window + reduced_window)</div>
<div class="line"><span class="lineno">  219</span> </div>
<div class="line"><span class="lineno">  220</span>            subwords_indices = [word.index]</div>
<div class="line"><span class="lineno">  221</span>            word2_subwords = model.wv.ngrams_word[model.wv.index2word[word.index]]</div>
<div class="line"><span class="lineno">  222</span> </div>
<div class="line"><span class="lineno">  223</span>            <span class="keywordflow">for</span> subword <span class="keywordflow">in</span> word2_subwords:</div>
<div class="line"><span class="lineno">  224</span>                subwords_indices.append(model.wv.ngrams[subword])</div>
<div class="line"><span class="lineno">  225</span> </div>
<div class="line"><span class="lineno">  226</span>            <span class="keywordflow">for</span> pos2, word2 <span class="keywordflow">in</span> enumerate(word_vocabs[start:(pos + model.window + 1 - reduced_window)], start):</div>
<div class="line"><span class="lineno">  227</span>                <span class="keywordflow">if</span> pos2 != pos:  <span class="comment"># don&#39;t train on the `word` itself</span></div>
<div class="line"><span class="lineno">  228</span>                    train_sg_pair(model, model.wv.index2word[word2.index], subwords_indices, alpha, is_ft=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  229</span> </div>
<div class="line"><span class="lineno">  230</span>        result += len(word_vocabs)</div>
<div class="line"><span class="lineno">  231</span>    <span class="keywordflow">return</span> result</div>
<div class="line"><span class="lineno">  232</span> </div>
<div class="line"><span class="lineno">  233</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a2d45dfe1d6f5696ffc387ba15fe6bccd" name="a2d45dfe1d6f5696ffc387ba15fe6bccd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d45dfe1d6f5696ffc387ba15fe6bccd">&#9670;&#160;</a></span>logger</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.fasttext.logger = logging.getLogger(__name__)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a41cd5460df788b06985a2a007662afe5" name="a41cd5460df788b06985a2a007662afe5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a41cd5460df788b06985a2a007662afe5">&#9670;&#160;</a></span>MAX_WORDS_IN_BATCH</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int gensim.models.deprecated.fasttext.MAX_WORDS_IN_BATCH = 10000</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
