<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: gensim.models.word2vec.Word2Vec Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacegensim.html">gensim</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models.html">models</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1word2vec.html">word2vec</a></li><li class="navelem"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html">Word2Vec</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="classgensim_1_1models_1_1word2vec_1_1_word2_vec-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">gensim.models.word2vec.Word2Vec Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for gensim.models.word2vec.Word2Vec:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classgensim_1_1models_1_1word2vec_1_1_word2_vec.png" usemap="#gensim.models.word2vec.Word2Vec_map" alt=""/>
  <map id="gensim.models.word2vec.Word2Vec_map" name="gensim.models.word2vec.Word2Vec_map">
<area href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html" alt="gensim.models.base_any2vec.BaseWordEmbeddingsModel" shape="rect" coords="0,168,346,192"/>
<area href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html" alt="gensim.models.base_any2vec.BaseAny2VecModel" shape="rect" coords="0,112,346,136"/>
<area href="classgensim_1_1utils_1_1_save_load.html" alt="gensim.utils.SaveLoad" shape="rect" coords="0,56,346,80"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a74120a77ebe63940fb8692cf3cc4d536" id="r_a74120a77ebe63940fb8692cf3cc4d536"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a74120a77ebe63940fb8692cf3cc4d536">__init__</a> (self, sentences=None, corpus_file=None, size=100, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#aabcca7460d56cd4ac218f01cce509d5e">alpha</a>=0.025, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a9f1346f14b6cf3bbe9938bd974aebdb0">window</a>=5, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#afc6a7a443083a05058a9f445b200307a">min_count</a>=5, max_vocab_size=None, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a82f9bef60f089d1c3c1b5816b7241f48">sample</a>=1e-3, seed=1, <a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#afabc9719a977187125422e12b826a982">workers</a>=3, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a415ab7bc044d543b619648e5239e1f45">min_alpha</a>=0.0001, <a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a1d589a8d7b122dffd555e9bc8d746b48">sg</a>=0, <a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a523cc58f02b0dcf672056d275a5585cc">hs</a>=0, <a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a17c87313bad8678d860579476c866990">negative</a>=5, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a9453990e91d506ec4176a6b954171764">ns_exponent</a>=0.75, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ab3174a404a8ac0021323c06f58c4376d">cbow_mean</a>=1, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a02212289ed83cf48d49fbeae8f5129f7">hashfxn</a>=hash, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ac283b24230213e3c3903c38043d8e4f2">iter</a>=5, null_word=0, trim_rule=None, sorted_vocab=1, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#ab51030aec82b81f33a405ddf73e970b5">batch_words</a>=MAX_WORDS_IN_BATCH, <a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a7356f0b5c78c282c314d6f16f3933292">compute_loss</a>=False, <a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a8de8ffa27932afb332d78cca6355bea3">callbacks</a>=(), <a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#aaa915e33452de6bc501705c3ac04c3e7">max_final_vocab</a>=None)</td></tr>
<tr class="separator:a74120a77ebe63940fb8692cf3cc4d536"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa10c70a15d13b09500372b8652bef4f7" id="r_aa10c70a15d13b09500372b8652bef4f7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#aa10c70a15d13b09500372b8652bef4f7">train</a> (self, sentences=None, corpus_file=None, total_examples=None, total_words=None, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#aa9d08186dc167abf54467f0a72baa6fb">epochs</a>=None, start_alpha=None, end_alpha=None, word_count=0, queue_factor=2, report_delay=1.0, <a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a7356f0b5c78c282c314d6f16f3933292">compute_loss</a>=False, <a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a8de8ffa27932afb332d78cca6355bea3">callbacks</a>=())</td></tr>
<tr class="separator:aa10c70a15d13b09500372b8652bef4f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32cf864074108c28edeb1fcdc3397b4c" id="r_a32cf864074108c28edeb1fcdc3397b4c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a32cf864074108c28edeb1fcdc3397b4c">score</a> (self, sentences, total_sentences=<a class="el" href="namespacegensim_1_1models_1_1word2vec.html#afcae40e2c97fbb41616072e53d221642">int</a>(1e6), chunksize=100, queue_factor=2, report_delay=1)</td></tr>
<tr class="separator:a32cf864074108c28edeb1fcdc3397b4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01ffef0f127500d9637cb61d03245d5e" id="r_a01ffef0f127500d9637cb61d03245d5e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a01ffef0f127500d9637cb61d03245d5e">clear_sims</a> (self)</td></tr>
<tr class="separator:a01ffef0f127500d9637cb61d03245d5e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9a256ee7a869a0b17ab5a61057b8e45" id="r_ac9a256ee7a869a0b17ab5a61057b8e45"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#ac9a256ee7a869a0b17ab5a61057b8e45">intersect_word2vec_format</a> (self, fname, lockf=0.0, <a class="el" href="namespacegensim_1_1models_1_1word2vec.html#a40324d8b9a2cb8fcaa7a8941a3c50d15">binary</a>=False, encoding='utf8', unicode_errors='strict')</td></tr>
<tr class="separator:ac9a256ee7a869a0b17ab5a61057b8e45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62a800fade15ba778f976bae2ac5318d" id="r_a62a800fade15ba778f976bae2ac5318d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a62a800fade15ba778f976bae2ac5318d">__getitem__</a> (self, words)</td></tr>
<tr class="separator:a62a800fade15ba778f976bae2ac5318d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43f54d1e86ecf7cb5b1616267bbafa40" id="r_a43f54d1e86ecf7cb5b1616267bbafa40"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a43f54d1e86ecf7cb5b1616267bbafa40">__contains__</a> (self, word)</td></tr>
<tr class="separator:a43f54d1e86ecf7cb5b1616267bbafa40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a270be5eb124095a586ab0eb997e30599" id="r_a270be5eb124095a586ab0eb997e30599"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a270be5eb124095a586ab0eb997e30599">predict_output_word</a> (self, context_words_list, topn=10)</td></tr>
<tr class="separator:a270be5eb124095a586ab0eb997e30599"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae98077330956bfd4549fb50fb8e3c4bd" id="r_ae98077330956bfd4549fb50fb8e3c4bd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#ae98077330956bfd4549fb50fb8e3c4bd">init_sims</a> (self, replace=False)</td></tr>
<tr class="separator:ae98077330956bfd4549fb50fb8e3c4bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac95948a74a57dd02bc4c4213e23ebdb3" id="r_ac95948a74a57dd02bc4c4213e23ebdb3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#ac95948a74a57dd02bc4c4213e23ebdb3">reset_from</a> (self, other_model)</td></tr>
<tr class="separator:ac95948a74a57dd02bc4c4213e23ebdb3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af49d1f6c8bb6ac1c23a004919a284962" id="r_af49d1f6c8bb6ac1c23a004919a284962"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#af49d1f6c8bb6ac1c23a004919a284962">accuracy</a> (self, questions, restrict_vocab=30000, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a79de4c7cebaaf19f884f1f3c9e982f28">most_similar</a>=None, case_insensitive=True)</td></tr>
<tr class="separator:af49d1f6c8bb6ac1c23a004919a284962"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a201840cce09c98ed0fe106d26d385e04" id="r_a201840cce09c98ed0fe106d26d385e04"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a201840cce09c98ed0fe106d26d385e04">__str__</a> (self)</td></tr>
<tr class="separator:a201840cce09c98ed0fe106d26d385e04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72d938f82ab91eb23dcf52224af5848d" id="r_a72d938f82ab91eb23dcf52224af5848d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a72d938f82ab91eb23dcf52224af5848d">delete_temporary_training_data</a> (self, replace_word_vectors_with_normalized=False)</td></tr>
<tr class="separator:a72d938f82ab91eb23dcf52224af5848d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad77cee4ec895484e53a4405830d272aa" id="r_ad77cee4ec895484e53a4405830d272aa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#ad77cee4ec895484e53a4405830d272aa">save</a> (self, *<a class="el" href="namespacegensim_1_1models_1_1word2vec.html#a55bfd583221165d36c05d9baed009cce">args</a>, **kwargs)</td></tr>
<tr class="separator:ad77cee4ec895484e53a4405830d272aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae97038d8795772d441574f8e2b35c334" id="r_ae97038d8795772d441574f8e2b35c334"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#ae97038d8795772d441574f8e2b35c334">get_latest_training_loss</a> (self)</td></tr>
<tr class="separator:ae97038d8795772d441574f8e2b35c334"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a084c2a637534ad0e1adc94d7a1278d31" id="r_a084c2a637534ad0e1adc94d7a1278d31"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a084c2a637534ad0e1adc94d7a1278d31">load_word2vec_format</a> (cls, fname, fvocab=None, <a class="el" href="namespacegensim_1_1models_1_1word2vec.html#a40324d8b9a2cb8fcaa7a8941a3c50d15">binary</a>=False, encoding='utf8', unicode_errors='strict', limit=None, datatype=REAL)</td></tr>
<tr class="separator:a084c2a637534ad0e1adc94d7a1278d31"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a455b2aff149dd82fdcc28d4d0bf8b697" id="r_a455b2aff149dd82fdcc28d4d0bf8b697"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a455b2aff149dd82fdcc28d4d0bf8b697">save_word2vec_format</a> (self, fname, fvocab=None, <a class="el" href="namespacegensim_1_1models_1_1word2vec.html#a40324d8b9a2cb8fcaa7a8941a3c50d15">binary</a>=False)</td></tr>
<tr class="separator:a455b2aff149dd82fdcc28d4d0bf8b697"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2fa09c79252cd54a67ffc80b57e61dfe" id="r_a2fa09c79252cd54a67ffc80b57e61dfe"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a2fa09c79252cd54a67ffc80b57e61dfe">load</a> (cls, *<a class="el" href="namespacegensim_1_1models_1_1word2vec.html#a55bfd583221165d36c05d9baed009cce">args</a>, **kwargs)</td></tr>
<tr class="separator:a2fa09c79252cd54a67ffc80b57e61dfe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html">gensim.models.base_any2vec.BaseWordEmbeddingsModel</a></td></tr>
<tr class="memitem:ac283b24230213e3c3903c38043d8e4f2 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ac283b24230213e3c3903c38043d8e4f2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ac283b24230213e3c3903c38043d8e4f2">iter</a> (self)</td></tr>
<tr class="separator:ac283b24230213e3c3903c38043d8e4f2 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c22fa5bd613e33aee5cb98684894d43 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a4c22fa5bd613e33aee5cb98684894d43"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a4c22fa5bd613e33aee5cb98684894d43">iter</a> (self, value)</td></tr>
<tr class="separator:a4c22fa5bd613e33aee5cb98684894d43 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac610e13706415ed30f6b73125209ea4b inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ac610e13706415ed30f6b73125209ea4b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ac610e13706415ed30f6b73125209ea4b">syn1</a> (self)</td></tr>
<tr class="separator:ac610e13706415ed30f6b73125209ea4b inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3bc500faf30431eb8bbb995f0e786ec4 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a3bc500faf30431eb8bbb995f0e786ec4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a3bc500faf30431eb8bbb995f0e786ec4">syn1</a> (self, value)</td></tr>
<tr class="separator:a3bc500faf30431eb8bbb995f0e786ec4 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac610e13706415ed30f6b73125209ea4b inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ac610e13706415ed30f6b73125209ea4b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ac610e13706415ed30f6b73125209ea4b">syn1</a> (self)</td></tr>
<tr class="separator:ac610e13706415ed30f6b73125209ea4b inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46031d1b560941279ac5fcbac69c81cc inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a46031d1b560941279ac5fcbac69c81cc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a46031d1b560941279ac5fcbac69c81cc">syn1neg</a> (self)</td></tr>
<tr class="separator:a46031d1b560941279ac5fcbac69c81cc inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5823581e9f2c8e264e349fcd9402e23b inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a5823581e9f2c8e264e349fcd9402e23b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a5823581e9f2c8e264e349fcd9402e23b">syn1neg</a> (self, value)</td></tr>
<tr class="separator:a5823581e9f2c8e264e349fcd9402e23b inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46031d1b560941279ac5fcbac69c81cc inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a46031d1b560941279ac5fcbac69c81cc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a46031d1b560941279ac5fcbac69c81cc">syn1neg</a> (self)</td></tr>
<tr class="separator:a46031d1b560941279ac5fcbac69c81cc inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a694a196d5456c29779810a08bdb63e15 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a694a196d5456c29779810a08bdb63e15"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a694a196d5456c29779810a08bdb63e15">syn0_lockf</a> (self)</td></tr>
<tr class="separator:a694a196d5456c29779810a08bdb63e15 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ed9721d5c1059f94448021e824bd5e3 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a7ed9721d5c1059f94448021e824bd5e3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a7ed9721d5c1059f94448021e824bd5e3">syn0_lockf</a> (self, value)</td></tr>
<tr class="separator:a7ed9721d5c1059f94448021e824bd5e3 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a694a196d5456c29779810a08bdb63e15 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a694a196d5456c29779810a08bdb63e15"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a694a196d5456c29779810a08bdb63e15">syn0_lockf</a> (self)</td></tr>
<tr class="separator:a694a196d5456c29779810a08bdb63e15 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9922736d82166f68da2e9d68b3cb77d3 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a9922736d82166f68da2e9d68b3cb77d3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a9922736d82166f68da2e9d68b3cb77d3">layer1_size</a> (self)</td></tr>
<tr class="separator:a9922736d82166f68da2e9d68b3cb77d3 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af764b8da6650bcd57f6caf1c0ca43f91 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_af764b8da6650bcd57f6caf1c0ca43f91"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#af764b8da6650bcd57f6caf1c0ca43f91">layer1_size</a> (self, value)</td></tr>
<tr class="separator:af764b8da6650bcd57f6caf1c0ca43f91 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02212289ed83cf48d49fbeae8f5129f7 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a02212289ed83cf48d49fbeae8f5129f7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a02212289ed83cf48d49fbeae8f5129f7">hashfxn</a> (self)</td></tr>
<tr class="separator:a02212289ed83cf48d49fbeae8f5129f7 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b515b69cab0ec94789685cfd3469de7 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a0b515b69cab0ec94789685cfd3469de7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a0b515b69cab0ec94789685cfd3469de7">hashfxn</a> (self, value)</td></tr>
<tr class="separator:a0b515b69cab0ec94789685cfd3469de7 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82f9bef60f089d1c3c1b5816b7241f48 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a82f9bef60f089d1c3c1b5816b7241f48"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a82f9bef60f089d1c3c1b5816b7241f48">sample</a> (self)</td></tr>
<tr class="separator:a82f9bef60f089d1c3c1b5816b7241f48 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a62c5a22f06f4737d9d06bf9871020e inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a4a62c5a22f06f4737d9d06bf9871020e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a4a62c5a22f06f4737d9d06bf9871020e">sample</a> (self, value)</td></tr>
<tr class="separator:a4a62c5a22f06f4737d9d06bf9871020e inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc6a7a443083a05058a9f445b200307a inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_afc6a7a443083a05058a9f445b200307a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#afc6a7a443083a05058a9f445b200307a">min_count</a> (self)</td></tr>
<tr class="separator:afc6a7a443083a05058a9f445b200307a inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abec84555e5618b29ba00c027f018cfc0 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_abec84555e5618b29ba00c027f018cfc0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#abec84555e5618b29ba00c027f018cfc0">min_count</a> (self, value)</td></tr>
<tr class="separator:abec84555e5618b29ba00c027f018cfc0 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf7b64d2606f84fd324a4ab8a26bc27d inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_abf7b64d2606f84fd324a4ab8a26bc27d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#abf7b64d2606f84fd324a4ab8a26bc27d">cum_table</a> (self)</td></tr>
<tr class="separator:abf7b64d2606f84fd324a4ab8a26bc27d inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaefcdf99f77743b4eef68d90f6710833 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_aaefcdf99f77743b4eef68d90f6710833"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#aaefcdf99f77743b4eef68d90f6710833">cum_table</a> (self, value)</td></tr>
<tr class="separator:aaefcdf99f77743b4eef68d90f6710833 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf7b64d2606f84fd324a4ab8a26bc27d inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_abf7b64d2606f84fd324a4ab8a26bc27d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#abf7b64d2606f84fd324a4ab8a26bc27d">cum_table</a> (self)</td></tr>
<tr class="separator:abf7b64d2606f84fd324a4ab8a26bc27d inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51c9f9367690d5c22c49e12be4b32012 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a51c9f9367690d5c22c49e12be4b32012"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a51c9f9367690d5c22c49e12be4b32012">build_vocab</a> (self, sentences=None, corpus_file=None, update=False, progress_per=10000, keep_raw_vocab=False, trim_rule=None, **kwargs)</td></tr>
<tr class="separator:a51c9f9367690d5c22c49e12be4b32012 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53af5c051975921ce162c953a543e54c inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a53af5c051975921ce162c953a543e54c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a53af5c051975921ce162c953a543e54c">build_vocab_from_freq</a> (self, word_freq, keep_raw_vocab=False, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a5ef4abba7bdf03fad810528232cbf82d">corpus_count</a>=None, trim_rule=None, update=False)</td></tr>
<tr class="separator:a53af5c051975921ce162c953a543e54c inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f480f10613dabc1ea0ddf54fa9f549e inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a7f480f10613dabc1ea0ddf54fa9f549e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a7f480f10613dabc1ea0ddf54fa9f549e">estimate_memory</a> (self, vocab_size=None, report=None)</td></tr>
<tr class="separator:a7f480f10613dabc1ea0ddf54fa9f549e inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79de4c7cebaaf19f884f1f3c9e982f28 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a79de4c7cebaaf19f884f1f3c9e982f28"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a79de4c7cebaaf19f884f1f3c9e982f28">most_similar</a> (self, positive=None, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ab0f17d19ddd94d3d6a26c3fe382a942b">negative</a>=None, topn=10, restrict_vocab=None, indexer=None)</td></tr>
<tr class="separator:a79de4c7cebaaf19f884f1f3c9e982f28 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae73673d5ec8d74aa44d0d3f6424ae10e inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ae73673d5ec8d74aa44d0d3f6424ae10e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ae73673d5ec8d74aa44d0d3f6424ae10e">wmdistance</a> (self, document1, document2)</td></tr>
<tr class="separator:ae73673d5ec8d74aa44d0d3f6424ae10e inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7a2ab898171b52ddfc76e72b8044d2c inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_af7a2ab898171b52ddfc76e72b8044d2c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#af7a2ab898171b52ddfc76e72b8044d2c">most_similar_cosmul</a> (self, positive=None, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ab0f17d19ddd94d3d6a26c3fe382a942b">negative</a>=None, topn=10)</td></tr>
<tr class="separator:af7a2ab898171b52ddfc76e72b8044d2c inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99d62be4558a11ff76b7a9a34c231bbc inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a99d62be4558a11ff76b7a9a34c231bbc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a99d62be4558a11ff76b7a9a34c231bbc">similar_by_word</a> (self, word, topn=10, restrict_vocab=None)</td></tr>
<tr class="separator:a99d62be4558a11ff76b7a9a34c231bbc inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8fa53943aba73aa398730245d1aa2cf inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ad8fa53943aba73aa398730245d1aa2cf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ad8fa53943aba73aa398730245d1aa2cf">similar_by_vector</a> (self, vector, topn=10, restrict_vocab=None)</td></tr>
<tr class="separator:ad8fa53943aba73aa398730245d1aa2cf inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e8535a4be8191a3e42c994cab32f915 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a0e8535a4be8191a3e42c994cab32f915"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a0e8535a4be8191a3e42c994cab32f915">doesnt_match</a> (self, words)</td></tr>
<tr class="separator:a0e8535a4be8191a3e42c994cab32f915 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf6dc205ac773ebe988398f99fa261e0 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_adf6dc205ac773ebe988398f99fa261e0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#adf6dc205ac773ebe988398f99fa261e0">similarity</a> (self, w1, w2)</td></tr>
<tr class="separator:adf6dc205ac773ebe988398f99fa261e0 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75d241c6240ad48d0c8a6e0637ff1de9 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a75d241c6240ad48d0c8a6e0637ff1de9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a75d241c6240ad48d0c8a6e0637ff1de9">n_similarity</a> (self, ws1, ws2)</td></tr>
<tr class="separator:a75d241c6240ad48d0c8a6e0637ff1de9 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab309d5d6b9867a976980e116a7efa552 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ab309d5d6b9867a976980e116a7efa552"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ab309d5d6b9867a976980e116a7efa552">evaluate_word_pairs</a> (self, pairs, delimiter='\t', restrict_vocab=300000, case_insensitive=True, dummy4unknown=False)</td></tr>
<tr class="separator:ab309d5d6b9867a976980e116a7efa552 inherit pub_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-static-methods" name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:aec29fc5498af2137014ec6af6ce6df2e" id="r_aec29fc5498af2137014ec6af6ce6df2e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#aec29fc5498af2137014ec6af6ce6df2e">log_accuracy</a> (section)</td></tr>
<tr class="separator:aec29fc5498af2137014ec6af6ce6df2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:aaa915e33452de6bc501705c3ac04c3e7" id="r_aaa915e33452de6bc501705c3ac04c3e7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#aaa915e33452de6bc501705c3ac04c3e7">max_final_vocab</a></td></tr>
<tr class="separator:aaa915e33452de6bc501705c3ac04c3e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8de8ffa27932afb332d78cca6355bea3" id="r_a8de8ffa27932afb332d78cca6355bea3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a8de8ffa27932afb332d78cca6355bea3">callbacks</a></td></tr>
<tr class="separator:a8de8ffa27932afb332d78cca6355bea3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a251d67682ef42a76cf36cbfa81ed9dd3" id="r_a251d67682ef42a76cf36cbfa81ed9dd3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a251d67682ef42a76cf36cbfa81ed9dd3">load</a></td></tr>
<tr class="separator:a251d67682ef42a76cf36cbfa81ed9dd3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a357ac9cc29d94de58e46041f69168ae6" id="r_a357ac9cc29d94de58e46041f69168ae6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a357ac9cc29d94de58e46041f69168ae6">wv</a></td></tr>
<tr class="separator:a357ac9cc29d94de58e46041f69168ae6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad960f930ac57ad61d4ac1f1909fc6a8b" id="r_ad960f930ac57ad61d4ac1f1909fc6a8b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#ad960f930ac57ad61d4ac1f1909fc6a8b">vocabulary</a></td></tr>
<tr class="separator:ad960f930ac57ad61d4ac1f1909fc6a8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a402b65c7086e51f80aeb6436166b89b5" id="r_a402b65c7086e51f80aeb6436166b89b5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a402b65c7086e51f80aeb6436166b89b5">trainables</a></td></tr>
<tr class="separator:a402b65c7086e51f80aeb6436166b89b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7356f0b5c78c282c314d6f16f3933292" id="r_a7356f0b5c78c282c314d6f16f3933292"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a7356f0b5c78c282c314d6f16f3933292">compute_loss</a></td></tr>
<tr class="separator:a7356f0b5c78c282c314d6f16f3933292"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f3058a2f528e0e71181d6eb6436e870" id="r_a8f3058a2f528e0e71181d6eb6436e870"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a8f3058a2f528e0e71181d6eb6436e870">running_training_loss</a></td></tr>
<tr class="separator:a8f3058a2f528e0e71181d6eb6436e870"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afabc9719a977187125422e12b826a982" id="r_afabc9719a977187125422e12b826a982"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#afabc9719a977187125422e12b826a982">workers</a></td></tr>
<tr class="separator:afabc9719a977187125422e12b826a982"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d589a8d7b122dffd555e9bc8d746b48" id="r_a1d589a8d7b122dffd555e9bc8d746b48"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a1d589a8d7b122dffd555e9bc8d746b48">sg</a></td></tr>
<tr class="separator:a1d589a8d7b122dffd555e9bc8d746b48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a523cc58f02b0dcf672056d275a5585cc" id="r_a523cc58f02b0dcf672056d275a5585cc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a523cc58f02b0dcf672056d275a5585cc">hs</a></td></tr>
<tr class="separator:a523cc58f02b0dcf672056d275a5585cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80a761167f0d43a06e67cb6fdfb27936" id="r_a80a761167f0d43a06e67cb6fdfb27936"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a80a761167f0d43a06e67cb6fdfb27936">corpus_count</a></td></tr>
<tr class="separator:a80a761167f0d43a06e67cb6fdfb27936"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17c87313bad8678d860579476c866990" id="r_a17c87313bad8678d860579476c866990"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a17c87313bad8678d860579476c866990">negative</a></td></tr>
<tr class="separator:a17c87313bad8678d860579476c866990"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ba4f2fe0c597aeb264e4d1a9b5e9e65" id="r_a3ba4f2fe0c597aeb264e4d1a9b5e9e65"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a3ba4f2fe0c597aeb264e4d1a9b5e9e65">model_trimmed_post_training</a></td></tr>
<tr class="separator:a3ba4f2fe0c597aeb264e4d1a9b5e9e65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html">gensim.models.base_any2vec.BaseWordEmbeddingsModel</a></td></tr>
<tr class="memitem:aa9c5fa3e03980fceb9c4b13d1e69aebb inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_aa9c5fa3e03980fceb9c4b13d1e69aebb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#aa9c5fa3e03980fceb9c4b13d1e69aebb">sg</a></td></tr>
<tr class="separator:aa9c5fa3e03980fceb9c4b13d1e69aebb inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabcca7460d56cd4ac218f01cce509d5e inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_aabcca7460d56cd4ac218f01cce509d5e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#aabcca7460d56cd4ac218f01cce509d5e">alpha</a></td></tr>
<tr class="separator:aabcca7460d56cd4ac218f01cce509d5e inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f1346f14b6cf3bbe9938bd974aebdb0 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a9f1346f14b6cf3bbe9938bd974aebdb0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a9f1346f14b6cf3bbe9938bd974aebdb0">window</a></td></tr>
<tr class="separator:a9f1346f14b6cf3bbe9938bd974aebdb0 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a14b9bd5de0c779c17d9ce4445e061048 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a14b9bd5de0c779c17d9ce4445e061048"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a14b9bd5de0c779c17d9ce4445e061048">random</a></td></tr>
<tr class="separator:a14b9bd5de0c779c17d9ce4445e061048 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a415ab7bc044d543b619648e5239e1f45 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a415ab7bc044d543b619648e5239e1f45"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a415ab7bc044d543b619648e5239e1f45">min_alpha</a></td></tr>
<tr class="separator:a415ab7bc044d543b619648e5239e1f45 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82594ade701efe61c470d73861dd3c41 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a82594ade701efe61c470d73861dd3c41"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a82594ade701efe61c470d73861dd3c41">hs</a></td></tr>
<tr class="separator:a82594ade701efe61c470d73861dd3c41 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0f17d19ddd94d3d6a26c3fe382a942b inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ab0f17d19ddd94d3d6a26c3fe382a942b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ab0f17d19ddd94d3d6a26c3fe382a942b">negative</a></td></tr>
<tr class="separator:ab0f17d19ddd94d3d6a26c3fe382a942b inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9453990e91d506ec4176a6b954171764 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a9453990e91d506ec4176a6b954171764"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a9453990e91d506ec4176a6b954171764">ns_exponent</a></td></tr>
<tr class="separator:a9453990e91d506ec4176a6b954171764 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3174a404a8ac0021323c06f58c4376d inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ab3174a404a8ac0021323c06f58c4376d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ab3174a404a8ac0021323c06f58c4376d">cbow_mean</a></td></tr>
<tr class="separator:ab3174a404a8ac0021323c06f58c4376d inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6dc04f25fe11bd2c2768030d28ff6496 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a6dc04f25fe11bd2c2768030d28ff6496"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a6dc04f25fe11bd2c2768030d28ff6496">compute_loss</a></td></tr>
<tr class="separator:a6dc04f25fe11bd2c2768030d28ff6496 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a185b178b6b4e1a67a5dc5f8436e976ec inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a185b178b6b4e1a67a5dc5f8436e976ec"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a185b178b6b4e1a67a5dc5f8436e976ec">running_training_loss</a></td></tr>
<tr class="separator:a185b178b6b4e1a67a5dc5f8436e976ec inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7219ae3952ff934386b619d0dfbca669 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a7219ae3952ff934386b619d0dfbca669"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a7219ae3952ff934386b619d0dfbca669">min_alpha_yet_reached</a></td></tr>
<tr class="separator:a7219ae3952ff934386b619d0dfbca669 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ef4abba7bdf03fad810528232cbf82d inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a5ef4abba7bdf03fad810528232cbf82d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a5ef4abba7bdf03fad810528232cbf82d">corpus_count</a></td></tr>
<tr class="separator:a5ef4abba7bdf03fad810528232cbf82d inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab712cfee950b2b1b008cdd3593dbbf8c inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ab712cfee950b2b1b008cdd3593dbbf8c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ab712cfee950b2b1b008cdd3593dbbf8c">corpus_total_words</a></td></tr>
<tr class="separator:ab712cfee950b2b1b008cdd3593dbbf8c inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9d08186dc167abf54467f0a72baa6fb inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_aa9d08186dc167abf54467f0a72baa6fb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#aa9d08186dc167abf54467f0a72baa6fb">epochs</a></td></tr>
<tr class="separator:aa9d08186dc167abf54467f0a72baa6fb inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54243b7fb1474ae916471e6722b839ac inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a54243b7fb1474ae916471e6722b839ac"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a54243b7fb1474ae916471e6722b839ac">vector_size</a></td></tr>
<tr class="separator:a54243b7fb1474ae916471e6722b839ac inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2aa69f998be5b336ccbb78697f677013 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a2aa69f998be5b336ccbb78697f677013"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a2aa69f998be5b336ccbb78697f677013">wv</a></td></tr>
<tr class="separator:a2aa69f998be5b336ccbb78697f677013 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a864331b062b24273f0fe3be5783decb6 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a864331b062b24273f0fe3be5783decb6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a864331b062b24273f0fe3be5783decb6">workers</a></td></tr>
<tr class="separator:a864331b062b24273f0fe3be5783decb6 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html">gensim.models.base_any2vec.BaseAny2VecModel</a></td></tr>
<tr class="memitem:a708d9972ab8408dadc44d6dbb9023a38 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_a708d9972ab8408dadc44d6dbb9023a38"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a708d9972ab8408dadc44d6dbb9023a38">vector_size</a></td></tr>
<tr class="separator:a708d9972ab8408dadc44d6dbb9023a38 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5bac75f2674d005b66f096fb6603151 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_aa5bac75f2674d005b66f096fb6603151"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#aa5bac75f2674d005b66f096fb6603151">workers</a></td></tr>
<tr class="separator:aa5bac75f2674d005b66f096fb6603151 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ce3a4a004446fc854197ae769de296f inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_a0ce3a4a004446fc854197ae769de296f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a0ce3a4a004446fc854197ae769de296f">epochs</a></td></tr>
<tr class="separator:a0ce3a4a004446fc854197ae769de296f inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb97a5e667d1efdbc149790ee727c186 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_acb97a5e667d1efdbc149790ee727c186"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#acb97a5e667d1efdbc149790ee727c186">train_count</a></td></tr>
<tr class="separator:acb97a5e667d1efdbc149790ee727c186 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e87ccc59ad62cc47ea80af5beae7a80 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_a5e87ccc59ad62cc47ea80af5beae7a80"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a5e87ccc59ad62cc47ea80af5beae7a80">total_train_time</a></td></tr>
<tr class="separator:a5e87ccc59ad62cc47ea80af5beae7a80 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab51030aec82b81f33a405ddf73e970b5 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_ab51030aec82b81f33a405ddf73e970b5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#ab51030aec82b81f33a405ddf73e970b5">batch_words</a></td></tr>
<tr class="separator:ab51030aec82b81f33a405ddf73e970b5 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a345fa8c902bbfa6c63ce5e686d7354c4 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_a345fa8c902bbfa6c63ce5e686d7354c4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a345fa8c902bbfa6c63ce5e686d7354c4">model_trimmed_post_training</a></td></tr>
<tr class="separator:a345fa8c902bbfa6c63ce5e686d7354c4 inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bae56911ed3cc9d956035ed2ff6922b inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_a5bae56911ed3cc9d956035ed2ff6922b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a5bae56911ed3cc9d956035ed2ff6922b">callbacks</a></td></tr>
<tr class="separator:a5bae56911ed3cc9d956035ed2ff6922b inherit pub_attribs_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-methods" name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:a22066c16eb4f314c3481929d08bbb735" id="r_a22066c16eb4f314c3481929d08bbb735"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a22066c16eb4f314c3481929d08bbb735">_do_train_epoch</a> (self, corpus_file, thread_id, <a class="el" href="__lapack__subroutines_8h.html#ac5c1dfc0f77d6570b83bf10cfe850d4e">offset</a>, cython_vocab, thread_private_mem, cur_epoch, total_examples=None, total_words=None, **kwargs)</td></tr>
<tr class="separator:a22066c16eb4f314c3481929d08bbb735"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a697958bacce4d17a2be3adbf5cba1e32" id="r_a697958bacce4d17a2be3adbf5cba1e32"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a697958bacce4d17a2be3adbf5cba1e32">_do_train_job</a> (self, sentences, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#aabcca7460d56cd4ac218f01cce509d5e">alpha</a>, inits)</td></tr>
<tr class="separator:a697958bacce4d17a2be3adbf5cba1e32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87447afbf7428f59abd8f8c5216a0b67" id="r_a87447afbf7428f59abd8f8c5216a0b67"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#a87447afbf7428f59abd8f8c5216a0b67">_clear_post_train</a> (self)</td></tr>
<tr class="separator:a87447afbf7428f59abd8f8c5216a0b67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aadc835e653038b934b64b38256b8dc8a" id="r_aadc835e653038b934b64b38256b8dc8a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#aadc835e653038b934b64b38256b8dc8a">_set_train_params</a> (self, **kwargs)</td></tr>
<tr class="separator:aadc835e653038b934b64b38256b8dc8a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2e3146bf45aa485d2b46a9e3bc3dfe5" id="r_ab2e3146bf45aa485d2b46a9e3bc3dfe5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1word2vec_1_1_word2_vec.html#ab2e3146bf45aa485d2b46a9e3bc3dfe5">_minimize_model</a> (self, save_syn1=False, save_syn1neg=False, save_vectors_lockf=False)</td></tr>
<tr class="separator:ab2e3146bf45aa485d2b46a9e3bc3dfe5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html">gensim.models.base_any2vec.BaseWordEmbeddingsModel</a></td></tr>
<tr class="memitem:ad760c024f2e7e09ad6b6f06a065af63d inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ad760c024f2e7e09ad6b6f06a065af63d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ad760c024f2e7e09ad6b6f06a065af63d">_get_job_params</a> (self, cur_epoch)</td></tr>
<tr class="separator:ad760c024f2e7e09ad6b6f06a065af63d inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8e9efad9e3fd285a7f62ca9b23d48a4 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_ac8e9efad9e3fd285a7f62ca9b23d48a4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ac8e9efad9e3fd285a7f62ca9b23d48a4">_update_job_params</a> (self, job_params, epoch_progress, cur_epoch)</td></tr>
<tr class="separator:ac8e9efad9e3fd285a7f62ca9b23d48a4 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0072d7a83a39673bb83900e54fee6687 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a0072d7a83a39673bb83900e54fee6687"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a0072d7a83a39673bb83900e54fee6687">_get_thread_working_mem</a> (self)</td></tr>
<tr class="separator:a0072d7a83a39673bb83900e54fee6687 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61bcfb159459be0ffa9812ae7026c82d inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a61bcfb159459be0ffa9812ae7026c82d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a61bcfb159459be0ffa9812ae7026c82d">_raw_word_count</a> (self, job)</td></tr>
<tr class="separator:a61bcfb159459be0ffa9812ae7026c82d inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4dec6d98ff5e7d29749f952da49c772f inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a4dec6d98ff5e7d29749f952da49c772f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a4dec6d98ff5e7d29749f952da49c772f">_check_training_sanity</a> (self, <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#aa9d08186dc167abf54467f0a72baa6fb">epochs</a>=None, total_examples=None, total_words=None, **kwargs)</td></tr>
<tr class="separator:a4dec6d98ff5e7d29749f952da49c772f inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acef13a6af25dd9a50ad48f360ea08f16 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_acef13a6af25dd9a50ad48f360ea08f16"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#acef13a6af25dd9a50ad48f360ea08f16">_log_progress</a> (self, job_queue, progress_queue, cur_epoch, example_count, total_examples, raw_word_count, total_words, trained_word_count, elapsed)</td></tr>
<tr class="separator:acef13a6af25dd9a50ad48f360ea08f16 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a747f288af7421e90519d9a3eec30f477 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_a747f288af7421e90519d9a3eec30f477"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a747f288af7421e90519d9a3eec30f477">_log_epoch_end</a> (self, cur_epoch, example_count, total_examples, raw_word_count, total_words, trained_word_count, elapsed, is_corpus_file_mode)</td></tr>
<tr class="separator:a747f288af7421e90519d9a3eec30f477 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea97d18f55dbf2bb405d4567e2fa18e8 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model" id="r_aea97d18f55dbf2bb405d4567e2fa18e8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#aea97d18f55dbf2bb405d4567e2fa18e8">_log_train_end</a> (self, raw_word_count, trained_word_count, total_elapsed, job_tally)</td></tr>
<tr class="separator:aea97d18f55dbf2bb405d4567e2fa18e8 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html">gensim.models.base_any2vec.BaseAny2VecModel</a></td></tr>
<tr class="memitem:a1c3a4a2b77289214e2e0dffa50b48456 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_a1c3a4a2b77289214e2e0dffa50b48456"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a1c3a4a2b77289214e2e0dffa50b48456">_check_input_data_sanity</a> (self, data_iterable=None, corpus_file=None)</td></tr>
<tr class="separator:a1c3a4a2b77289214e2e0dffa50b48456 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a36f6119dc89ca54cdcfae610ee18841b inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_a36f6119dc89ca54cdcfae610ee18841b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a36f6119dc89ca54cdcfae610ee18841b">_worker_loop_corpusfile</a> (self, corpus_file, thread_id, <a class="el" href="__lapack__subroutines_8h.html#ac5c1dfc0f77d6570b83bf10cfe850d4e">offset</a>, cython_vocab, progress_queue, cur_epoch=0, total_examples=None, total_words=None, **kwargs)</td></tr>
<tr class="separator:a36f6119dc89ca54cdcfae610ee18841b inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5ceb0debba62f6b8d93364e2db8c330 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_af5ceb0debba62f6b8d93364e2db8c330"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#af5ceb0debba62f6b8d93364e2db8c330">_worker_loop</a> (self, job_queue, progress_queue)</td></tr>
<tr class="separator:af5ceb0debba62f6b8d93364e2db8c330 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63b5bb423be9193ce4b2e6742a64d63b inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_a63b5bb423be9193ce4b2e6742a64d63b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a63b5bb423be9193ce4b2e6742a64d63b">_job_producer</a> (self, data_iterator, job_queue, cur_epoch=0, total_examples=None, total_words=None)</td></tr>
<tr class="separator:a63b5bb423be9193ce4b2e6742a64d63b inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1824be09b9d7f1e9d66529c25dcac215 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_a1824be09b9d7f1e9d66529c25dcac215"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a1824be09b9d7f1e9d66529c25dcac215">_log_epoch_progress</a> (self, progress_queue=None, job_queue=None, cur_epoch=0, total_examples=None, total_words=None, report_delay=1.0, is_corpus_file_mode=None)</td></tr>
<tr class="separator:a1824be09b9d7f1e9d66529c25dcac215 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c62d2b75a15603ec5a874823119be32 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_a1c62d2b75a15603ec5a874823119be32"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a1c62d2b75a15603ec5a874823119be32">_train_epoch_corpusfile</a> (self, corpus_file, cur_epoch=0, total_examples=None, total_words=None, **kwargs)</td></tr>
<tr class="separator:a1c62d2b75a15603ec5a874823119be32 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adaf2884199e3dd10838bf8662e2df195 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model" id="r_adaf2884199e3dd10838bf8662e2df195"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#adaf2884199e3dd10838bf8662e2df195">_train_epoch</a> (self, data_iterable, cur_epoch=0, total_examples=None, total_words=None, queue_factor=2, report_delay=1.0)</td></tr>
<tr class="separator:adaf2884199e3dd10838bf8662e2df195 inherit pro_methods_classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_classgensim_1_1utils_1_1_save_load"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classgensim_1_1utils_1_1_save_load')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classgensim_1_1utils_1_1_save_load.html">gensim.utils.SaveLoad</a></td></tr>
<tr class="memitem:ace7b79d8870c44c2bab0d590a5aca91e inherit pro_methods_classgensim_1_1utils_1_1_save_load" id="r_ace7b79d8870c44c2bab0d590a5aca91e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1utils_1_1_save_load.html#ace7b79d8870c44c2bab0d590a5aca91e">_load_specials</a> (self, fname, mmap, compress, subname)</td></tr>
<tr class="separator:ace7b79d8870c44c2bab0d590a5aca91e inherit pro_methods_classgensim_1_1utils_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd9faa42ba3aae8f0a175418889d425c inherit pro_methods_classgensim_1_1utils_1_1_save_load" id="r_acd9faa42ba3aae8f0a175418889d425c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1utils_1_1_save_load.html#acd9faa42ba3aae8f0a175418889d425c">_smart_save</a> (self, fname, separately=None, sep_limit=10 *1024 **2, ignore=frozenset(), pickle_protocol=2)</td></tr>
<tr class="separator:acd9faa42ba3aae8f0a175418889d425c inherit pro_methods_classgensim_1_1utils_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bae38a76fa8264d2c8759b9d40a6f5c inherit pro_methods_classgensim_1_1utils_1_1_save_load" id="r_a4bae38a76fa8264d2c8759b9d40a6f5c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1utils_1_1_save_load.html#a4bae38a76fa8264d2c8759b9d40a6f5c">_save_specials</a> (self, fname, separately, sep_limit, ignore, pickle_protocol, compress, subname)</td></tr>
<tr class="separator:a4bae38a76fa8264d2c8759b9d40a6f5c inherit pro_methods_classgensim_1_1utils_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="inherited" name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pro_static_methods_classgensim_1_1utils_1_1_save_load"><td colspan="2" onclick="javascript:toggleInherit('pro_static_methods_classgensim_1_1utils_1_1_save_load')"><img src="closed.png" alt="-"/>&#160;Static Protected Member Functions inherited from <a class="el" href="classgensim_1_1utils_1_1_save_load.html">gensim.utils.SaveLoad</a></td></tr>
<tr class="memitem:a6cf051b348407267110444260535d143 inherit pro_static_methods_classgensim_1_1utils_1_1_save_load" id="r_a6cf051b348407267110444260535d143"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1utils_1_1_save_load.html#a6cf051b348407267110444260535d143">_adapt_by_suffix</a> (fname)</td></tr>
<tr class="separator:a6cf051b348407267110444260535d143 inherit pro_static_methods_classgensim_1_1utils_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Train, use and evaluate neural networks described in https://code.google.com/p/word2vec/.

Once you're finished training a model (=no more updates, only querying)
store and use only the :class:`~gensim.models.keyedvectors.KeyedVectors` instance in `self.wv` to reduce memory.

The model can be stored/loaded via its :meth:`~gensim.models.word2vec.Word2Vec.save` and
:meth:`~gensim.models.word2vec.Word2Vec.load` methods.

The trained word vectors can also be stored/loaded from a format compatible with the
original word2vec implementation via `self.wv.save_word2vec_format`
and :meth:`gensim.models.keyedvectors.KeyedVectors.load_word2vec_format`.

Some important attributes are the following:

Attributes
----------
wv : :class:`~gensim.models.keyedvectors.Word2VecKeyedVectors`
    This object essentially contains the mapping between words and embeddings. After training, it can be used
    directly to query those embeddings in various ways. See the module level docstring for examples.

vocabulary : :class:`~gensim.models.word2vec.Word2VecVocab`
    This object represents the vocabulary (sometimes called Dictionary in gensim) of the model.
    Besides keeping track of all unique words, this object provides extra functionality, such as
    constructing a huffman tree (frequent words are closer to the root), or discarding extremely rare words.

trainables : :class:`~gensim.models.word2vec.Word2VecTrainables`
    This object represents the inner shallow neural network used to train the embeddings. The semantics of the
    network differ slightly in the two available training modes (CBOW or SG) but you can think of it as a NN with
    a single projection and hidden layer which we train on the corpus. The weights are then used as our embeddings
    (which means that the size of the hidden layer is equal to the number of features `self.size`).</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a74120a77ebe63940fb8692cf3cc4d536" name="a74120a77ebe63940fb8692cf3cc4d536"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74120a77ebe63940fb8692cf3cc4d536">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>corpus_file</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>size</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.025</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>window</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_count</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_vocab_size</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample</em> = <code>1e-3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>seed</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>workers</em> = <code>3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_alpha</em> = <code>0.0001</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sg</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hs</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>negative</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ns_exponent</em> = <code>0.75</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cbow_mean</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hashfxn</em> = <code>hash</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>iter</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>null_word</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>trim_rule</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sorted_vocab</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_words</em> = <code>MAX_WORDS_IN_BATCH</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>compute_loss</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>callbacks</em> = <code>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_final_vocab</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Parameters
----------
sentences : iterable of iterables, optional
    The `sentences` iterable can be simply a list of lists of tokens, but for larger corpora,
    consider an iterable that streams the sentences directly from disk/network.
    See :class:`~gensim.models.word2vec.BrownCorpus`, :class:`~gensim.models.word2vec.Text8Corpus`
    or :class:`~gensim.models.word2vec.LineSentence` in :mod:`~gensim.models.word2vec` module for such examples.
    See also the `tutorial on data streaming in Python
    &lt;https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/&gt;`_.
    If you don't supply `sentences`, the model is left uninitialized -- use if you plan to initialize it
    in some other way.
corpus_file : str, optional
    Path to a corpus file in :class:`~gensim.models.word2vec.LineSentence` format.
    You may use this argument instead of `sentences` to get performance boost. Only one of `sentences` or
    `corpus_file` arguments need to be passed (or none of them, in that case, the model is left uninitialized).
size : int, optional
    Dimensionality of the word vectors.
window : int, optional
    Maximum distance between the current and predicted word within a sentence.
min_count : int, optional
    Ignores all words with total frequency lower than this.
workers : int, optional
    Use these many worker threads to train the model (=faster training with multicore machines).
sg : {0, 1}, optional
    Training algorithm: 1 for skip-gram; otherwise CBOW.
hs : {0, 1}, optional
    If 1, hierarchical softmax will be used for model training.
    If 0, and `negative` is non-zero, negative sampling will be used.
negative : int, optional
    If &gt; 0, negative sampling will be used, the int for negative specifies how many "noise words"
    should be drawn (usually between 5-20).
    If set to 0, no negative sampling is used.
ns_exponent : float, optional
    The exponent used to shape the negative sampling distribution. A value of 1.0 samples exactly in proportion
    to the frequencies, 0.0 samples all words equally, while a negative value samples low-frequency words more
    than high-frequency words. The popular default value of 0.75 was chosen by the original Word2Vec paper.
    More recently, in https://arxiv.org/abs/1804.04212, Caselles-Dupré, Lesaint, &amp; Royo-Letelier suggest that
    other values may perform better for recommendation applications.
cbow_mean : {0, 1}, optional
    If 0, use the sum of the context word vectors. If 1, use the mean, only applies when cbow is used.
alpha : float, optional
    The initial learning rate.
min_alpha : float, optional
    Learning rate will linearly drop to `min_alpha` as training progresses.
seed : int, optional
    Seed for the random number generator. Initial vectors for each word are seeded with a hash of
    the concatenation of word + `str(seed)`. Note that for a fully deterministically-reproducible run,
    you must also limit the model to a single worker thread (`workers=1`), to eliminate ordering jitter
    from OS thread scheduling. (In Python 3, reproducibility between interpreter launches also requires
    use of the `PYTHONHASHSEED` environment variable to control hash randomization).
max_vocab_size : int, optional
    Limits the RAM during vocabulary building; if there are more unique
    words than this, then prune the infrequent ones. Every 10 million word types need about 1GB of RAM.
    Set to `None` for no limit.
max_final_vocab : int, optional
    Limits the vocab to a target vocab size by automatically picking a matching min_count. If the specified
    min_count is more than the calculated min_count, the specified min_count will be used.
    Set to `None` if not required.
sample : float, optional
    The threshold for configuring which higher-frequency words are randomly downsampled,
    useful range is (0, 1e-5).
hashfxn : function, optional
    Hash function to use to randomly initialize weights, for increased training reproducibility.
iter : int, optional
    Number of iterations (epochs) over the corpus.
trim_rule : function, optional
    Vocabulary trimming rule, specifies whether certain words should remain in the vocabulary,
    be trimmed away, or handled using the default (discard if word count &lt; min_count).
    Can be None (min_count will be used, look to :func:`~gensim.utils.keep_vocab_item`),
    or a callable that accepts parameters (word, count, min_count) and returns either
    :attr:`gensim.utils.RULE_DISCARD`, :attr:`gensim.utils.RULE_KEEP` or :attr:`gensim.utils.RULE_DEFAULT`.
    The rule, if given, is only used to prune vocabulary during build_vocab() and is not stored as part of the
    model.

    The input parameters are of the following types:
        * `word` (str) - the word we are examining
        * `count` (int) - the word's frequency count in the corpus
        * `min_count` (int) - the minimum count threshold.
sorted_vocab : {0, 1}, optional
    If 1, sort the vocabulary by descending frequency before assigning word indexes.
    See :meth:`~gensim.models.word2vec.Word2VecVocab.sort_vocab()`.
batch_words : int, optional
    Target size (in words) for batches of examples passed to worker threads (and
    thus cython routines).(Larger batches will be passed if individual
    texts are longer than 10000 words, but the standard cython code truncates to that maximum.)
compute_loss: bool, optional
    If True, computes and stores loss value which can be retrieved using
    :meth:`~gensim.models.word2vec.Word2Vec.get_latest_training_loss`.
callbacks : iterable of :class:`~gensim.models.callbacks.CallbackAny2Vec`, optional
    Sequence of callbacks to be executed at specific stages during training.

Examples
--------
Initialize and train a :class:`~gensim.models.word2vec.Word2Vec` model

.. sourcecode:: pycon

    &gt;&gt;&gt; from gensim.models import Word2Vec
    &gt;&gt;&gt; sentences = [["cat", "say", "meow"], ["dog", "say", "woof"]]
    &gt;&gt;&gt; model = Word2Vec(sentences, min_count=1)</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#aa741cbba77a2d9c6d19829e635a2a8d5">gensim.models.base_any2vec.BaseWordEmbeddingsModel</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  481</span>                 max_final_vocab=<span class="keywordtype">None</span>):</div>
<div class="line"><span class="lineno">  482</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  483</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  484</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  485</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  486</span><span class="stringliteral">        sentences : iterable of iterables, optional</span></div>
<div class="line"><span class="lineno">  487</span><span class="stringliteral">            The `sentences` iterable can be simply a list of lists of tokens, but for larger corpora,</span></div>
<div class="line"><span class="lineno">  488</span><span class="stringliteral">            consider an iterable that streams the sentences directly from disk/network.</span></div>
<div class="line"><span class="lineno">  489</span><span class="stringliteral">            See :class:`~gensim.models.word2vec.BrownCorpus`, :class:`~gensim.models.word2vec.Text8Corpus`</span></div>
<div class="line"><span class="lineno">  490</span><span class="stringliteral">            or :class:`~gensim.models.word2vec.LineSentence` in :mod:`~gensim.models.word2vec` module for such examples.</span></div>
<div class="line"><span class="lineno">  491</span><span class="stringliteral">            See also the `tutorial on data streaming in Python</span></div>
<div class="line"><span class="lineno">  492</span><span class="stringliteral">            &lt;https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/&gt;`_.</span></div>
<div class="line"><span class="lineno">  493</span><span class="stringliteral">            If you don&#39;t supply `sentences`, the model is left uninitialized -- use if you plan to initialize it</span></div>
<div class="line"><span class="lineno">  494</span><span class="stringliteral">            in some other way.</span></div>
<div class="line"><span class="lineno">  495</span><span class="stringliteral">        corpus_file : str, optional</span></div>
<div class="line"><span class="lineno">  496</span><span class="stringliteral">            Path to a corpus file in :class:`~gensim.models.word2vec.LineSentence` format.</span></div>
<div class="line"><span class="lineno">  497</span><span class="stringliteral">            You may use this argument instead of `sentences` to get performance boost. Only one of `sentences` or</span></div>
<div class="line"><span class="lineno">  498</span><span class="stringliteral">            `corpus_file` arguments need to be passed (or none of them, in that case, the model is left uninitialized).</span></div>
<div class="line"><span class="lineno">  499</span><span class="stringliteral">        size : int, optional</span></div>
<div class="line"><span class="lineno">  500</span><span class="stringliteral">            Dimensionality of the word vectors.</span></div>
<div class="line"><span class="lineno">  501</span><span class="stringliteral">        window : int, optional</span></div>
<div class="line"><span class="lineno">  502</span><span class="stringliteral">            Maximum distance between the current and predicted word within a sentence.</span></div>
<div class="line"><span class="lineno">  503</span><span class="stringliteral">        min_count : int, optional</span></div>
<div class="line"><span class="lineno">  504</span><span class="stringliteral">            Ignores all words with total frequency lower than this.</span></div>
<div class="line"><span class="lineno">  505</span><span class="stringliteral">        workers : int, optional</span></div>
<div class="line"><span class="lineno">  506</span><span class="stringliteral">            Use these many worker threads to train the model (=faster training with multicore machines).</span></div>
<div class="line"><span class="lineno">  507</span><span class="stringliteral">        sg : {0, 1}, optional</span></div>
<div class="line"><span class="lineno">  508</span><span class="stringliteral">            Training algorithm: 1 for skip-gram; otherwise CBOW.</span></div>
<div class="line"><span class="lineno">  509</span><span class="stringliteral">        hs : {0, 1}, optional</span></div>
<div class="line"><span class="lineno">  510</span><span class="stringliteral">            If 1, hierarchical softmax will be used for model training.</span></div>
<div class="line"><span class="lineno">  511</span><span class="stringliteral">            If 0, and `negative` is non-zero, negative sampling will be used.</span></div>
<div class="line"><span class="lineno">  512</span><span class="stringliteral">        negative : int, optional</span></div>
<div class="line"><span class="lineno">  513</span><span class="stringliteral">            If &gt; 0, negative sampling will be used, the int for negative specifies how many &quot;noise words&quot;</span></div>
<div class="line"><span class="lineno">  514</span><span class="stringliteral">            should be drawn (usually between 5-20).</span></div>
<div class="line"><span class="lineno">  515</span><span class="stringliteral">            If set to 0, no negative sampling is used.</span></div>
<div class="line"><span class="lineno">  516</span><span class="stringliteral">        ns_exponent : float, optional</span></div>
<div class="line"><span class="lineno">  517</span><span class="stringliteral">            The exponent used to shape the negative sampling distribution. A value of 1.0 samples exactly in proportion</span></div>
<div class="line"><span class="lineno">  518</span><span class="stringliteral">            to the frequencies, 0.0 samples all words equally, while a negative value samples low-frequency words more</span></div>
<div class="line"><span class="lineno">  519</span><span class="stringliteral">            than high-frequency words. The popular default value of 0.75 was chosen by the original Word2Vec paper.</span></div>
<div class="line"><span class="lineno">  520</span><span class="stringliteral">            More recently, in https://arxiv.org/abs/1804.04212, Caselles-Dupré, Lesaint, &amp; Royo-Letelier suggest that</span></div>
<div class="line"><span class="lineno">  521</span><span class="stringliteral">            other values may perform better for recommendation applications.</span></div>
<div class="line"><span class="lineno">  522</span><span class="stringliteral">        cbow_mean : {0, 1}, optional</span></div>
<div class="line"><span class="lineno">  523</span><span class="stringliteral">            If 0, use the sum of the context word vectors. If 1, use the mean, only applies when cbow is used.</span></div>
<div class="line"><span class="lineno">  524</span><span class="stringliteral">        alpha : float, optional</span></div>
<div class="line"><span class="lineno">  525</span><span class="stringliteral">            The initial learning rate.</span></div>
<div class="line"><span class="lineno">  526</span><span class="stringliteral">        min_alpha : float, optional</span></div>
<div class="line"><span class="lineno">  527</span><span class="stringliteral">            Learning rate will linearly drop to `min_alpha` as training progresses.</span></div>
<div class="line"><span class="lineno">  528</span><span class="stringliteral">        seed : int, optional</span></div>
<div class="line"><span class="lineno">  529</span><span class="stringliteral">            Seed for the random number generator. Initial vectors for each word are seeded with a hash of</span></div>
<div class="line"><span class="lineno">  530</span><span class="stringliteral">            the concatenation of word + `str(seed)`. Note that for a fully deterministically-reproducible run,</span></div>
<div class="line"><span class="lineno">  531</span><span class="stringliteral">            you must also limit the model to a single worker thread (`workers=1`), to eliminate ordering jitter</span></div>
<div class="line"><span class="lineno">  532</span><span class="stringliteral">            from OS thread scheduling. (In Python 3, reproducibility between interpreter launches also requires</span></div>
<div class="line"><span class="lineno">  533</span><span class="stringliteral">            use of the `PYTHONHASHSEED` environment variable to control hash randomization).</span></div>
<div class="line"><span class="lineno">  534</span><span class="stringliteral">        max_vocab_size : int, optional</span></div>
<div class="line"><span class="lineno">  535</span><span class="stringliteral">            Limits the RAM during vocabulary building; if there are more unique</span></div>
<div class="line"><span class="lineno">  536</span><span class="stringliteral">            words than this, then prune the infrequent ones. Every 10 million word types need about 1GB of RAM.</span></div>
<div class="line"><span class="lineno">  537</span><span class="stringliteral">            Set to `None` for no limit.</span></div>
<div class="line"><span class="lineno">  538</span><span class="stringliteral">        max_final_vocab : int, optional</span></div>
<div class="line"><span class="lineno">  539</span><span class="stringliteral">            Limits the vocab to a target vocab size by automatically picking a matching min_count. If the specified</span></div>
<div class="line"><span class="lineno">  540</span><span class="stringliteral">            min_count is more than the calculated min_count, the specified min_count will be used.</span></div>
<div class="line"><span class="lineno">  541</span><span class="stringliteral">            Set to `None` if not required.</span></div>
<div class="line"><span class="lineno">  542</span><span class="stringliteral">        sample : float, optional</span></div>
<div class="line"><span class="lineno">  543</span><span class="stringliteral">            The threshold for configuring which higher-frequency words are randomly downsampled,</span></div>
<div class="line"><span class="lineno">  544</span><span class="stringliteral">            useful range is (0, 1e-5).</span></div>
<div class="line"><span class="lineno">  545</span><span class="stringliteral">        hashfxn : function, optional</span></div>
<div class="line"><span class="lineno">  546</span><span class="stringliteral">            Hash function to use to randomly initialize weights, for increased training reproducibility.</span></div>
<div class="line"><span class="lineno">  547</span><span class="stringliteral">        iter : int, optional</span></div>
<div class="line"><span class="lineno">  548</span><span class="stringliteral">            Number of iterations (epochs) over the corpus.</span></div>
<div class="line"><span class="lineno">  549</span><span class="stringliteral">        trim_rule : function, optional</span></div>
<div class="line"><span class="lineno">  550</span><span class="stringliteral">            Vocabulary trimming rule, specifies whether certain words should remain in the vocabulary,</span></div>
<div class="line"><span class="lineno">  551</span><span class="stringliteral">            be trimmed away, or handled using the default (discard if word count &lt; min_count).</span></div>
<div class="line"><span class="lineno">  552</span><span class="stringliteral">            Can be None (min_count will be used, look to :func:`~gensim.utils.keep_vocab_item`),</span></div>
<div class="line"><span class="lineno">  553</span><span class="stringliteral">            or a callable that accepts parameters (word, count, min_count) and returns either</span></div>
<div class="line"><span class="lineno">  554</span><span class="stringliteral">            :attr:`gensim.utils.RULE_DISCARD`, :attr:`gensim.utils.RULE_KEEP` or :attr:`gensim.utils.RULE_DEFAULT`.</span></div>
<div class="line"><span class="lineno">  555</span><span class="stringliteral">            The rule, if given, is only used to prune vocabulary during build_vocab() and is not stored as part of the</span></div>
<div class="line"><span class="lineno">  556</span><span class="stringliteral">            model.</span></div>
<div class="line"><span class="lineno">  557</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  558</span><span class="stringliteral">            The input parameters are of the following types:</span></div>
<div class="line"><span class="lineno">  559</span><span class="stringliteral">                * `word` (str) - the word we are examining</span></div>
<div class="line"><span class="lineno">  560</span><span class="stringliteral">                * `count` (int) - the word&#39;s frequency count in the corpus</span></div>
<div class="line"><span class="lineno">  561</span><span class="stringliteral">                * `min_count` (int) - the minimum count threshold.</span></div>
<div class="line"><span class="lineno">  562</span><span class="stringliteral">        sorted_vocab : {0, 1}, optional</span></div>
<div class="line"><span class="lineno">  563</span><span class="stringliteral">            If 1, sort the vocabulary by descending frequency before assigning word indexes.</span></div>
<div class="line"><span class="lineno">  564</span><span class="stringliteral">            See :meth:`~gensim.models.word2vec.Word2VecVocab.sort_vocab()`.</span></div>
<div class="line"><span class="lineno">  565</span><span class="stringliteral">        batch_words : int, optional</span></div>
<div class="line"><span class="lineno">  566</span><span class="stringliteral">            Target size (in words) for batches of examples passed to worker threads (and</span></div>
<div class="line"><span class="lineno">  567</span><span class="stringliteral">            thus cython routines).(Larger batches will be passed if individual</span></div>
<div class="line"><span class="lineno">  568</span><span class="stringliteral">            texts are longer than 10000 words, but the standard cython code truncates to that maximum.)</span></div>
<div class="line"><span class="lineno">  569</span><span class="stringliteral">        compute_loss: bool, optional</span></div>
<div class="line"><span class="lineno">  570</span><span class="stringliteral">            If True, computes and stores loss value which can be retrieved using</span></div>
<div class="line"><span class="lineno">  571</span><span class="stringliteral">            :meth:`~gensim.models.word2vec.Word2Vec.get_latest_training_loss`.</span></div>
<div class="line"><span class="lineno">  572</span><span class="stringliteral">        callbacks : iterable of :class:`~gensim.models.callbacks.CallbackAny2Vec`, optional</span></div>
<div class="line"><span class="lineno">  573</span><span class="stringliteral">            Sequence of callbacks to be executed at specific stages during training.</span></div>
<div class="line"><span class="lineno">  574</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  575</span><span class="stringliteral">        Examples</span></div>
<div class="line"><span class="lineno">  576</span><span class="stringliteral">        --------</span></div>
<div class="line"><span class="lineno">  577</span><span class="stringliteral">        Initialize and train a :class:`~gensim.models.word2vec.Word2Vec` model</span></div>
<div class="line"><span class="lineno">  578</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  579</span><span class="stringliteral">        .. sourcecode:: pycon</span></div>
<div class="line"><span class="lineno">  580</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  581</span><span class="stringliteral">            &gt;&gt;&gt; from gensim.models import Word2Vec</span></div>
<div class="line"><span class="lineno">  582</span><span class="stringliteral">            &gt;&gt;&gt; sentences = [[&quot;cat&quot;, &quot;say&quot;, &quot;meow&quot;], [&quot;dog&quot;, &quot;say&quot;, &quot;woof&quot;]]</span></div>
<div class="line"><span class="lineno">  583</span><span class="stringliteral">            &gt;&gt;&gt; model = Word2Vec(sentences, min_count=1)</span></div>
<div class="line"><span class="lineno">  584</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  585</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  586</span>        self.max_final_vocab = max_final_vocab</div>
<div class="line"><span class="lineno">  587</span> </div>
<div class="line"><span class="lineno">  588</span>        self.callbacks = callbacks</div>
<div class="line"><span class="lineno">  589</span>        self.load = call_on_class_only</div>
<div class="line"><span class="lineno">  590</span> </div>
<div class="line"><span class="lineno">  591</span>        self.wv = Word2VecKeyedVectors(size)</div>
<div class="line"><span class="lineno">  592</span>        self.vocabulary = Word2VecVocab(</div>
<div class="line"><span class="lineno">  593</span>            max_vocab_size=max_vocab_size, min_count=min_count, sample=sample, sorted_vocab=bool(sorted_vocab),</div>
<div class="line"><span class="lineno">  594</span>            null_word=null_word, max_final_vocab=max_final_vocab, ns_exponent=ns_exponent)</div>
<div class="line"><span class="lineno">  595</span>        self.trainables = Word2VecTrainables(seed=seed, vector_size=size, hashfxn=hashfxn)</div>
<div class="line"><span class="lineno">  596</span> </div>
<div class="line"><span class="lineno">  597</span>        super(Word2Vec, self).__init__(</div>
<div class="line"><span class="lineno">  598</span>            sentences=sentences, corpus_file=corpus_file, workers=workers, vector_size=size, epochs=iter,</div>
<div class="line"><span class="lineno">  599</span>            callbacks=callbacks, batch_words=batch_words, trim_rule=trim_rule, sg=sg, alpha=alpha, window=window,</div>
<div class="line"><span class="lineno">  600</span>            seed=seed, hs=hs, negative=negative, cbow_mean=cbow_mean, min_alpha=min_alpha, compute_loss=compute_loss)</div>
<div class="line"><span class="lineno">  601</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a43f54d1e86ecf7cb5b1616267bbafa40" name="a43f54d1e86ecf7cb5b1616267bbafa40"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a43f54d1e86ecf7cb5b1616267bbafa40">&#9670;&#160;</a></span>__contains__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.__contains__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use `self.wv.__contains__` instead.
Refer to the documentation for :meth:`~gensim.models.keyedvectors.Word2VecKeyedVectors.__contains__`.</pre> <div class="fragment"><div class="line"><span class="lineno">  935</span>    <span class="keyword">def </span>__contains__(self, word):</div>
<div class="line"><span class="lineno">  936</span>        <span class="stringliteral">&quot;&quot;&quot;Deprecated. Use `self.wv.__contains__` instead.</span></div>
<div class="line"><span class="lineno">  937</span><span class="stringliteral">        Refer to the documentation for :meth:`~gensim.models.keyedvectors.Word2VecKeyedVectors.__contains__`.</span></div>
<div class="line"><span class="lineno">  938</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  939</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  940</span>        <span class="keywordflow">return</span> self.wv.__contains__(word)</div>
<div class="line"><span class="lineno">  941</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a62a800fade15ba778f976bae2ac5318d" name="a62a800fade15ba778f976bae2ac5318d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a62a800fade15ba778f976bae2ac5318d">&#9670;&#160;</a></span>__getitem__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.__getitem__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>words</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use `self.wv.__getitem__` instead.
Refer to the documentation for :meth:`~gensim.models.keyedvectors.Word2VecKeyedVectors.__getitem__`.</pre> <div class="fragment"><div class="line"><span class="lineno">  927</span>    <span class="keyword">def </span>__getitem__(self, words):</div>
<div class="line"><span class="lineno">  928</span>        <span class="stringliteral">&quot;&quot;&quot;Deprecated. Use `self.wv.__getitem__` instead.</span></div>
<div class="line"><span class="lineno">  929</span><span class="stringliteral">        Refer to the documentation for :meth:`~gensim.models.keyedvectors.Word2VecKeyedVectors.__getitem__`.</span></div>
<div class="line"><span class="lineno">  930</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  931</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  932</span>        <span class="keywordflow">return</span> self.wv.__getitem__(words)</div>
<div class="line"><span class="lineno">  933</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a201840cce09c98ed0fe106d26d385e04" name="a201840cce09c98ed0fe106d26d385e04"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a201840cce09c98ed0fe106d26d385e04">&#9670;&#160;</a></span>__str__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.__str__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Human readable representation of the model's state.

Returns
-------
str
    Human readable representation of the model's state, including the vocabulary size, vector size
    and learning rate.</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a1dc06aba8820578a0b7be4d2b66e774c">gensim.models.base_any2vec.BaseWordEmbeddingsModel</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1034</span>    <span class="keyword">def </span>__str__(self):</div>
<div class="line"><span class="lineno"> 1035</span>        <span class="stringliteral">&quot;&quot;&quot;Human readable representation of the model&#39;s state.</span></div>
<div class="line"><span class="lineno"> 1036</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1037</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno"> 1038</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno"> 1039</span><span class="stringliteral">        str</span></div>
<div class="line"><span class="lineno"> 1040</span><span class="stringliteral">            Human readable representation of the model&#39;s state, including the vocabulary size, vector size</span></div>
<div class="line"><span class="lineno"> 1041</span><span class="stringliteral">            and learning rate.</span></div>
<div class="line"><span class="lineno"> 1042</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1043</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1044</span>        <span class="keywordflow">return</span> <span class="stringliteral">&quot;%s(vocab=%s, size=%s, alpha=%s)&quot;</span> % (</div>
<div class="line"><span class="lineno"> 1045</span>            self.__class__.__name__, len(self.wv.index2word), self.wv.vector_size, self.alpha</div>
<div class="line"><span class="lineno"> 1046</span>        )</div>
<div class="line"><span class="lineno"> 1047</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a87447afbf7428f59abd8f8c5216a0b67" name="a87447afbf7428f59abd8f8c5216a0b67"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a87447afbf7428f59abd8f8c5216a0b67">&#9670;&#160;</a></span>_clear_post_train()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec._clear_post_train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Remove all L2-normalized word vectors from the model.</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a092bda584d374f781aaf3d82f43c8032">gensim.models.base_any2vec.BaseWordEmbeddingsModel</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  641</span>    <span class="keyword">def </span>_clear_post_train(self):</div>
<div class="line"><span class="lineno">  642</span>        <span class="stringliteral">&quot;&quot;&quot;Remove all L2-normalized word vectors from the model.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  643</span>        self.wv.vectors_norm = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  644</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a22066c16eb4f314c3481929d08bbb735" name="a22066c16eb4f314c3481929d08bbb735"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a22066c16eb4f314c3481929d08bbb735">&#9670;&#160;</a></span>_do_train_epoch()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec._do_train_epoch </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>corpus_file</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>thread_id</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cython_vocab</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>thread_private_mem</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cur_epoch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_examples</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_words</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#af2df459a0753d22f3778117e7adb01dd">gensim.models.base_any2vec.BaseAny2VecModel</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  603</span>                        total_examples=<span class="keywordtype">None</span>, total_words=<span class="keywordtype">None</span>, **kwargs):</div>
<div class="line"><span class="lineno">  604</span>        work, neu1 = thread_private_mem</div>
<div class="line"><span class="lineno">  605</span> </div>
<div class="line"><span class="lineno">  606</span>        <span class="keywordflow">if</span> self.sg:</div>
<div class="line"><span class="lineno">  607</span>            examples, tally, raw_tally = train_epoch_sg(self, corpus_file, offset, cython_vocab, cur_epoch,</div>
<div class="line"><span class="lineno">  608</span>                                                        total_examples, total_words, work, neu1, self.compute_loss)</div>
<div class="line"><span class="lineno">  609</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  610</span>            examples, tally, raw_tally = train_epoch_cbow(self, corpus_file, offset, cython_vocab, cur_epoch,</div>
<div class="line"><span class="lineno">  611</span>                                                          total_examples, total_words, work, neu1, self.compute_loss)</div>
<div class="line"><span class="lineno">  612</span> </div>
<div class="line"><span class="lineno">  613</span>        <span class="keywordflow">return</span> examples, tally, raw_tally</div>
<div class="line"><span class="lineno">  614</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a697958bacce4d17a2be3adbf5cba1e32" name="a697958bacce4d17a2be3adbf5cba1e32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a697958bacce4d17a2be3adbf5cba1e32">&#9670;&#160;</a></span>_do_train_job()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec._do_train_job </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inits</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Train the model on a single batch of sentences.

Parameters
----------
sentences : iterable of list of str
    Corpus chunk to be used in this training batch.
alpha : float
    The learning rate used in this batch.
inits : (np.ndarray, np.ndarray)
    Each worker threads private work memory.

Returns
-------
(int, int)
     2-tuple (effective word count after ignoring unknown words and sentence length trimming, total word count).</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a9c3fc464c0c07500f0835c2e8e51a041">gensim.models.base_any2vec.BaseWordEmbeddingsModel</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  615</span>    <span class="keyword">def </span>_do_train_job(self, sentences, alpha, inits):</div>
<div class="line"><span class="lineno">  616</span>        <span class="stringliteral">&quot;&quot;&quot;Train the model on a single batch of sentences.</span></div>
<div class="line"><span class="lineno">  617</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  618</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  619</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  620</span><span class="stringliteral">        sentences : iterable of list of str</span></div>
<div class="line"><span class="lineno">  621</span><span class="stringliteral">            Corpus chunk to be used in this training batch.</span></div>
<div class="line"><span class="lineno">  622</span><span class="stringliteral">        alpha : float</span></div>
<div class="line"><span class="lineno">  623</span><span class="stringliteral">            The learning rate used in this batch.</span></div>
<div class="line"><span class="lineno">  624</span><span class="stringliteral">        inits : (np.ndarray, np.ndarray)</span></div>
<div class="line"><span class="lineno">  625</span><span class="stringliteral">            Each worker threads private work memory.</span></div>
<div class="line"><span class="lineno">  626</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  627</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  628</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  629</span><span class="stringliteral">        (int, int)</span></div>
<div class="line"><span class="lineno">  630</span><span class="stringliteral">             2-tuple (effective word count after ignoring unknown words and sentence length trimming, total word count).</span></div>
<div class="line"><span class="lineno">  631</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  632</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  633</span>        work, neu1 = inits</div>
<div class="line"><span class="lineno">  634</span>        tally = 0</div>
<div class="line"><span class="lineno">  635</span>        <span class="keywordflow">if</span> self.sg:</div>
<div class="line"><span class="lineno">  636</span>            tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)</div>
<div class="line"><span class="lineno">  637</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  638</span>            tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)</div>
<div class="line"><span class="lineno">  639</span>        <span class="keywordflow">return</span> tally, self._raw_word_count(sentences)</div>
<div class="line"><span class="lineno">  640</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab2e3146bf45aa485d2b46a9e3bc3dfe5" name="ab2e3146bf45aa485d2b46a9e3bc3dfe5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab2e3146bf45aa485d2b46a9e3bc3dfe5">&#9670;&#160;</a></span>_minimize_model()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec._minimize_model </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>save_syn1</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>save_syn1neg</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>save_vectors_lockf</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1095</span>    <span class="keyword">def </span>_minimize_model(self, save_syn1=False, save_syn1neg=False, save_vectors_lockf=False):</div>
<div class="line"><span class="lineno"> 1096</span>        <span class="keywordflow">if</span> save_syn1 <span class="keywordflow">and</span> save_syn1neg <span class="keywordflow">and</span> save_vectors_lockf:</div>
<div class="line"><span class="lineno"> 1097</span>            <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno"> 1098</span>        <span class="keywordflow">if</span> hasattr(self.trainables, <span class="stringliteral">&#39;syn1&#39;</span>) <span class="keywordflow">and</span> <span class="keywordflow">not</span> save_syn1:</div>
<div class="line"><span class="lineno"> 1099</span>            del self.trainables.syn1</div>
<div class="line"><span class="lineno"> 1100</span>        <span class="keywordflow">if</span> hasattr(self.trainables, <span class="stringliteral">&#39;syn1neg&#39;</span>) <span class="keywordflow">and</span> <span class="keywordflow">not</span> save_syn1neg:</div>
<div class="line"><span class="lineno"> 1101</span>            del self.trainables.syn1neg</div>
<div class="line"><span class="lineno"> 1102</span>        <span class="keywordflow">if</span> hasattr(self.trainables, <span class="stringliteral">&#39;vectors_lockf&#39;</span>) <span class="keywordflow">and</span> <span class="keywordflow">not</span> save_vectors_lockf:</div>
<div class="line"><span class="lineno"> 1103</span>            del self.trainables.vectors_lockf</div>
<div class="line"><span class="lineno"> 1104</span>        self.model_trimmed_post_training = <span class="keyword">True</span></div>
<div class="line"><span class="lineno"> 1105</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aadc835e653038b934b64b38256b8dc8a" name="aadc835e653038b934b64b38256b8dc8a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aadc835e653038b934b64b38256b8dc8a">&#9670;&#160;</a></span>_set_train_params()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec._set_train_params </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Set model parameters required for training.</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#afe045add73be44541332719ca1bce124">gensim.models.base_any2vec.BaseWordEmbeddingsModel</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  645</span>    <span class="keyword">def </span>_set_train_params(self, **kwargs):</div>
<div class="line"><span class="lineno">  646</span>        <span class="keywordflow">if</span> <span class="stringliteral">&#39;compute_loss&#39;</span> <span class="keywordflow">in</span> kwargs:</div>
<div class="line"><span class="lineno">  647</span>            self.compute_loss = kwargs[<span class="stringliteral">&#39;compute_loss&#39;</span>]</div>
<div class="line"><span class="lineno">  648</span>        self.running_training_loss = 0</div>
<div class="line"><span class="lineno">  649</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af49d1f6c8bb6ac1c23a004919a284962" name="af49d1f6c8bb6ac1c23a004919a284962"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af49d1f6c8bb6ac1c23a004919a284962">&#9670;&#160;</a></span>accuracy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.accuracy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>questions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>restrict_vocab</em> = <code>30000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>most_similar</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>case_insensitive</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use `self.wv.accuracy` instead.
See :meth:`~gensim.models.word2vec.Word2VecKeyedVectors.accuracy`.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1026</span>    <span class="keyword">def </span>accuracy(self, questions, restrict_vocab=30000, most_similar=None, case_insensitive=True):</div>
<div class="line"><span class="lineno"> 1027</span>        <span class="stringliteral">&quot;&quot;&quot;Deprecated. Use `self.wv.accuracy` instead.</span></div>
<div class="line"><span class="lineno"> 1028</span><span class="stringliteral">        See :meth:`~gensim.models.word2vec.Word2VecKeyedVectors.accuracy`.</span></div>
<div class="line"><span class="lineno"> 1029</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1030</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1031</span>        most_similar = most_similar <span class="keywordflow">or</span> Word2VecKeyedVectors.most_similar</div>
<div class="line"><span class="lineno"> 1032</span>        <span class="keywordflow">return</span> self.wv.accuracy(questions, restrict_vocab, most_similar, case_insensitive)</div>
<div class="line"><span class="lineno"> 1033</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a01ffef0f127500d9637cb61d03245d5e" name="a01ffef0f127500d9637cb61d03245d5e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01ffef0f127500d9637cb61d03245d5e">&#9670;&#160;</a></span>clear_sims()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.clear_sims </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Remove all L2-normalized word vectors from the model, to free up memory.

You can recompute them later again using the :meth:`~gensim.models.word2vec.Word2Vec.init_sims` method.</pre> <div class="fragment"><div class="line"><span class="lineno">  858</span>    <span class="keyword">def </span>clear_sims(self):</div>
<div class="line"><span class="lineno">  859</span>        <span class="stringliteral">&quot;&quot;&quot;Remove all L2-normalized word vectors from the model, to free up memory.</span></div>
<div class="line"><span class="lineno">  860</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  861</span><span class="stringliteral">        You can recompute them later again using the :meth:`~gensim.models.word2vec.Word2Vec.init_sims` method.</span></div>
<div class="line"><span class="lineno">  862</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  863</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  864</span>        self.wv.vectors_norm = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  865</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a72d938f82ab91eb23dcf52224af5848d" name="a72d938f82ab91eb23dcf52224af5848d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a72d938f82ab91eb23dcf52224af5848d">&#9670;&#160;</a></span>delete_temporary_training_data()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.delete_temporary_training_data </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>replace_word_vectors_with_normalized</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Discard parameters that are used in training and scoring, to save memory.

Warnings
--------
Use only if you're sure you're done training a model.

Parameters
----------
replace_word_vectors_with_normalized : bool, optional
    If True, forget the original (not normalized) word vectors and only keep
    the L2-normalized word vectors, to save even more memory.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1048</span>    <span class="keyword">def </span>delete_temporary_training_data(self, replace_word_vectors_with_normalized=False):</div>
<div class="line"><span class="lineno"> 1049</span>        <span class="stringliteral">&quot;&quot;&quot;Discard parameters that are used in training and scoring, to save memory.</span></div>
<div class="line"><span class="lineno"> 1050</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1051</span><span class="stringliteral">        Warnings</span></div>
<div class="line"><span class="lineno"> 1052</span><span class="stringliteral">        --------</span></div>
<div class="line"><span class="lineno"> 1053</span><span class="stringliteral">        Use only if you&#39;re sure you&#39;re done training a model.</span></div>
<div class="line"><span class="lineno"> 1054</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1055</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno"> 1056</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno"> 1057</span><span class="stringliteral">        replace_word_vectors_with_normalized : bool, optional</span></div>
<div class="line"><span class="lineno"> 1058</span><span class="stringliteral">            If True, forget the original (not normalized) word vectors and only keep</span></div>
<div class="line"><span class="lineno"> 1059</span><span class="stringliteral">            the L2-normalized word vectors, to save even more memory.</span></div>
<div class="line"><span class="lineno"> 1060</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1061</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1062</span>        <span class="keywordflow">if</span> replace_word_vectors_with_normalized:</div>
<div class="line"><span class="lineno"> 1063</span>            self.init_sims(replace=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1064</span>        self._minimize_model()</div>
<div class="line"><span class="lineno"> 1065</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae97038d8795772d441574f8e2b35c334" name="ae97038d8795772d441574f8e2b35c334"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae97038d8795772d441574f8e2b35c334">&#9670;&#160;</a></span>get_latest_training_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.get_latest_training_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get current value of the training loss.

Returns
-------
float
    Current training loss.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1081</span>    <span class="keyword">def </span>get_latest_training_loss(self):</div>
<div class="line"><span class="lineno"> 1082</span>        <span class="stringliteral">&quot;&quot;&quot;Get current value of the training loss.</span></div>
<div class="line"><span class="lineno"> 1083</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1084</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno"> 1085</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno"> 1086</span><span class="stringliteral">        float</span></div>
<div class="line"><span class="lineno"> 1087</span><span class="stringliteral">            Current training loss.</span></div>
<div class="line"><span class="lineno"> 1088</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1089</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1090</span>        <span class="keywordflow">return</span> self.running_training_loss</div>
<div class="line"><span class="lineno"> 1091</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae98077330956bfd4549fb50fb8e3c4bd" name="ae98077330956bfd4549fb50fb8e3c4bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae98077330956bfd4549fb50fb8e3c4bd">&#9670;&#160;</a></span>init_sims()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.init_sims </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>replace</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use `self.wv.init_sims` instead.
See :meth:`~gensim.models.keyedvectors.Word2VecKeyedVectors.init_sims`.</pre> <div class="fragment"><div class="line"><span class="lineno">  985</span>    <span class="keyword">def </span>init_sims(self, replace=False):</div>
<div class="line"><span class="lineno">  986</span>        <span class="stringliteral">&quot;&quot;&quot;Deprecated. Use `self.wv.init_sims` instead.</span></div>
<div class="line"><span class="lineno">  987</span><span class="stringliteral">        See :meth:`~gensim.models.keyedvectors.Word2VecKeyedVectors.init_sims`.</span></div>
<div class="line"><span class="lineno">  988</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  989</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  990</span>        <span class="keywordflow">if</span> replace <span class="keywordflow">and</span> hasattr(self.trainables, <span class="stringliteral">&#39;syn1&#39;</span>):</div>
<div class="line"><span class="lineno">  991</span>            del self.trainables.syn1</div>
<div class="line"><span class="lineno">  992</span>        <span class="keywordflow">return</span> self.wv.init_sims(replace)</div>
<div class="line"><span class="lineno">  993</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac9a256ee7a869a0b17ab5a61057b8e45" name="ac9a256ee7a869a0b17ab5a61057b8e45"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac9a256ee7a869a0b17ab5a61057b8e45">&#9670;&#160;</a></span>intersect_word2vec_format()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.intersect_word2vec_format </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fname</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>lockf</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>binary</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>encoding</em> = <code>'utf8'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>unicode_errors</em> = <code>'strict'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Merge in an input-hidden weight matrix loaded from the original C word2vec-tool format,
where it intersects with the current vocabulary.

No words are added to the existing vocabulary, but intersecting words adopt the file's weights, and
non-intersecting words are left alone.

Parameters
----------
fname : str
    The file path to load the vectors from.
lockf : float, optional
    Lock-factor value to be set for any imported word-vectors; the
    default value of 0.0 prevents further updating of the vector during subsequent
    training. Use 1.0 to allow further training updates of merged vectors.
binary : bool, optional
    If True, `fname` is in the binary word2vec C format.
encoding : str, optional
    Encoding of `text` for `unicode` function (python2 only).
unicode_errors : str, optional
    Error handling behaviour, used as parameter for `unicode` function (python2 only).</pre> <div class="fragment"><div class="line"><span class="lineno">  866</span>    <span class="keyword">def </span>intersect_word2vec_format(self, fname, lockf=0.0, binary=False, encoding=&#39;utf8&#39;, unicode_errors=&#39;strict&#39;):</div>
<div class="line"><span class="lineno">  867</span>        <span class="stringliteral">&quot;&quot;&quot;Merge in an input-hidden weight matrix loaded from the original C word2vec-tool format,</span></div>
<div class="line"><span class="lineno">  868</span><span class="stringliteral">        where it intersects with the current vocabulary.</span></div>
<div class="line"><span class="lineno">  869</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  870</span><span class="stringliteral">        No words are added to the existing vocabulary, but intersecting words adopt the file&#39;s weights, and</span></div>
<div class="line"><span class="lineno">  871</span><span class="stringliteral">        non-intersecting words are left alone.</span></div>
<div class="line"><span class="lineno">  872</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  873</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  874</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  875</span><span class="stringliteral">        fname : str</span></div>
<div class="line"><span class="lineno">  876</span><span class="stringliteral">            The file path to load the vectors from.</span></div>
<div class="line"><span class="lineno">  877</span><span class="stringliteral">        lockf : float, optional</span></div>
<div class="line"><span class="lineno">  878</span><span class="stringliteral">            Lock-factor value to be set for any imported word-vectors; the</span></div>
<div class="line"><span class="lineno">  879</span><span class="stringliteral">            default value of 0.0 prevents further updating of the vector during subsequent</span></div>
<div class="line"><span class="lineno">  880</span><span class="stringliteral">            training. Use 1.0 to allow further training updates of merged vectors.</span></div>
<div class="line"><span class="lineno">  881</span><span class="stringliteral">        binary : bool, optional</span></div>
<div class="line"><span class="lineno">  882</span><span class="stringliteral">            If True, `fname` is in the binary word2vec C format.</span></div>
<div class="line"><span class="lineno">  883</span><span class="stringliteral">        encoding : str, optional</span></div>
<div class="line"><span class="lineno">  884</span><span class="stringliteral">            Encoding of `text` for `unicode` function (python2 only).</span></div>
<div class="line"><span class="lineno">  885</span><span class="stringliteral">        unicode_errors : str, optional</span></div>
<div class="line"><span class="lineno">  886</span><span class="stringliteral">            Error handling behaviour, used as parameter for `unicode` function (python2 only).</span></div>
<div class="line"><span class="lineno">  887</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  888</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  889</span>        overlap_count = 0</div>
<div class="line"><span class="lineno">  890</span>        logger.info(<span class="stringliteral">&quot;loading projection weights from %s&quot;</span>, fname)</div>
<div class="line"><span class="lineno">  891</span>        <span class="keyword">with</span> utils.open(fname, <span class="stringliteral">&#39;rb&#39;</span>) <span class="keyword">as</span> fin:</div>
<div class="line"><span class="lineno">  892</span>            header = utils.to_unicode(fin.readline(), encoding=encoding)</div>
<div class="line"><span class="lineno">  893</span>            vocab_size, vector_size = (int(x) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> header.split())  <span class="comment"># throws for invalid file format</span></div>
<div class="line"><span class="lineno">  894</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> vector_size == self.wv.vector_size:</div>
<div class="line"><span class="lineno">  895</span>                <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;incompatible vector size %d in file %s&quot;</span> % (vector_size, fname))</div>
<div class="line"><span class="lineno">  896</span>                <span class="comment"># TOCONSIDER: maybe mismatched vectors still useful enough to merge (truncating/padding)?</span></div>
<div class="line"><span class="lineno">  897</span>            <span class="keywordflow">if</span> binary:</div>
<div class="line"><span class="lineno">  898</span>                binary_len = <a class="code hl_namespace" href="namespacedtype.html">dtype</a>(REAL).itemsize * vector_size</div>
<div class="line"><span class="lineno">  899</span>                <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(vocab_size):</div>
<div class="line"><span class="lineno">  900</span>                    <span class="comment"># mixed text and binary: read text first, then binary</span></div>
<div class="line"><span class="lineno">  901</span>                    word = []</div>
<div class="line"><span class="lineno">  902</span>                    <span class="keywordflow">while</span> <span class="keyword">True</span>:</div>
<div class="line"><span class="lineno">  903</span>                        ch = fin.read(1)</div>
<div class="line"><span class="lineno">  904</span>                        <span class="keywordflow">if</span> ch == b<span class="stringliteral">&#39; &#39;</span>:</div>
<div class="line"><span class="lineno">  905</span>                            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  906</span>                        <span class="keywordflow">if</span> ch != b<span class="stringliteral">&#39;\n&#39;</span>:  <span class="comment"># ignore newlines in front of words (some binary files have)</span></div>
<div class="line"><span class="lineno">  907</span>                            word.append(ch)</div>
<div class="line"><span class="lineno">  908</span>                    word = utils.to_unicode(b<span class="stringliteral">&#39;&#39;</span>.join(word), encoding=encoding, errors=unicode_errors)</div>
<div class="line"><span class="lineno">  909</span>                    weights = fromstring(fin.read(binary_len), dtype=REAL)</div>
<div class="line"><span class="lineno">  910</span>                    <span class="keywordflow">if</span> word <span class="keywordflow">in</span> self.wv.vocab:</div>
<div class="line"><span class="lineno">  911</span>                        overlap_count += 1</div>
<div class="line"><span class="lineno">  912</span>                        self.wv.vectors[self.wv.vocab[word].index] = weights</div>
<div class="line"><span class="lineno">  913</span>                        self.trainables.vectors_lockf[self.wv.vocab[word].index] = lockf  <span class="comment"># lock-factor: 0.0=no changes</span></div>
<div class="line"><span class="lineno">  914</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  915</span>                <span class="keywordflow">for</span> line_no, line <span class="keywordflow">in</span> enumerate(fin):</div>
<div class="line"><span class="lineno">  916</span>                    parts = utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split(<span class="stringliteral">&quot; &quot;</span>)</div>
<div class="line"><span class="lineno">  917</span>                    <span class="keywordflow">if</span> len(parts) != vector_size + 1:</div>
<div class="line"><span class="lineno">  918</span>                        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;invalid vector on line %s (is this really the text format?)&quot;</span> % line_no)</div>
<div class="line"><span class="lineno">  919</span>                    word, weights = parts[0], [REAL(x) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> parts[1:]]</div>
<div class="line"><span class="lineno">  920</span>                    <span class="keywordflow">if</span> word <span class="keywordflow">in</span> self.wv.vocab:</div>
<div class="line"><span class="lineno">  921</span>                        overlap_count += 1</div>
<div class="line"><span class="lineno">  922</span>                        self.wv.vectors[self.wv.vocab[word].index] = weights</div>
<div class="line"><span class="lineno">  923</span>                        self.trainables.vectors_lockf[self.wv.vocab[word].index] = lockf  <span class="comment"># lock-factor: 0.0=no changes</span></div>
<div class="line"><span class="lineno">  924</span>        logger.info(<span class="stringliteral">&quot;merged %d vectors into %s matrix from %s&quot;</span>, overlap_count, self.wv.vectors.shape, fname)</div>
<div class="line"><span class="lineno">  925</span> </div>
<div class="ttc" id="anamespacedtype_html"><div class="ttname"><a href="namespacedtype.html">dtype</a></div><div class="ttdef"><b>Definition</b> dtype.py:1</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a2fa09c79252cd54a67ffc80b57e61dfe" name="a2fa09c79252cd54a67ffc80b57e61dfe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2fa09c79252cd54a67ffc80b57e61dfe">&#9670;&#160;</a></span>load()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.load </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Load a previously saved :class:`~gensim.models.word2vec.Word2Vec` model.

See Also
--------
:meth:`~gensim.models.word2vec.Word2Vec.save`
    Save model.

Parameters
----------
fname : str
    Path to the saved file.

Returns
-------
:class:`~gensim.models.word2vec.Word2Vec`
    Loaded model.</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#ab49365900af2d860f497162f8f4e622f">gensim.models.base_any2vec.BaseWordEmbeddingsModel</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1121</span>    <span class="keyword">def </span>load(cls, *args, **kwargs):</div>
<div class="line"><span class="lineno"> 1122</span>        <span class="stringliteral">&quot;&quot;&quot;Load a previously saved :class:`~gensim.models.word2vec.Word2Vec` model.</span></div>
<div class="line"><span class="lineno"> 1123</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1124</span><span class="stringliteral">        See Also</span></div>
<div class="line"><span class="lineno"> 1125</span><span class="stringliteral">        --------</span></div>
<div class="line"><span class="lineno"> 1126</span><span class="stringliteral">        :meth:`~gensim.models.word2vec.Word2Vec.save`</span></div>
<div class="line"><span class="lineno"> 1127</span><span class="stringliteral">            Save model.</span></div>
<div class="line"><span class="lineno"> 1128</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1129</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno"> 1130</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno"> 1131</span><span class="stringliteral">        fname : str</span></div>
<div class="line"><span class="lineno"> 1132</span><span class="stringliteral">            Path to the saved file.</span></div>
<div class="line"><span class="lineno"> 1133</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1134</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno"> 1135</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno"> 1136</span><span class="stringliteral">        :class:`~gensim.models.word2vec.Word2Vec`</span></div>
<div class="line"><span class="lineno"> 1137</span><span class="stringliteral">            Loaded model.</span></div>
<div class="line"><span class="lineno"> 1138</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1139</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1140</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno"> 1141</span>            model = super(Word2Vec, cls).load(*args, **kwargs)</div>
<div class="line"><span class="lineno"> 1142</span> </div>
<div class="line"><span class="lineno"> 1143</span>            <span class="comment"># for backward compatibility for `max_final_vocab` feature</span></div>
<div class="line"><span class="lineno"> 1144</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(model, <span class="stringliteral">&#39;max_final_vocab&#39;</span>):</div>
<div class="line"><span class="lineno"> 1145</span>                model.max_final_vocab = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1146</span>                model.vocabulary.max_final_vocab = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1147</span> </div>
<div class="line"><span class="lineno"> 1148</span>            <span class="keywordflow">return</span> model</div>
<div class="line"><span class="lineno"> 1149</span>        <span class="keywordflow">except</span> AttributeError:</div>
<div class="line"><span class="lineno"> 1150</span>            logger.info(<span class="stringliteral">&#39;Model saved using code from earlier Gensim Version. Re-loading old model in a compatible way.&#39;</span>)</div>
<div class="line"><span class="lineno"> 1151</span>            <span class="keyword">from</span> <a class="code hl_namespace" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html">gensim.models.deprecated.word2vec</a> <span class="keyword">import</span> load_old_word2vec</div>
<div class="line"><span class="lineno"> 1152</span>            <span class="keywordflow">return</span> load_old_word2vec(*args, **kwargs)</div>
<div class="line"><span class="lineno"> 1153</span> </div>
<div class="line"><span class="lineno"> 1154</span> </div>
<div class="ttc" id="anamespacegensim_1_1models_1_1deprecated_1_1word2vec_html"><div class="ttname"><a href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html">gensim.models.deprecated.word2vec</a></div><div class="ttdef"><b>Definition</b> word2vec.py:1</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a084c2a637534ad0e1adc94d7a1278d31" name="a084c2a637534ad0e1adc94d7a1278d31"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a084c2a637534ad0e1adc94d7a1278d31">&#9670;&#160;</a></span>load_word2vec_format()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.load_word2vec_format </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fname</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fvocab</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>binary</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>encoding</em> = <code>'utf8'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>unicode_errors</em> = <code>'strict'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>limit</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>datatype</em> = <code>REAL</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use :meth:`gensim.models.KeyedVectors.load_word2vec_format` instead.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1109</span>            limit=<span class="keywordtype">None</span>, datatype=REAL):</div>
<div class="line"><span class="lineno"> 1110</span>        <span class="stringliteral">&quot;&quot;&quot;Deprecated. Use :meth:`gensim.models.KeyedVectors.load_word2vec_format` instead.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1111</span>        <span class="keywordflow">raise</span> DeprecationWarning(<span class="stringliteral">&quot;Deprecated. Use gensim.models.KeyedVectors.load_word2vec_format instead.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1112</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aec29fc5498af2137014ec6af6ce6df2e" name="aec29fc5498af2137014ec6af6ce6df2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec29fc5498af2137014ec6af6ce6df2e">&#9670;&#160;</a></span>log_accuracy()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.log_accuracy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>section</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use `self.wv.log_accuracy` instead.
See :meth:`~gensim.models.word2vec.Word2VecKeyedVectors.log_accuracy`.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1018</span>    <span class="keyword">def </span>log_accuracy(section):</div>
<div class="line"><span class="lineno"> 1019</span>        <span class="stringliteral">&quot;&quot;&quot;Deprecated. Use `self.wv.log_accuracy` instead.</span></div>
<div class="line"><span class="lineno"> 1020</span><span class="stringliteral">        See :meth:`~gensim.models.word2vec.Word2VecKeyedVectors.log_accuracy`.</span></div>
<div class="line"><span class="lineno"> 1021</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1022</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1023</span>        <span class="keywordflow">return</span> Word2VecKeyedVectors.log_accuracy(section)</div>
<div class="line"><span class="lineno"> 1024</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a270be5eb124095a586ab0eb997e30599" name="a270be5eb124095a586ab0eb997e30599"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a270be5eb124095a586ab0eb997e30599">&#9670;&#160;</a></span>predict_output_word()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.predict_output_word </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>context_words_list</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>topn</em> = <code>10</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get the probability distribution of the center word given context words.

Parameters
----------
context_words_list : list of str
    List of context words.
topn : int, optional
    Return `topn` words and their probabilities.

Returns
-------
list of (str, float)
    `topn` length list of tuples of (word, probability).</pre> <div class="fragment"><div class="line"><span class="lineno">  942</span>    <span class="keyword">def </span>predict_output_word(self, context_words_list, topn=10):</div>
<div class="line"><span class="lineno">  943</span>        <span class="stringliteral">&quot;&quot;&quot;Get the probability distribution of the center word given context words.</span></div>
<div class="line"><span class="lineno">  944</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  945</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  946</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  947</span><span class="stringliteral">        context_words_list : list of str</span></div>
<div class="line"><span class="lineno">  948</span><span class="stringliteral">            List of context words.</span></div>
<div class="line"><span class="lineno">  949</span><span class="stringliteral">        topn : int, optional</span></div>
<div class="line"><span class="lineno">  950</span><span class="stringliteral">            Return `topn` words and their probabilities.</span></div>
<div class="line"><span class="lineno">  951</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  952</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  953</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  954</span><span class="stringliteral">        list of (str, float)</span></div>
<div class="line"><span class="lineno">  955</span><span class="stringliteral">            `topn` length list of tuples of (word, probability).</span></div>
<div class="line"><span class="lineno">  956</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  957</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  958</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.negative:</div>
<div class="line"><span class="lineno">  959</span>            <span class="keywordflow">raise</span> RuntimeError(</div>
<div class="line"><span class="lineno">  960</span>                <span class="stringliteral">&quot;We have currently only implemented predict_output_word for the negative sampling scheme, &quot;</span></div>
<div class="line"><span class="lineno">  961</span>                <span class="stringliteral">&quot;so you need to have run word2vec with negative &gt; 0 for this to work.&quot;</span></div>
<div class="line"><span class="lineno">  962</span>            )</div>
<div class="line"><span class="lineno">  963</span> </div>
<div class="line"><span class="lineno">  964</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(self.wv, <span class="stringliteral">&#39;vectors&#39;</span>) <span class="keywordflow">or</span> <span class="keywordflow">not</span> hasattr(self.trainables, <span class="stringliteral">&#39;syn1neg&#39;</span>):</div>
<div class="line"><span class="lineno">  965</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;Parameters required for predicting the output words not found.&quot;</span>)</div>
<div class="line"><span class="lineno">  966</span> </div>
<div class="line"><span class="lineno">  967</span>        word_vocabs = [self.wv.vocab[w] <span class="keywordflow">for</span> w <span class="keywordflow">in</span> context_words_list <span class="keywordflow">if</span> w <span class="keywordflow">in</span> self.wv.vocab]</div>
<div class="line"><span class="lineno">  968</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> word_vocabs:</div>
<div class="line"><span class="lineno">  969</span>            warnings.warn(<span class="stringliteral">&quot;All the input context words are out-of-vocabulary for the current model.&quot;</span>)</div>
<div class="line"><span class="lineno">  970</span>            <span class="keywordflow">return</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  971</span> </div>
<div class="line"><span class="lineno">  972</span>        word2_indices = [word.index <span class="keywordflow">for</span> word <span class="keywordflow">in</span> word_vocabs]</div>
<div class="line"><span class="lineno">  973</span> </div>
<div class="line"><span class="lineno">  974</span>        l1 = np_sum(self.wv.vectors[word2_indices], axis=0)</div>
<div class="line"><span class="lineno">  975</span>        <span class="keywordflow">if</span> word2_indices <span class="keywordflow">and</span> self.cbow_mean:</div>
<div class="line"><span class="lineno">  976</span>            l1 /= len(word2_indices)</div>
<div class="line"><span class="lineno">  977</span> </div>
<div class="line"><span class="lineno">  978</span>        <span class="comment"># propagate hidden -&gt; output and take softmax to get probabilities</span></div>
<div class="line"><span class="lineno">  979</span>        prob_values = exp(dot(l1, self.trainables.syn1neg.T))</div>
<div class="line"><span class="lineno">  980</span>        prob_values /= sum(prob_values)</div>
<div class="line"><span class="lineno">  981</span>        top_indices = matutils.argsort(prob_values, topn=topn, reverse=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  982</span>        <span class="comment"># returning the most probable output words with their probabilities</span></div>
<div class="line"><span class="lineno">  983</span>        <span class="keywordflow">return</span> [(self.wv.index2word[index1], prob_values[index1]) <span class="keywordflow">for</span> index1 <span class="keywordflow">in</span> top_indices]</div>
<div class="line"><span class="lineno">  984</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac95948a74a57dd02bc4c4213e23ebdb3" name="ac95948a74a57dd02bc4c4213e23ebdb3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac95948a74a57dd02bc4c4213e23ebdb3">&#9670;&#160;</a></span>reset_from()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.reset_from </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>other_model</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Borrow shareable pre-built structures from `other_model` and reset hidden layer weights.

Structures copied are:
    * Vocabulary
    * Index to word mapping
    * Cumulative frequency table (used for negative sampling)
    * Cached corpus length

Useful when testing multiple models on the same corpus in parallel.

Parameters
----------
other_model : :class:`~gensim.models.word2vec.Word2Vec`
    Another model to copy the internal structures from.</pre> <div class="fragment"><div class="line"><span class="lineno">  994</span>    <span class="keyword">def </span>reset_from(self, other_model):</div>
<div class="line"><span class="lineno">  995</span>        <span class="stringliteral">&quot;&quot;&quot;Borrow shareable pre-built structures from `other_model` and reset hidden layer weights.</span></div>
<div class="line"><span class="lineno">  996</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  997</span><span class="stringliteral">        Structures copied are:</span></div>
<div class="line"><span class="lineno">  998</span><span class="stringliteral">            * Vocabulary</span></div>
<div class="line"><span class="lineno">  999</span><span class="stringliteral">            * Index to word mapping</span></div>
<div class="line"><span class="lineno"> 1000</span><span class="stringliteral">            * Cumulative frequency table (used for negative sampling)</span></div>
<div class="line"><span class="lineno"> 1001</span><span class="stringliteral">            * Cached corpus length</span></div>
<div class="line"><span class="lineno"> 1002</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1003</span><span class="stringliteral">        Useful when testing multiple models on the same corpus in parallel.</span></div>
<div class="line"><span class="lineno"> 1004</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1005</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno"> 1006</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno"> 1007</span><span class="stringliteral">        other_model : :class:`~gensim.models.word2vec.Word2Vec`</span></div>
<div class="line"><span class="lineno"> 1008</span><span class="stringliteral">            Another model to copy the internal structures from.</span></div>
<div class="line"><span class="lineno"> 1009</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1010</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1011</span>        self.wv.vocab = other_model.wv.vocab</div>
<div class="line"><span class="lineno"> 1012</span>        self.wv.index2word = other_model.wv.index2word</div>
<div class="line"><span class="lineno"> 1013</span>        self.vocabulary.cum_table = other_model.vocabulary.cum_table</div>
<div class="line"><span class="lineno"> 1014</span>        self.corpus_count = other_model.corpus_count</div>
<div class="line"><span class="lineno"> 1015</span>        self.trainables.reset_weights(self.hs, self.negative, self.wv)</div>
<div class="line"><span class="lineno"> 1016</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad77cee4ec895484e53a4405830d272aa" name="ad77cee4ec895484e53a4405830d272aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad77cee4ec895484e53a4405830d272aa">&#9670;&#160;</a></span>save()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.save </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Save the model.
This saved model can be loaded again using :func:`~gensim.models.word2vec.Word2Vec.load`, which supports
online training and getting vectors for vocabulary words.

Parameters
----------
fname : str
    Path to the file.</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_any2_vec_model.html#a548d65fb2c855c406414207a78c27d93">gensim.models.base_any2vec.BaseAny2VecModel</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1066</span>    <span class="keyword">def </span>save(self, *args, **kwargs):</div>
<div class="line"><span class="lineno"> 1067</span>        <span class="stringliteral">&quot;&quot;&quot;Save the model.</span></div>
<div class="line"><span class="lineno"> 1068</span><span class="stringliteral">        This saved model can be loaded again using :func:`~gensim.models.word2vec.Word2Vec.load`, which supports</span></div>
<div class="line"><span class="lineno"> 1069</span><span class="stringliteral">        online training and getting vectors for vocabulary words.</span></div>
<div class="line"><span class="lineno"> 1070</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1071</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno"> 1072</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno"> 1073</span><span class="stringliteral">        fname : str</span></div>
<div class="line"><span class="lineno"> 1074</span><span class="stringliteral">            Path to the file.</span></div>
<div class="line"><span class="lineno"> 1075</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1076</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1077</span>        <span class="comment"># don&#39;t bother storing the cached normalized vectors, recalculable table</span></div>
<div class="line"><span class="lineno"> 1078</span>        kwargs[<span class="stringliteral">&#39;ignore&#39;</span>] = kwargs.get(<span class="stringliteral">&#39;ignore&#39;</span>, [<span class="stringliteral">&#39;vectors_norm&#39;</span>, <span class="stringliteral">&#39;cum_table&#39;</span>])</div>
<div class="line"><span class="lineno"> 1079</span>        super(Word2Vec, self).save(*args, **kwargs)</div>
<div class="line"><span class="lineno"> 1080</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a455b2aff149dd82fdcc28d4d0bf8b697" name="a455b2aff149dd82fdcc28d4d0bf8b697"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a455b2aff149dd82fdcc28d4d0bf8b697">&#9670;&#160;</a></span>save_word2vec_format()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.save_word2vec_format </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fname</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fvocab</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>binary</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use `model.wv.save_word2vec_format` instead.
See :meth:`gensim.models.KeyedVectors.save_word2vec_format`.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1113</span>    <span class="keyword">def </span>save_word2vec_format(self, fname, fvocab=None, binary=False):</div>
<div class="line"><span class="lineno"> 1114</span>        <span class="stringliteral">&quot;&quot;&quot;Deprecated. Use `model.wv.save_word2vec_format` instead.</span></div>
<div class="line"><span class="lineno"> 1115</span><span class="stringliteral">        See :meth:`gensim.models.KeyedVectors.save_word2vec_format`.</span></div>
<div class="line"><span class="lineno"> 1116</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1117</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1118</span>        <span class="keywordflow">raise</span> DeprecationWarning(<span class="stringliteral">&quot;Deprecated. Use model.wv.save_word2vec_format instead.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1119</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a32cf864074108c28edeb1fcdc3397b4c" name="a32cf864074108c28edeb1fcdc3397b4c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a32cf864074108c28edeb1fcdc3397b4c">&#9670;&#160;</a></span>score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_sentences</em> = <code><a class="el" href="namespacegensim_1_1models_1_1word2vec.html#afcae40e2c97fbb41616072e53d221642">int</a>(1e6)</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>chunksize</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>queue_factor</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>report_delay</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Score the log probability for a sequence of sentences.
This does not change the fitted model in any way (see :meth:`~gensim.models.word2vec.Word2Vec.train` for that).

Gensim has currently only implemented score for the hierarchical softmax scheme,
so you need to have run word2vec with `hs=1` and `negative=0` for this to work.

Note that you should specify `total_sentences`; you'll run into problems if you ask to
score more than this number of sentences but it is inefficient to set the value too high.

See the `article by Matt Taddy: "Document Classification by Inversion of Distributed Language Representations"
&lt;https://arxiv.org/pdf/1504.07295.pdf&gt;`_ and the
`gensim demo &lt;https://github.com/piskvorky/gensim/blob/develop/docs/notebooks/deepir.ipynb&gt;`_ for examples of
how to use such scores in document classification.

Parameters
----------
sentences : iterable of list of str
    The `sentences` iterable can be simply a list of lists of tokens, but for larger corpora,
    consider an iterable that streams the sentences directly from disk/network.
    See :class:`~gensim.models.word2vec.BrownCorpus`, :class:`~gensim.models.word2vec.Text8Corpus`
    or :class:`~gensim.models.word2vec.LineSentence` in :mod:`~gensim.models.word2vec` module for such examples.
total_sentences : int, optional
    Count of sentences.
chunksize : int, optional
    Chunksize of jobs
queue_factor : int, optional
    Multiplier for size of queue (number of workers * queue_factor).
report_delay : float, optional
    Seconds to wait before reporting progress.</pre> <div class="fragment"><div class="line"><span class="lineno">  729</span>    <span class="keyword">def </span>score(self, sentences, total_sentences=int(1e6), chunksize=100, queue_factor=2, report_delay=1):</div>
<div class="line"><span class="lineno">  730</span>        <span class="stringliteral">&quot;&quot;&quot;Score the log probability for a sequence of sentences.</span></div>
<div class="line"><span class="lineno">  731</span><span class="stringliteral">        This does not change the fitted model in any way (see :meth:`~gensim.models.word2vec.Word2Vec.train` for that).</span></div>
<div class="line"><span class="lineno">  732</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  733</span><span class="stringliteral">        Gensim has currently only implemented score for the hierarchical softmax scheme,</span></div>
<div class="line"><span class="lineno">  734</span><span class="stringliteral">        so you need to have run word2vec with `hs=1` and `negative=0` for this to work.</span></div>
<div class="line"><span class="lineno">  735</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  736</span><span class="stringliteral">        Note that you should specify `total_sentences`; you&#39;ll run into problems if you ask to</span></div>
<div class="line"><span class="lineno">  737</span><span class="stringliteral">        score more than this number of sentences but it is inefficient to set the value too high.</span></div>
<div class="line"><span class="lineno">  738</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  739</span><span class="stringliteral">        See the `article by Matt Taddy: &quot;Document Classification by Inversion of Distributed Language Representations&quot;</span></div>
<div class="line"><span class="lineno">  740</span><span class="stringliteral">        &lt;https://arxiv.org/pdf/1504.07295.pdf&gt;`_ and the</span></div>
<div class="line"><span class="lineno">  741</span><span class="stringliteral">        `gensim demo &lt;https://github.com/piskvorky/gensim/blob/develop/docs/notebooks/deepir.ipynb&gt;`_ for examples of</span></div>
<div class="line"><span class="lineno">  742</span><span class="stringliteral">        how to use such scores in document classification.</span></div>
<div class="line"><span class="lineno">  743</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  744</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  745</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  746</span><span class="stringliteral">        sentences : iterable of list of str</span></div>
<div class="line"><span class="lineno">  747</span><span class="stringliteral">            The `sentences` iterable can be simply a list of lists of tokens, but for larger corpora,</span></div>
<div class="line"><span class="lineno">  748</span><span class="stringliteral">            consider an iterable that streams the sentences directly from disk/network.</span></div>
<div class="line"><span class="lineno">  749</span><span class="stringliteral">            See :class:`~gensim.models.word2vec.BrownCorpus`, :class:`~gensim.models.word2vec.Text8Corpus`</span></div>
<div class="line"><span class="lineno">  750</span><span class="stringliteral">            or :class:`~gensim.models.word2vec.LineSentence` in :mod:`~gensim.models.word2vec` module for such examples.</span></div>
<div class="line"><span class="lineno">  751</span><span class="stringliteral">        total_sentences : int, optional</span></div>
<div class="line"><span class="lineno">  752</span><span class="stringliteral">            Count of sentences.</span></div>
<div class="line"><span class="lineno">  753</span><span class="stringliteral">        chunksize : int, optional</span></div>
<div class="line"><span class="lineno">  754</span><span class="stringliteral">            Chunksize of jobs</span></div>
<div class="line"><span class="lineno">  755</span><span class="stringliteral">        queue_factor : int, optional</span></div>
<div class="line"><span class="lineno">  756</span><span class="stringliteral">            Multiplier for size of queue (number of workers * queue_factor).</span></div>
<div class="line"><span class="lineno">  757</span><span class="stringliteral">        report_delay : float, optional</span></div>
<div class="line"><span class="lineno">  758</span><span class="stringliteral">            Seconds to wait before reporting progress.</span></div>
<div class="line"><span class="lineno">  759</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  760</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  761</span>        logger.info(</div>
<div class="line"><span class="lineno">  762</span>            <span class="stringliteral">&quot;scoring sentences with %i workers on %i vocabulary and %i features, &quot;</span></div>
<div class="line"><span class="lineno">  763</span>            <span class="stringliteral">&quot;using sg=%s hs=%s sample=%s and negative=%s&quot;</span>,</div>
<div class="line"><span class="lineno">  764</span>            self.workers, len(self.wv.vocab), self.trainables.layer1_size, self.sg, self.hs,</div>
<div class="line"><span class="lineno">  765</span>            self.vocabulary.sample, self.negative</div>
<div class="line"><span class="lineno">  766</span>        )</div>
<div class="line"><span class="lineno">  767</span> </div>
<div class="line"><span class="lineno">  768</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.wv.vocab:</div>
<div class="line"><span class="lineno">  769</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;you must first build vocabulary before scoring new data&quot;</span>)</div>
<div class="line"><span class="lineno">  770</span> </div>
<div class="line"><span class="lineno">  771</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.hs:</div>
<div class="line"><span class="lineno">  772</span>            <span class="keywordflow">raise</span> RuntimeError(</div>
<div class="line"><span class="lineno">  773</span>                <span class="stringliteral">&quot;We have currently only implemented score for the hierarchical softmax scheme, &quot;</span></div>
<div class="line"><span class="lineno">  774</span>                <span class="stringliteral">&quot;so you need to have run word2vec with hs=1 and negative=0 for this to work.&quot;</span></div>
<div class="line"><span class="lineno">  775</span>            )</div>
<div class="line"><span class="lineno">  776</span> </div>
<div class="line"><span class="lineno">  777</span>        <span class="keyword">def </span>worker_loop():</div>
<div class="line"><span class="lineno">  778</span>            <span class="stringliteral">&quot;&quot;&quot;Compute log probability for each sentence, lifting lists of sentences from the jobs queue.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  779</span>            work = zeros(1, dtype=REAL)  <span class="comment"># for sg hs, we actually only need one memory loc (running sum)</span></div>
<div class="line"><span class="lineno">  780</span>            neu1 = matutils.zeros_aligned(self.trainables.layer1_size, dtype=REAL)</div>
<div class="line"><span class="lineno">  781</span>            <span class="keywordflow">while</span> <span class="keyword">True</span>:</div>
<div class="line"><span class="lineno">  782</span>                job = job_queue.get()</div>
<div class="line"><span class="lineno">  783</span>                <span class="keywordflow">if</span> job <span class="keywordflow">is</span> <span class="keywordtype">None</span>:  <span class="comment"># signal to finish</span></div>
<div class="line"><span class="lineno">  784</span>                    <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  785</span>                ns = 0</div>
<div class="line"><span class="lineno">  786</span>                <span class="keywordflow">for</span> sentence_id, sentence <span class="keywordflow">in</span> job:</div>
<div class="line"><span class="lineno">  787</span>                    <span class="keywordflow">if</span> sentence_id &gt;= total_sentences:</div>
<div class="line"><span class="lineno">  788</span>                        <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  789</span>                    <span class="keywordflow">if</span> self.sg:</div>
<div class="line"><span class="lineno">  790</span>                        score = score_sentence_sg(self, sentence, work)</div>
<div class="line"><span class="lineno">  791</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  792</span>                        score = score_sentence_cbow(self, sentence, work, neu1)</div>
<div class="line"><span class="lineno">  793</span>                    sentence_scores[sentence_id] = score</div>
<div class="line"><span class="lineno">  794</span>                    ns += 1</div>
<div class="line"><span class="lineno">  795</span>                progress_queue.put(ns)  <span class="comment"># report progress</span></div>
<div class="line"><span class="lineno">  796</span> </div>
<div class="line"><span class="lineno">  797</span>        start, next_report = default_timer(), 1.0</div>
<div class="line"><span class="lineno">  798</span>        <span class="comment"># buffer ahead only a limited number of jobs.. this is the reason we can&#39;t simply use ThreadPool :(</span></div>
<div class="line"><span class="lineno">  799</span>        job_queue = Queue(maxsize=queue_factor * self.workers)</div>
<div class="line"><span class="lineno">  800</span>        progress_queue = Queue(maxsize=(queue_factor + 1) * self.workers)</div>
<div class="line"><span class="lineno">  801</span> </div>
<div class="line"><span class="lineno">  802</span>        workers = [threading.Thread(target=worker_loop) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(self.workers)]</div>
<div class="line"><span class="lineno">  803</span>        <span class="keywordflow">for</span> thread <span class="keywordflow">in</span> workers:</div>
<div class="line"><span class="lineno">  804</span>            thread.daemon = <span class="keyword">True</span>  <span class="comment"># make interrupting the process with ctrl+c easier</span></div>
<div class="line"><span class="lineno">  805</span>            thread.start()</div>
<div class="line"><span class="lineno">  806</span> </div>
<div class="line"><span class="lineno">  807</span>        sentence_count = 0</div>
<div class="line"><span class="lineno">  808</span>        sentence_scores = matutils.zeros_aligned(total_sentences, dtype=REAL)</div>
<div class="line"><span class="lineno">  809</span> </div>
<div class="line"><span class="lineno">  810</span>        push_done = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  811</span>        done_jobs = 0</div>
<div class="line"><span class="lineno">  812</span>        jobs_source = enumerate(utils.grouper(enumerate(sentences), chunksize))</div>
<div class="line"><span class="lineno">  813</span> </div>
<div class="line"><span class="lineno">  814</span>        <span class="comment"># fill jobs queue with (id, sentence) job items</span></div>
<div class="line"><span class="lineno">  815</span>        <span class="keywordflow">while</span> <span class="keyword">True</span>:</div>
<div class="line"><span class="lineno">  816</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  817</span>                job_no, items = next(jobs_source)</div>
<div class="line"><span class="lineno">  818</span>                <span class="keywordflow">if</span> (job_no - 1) * chunksize &gt; total_sentences:</div>
<div class="line"><span class="lineno">  819</span>                    logger.warning(</div>
<div class="line"><span class="lineno">  820</span>                        <span class="stringliteral">&quot;terminating after %i sentences (set higher total_sentences if you want more).&quot;</span>,</div>
<div class="line"><span class="lineno">  821</span>                        total_sentences</div>
<div class="line"><span class="lineno">  822</span>                    )</div>
<div class="line"><span class="lineno">  823</span>                    job_no -= 1</div>
<div class="line"><span class="lineno">  824</span>                    <span class="keywordflow">raise</span> StopIteration()</div>
<div class="line"><span class="lineno">  825</span>                logger.debug(<span class="stringliteral">&quot;putting job #%i in the queue&quot;</span>, job_no)</div>
<div class="line"><span class="lineno">  826</span>                job_queue.put(items)</div>
<div class="line"><span class="lineno">  827</span>            <span class="keywordflow">except</span> StopIteration:</div>
<div class="line"><span class="lineno">  828</span>                logger.info(<span class="stringliteral">&quot;reached end of input; waiting to finish %i outstanding jobs&quot;</span>, job_no - done_jobs + 1)</div>
<div class="line"><span class="lineno">  829</span>                <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(self.workers):</div>
<div class="line"><span class="lineno">  830</span>                    job_queue.put(<span class="keywordtype">None</span>)  <span class="comment"># give the workers heads up that they can finish -- no more work!</span></div>
<div class="line"><span class="lineno">  831</span>                push_done = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  832</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  833</span>                <span class="keywordflow">while</span> done_jobs &lt; (job_no + 1) <span class="keywordflow">or</span> <span class="keywordflow">not</span> push_done:</div>
<div class="line"><span class="lineno">  834</span>                    ns = progress_queue.get(push_done)  <span class="comment"># only block after all jobs pushed</span></div>
<div class="line"><span class="lineno">  835</span>                    sentence_count += ns</div>
<div class="line"><span class="lineno">  836</span>                    done_jobs += 1</div>
<div class="line"><span class="lineno">  837</span>                    elapsed = default_timer() - start</div>
<div class="line"><span class="lineno">  838</span>                    <span class="keywordflow">if</span> elapsed &gt;= next_report:</div>
<div class="line"><span class="lineno">  839</span>                        logger.info(</div>
<div class="line"><span class="lineno">  840</span>                            <span class="stringliteral">&quot;PROGRESS: at %.2f%% sentences, %.0f sentences/s&quot;</span>,</div>
<div class="line"><span class="lineno">  841</span>                            100.0 * sentence_count, sentence_count / elapsed</div>
<div class="line"><span class="lineno">  842</span>                        )</div>
<div class="line"><span class="lineno">  843</span>                        next_report = elapsed + report_delay  <span class="comment"># don&#39;t flood log, wait report_delay seconds</span></div>
<div class="line"><span class="lineno">  844</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  845</span>                    <span class="comment"># loop ended by job count; really done</span></div>
<div class="line"><span class="lineno">  846</span>                    <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  847</span>            <span class="keywordflow">except</span> Empty:</div>
<div class="line"><span class="lineno">  848</span>                <span class="keywordflow">pass</span>  <span class="comment"># already out of loop; continue to next push</span></div>
<div class="line"><span class="lineno">  849</span> </div>
<div class="line"><span class="lineno">  850</span>        elapsed = default_timer() - start</div>
<div class="line"><span class="lineno">  851</span>        self.clear_sims()</div>
<div class="line"><span class="lineno">  852</span>        logger.info(</div>
<div class="line"><span class="lineno">  853</span>            <span class="stringliteral">&quot;scoring %i sentences took %.1fs, %.0f sentences/s&quot;</span>,</div>
<div class="line"><span class="lineno">  854</span>            sentence_count, elapsed, sentence_count / elapsed</div>
<div class="line"><span class="lineno">  855</span>        )</div>
<div class="line"><span class="lineno">  856</span>        <span class="keywordflow">return</span> sentence_scores[:sentence_count]</div>
<div class="line"><span class="lineno">  857</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa10c70a15d13b09500372b8652bef4f7" name="aa10c70a15d13b09500372b8652bef4f7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa10c70a15d13b09500372b8652bef4f7">&#9670;&#160;</a></span>train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>corpus_file</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_examples</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_words</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>epochs</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>start_alpha</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>end_alpha</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_count</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>queue_factor</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>report_delay</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>compute_loss</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>callbacks</em> = <code>()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update the model's neural weights from a sequence of sentences.

Notes
-----
To support linear learning-rate decay from (initial) `alpha` to `min_alpha`, and accurate
progress-percentage logging, either `total_examples` (count of sentences) or `total_words` (count of
raw words in sentences) **MUST** be provided. If `sentences` is the same corpus
that was provided to :meth:`~gensim.models.word2vec.Word2Vec.build_vocab` earlier,
you can simply use `total_examples=self.corpus_count`.

Warnings
--------
To avoid common mistakes around the model's ability to do multiple training passes itself, an
explicit `epochs` argument **MUST** be provided. In the common and recommended case
where :meth:`~gensim.models.word2vec.Word2Vec.train` is only called once, you can set `epochs=self.iter`.

Parameters
----------
sentences : iterable of list of str
    The `sentences` iterable can be simply a list of lists of tokens, but for larger corpora,
    consider an iterable that streams the sentences directly from disk/network.
    See :class:`~gensim.models.word2vec.BrownCorpus`, :class:`~gensim.models.word2vec.Text8Corpus`
    or :class:`~gensim.models.word2vec.LineSentence` in :mod:`~gensim.models.word2vec` module for such examples.
    See also the `tutorial on data streaming in Python
    &lt;https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/&gt;`_.
corpus_file : str, optional
    Path to a corpus file in :class:`~gensim.models.word2vec.LineSentence` format.
    You may use this argument instead of `sentences` to get performance boost. Only one of `sentences` or
    `corpus_file` arguments need to be passed (not both of them).
total_examples : int
    Count of sentences.
total_words : int
    Count of raw words in sentences.
epochs : int
    Number of iterations (epochs) over the corpus.
start_alpha : float, optional
    Initial learning rate. If supplied, replaces the starting `alpha` from the constructor,
    for this one call to`train()`.
    Use only if making multiple calls to `train()`, when you want to manage the alpha learning-rate yourself
    (not recommended).
end_alpha : float, optional
    Final learning rate. Drops linearly from `start_alpha`.
    If supplied, this replaces the final `min_alpha` from the constructor, for this one call to `train()`.
    Use only if making multiple calls to `train()`, when you want to manage the alpha learning-rate yourself
    (not recommended).
word_count : int, optional
    Count of words already trained. Set this to 0 for the usual
    case of training on all words in sentences.
queue_factor : int, optional
    Multiplier for size of queue (number of workers * queue_factor).
report_delay : float, optional
    Seconds to wait before reporting progress.
compute_loss: bool, optional
    If True, computes and stores loss value which can be retrieved using
    :meth:`~gensim.models.word2vec.Word2Vec.get_latest_training_loss`.
callbacks : iterable of :class:`~gensim.models.callbacks.CallbackAny2Vec`, optional
    Sequence of callbacks to be executed at specific stages during training.

Examples
--------
.. sourcecode:: pycon

    &gt;&gt;&gt; from gensim.models import Word2Vec
    &gt;&gt;&gt; sentences = [["cat", "say", "meow"], ["dog", "say", "woof"]]
    &gt;&gt;&gt;
    &gt;&gt;&gt; model = Word2Vec(min_count=1)
    &gt;&gt;&gt; model.build_vocab(sentences)  # prepare the model vocabulary
    &gt;&gt;&gt; model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)  # train word vectors
    (1, 30)</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1base__any2vec_1_1_base_word_embeddings_model.html#a14157aa8563c47cc13e24ae6776282af">gensim.models.base_any2vec.BaseWordEmbeddingsModel</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  652</span>              queue_factor=2, report_delay=1.0, compute_loss=<span class="keyword">False</span>, callbacks=()):</div>
<div class="line"><span class="lineno">  653</span>        <span class="stringliteral">&quot;&quot;&quot;Update the model&#39;s neural weights from a sequence of sentences.</span></div>
<div class="line"><span class="lineno">  654</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  655</span><span class="stringliteral">        Notes</span></div>
<div class="line"><span class="lineno">  656</span><span class="stringliteral">        -----</span></div>
<div class="line"><span class="lineno">  657</span><span class="stringliteral">        To support linear learning-rate decay from (initial) `alpha` to `min_alpha`, and accurate</span></div>
<div class="line"><span class="lineno">  658</span><span class="stringliteral">        progress-percentage logging, either `total_examples` (count of sentences) or `total_words` (count of</span></div>
<div class="line"><span class="lineno">  659</span><span class="stringliteral">        raw words in sentences) **MUST** be provided. If `sentences` is the same corpus</span></div>
<div class="line"><span class="lineno">  660</span><span class="stringliteral">        that was provided to :meth:`~gensim.models.word2vec.Word2Vec.build_vocab` earlier,</span></div>
<div class="line"><span class="lineno">  661</span><span class="stringliteral">        you can simply use `total_examples=self.corpus_count`.</span></div>
<div class="line"><span class="lineno">  662</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  663</span><span class="stringliteral">        Warnings</span></div>
<div class="line"><span class="lineno">  664</span><span class="stringliteral">        --------</span></div>
<div class="line"><span class="lineno">  665</span><span class="stringliteral">        To avoid common mistakes around the model&#39;s ability to do multiple training passes itself, an</span></div>
<div class="line"><span class="lineno">  666</span><span class="stringliteral">        explicit `epochs` argument **MUST** be provided. In the common and recommended case</span></div>
<div class="line"><span class="lineno">  667</span><span class="stringliteral">        where :meth:`~gensim.models.word2vec.Word2Vec.train` is only called once, you can set `epochs=self.iter`.</span></div>
<div class="line"><span class="lineno">  668</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  669</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  670</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  671</span><span class="stringliteral">        sentences : iterable of list of str</span></div>
<div class="line"><span class="lineno">  672</span><span class="stringliteral">            The `sentences` iterable can be simply a list of lists of tokens, but for larger corpora,</span></div>
<div class="line"><span class="lineno">  673</span><span class="stringliteral">            consider an iterable that streams the sentences directly from disk/network.</span></div>
<div class="line"><span class="lineno">  674</span><span class="stringliteral">            See :class:`~gensim.models.word2vec.BrownCorpus`, :class:`~gensim.models.word2vec.Text8Corpus`</span></div>
<div class="line"><span class="lineno">  675</span><span class="stringliteral">            or :class:`~gensim.models.word2vec.LineSentence` in :mod:`~gensim.models.word2vec` module for such examples.</span></div>
<div class="line"><span class="lineno">  676</span><span class="stringliteral">            See also the `tutorial on data streaming in Python</span></div>
<div class="line"><span class="lineno">  677</span><span class="stringliteral">            &lt;https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/&gt;`_.</span></div>
<div class="line"><span class="lineno">  678</span><span class="stringliteral">        corpus_file : str, optional</span></div>
<div class="line"><span class="lineno">  679</span><span class="stringliteral">            Path to a corpus file in :class:`~gensim.models.word2vec.LineSentence` format.</span></div>
<div class="line"><span class="lineno">  680</span><span class="stringliteral">            You may use this argument instead of `sentences` to get performance boost. Only one of `sentences` or</span></div>
<div class="line"><span class="lineno">  681</span><span class="stringliteral">            `corpus_file` arguments need to be passed (not both of them).</span></div>
<div class="line"><span class="lineno">  682</span><span class="stringliteral">        total_examples : int</span></div>
<div class="line"><span class="lineno">  683</span><span class="stringliteral">            Count of sentences.</span></div>
<div class="line"><span class="lineno">  684</span><span class="stringliteral">        total_words : int</span></div>
<div class="line"><span class="lineno">  685</span><span class="stringliteral">            Count of raw words in sentences.</span></div>
<div class="line"><span class="lineno">  686</span><span class="stringliteral">        epochs : int</span></div>
<div class="line"><span class="lineno">  687</span><span class="stringliteral">            Number of iterations (epochs) over the corpus.</span></div>
<div class="line"><span class="lineno">  688</span><span class="stringliteral">        start_alpha : float, optional</span></div>
<div class="line"><span class="lineno">  689</span><span class="stringliteral">            Initial learning rate. If supplied, replaces the starting `alpha` from the constructor,</span></div>
<div class="line"><span class="lineno">  690</span><span class="stringliteral">            for this one call to`train()`.</span></div>
<div class="line"><span class="lineno">  691</span><span class="stringliteral">            Use only if making multiple calls to `train()`, when you want to manage the alpha learning-rate yourself</span></div>
<div class="line"><span class="lineno">  692</span><span class="stringliteral">            (not recommended).</span></div>
<div class="line"><span class="lineno">  693</span><span class="stringliteral">        end_alpha : float, optional</span></div>
<div class="line"><span class="lineno">  694</span><span class="stringliteral">            Final learning rate. Drops linearly from `start_alpha`.</span></div>
<div class="line"><span class="lineno">  695</span><span class="stringliteral">            If supplied, this replaces the final `min_alpha` from the constructor, for this one call to `train()`.</span></div>
<div class="line"><span class="lineno">  696</span><span class="stringliteral">            Use only if making multiple calls to `train()`, when you want to manage the alpha learning-rate yourself</span></div>
<div class="line"><span class="lineno">  697</span><span class="stringliteral">            (not recommended).</span></div>
<div class="line"><span class="lineno">  698</span><span class="stringliteral">        word_count : int, optional</span></div>
<div class="line"><span class="lineno">  699</span><span class="stringliteral">            Count of words already trained. Set this to 0 for the usual</span></div>
<div class="line"><span class="lineno">  700</span><span class="stringliteral">            case of training on all words in sentences.</span></div>
<div class="line"><span class="lineno">  701</span><span class="stringliteral">        queue_factor : int, optional</span></div>
<div class="line"><span class="lineno">  702</span><span class="stringliteral">            Multiplier for size of queue (number of workers * queue_factor).</span></div>
<div class="line"><span class="lineno">  703</span><span class="stringliteral">        report_delay : float, optional</span></div>
<div class="line"><span class="lineno">  704</span><span class="stringliteral">            Seconds to wait before reporting progress.</span></div>
<div class="line"><span class="lineno">  705</span><span class="stringliteral">        compute_loss: bool, optional</span></div>
<div class="line"><span class="lineno">  706</span><span class="stringliteral">            If True, computes and stores loss value which can be retrieved using</span></div>
<div class="line"><span class="lineno">  707</span><span class="stringliteral">            :meth:`~gensim.models.word2vec.Word2Vec.get_latest_training_loss`.</span></div>
<div class="line"><span class="lineno">  708</span><span class="stringliteral">        callbacks : iterable of :class:`~gensim.models.callbacks.CallbackAny2Vec`, optional</span></div>
<div class="line"><span class="lineno">  709</span><span class="stringliteral">            Sequence of callbacks to be executed at specific stages during training.</span></div>
<div class="line"><span class="lineno">  710</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  711</span><span class="stringliteral">        Examples</span></div>
<div class="line"><span class="lineno">  712</span><span class="stringliteral">        --------</span></div>
<div class="line"><span class="lineno">  713</span><span class="stringliteral">        .. sourcecode:: pycon</span></div>
<div class="line"><span class="lineno">  714</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  715</span><span class="stringliteral">            &gt;&gt;&gt; from gensim.models import Word2Vec</span></div>
<div class="line"><span class="lineno">  716</span><span class="stringliteral">            &gt;&gt;&gt; sentences = [[&quot;cat&quot;, &quot;say&quot;, &quot;meow&quot;], [&quot;dog&quot;, &quot;say&quot;, &quot;woof&quot;]]</span></div>
<div class="line"><span class="lineno">  717</span><span class="stringliteral">            &gt;&gt;&gt;</span></div>
<div class="line"><span class="lineno">  718</span><span class="stringliteral">            &gt;&gt;&gt; model = Word2Vec(min_count=1)</span></div>
<div class="line"><span class="lineno">  719</span><span class="stringliteral">            &gt;&gt;&gt; model.build_vocab(sentences)  # prepare the model vocabulary</span></div>
<div class="line"><span class="lineno">  720</span><span class="stringliteral">            &gt;&gt;&gt; model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)  # train word vectors</span></div>
<div class="line"><span class="lineno">  721</span><span class="stringliteral">            (1, 30)</span></div>
<div class="line"><span class="lineno">  722</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  723</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  724</span>        <span class="keywordflow">return</span> super(Word2Vec, self).train(</div>
<div class="line"><span class="lineno">  725</span>            sentences=sentences, corpus_file=corpus_file, total_examples=total_examples, total_words=total_words,</div>
<div class="line"><span class="lineno">  726</span>            epochs=epochs, start_alpha=start_alpha, end_alpha=end_alpha, word_count=word_count,</div>
<div class="line"><span class="lineno">  727</span>            queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)</div>
<div class="line"><span class="lineno">  728</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a8de8ffa27932afb332d78cca6355bea3" name="a8de8ffa27932afb332d78cca6355bea3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8de8ffa27932afb332d78cca6355bea3">&#9670;&#160;</a></span>callbacks</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.callbacks</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7356f0b5c78c282c314d6f16f3933292" name="a7356f0b5c78c282c314d6f16f3933292"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7356f0b5c78c282c314d6f16f3933292">&#9670;&#160;</a></span>compute_loss</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.compute_loss</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a80a761167f0d43a06e67cb6fdfb27936" name="a80a761167f0d43a06e67cb6fdfb27936"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80a761167f0d43a06e67cb6fdfb27936">&#9670;&#160;</a></span>corpus_count</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.corpus_count</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a523cc58f02b0dcf672056d275a5585cc" name="a523cc58f02b0dcf672056d275a5585cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a523cc58f02b0dcf672056d275a5585cc">&#9670;&#160;</a></span>hs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.hs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a251d67682ef42a76cf36cbfa81ed9dd3" name="a251d67682ef42a76cf36cbfa81ed9dd3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a251d67682ef42a76cf36cbfa81ed9dd3">&#9670;&#160;</a></span>load</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.load</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aaa915e33452de6bc501705c3ac04c3e7" name="aaa915e33452de6bc501705c3ac04c3e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaa915e33452de6bc501705c3ac04c3e7">&#9670;&#160;</a></span>max_final_vocab</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.max_final_vocab</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3ba4f2fe0c597aeb264e4d1a9b5e9e65" name="a3ba4f2fe0c597aeb264e4d1a9b5e9e65"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3ba4f2fe0c597aeb264e4d1a9b5e9e65">&#9670;&#160;</a></span>model_trimmed_post_training</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.model_trimmed_post_training</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a17c87313bad8678d860579476c866990" name="a17c87313bad8678d860579476c866990"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a17c87313bad8678d860579476c866990">&#9670;&#160;</a></span>negative</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.negative</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8f3058a2f528e0e71181d6eb6436e870" name="a8f3058a2f528e0e71181d6eb6436e870"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8f3058a2f528e0e71181d6eb6436e870">&#9670;&#160;</a></span>running_training_loss</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.running_training_loss</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1d589a8d7b122dffd555e9bc8d746b48" name="a1d589a8d7b122dffd555e9bc8d746b48"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d589a8d7b122dffd555e9bc8d746b48">&#9670;&#160;</a></span>sg</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.sg</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a402b65c7086e51f80aeb6436166b89b5" name="a402b65c7086e51f80aeb6436166b89b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a402b65c7086e51f80aeb6436166b89b5">&#9670;&#160;</a></span>trainables</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.trainables</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad960f930ac57ad61d4ac1f1909fc6a8b" name="ad960f930ac57ad61d4ac1f1909fc6a8b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad960f930ac57ad61d4ac1f1909fc6a8b">&#9670;&#160;</a></span>vocabulary</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.vocabulary</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afabc9719a977187125422e12b826a982" name="afabc9719a977187125422e12b826a982"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afabc9719a977187125422e12b826a982">&#9670;&#160;</a></span>workers</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.workers</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a357ac9cc29d94de58e46041f69168ae6" name="a357ac9cc29d94de58e46041f69168ae6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a357ac9cc29d94de58e46041f69168ae6">&#9670;&#160;</a></span>wv</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.word2vec.Word2Vec.wv</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/rafael/Documents/GitHub/PUC-GCES-PY/Tp-GCS-Rafael-Augusto/venv/lib/python3.9/site-packages/gensim/models/<a class="el" href="word2vec_8py.html">word2vec.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
