<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.gaussian_process._gpr.GaussianProcessRegressor Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1gaussian__process.html">gaussian_process</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1gaussian__process_1_1__gpr.html">_gpr</a></li><li class="navelem"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html">GaussianProcessRegressor</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="#pro-static-attribs">Static Protected Attributes</a> &#124;
<a href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">sklearn.gaussian_process._gpr.GaussianProcessRegressor Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for sklearn.gaussian_process._gpr.GaussianProcessRegressor:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.png" usemap="#sklearn.gaussian_5Fprocess._5Fgpr.GaussianProcessRegressor_map" alt=""/>
  <map id="sklearn.gaussian_5Fprocess._5Fgpr.GaussianProcessRegressor_map" name="sklearn.gaussian_5Fprocess._5Fgpr.GaussianProcessRegressor_map">
<area href="classsklearn_1_1base_1_1_multi_output_mixin.html" alt="sklearn.base.MultiOutputMixin" shape="rect" coords="0,0,349,24"/>
<area href="classsklearn_1_1base_1_1_regressor_mixin.html" alt="sklearn.base.RegressorMixin" shape="rect" coords="359,0,708,24"/>
<area href="classsklearn_1_1base_1_1_base_estimator.html" alt="sklearn.base.BaseEstimator" shape="rect" coords="718,0,1067,24"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:afa340368607f3efd0a9484049fb56e5a" id="r_afa340368607f3efd0a9484049fb56e5a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#afa340368607f3efd0a9484049fb56e5a">__init__</a> (self, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#af846d5cd1e17dfa525fb99fcaa867ed7">kernel</a>=None, *<a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#abc89fb029f5d119897dd84616d84cc91">alpha</a>=1e-10, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#ae974bf9af46dbf9052e39cce9a0fcb42">optimizer</a>=&quot;fmin_l_bfgs_b&quot;, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#aeca5128011525338dfc4773c9ec15df8">n_restarts_optimizer</a>=0, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a9afd45fe3416504d43c4b9a7f53240a2">normalize_y</a>=False, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a658f726e6f37d4b3f2739b4ffe3b9fb0">copy_X_train</a>=True, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a54770fcb8d43e6d4cfe331733dd2a95f">random_state</a>=None)</td></tr>
<tr class="separator:afa340368607f3efd0a9484049fb56e5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade4077cc91e436180791b0f6a7bc0aba" id="r_ade4077cc91e436180791b0f6a7bc0aba"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#ade4077cc91e436180791b0f6a7bc0aba">fit</a> (self, X, y)</td></tr>
<tr class="separator:ade4077cc91e436180791b0f6a7bc0aba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a390a70193d548557f9cdcd3775c2f3d2" id="r_a390a70193d548557f9cdcd3775c2f3d2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a390a70193d548557f9cdcd3775c2f3d2">predict</a> (self, X, return_std=False, return_cov=False)</td></tr>
<tr class="separator:a390a70193d548557f9cdcd3775c2f3d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a244700908024966019e0a5b5222febb4" id="r_a244700908024966019e0a5b5222febb4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a244700908024966019e0a5b5222febb4">sample_y</a> (self, X, n_samples=1, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a54770fcb8d43e6d4cfe331733dd2a95f">random_state</a>=0)</td></tr>
<tr class="separator:a244700908024966019e0a5b5222febb4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae13a5f19a008496c28127232c7df7615" id="r_ae13a5f19a008496c28127232c7df7615"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#ae13a5f19a008496c28127232c7df7615">log_marginal_likelihood</a> (self, <a class="el" href="__lapack__subroutines_8h.html#a68abd7cf2689a313136b50c232300582">theta</a>=None, eval_gradient=False, clone_kernel=True)</td></tr>
<tr class="separator:ae13a5f19a008496c28127232c7df7615"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classsklearn_1_1base_1_1_regressor_mixin"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classsklearn_1_1base_1_1_regressor_mixin')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classsklearn_1_1base_1_1_regressor_mixin.html">sklearn.base.RegressorMixin</a></td></tr>
<tr class="memitem:adce4557f75f598bbc92379cd10c43a7d inherit pub_methods_classsklearn_1_1base_1_1_regressor_mixin" id="r_adce4557f75f598bbc92379cd10c43a7d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_regressor_mixin.html#adce4557f75f598bbc92379cd10c43a7d">score</a> (self, X, y, sample_weight=None)</td></tr>
<tr class="separator:adce4557f75f598bbc92379cd10c43a7d inherit pub_methods_classsklearn_1_1base_1_1_regressor_mixin"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:a5c3e0c802dfacfbaceafb925c411b211 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a5c3e0c802dfacfbaceafb925c411b211"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a5c3e0c802dfacfbaceafb925c411b211">get_params</a> (self, deep=True)</td></tr>
<tr class="separator:a5c3e0c802dfacfbaceafb925c411b211 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8177e7086e8cbed1fec2bcdae9202c1 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_af8177e7086e8cbed1fec2bcdae9202c1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#af8177e7086e8cbed1fec2bcdae9202c1">set_params</a> (self, **params)</td></tr>
<tr class="separator:af8177e7086e8cbed1fec2bcdae9202c1 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5da47f044a7f6bc188b93722cad7a4c inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ad5da47f044a7f6bc188b93722cad7a4c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ad5da47f044a7f6bc188b93722cad7a4c">__repr__</a> (self, N_CHAR_MAX=700)</td></tr>
<tr class="separator:ad5da47f044a7f6bc188b93722cad7a4c inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f3d56fd989ef4230f70670d6128549e inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a1f3d56fd989ef4230f70670d6128549e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a1f3d56fd989ef4230f70670d6128549e">__getstate__</a> (self)</td></tr>
<tr class="separator:a1f3d56fd989ef4230f70670d6128549e inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e30cf35986d0ed01728b435e83bd427 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a4e30cf35986d0ed01728b435e83bd427"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a4e30cf35986d0ed01728b435e83bd427">__setstate__</a> (self, state)</td></tr>
<tr class="separator:a4e30cf35986d0ed01728b435e83bd427 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:af846d5cd1e17dfa525fb99fcaa867ed7" id="r_af846d5cd1e17dfa525fb99fcaa867ed7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#af846d5cd1e17dfa525fb99fcaa867ed7">kernel</a></td></tr>
<tr class="separator:af846d5cd1e17dfa525fb99fcaa867ed7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc89fb029f5d119897dd84616d84cc91" id="r_abc89fb029f5d119897dd84616d84cc91"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#abc89fb029f5d119897dd84616d84cc91">alpha</a></td></tr>
<tr class="separator:abc89fb029f5d119897dd84616d84cc91"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae974bf9af46dbf9052e39cce9a0fcb42" id="r_ae974bf9af46dbf9052e39cce9a0fcb42"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#ae974bf9af46dbf9052e39cce9a0fcb42">optimizer</a></td></tr>
<tr class="separator:ae974bf9af46dbf9052e39cce9a0fcb42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeca5128011525338dfc4773c9ec15df8" id="r_aeca5128011525338dfc4773c9ec15df8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#aeca5128011525338dfc4773c9ec15df8">n_restarts_optimizer</a></td></tr>
<tr class="separator:aeca5128011525338dfc4773c9ec15df8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9afd45fe3416504d43c4b9a7f53240a2" id="r_a9afd45fe3416504d43c4b9a7f53240a2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a9afd45fe3416504d43c4b9a7f53240a2">normalize_y</a></td></tr>
<tr class="separator:a9afd45fe3416504d43c4b9a7f53240a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a658f726e6f37d4b3f2739b4ffe3b9fb0" id="r_a658f726e6f37d4b3f2739b4ffe3b9fb0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a658f726e6f37d4b3f2739b4ffe3b9fb0">copy_X_train</a></td></tr>
<tr class="separator:a658f726e6f37d4b3f2739b4ffe3b9fb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54770fcb8d43e6d4cfe331733dd2a95f" id="r_a54770fcb8d43e6d4cfe331733dd2a95f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a54770fcb8d43e6d4cfe331733dd2a95f">random_state</a></td></tr>
<tr class="separator:a54770fcb8d43e6d4cfe331733dd2a95f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ad32ca507113ebc23df62d98f85b1ea" id="r_a6ad32ca507113ebc23df62d98f85b1ea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a6ad32ca507113ebc23df62d98f85b1ea">kernel_</a></td></tr>
<tr class="separator:a6ad32ca507113ebc23df62d98f85b1ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67461b5efc90794919da2f89486f2c5d" id="r_a67461b5efc90794919da2f89486f2c5d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a67461b5efc90794919da2f89486f2c5d">X_train_</a></td></tr>
<tr class="separator:a67461b5efc90794919da2f89486f2c5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd7e37c72447f44c7ba2a44c36b77dda" id="r_afd7e37c72447f44c7ba2a44c36b77dda"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#afd7e37c72447f44c7ba2a44c36b77dda">y_train_</a></td></tr>
<tr class="separator:afd7e37c72447f44c7ba2a44c36b77dda"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c36e6a2ff97d218370d8ceea7238a5a" id="r_a2c36e6a2ff97d218370d8ceea7238a5a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a2c36e6a2ff97d218370d8ceea7238a5a">log_marginal_likelihood_value_</a></td></tr>
<tr class="separator:a2c36e6a2ff97d218370d8ceea7238a5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee925c9908927bcbef5a4f38b928aced" id="r_aee925c9908927bcbef5a4f38b928aced"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#aee925c9908927bcbef5a4f38b928aced">L_</a></td></tr>
<tr class="separator:aee925c9908927bcbef5a4f38b928aced"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3db83b2a609a2c39200fdd4506adbc66" id="r_a3db83b2a609a2c39200fdd4506adbc66"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a3db83b2a609a2c39200fdd4506adbc66">alpha_</a></td></tr>
<tr class="separator:a3db83b2a609a2c39200fdd4506adbc66"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:a66d54a0fbf5710ff325104e2d2c9d7b0 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator" id="r_a66d54a0fbf5710ff325104e2d2c9d7b0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a66d54a0fbf5710ff325104e2d2c9d7b0">n_features_in_</a></td></tr>
<tr class="separator:a66d54a0fbf5710ff325104e2d2c9d7b0 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ad6c8c0f63c0b4c97c501765e93cc78 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator" id="r_a2ad6c8c0f63c0b4c97c501765e93cc78"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a2ad6c8c0f63c0b4c97c501765e93cc78">feature_names_in_</a></td></tr>
<tr class="separator:a2ad6c8c0f63c0b4c97c501765e93cc78 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-methods" name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:ae8cc5e8995a9e88832c54c6a0e4dcb32" id="r_ae8cc5e8995a9e88832c54c6a0e4dcb32"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#ae8cc5e8995a9e88832c54c6a0e4dcb32">_constrained_optimization</a> (self, obj_func, initial_theta, bounds)</td></tr>
<tr class="separator:ae8cc5e8995a9e88832c54c6a0e4dcb32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a735fc4cc3fce277b38ce9c9fe1f584e2" id="r_a735fc4cc3fce277b38ce9c9fe1f584e2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a735fc4cc3fce277b38ce9c9fe1f584e2">_more_tags</a> (self)</td></tr>
<tr class="separator:a735fc4cc3fce277b38ce9c9fe1f584e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:ab7620691376c89dd6b11583a7ec88056 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ab7620691376c89dd6b11583a7ec88056"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ab7620691376c89dd6b11583a7ec88056">_get_param_names</a> (cls)</td></tr>
<tr class="separator:ab7620691376c89dd6b11583a7ec88056 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17c0074e0a07bf88909d50bbd89a2735 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a17c0074e0a07bf88909d50bbd89a2735"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a17c0074e0a07bf88909d50bbd89a2735">_get_tags</a> (self)</td></tr>
<tr class="separator:a17c0074e0a07bf88909d50bbd89a2735 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeced67fac6e13c3a6e7f6866e83c02f5 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_aeced67fac6e13c3a6e7f6866e83c02f5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#aeced67fac6e13c3a6e7f6866e83c02f5">_check_n_features</a> (self, X, reset)</td></tr>
<tr class="separator:aeced67fac6e13c3a6e7f6866e83c02f5 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a167be2ae43526843680356c2b2712125 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a167be2ae43526843680356c2b2712125"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a167be2ae43526843680356c2b2712125">_check_feature_names</a> (self, X, *reset)</td></tr>
<tr class="separator:a167be2ae43526843680356c2b2712125 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a846c04fab4a234189ebac04e5ed9b8a6 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a846c04fab4a234189ebac04e5ed9b8a6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a846c04fab4a234189ebac04e5ed9b8a6">_validate_data</a> (self, X=&quot;no_validation&quot;, y=&quot;no_validation&quot;, reset=True, validate_separately=False, **check_params)</td></tr>
<tr class="separator:a846c04fab4a234189ebac04e5ed9b8a6 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8f8e87d8b09ffa6ac9a38403510b839 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_aa8f8e87d8b09ffa6ac9a38403510b839"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#aa8f8e87d8b09ffa6ac9a38403510b839">_validate_params</a> (self)</td></tr>
<tr class="separator:aa8f8e87d8b09ffa6ac9a38403510b839 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f2a9aeff923062d9b8d64ff8ae9a15f inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a1f2a9aeff923062d9b8d64ff8ae9a15f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a1f2a9aeff923062d9b8d64ff8ae9a15f">_repr_html_</a> (self)</td></tr>
<tr class="separator:a1f2a9aeff923062d9b8d64ff8ae9a15f inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab49884d0348bb8bf19b65d1d68cffcaf inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ab49884d0348bb8bf19b65d1d68cffcaf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ab49884d0348bb8bf19b65d1d68cffcaf">_repr_html_inner</a> (self)</td></tr>
<tr class="separator:ab49884d0348bb8bf19b65d1d68cffcaf inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1dde4ef8aac627f20f205e41a0b14efc inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a1dde4ef8aac627f20f205e41a0b14efc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a1dde4ef8aac627f20f205e41a0b14efc">_repr_mimebundle_</a> (self, **kwargs)</td></tr>
<tr class="separator:a1dde4ef8aac627f20f205e41a0b14efc inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-attribs" name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a5313f334aba0f90ef98f380e5b552181" id="r_a5313f334aba0f90ef98f380e5b552181"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a5313f334aba0f90ef98f380e5b552181">_rng</a></td></tr>
<tr class="separator:a5313f334aba0f90ef98f380e5b552181"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca3e904033b5bfa2f41362d228d94a39" id="r_aca3e904033b5bfa2f41362d228d94a39"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#aca3e904033b5bfa2f41362d228d94a39">_y_train_mean</a></td></tr>
<tr class="separator:aca3e904033b5bfa2f41362d228d94a39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38d727c8ede6547f8381384c33f1790e" id="r_a38d727c8ede6547f8381384c33f1790e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#a38d727c8ede6547f8381384c33f1790e">_y_train_std</a></td></tr>
<tr class="separator:a38d727c8ede6547f8381384c33f1790e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_attribs_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pro_attribs_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Protected Attributes inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:aa788e7d07aae196ad4045be35ec03ebd inherit pro_attribs_classsklearn_1_1base_1_1_base_estimator" id="r_aa788e7d07aae196ad4045be35ec03ebd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#aa788e7d07aae196ad4045be35ec03ebd">_parameter_constraints</a></td></tr>
<tr class="separator:aa788e7d07aae196ad4045be35ec03ebd inherit pro_attribs_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-static-attribs" name="pro-static-attribs"></a>
Static Protected Attributes</h2></td></tr>
<tr class="memitem:af1c43721a8c2c3e25194e651e87a46c5" id="r_af1c43721a8c2c3e25194e651e87a46c5"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpr_1_1_gaussian_process_regressor.html#af1c43721a8c2c3e25194e651e87a46c5">_parameter_constraints</a></td></tr>
<tr class="separator:af1c43721a8c2c3e25194e651e87a46c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_static_attribs_classsklearn_1_1base_1_1_regressor_mixin"><td colspan="2" onclick="javascript:toggleInherit('pro_static_attribs_classsklearn_1_1base_1_1_regressor_mixin')"><img src="closed.png" alt="-"/>&#160;Static Protected Attributes inherited from <a class="el" href="classsklearn_1_1base_1_1_regressor_mixin.html">sklearn.base.RegressorMixin</a></td></tr>
<tr class="memitem:aba1660973f816763e0ab74f0becd1a06 inherit pro_static_attribs_classsklearn_1_1base_1_1_regressor_mixin" id="r_aba1660973f816763e0ab74f0becd1a06"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_regressor_mixin.html#aba1660973f816763e0ab74f0becd1a06">_estimator_type</a> = &quot;regressor&quot;</td></tr>
<tr class="separator:aba1660973f816763e0ab74f0becd1a06 inherit pro_static_attribs_classsklearn_1_1base_1_1_regressor_mixin"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Gaussian process regression (GPR).

The implementation is based on Algorithm 2.1 of [RW2006]_.

In addition to standard scikit-learn estimator API,
:class:`GaussianProcessRegressor`:

   * allows prediction without prior fitting (based on the GP prior)
   * provides an additional method `sample_y(X)`, which evaluates samples
     drawn from the GPR (prior or posterior) at given inputs
   * exposes a method `log_marginal_likelihood(theta)`, which can be used
     externally for other ways of selecting hyperparameters, e.g., via
     Markov chain Monte Carlo.

Read more in the :ref:`User Guide &lt;gaussian_process&gt;`.

.. versionadded:: 0.18

Parameters
----------
kernel : kernel instance, default=None
    The kernel specifying the covariance function of the GP. If None is
    passed, the kernel ``ConstantKernel(1.0, constant_value_bounds="fixed")
    * RBF(1.0, length_scale_bounds="fixed")`` is used as default. Note that
    the kernel hyperparameters are optimized during fitting unless the
    bounds are marked as "fixed".

alpha : float or ndarray of shape (n_samples,), default=1e-10
    Value added to the diagonal of the kernel matrix during fitting.
    This can prevent a potential numerical issue during fitting, by
    ensuring that the calculated values form a positive definite matrix.
    It can also be interpreted as the variance of additional Gaussian
    measurement noise on the training observations. Note that this is
    different from using a `WhiteKernel`. If an array is passed, it must
    have the same number of entries as the data used for fitting and is
    used as datapoint-dependent noise level. Allowing to specify the
    noise level directly as a parameter is mainly for convenience and
    for consistency with :class:`~sklearn.linear_model.Ridge`.

optimizer : "fmin_l_bfgs_b", callable or None, default="fmin_l_bfgs_b"
    Can either be one of the internally supported optimizers for optimizing
    the kernel's parameters, specified by a string, or an externally
    defined optimizer passed as a callable. If a callable is passed, it
    must have the signature::

        def optimizer(obj_func, initial_theta, bounds):
            # * 'obj_func': the objective function to be minimized, which
            #   takes the hyperparameters theta as a parameter and an
            #   optional flag eval_gradient, which determines if the
            #   gradient is returned additionally to the function value
            # * 'initial_theta': the initial value for theta, which can be
            #   used by local optimizers
            # * 'bounds': the bounds on the values of theta
            ....
            # Returned are the best found hyperparameters theta and
            # the corresponding value of the target function.
            return theta_opt, func_min

    Per default, the L-BFGS-B algorithm from `scipy.optimize.minimize`
    is used. If None is passed, the kernel's parameters are kept fixed.
    Available internal optimizers are: `{'fmin_l_bfgs_b'}`.

n_restarts_optimizer : int, default=0
    The number of restarts of the optimizer for finding the kernel's
    parameters which maximize the log-marginal likelihood. The first run
    of the optimizer is performed from the kernel's initial parameters,
    the remaining ones (if any) from thetas sampled log-uniform randomly
    from the space of allowed theta-values. If greater than 0, all bounds
    must be finite. Note that `n_restarts_optimizer == 0` implies that one
    run is performed.

normalize_y : bool, default=False
    Whether or not to normalize the target values `y` by removing the mean
    and scaling to unit-variance. This is recommended for cases where
    zero-mean, unit-variance priors are used. Note that, in this
    implementation, the normalisation is reversed before the GP predictions
    are reported.

    .. versionchanged:: 0.23

copy_X_train : bool, default=True
    If True, a persistent copy of the training data is stored in the
    object. Otherwise, just a reference to the training data is stored,
    which might cause predictions to change if the data is modified
    externally.

random_state : int, RandomState instance or None, default=None
    Determines random number generation used to initialize the centers.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Attributes
----------
X_train_ : array-like of shape (n_samples, n_features) or list of object
    Feature vectors or other representations of training data (also
    required for prediction).

y_train_ : array-like of shape (n_samples,) or (n_samples, n_targets)
    Target values in training data (also required for prediction).

kernel_ : kernel instance
    The kernel used for prediction. The structure of the kernel is the
    same as the one passed as parameter but with optimized hyperparameters.

L_ : array-like of shape (n_samples, n_samples)
    Lower-triangular Cholesky decomposition of the kernel in ``X_train_``.

alpha_ : array-like of shape (n_samples,)
    Dual coefficients of training data points in kernel space.

log_marginal_likelihood_value_ : float
    The log-marginal-likelihood of ``self.kernel_.theta``.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

See Also
--------
GaussianProcessClassifier : Gaussian process classification (GPC)
    based on Laplace approximation.

References
----------
.. [RW2006] `Carl E. Rasmussen and Christopher K.I. Williams,
   "Gaussian Processes for Machine Learning",
   MIT Press 2006 &lt;https://www.gaussianprocess.org/gpml/chapters/RW.pdf&gt;`_

Examples
--------
&gt;&gt;&gt; from sklearn.datasets import make_friedman2
&gt;&gt;&gt; from sklearn.gaussian_process import GaussianProcessRegressor
&gt;&gt;&gt; from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel
&gt;&gt;&gt; X, y = make_friedman2(n_samples=500, noise=0, random_state=0)
&gt;&gt;&gt; kernel = DotProduct() + WhiteKernel()
&gt;&gt;&gt; gpr = GaussianProcessRegressor(kernel=kernel,
...         random_state=0).fit(X, y)
&gt;&gt;&gt; gpr.score(X, y)
0.3680...
&gt;&gt;&gt; gpr.predict(X[:2,:], return_std=True)
(array([653.0..., 592.1...]), array([316.6..., 316.6...]))
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="afa340368607f3efd0a9484049fb56e5a" name="afa340368607f3efd0a9484049fb56e5a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afa340368607f3efd0a9484049fb56e5a">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>kernel</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>1e-10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>optimizer</em> = <code>&quot;fmin_l_bfgs_b&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_restarts_optimizer</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize_y</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>copy_X_train</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  197</span>    ):</div>
<div class="line"><span class="lineno">  198</span>        self.kernel = kernel</div>
<div class="line"><span class="lineno">  199</span>        self.alpha = alpha</div>
<div class="line"><span class="lineno">  200</span>        self.optimizer = optimizer</div>
<div class="line"><span class="lineno">  201</span>        self.n_restarts_optimizer = n_restarts_optimizer</div>
<div class="line"><span class="lineno">  202</span>        self.normalize_y = normalize_y</div>
<div class="line"><span class="lineno">  203</span>        self.copy_X_train = copy_X_train</div>
<div class="line"><span class="lineno">  204</span>        self.random_state = random_state</div>
<div class="line"><span class="lineno">  205</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="ae8cc5e8995a9e88832c54c6a0e4dcb32" name="ae8cc5e8995a9e88832c54c6a0e4dcb32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae8cc5e8995a9e88832c54c6a0e4dcb32">&#9670;&#160;</a></span>_constrained_optimization()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor._constrained_optimization </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>obj_func</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>initial_theta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>bounds</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  620</span>    <span class="keyword">def </span>_constrained_optimization(self, obj_func, initial_theta, bounds):</div>
<div class="line"><span class="lineno">  621</span>        <span class="keywordflow">if</span> self.optimizer == <span class="stringliteral">&quot;fmin_l_bfgs_b&quot;</span>:</div>
<div class="line"><span class="lineno">  622</span>            opt_res = scipy.optimize.minimize(</div>
<div class="line"><span class="lineno">  623</span>                obj_func,</div>
<div class="line"><span class="lineno">  624</span>                initial_theta,</div>
<div class="line"><span class="lineno">  625</span>                method=<span class="stringliteral">&quot;L-BFGS-B&quot;</span>,</div>
<div class="line"><span class="lineno">  626</span>                jac=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  627</span>                bounds=bounds,</div>
<div class="line"><span class="lineno">  628</span>            )</div>
<div class="line"><span class="lineno">  629</span>            _check_optimize_result(<span class="stringliteral">&quot;lbfgs&quot;</span>, opt_res)</div>
<div class="line"><span class="lineno">  630</span>            theta_opt, func_min = opt_res.x, opt_res.fun</div>
<div class="line"><span class="lineno">  631</span>        <span class="keywordflow">elif</span> callable(self.optimizer):</div>
<div class="line"><span class="lineno">  632</span>            theta_opt, func_min = self.optimizer(obj_func, initial_theta, bounds=bounds)</div>
<div class="line"><span class="lineno">  633</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  634</span>            <span class="keywordflow">raise</span> ValueError(f<span class="stringliteral">&quot;Unknown optimizer {self.optimizer}.&quot;</span>)</div>
<div class="line"><span class="lineno">  635</span> </div>
<div class="line"><span class="lineno">  636</span>        <span class="keywordflow">return</span> theta_opt, func_min</div>
<div class="line"><span class="lineno">  637</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a735fc4cc3fce277b38ce9c9fe1f584e2" name="a735fc4cc3fce277b38ce9c9fe1f584e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a735fc4cc3fce277b38ce9c9fe1f584e2">&#9670;&#160;</a></span>_more_tags()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor._more_tags </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Reimplemented from <a class="el" href="classsklearn_1_1base_1_1_multi_output_mixin.html#a2c8364dc37caf2b1f25c5409e950327e">sklearn.base.MultiOutputMixin</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  638</span>    <span class="keyword">def </span>_more_tags(self):</div>
<div class="line"><span class="lineno">  639</span>        <span class="keywordflow">return</span> {<span class="stringliteral">&quot;requires_fit&quot;</span>: <span class="keyword">False</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="ade4077cc91e436180791b0f6a7bc0aba" name="ade4077cc91e436180791b0f6a7bc0aba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade4077cc91e436180791b0f6a7bc0aba">&#9670;&#160;</a></span>fit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Fit Gaussian process regression model.

Parameters
----------
X : array-like of shape (n_samples, n_features) or list of object
    Feature vectors or other representations of training data.

y : array-like of shape (n_samples,) or (n_samples, n_targets)
    Target values.

Returns
-------
self : object
    GaussianProcessRegressor class instance.
</pre> <div class="fragment"><div class="line"><span class="lineno">  206</span>    <span class="keyword">def </span>fit(self, X, y):</div>
<div class="line"><span class="lineno">  207</span>        <span class="stringliteral">&quot;&quot;&quot;Fit Gaussian process regression model.</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">        X : array-like of shape (n_samples, n_features) or list of object</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">            Feature vectors or other representations of training data.</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">        y : array-like of shape (n_samples,) or (n_samples, n_targets)</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">            Target values.</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">        self : object</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">            GaussianProcessRegressor class instance.</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  222</span>        self._validate_params()</div>
<div class="line"><span class="lineno">  223</span> </div>
<div class="line"><span class="lineno">  224</span>        <span class="keywordflow">if</span> self.kernel <span class="keywordflow">is</span> <span class="keywordtype">None</span>:  <span class="comment"># Use an RBF kernel as default</span></div>
<div class="line"><span class="lineno">  225</span>            self.kernel_ = C(1.0, constant_value_bounds=<span class="stringliteral">&quot;fixed&quot;</span>) * RBF(</div>
<div class="line"><span class="lineno">  226</span>                1.0, length_scale_bounds=<span class="stringliteral">&quot;fixed&quot;</span></div>
<div class="line"><span class="lineno">  227</span>            )</div>
<div class="line"><span class="lineno">  228</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  229</span>            self.kernel_ = clone(self.kernel)</div>
<div class="line"><span class="lineno">  230</span> </div>
<div class="line"><span class="lineno">  231</span>        self._rng = check_random_state(self.random_state)</div>
<div class="line"><span class="lineno">  232</span> </div>
<div class="line"><span class="lineno">  233</span>        <span class="keywordflow">if</span> self.kernel_.requires_vector_input:</div>
<div class="line"><span class="lineno">  234</span>            dtype, ensure_2d = <span class="stringliteral">&quot;numeric&quot;</span>, <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  235</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  236</span>            dtype, ensure_2d = <span class="keywordtype">None</span>, <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  237</span>        X, y = self._validate_data(</div>
<div class="line"><span class="lineno">  238</span>            X,</div>
<div class="line"><span class="lineno">  239</span>            y,</div>
<div class="line"><span class="lineno">  240</span>            multi_output=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  241</span>            y_numeric=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  242</span>            ensure_2d=ensure_2d,</div>
<div class="line"><span class="lineno">  243</span>            dtype=dtype,</div>
<div class="line"><span class="lineno">  244</span>        )</div>
<div class="line"><span class="lineno">  245</span> </div>
<div class="line"><span class="lineno">  246</span>        <span class="comment"># Normalize target value</span></div>
<div class="line"><span class="lineno">  247</span>        <span class="keywordflow">if</span> self.normalize_y:</div>
<div class="line"><span class="lineno">  248</span>            self._y_train_mean = np.mean(y, axis=0)</div>
<div class="line"><span class="lineno">  249</span>            self._y_train_std = _handle_zeros_in_scale(np.std(y, axis=0), copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  250</span> </div>
<div class="line"><span class="lineno">  251</span>            <span class="comment"># Remove mean and make unit variance</span></div>
<div class="line"><span class="lineno">  252</span>            y = (y - self._y_train_mean) / self._y_train_std</div>
<div class="line"><span class="lineno">  253</span> </div>
<div class="line"><span class="lineno">  254</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  255</span>            shape_y_stats = (y.shape[1],) <span class="keywordflow">if</span> y.ndim == 2 <span class="keywordflow">else</span> 1</div>
<div class="line"><span class="lineno">  256</span>            self._y_train_mean = np.zeros(shape=shape_y_stats)</div>
<div class="line"><span class="lineno">  257</span>            self._y_train_std = np.ones(shape=shape_y_stats)</div>
<div class="line"><span class="lineno">  258</span> </div>
<div class="line"><span class="lineno">  259</span>        <span class="keywordflow">if</span> np.iterable(self.alpha) <span class="keywordflow">and</span> self.alpha.shape[0] != y.shape[0]:</div>
<div class="line"><span class="lineno">  260</span>            <span class="keywordflow">if</span> self.alpha.shape[0] == 1:</div>
<div class="line"><span class="lineno">  261</span>                self.alpha = self.alpha[0]</div>
<div class="line"><span class="lineno">  262</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  263</span>                <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  264</span>                    <span class="stringliteral">&quot;alpha must be a scalar or an array with same number of &quot;</span></div>
<div class="line"><span class="lineno">  265</span>                    f<span class="stringliteral">&quot;entries as y. ({self.alpha.shape[0]} != {y.shape[0]})&quot;</span></div>
<div class="line"><span class="lineno">  266</span>                )</div>
<div class="line"><span class="lineno">  267</span> </div>
<div class="line"><span class="lineno">  268</span>        self.X_train_ = np.copy(X) <span class="keywordflow">if</span> self.copy_X_train <span class="keywordflow">else</span> X</div>
<div class="line"><span class="lineno">  269</span>        self.y_train_ = np.copy(y) <span class="keywordflow">if</span> self.copy_X_train <span class="keywordflow">else</span> y</div>
<div class="line"><span class="lineno">  270</span> </div>
<div class="line"><span class="lineno">  271</span>        <span class="keywordflow">if</span> self.optimizer <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> self.kernel_.n_dims &gt; 0:</div>
<div class="line"><span class="lineno">  272</span>            <span class="comment"># Choose hyperparameters based on maximizing the log-marginal</span></div>
<div class="line"><span class="lineno">  273</span>            <span class="comment"># likelihood (potentially starting from several initial values)</span></div>
<div class="line"><span class="lineno">  274</span>            <span class="keyword">def </span>obj_func(theta, eval_gradient=True):</div>
<div class="line"><span class="lineno">  275</span>                <span class="keywordflow">if</span> eval_gradient:</div>
<div class="line"><span class="lineno">  276</span>                    lml, grad = self.log_marginal_likelihood(</div>
<div class="line"><span class="lineno">  277</span>                        theta, eval_gradient=<span class="keyword">True</span>, clone_kernel=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  278</span>                    )</div>
<div class="line"><span class="lineno">  279</span>                    <span class="keywordflow">return</span> -lml, -grad</div>
<div class="line"><span class="lineno">  280</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  281</span>                    <span class="keywordflow">return</span> -self.log_marginal_likelihood(theta, clone_kernel=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  282</span> </div>
<div class="line"><span class="lineno">  283</span>            <span class="comment"># First optimize starting from theta specified in kernel</span></div>
<div class="line"><span class="lineno">  284</span>            optima = [</div>
<div class="line"><span class="lineno">  285</span>                (</div>
<div class="line"><span class="lineno">  286</span>                    self._constrained_optimization(</div>
<div class="line"><span class="lineno">  287</span>                        obj_func, self.kernel_.theta, self.kernel_.bounds</div>
<div class="line"><span class="lineno">  288</span>                    )</div>
<div class="line"><span class="lineno">  289</span>                )</div>
<div class="line"><span class="lineno">  290</span>            ]</div>
<div class="line"><span class="lineno">  291</span> </div>
<div class="line"><span class="lineno">  292</span>            <span class="comment"># Additional runs are performed from log-uniform chosen initial</span></div>
<div class="line"><span class="lineno">  293</span>            <span class="comment"># theta</span></div>
<div class="line"><span class="lineno">  294</span>            <span class="keywordflow">if</span> self.n_restarts_optimizer &gt; 0:</div>
<div class="line"><span class="lineno">  295</span>                <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.isfinite(self.kernel_.bounds).all():</div>
<div class="line"><span class="lineno">  296</span>                    <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  297</span>                        <span class="stringliteral">&quot;Multiple optimizer restarts (n_restarts_optimizer&gt;0) &quot;</span></div>
<div class="line"><span class="lineno">  298</span>                        <span class="stringliteral">&quot;requires that all bounds are finite.&quot;</span></div>
<div class="line"><span class="lineno">  299</span>                    )</div>
<div class="line"><span class="lineno">  300</span>                bounds = self.kernel_.bounds</div>
<div class="line"><span class="lineno">  301</span>                <span class="keywordflow">for</span> iteration <span class="keywordflow">in</span> range(self.n_restarts_optimizer):</div>
<div class="line"><span class="lineno">  302</span>                    theta_initial = self._rng.uniform(bounds[:, 0], bounds[:, 1])</div>
<div class="line"><span class="lineno">  303</span>                    optima.append(</div>
<div class="line"><span class="lineno">  304</span>                        self._constrained_optimization(obj_func, theta_initial, bounds)</div>
<div class="line"><span class="lineno">  305</span>                    )</div>
<div class="line"><span class="lineno">  306</span>            <span class="comment"># Select result from run with minimal (negative) log-marginal</span></div>
<div class="line"><span class="lineno">  307</span>            <span class="comment"># likelihood</span></div>
<div class="line"><span class="lineno">  308</span>            lml_values = list(map(itemgetter(1), optima))</div>
<div class="line"><span class="lineno">  309</span>            self.kernel_.theta = optima[np.argmin(lml_values)][0]</div>
<div class="line"><span class="lineno">  310</span>            self.kernel_._check_bounds_params()</div>
<div class="line"><span class="lineno">  311</span> </div>
<div class="line"><span class="lineno">  312</span>            self.log_marginal_likelihood_value_ = -np.min(lml_values)</div>
<div class="line"><span class="lineno">  313</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  314</span>            self.log_marginal_likelihood_value_ = self.log_marginal_likelihood(</div>
<div class="line"><span class="lineno">  315</span>                self.kernel_.theta, clone_kernel=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  316</span>            )</div>
<div class="line"><span class="lineno">  317</span> </div>
<div class="line"><span class="lineno">  318</span>        <span class="comment"># Precompute quantities required for predictions which are independent</span></div>
<div class="line"><span class="lineno">  319</span>        <span class="comment"># of actual query points</span></div>
<div class="line"><span class="lineno">  320</span>        <span class="comment"># Alg. 2.1, page 19, line 2 -&gt; L = cholesky(K + sigma^2 I)</span></div>
<div class="line"><span class="lineno">  321</span>        K = self.kernel_(self.X_train_)</div>
<div class="line"><span class="lineno">  322</span>        K[np.diag_indices_from(K)] += self.alpha</div>
<div class="line"><span class="lineno">  323</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  324</span>            self.L_ = cholesky(K, lower=GPR_CHOLESKY_LOWER, check_finite=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  325</span>        <span class="keywordflow">except</span> np.linalg.LinAlgError <span class="keyword">as</span> exc:</div>
<div class="line"><span class="lineno">  326</span>            exc.args = (</div>
<div class="line"><span class="lineno">  327</span>                f<span class="stringliteral">&quot;The kernel, {self.kernel_}, is not returning a positive &quot;</span></div>
<div class="line"><span class="lineno">  328</span>                <span class="stringliteral">&quot;definite matrix. Try gradually increasing the &#39;alpha&#39; &quot;</span></div>
<div class="line"><span class="lineno">  329</span>                <span class="stringliteral">&quot;parameter of your GaussianProcessRegressor estimator.&quot;</span>,</div>
<div class="line"><span class="lineno">  330</span>            ) + exc.args</div>
<div class="line"><span class="lineno">  331</span>            <span class="keywordflow">raise</span></div>
<div class="line"><span class="lineno">  332</span>        <span class="comment"># Alg 2.1, page 19, line 3 -&gt; alpha = L^T \ (L \ y)</span></div>
<div class="line"><span class="lineno">  333</span>        self.alpha_ = cho_solve(</div>
<div class="line"><span class="lineno">  334</span>            (self.L_, GPR_CHOLESKY_LOWER),</div>
<div class="line"><span class="lineno">  335</span>            self.y_train_,</div>
<div class="line"><span class="lineno">  336</span>            check_finite=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  337</span>        )</div>
<div class="line"><span class="lineno">  338</span>        <span class="keywordflow">return</span> self</div>
<div class="line"><span class="lineno">  339</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae13a5f19a008496c28127232c7df7615" name="ae13a5f19a008496c28127232c7df7615"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae13a5f19a008496c28127232c7df7615">&#9670;&#160;</a></span>log_marginal_likelihood()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>theta</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>eval_gradient</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clone_kernel</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return log-marginal likelihood of theta for training data.

Parameters
----------
theta : array-like of shape (n_kernel_params,) default=None
    Kernel hyperparameters for which the log-marginal likelihood is
    evaluated. If None, the precomputed log_marginal_likelihood
    of ``self.kernel_.theta`` is returned.

eval_gradient : bool, default=False
    If True, the gradient of the log-marginal likelihood with respect
    to the kernel hyperparameters at position theta is returned
    additionally. If True, theta must not be None.

clone_kernel : bool, default=True
    If True, the kernel attribute is copied. If False, the kernel
    attribute is modified, but may result in a performance improvement.

Returns
-------
log_likelihood : float
    Log-marginal likelihood of theta for training data.

log_likelihood_gradient : ndarray of shape (n_kernel_params,), optional
    Gradient of the log-marginal likelihood with respect to the kernel
    hyperparameters at position theta.
    Only returned when eval_gradient is True.
</pre> <div class="fragment"><div class="line"><span class="lineno">  505</span>    ):</div>
<div class="line"><span class="lineno">  506</span>        <span class="stringliteral">&quot;&quot;&quot;Return log-marginal likelihood of theta for training data.</span></div>
<div class="line"><span class="lineno">  507</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  508</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  509</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  510</span><span class="stringliteral">        theta : array-like of shape (n_kernel_params,) default=None</span></div>
<div class="line"><span class="lineno">  511</span><span class="stringliteral">            Kernel hyperparameters for which the log-marginal likelihood is</span></div>
<div class="line"><span class="lineno">  512</span><span class="stringliteral">            evaluated. If None, the precomputed log_marginal_likelihood</span></div>
<div class="line"><span class="lineno">  513</span><span class="stringliteral">            of ``self.kernel_.theta`` is returned.</span></div>
<div class="line"><span class="lineno">  514</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  515</span><span class="stringliteral">        eval_gradient : bool, default=False</span></div>
<div class="line"><span class="lineno">  516</span><span class="stringliteral">            If True, the gradient of the log-marginal likelihood with respect</span></div>
<div class="line"><span class="lineno">  517</span><span class="stringliteral">            to the kernel hyperparameters at position theta is returned</span></div>
<div class="line"><span class="lineno">  518</span><span class="stringliteral">            additionally. If True, theta must not be None.</span></div>
<div class="line"><span class="lineno">  519</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  520</span><span class="stringliteral">        clone_kernel : bool, default=True</span></div>
<div class="line"><span class="lineno">  521</span><span class="stringliteral">            If True, the kernel attribute is copied. If False, the kernel</span></div>
<div class="line"><span class="lineno">  522</span><span class="stringliteral">            attribute is modified, but may result in a performance improvement.</span></div>
<div class="line"><span class="lineno">  523</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  524</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  525</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  526</span><span class="stringliteral">        log_likelihood : float</span></div>
<div class="line"><span class="lineno">  527</span><span class="stringliteral">            Log-marginal likelihood of theta for training data.</span></div>
<div class="line"><span class="lineno">  528</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  529</span><span class="stringliteral">        log_likelihood_gradient : ndarray of shape (n_kernel_params,), optional</span></div>
<div class="line"><span class="lineno">  530</span><span class="stringliteral">            Gradient of the log-marginal likelihood with respect to the kernel</span></div>
<div class="line"><span class="lineno">  531</span><span class="stringliteral">            hyperparameters at position theta.</span></div>
<div class="line"><span class="lineno">  532</span><span class="stringliteral">            Only returned when eval_gradient is True.</span></div>
<div class="line"><span class="lineno">  533</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  534</span>        <span class="keywordflow">if</span> theta <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  535</span>            <span class="keywordflow">if</span> eval_gradient:</div>
<div class="line"><span class="lineno">  536</span>                <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Gradient can only be evaluated for theta!=None&quot;</span>)</div>
<div class="line"><span class="lineno">  537</span>            <span class="keywordflow">return</span> self.log_marginal_likelihood_value_</div>
<div class="line"><span class="lineno">  538</span> </div>
<div class="line"><span class="lineno">  539</span>        <span class="keywordflow">if</span> clone_kernel:</div>
<div class="line"><span class="lineno">  540</span>            kernel = self.kernel_.clone_with_theta(theta)</div>
<div class="line"><span class="lineno">  541</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  542</span>            kernel = self.kernel_</div>
<div class="line"><span class="lineno">  543</span>            kernel.theta = theta</div>
<div class="line"><span class="lineno">  544</span> </div>
<div class="line"><span class="lineno">  545</span>        <span class="keywordflow">if</span> eval_gradient:</div>
<div class="line"><span class="lineno">  546</span>            K, K_gradient = kernel(self.X_train_, eval_gradient=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  547</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  548</span>            K = kernel(self.X_train_)</div>
<div class="line"><span class="lineno">  549</span> </div>
<div class="line"><span class="lineno">  550</span>        <span class="comment"># Alg. 2.1, page 19, line 2 -&gt; L = cholesky(K + sigma^2 I)</span></div>
<div class="line"><span class="lineno">  551</span>        K[np.diag_indices_from(K)] += self.alpha</div>
<div class="line"><span class="lineno">  552</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  553</span>            L = cholesky(K, lower=GPR_CHOLESKY_LOWER, check_finite=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  554</span>        <span class="keywordflow">except</span> np.linalg.LinAlgError:</div>
<div class="line"><span class="lineno">  555</span>            <span class="keywordflow">return</span> (-np.inf, np.zeros_like(theta)) <span class="keywordflow">if</span> eval_gradient <span class="keywordflow">else</span> -np.inf</div>
<div class="line"><span class="lineno">  556</span> </div>
<div class="line"><span class="lineno">  557</span>        <span class="comment"># Support multi-dimensional output of self.y_train_</span></div>
<div class="line"><span class="lineno">  558</span>        y_train = self.y_train_</div>
<div class="line"><span class="lineno">  559</span>        <span class="keywordflow">if</span> y_train.ndim == 1:</div>
<div class="line"><span class="lineno">  560</span>            y_train = y_train[:, np.newaxis]</div>
<div class="line"><span class="lineno">  561</span> </div>
<div class="line"><span class="lineno">  562</span>        <span class="comment"># Alg 2.1, page 19, line 3 -&gt; alpha = L^T \ (L \ y)</span></div>
<div class="line"><span class="lineno">  563</span>        alpha = cho_solve((L, GPR_CHOLESKY_LOWER), y_train, check_finite=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  564</span> </div>
<div class="line"><span class="lineno">  565</span>        <span class="comment"># Alg 2.1, page 19, line 7</span></div>
<div class="line"><span class="lineno">  566</span>        <span class="comment"># -0.5 . y^T . alpha - sum(log(diag(L))) - n_samples / 2 log(2*pi)</span></div>
<div class="line"><span class="lineno">  567</span>        <span class="comment"># y is originally thought to be a (1, n_samples) row vector. However,</span></div>
<div class="line"><span class="lineno">  568</span>        <span class="comment"># in multioutputs, y is of shape (n_samples, 2) and we need to compute</span></div>
<div class="line"><span class="lineno">  569</span>        <span class="comment"># y^T . alpha for each output, independently using einsum. Thus, it</span></div>
<div class="line"><span class="lineno">  570</span>        <span class="comment"># is equivalent to:</span></div>
<div class="line"><span class="lineno">  571</span>        <span class="comment"># for output_idx in range(n_outputs):</span></div>
<div class="line"><span class="lineno">  572</span>        <span class="comment">#     log_likelihood_dims[output_idx] = (</span></div>
<div class="line"><span class="lineno">  573</span>        <span class="comment">#         y_train[:, [output_idx]] @ alpha[:, [output_idx]]</span></div>
<div class="line"><span class="lineno">  574</span>        <span class="comment">#     )</span></div>
<div class="line"><span class="lineno">  575</span>        log_likelihood_dims = -0.5 * np.einsum(<span class="stringliteral">&quot;ik,ik-&gt;k&quot;</span>, y_train, alpha)</div>
<div class="line"><span class="lineno">  576</span>        log_likelihood_dims -= np.log(np.diag(L)).sum()</div>
<div class="line"><span class="lineno">  577</span>        log_likelihood_dims -= K.shape[0] / 2 * np.log(2 * np.pi)</div>
<div class="line"><span class="lineno">  578</span>        <span class="comment"># the log likehood is sum-up across the outputs</span></div>
<div class="line"><span class="lineno">  579</span>        log_likelihood = log_likelihood_dims.sum(axis=-1)</div>
<div class="line"><span class="lineno">  580</span> </div>
<div class="line"><span class="lineno">  581</span>        <span class="keywordflow">if</span> eval_gradient:</div>
<div class="line"><span class="lineno">  582</span>            <span class="comment"># Eq. 5.9, p. 114, and footnote 5 in p. 114</span></div>
<div class="line"><span class="lineno">  583</span>            <span class="comment"># 0.5 * trace((alpha . alpha^T - K^-1) . K_gradient)</span></div>
<div class="line"><span class="lineno">  584</span>            <span class="comment"># alpha is supposed to be a vector of (n_samples,) elements. With</span></div>
<div class="line"><span class="lineno">  585</span>            <span class="comment"># multioutputs, alpha is a matrix of size (n_samples, n_outputs).</span></div>
<div class="line"><span class="lineno">  586</span>            <span class="comment"># Therefore, we want to construct a matrix of</span></div>
<div class="line"><span class="lineno">  587</span>            <span class="comment"># (n_samples, n_samples, n_outputs) equivalent to</span></div>
<div class="line"><span class="lineno">  588</span>            <span class="comment"># for output_idx in range(n_outputs):</span></div>
<div class="line"><span class="lineno">  589</span>            <span class="comment">#     output_alpha = alpha[:, [output_idx]]</span></div>
<div class="line"><span class="lineno">  590</span>            <span class="comment">#     inner_term[..., output_idx] = output_alpha @ output_alpha.T</span></div>
<div class="line"><span class="lineno">  591</span>            inner_term = np.einsum(<span class="stringliteral">&quot;ik,jk-&gt;ijk&quot;</span>, alpha, alpha)</div>
<div class="line"><span class="lineno">  592</span>            <span class="comment"># compute K^-1 of shape (n_samples, n_samples)</span></div>
<div class="line"><span class="lineno">  593</span>            K_inv = cho_solve(</div>
<div class="line"><span class="lineno">  594</span>                (L, GPR_CHOLESKY_LOWER), np.eye(K.shape[0]), check_finite=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  595</span>            )</div>
<div class="line"><span class="lineno">  596</span>            <span class="comment"># create a new axis to use broadcasting between inner_term and</span></div>
<div class="line"><span class="lineno">  597</span>            <span class="comment"># K_inv</span></div>
<div class="line"><span class="lineno">  598</span>            inner_term -= K_inv[..., np.newaxis]</div>
<div class="line"><span class="lineno">  599</span>            <span class="comment"># Since we are interested about the trace of</span></div>
<div class="line"><span class="lineno">  600</span>            <span class="comment"># inner_term @ K_gradient, we don&#39;t explicitly compute the</span></div>
<div class="line"><span class="lineno">  601</span>            <span class="comment"># matrix-by-matrix operation and instead use an einsum. Therefore</span></div>
<div class="line"><span class="lineno">  602</span>            <span class="comment"># it is equivalent to:</span></div>
<div class="line"><span class="lineno">  603</span>            <span class="comment"># for param_idx in range(n_kernel_params):</span></div>
<div class="line"><span class="lineno">  604</span>            <span class="comment">#     for output_idx in range(n_output):</span></div>
<div class="line"><span class="lineno">  605</span>            <span class="comment">#         log_likehood_gradient_dims[param_idx, output_idx] = (</span></div>
<div class="line"><span class="lineno">  606</span>            <span class="comment">#             inner_term[..., output_idx] @</span></div>
<div class="line"><span class="lineno">  607</span>            <span class="comment">#             K_gradient[..., param_idx]</span></div>
<div class="line"><span class="lineno">  608</span>            <span class="comment">#         )</span></div>
<div class="line"><span class="lineno">  609</span>            log_likelihood_gradient_dims = 0.5 * np.einsum(</div>
<div class="line"><span class="lineno">  610</span>                <span class="stringliteral">&quot;ijl,jik-&gt;kl&quot;</span>, inner_term, K_gradient</div>
<div class="line"><span class="lineno">  611</span>            )</div>
<div class="line"><span class="lineno">  612</span>            <span class="comment"># the log likehood gradient is the sum-up across the outputs</span></div>
<div class="line"><span class="lineno">  613</span>            log_likelihood_gradient = log_likelihood_gradient_dims.sum(axis=-1)</div>
<div class="line"><span class="lineno">  614</span> </div>
<div class="line"><span class="lineno">  615</span>        <span class="keywordflow">if</span> eval_gradient:</div>
<div class="line"><span class="lineno">  616</span>            <span class="keywordflow">return</span> log_likelihood, log_likelihood_gradient</div>
<div class="line"><span class="lineno">  617</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  618</span>            <span class="keywordflow">return</span> log_likelihood</div>
<div class="line"><span class="lineno">  619</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a390a70193d548557f9cdcd3775c2f3d2" name="a390a70193d548557f9cdcd3775c2f3d2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a390a70193d548557f9cdcd3775c2f3d2">&#9670;&#160;</a></span>predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_std</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_cov</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Predict using the Gaussian process regression model.

We can also predict based on an unfitted model by using the GP prior.
In addition to the mean of the predictive distribution, optionally also
returns its standard deviation (`return_std=True`) or covariance
(`return_cov=True`). Note that at most one of the two can be requested.

Parameters
----------
X : array-like of shape (n_samples, n_features) or list of object
    Query points where the GP is evaluated.

return_std : bool, default=False
    If True, the standard-deviation of the predictive distribution at
    the query points is returned along with the mean.

return_cov : bool, default=False
    If True, the covariance of the joint predictive distribution at
    the query points is returned along with the mean.

Returns
-------
y_mean : ndarray of shape (n_samples,) or (n_samples, n_targets)
    Mean of predictive distribution a query points.

y_std : ndarray of shape (n_samples,) or (n_samples, n_targets), optional
    Standard deviation of predictive distribution at query points.
    Only returned when `return_std` is True.

y_cov : ndarray of shape (n_samples, n_samples) or \
        (n_samples, n_samples, n_targets), optional
    Covariance of joint predictive distribution a query points.
    Only returned when `return_cov` is True.
</pre> <div class="fragment"><div class="line"><span class="lineno">  340</span>    <span class="keyword">def </span>predict(self, X, return_std=False, return_cov=False):</div>
<div class="line"><span class="lineno">  341</span>        <span class="stringliteral">&quot;&quot;&quot;Predict using the Gaussian process regression model.</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral">        We can also predict based on an unfitted model by using the GP prior.</span></div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">        In addition to the mean of the predictive distribution, optionally also</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral">        returns its standard deviation (`return_std=True`) or covariance</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">        (`return_cov=True`). Note that at most one of the two can be requested.</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">        X : array-like of shape (n_samples, n_features) or list of object</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">            Query points where the GP is evaluated.</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral">        return_std : bool, default=False</span></div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">            If True, the standard-deviation of the predictive distribution at</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">            the query points is returned along with the mean.</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">        return_cov : bool, default=False</span></div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral">            If True, the covariance of the joint predictive distribution at</span></div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral">            the query points is returned along with the mean.</span></div>
<div class="line"><span class="lineno">  360</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  361</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  363</span><span class="stringliteral">        y_mean : ndarray of shape (n_samples,) or (n_samples, n_targets)</span></div>
<div class="line"><span class="lineno">  364</span><span class="stringliteral">            Mean of predictive distribution a query points.</span></div>
<div class="line"><span class="lineno">  365</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  366</span><span class="stringliteral">        y_std : ndarray of shape (n_samples,) or (n_samples, n_targets), optional</span></div>
<div class="line"><span class="lineno">  367</span><span class="stringliteral">            Standard deviation of predictive distribution at query points.</span></div>
<div class="line"><span class="lineno">  368</span><span class="stringliteral">            Only returned when `return_std` is True.</span></div>
<div class="line"><span class="lineno">  369</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  370</span><span class="stringliteral">        y_cov : ndarray of shape (n_samples, n_samples) or \</span></div>
<div class="line"><span class="lineno">  371</span><span class="stringliteral">                (n_samples, n_samples, n_targets), optional</span></div>
<div class="line"><span class="lineno">  372</span><span class="stringliteral">            Covariance of joint predictive distribution a query points.</span></div>
<div class="line"><span class="lineno">  373</span><span class="stringliteral">            Only returned when `return_cov` is True.</span></div>
<div class="line"><span class="lineno">  374</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  375</span>        <span class="keywordflow">if</span> return_std <span class="keywordflow">and</span> return_cov:</div>
<div class="line"><span class="lineno">  376</span>            <span class="keywordflow">raise</span> RuntimeError(</div>
<div class="line"><span class="lineno">  377</span>                <span class="stringliteral">&quot;At most one of return_std or return_cov can be requested.&quot;</span></div>
<div class="line"><span class="lineno">  378</span>            )</div>
<div class="line"><span class="lineno">  379</span> </div>
<div class="line"><span class="lineno">  380</span>        <span class="keywordflow">if</span> self.kernel <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">or</span> self.kernel.requires_vector_input:</div>
<div class="line"><span class="lineno">  381</span>            dtype, ensure_2d = <span class="stringliteral">&quot;numeric&quot;</span>, <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  382</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  383</span>            dtype, ensure_2d = <span class="keywordtype">None</span>, <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  384</span> </div>
<div class="line"><span class="lineno">  385</span>        X = self._validate_data(X, ensure_2d=ensure_2d, dtype=dtype, reset=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  386</span> </div>
<div class="line"><span class="lineno">  387</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(self, <span class="stringliteral">&quot;X_train_&quot;</span>):  <span class="comment"># Unfitted;predict based on GP prior</span></div>
<div class="line"><span class="lineno">  388</span>            <span class="keywordflow">if</span> self.kernel <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  389</span>                kernel = C(1.0, constant_value_bounds=<span class="stringliteral">&quot;fixed&quot;</span>) * RBF(</div>
<div class="line"><span class="lineno">  390</span>                    1.0, length_scale_bounds=<span class="stringliteral">&quot;fixed&quot;</span></div>
<div class="line"><span class="lineno">  391</span>                )</div>
<div class="line"><span class="lineno">  392</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  393</span>                kernel = self.kernel</div>
<div class="line"><span class="lineno">  394</span>            y_mean = np.zeros(X.shape[0])</div>
<div class="line"><span class="lineno">  395</span>            <span class="keywordflow">if</span> return_cov:</div>
<div class="line"><span class="lineno">  396</span>                y_cov = kernel(X)</div>
<div class="line"><span class="lineno">  397</span>                <span class="keywordflow">return</span> y_mean, y_cov</div>
<div class="line"><span class="lineno">  398</span>            <span class="keywordflow">elif</span> return_std:</div>
<div class="line"><span class="lineno">  399</span>                y_var = kernel.diag(X)</div>
<div class="line"><span class="lineno">  400</span>                <span class="keywordflow">return</span> y_mean, np.sqrt(y_var)</div>
<div class="line"><span class="lineno">  401</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  402</span>                <span class="keywordflow">return</span> y_mean</div>
<div class="line"><span class="lineno">  403</span>        <span class="keywordflow">else</span>:  <span class="comment"># Predict based on GP posterior</span></div>
<div class="line"><span class="lineno">  404</span>            <span class="comment"># Alg 2.1, page 19, line 4 -&gt; f*_bar = K(X_test, X_train) . alpha</span></div>
<div class="line"><span class="lineno">  405</span>            K_trans = self.kernel_(X, self.X_train_)</div>
<div class="line"><span class="lineno">  406</span>            y_mean = K_trans @ self.alpha_</div>
<div class="line"><span class="lineno">  407</span> </div>
<div class="line"><span class="lineno">  408</span>            <span class="comment"># undo normalisation</span></div>
<div class="line"><span class="lineno">  409</span>            y_mean = self._y_train_std * y_mean + self._y_train_mean</div>
<div class="line"><span class="lineno">  410</span> </div>
<div class="line"><span class="lineno">  411</span>            <span class="comment"># if y_mean has shape (n_samples, 1), reshape to (n_samples,)</span></div>
<div class="line"><span class="lineno">  412</span>            <span class="keywordflow">if</span> y_mean.ndim &gt; 1 <span class="keywordflow">and</span> y_mean.shape[1] == 1:</div>
<div class="line"><span class="lineno">  413</span>                y_mean = np.squeeze(y_mean, axis=1)</div>
<div class="line"><span class="lineno">  414</span> </div>
<div class="line"><span class="lineno">  415</span>            <span class="comment"># Alg 2.1, page 19, line 5 -&gt; v = L \ K(X_test, X_train)^T</span></div>
<div class="line"><span class="lineno">  416</span>            V = solve_triangular(</div>
<div class="line"><span class="lineno">  417</span>                self.L_, K_trans.T, lower=GPR_CHOLESKY_LOWER, check_finite=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  418</span>            )</div>
<div class="line"><span class="lineno">  419</span> </div>
<div class="line"><span class="lineno">  420</span>            <span class="keywordflow">if</span> return_cov:</div>
<div class="line"><span class="lineno">  421</span>                <span class="comment"># Alg 2.1, page 19, line 6 -&gt; K(X_test, X_test) - v^T. v</span></div>
<div class="line"><span class="lineno">  422</span>                y_cov = self.kernel_(X) - V.T @ V</div>
<div class="line"><span class="lineno">  423</span> </div>
<div class="line"><span class="lineno">  424</span>                <span class="comment"># undo normalisation</span></div>
<div class="line"><span class="lineno">  425</span>                y_cov = np.outer(y_cov, self._y_train_std**2).reshape(</div>
<div class="line"><span class="lineno">  426</span>                    *y_cov.shape, -1</div>
<div class="line"><span class="lineno">  427</span>                )</div>
<div class="line"><span class="lineno">  428</span>                <span class="comment"># if y_cov has shape (n_samples, n_samples, 1), reshape to</span></div>
<div class="line"><span class="lineno">  429</span>                <span class="comment"># (n_samples, n_samples)</span></div>
<div class="line"><span class="lineno">  430</span>                <span class="keywordflow">if</span> y_cov.shape[2] == 1:</div>
<div class="line"><span class="lineno">  431</span>                    y_cov = np.squeeze(y_cov, axis=2)</div>
<div class="line"><span class="lineno">  432</span> </div>
<div class="line"><span class="lineno">  433</span>                <span class="keywordflow">return</span> y_mean, y_cov</div>
<div class="line"><span class="lineno">  434</span>            <span class="keywordflow">elif</span> return_std:</div>
<div class="line"><span class="lineno">  435</span>                <span class="comment"># Compute variance of predictive distribution</span></div>
<div class="line"><span class="lineno">  436</span>                <span class="comment"># Use einsum to avoid explicitly forming the large matrix</span></div>
<div class="line"><span class="lineno">  437</span>                <span class="comment"># V^T @ V just to extract its diagonal afterward.</span></div>
<div class="line"><span class="lineno">  438</span>                y_var = self.kernel_.diag(X).copy()</div>
<div class="line"><span class="lineno">  439</span>                y_var -= np.einsum(<span class="stringliteral">&quot;ij,ji-&gt;i&quot;</span>, V.T, V)</div>
<div class="line"><span class="lineno">  440</span> </div>
<div class="line"><span class="lineno">  441</span>                <span class="comment"># Check if any of the variances is negative because of</span></div>
<div class="line"><span class="lineno">  442</span>                <span class="comment"># numerical issues. If yes: set the variance to 0.</span></div>
<div class="line"><span class="lineno">  443</span>                y_var_negative = y_var &lt; 0</div>
<div class="line"><span class="lineno">  444</span>                <span class="keywordflow">if</span> np.any(y_var_negative):</div>
<div class="line"><span class="lineno">  445</span>                    warnings.warn(</div>
<div class="line"><span class="lineno">  446</span>                        <span class="stringliteral">&quot;Predicted variances smaller than 0. &quot;</span></div>
<div class="line"><span class="lineno">  447</span>                        <span class="stringliteral">&quot;Setting those variances to 0.&quot;</span></div>
<div class="line"><span class="lineno">  448</span>                    )</div>
<div class="line"><span class="lineno">  449</span>                    y_var[y_var_negative] = 0.0</div>
<div class="line"><span class="lineno">  450</span> </div>
<div class="line"><span class="lineno">  451</span>                <span class="comment"># undo normalisation</span></div>
<div class="line"><span class="lineno">  452</span>                y_var = np.outer(y_var, self._y_train_std**2).reshape(</div>
<div class="line"><span class="lineno">  453</span>                    *y_var.shape, -1</div>
<div class="line"><span class="lineno">  454</span>                )</div>
<div class="line"><span class="lineno">  455</span> </div>
<div class="line"><span class="lineno">  456</span>                <span class="comment"># if y_var has shape (n_samples, 1), reshape to (n_samples,)</span></div>
<div class="line"><span class="lineno">  457</span>                <span class="keywordflow">if</span> y_var.shape[1] == 1:</div>
<div class="line"><span class="lineno">  458</span>                    y_var = np.squeeze(y_var, axis=1)</div>
<div class="line"><span class="lineno">  459</span> </div>
<div class="line"><span class="lineno">  460</span>                <span class="keywordflow">return</span> y_mean, np.sqrt(y_var)</div>
<div class="line"><span class="lineno">  461</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  462</span>                <span class="keywordflow">return</span> y_mean</div>
<div class="line"><span class="lineno">  463</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a244700908024966019e0a5b5222febb4" name="a244700908024966019e0a5b5222febb4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a244700908024966019e0a5b5222febb4">&#9670;&#160;</a></span>sample_y()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_samples</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Draw samples from Gaussian process and evaluate at X.

Parameters
----------
X : array-like of shape (n_samples_X, n_features) or list of object
    Query points where the GP is evaluated.

n_samples : int, default=1
    Number of samples drawn from the Gaussian process per query point.

random_state : int, RandomState instance or None, default=0
    Determines random number generation to randomly draw samples.
    Pass an int for reproducible results across multiple function
    calls.
    See :term:`Glossary &lt;random_state&gt;`.

Returns
-------
y_samples : ndarray of shape (n_samples_X, n_samples), or \
    (n_samples_X, n_targets, n_samples)
    Values of n_samples samples drawn from Gaussian process and
    evaluated at query points.
</pre> <div class="fragment"><div class="line"><span class="lineno">  464</span>    <span class="keyword">def </span>sample_y(self, X, n_samples=1, random_state=0):</div>
<div class="line"><span class="lineno">  465</span>        <span class="stringliteral">&quot;&quot;&quot;Draw samples from Gaussian process and evaluate at X.</span></div>
<div class="line"><span class="lineno">  466</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  467</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  468</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  469</span><span class="stringliteral">        X : array-like of shape (n_samples_X, n_features) or list of object</span></div>
<div class="line"><span class="lineno">  470</span><span class="stringliteral">            Query points where the GP is evaluated.</span></div>
<div class="line"><span class="lineno">  471</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  472</span><span class="stringliteral">        n_samples : int, default=1</span></div>
<div class="line"><span class="lineno">  473</span><span class="stringliteral">            Number of samples drawn from the Gaussian process per query point.</span></div>
<div class="line"><span class="lineno">  474</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  475</span><span class="stringliteral">        random_state : int, RandomState instance or None, default=0</span></div>
<div class="line"><span class="lineno">  476</span><span class="stringliteral">            Determines random number generation to randomly draw samples.</span></div>
<div class="line"><span class="lineno">  477</span><span class="stringliteral">            Pass an int for reproducible results across multiple function</span></div>
<div class="line"><span class="lineno">  478</span><span class="stringliteral">            calls.</span></div>
<div class="line"><span class="lineno">  479</span><span class="stringliteral">            See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  480</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  481</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  482</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  483</span><span class="stringliteral">        y_samples : ndarray of shape (n_samples_X, n_samples), or \</span></div>
<div class="line"><span class="lineno">  484</span><span class="stringliteral">            (n_samples_X, n_targets, n_samples)</span></div>
<div class="line"><span class="lineno">  485</span><span class="stringliteral">            Values of n_samples samples drawn from Gaussian process and</span></div>
<div class="line"><span class="lineno">  486</span><span class="stringliteral">            evaluated at query points.</span></div>
<div class="line"><span class="lineno">  487</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  488</span>        rng = check_random_state(random_state)</div>
<div class="line"><span class="lineno">  489</span> </div>
<div class="line"><span class="lineno">  490</span>        y_mean, y_cov = self.predict(X, return_cov=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  491</span>        <span class="keywordflow">if</span> y_mean.ndim == 1:</div>
<div class="line"><span class="lineno">  492</span>            y_samples = rng.multivariate_normal(y_mean, y_cov, n_samples).T</div>
<div class="line"><span class="lineno">  493</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  494</span>            y_samples = [</div>
<div class="line"><span class="lineno">  495</span>                rng.multivariate_normal(</div>
<div class="line"><span class="lineno">  496</span>                    y_mean[:, target], y_cov[..., target], n_samples</div>
<div class="line"><span class="lineno">  497</span>                ).T[:, np.newaxis]</div>
<div class="line"><span class="lineno">  498</span>                <span class="keywordflow">for</span> target <span class="keywordflow">in</span> range(y_mean.shape[1])</div>
<div class="line"><span class="lineno">  499</span>            ]</div>
<div class="line"><span class="lineno">  500</span>            y_samples = np.hstack(y_samples)</div>
<div class="line"><span class="lineno">  501</span>        <span class="keywordflow">return</span> y_samples</div>
<div class="line"><span class="lineno">  502</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="af1c43721a8c2c3e25194e651e87a46c5" name="af1c43721a8c2c3e25194e651e87a46c5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af1c43721a8c2c3e25194e651e87a46c5">&#9670;&#160;</a></span>_parameter_constraints</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">dict sklearn.gaussian_process._gpr.GaussianProcessRegressor._parameter_constraints</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=  {</div>
<div class="line">        <span class="stringliteral">&quot;kernel&quot;</span>: [<span class="keywordtype">None</span>, Kernel],</div>
<div class="line">        <span class="stringliteral">&quot;alpha&quot;</span>: [Interval(Real, 0, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;left&quot;</span>), np.ndarray],</div>
<div class="line">        <span class="stringliteral">&quot;optimizer&quot;</span>: [StrOptions({<span class="stringliteral">&quot;fmin_l_bfgs_b&quot;</span>}), callable, <span class="keywordtype">None</span>],</div>
<div class="line">        <span class="stringliteral">&quot;n_restarts_optimizer&quot;</span>: [Interval(Integral, 0, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;left&quot;</span>)],</div>
<div class="line">        <span class="stringliteral">&quot;normalize_y&quot;</span>: [<span class="stringliteral">&quot;boolean&quot;</span>],</div>
<div class="line">        <span class="stringliteral">&quot;copy_X_train&quot;</span>: [<span class="stringliteral">&quot;boolean&quot;</span>],</div>
<div class="line">        <span class="stringliteral">&quot;random_state&quot;</span>: [<span class="stringliteral">&quot;random_state&quot;</span>],</div>
<div class="line">    }</div>
</div><!-- fragment -->
</div>
</div>
<a id="a5313f334aba0f90ef98f380e5b552181" name="a5313f334aba0f90ef98f380e5b552181"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5313f334aba0f90ef98f380e5b552181">&#9670;&#160;</a></span>_rng</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor._rng</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aca3e904033b5bfa2f41362d228d94a39" name="aca3e904033b5bfa2f41362d228d94a39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca3e904033b5bfa2f41362d228d94a39">&#9670;&#160;</a></span>_y_train_mean</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor._y_train_mean</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a38d727c8ede6547f8381384c33f1790e" name="a38d727c8ede6547f8381384c33f1790e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38d727c8ede6547f8381384c33f1790e">&#9670;&#160;</a></span>_y_train_std</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor._y_train_std</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="abc89fb029f5d119897dd84616d84cc91" name="abc89fb029f5d119897dd84616d84cc91"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abc89fb029f5d119897dd84616d84cc91">&#9670;&#160;</a></span>alpha</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.alpha</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3db83b2a609a2c39200fdd4506adbc66" name="a3db83b2a609a2c39200fdd4506adbc66"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3db83b2a609a2c39200fdd4506adbc66">&#9670;&#160;</a></span>alpha_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.alpha_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a658f726e6f37d4b3f2739b4ffe3b9fb0" name="a658f726e6f37d4b3f2739b4ffe3b9fb0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a658f726e6f37d4b3f2739b4ffe3b9fb0">&#9670;&#160;</a></span>copy_X_train</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.copy_X_train</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af846d5cd1e17dfa525fb99fcaa867ed7" name="af846d5cd1e17dfa525fb99fcaa867ed7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af846d5cd1e17dfa525fb99fcaa867ed7">&#9670;&#160;</a></span>kernel</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.kernel</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6ad32ca507113ebc23df62d98f85b1ea" name="a6ad32ca507113ebc23df62d98f85b1ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ad32ca507113ebc23df62d98f85b1ea">&#9670;&#160;</a></span>kernel_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.kernel_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aee925c9908927bcbef5a4f38b928aced" name="aee925c9908927bcbef5a4f38b928aced"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee925c9908927bcbef5a4f38b928aced">&#9670;&#160;</a></span>L_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.L_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2c36e6a2ff97d218370d8ceea7238a5a" name="a2c36e6a2ff97d218370d8ceea7238a5a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2c36e6a2ff97d218370d8ceea7238a5a">&#9670;&#160;</a></span>log_marginal_likelihood_value_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood_value_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aeca5128011525338dfc4773c9ec15df8" name="aeca5128011525338dfc4773c9ec15df8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeca5128011525338dfc4773c9ec15df8">&#9670;&#160;</a></span>n_restarts_optimizer</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.n_restarts_optimizer</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9afd45fe3416504d43c4b9a7f53240a2" name="a9afd45fe3416504d43c4b9a7f53240a2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9afd45fe3416504d43c4b9a7f53240a2">&#9670;&#160;</a></span>normalize_y</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.normalize_y</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae974bf9af46dbf9052e39cce9a0fcb42" name="ae974bf9af46dbf9052e39cce9a0fcb42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae974bf9af46dbf9052e39cce9a0fcb42">&#9670;&#160;</a></span>optimizer</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.optimizer</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a54770fcb8d43e6d4cfe331733dd2a95f" name="a54770fcb8d43e6d4cfe331733dd2a95f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54770fcb8d43e6d4cfe331733dd2a95f">&#9670;&#160;</a></span>random_state</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.random_state</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a67461b5efc90794919da2f89486f2c5d" name="a67461b5efc90794919da2f89486f2c5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a67461b5efc90794919da2f89486f2c5d">&#9670;&#160;</a></span>X_train_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.X_train_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afd7e37c72447f44c7ba2a44c36b77dda" name="afd7e37c72447f44c7ba2a44c36b77dda"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd7e37c72447f44c7ba2a44c36b77dda">&#9670;&#160;</a></span>y_train_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpr.GaussianProcessRegressor.y_train_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/rafael/Documents/GitHub/PUC-GCES-PY/Tp-GCS-Rafael-Augusto/venv/lib/python3.9/site-packages/sklearn/gaussian_process/<a class="el" href="__gpr_8py.html">_gpr.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
