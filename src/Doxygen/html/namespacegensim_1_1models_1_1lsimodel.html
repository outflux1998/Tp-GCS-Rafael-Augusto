<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: gensim.models.lsimodel Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacegensim.html">gensim</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models.html">models</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1lsimodel.html">lsimodel</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">gensim.models.lsimodel Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1lsimodel_1_1_lsi_model.html">LsiModel</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1lsimodel_1_1_projection.html">Projection</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:afffedc8e5c4ce554680edc756c0a0b7d" id="r_afffedc8e5c4ce554680edc756c0a0b7d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1lsimodel.html#afffedc8e5c4ce554680edc756c0a0b7d">clip_spectrum</a> (s, <a class="el" href="__blas__subroutines_8h.html#afa8f30d4cfebc7d1efb06e7d245eff5a">k</a>, discard=0.001)</td></tr>
<tr class="separator:afffedc8e5c4ce554680edc756c0a0b7d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ffbdf2017138b87b909ecd2189e0077" id="r_a7ffbdf2017138b87b909ecd2189e0077"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1lsimodel.html#a7ffbdf2017138b87b909ecd2189e0077">asfarray</a> (<a class="el" href="__blas__subroutines_8h.html#a4da0a64c77789ca4c8115aef76120fd2">a</a>, name='')</td></tr>
<tr class="separator:a7ffbdf2017138b87b909ecd2189e0077"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20a64c65624852dba7af4f18f6fb7dc3" id="r_a20a64c65624852dba7af4f18f6fb7dc3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1lsimodel.html#a20a64c65624852dba7af4f18f6fb7dc3">ascarray</a> (<a class="el" href="__blas__subroutines_8h.html#a4da0a64c77789ca4c8115aef76120fd2">a</a>, name='')</td></tr>
<tr class="separator:a20a64c65624852dba7af4f18f6fb7dc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee15aa40e40709f6de7eed12916032ac" id="r_aee15aa40e40709f6de7eed12916032ac"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1lsimodel.html#aee15aa40e40709f6de7eed12916032ac">print_debug</a> (id2token, u, s, topics, num_words=10, num_neg=None)</td></tr>
<tr class="separator:aee15aa40e40709f6de7eed12916032ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ac82cc107d112fc2f95e69167f84c93" id="r_a9ac82cc107d112fc2f95e69167f84c93"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1lsimodel.html#a9ac82cc107d112fc2f95e69167f84c93">stochastic_svd</a> (corpus, rank, num_terms, chunksize=20000, extra_dims=None, power_iters=0, dtype=np.float64, <a class="el" href="__lapack__subroutines_8h.html#a57833d05f43fd1408080af6eec88fc43">eps</a>=1e-6)</td></tr>
<tr class="separator:a9ac82cc107d112fc2f95e69167f84c93"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:acf05df968292d4e3124602cb0614f7b7" id="r_acf05df968292d4e3124602cb0614f7b7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1lsimodel.html#acf05df968292d4e3124602cb0614f7b7">logger</a> = logging.getLogger(__name__)</td></tr>
<tr class="separator:acf05df968292d4e3124602cb0614f7b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25de68674a3627039de5c4ff2d241d7a" id="r_a25de68674a3627039de5c4ff2d241d7a"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1lsimodel.html#a25de68674a3627039de5c4ff2d241d7a">P2_EXTRA_DIMS</a> = 100</td></tr>
<tr class="separator:a25de68674a3627039de5c4ff2d241d7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7436e9c7b7b08905737494cc54abc6c" id="r_ab7436e9c7b7b08905737494cc54abc6c"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1lsimodel.html#ab7436e9c7b7b08905737494cc54abc6c">P2_EXTRA_ITERS</a> = 2</td></tr>
<tr class="separator:ab7436e9c7b7b08905737494cc54abc6c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Module for `Latent Semantic Analysis (aka Latent Semantic Indexing)
&lt;https://en.wikipedia.org/wiki/Latent_semantic_analysis#Latent_semantic_indexing&gt;`_.

Implements fast truncated SVD (Singular Value Decomposition). The SVD decomposition can be updated with new observations
at any time, for an online, incremental, memory-efficient training.

This module actually contains several algorithms for decomposition of large corpora, a
combination of which effectively and transparently allows building LSI models for:

* corpora much larger than RAM: only constant memory is needed, independent of
  the corpus size
* corpora that are streamed: documents are only accessed sequentially, no
  random access
* corpora that cannot be even temporarily stored: each document can only be
  seen once and must be processed immediately (one-pass algorithm)
* distributed computing for very large corpora, making use of a cluster of
  machines

Wall-clock `performance on the English Wikipedia &lt;http://radimrehurek.com/gensim/wiki.html&gt;`_
(2G corpus positions, 3.2M documents, 100K features, 0.5G non-zero entries in the final TF-IDF matrix),
requesting the top 400 LSI factors:

====================================================== ============ ==================
 algorithm                                             serial       distributed
====================================================== ============ ==================
 one-pass merge algorithm                              5h14m        1h41m
 multi-pass stochastic algo (with 2 power iterations)  5h39m        N/A [1]_
====================================================== ============ ==================


*serial* = Core 2 Duo MacBook Pro 2.53Ghz, 4GB RAM, libVec

*distributed* = cluster of four logical nodes on three physical machines, each
with dual core Xeon 2.0GHz, 4GB RAM, ATLAS


Examples
--------
.. sourcecode:: pycon

    &gt;&gt;&gt; from gensim.test.utils import common_dictionary, common_corpus
    &gt;&gt;&gt; from gensim.models import LsiModel
    &gt;&gt;&gt;
    &gt;&gt;&gt; model = LsiModel(common_corpus, id2word=common_dictionary)
    &gt;&gt;&gt; vectorized_corpus = model[common_corpus]  # vectorize input copus in BoW format


.. [1] The stochastic algo could be distributed too, but most time is already spent
   reading/decompressing the input from disk in its 4 passes. The extra network
   traffic due to data distribution across cluster nodes would likely make it
   *slower*.</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a20a64c65624852dba7af4f18f6fb7dc3" name="a20a64c65624852dba7af4f18f6fb7dc3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20a64c65624852dba7af4f18f6fb7dc3">&#9670;&#160;</a></span>ascarray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.lsimodel.ascarray </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em> = <code>''</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return a contiguous array in memory (C order).

Parameters
----------
a : numpy.ndarray
    Input array.
name : str, optional
    Array name, used for logging purposes.

Returns
-------
np.ndarray
    Contiguous array (row-major order) of same shape and content as `a`.</pre> <div class="fragment"><div class="line"><span class="lineno">  132</span><span class="keyword">def </span>ascarray(a, name=&#39;&#39;):</div>
<div class="line"><span class="lineno">  133</span>    <span class="stringliteral">&quot;&quot;&quot;Return a contiguous array in memory (C order).</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">    a : numpy.ndarray</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">        Input array.</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral">    name : str, optional</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">        Array name, used for logging purposes.</span></div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">    np.ndarray</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">        Contiguous array (row-major order) of same shape and content as `a`.</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  148</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> a.flags.contiguous:</div>
<div class="line"><span class="lineno">  149</span>        logger.debug(<span class="stringliteral">&quot;converting %s array %s to C order&quot;</span>, a.shape, name)</div>
<div class="line"><span class="lineno">  150</span>        a = np.ascontiguousarray(a)</div>
<div class="line"><span class="lineno">  151</span>    <span class="keywordflow">return</span> a</div>
<div class="line"><span class="lineno">  152</span> </div>
<div class="line"><span class="lineno">  153</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7ffbdf2017138b87b909ecd2189e0077" name="a7ffbdf2017138b87b909ecd2189e0077"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7ffbdf2017138b87b909ecd2189e0077">&#9670;&#160;</a></span>asfarray()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.lsimodel.asfarray </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em> = <code>''</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get an array laid out in Fortran order in memory.

Parameters
----------
a : numpy.ndarray
    Input array.
name : str, optional
    Array name, used only for logging purposes.

Returns
-------
np.ndarray
    The input `a` in Fortran, or column-major order.</pre> <div class="fragment"><div class="line"><span class="lineno">  110</span><span class="keyword">def </span>asfarray(a, name=&#39;&#39;):</div>
<div class="line"><span class="lineno">  111</span>    <span class="stringliteral">&quot;&quot;&quot;Get an array laid out in Fortran order in memory.</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">    a : numpy.ndarray</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral">        Input array.</span></div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">    name : str, optional</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">        Array name, used only for logging purposes.</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">    np.ndarray</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">        The input `a` in Fortran, or column-major order.</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  126</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> a.flags.f_contiguous:</div>
<div class="line"><span class="lineno">  127</span>        logger.debug(<span class="stringliteral">&quot;converting %s array %s to FORTRAN order&quot;</span>, a.shape, name)</div>
<div class="line"><span class="lineno">  128</span>        a = np.asfortranarray(a)</div>
<div class="line"><span class="lineno">  129</span>    <span class="keywordflow">return</span> a</div>
<div class="line"><span class="lineno">  130</span> </div>
<div class="line"><span class="lineno">  131</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afffedc8e5c4ce554680edc756c0a0b7d" name="afffedc8e5c4ce554680edc756c0a0b7d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afffedc8e5c4ce554680edc756c0a0b7d">&#9670;&#160;</a></span>clip_spectrum()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.lsimodel.clip_spectrum </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>discard</em> = <code>0.001</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Find how many factors should be kept to avoid storing spurious (tiny, numerically unstable) values.

Parameters
----------
s : list of float
    Eigenvalues of the original matrix.
k : int
    Maximum desired rank (number of factors)
discard: float
    Percentage of the spectrum's energy to be discarded.

Returns
-------
int
    Rank (number of factors) of the reduced matrix.</pre> <div class="fragment"><div class="line"><span class="lineno">   82</span><span class="keyword">def </span>clip_spectrum(s, k, discard=0.001):</div>
<div class="line"><span class="lineno">   83</span>    <span class="stringliteral">&quot;&quot;&quot;Find how many factors should be kept to avoid storing spurious (tiny, numerically unstable) values.</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">    s : list of float</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">        Eigenvalues of the original matrix.</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">    k : int</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">        Maximum desired rank (number of factors)</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">    discard: float</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral">        Percentage of the spectrum&#39;s energy to be discarded.</span></div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral">    int</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral">        Rank (number of factors) of the reduced matrix.</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  101</span>    <span class="comment"># compute relative contribution of eigenvalues towards the energy spectrum</span></div>
<div class="line"><span class="lineno">  102</span>    rel_spectrum = np.abs(1.0 - np.cumsum(s / np.sum(s)))</div>
<div class="line"><span class="lineno">  103</span>    <span class="comment"># ignore the last `discard` mass (or 1/k, whichever is smaller) of the spectrum</span></div>
<div class="line"><span class="lineno">  104</span>    small = 1 + len(np.where(rel_spectrum &gt; min(discard, 1.0 / k))[0])</div>
<div class="line"><span class="lineno">  105</span>    k = min(k, small)  <span class="comment"># clip against k</span></div>
<div class="line"><span class="lineno">  106</span>    logger.info(<span class="stringliteral">&quot;keeping %i factors (discarding %.3f%% of energy spectrum)&quot;</span>, k, 100 * rel_spectrum[k - 1])</div>
<div class="line"><span class="lineno">  107</span>    <span class="keywordflow">return</span> k</div>
<div class="line"><span class="lineno">  108</span> </div>
<div class="line"><span class="lineno">  109</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aee15aa40e40709f6de7eed12916032ac" name="aee15aa40e40709f6de7eed12916032ac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee15aa40e40709f6de7eed12916032ac">&#9670;&#160;</a></span>print_debug()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.lsimodel.print_debug </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>id2token</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>u</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>topics</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_words</em> = <code>10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_neg</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Log the most salient words per topic.

Parameters
----------
id2token : :class:`~gensim.corpora.dictionary.Dictionary`
    Mapping from ID to word in the Dictionary.
u : np.ndarray
    The 2D U decomposition matrix.
s : np.ndarray
    The 1D reduced array of eigenvalues used for decomposition.
topics : list of int
    Sequence of topic IDs to be printed
num_words : int, optional
    Number of words to be included for each topic.
num_neg : int, optional
    Number of words with a negative contribution to a topic that should be included.</pre> <div class="fragment"><div class="line"><span class="lineno">  803</span><span class="keyword">def </span>print_debug(id2token, u, s, topics, num_words=10, num_neg=None):</div>
<div class="line"><span class="lineno">  804</span>    <span class="stringliteral">&quot;&quot;&quot;Log the most salient words per topic.</span></div>
<div class="line"><span class="lineno">  805</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  806</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  807</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  808</span><span class="stringliteral">    id2token : :class:`~gensim.corpora.dictionary.Dictionary`</span></div>
<div class="line"><span class="lineno">  809</span><span class="stringliteral">        Mapping from ID to word in the Dictionary.</span></div>
<div class="line"><span class="lineno">  810</span><span class="stringliteral">    u : np.ndarray</span></div>
<div class="line"><span class="lineno">  811</span><span class="stringliteral">        The 2D U decomposition matrix.</span></div>
<div class="line"><span class="lineno">  812</span><span class="stringliteral">    s : np.ndarray</span></div>
<div class="line"><span class="lineno">  813</span><span class="stringliteral">        The 1D reduced array of eigenvalues used for decomposition.</span></div>
<div class="line"><span class="lineno">  814</span><span class="stringliteral">    topics : list of int</span></div>
<div class="line"><span class="lineno">  815</span><span class="stringliteral">        Sequence of topic IDs to be printed</span></div>
<div class="line"><span class="lineno">  816</span><span class="stringliteral">    num_words : int, optional</span></div>
<div class="line"><span class="lineno">  817</span><span class="stringliteral">        Number of words to be included for each topic.</span></div>
<div class="line"><span class="lineno">  818</span><span class="stringliteral">    num_neg : int, optional</span></div>
<div class="line"><span class="lineno">  819</span><span class="stringliteral">        Number of words with a negative contribution to a topic that should be included.</span></div>
<div class="line"><span class="lineno">  820</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  821</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  822</span>    <span class="keywordflow">if</span> num_neg <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  823</span>        <span class="comment"># by default, print half as many salient negative words as positive</span></div>
<div class="line"><span class="lineno">  824</span>        num_neg = num_words / 2</div>
<div class="line"><span class="lineno">  825</span> </div>
<div class="line"><span class="lineno">  826</span>    logger.info(<span class="stringliteral">&#39;computing word-topic salience for %i topics&#39;</span>, len(topics))</div>
<div class="line"><span class="lineno">  827</span>    topics, result = set(topics), {}</div>
<div class="line"><span class="lineno">  828</span>    <span class="comment"># TODO speed up by block computation</span></div>
<div class="line"><span class="lineno">  829</span>    <span class="keywordflow">for</span> uvecno, uvec <span class="keywordflow">in</span> enumerate(u):</div>
<div class="line"><span class="lineno">  830</span>        uvec = np.abs(np.asarray(uvec).flatten())</div>
<div class="line"><span class="lineno">  831</span>        udiff = uvec / np.sqrt(np.sum(np.dot(uvec, uvec)))</div>
<div class="line"><span class="lineno">  832</span>        <span class="keywordflow">for</span> topic <span class="keywordflow">in</span> topics:</div>
<div class="line"><span class="lineno">  833</span>            result.setdefault(topic, []).append((udiff[topic], uvecno))</div>
<div class="line"><span class="lineno">  834</span> </div>
<div class="line"><span class="lineno">  835</span>    logger.debug(<span class="stringliteral">&quot;printing %i+%i salient words&quot;</span>, num_words, num_neg)</div>
<div class="line"><span class="lineno">  836</span>    <span class="keywordflow">for</span> topic <span class="keywordflow">in</span> sorted(iterkeys(result)):</div>
<div class="line"><span class="lineno">  837</span>        weights = sorted(result[topic], key=<span class="keyword">lambda</span> x: -abs(x[0]))</div>
<div class="line"><span class="lineno">  838</span>        _, most = weights[0]</div>
<div class="line"><span class="lineno">  839</span>        <span class="keywordflow">if</span> u[most, topic] &lt; 0.0:  <span class="comment"># the most significant word has a negative sign =&gt; flip sign of u[most]</span></div>
<div class="line"><span class="lineno">  840</span>            normalize = -1.0</div>
<div class="line"><span class="lineno">  841</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  842</span>            normalize = 1.0</div>
<div class="line"><span class="lineno">  843</span> </div>
<div class="line"><span class="lineno">  844</span>        <span class="comment"># order features according to salience; ignore near-zero entries in u</span></div>
<div class="line"><span class="lineno">  845</span>        pos, neg = [], []</div>
<div class="line"><span class="lineno">  846</span>        <span class="keywordflow">for</span> weight, uvecno <span class="keywordflow">in</span> weights:</div>
<div class="line"><span class="lineno">  847</span>            <span class="keywordflow">if</span> normalize * u[uvecno, topic] &gt; 0.0001:</div>
<div class="line"><span class="lineno">  848</span>                pos.append(<span class="stringliteral">&#39;%s(%.3f)&#39;</span> % (id2token[uvecno], u[uvecno, topic]))</div>
<div class="line"><span class="lineno">  849</span>                <span class="keywordflow">if</span> len(pos) &gt;= num_words:</div>
<div class="line"><span class="lineno">  850</span>                    <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  851</span> </div>
<div class="line"><span class="lineno">  852</span>        <span class="keywordflow">for</span> weight, uvecno <span class="keywordflow">in</span> weights:</div>
<div class="line"><span class="lineno">  853</span>            <span class="keywordflow">if</span> normalize * u[uvecno, topic] &lt; -0.0001:</div>
<div class="line"><span class="lineno">  854</span>                neg.append(<span class="stringliteral">&#39;%s(%.3f)&#39;</span> % (id2token[uvecno], u[uvecno, topic]))</div>
<div class="line"><span class="lineno">  855</span>                <span class="keywordflow">if</span> len(neg) &gt;= num_neg:</div>
<div class="line"><span class="lineno">  856</span>                    <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  857</span> </div>
<div class="line"><span class="lineno">  858</span>        logger.info(<span class="stringliteral">&#39;topic #%s(%.3f): %s, ..., %s&#39;</span>, topic, s[topic], <span class="stringliteral">&#39;, &#39;</span>.join(pos), <span class="stringliteral">&#39;, &#39;</span>.join(neg))</div>
<div class="line"><span class="lineno">  859</span> </div>
<div class="line"><span class="lineno">  860</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9ac82cc107d112fc2f95e69167f84c93" name="a9ac82cc107d112fc2f95e69167f84c93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9ac82cc107d112fc2f95e69167f84c93">&#9670;&#160;</a></span>stochastic_svd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.lsimodel.stochastic_svd </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>corpus</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rank</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_terms</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>chunksize</em> = <code>20000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>extra_dims</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>power_iters</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em> = <code>np.float64</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>eps</em> = <code>1e-6</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Run truncated Singular Value Decomposition (SVD) on a sparse input.

Parameters
----------
corpus : {iterable of list of (int, float), scipy.sparse}
    Input corpus as a stream (does not have to fit in RAM)
    or a sparse matrix of shape (`num_terms`, num_documents).
rank : int
    Desired number of factors to be retained after decomposition.
num_terms : int
    The number of features (terms) in `corpus`.
chunksize :  int, optional
    Number of documents to be used in each training chunk.
extra_dims : int, optional
    Extra samples to be used besides the rank `k`. Can improve accuracy.
power_iters: int, optional
    Number of power iteration steps to be used. Increasing the number of power iterations improves accuracy,
    but lowers performance.
dtype : numpy.dtype, optional
    Enforces a type for elements of the decomposed matrix.
eps: float, optional
    Percentage of the spectrum's energy to be discarded.

Notes
-----
The corpus may be larger than RAM (iterator of vectors), if `corpus` is a `scipy.sparse.csc` instead,
it is assumed the whole corpus fits into core memory and a different (more efficient) code path is chosen.
This may return less than the requested number of top `rank` factors, in case the input itself is of lower rank.
The `extra_dims` (oversampling) and especially `power_iters` (power iterations) parameters affect accuracy of the
decomposition.

This algorithm uses `2 + power_iters` passes over the input data. In case you can only afford a single pass,
set `onepass=True` in :class:`~gensim.models.lsimodel.LsiModel` and avoid using this function directly.

The decomposition algorithm is based on `"Finding structure with randomness:
Probabilistic algorithms for constructing approximate matrix decompositions" &lt;https://arxiv.org/abs/0909.4061&gt;`_.


Returns
-------
(np.ndarray 2D, np.ndarray 1D)
    The left singular vectors and the singular values of the `corpus`.</pre> <div class="fragment"><div class="line"><span class="lineno">  862</span>                   power_iters=0, dtype=np.float64, eps=1e-6):</div>
<div class="line"><span class="lineno">  863</span>    <span class="stringliteral">&quot;&quot;&quot;Run truncated Singular Value Decomposition (SVD) on a sparse input.</span></div>
<div class="line"><span class="lineno">  864</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  865</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  866</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  867</span><span class="stringliteral">    corpus : {iterable of list of (int, float), scipy.sparse}</span></div>
<div class="line"><span class="lineno">  868</span><span class="stringliteral">        Input corpus as a stream (does not have to fit in RAM)</span></div>
<div class="line"><span class="lineno">  869</span><span class="stringliteral">        or a sparse matrix of shape (`num_terms`, num_documents).</span></div>
<div class="line"><span class="lineno">  870</span><span class="stringliteral">    rank : int</span></div>
<div class="line"><span class="lineno">  871</span><span class="stringliteral">        Desired number of factors to be retained after decomposition.</span></div>
<div class="line"><span class="lineno">  872</span><span class="stringliteral">    num_terms : int</span></div>
<div class="line"><span class="lineno">  873</span><span class="stringliteral">        The number of features (terms) in `corpus`.</span></div>
<div class="line"><span class="lineno">  874</span><span class="stringliteral">    chunksize :  int, optional</span></div>
<div class="line"><span class="lineno">  875</span><span class="stringliteral">        Number of documents to be used in each training chunk.</span></div>
<div class="line"><span class="lineno">  876</span><span class="stringliteral">    extra_dims : int, optional</span></div>
<div class="line"><span class="lineno">  877</span><span class="stringliteral">        Extra samples to be used besides the rank `k`. Can improve accuracy.</span></div>
<div class="line"><span class="lineno">  878</span><span class="stringliteral">    power_iters: int, optional</span></div>
<div class="line"><span class="lineno">  879</span><span class="stringliteral">        Number of power iteration steps to be used. Increasing the number of power iterations improves accuracy,</span></div>
<div class="line"><span class="lineno">  880</span><span class="stringliteral">        but lowers performance.</span></div>
<div class="line"><span class="lineno">  881</span><span class="stringliteral">    dtype : numpy.dtype, optional</span></div>
<div class="line"><span class="lineno">  882</span><span class="stringliteral">        Enforces a type for elements of the decomposed matrix.</span></div>
<div class="line"><span class="lineno">  883</span><span class="stringliteral">    eps: float, optional</span></div>
<div class="line"><span class="lineno">  884</span><span class="stringliteral">        Percentage of the spectrum&#39;s energy to be discarded.</span></div>
<div class="line"><span class="lineno">  885</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  886</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  887</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  888</span><span class="stringliteral">    The corpus may be larger than RAM (iterator of vectors), if `corpus` is a `scipy.sparse.csc` instead,</span></div>
<div class="line"><span class="lineno">  889</span><span class="stringliteral">    it is assumed the whole corpus fits into core memory and a different (more efficient) code path is chosen.</span></div>
<div class="line"><span class="lineno">  890</span><span class="stringliteral">    This may return less than the requested number of top `rank` factors, in case the input itself is of lower rank.</span></div>
<div class="line"><span class="lineno">  891</span><span class="stringliteral">    The `extra_dims` (oversampling) and especially `power_iters` (power iterations) parameters affect accuracy of the</span></div>
<div class="line"><span class="lineno">  892</span><span class="stringliteral">    decomposition.</span></div>
<div class="line"><span class="lineno">  893</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  894</span><span class="stringliteral">    This algorithm uses `2 + power_iters` passes over the input data. In case you can only afford a single pass,</span></div>
<div class="line"><span class="lineno">  895</span><span class="stringliteral">    set `onepass=True` in :class:`~gensim.models.lsimodel.LsiModel` and avoid using this function directly.</span></div>
<div class="line"><span class="lineno">  896</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  897</span><span class="stringliteral">    The decomposition algorithm is based on `&quot;Finding structure with randomness:</span></div>
<div class="line"><span class="lineno">  898</span><span class="stringliteral">    Probabilistic algorithms for constructing approximate matrix decompositions&quot; &lt;https://arxiv.org/abs/0909.4061&gt;`_.</span></div>
<div class="line"><span class="lineno">  899</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  900</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  901</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  902</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  903</span><span class="stringliteral">    (np.ndarray 2D, np.ndarray 1D)</span></div>
<div class="line"><span class="lineno">  904</span><span class="stringliteral">        The left singular vectors and the singular values of the `corpus`.</span></div>
<div class="line"><span class="lineno">  905</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  906</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  907</span>    rank = int(rank)</div>
<div class="line"><span class="lineno">  908</span>    <span class="keywordflow">if</span> extra_dims <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  909</span>        samples = max(10, 2 * rank)  <span class="comment"># use more samples than requested factors, to improve accuracy</span></div>
<div class="line"><span class="lineno">  910</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  911</span>        samples = rank + int(extra_dims)</div>
<div class="line"><span class="lineno">  912</span>    logger.info(<span class="stringliteral">&quot;using %i extra samples and %i power iterations&quot;</span>, samples - rank, power_iters)</div>
<div class="line"><span class="lineno">  913</span> </div>
<div class="line"><span class="lineno">  914</span>    num_terms = int(num_terms)</div>
<div class="line"><span class="lineno">  915</span> </div>
<div class="line"><span class="lineno">  916</span>    <span class="comment"># first phase: construct the orthonormal action matrix Q = orth(Y) = orth((A * A.T)^q * A * O)</span></div>
<div class="line"><span class="lineno">  917</span>    <span class="comment"># build Y in blocks of `chunksize` documents (much faster than going one-by-one</span></div>
<div class="line"><span class="lineno">  918</span>    <span class="comment"># and more memory friendly than processing all documents at once)</span></div>
<div class="line"><span class="lineno">  919</span>    y = np.zeros(dtype=dtype, shape=(num_terms, samples))</div>
<div class="line"><span class="lineno">  920</span>    logger.info(<span class="stringliteral">&quot;1st phase: constructing %s action matrix&quot;</span>, str(y.shape))</div>
<div class="line"><span class="lineno">  921</span> </div>
<div class="line"><span class="lineno">  922</span>    <span class="keywordflow">if</span> scipy.sparse.issparse(corpus):</div>
<div class="line"><span class="lineno">  923</span>        m, n = corpus.shape</div>
<div class="line"><span class="lineno">  924</span>        <span class="keyword">assert</span> num_terms == m, <span class="stringliteral">&quot;mismatch in number of features: %i in sparse matrix vs. %i parameter&quot;</span> % (m, num_terms)</div>
<div class="line"><span class="lineno">  925</span>        o = np.random.normal(0.0, 1.0, (n, samples)).astype(y.dtype)  <span class="comment"># draw a random gaussian matrix</span></div>
<div class="line"><span class="lineno">  926</span>        sparsetools.csc_matvecs(m, n, samples, corpus.indptr, corpus.indices,</div>
<div class="line"><span class="lineno">  927</span>                                corpus.data, o.ravel(), y.ravel())  <span class="comment"># y = corpus * o</span></div>
<div class="line"><span class="lineno">  928</span>        del o</div>
<div class="line"><span class="lineno">  929</span> </div>
<div class="line"><span class="lineno">  930</span>        <span class="comment"># unlike np, scipy.sparse `astype()` copies everything, even if there is no change to dtype!</span></div>
<div class="line"><span class="lineno">  931</span>        <span class="comment"># so check for equal dtype explicitly, to avoid the extra memory footprint if possible</span></div>
<div class="line"><span class="lineno">  932</span>        <span class="keywordflow">if</span> y.dtype != dtype:</div>
<div class="line"><span class="lineno">  933</span>            y = y.astype(dtype)</div>
<div class="line"><span class="lineno">  934</span> </div>
<div class="line"><span class="lineno">  935</span>        logger.info(<span class="stringliteral">&quot;orthonormalizing %s action matrix&quot;</span>, str(y.shape))</div>
<div class="line"><span class="lineno">  936</span>        y = [y]</div>
<div class="line"><span class="lineno">  937</span>        q, _ = matutils.qr_destroy(y)  <span class="comment"># orthonormalize the range</span></div>
<div class="line"><span class="lineno">  938</span> </div>
<div class="line"><span class="lineno">  939</span>        logger.debug(<span class="stringliteral">&quot;running %i power iterations&quot;</span>, power_iters)</div>
<div class="line"><span class="lineno">  940</span>        <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(power_iters):</div>
<div class="line"><span class="lineno">  941</span>            q = corpus.T * q</div>
<div class="line"><span class="lineno">  942</span>            q = [corpus * q]</div>
<div class="line"><span class="lineno">  943</span>            q, _ = matutils.qr_destroy(q)  <span class="comment"># orthonormalize the range after each power iteration step</span></div>
<div class="line"><span class="lineno">  944</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  945</span>        num_docs = 0</div>
<div class="line"><span class="lineno">  946</span>        <span class="keywordflow">for</span> chunk_no, chunk <span class="keywordflow">in</span> enumerate(utils.grouper(corpus, chunksize)):</div>
<div class="line"><span class="lineno">  947</span>            logger.info(<span class="stringliteral">&#39;PROGRESS: at document #%i&#39;</span>, (chunk_no * chunksize))</div>
<div class="line"><span class="lineno">  948</span>            <span class="comment"># construct the chunk as a sparse matrix, to minimize memory overhead</span></div>
<div class="line"><span class="lineno">  949</span>            <span class="comment"># definitely avoid materializing it as a dense (num_terms x chunksize) matrix!</span></div>
<div class="line"><span class="lineno">  950</span>            s = sum(len(doc) <span class="keywordflow">for</span> doc <span class="keywordflow">in</span> chunk)</div>
<div class="line"><span class="lineno">  951</span>            chunk = matutils.corpus2csc(chunk, num_terms=num_terms, dtype=dtype)  <span class="comment"># documents = columns of sparse CSC</span></div>
<div class="line"><span class="lineno">  952</span>            m, n = chunk.shape</div>
<div class="line"><span class="lineno">  953</span>            <span class="keyword">assert</span> m == num_terms</div>
<div class="line"><span class="lineno">  954</span>            <span class="keyword">assert</span> n &lt;= chunksize  <span class="comment"># the very last chunk of A is allowed to be smaller in size</span></div>
<div class="line"><span class="lineno">  955</span>            num_docs += n</div>
<div class="line"><span class="lineno">  956</span>            logger.debug(<span class="stringliteral">&quot;multiplying chunk * gauss&quot;</span>)</div>
<div class="line"><span class="lineno">  957</span>            o = np.random.normal(0.0, 1.0, (n, samples)).astype(dtype)  <span class="comment"># draw a random gaussian matrix</span></div>
<div class="line"><span class="lineno">  958</span>            sparsetools.csc_matvecs(</div>
<div class="line"><span class="lineno">  959</span>                m, n, samples, chunk.indptr, chunk.indices,  <span class="comment"># y = y + chunk * o</span></div>
<div class="line"><span class="lineno">  960</span>                chunk.data, o.ravel(), y.ravel()</div>
<div class="line"><span class="lineno">  961</span>            )</div>
<div class="line"><span class="lineno">  962</span>            del chunk, o</div>
<div class="line"><span class="lineno">  963</span>        y = [y]</div>
<div class="line"><span class="lineno">  964</span>        q, _ = matutils.qr_destroy(y)  <span class="comment"># orthonormalize the range</span></div>
<div class="line"><span class="lineno">  965</span> </div>
<div class="line"><span class="lineno">  966</span>        <span class="keywordflow">for</span> power_iter <span class="keywordflow">in</span> range(power_iters):</div>
<div class="line"><span class="lineno">  967</span>            logger.info(<span class="stringliteral">&quot;running power iteration #%i&quot;</span>, power_iter + 1)</div>
<div class="line"><span class="lineno">  968</span>            yold = q.copy()</div>
<div class="line"><span class="lineno">  969</span>            q[:] = 0.0</div>
<div class="line"><span class="lineno">  970</span>            <span class="keywordflow">for</span> chunk_no, chunk <span class="keywordflow">in</span> enumerate(utils.grouper(corpus, chunksize)):</div>
<div class="line"><span class="lineno">  971</span>                logger.info(<span class="stringliteral">&#39;PROGRESS: at document #%i/%i&#39;</span>, chunk_no * chunksize, num_docs)</div>
<div class="line"><span class="lineno">  972</span>                <span class="comment"># documents = columns of sparse CSC</span></div>
<div class="line"><span class="lineno">  973</span>                chunk = matutils.corpus2csc(chunk, num_terms=num_terms, dtype=dtype)</div>
<div class="line"><span class="lineno">  974</span>                tmp = chunk.T * yold</div>
<div class="line"><span class="lineno">  975</span>                tmp = chunk * tmp</div>
<div class="line"><span class="lineno">  976</span>                del chunk</div>
<div class="line"><span class="lineno">  977</span>                q += tmp</div>
<div class="line"><span class="lineno">  978</span>            del yold</div>
<div class="line"><span class="lineno">  979</span>            q = [q]</div>
<div class="line"><span class="lineno">  980</span>            q, _ = matutils.qr_destroy(q)  <span class="comment"># orthonormalize the range</span></div>
<div class="line"><span class="lineno">  981</span> </div>
<div class="line"><span class="lineno">  982</span>    qt = q[:, :samples].T.copy()</div>
<div class="line"><span class="lineno">  983</span>    del q</div>
<div class="line"><span class="lineno">  984</span> </div>
<div class="line"><span class="lineno">  985</span>    <span class="keywordflow">if</span> scipy.sparse.issparse(corpus):</div>
<div class="line"><span class="lineno">  986</span>        b = qt * corpus</div>
<div class="line"><span class="lineno">  987</span>        logger.info(<span class="stringliteral">&quot;2nd phase: running dense svd on %s matrix&quot;</span>, str(b.shape))</div>
<div class="line"><span class="lineno">  988</span>        u, s, vt = scipy.linalg.svd(b, full_matrices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  989</span>        del b, vt</div>
<div class="line"><span class="lineno">  990</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  991</span>        <span class="comment"># second phase: construct the covariance matrix X = B * B.T, where B = Q.T * A</span></div>
<div class="line"><span class="lineno">  992</span>        <span class="comment"># again, construct X incrementally, in chunks of `chunksize` documents from the streaming</span></div>
<div class="line"><span class="lineno">  993</span>        <span class="comment"># input corpus A, to avoid using O(number of documents) memory</span></div>
<div class="line"><span class="lineno">  994</span>        x = np.zeros(shape=(qt.shape[0], qt.shape[0]), dtype=dtype)</div>
<div class="line"><span class="lineno">  995</span>        logger.info(<span class="stringliteral">&quot;2nd phase: constructing %s covariance matrix&quot;</span>, str(x.shape))</div>
<div class="line"><span class="lineno">  996</span>        <span class="keywordflow">for</span> chunk_no, chunk <span class="keywordflow">in</span> enumerate(utils.grouper(corpus, chunksize)):</div>
<div class="line"><span class="lineno">  997</span>            logger.info(<span class="stringliteral">&#39;PROGRESS: at document #%i/%i&#39;</span>, chunk_no * chunksize, num_docs)</div>
<div class="line"><span class="lineno">  998</span>            chunk = matutils.corpus2csc(chunk, num_terms=num_terms, dtype=qt.dtype)</div>
<div class="line"><span class="lineno">  999</span>            b = qt * chunk  <span class="comment"># dense * sparse matrix multiply</span></div>
<div class="line"><span class="lineno"> 1000</span>            del chunk</div>
<div class="line"><span class="lineno"> 1001</span>            x += np.dot(b, b.T)  <span class="comment"># TODO should call the BLAS routine SYRK, but there is no SYRK wrapper in scipy :(</span></div>
<div class="line"><span class="lineno"> 1002</span>            del b</div>
<div class="line"><span class="lineno"> 1003</span> </div>
<div class="line"><span class="lineno"> 1004</span>        <span class="comment"># now we&#39;re ready to compute decomposition of the small matrix X</span></div>
<div class="line"><span class="lineno"> 1005</span>        logger.info(<span class="stringliteral">&quot;running dense decomposition on %s covariance matrix&quot;</span>, str(x.shape))</div>
<div class="line"><span class="lineno"> 1006</span>        <span class="comment"># could use linalg.eigh, but who cares... and svd returns the factors already sorted :)</span></div>
<div class="line"><span class="lineno"> 1007</span>        u, s, vt = scipy.linalg.svd(x)</div>
<div class="line"><span class="lineno"> 1008</span>        <span class="comment"># sqrt to go back from singular values of X to singular values of B = singular values of the corpus</span></div>
<div class="line"><span class="lineno"> 1009</span>        s = np.sqrt(s)</div>
<div class="line"><span class="lineno"> 1010</span>    q = qt.T.copy()</div>
<div class="line"><span class="lineno"> 1011</span>    del qt</div>
<div class="line"><span class="lineno"> 1012</span> </div>
<div class="line"><span class="lineno"> 1013</span>    logger.info(<span class="stringliteral">&quot;computing the final decomposition&quot;</span>)</div>
<div class="line"><span class="lineno"> 1014</span>    keep = clip_spectrum(s ** 2, rank, discard=eps)</div>
<div class="line"><span class="lineno"> 1015</span>    u = u[:, :keep].copy()</div>
<div class="line"><span class="lineno"> 1016</span>    s = s[:keep]</div>
<div class="line"><span class="lineno"> 1017</span>    u = np.dot(q, u)</div>
<div class="line"><span class="lineno"> 1018</span>    <span class="keywordflow">return</span> u.astype(dtype), s.astype(dtype)</div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="acf05df968292d4e3124602cb0614f7b7" name="acf05df968292d4e3124602cb0614f7b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acf05df968292d4e3124602cb0614f7b7">&#9670;&#160;</a></span>logger</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.lsimodel.logger = logging.getLogger(__name__)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a25de68674a3627039de5c4ff2d241d7a" name="a25de68674a3627039de5c4ff2d241d7a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25de68674a3627039de5c4ff2d241d7a">&#9670;&#160;</a></span>P2_EXTRA_DIMS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int gensim.models.lsimodel.P2_EXTRA_DIMS = 100</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab7436e9c7b7b08905737494cc54abc6c" name="ab7436e9c7b7b08905737494cc54abc6c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab7436e9c7b7b08905737494cc54abc6c">&#9670;&#160;</a></span>P2_EXTRA_ITERS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int gensim.models.lsimodel.P2_EXTRA_ITERS = 2</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
