<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.utils.tests.test_extmath Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1utils.html">utils</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1utils_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html">test_extmath</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.utils.tests.test_extmath Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a85ccc7e9334536f39375883b1f2eadef" id="r_a85ccc7e9334536f39375883b1f2eadef"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a85ccc7e9334536f39375883b1f2eadef">test_density</a> ()</td></tr>
<tr class="separator:a85ccc7e9334536f39375883b1f2eadef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72b1fac2dda0edb9cd25da2b3c64cc67" id="r_a72b1fac2dda0edb9cd25da2b3c64cc67"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a72b1fac2dda0edb9cd25da2b3c64cc67">test_density_deprecated_kwargs</a> ()</td></tr>
<tr class="separator:a72b1fac2dda0edb9cd25da2b3c64cc67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47018d758d78c188429652d5e77f9fd3" id="r_a47018d758d78c188429652d5e77f9fd3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a47018d758d78c188429652d5e77f9fd3">test_uniform_weights</a> ()</td></tr>
<tr class="separator:a47018d758d78c188429652d5e77f9fd3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaabdafb131665fb973916a328852f690" id="r_aaabdafb131665fb973916a328852f690"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#aaabdafb131665fb973916a328852f690">test_random_weights</a> ()</td></tr>
<tr class="separator:aaabdafb131665fb973916a328852f690"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c97b6e3a6bd0da256c63bf381c932aa" id="r_a5c97b6e3a6bd0da256c63bf381c932aa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a5c97b6e3a6bd0da256c63bf381c932aa">check_randomized_svd_low_rank</a> (dtype)</td></tr>
<tr class="separator:a5c97b6e3a6bd0da256c63bf381c932aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb8d362515c086f3397169c27823443e" id="r_abb8d362515c086f3397169c27823443e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#abb8d362515c086f3397169c27823443e">test_randomized_svd_low_rank_all_dtypes</a> (dtype)</td></tr>
<tr class="separator:abb8d362515c086f3397169c27823443e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2eb4e747e8c2fad0cc47e825f3acce96" id="r_a2eb4e747e8c2fad0cc47e825f3acce96"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a2eb4e747e8c2fad0cc47e825f3acce96">test_randomized_eigsh</a> (dtype)</td></tr>
<tr class="separator:a2eb4e747e8c2fad0cc47e825f3acce96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a383bd2cc8cfd7a15f9393d97f65b32f6" id="r_a383bd2cc8cfd7a15f9393d97f65b32f6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a383bd2cc8cfd7a15f9393d97f65b32f6">test_randomized_eigsh_compared_to_others</a> (<a class="el" href="__blas__subroutines_8h.html#afa8f30d4cfebc7d1efb06e7d245eff5a">k</a>)</td></tr>
<tr class="separator:a383bd2cc8cfd7a15f9393d97f65b32f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0905cc045efc3b8f32f9892b53f96e93" id="r_a0905cc045efc3b8f32f9892b53f96e93"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a0905cc045efc3b8f32f9892b53f96e93">test_randomized_eigsh_reconst_low_rank</a> (<a class="el" href="__blas__subroutines_8h.html#a25eafceb38c8e75bc60701fea6623f71">n</a>, rank)</td></tr>
<tr class="separator:a0905cc045efc3b8f32f9892b53f96e93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b4e5f9b7afd5d4076609a746d7fc60f" id="r_a2b4e5f9b7afd5d4076609a746d7fc60f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a2b4e5f9b7afd5d4076609a746d7fc60f">test_row_norms</a> (dtype)</td></tr>
<tr class="separator:a2b4e5f9b7afd5d4076609a746d7fc60f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05704cb55e3f6e47d2db6c24864fb113" id="r_a05704cb55e3f6e47d2db6c24864fb113"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a05704cb55e3f6e47d2db6c24864fb113">test_randomized_svd_low_rank_with_noise</a> ()</td></tr>
<tr class="separator:a05704cb55e3f6e47d2db6c24864fb113"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a884dd339539109e9b60643e62bb040ac" id="r_a884dd339539109e9b60643e62bb040ac"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a884dd339539109e9b60643e62bb040ac">test_randomized_svd_infinite_rank</a> ()</td></tr>
<tr class="separator:a884dd339539109e9b60643e62bb040ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9df8af838329a008ebe875190007d51" id="r_ac9df8af838329a008ebe875190007d51"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#ac9df8af838329a008ebe875190007d51">test_randomized_svd_transpose_consistency</a> ()</td></tr>
<tr class="separator:ac9df8af838329a008ebe875190007d51"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4cf2ff2f442d49bc2295ff6a1ca0dc1e" id="r_a4cf2ff2f442d49bc2295ff6a1ca0dc1e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a4cf2ff2f442d49bc2295ff6a1ca0dc1e">test_randomized_svd_power_iteration_normalizer</a> ()</td></tr>
<tr class="separator:a4cf2ff2f442d49bc2295ff6a1ca0dc1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a813eb4405ad5cb3690d648017c5490be" id="r_a813eb4405ad5cb3690d648017c5490be"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a813eb4405ad5cb3690d648017c5490be">test_randomized_svd_sparse_warnings</a> ()</td></tr>
<tr class="separator:a813eb4405ad5cb3690d648017c5490be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0605caf79879c1fdca6bf9e78883e591" id="r_a0605caf79879c1fdca6bf9e78883e591"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a0605caf79879c1fdca6bf9e78883e591">test_svd_flip</a> ()</td></tr>
<tr class="separator:a0605caf79879c1fdca6bf9e78883e591"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aceb1f60bf7dd53639fe2fed7fd0fb25a" id="r_aceb1f60bf7dd53639fe2fed7fd0fb25a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#aceb1f60bf7dd53639fe2fed7fd0fb25a">test_randomized_svd_sign_flip</a> ()</td></tr>
<tr class="separator:aceb1f60bf7dd53639fe2fed7fd0fb25a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d07a9341e0477bbd158578200c71e34" id="r_a9d07a9341e0477bbd158578200c71e34"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a9d07a9341e0477bbd158578200c71e34">test_randomized_svd_sign_flip_with_transpose</a> ()</td></tr>
<tr class="separator:a9d07a9341e0477bbd158578200c71e34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05a50bdb2240c69d97514a45a102cc63" id="r_a05a50bdb2240c69d97514a45a102cc63"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a05a50bdb2240c69d97514a45a102cc63">test_randomized_svd_lapack_driver</a> (<a class="el" href="__blas__subroutines_8h.html#a25eafceb38c8e75bc60701fea6623f71">n</a>, m, <a class="el" href="__blas__subroutines_8h.html#afa8f30d4cfebc7d1efb06e7d245eff5a">k</a>, seed)</td></tr>
<tr class="separator:a05a50bdb2240c69d97514a45a102cc63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93b77e6a99170ffc6c34646f16e38d17" id="r_a93b77e6a99170ffc6c34646f16e38d17"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a93b77e6a99170ffc6c34646f16e38d17">test_cartesian</a> ()</td></tr>
<tr class="separator:a93b77e6a99170ffc6c34646f16e38d17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a857e539a2982b400bbe5e7fb2cb6f593" id="r_a857e539a2982b400bbe5e7fb2cb6f593"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a857e539a2982b400bbe5e7fb2cb6f593">test_cartesian_mix_types</a> (arrays, output_dtype)</td></tr>
<tr class="separator:a857e539a2982b400bbe5e7fb2cb6f593"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae517d4ddd7a7ebddee519b2ebf0342df" id="r_ae517d4ddd7a7ebddee519b2ebf0342df"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#ae517d4ddd7a7ebddee519b2ebf0342df">test_logistic_sigmoid</a> ()</td></tr>
<tr class="separator:ae517d4ddd7a7ebddee519b2ebf0342df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c7d176292e3bf2ead3d425c56b49c9b" id="r_a1c7d176292e3bf2ead3d425c56b49c9b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a1c7d176292e3bf2ead3d425c56b49c9b">rng</a> ()</td></tr>
<tr class="separator:a1c7d176292e3bf2ead3d425c56b49c9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a498982271800a3fd73ef9b3688adcf76" id="r_a498982271800a3fd73ef9b3688adcf76"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a498982271800a3fd73ef9b3688adcf76">test_incremental_weighted_mean_and_variance_simple</a> (<a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a1c7d176292e3bf2ead3d425c56b49c9b">rng</a>, dtype)</td></tr>
<tr class="separator:a498982271800a3fd73ef9b3688adcf76"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65da25865856130615f747b8f074ebea" id="r_a65da25865856130615f747b8f074ebea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a65da25865856130615f747b8f074ebea">test_incremental_weighted_mean_and_variance</a> (mean, var, weight_loc, weight_scale, <a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a1c7d176292e3bf2ead3d425c56b49c9b">rng</a>)</td></tr>
<tr class="separator:a65da25865856130615f747b8f074ebea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab4d3eb17fb267658b89e17b10b18d20" id="r_aab4d3eb17fb267658b89e17b10b18d20"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#aab4d3eb17fb267658b89e17b10b18d20">test_incremental_weighted_mean_and_variance_ignore_nan</a> (dtype)</td></tr>
<tr class="separator:aab4d3eb17fb267658b89e17b10b18d20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9168ace6a98d8ecc4c24622ab3e33fea" id="r_a9168ace6a98d8ecc4c24622ab3e33fea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a9168ace6a98d8ecc4c24622ab3e33fea">test_incremental_variance_update_formulas</a> ()</td></tr>
<tr class="separator:a9168ace6a98d8ecc4c24622ab3e33fea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a263b023c3bc9a1c36838630c5e74f2ed" id="r_a263b023c3bc9a1c36838630c5e74f2ed"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a263b023c3bc9a1c36838630c5e74f2ed">test_incremental_mean_and_variance_ignore_nan</a> ()</td></tr>
<tr class="separator:a263b023c3bc9a1c36838630c5e74f2ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65a999d580712979549af462caf3ea4a" id="r_a65a999d580712979549af462caf3ea4a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a65a999d580712979549af462caf3ea4a">test_incremental_variance_numerical_stability</a> ()</td></tr>
<tr class="separator:a65a999d580712979549af462caf3ea4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a495a034fab1918ffb4dd6c5ea54608a5" id="r_a495a034fab1918ffb4dd6c5ea54608a5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a495a034fab1918ffb4dd6c5ea54608a5">test_incremental_variance_ddof</a> ()</td></tr>
<tr class="separator:a495a034fab1918ffb4dd6c5ea54608a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a909b2b5d502ced1dbd91670153386f44" id="r_a909b2b5d502ced1dbd91670153386f44"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a909b2b5d502ced1dbd91670153386f44">test_vector_sign_flip</a> ()</td></tr>
<tr class="separator:a909b2b5d502ced1dbd91670153386f44"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90dbd353c8a6ff154dc6136d7e55ec13" id="r_a90dbd353c8a6ff154dc6136d7e55ec13"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a90dbd353c8a6ff154dc6136d7e55ec13">test_softmax</a> ()</td></tr>
<tr class="separator:a90dbd353c8a6ff154dc6136d7e55ec13"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6907af7949f55e5e3a42d99d7894ebdb" id="r_a6907af7949f55e5e3a42d99d7894ebdb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a6907af7949f55e5e3a42d99d7894ebdb">test_stable_cumsum</a> ()</td></tr>
<tr class="separator:a6907af7949f55e5e3a42d99d7894ebdb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6f4c1e5eb522013391155005d15ace1" id="r_ad6f4c1e5eb522013391155005d15ace1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#ad6f4c1e5eb522013391155005d15ace1">test_safe_sparse_dot_2d</a> (A_array_constr, B_array_constr)</td></tr>
<tr class="separator:ad6f4c1e5eb522013391155005d15ace1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad4c817c351cad8baff4348aa97aa4bf2" id="r_ad4c817c351cad8baff4348aa97aa4bf2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#ad4c817c351cad8baff4348aa97aa4bf2">test_safe_sparse_dot_nd</a> ()</td></tr>
<tr class="separator:ad4c817c351cad8baff4348aa97aa4bf2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95d4c5d2bc357bbe6e1fc8978147d03b" id="r_a95d4c5d2bc357bbe6e1fc8978147d03b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#a95d4c5d2bc357bbe6e1fc8978147d03b">test_safe_sparse_dot_2d_1d</a> (A_array_constr)</td></tr>
<tr class="separator:a95d4c5d2bc357bbe6e1fc8978147d03b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea29c759b654613b11c01706066bf12c" id="r_aea29c759b654613b11c01706066bf12c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1utils_1_1tests_1_1test__extmath.html#aea29c759b654613b11c01706066bf12c">test_safe_sparse_dot_dense_output</a> (dense_output)</td></tr>
<tr class="separator:aea29c759b654613b11c01706066bf12c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a5c97b6e3a6bd0da256c63bf381c932aa" name="a5c97b6e3a6bd0da256c63bf381c932aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5c97b6e3a6bd0da256c63bf381c932aa">&#9670;&#160;</a></span>check_randomized_svd_low_rank()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.check_randomized_svd_low_rank </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   98</span><span class="keyword">def </span>check_randomized_svd_low_rank(dtype):</div>
<div class="line"><span class="lineno">   99</span>    <span class="comment"># Check that extmath.randomized_svd is consistent with linalg.svd</span></div>
<div class="line"><span class="lineno">  100</span>    n_samples = 100</div>
<div class="line"><span class="lineno">  101</span>    n_features = 500</div>
<div class="line"><span class="lineno">  102</span>    rank = 5</div>
<div class="line"><span class="lineno">  103</span>    k = 10</div>
<div class="line"><span class="lineno">  104</span>    decimal = 5 <span class="keywordflow">if</span> dtype == np.float32 <span class="keywordflow">else</span> 7</div>
<div class="line"><span class="lineno">  105</span>    dtype = np.dtype(dtype)</div>
<div class="line"><span class="lineno">  106</span> </div>
<div class="line"><span class="lineno">  107</span>    <span class="comment"># generate a matrix X of approximate effective rank `rank` and no noise</span></div>
<div class="line"><span class="lineno">  108</span>    <span class="comment"># component (very structured signal):</span></div>
<div class="line"><span class="lineno">  109</span>    X = make_low_rank_matrix(</div>
<div class="line"><span class="lineno">  110</span>        n_samples=n_samples,</div>
<div class="line"><span class="lineno">  111</span>        n_features=n_features,</div>
<div class="line"><span class="lineno">  112</span>        effective_rank=rank,</div>
<div class="line"><span class="lineno">  113</span>        tail_strength=0.0,</div>
<div class="line"><span class="lineno">  114</span>        random_state=0,</div>
<div class="line"><span class="lineno">  115</span>    ).astype(dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  116</span>    <span class="keyword">assert</span> X.shape == (n_samples, n_features)</div>
<div class="line"><span class="lineno">  117</span> </div>
<div class="line"><span class="lineno">  118</span>    <span class="comment"># compute the singular values of X using the slow exact method</span></div>
<div class="line"><span class="lineno">  119</span>    U, s, Vt = linalg.svd(X, full_matrices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  120</span> </div>
<div class="line"><span class="lineno">  121</span>    <span class="comment"># Convert the singular values to the specific dtype</span></div>
<div class="line"><span class="lineno">  122</span>    U = U.astype(dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  123</span>    s = s.astype(dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  124</span>    Vt = Vt.astype(dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  125</span> </div>
<div class="line"><span class="lineno">  126</span>    <span class="keywordflow">for</span> normalizer <span class="keywordflow">in</span> [<span class="stringliteral">&quot;auto&quot;</span>, <span class="stringliteral">&quot;LU&quot;</span>, <span class="stringliteral">&quot;QR&quot;</span>]:  <span class="comment"># &#39;none&#39; would not be stable</span></div>
<div class="line"><span class="lineno">  127</span>        <span class="comment"># compute the singular values of X using the fast approximate method</span></div>
<div class="line"><span class="lineno">  128</span>        Ua, sa, Va = randomized_svd(</div>
<div class="line"><span class="lineno">  129</span>            X, k, power_iteration_normalizer=normalizer, random_state=0</div>
<div class="line"><span class="lineno">  130</span>        )</div>
<div class="line"><span class="lineno">  131</span> </div>
<div class="line"><span class="lineno">  132</span>        <span class="comment"># If the input dtype is float, then the output dtype is float of the</span></div>
<div class="line"><span class="lineno">  133</span>        <span class="comment"># same bit size (f32 is not upcast to f64)</span></div>
<div class="line"><span class="lineno">  134</span>        <span class="comment"># But if the input dtype is int, the output dtype is float64</span></div>
<div class="line"><span class="lineno">  135</span>        <span class="keywordflow">if</span> dtype.kind == <span class="stringliteral">&quot;f&quot;</span>:</div>
<div class="line"><span class="lineno">  136</span>            <span class="keyword">assert</span> Ua.dtype == dtype</div>
<div class="line"><span class="lineno">  137</span>            <span class="keyword">assert</span> sa.dtype == dtype</div>
<div class="line"><span class="lineno">  138</span>            <span class="keyword">assert</span> Va.dtype == dtype</div>
<div class="line"><span class="lineno">  139</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  140</span>            <span class="keyword">assert</span> Ua.dtype == np.float64</div>
<div class="line"><span class="lineno">  141</span>            <span class="keyword">assert</span> sa.dtype == np.float64</div>
<div class="line"><span class="lineno">  142</span>            <span class="keyword">assert</span> Va.dtype == np.float64</div>
<div class="line"><span class="lineno">  143</span> </div>
<div class="line"><span class="lineno">  144</span>        <span class="keyword">assert</span> Ua.shape == (n_samples, k)</div>
<div class="line"><span class="lineno">  145</span>        <span class="keyword">assert</span> sa.shape == (k,)</div>
<div class="line"><span class="lineno">  146</span>        <span class="keyword">assert</span> Va.shape == (k, n_features)</div>
<div class="line"><span class="lineno">  147</span> </div>
<div class="line"><span class="lineno">  148</span>        <span class="comment"># ensure that the singular values of both methods are equal up to the</span></div>
<div class="line"><span class="lineno">  149</span>        <span class="comment"># real rank of the matrix</span></div>
<div class="line"><span class="lineno">  150</span>        assert_almost_equal(s[:k], sa, decimal=decimal)</div>
<div class="line"><span class="lineno">  151</span> </div>
<div class="line"><span class="lineno">  152</span>        <span class="comment"># check the singular vectors too (while not checking the sign)</span></div>
<div class="line"><span class="lineno">  153</span>        assert_almost_equal(</div>
<div class="line"><span class="lineno">  154</span>            np.dot(U[:, :k], Vt[:k, :]), np.dot(Ua, Va), decimal=decimal</div>
<div class="line"><span class="lineno">  155</span>        )</div>
<div class="line"><span class="lineno">  156</span> </div>
<div class="line"><span class="lineno">  157</span>        <span class="comment"># check the sparse matrix representation</span></div>
<div class="line"><span class="lineno">  158</span>        X = sparse.csr_matrix(X)</div>
<div class="line"><span class="lineno">  159</span> </div>
<div class="line"><span class="lineno">  160</span>        <span class="comment"># compute the singular values of X using the fast approximate method</span></div>
<div class="line"><span class="lineno">  161</span>        Ua, sa, Va = randomized_svd(</div>
<div class="line"><span class="lineno">  162</span>            X, k, power_iteration_normalizer=normalizer, random_state=0</div>
<div class="line"><span class="lineno">  163</span>        )</div>
<div class="line"><span class="lineno">  164</span>        <span class="keywordflow">if</span> dtype.kind == <span class="stringliteral">&quot;f&quot;</span>:</div>
<div class="line"><span class="lineno">  165</span>            <span class="keyword">assert</span> Ua.dtype == dtype</div>
<div class="line"><span class="lineno">  166</span>            <span class="keyword">assert</span> sa.dtype == dtype</div>
<div class="line"><span class="lineno">  167</span>            <span class="keyword">assert</span> Va.dtype == dtype</div>
<div class="line"><span class="lineno">  168</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  169</span>            <span class="keyword">assert</span> Ua.dtype.kind == <span class="stringliteral">&quot;f&quot;</span></div>
<div class="line"><span class="lineno">  170</span>            <span class="keyword">assert</span> sa.dtype.kind == <span class="stringliteral">&quot;f&quot;</span></div>
<div class="line"><span class="lineno">  171</span>            <span class="keyword">assert</span> Va.dtype.kind == <span class="stringliteral">&quot;f&quot;</span></div>
<div class="line"><span class="lineno">  172</span> </div>
<div class="line"><span class="lineno">  173</span>        assert_almost_equal(s[:rank], sa[:rank], decimal=decimal)</div>
<div class="line"><span class="lineno">  174</span> </div>
<div class="line"><span class="lineno">  175</span> </div>
<div class="line"><span class="lineno">  176</span><span class="preprocessor">@pytest.mark.parametrize(&quot;dtype&quot;, (np.int32, np.int64, np.float32, np.float64)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a1c7d176292e3bf2ead3d425c56b49c9b" name="a1c7d176292e3bf2ead3d425c56b49c9b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c7d176292e3bf2ead3d425c56b49c9b">&#9670;&#160;</a></span>rng()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.rng </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  677</span><span class="keyword">def </span>rng():</div>
<div class="line"><span class="lineno">  678</span>    <span class="keywordflow">return</span> np.random.RandomState(42)</div>
<div class="line"><span class="lineno">  679</span> </div>
<div class="line"><span class="lineno">  680</span> </div>
<div class="line"><span class="lineno">  681</span><span class="preprocessor">@pytest.mark.parametrize(&quot;dtype&quot;, [np.float32, np.float64])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a93b77e6a99170ffc6c34646f16e38d17" name="a93b77e6a99170ffc6c34646f16e38d17"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a93b77e6a99170ffc6c34646f16e38d17">&#9670;&#160;</a></span>test_cartesian()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_cartesian </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  610</span><span class="keyword">def </span>test_cartesian():</div>
<div class="line"><span class="lineno">  611</span>    <span class="comment"># Check if cartesian product delivers the right results</span></div>
<div class="line"><span class="lineno">  612</span> </div>
<div class="line"><span class="lineno">  613</span>    axes = (np.array([1, 2, 3]), np.array([4, 5]), np.array([6, 7]))</div>
<div class="line"><span class="lineno">  614</span> </div>
<div class="line"><span class="lineno">  615</span>    true_out = np.array(</div>
<div class="line"><span class="lineno">  616</span>        [</div>
<div class="line"><span class="lineno">  617</span>            [1, 4, 6],</div>
<div class="line"><span class="lineno">  618</span>            [1, 4, 7],</div>
<div class="line"><span class="lineno">  619</span>            [1, 5, 6],</div>
<div class="line"><span class="lineno">  620</span>            [1, 5, 7],</div>
<div class="line"><span class="lineno">  621</span>            [2, 4, 6],</div>
<div class="line"><span class="lineno">  622</span>            [2, 4, 7],</div>
<div class="line"><span class="lineno">  623</span>            [2, 5, 6],</div>
<div class="line"><span class="lineno">  624</span>            [2, 5, 7],</div>
<div class="line"><span class="lineno">  625</span>            [3, 4, 6],</div>
<div class="line"><span class="lineno">  626</span>            [3, 4, 7],</div>
<div class="line"><span class="lineno">  627</span>            [3, 5, 6],</div>
<div class="line"><span class="lineno">  628</span>            [3, 5, 7],</div>
<div class="line"><span class="lineno">  629</span>        ]</div>
<div class="line"><span class="lineno">  630</span>    )</div>
<div class="line"><span class="lineno">  631</span> </div>
<div class="line"><span class="lineno">  632</span>    out = cartesian(axes)</div>
<div class="line"><span class="lineno">  633</span>    assert_array_equal(true_out, out)</div>
<div class="line"><span class="lineno">  634</span> </div>
<div class="line"><span class="lineno">  635</span>    <span class="comment"># check single axis</span></div>
<div class="line"><span class="lineno">  636</span>    x = np.arange(3)</div>
<div class="line"><span class="lineno">  637</span>    assert_array_equal(x[:, np.newaxis], cartesian((x,)))</div>
<div class="line"><span class="lineno">  638</span> </div>
<div class="line"><span class="lineno">  639</span> </div>
<div class="line"><span class="lineno">  640</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  641</span>    <span class="stringliteral">&quot;arrays, output_dtype&quot;</span>,</div>
<div class="line"><span class="lineno">  642</span>    [</div>
<div class="line"><span class="lineno">  643</span>        (</div>
<div class="line"><span class="lineno">  644</span>            [np.array([1, 2, 3], dtype=np.int32), np.array([4, 5], dtype=np.int64)],</div>
<div class="line"><span class="lineno">  645</span>            np.dtype(np.int64),</div>
<div class="line"><span class="lineno">  646</span>        ),</div>
<div class="line"><span class="lineno">  647</span>        (</div>
<div class="line"><span class="lineno">  648</span>            [np.array([1, 2, 3], dtype=np.int32), np.array([4, 5], dtype=np.float64)],</div>
<div class="line"><span class="lineno">  649</span>            np.dtype(np.float64),</div>
<div class="line"><span class="lineno">  650</span>        ),</div>
<div class="line"><span class="lineno">  651</span>        (</div>
<div class="line"><span class="lineno">  652</span>            [np.array([1, 2, 3], dtype=np.int32), np.array([<span class="stringliteral">&quot;x&quot;</span>, <span class="stringliteral">&quot;y&quot;</span>], dtype=object)],</div>
<div class="line"><span class="lineno">  653</span>            np.dtype(object),</div>
<div class="line"><span class="lineno">  654</span>        ),</div>
<div class="line"><span class="lineno">  655</span>    ],</div>
<div class="line"><span class="lineno">  656</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a857e539a2982b400bbe5e7fb2cb6f593" name="a857e539a2982b400bbe5e7fb2cb6f593"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a857e539a2982b400bbe5e7fb2cb6f593">&#9670;&#160;</a></span>test_cartesian_mix_types()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_cartesian_mix_types </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>arrays</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_dtype</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that the cartesian product works with mixed types.</pre> <div class="fragment"><div class="line"><span class="lineno">  657</span><span class="keyword">def </span>test_cartesian_mix_types(arrays, output_dtype):</div>
<div class="line"><span class="lineno">  658</span>    <span class="stringliteral">&quot;&quot;&quot;Check that the cartesian product works with mixed types.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  659</span>    output = cartesian(arrays)</div>
<div class="line"><span class="lineno">  660</span> </div>
<div class="line"><span class="lineno">  661</span>    <span class="keyword">assert</span> output.dtype == output_dtype</div>
<div class="line"><span class="lineno">  662</span> </div>
<div class="line"><span class="lineno">  663</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a85ccc7e9334536f39375883b1f2eadef" name="a85ccc7e9334536f39375883b1f2eadef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85ccc7e9334536f39375883b1f2eadef">&#9670;&#160;</a></span>test_density()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_density </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   38</span><span class="keyword">def </span>test_density():</div>
<div class="line"><span class="lineno">   39</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">   40</span>    X = rng.randint(10, size=(10, 5))</div>
<div class="line"><span class="lineno">   41</span>    X[1, 2] = 0</div>
<div class="line"><span class="lineno">   42</span>    X[5, 3] = 0</div>
<div class="line"><span class="lineno">   43</span>    X_csr = sparse.csr_matrix(X)</div>
<div class="line"><span class="lineno">   44</span>    X_csc = sparse.csc_matrix(X)</div>
<div class="line"><span class="lineno">   45</span>    X_coo = sparse.coo_matrix(X)</div>
<div class="line"><span class="lineno">   46</span>    X_lil = sparse.lil_matrix(X)</div>
<div class="line"><span class="lineno">   47</span> </div>
<div class="line"><span class="lineno">   48</span>    <span class="keywordflow">for</span> X_ <span class="keywordflow">in</span> (X_csr, X_csc, X_coo, X_lil):</div>
<div class="line"><span class="lineno">   49</span>        <span class="keyword">assert</span> density(X_) == density(X)</div>
<div class="line"><span class="lineno">   50</span> </div>
<div class="line"><span class="lineno">   51</span> </div>
<div class="line"><span class="lineno">   52</span><span class="comment"># TODO(1.4): Remove test</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a72b1fac2dda0edb9cd25da2b3c64cc67" name="a72b1fac2dda0edb9cd25da2b3c64cc67"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a72b1fac2dda0edb9cd25da2b3c64cc67">&#9670;&#160;</a></span>test_density_deprecated_kwargs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_density_deprecated_kwargs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that future warning is raised when user enters keyword arguments.</pre> <div class="fragment"><div class="line"><span class="lineno">   53</span><span class="keyword">def </span>test_density_deprecated_kwargs():</div>
<div class="line"><span class="lineno">   54</span>    <span class="stringliteral">&quot;&quot;&quot;Check that future warning is raised when user enters keyword arguments.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   55</span>    test_array = np.array([[1, 2, 3], [4, 5, 6]])</div>
<div class="line"><span class="lineno">   56</span>    <span class="keyword">with</span> pytest.warns(</div>
<div class="line"><span class="lineno">   57</span>        FutureWarning,</div>
<div class="line"><span class="lineno">   58</span>        match=(</div>
<div class="line"><span class="lineno">   59</span>            <span class="stringliteral">&quot;Additional keyword arguments are deprecated in version 1.2 and will be&quot;</span></div>
<div class="line"><span class="lineno">   60</span>            <span class="stringliteral">&quot; removed in version 1.4.&quot;</span></div>
<div class="line"><span class="lineno">   61</span>        ),</div>
<div class="line"><span class="lineno">   62</span>    ):</div>
<div class="line"><span class="lineno">   63</span>        density(test_array, a=1)</div>
<div class="line"><span class="lineno">   64</span> </div>
<div class="line"><span class="lineno">   65</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a263b023c3bc9a1c36838630c5e74f2ed" name="a263b023c3bc9a1c36838630c5e74f2ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a263b023c3bc9a1c36838630c5e74f2ed">&#9670;&#160;</a></span>test_incremental_mean_and_variance_ignore_nan()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_incremental_mean_and_variance_ignore_nan </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  803</span><span class="keyword">def </span>test_incremental_mean_and_variance_ignore_nan():</div>
<div class="line"><span class="lineno">  804</span>    old_means = np.array([535.0, 535.0, 535.0, 535.0])</div>
<div class="line"><span class="lineno">  805</span>    old_variances = np.array([4225.0, 4225.0, 4225.0, 4225.0])</div>
<div class="line"><span class="lineno">  806</span>    old_sample_count = np.array([2, 2, 2, 2], dtype=np.int32)</div>
<div class="line"><span class="lineno">  807</span> </div>
<div class="line"><span class="lineno">  808</span>    X = np.array([[170, 170, 170, 170], [430, 430, 430, 430], [300, 300, 300, 300]])</div>
<div class="line"><span class="lineno">  809</span> </div>
<div class="line"><span class="lineno">  810</span>    X_nan = np.array(</div>
<div class="line"><span class="lineno">  811</span>        [</div>
<div class="line"><span class="lineno">  812</span>            [170, np.nan, 170, 170],</div>
<div class="line"><span class="lineno">  813</span>            [np.nan, 170, 430, 430],</div>
<div class="line"><span class="lineno">  814</span>            [430, 430, np.nan, 300],</div>
<div class="line"><span class="lineno">  815</span>            [300, 300, 300, np.nan],</div>
<div class="line"><span class="lineno">  816</span>        ]</div>
<div class="line"><span class="lineno">  817</span>    )</div>
<div class="line"><span class="lineno">  818</span> </div>
<div class="line"><span class="lineno">  819</span>    X_means, X_variances, X_count = _incremental_mean_and_var(</div>
<div class="line"><span class="lineno">  820</span>        X, old_means, old_variances, old_sample_count</div>
<div class="line"><span class="lineno">  821</span>    )</div>
<div class="line"><span class="lineno">  822</span>    X_nan_means, X_nan_variances, X_nan_count = _incremental_mean_and_var(</div>
<div class="line"><span class="lineno">  823</span>        X_nan, old_means, old_variances, old_sample_count</div>
<div class="line"><span class="lineno">  824</span>    )</div>
<div class="line"><span class="lineno">  825</span> </div>
<div class="line"><span class="lineno">  826</span>    assert_allclose(X_nan_means, X_means)</div>
<div class="line"><span class="lineno">  827</span>    assert_allclose(X_nan_variances, X_variances)</div>
<div class="line"><span class="lineno">  828</span>    assert_allclose(X_nan_count, X_count)</div>
<div class="line"><span class="lineno">  829</span> </div>
<div class="line"><span class="lineno">  830</span> </div>
<div class="line"><span class="lineno">  831</span><span class="preprocessor">@skip_if_32bit</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a495a034fab1918ffb4dd6c5ea54608a5" name="a495a034fab1918ffb4dd6c5ea54608a5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a495a034fab1918ffb4dd6c5ea54608a5">&#9670;&#160;</a></span>test_incremental_variance_ddof()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_incremental_variance_ddof </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  904</span><span class="keyword">def </span>test_incremental_variance_ddof():</div>
<div class="line"><span class="lineno">  905</span>    <span class="comment"># Test that degrees of freedom parameter for calculations are correct.</span></div>
<div class="line"><span class="lineno">  906</span>    rng = np.random.RandomState(1999)</div>
<div class="line"><span class="lineno">  907</span>    X = rng.randn(50, 10)</div>
<div class="line"><span class="lineno">  908</span>    n_samples, n_features = X.shape</div>
<div class="line"><span class="lineno">  909</span>    <span class="keywordflow">for</span> batch_size <span class="keywordflow">in</span> [11, 20, 37]:</div>
<div class="line"><span class="lineno">  910</span>        steps = np.arange(0, X.shape[0], batch_size)</div>
<div class="line"><span class="lineno">  911</span>        <span class="keywordflow">if</span> steps[-1] != X.shape[0]:</div>
<div class="line"><span class="lineno">  912</span>            steps = np.hstack([steps, n_samples])</div>
<div class="line"><span class="lineno">  913</span> </div>
<div class="line"><span class="lineno">  914</span>        <span class="keywordflow">for</span> i, j <span class="keywordflow">in</span> zip(steps[:-1], steps[1:]):</div>
<div class="line"><span class="lineno">  915</span>            batch = X[i:j, :]</div>
<div class="line"><span class="lineno">  916</span>            <span class="keywordflow">if</span> i == 0:</div>
<div class="line"><span class="lineno">  917</span>                incremental_means = batch.mean(axis=0)</div>
<div class="line"><span class="lineno">  918</span>                incremental_variances = batch.var(axis=0)</div>
<div class="line"><span class="lineno">  919</span>                <span class="comment"># Assign this twice so that the test logic is consistent</span></div>
<div class="line"><span class="lineno">  920</span>                incremental_count = batch.shape[0]</div>
<div class="line"><span class="lineno">  921</span>                sample_count = np.full(batch.shape[1], batch.shape[0], dtype=np.int32)</div>
<div class="line"><span class="lineno">  922</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  923</span>                result = _incremental_mean_and_var(</div>
<div class="line"><span class="lineno">  924</span>                    batch, incremental_means, incremental_variances, sample_count</div>
<div class="line"><span class="lineno">  925</span>                )</div>
<div class="line"><span class="lineno">  926</span>                (incremental_means, incremental_variances, incremental_count) = result</div>
<div class="line"><span class="lineno">  927</span>                sample_count += batch.shape[0]</div>
<div class="line"><span class="lineno">  928</span> </div>
<div class="line"><span class="lineno">  929</span>            calculated_means = np.mean(X[:j], axis=0)</div>
<div class="line"><span class="lineno">  930</span>            calculated_variances = np.var(X[:j], axis=0)</div>
<div class="line"><span class="lineno">  931</span>            assert_almost_equal(incremental_means, calculated_means, 6)</div>
<div class="line"><span class="lineno">  932</span>            assert_almost_equal(incremental_variances, calculated_variances, 6)</div>
<div class="line"><span class="lineno">  933</span>            assert_array_equal(incremental_count, sample_count)</div>
<div class="line"><span class="lineno">  934</span> </div>
<div class="line"><span class="lineno">  935</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a65a999d580712979549af462caf3ea4a" name="a65a999d580712979549af462caf3ea4a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65a999d580712979549af462caf3ea4a">&#9670;&#160;</a></span>test_incremental_variance_numerical_stability()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_incremental_variance_numerical_stability </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  832</span><span class="keyword">def </span>test_incremental_variance_numerical_stability():</div>
<div class="line"><span class="lineno">  833</span>    <span class="comment"># Test Youngs and Cramer incremental variance formulas.</span></div>
<div class="line"><span class="lineno">  834</span> </div>
<div class="line"><span class="lineno">  835</span>    <span class="keyword">def </span>np_var(A):</div>
<div class="line"><span class="lineno">  836</span>        <span class="keywordflow">return</span> A.var(axis=0)</div>
<div class="line"><span class="lineno">  837</span> </div>
<div class="line"><span class="lineno">  838</span>    <span class="comment"># Naive one pass variance computation - not numerically stable</span></div>
<div class="line"><span class="lineno">  839</span>    <span class="comment"># https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance</span></div>
<div class="line"><span class="lineno">  840</span>    <span class="keyword">def </span>one_pass_var(X):</div>
<div class="line"><span class="lineno">  841</span>        n = X.shape[0]</div>
<div class="line"><span class="lineno">  842</span>        exp_x2 = (X**2).sum(axis=0) / n</div>
<div class="line"><span class="lineno">  843</span>        expx_2 = (X.sum(axis=0) / n) ** 2</div>
<div class="line"><span class="lineno">  844</span>        <span class="keywordflow">return</span> exp_x2 - expx_2</div>
<div class="line"><span class="lineno">  845</span> </div>
<div class="line"><span class="lineno">  846</span>    <span class="comment"># Two-pass algorithm, stable.</span></div>
<div class="line"><span class="lineno">  847</span>    <span class="comment"># We use it as a benchmark. It is not an online algorithm</span></div>
<div class="line"><span class="lineno">  848</span>    <span class="comment"># https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Two-pass_algorithm</span></div>
<div class="line"><span class="lineno">  849</span>    <span class="keyword">def </span>two_pass_var(X):</div>
<div class="line"><span class="lineno">  850</span>        mean = X.mean(axis=0)</div>
<div class="line"><span class="lineno">  851</span>        Y = X.copy()</div>
<div class="line"><span class="lineno">  852</span>        <span class="keywordflow">return</span> np.mean((Y - mean) ** 2, axis=0)</div>
<div class="line"><span class="lineno">  853</span> </div>
<div class="line"><span class="lineno">  854</span>    <span class="comment"># Naive online implementation</span></div>
<div class="line"><span class="lineno">  855</span>    <span class="comment"># https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Online_algorithm</span></div>
<div class="line"><span class="lineno">  856</span>    <span class="comment"># This works only for chunks for size 1</span></div>
<div class="line"><span class="lineno">  857</span>    <span class="keyword">def </span>naive_mean_variance_update(x, last_mean, last_variance, last_sample_count):</div>
<div class="line"><span class="lineno">  858</span>        updated_sample_count = last_sample_count + 1</div>
<div class="line"><span class="lineno">  859</span>        samples_ratio = last_sample_count / float(updated_sample_count)</div>
<div class="line"><span class="lineno">  860</span>        updated_mean = x / updated_sample_count + last_mean * samples_ratio</div>
<div class="line"><span class="lineno">  861</span>        updated_variance = (</div>
<div class="line"><span class="lineno">  862</span>            last_variance * samples_ratio</div>
<div class="line"><span class="lineno">  863</span>            + (x - last_mean) * (x - updated_mean) / updated_sample_count</div>
<div class="line"><span class="lineno">  864</span>        )</div>
<div class="line"><span class="lineno">  865</span>        <span class="keywordflow">return</span> updated_mean, updated_variance, updated_sample_count</div>
<div class="line"><span class="lineno">  866</span> </div>
<div class="line"><span class="lineno">  867</span>    <span class="comment"># We want to show a case when one_pass_var has error &gt; 1e-3 while</span></div>
<div class="line"><span class="lineno">  868</span>    <span class="comment"># _batch_mean_variance_update has less.</span></div>
<div class="line"><span class="lineno">  869</span>    tol = 200</div>
<div class="line"><span class="lineno">  870</span>    n_features = 2</div>
<div class="line"><span class="lineno">  871</span>    n_samples = 10000</div>
<div class="line"><span class="lineno">  872</span>    x1 = np.array(1e8, dtype=np.float64)</div>
<div class="line"><span class="lineno">  873</span>    x2 = np.log(1e-5, dtype=np.float64)</div>
<div class="line"><span class="lineno">  874</span>    A0 = np.full((n_samples // 2, n_features), x1, dtype=np.float64)</div>
<div class="line"><span class="lineno">  875</span>    A1 = np.full((n_samples // 2, n_features), x2, dtype=np.float64)</div>
<div class="line"><span class="lineno">  876</span>    A = np.vstack((A0, A1))</div>
<div class="line"><span class="lineno">  877</span> </div>
<div class="line"><span class="lineno">  878</span>    <span class="comment"># Naive one pass var: &gt;tol (=1063)</span></div>
<div class="line"><span class="lineno">  879</span>    <span class="keyword">assert</span> np.abs(np_var(A) - one_pass_var(A)).max() &gt; tol</div>
<div class="line"><span class="lineno">  880</span> </div>
<div class="line"><span class="lineno">  881</span>    <span class="comment"># Starting point for online algorithms: after A0</span></div>
<div class="line"><span class="lineno">  882</span> </div>
<div class="line"><span class="lineno">  883</span>    <span class="comment"># Naive implementation: &gt;tol (436)</span></div>
<div class="line"><span class="lineno">  884</span>    mean, var, n = A0[0, :], np.zeros(n_features), n_samples // 2</div>
<div class="line"><span class="lineno">  885</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(A1.shape[0]):</div>
<div class="line"><span class="lineno">  886</span>        mean, var, n = naive_mean_variance_update(A1[i, :], mean, var, n)</div>
<div class="line"><span class="lineno">  887</span>    <span class="keyword">assert</span> n == A.shape[0]</div>
<div class="line"><span class="lineno">  888</span>    <span class="comment"># the mean is also slightly unstable</span></div>
<div class="line"><span class="lineno">  889</span>    <span class="keyword">assert</span> np.abs(A.mean(axis=0) - mean).max() &gt; 1e-6</div>
<div class="line"><span class="lineno">  890</span>    <span class="keyword">assert</span> np.abs(np_var(A) - var).max() &gt; tol</div>
<div class="line"><span class="lineno">  891</span> </div>
<div class="line"><span class="lineno">  892</span>    <span class="comment"># Robust implementation: &lt;tol (177)</span></div>
<div class="line"><span class="lineno">  893</span>    mean, var = A0[0, :], np.zeros(n_features)</div>
<div class="line"><span class="lineno">  894</span>    n = np.full(n_features, n_samples // 2, dtype=np.int32)</div>
<div class="line"><span class="lineno">  895</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(A1.shape[0]):</div>
<div class="line"><span class="lineno">  896</span>        mean, var, n = _incremental_mean_and_var(</div>
<div class="line"><span class="lineno">  897</span>            A1[i, :].reshape((1, A1.shape[1])), mean, var, n</div>
<div class="line"><span class="lineno">  898</span>        )</div>
<div class="line"><span class="lineno">  899</span>    assert_array_equal(n, A.shape[0])</div>
<div class="line"><span class="lineno">  900</span>    assert_array_almost_equal(A.mean(axis=0), mean)</div>
<div class="line"><span class="lineno">  901</span>    <span class="keyword">assert</span> tol &gt; np.abs(np_var(A) - var).max()</div>
<div class="line"><span class="lineno">  902</span> </div>
<div class="line"><span class="lineno">  903</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9168ace6a98d8ecc4c24622ab3e33fea" name="a9168ace6a98d8ecc4c24622ab3e33fea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9168ace6a98d8ecc4c24622ab3e33fea">&#9670;&#160;</a></span>test_incremental_variance_update_formulas()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_incremental_variance_update_formulas </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  777</span><span class="keyword">def </span>test_incremental_variance_update_formulas():</div>
<div class="line"><span class="lineno">  778</span>    <span class="comment"># Test Youngs and Cramer incremental variance formulas.</span></div>
<div class="line"><span class="lineno">  779</span>    <span class="comment"># Doggie data from https://www.mathsisfun.com/data/standard-deviation.html</span></div>
<div class="line"><span class="lineno">  780</span>    A = np.array(</div>
<div class="line"><span class="lineno">  781</span>        [</div>
<div class="line"><span class="lineno">  782</span>            [600, 470, 170, 430, 300],</div>
<div class="line"><span class="lineno">  783</span>            [600, 470, 170, 430, 300],</div>
<div class="line"><span class="lineno">  784</span>            [600, 470, 170, 430, 300],</div>
<div class="line"><span class="lineno">  785</span>            [600, 470, 170, 430, 300],</div>
<div class="line"><span class="lineno">  786</span>        ]</div>
<div class="line"><span class="lineno">  787</span>    ).T</div>
<div class="line"><span class="lineno">  788</span>    idx = 2</div>
<div class="line"><span class="lineno">  789</span>    X1 = A[:idx, :]</div>
<div class="line"><span class="lineno">  790</span>    X2 = A[idx:, :]</div>
<div class="line"><span class="lineno">  791</span> </div>
<div class="line"><span class="lineno">  792</span>    old_means = X1.mean(axis=0)</div>
<div class="line"><span class="lineno">  793</span>    old_variances = X1.var(axis=0)</div>
<div class="line"><span class="lineno">  794</span>    old_sample_count = np.full(X1.shape[1], X1.shape[0], dtype=np.int32)</div>
<div class="line"><span class="lineno">  795</span>    final_means, final_variances, final_count = _incremental_mean_and_var(</div>
<div class="line"><span class="lineno">  796</span>        X2, old_means, old_variances, old_sample_count</div>
<div class="line"><span class="lineno">  797</span>    )</div>
<div class="line"><span class="lineno">  798</span>    assert_almost_equal(final_means, A.mean(axis=0), 6)</div>
<div class="line"><span class="lineno">  799</span>    assert_almost_equal(final_variances, A.var(axis=0), 6)</div>
<div class="line"><span class="lineno">  800</span>    assert_almost_equal(final_count, A.shape[0])</div>
<div class="line"><span class="lineno">  801</span> </div>
<div class="line"><span class="lineno">  802</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a65da25865856130615f747b8f074ebea" name="a65da25865856130615f747b8f074ebea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65da25865856130615f747b8f074ebea">&#9670;&#160;</a></span>test_incremental_weighted_mean_and_variance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_incremental_weighted_mean_and_variance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mean</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>var</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>weight_loc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>weight_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rng</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  703</span>):</div>
<div class="line"><span class="lineno">  704</span> </div>
<div class="line"><span class="lineno">  705</span>    <span class="comment"># Testing of correctness and numerical stability</span></div>
<div class="line"><span class="lineno">  706</span>    <span class="keyword">def </span>_assert(X, sample_weight, expected_mean, expected_var):</div>
<div class="line"><span class="lineno">  707</span>        n = X.shape[0]</div>
<div class="line"><span class="lineno">  708</span>        <span class="keywordflow">for</span> chunk_size <span class="keywordflow">in</span> [1, n // 10 + 1, n // 4 + 1, n // 2 + 1, n]:</div>
<div class="line"><span class="lineno">  709</span>            last_mean, last_weight_sum, last_var = 0, 0, 0</div>
<div class="line"><span class="lineno">  710</span>            <span class="keywordflow">for</span> batch <span class="keywordflow">in</span> gen_batches(n, chunk_size):</div>
<div class="line"><span class="lineno">  711</span>                last_mean, last_var, last_weight_sum = _incremental_mean_and_var(</div>
<div class="line"><span class="lineno">  712</span>                    X[batch],</div>
<div class="line"><span class="lineno">  713</span>                    last_mean,</div>
<div class="line"><span class="lineno">  714</span>                    last_var,</div>
<div class="line"><span class="lineno">  715</span>                    last_weight_sum,</div>
<div class="line"><span class="lineno">  716</span>                    sample_weight=sample_weight[batch],</div>
<div class="line"><span class="lineno">  717</span>                )</div>
<div class="line"><span class="lineno">  718</span>            assert_allclose(last_mean, expected_mean)</div>
<div class="line"><span class="lineno">  719</span>            assert_allclose(last_var, expected_var, atol=1e-6)</div>
<div class="line"><span class="lineno">  720</span> </div>
<div class="line"><span class="lineno">  721</span>    size = (100, 20)</div>
<div class="line"><span class="lineno">  722</span>    weight = rng.normal(loc=weight_loc, scale=weight_scale, size=size[0])</div>
<div class="line"><span class="lineno">  723</span> </div>
<div class="line"><span class="lineno">  724</span>    <span class="comment"># Compare to weighted average: np.average</span></div>
<div class="line"><span class="lineno">  725</span>    X = rng.normal(loc=mean, scale=var, size=size)</div>
<div class="line"><span class="lineno">  726</span>    expected_mean = _safe_accumulator_op(np.average, X, weights=weight, axis=0)</div>
<div class="line"><span class="lineno">  727</span>    expected_var = _safe_accumulator_op(</div>
<div class="line"><span class="lineno">  728</span>        np.average, (X - expected_mean) ** 2, weights=weight, axis=0</div>
<div class="line"><span class="lineno">  729</span>    )</div>
<div class="line"><span class="lineno">  730</span>    _assert(X, weight, expected_mean, expected_var)</div>
<div class="line"><span class="lineno">  731</span> </div>
<div class="line"><span class="lineno">  732</span>    <span class="comment"># Compare to unweighted mean: np.mean</span></div>
<div class="line"><span class="lineno">  733</span>    X = rng.normal(loc=mean, scale=var, size=size)</div>
<div class="line"><span class="lineno">  734</span>    ones_weight = np.ones(size[0])</div>
<div class="line"><span class="lineno">  735</span>    expected_mean = _safe_accumulator_op(np.mean, X, axis=0)</div>
<div class="line"><span class="lineno">  736</span>    expected_var = _safe_accumulator_op(np.var, X, axis=0)</div>
<div class="line"><span class="lineno">  737</span>    _assert(X, ones_weight, expected_mean, expected_var)</div>
<div class="line"><span class="lineno">  738</span> </div>
<div class="line"><span class="lineno">  739</span> </div>
<div class="line"><span class="lineno">  740</span><span class="preprocessor">@pytest.mark.parametrize(&quot;dtype&quot;, [np.float32, np.float64])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aab4d3eb17fb267658b89e17b10b18d20" name="aab4d3eb17fb267658b89e17b10b18d20"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab4d3eb17fb267658b89e17b10b18d20">&#9670;&#160;</a></span>test_incremental_weighted_mean_and_variance_ignore_nan()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_incremental_weighted_mean_and_variance_ignore_nan </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  741</span><span class="keyword">def </span>test_incremental_weighted_mean_and_variance_ignore_nan(dtype):</div>
<div class="line"><span class="lineno">  742</span>    old_means = np.array([535.0, 535.0, 535.0, 535.0])</div>
<div class="line"><span class="lineno">  743</span>    old_variances = np.array([4225.0, 4225.0, 4225.0, 4225.0])</div>
<div class="line"><span class="lineno">  744</span>    old_weight_sum = np.array([2, 2, 2, 2], dtype=np.int32)</div>
<div class="line"><span class="lineno">  745</span>    sample_weights_X = np.ones(3)</div>
<div class="line"><span class="lineno">  746</span>    sample_weights_X_nan = np.ones(4)</div>
<div class="line"><span class="lineno">  747</span> </div>
<div class="line"><span class="lineno">  748</span>    X = np.array(</div>
<div class="line"><span class="lineno">  749</span>        [[170, 170, 170, 170], [430, 430, 430, 430], [300, 300, 300, 300]]</div>
<div class="line"><span class="lineno">  750</span>    ).astype(dtype)</div>
<div class="line"><span class="lineno">  751</span> </div>
<div class="line"><span class="lineno">  752</span>    X_nan = np.array(</div>
<div class="line"><span class="lineno">  753</span>        [</div>
<div class="line"><span class="lineno">  754</span>            [170, np.nan, 170, 170],</div>
<div class="line"><span class="lineno">  755</span>            [np.nan, 170, 430, 430],</div>
<div class="line"><span class="lineno">  756</span>            [430, 430, np.nan, 300],</div>
<div class="line"><span class="lineno">  757</span>            [300, 300, 300, np.nan],</div>
<div class="line"><span class="lineno">  758</span>        ]</div>
<div class="line"><span class="lineno">  759</span>    ).astype(dtype)</div>
<div class="line"><span class="lineno">  760</span> </div>
<div class="line"><span class="lineno">  761</span>    X_means, X_variances, X_count = _incremental_mean_and_var(</div>
<div class="line"><span class="lineno">  762</span>        X, old_means, old_variances, old_weight_sum, sample_weight=sample_weights_X</div>
<div class="line"><span class="lineno">  763</span>    )</div>
<div class="line"><span class="lineno">  764</span>    X_nan_means, X_nan_variances, X_nan_count = _incremental_mean_and_var(</div>
<div class="line"><span class="lineno">  765</span>        X_nan,</div>
<div class="line"><span class="lineno">  766</span>        old_means,</div>
<div class="line"><span class="lineno">  767</span>        old_variances,</div>
<div class="line"><span class="lineno">  768</span>        old_weight_sum,</div>
<div class="line"><span class="lineno">  769</span>        sample_weight=sample_weights_X_nan,</div>
<div class="line"><span class="lineno">  770</span>    )</div>
<div class="line"><span class="lineno">  771</span> </div>
<div class="line"><span class="lineno">  772</span>    assert_allclose(X_nan_means, X_means)</div>
<div class="line"><span class="lineno">  773</span>    assert_allclose(X_nan_variances, X_variances)</div>
<div class="line"><span class="lineno">  774</span>    assert_allclose(X_nan_count, X_count)</div>
<div class="line"><span class="lineno">  775</span> </div>
<div class="line"><span class="lineno">  776</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a498982271800a3fd73ef9b3688adcf76" name="a498982271800a3fd73ef9b3688adcf76"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a498982271800a3fd73ef9b3688adcf76">&#9670;&#160;</a></span>test_incremental_weighted_mean_and_variance_simple()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_incremental_weighted_mean_and_variance_simple </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rng</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  682</span><span class="keyword">def </span>test_incremental_weighted_mean_and_variance_simple(rng, dtype):</div>
<div class="line"><span class="lineno">  683</span>    mult = 10</div>
<div class="line"><span class="lineno">  684</span>    X = rng.rand(1000, 20).astype(dtype) * mult</div>
<div class="line"><span class="lineno">  685</span>    sample_weight = rng.rand(X.shape[0]) * mult</div>
<div class="line"><span class="lineno">  686</span>    mean, var, _ = _incremental_mean_and_var(X, 0, 0, 0, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  687</span> </div>
<div class="line"><span class="lineno">  688</span>    expected_mean = np.average(X, weights=sample_weight, axis=0)</div>
<div class="line"><span class="lineno">  689</span>    expected_var = (</div>
<div class="line"><span class="lineno">  690</span>        np.average(X**2, weights=sample_weight, axis=0) - expected_mean**2</div>
<div class="line"><span class="lineno">  691</span>    )</div>
<div class="line"><span class="lineno">  692</span>    assert_almost_equal(mean, expected_mean)</div>
<div class="line"><span class="lineno">  693</span>    assert_almost_equal(var, expected_var)</div>
<div class="line"><span class="lineno">  694</span> </div>
<div class="line"><span class="lineno">  695</span> </div>
<div class="line"><span class="lineno">  696</span><span class="preprocessor">@pytest.mark.parametrize(&quot;mean&quot;, [0, 1e7, -1e7])</span></div>
<div class="line"><span class="lineno">  697</span><span class="preprocessor">@pytest.mark.parametrize(&quot;var&quot;, [1, 1e-8, 1e5])</span></div>
<div class="line"><span class="lineno">  698</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  699</span>    <span class="stringliteral">&quot;weight_loc, weight_scale&quot;</span>, [(0, 1), (0, 1e-8), (1, 1e-8), (10, 1), (1e7, 1)]</div>
<div class="line"><span class="lineno">  700</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae517d4ddd7a7ebddee519b2ebf0342df" name="ae517d4ddd7a7ebddee519b2ebf0342df"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae517d4ddd7a7ebddee519b2ebf0342df">&#9670;&#160;</a></span>test_logistic_sigmoid()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_logistic_sigmoid </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  664</span><span class="keyword">def </span>test_logistic_sigmoid():</div>
<div class="line"><span class="lineno">  665</span>    <span class="comment"># Check correctness and robustness of logistic sigmoid implementation</span></div>
<div class="line"><span class="lineno">  666</span>    <span class="keyword">def </span>naive_log_logistic(x):</div>
<div class="line"><span class="lineno">  667</span>        <span class="keywordflow">return</span> np.log(expit(x))</div>
<div class="line"><span class="lineno">  668</span> </div>
<div class="line"><span class="lineno">  669</span>    x = np.linspace(-2, 2, 50)</div>
<div class="line"><span class="lineno">  670</span>    assert_array_almost_equal(log_logistic(x), naive_log_logistic(x))</div>
<div class="line"><span class="lineno">  671</span> </div>
<div class="line"><span class="lineno">  672</span>    extreme_x = np.array([-100.0, 100.0])</div>
<div class="line"><span class="lineno">  673</span>    assert_array_almost_equal(log_logistic(extreme_x), [-100, 0])</div>
<div class="line"><span class="lineno">  674</span> </div>
<div class="line"><span class="lineno">  675</span> </div>
<div class="line"><span class="lineno">  676</span><span class="preprocessor">@pytest.fixture()</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aaabdafb131665fb973916a328852f690" name="aaabdafb131665fb973916a328852f690"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaabdafb131665fb973916a328852f690">&#9670;&#160;</a></span>test_random_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_random_weights </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   80</span><span class="keyword">def </span>test_random_weights():</div>
<div class="line"><span class="lineno">   81</span>    <span class="comment"># set this up so that each row should have a weighted mode of 6,</span></div>
<div class="line"><span class="lineno">   82</span>    <span class="comment"># with a score that is easily reproduced</span></div>
<div class="line"><span class="lineno">   83</span>    mode_result = 6</div>
<div class="line"><span class="lineno">   84</span> </div>
<div class="line"><span class="lineno">   85</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">   86</span>    x = rng.randint(mode_result, size=(100, 10))</div>
<div class="line"><span class="lineno">   87</span>    w = rng.random_sample(x.shape)</div>
<div class="line"><span class="lineno">   88</span> </div>
<div class="line"><span class="lineno">   89</span>    x[:, :5] = mode_result</div>
<div class="line"><span class="lineno">   90</span>    w[:, :5] += 1</div>
<div class="line"><span class="lineno">   91</span> </div>
<div class="line"><span class="lineno">   92</span>    mode, score = weighted_mode(x, w, axis=1)</div>
<div class="line"><span class="lineno">   93</span> </div>
<div class="line"><span class="lineno">   94</span>    assert_array_equal(mode, mode_result)</div>
<div class="line"><span class="lineno">   95</span>    assert_array_almost_equal(score.ravel(), w[:, :5].sum(1))</div>
<div class="line"><span class="lineno">   96</span> </div>
<div class="line"><span class="lineno">   97</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2eb4e747e8c2fad0cc47e825f3acce96" name="a2eb4e747e8c2fad0cc47e825f3acce96"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2eb4e747e8c2fad0cc47e825f3acce96">&#9670;&#160;</a></span>test_randomized_eigsh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_eigsh </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test that `_randomized_eigsh` returns the appropriate components</pre> <div class="fragment"><div class="line"><span class="lineno">  182</span><span class="keyword">def </span>test_randomized_eigsh(dtype):</div>
<div class="line"><span class="lineno">  183</span>    <span class="stringliteral">&quot;&quot;&quot;Test that `_randomized_eigsh` returns the appropriate components&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  184</span> </div>
<div class="line"><span class="lineno">  185</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno">  186</span>    X = np.diag(np.array([1.0, -2.0, 0.0, 3.0], dtype=dtype))</div>
<div class="line"><span class="lineno">  187</span>    <span class="comment"># random rotation that preserves the eigenvalues of X</span></div>
<div class="line"><span class="lineno">  188</span>    rand_rot = np.linalg.qr(rng.normal(size=X.shape))[0]</div>
<div class="line"><span class="lineno">  189</span>    X = rand_rot @ X @ rand_rot.T</div>
<div class="line"><span class="lineno">  190</span> </div>
<div class="line"><span class="lineno">  191</span>    <span class="comment"># with &#39;module&#39; selection method, the negative eigenvalue shows up</span></div>
<div class="line"><span class="lineno">  192</span>    eigvals, eigvecs = _randomized_eigsh(X, n_components=2, selection=<span class="stringliteral">&quot;module&quot;</span>)</div>
<div class="line"><span class="lineno">  193</span>    <span class="comment"># eigenvalues</span></div>
<div class="line"><span class="lineno">  194</span>    <span class="keyword">assert</span> eigvals.shape == (2,)</div>
<div class="line"><span class="lineno">  195</span>    assert_array_almost_equal(eigvals, [3.0, -2.0])  <span class="comment"># negative eigenvalue here</span></div>
<div class="line"><span class="lineno">  196</span>    <span class="comment"># eigenvectors</span></div>
<div class="line"><span class="lineno">  197</span>    <span class="keyword">assert</span> eigvecs.shape == (4, 2)</div>
<div class="line"><span class="lineno">  198</span> </div>
<div class="line"><span class="lineno">  199</span>    <span class="comment"># with &#39;value&#39; selection method, the negative eigenvalue does not show up</span></div>
<div class="line"><span class="lineno">  200</span>    <span class="keyword">with</span> pytest.raises(NotImplementedError):</div>
<div class="line"><span class="lineno">  201</span>        _randomized_eigsh(X, n_components=2, selection=<span class="stringliteral">&quot;value&quot;</span>)</div>
<div class="line"><span class="lineno">  202</span> </div>
<div class="line"><span class="lineno">  203</span> </div>
<div class="line"><span class="lineno">  204</span><span class="preprocessor">@pytest.mark.parametrize(&quot;k&quot;, (10, 50, 100, 199, 200)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a383bd2cc8cfd7a15f9393d97f65b32f6" name="a383bd2cc8cfd7a15f9393d97f65b32f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a383bd2cc8cfd7a15f9393d97f65b32f6">&#9670;&#160;</a></span>test_randomized_eigsh_compared_to_others()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_eigsh_compared_to_others </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>k</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that `_randomized_eigsh` is similar to other `eigsh`

Tests that for a random PSD matrix, `_randomized_eigsh` provides results
comparable to LAPACK (scipy.linalg.eigh) and ARPACK
(scipy.sparse.linalg.eigsh).

Note: some versions of ARPACK do not support k=n_features.
</pre> <div class="fragment"><div class="line"><span class="lineno">  205</span><span class="keyword">def </span>test_randomized_eigsh_compared_to_others(k):</div>
<div class="line"><span class="lineno">  206</span>    <span class="stringliteral">&quot;&quot;&quot;Check that `_randomized_eigsh` is similar to other `eigsh`</span></div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">    Tests that for a random PSD matrix, `_randomized_eigsh` provides results</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">    comparable to LAPACK (scipy.linalg.eigh) and ARPACK</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">    (scipy.sparse.linalg.eigsh).</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">    Note: some versions of ARPACK do not support k=n_features.</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  214</span> </div>
<div class="line"><span class="lineno">  215</span>    <span class="comment"># make a random PSD matrix</span></div>
<div class="line"><span class="lineno">  216</span>    n_features = 200</div>
<div class="line"><span class="lineno">  217</span>    X = make_sparse_spd_matrix(n_features, random_state=0)</div>
<div class="line"><span class="lineno">  218</span> </div>
<div class="line"><span class="lineno">  219</span>    <span class="comment"># compare two versions of randomized</span></div>
<div class="line"><span class="lineno">  220</span>    <span class="comment"># rough and fast</span></div>
<div class="line"><span class="lineno">  221</span>    eigvals, eigvecs = _randomized_eigsh(</div>
<div class="line"><span class="lineno">  222</span>        X, n_components=k, selection=<span class="stringliteral">&quot;module&quot;</span>, n_iter=25, random_state=0</div>
<div class="line"><span class="lineno">  223</span>    )</div>
<div class="line"><span class="lineno">  224</span>    <span class="comment"># more accurate but slow (TODO find realistic settings here)</span></div>
<div class="line"><span class="lineno">  225</span>    eigvals_qr, eigvecs_qr = _randomized_eigsh(</div>
<div class="line"><span class="lineno">  226</span>        X,</div>
<div class="line"><span class="lineno">  227</span>        n_components=k,</div>
<div class="line"><span class="lineno">  228</span>        n_iter=25,</div>
<div class="line"><span class="lineno">  229</span>        n_oversamples=20,</div>
<div class="line"><span class="lineno">  230</span>        random_state=0,</div>
<div class="line"><span class="lineno">  231</span>        power_iteration_normalizer=<span class="stringliteral">&quot;QR&quot;</span>,</div>
<div class="line"><span class="lineno">  232</span>        selection=<span class="stringliteral">&quot;module&quot;</span>,</div>
<div class="line"><span class="lineno">  233</span>    )</div>
<div class="line"><span class="lineno">  234</span> </div>
<div class="line"><span class="lineno">  235</span>    <span class="comment"># with LAPACK</span></div>
<div class="line"><span class="lineno">  236</span>    eigvals_lapack, eigvecs_lapack = linalg.eigh(</div>
<div class="line"><span class="lineno">  237</span>        X, eigvals=(n_features - k, n_features - 1)</div>
<div class="line"><span class="lineno">  238</span>    )</div>
<div class="line"><span class="lineno">  239</span>    indices = eigvals_lapack.argsort()[::-1]</div>
<div class="line"><span class="lineno">  240</span>    eigvals_lapack = eigvals_lapack[indices]</div>
<div class="line"><span class="lineno">  241</span>    eigvecs_lapack = eigvecs_lapack[:, indices]</div>
<div class="line"><span class="lineno">  242</span> </div>
<div class="line"><span class="lineno">  243</span>    <span class="comment"># -- eigenvalues comparison</span></div>
<div class="line"><span class="lineno">  244</span>    <span class="keyword">assert</span> eigvals_lapack.shape == (k,)</div>
<div class="line"><span class="lineno">  245</span>    <span class="comment"># comparison precision</span></div>
<div class="line"><span class="lineno">  246</span>    assert_array_almost_equal(eigvals, eigvals_lapack, decimal=6)</div>
<div class="line"><span class="lineno">  247</span>    assert_array_almost_equal(eigvals_qr, eigvals_lapack, decimal=6)</div>
<div class="line"><span class="lineno">  248</span> </div>
<div class="line"><span class="lineno">  249</span>    <span class="comment"># -- eigenvectors comparison</span></div>
<div class="line"><span class="lineno">  250</span>    <span class="keyword">assert</span> eigvecs_lapack.shape == (n_features, k)</div>
<div class="line"><span class="lineno">  251</span>    <span class="comment"># flip eigenvectors&#39; sign to enforce deterministic output</span></div>
<div class="line"><span class="lineno">  252</span>    dummy_vecs = np.zeros_like(eigvecs).T</div>
<div class="line"><span class="lineno">  253</span>    eigvecs, _ = svd_flip(eigvecs, dummy_vecs)</div>
<div class="line"><span class="lineno">  254</span>    eigvecs_qr, _ = svd_flip(eigvecs_qr, dummy_vecs)</div>
<div class="line"><span class="lineno">  255</span>    eigvecs_lapack, _ = svd_flip(eigvecs_lapack, dummy_vecs)</div>
<div class="line"><span class="lineno">  256</span>    assert_array_almost_equal(eigvecs, eigvecs_lapack, decimal=4)</div>
<div class="line"><span class="lineno">  257</span>    assert_array_almost_equal(eigvecs_qr, eigvecs_lapack, decimal=6)</div>
<div class="line"><span class="lineno">  258</span> </div>
<div class="line"><span class="lineno">  259</span>    <span class="comment"># comparison ARPACK ~ LAPACK (some ARPACK implems do not support k=n)</span></div>
<div class="line"><span class="lineno">  260</span>    <span class="keywordflow">if</span> k &lt; n_features:</div>
<div class="line"><span class="lineno">  261</span>        v0 = _init_arpack_v0(n_features, random_state=0)</div>
<div class="line"><span class="lineno">  262</span>        <span class="comment"># &quot;LA&quot; largest algebraic &lt;=&gt; selection=&quot;value&quot; in randomized_eigsh</span></div>
<div class="line"><span class="lineno">  263</span>        eigvals_arpack, eigvecs_arpack = eigsh(</div>
<div class="line"><span class="lineno">  264</span>            X, k, which=<span class="stringliteral">&quot;LA&quot;</span>, tol=0, maxiter=<span class="keywordtype">None</span>, v0=v0</div>
<div class="line"><span class="lineno">  265</span>        )</div>
<div class="line"><span class="lineno">  266</span>        indices = eigvals_arpack.argsort()[::-1]</div>
<div class="line"><span class="lineno">  267</span>        <span class="comment"># eigenvalues</span></div>
<div class="line"><span class="lineno">  268</span>        eigvals_arpack = eigvals_arpack[indices]</div>
<div class="line"><span class="lineno">  269</span>        assert_array_almost_equal(eigvals_lapack, eigvals_arpack, decimal=10)</div>
<div class="line"><span class="lineno">  270</span>        <span class="comment"># eigenvectors</span></div>
<div class="line"><span class="lineno">  271</span>        eigvecs_arpack = eigvecs_arpack[:, indices]</div>
<div class="line"><span class="lineno">  272</span>        eigvecs_arpack, _ = svd_flip(eigvecs_arpack, dummy_vecs)</div>
<div class="line"><span class="lineno">  273</span>        assert_array_almost_equal(eigvecs_arpack, eigvecs_lapack, decimal=8)</div>
<div class="line"><span class="lineno">  274</span> </div>
<div class="line"><span class="lineno">  275</span> </div>
<div class="line"><span class="lineno">  276</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  277</span>    <span class="stringliteral">&quot;n,rank&quot;</span>,</div>
<div class="line"><span class="lineno">  278</span>    [</div>
<div class="line"><span class="lineno">  279</span>        (10, 7),</div>
<div class="line"><span class="lineno">  280</span>        (100, 10),</div>
<div class="line"><span class="lineno">  281</span>        (100, 80),</div>
<div class="line"><span class="lineno">  282</span>        (500, 10),</div>
<div class="line"><span class="lineno">  283</span>        (500, 250),</div>
<div class="line"><span class="lineno">  284</span>        (500, 400),</div>
<div class="line"><span class="lineno">  285</span>    ],</div>
<div class="line"><span class="lineno">  286</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a0905cc045efc3b8f32f9892b53f96e93" name="a0905cc045efc3b8f32f9892b53f96e93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0905cc045efc3b8f32f9892b53f96e93">&#9670;&#160;</a></span>test_randomized_eigsh_reconst_low_rank()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_eigsh_reconst_low_rank </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rank</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that randomized_eigsh is able to reconstruct a low rank psd matrix

Tests that the decomposition provided by `_randomized_eigsh` leads to
orthonormal eigenvectors, and that a low rank PSD matrix can be effectively
reconstructed with good accuracy using it.
</pre> <div class="fragment"><div class="line"><span class="lineno">  287</span><span class="keyword">def </span>test_randomized_eigsh_reconst_low_rank(n, rank):</div>
<div class="line"><span class="lineno">  288</span>    <span class="stringliteral">&quot;&quot;&quot;Check that randomized_eigsh is able to reconstruct a low rank psd matrix</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">    Tests that the decomposition provided by `_randomized_eigsh` leads to</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">    orthonormal eigenvectors, and that a low rank PSD matrix can be effectively</span></div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">    reconstructed with good accuracy using it.</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  294</span>    <span class="keyword">assert</span> rank &lt; n</div>
<div class="line"><span class="lineno">  295</span> </div>
<div class="line"><span class="lineno">  296</span>    <span class="comment"># create a low rank PSD</span></div>
<div class="line"><span class="lineno">  297</span>    rng = np.random.RandomState(69)</div>
<div class="line"><span class="lineno">  298</span>    X = rng.randn(n, rank)</div>
<div class="line"><span class="lineno">  299</span>    A = X @ X.T</div>
<div class="line"><span class="lineno">  300</span> </div>
<div class="line"><span class="lineno">  301</span>    <span class="comment"># approximate A with the &quot;right&quot; number of components</span></div>
<div class="line"><span class="lineno">  302</span>    S, V = _randomized_eigsh(A, n_components=rank, random_state=rng)</div>
<div class="line"><span class="lineno">  303</span>    <span class="comment"># orthonormality checks</span></div>
<div class="line"><span class="lineno">  304</span>    assert_array_almost_equal(np.linalg.norm(V, axis=0), np.ones(S.shape))</div>
<div class="line"><span class="lineno">  305</span>    assert_array_almost_equal(V.T @ V, np.diag(np.ones(S.shape)))</div>
<div class="line"><span class="lineno">  306</span>    <span class="comment"># reconstruction</span></div>
<div class="line"><span class="lineno">  307</span>    A_reconstruct = V @ np.diag(S) @ V.T</div>
<div class="line"><span class="lineno">  308</span> </div>
<div class="line"><span class="lineno">  309</span>    <span class="comment"># test that the approximation is good</span></div>
<div class="line"><span class="lineno">  310</span>    assert_array_almost_equal(A_reconstruct, A, decimal=6)</div>
<div class="line"><span class="lineno">  311</span> </div>
<div class="line"><span class="lineno">  312</span> </div>
<div class="line"><span class="lineno">  313</span><span class="preprocessor">@pytest.mark.parametrize(&quot;dtype&quot;, (np.float32, np.float64)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a884dd339539109e9b60643e62bb040ac" name="a884dd339539109e9b60643e62bb040ac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a884dd339539109e9b60643e62bb040ac">&#9670;&#160;</a></span>test_randomized_svd_infinite_rank()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_svd_infinite_rank </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  381</span><span class="keyword">def </span>test_randomized_svd_infinite_rank():</div>
<div class="line"><span class="lineno">  382</span>    <span class="comment"># Check that extmath.randomized_svd can handle noisy matrices</span></div>
<div class="line"><span class="lineno">  383</span>    n_samples = 100</div>
<div class="line"><span class="lineno">  384</span>    n_features = 500</div>
<div class="line"><span class="lineno">  385</span>    rank = 5</div>
<div class="line"><span class="lineno">  386</span>    k = 10</div>
<div class="line"><span class="lineno">  387</span> </div>
<div class="line"><span class="lineno">  388</span>    <span class="comment"># let us try again without &#39;low_rank component&#39;: just regularly but slowly</span></div>
<div class="line"><span class="lineno">  389</span>    <span class="comment"># decreasing singular values: the rank of the data matrix is infinite</span></div>
<div class="line"><span class="lineno">  390</span>    X = make_low_rank_matrix(</div>
<div class="line"><span class="lineno">  391</span>        n_samples=n_samples,</div>
<div class="line"><span class="lineno">  392</span>        n_features=n_features,</div>
<div class="line"><span class="lineno">  393</span>        effective_rank=rank,</div>
<div class="line"><span class="lineno">  394</span>        tail_strength=1.0,</div>
<div class="line"><span class="lineno">  395</span>        random_state=0,</div>
<div class="line"><span class="lineno">  396</span>    )</div>
<div class="line"><span class="lineno">  397</span>    <span class="keyword">assert</span> X.shape == (n_samples, n_features)</div>
<div class="line"><span class="lineno">  398</span> </div>
<div class="line"><span class="lineno">  399</span>    <span class="comment"># compute the singular values of X using the slow exact method</span></div>
<div class="line"><span class="lineno">  400</span>    _, s, _ = linalg.svd(X, full_matrices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  401</span>    <span class="keywordflow">for</span> normalizer <span class="keywordflow">in</span> [<span class="stringliteral">&quot;auto&quot;</span>, <span class="stringliteral">&quot;none&quot;</span>, <span class="stringliteral">&quot;LU&quot;</span>, <span class="stringliteral">&quot;QR&quot;</span>]:</div>
<div class="line"><span class="lineno">  402</span>        <span class="comment"># compute the singular values of X using the fast approximate method</span></div>
<div class="line"><span class="lineno">  403</span>        <span class="comment"># without the iterated power method</span></div>
<div class="line"><span class="lineno">  404</span>        _, sa, _ = randomized_svd(</div>
<div class="line"><span class="lineno">  405</span>            X, k, n_iter=0, power_iteration_normalizer=normalizer, random_state=0</div>
<div class="line"><span class="lineno">  406</span>        )</div>
<div class="line"><span class="lineno">  407</span> </div>
<div class="line"><span class="lineno">  408</span>        <span class="comment"># the approximation does not tolerate the noise:</span></div>
<div class="line"><span class="lineno">  409</span>        <span class="keyword">assert</span> np.abs(s[:k] - sa).max() &gt; 0.1</div>
<div class="line"><span class="lineno">  410</span> </div>
<div class="line"><span class="lineno">  411</span>        <span class="comment"># compute the singular values of X using the fast approximate method</span></div>
<div class="line"><span class="lineno">  412</span>        <span class="comment"># with iterated power method</span></div>
<div class="line"><span class="lineno">  413</span>        _, sap, _ = randomized_svd(</div>
<div class="line"><span class="lineno">  414</span>            X, k, n_iter=5, power_iteration_normalizer=normalizer, random_state=0</div>
<div class="line"><span class="lineno">  415</span>        )</div>
<div class="line"><span class="lineno">  416</span> </div>
<div class="line"><span class="lineno">  417</span>        <span class="comment"># the iterated power method is still managing to get most of the</span></div>
<div class="line"><span class="lineno">  418</span>        <span class="comment"># structure at the requested rank</span></div>
<div class="line"><span class="lineno">  419</span>        assert_almost_equal(s[:k], sap, decimal=3)</div>
<div class="line"><span class="lineno">  420</span> </div>
<div class="line"><span class="lineno">  421</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a05a50bdb2240c69d97514a45a102cc63" name="a05a50bdb2240c69d97514a45a102cc63"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a05a50bdb2240c69d97514a45a102cc63">&#9670;&#160;</a></span>test_randomized_svd_lapack_driver()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_svd_lapack_driver </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>m</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  588</span><span class="keyword">def </span>test_randomized_svd_lapack_driver(n, m, k, seed):</div>
<div class="line"><span class="lineno">  589</span>    <span class="comment"># Check that different SVD drivers provide consistent results</span></div>
<div class="line"><span class="lineno">  590</span> </div>
<div class="line"><span class="lineno">  591</span>    <span class="comment"># Matrix being compressed</span></div>
<div class="line"><span class="lineno">  592</span>    rng = np.random.RandomState(seed)</div>
<div class="line"><span class="lineno">  593</span>    X = rng.rand(n, m)</div>
<div class="line"><span class="lineno">  594</span> </div>
<div class="line"><span class="lineno">  595</span>    <span class="comment"># Number of components</span></div>
<div class="line"><span class="lineno">  596</span>    u1, s1, vt1 = randomized_svd(X, k, svd_lapack_driver=<span class="stringliteral">&quot;gesdd&quot;</span>, random_state=0)</div>
<div class="line"><span class="lineno">  597</span>    u2, s2, vt2 = randomized_svd(X, k, svd_lapack_driver=<span class="stringliteral">&quot;gesvd&quot;</span>, random_state=0)</div>
<div class="line"><span class="lineno">  598</span> </div>
<div class="line"><span class="lineno">  599</span>    <span class="comment"># Check shape and contents</span></div>
<div class="line"><span class="lineno">  600</span>    <span class="keyword">assert</span> u1.shape == u2.shape</div>
<div class="line"><span class="lineno">  601</span>    assert_allclose(u1, u2, atol=0, rtol=1e-3)</div>
<div class="line"><span class="lineno">  602</span> </div>
<div class="line"><span class="lineno">  603</span>    <span class="keyword">assert</span> s1.shape == s2.shape</div>
<div class="line"><span class="lineno">  604</span>    assert_allclose(s1, s2, atol=0, rtol=1e-3)</div>
<div class="line"><span class="lineno">  605</span> </div>
<div class="line"><span class="lineno">  606</span>    <span class="keyword">assert</span> vt1.shape == vt2.shape</div>
<div class="line"><span class="lineno">  607</span>    assert_allclose(vt1, vt2, atol=0, rtol=1e-3)</div>
<div class="line"><span class="lineno">  608</span> </div>
<div class="line"><span class="lineno">  609</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abb8d362515c086f3397169c27823443e" name="abb8d362515c086f3397169c27823443e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb8d362515c086f3397169c27823443e">&#9670;&#160;</a></span>test_randomized_svd_low_rank_all_dtypes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_svd_low_rank_all_dtypes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  177</span><span class="keyword">def </span>test_randomized_svd_low_rank_all_dtypes(dtype):</div>
<div class="line"><span class="lineno">  178</span>    check_randomized_svd_low_rank(dtype)</div>
<div class="line"><span class="lineno">  179</span> </div>
<div class="line"><span class="lineno">  180</span> </div>
<div class="line"><span class="lineno">  181</span><span class="preprocessor">@pytest.mark.parametrize(&quot;dtype&quot;, (np.int32, np.int64, np.float32, np.float64)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a05704cb55e3f6e47d2db6c24864fb113" name="a05704cb55e3f6e47d2db6c24864fb113"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a05704cb55e3f6e47d2db6c24864fb113">&#9670;&#160;</a></span>test_randomized_svd_low_rank_with_noise()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_svd_low_rank_with_noise </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  340</span><span class="keyword">def </span>test_randomized_svd_low_rank_with_noise():</div>
<div class="line"><span class="lineno">  341</span>    <span class="comment"># Check that extmath.randomized_svd can handle noisy matrices</span></div>
<div class="line"><span class="lineno">  342</span>    n_samples = 100</div>
<div class="line"><span class="lineno">  343</span>    n_features = 500</div>
<div class="line"><span class="lineno">  344</span>    rank = 5</div>
<div class="line"><span class="lineno">  345</span>    k = 10</div>
<div class="line"><span class="lineno">  346</span> </div>
<div class="line"><span class="lineno">  347</span>    <span class="comment"># generate a matrix X wity structure approximate rank `rank` and an</span></div>
<div class="line"><span class="lineno">  348</span>    <span class="comment"># important noisy component</span></div>
<div class="line"><span class="lineno">  349</span>    X = make_low_rank_matrix(</div>
<div class="line"><span class="lineno">  350</span>        n_samples=n_samples,</div>
<div class="line"><span class="lineno">  351</span>        n_features=n_features,</div>
<div class="line"><span class="lineno">  352</span>        effective_rank=rank,</div>
<div class="line"><span class="lineno">  353</span>        tail_strength=0.1,</div>
<div class="line"><span class="lineno">  354</span>        random_state=0,</div>
<div class="line"><span class="lineno">  355</span>    )</div>
<div class="line"><span class="lineno">  356</span>    <span class="keyword">assert</span> X.shape == (n_samples, n_features)</div>
<div class="line"><span class="lineno">  357</span> </div>
<div class="line"><span class="lineno">  358</span>    <span class="comment"># compute the singular values of X using the slow exact method</span></div>
<div class="line"><span class="lineno">  359</span>    _, s, _ = linalg.svd(X, full_matrices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  360</span> </div>
<div class="line"><span class="lineno">  361</span>    <span class="keywordflow">for</span> normalizer <span class="keywordflow">in</span> [<span class="stringliteral">&quot;auto&quot;</span>, <span class="stringliteral">&quot;none&quot;</span>, <span class="stringliteral">&quot;LU&quot;</span>, <span class="stringliteral">&quot;QR&quot;</span>]:</div>
<div class="line"><span class="lineno">  362</span>        <span class="comment"># compute the singular values of X using the fast approximate</span></div>
<div class="line"><span class="lineno">  363</span>        <span class="comment"># method without the iterated power method</span></div>
<div class="line"><span class="lineno">  364</span>        _, sa, _ = randomized_svd(</div>
<div class="line"><span class="lineno">  365</span>            X, k, n_iter=0, power_iteration_normalizer=normalizer, random_state=0</div>
<div class="line"><span class="lineno">  366</span>        )</div>
<div class="line"><span class="lineno">  367</span> </div>
<div class="line"><span class="lineno">  368</span>        <span class="comment"># the approximation does not tolerate the noise:</span></div>
<div class="line"><span class="lineno">  369</span>        <span class="keyword">assert</span> np.abs(s[:k] - sa).max() &gt; 0.01</div>
<div class="line"><span class="lineno">  370</span> </div>
<div class="line"><span class="lineno">  371</span>        <span class="comment"># compute the singular values of X using the fast approximate</span></div>
<div class="line"><span class="lineno">  372</span>        <span class="comment"># method with iterated power method</span></div>
<div class="line"><span class="lineno">  373</span>        _, sap, _ = randomized_svd(</div>
<div class="line"><span class="lineno">  374</span>            X, k, power_iteration_normalizer=normalizer, random_state=0</div>
<div class="line"><span class="lineno">  375</span>        )</div>
<div class="line"><span class="lineno">  376</span> </div>
<div class="line"><span class="lineno">  377</span>        <span class="comment"># the iterated power method is helping getting rid of the noise:</span></div>
<div class="line"><span class="lineno">  378</span>        assert_almost_equal(s[:k], sap, decimal=3)</div>
<div class="line"><span class="lineno">  379</span> </div>
<div class="line"><span class="lineno">  380</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4cf2ff2f442d49bc2295ff6a1ca0dc1e" name="a4cf2ff2f442d49bc2295ff6a1ca0dc1e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4cf2ff2f442d49bc2295ff6a1ca0dc1e">&#9670;&#160;</a></span>test_randomized_svd_power_iteration_normalizer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_svd_power_iteration_normalizer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  454</span><span class="keyword">def </span>test_randomized_svd_power_iteration_normalizer():</div>
<div class="line"><span class="lineno">  455</span>    <span class="comment"># randomized_svd with power_iteration_normalized=&#39;none&#39; diverges for</span></div>
<div class="line"><span class="lineno">  456</span>    <span class="comment"># large number of power iterations on this dataset</span></div>
<div class="line"><span class="lineno">  457</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno">  458</span>    X = make_low_rank_matrix(100, 500, effective_rank=50, random_state=rng)</div>
<div class="line"><span class="lineno">  459</span>    X += 3 * rng.randint(0, 2, size=X.shape)</div>
<div class="line"><span class="lineno">  460</span>    n_components = 50</div>
<div class="line"><span class="lineno">  461</span> </div>
<div class="line"><span class="lineno">  462</span>    <span class="comment"># Check that it diverges with many (non-normalized) power iterations</span></div>
<div class="line"><span class="lineno">  463</span>    U, s, Vt = randomized_svd(</div>
<div class="line"><span class="lineno">  464</span>        X, n_components, n_iter=2, power_iteration_normalizer=<span class="stringliteral">&quot;none&quot;</span>, random_state=0</div>
<div class="line"><span class="lineno">  465</span>    )</div>
<div class="line"><span class="lineno">  466</span>    A = X - U.dot(np.diag(s).dot(Vt))</div>
<div class="line"><span class="lineno">  467</span>    error_2 = linalg.norm(A, ord=<span class="stringliteral">&quot;fro&quot;</span>)</div>
<div class="line"><span class="lineno">  468</span>    U, s, Vt = randomized_svd(</div>
<div class="line"><span class="lineno">  469</span>        X, n_components, n_iter=20, power_iteration_normalizer=<span class="stringliteral">&quot;none&quot;</span>, random_state=0</div>
<div class="line"><span class="lineno">  470</span>    )</div>
<div class="line"><span class="lineno">  471</span>    A = X - U.dot(np.diag(s).dot(Vt))</div>
<div class="line"><span class="lineno">  472</span>    error_20 = linalg.norm(A, ord=<span class="stringliteral">&quot;fro&quot;</span>)</div>
<div class="line"><span class="lineno">  473</span>    <span class="keyword">assert</span> np.abs(error_2 - error_20) &gt; 100</div>
<div class="line"><span class="lineno">  474</span> </div>
<div class="line"><span class="lineno">  475</span>    <span class="keywordflow">for</span> normalizer <span class="keywordflow">in</span> [<span class="stringliteral">&quot;LU&quot;</span>, <span class="stringliteral">&quot;QR&quot;</span>, <span class="stringliteral">&quot;auto&quot;</span>]:</div>
<div class="line"><span class="lineno">  476</span>        U, s, Vt = randomized_svd(</div>
<div class="line"><span class="lineno">  477</span>            X,</div>
<div class="line"><span class="lineno">  478</span>            n_components,</div>
<div class="line"><span class="lineno">  479</span>            n_iter=2,</div>
<div class="line"><span class="lineno">  480</span>            power_iteration_normalizer=normalizer,</div>
<div class="line"><span class="lineno">  481</span>            random_state=0,</div>
<div class="line"><span class="lineno">  482</span>        )</div>
<div class="line"><span class="lineno">  483</span>        A = X - U.dot(np.diag(s).dot(Vt))</div>
<div class="line"><span class="lineno">  484</span>        error_2 = linalg.norm(A, ord=<span class="stringliteral">&quot;fro&quot;</span>)</div>
<div class="line"><span class="lineno">  485</span> </div>
<div class="line"><span class="lineno">  486</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> [5, 10, 50]:</div>
<div class="line"><span class="lineno">  487</span>            U, s, Vt = randomized_svd(</div>
<div class="line"><span class="lineno">  488</span>                X,</div>
<div class="line"><span class="lineno">  489</span>                n_components,</div>
<div class="line"><span class="lineno">  490</span>                n_iter=i,</div>
<div class="line"><span class="lineno">  491</span>                power_iteration_normalizer=normalizer,</div>
<div class="line"><span class="lineno">  492</span>                random_state=0,</div>
<div class="line"><span class="lineno">  493</span>            )</div>
<div class="line"><span class="lineno">  494</span>            A = X - U.dot(np.diag(s).dot(Vt))</div>
<div class="line"><span class="lineno">  495</span>            error = linalg.norm(A, ord=<span class="stringliteral">&quot;fro&quot;</span>)</div>
<div class="line"><span class="lineno">  496</span>            <span class="keyword">assert</span> 15 &gt; np.abs(error_2 - error)</div>
<div class="line"><span class="lineno">  497</span> </div>
<div class="line"><span class="lineno">  498</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aceb1f60bf7dd53639fe2fed7fd0fb25a" name="aceb1f60bf7dd53639fe2fed7fd0fb25a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aceb1f60bf7dd53639fe2fed7fd0fb25a">&#9670;&#160;</a></span>test_randomized_svd_sign_flip()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_svd_sign_flip </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  539</span><span class="keyword">def </span>test_randomized_svd_sign_flip():</div>
<div class="line"><span class="lineno">  540</span>    a = np.array([[2.0, 0.0], [0.0, 1.0]])</div>
<div class="line"><span class="lineno">  541</span>    u1, s1, v1 = randomized_svd(a, 2, flip_sign=<span class="keyword">True</span>, random_state=41)</div>
<div class="line"><span class="lineno">  542</span>    <span class="keywordflow">for</span> seed <span class="keywordflow">in</span> range(10):</div>
<div class="line"><span class="lineno">  543</span>        u2, s2, v2 = randomized_svd(a, 2, flip_sign=<span class="keyword">True</span>, random_state=seed)</div>
<div class="line"><span class="lineno">  544</span>        assert_almost_equal(u1, u2)</div>
<div class="line"><span class="lineno">  545</span>        assert_almost_equal(v1, v2)</div>
<div class="line"><span class="lineno">  546</span>        assert_almost_equal(np.dot(u2 * s2, v2), a)</div>
<div class="line"><span class="lineno">  547</span>        assert_almost_equal(np.dot(u2.T, u2), np.eye(2))</div>
<div class="line"><span class="lineno">  548</span>        assert_almost_equal(np.dot(v2.T, v2), np.eye(2))</div>
<div class="line"><span class="lineno">  549</span> </div>
<div class="line"><span class="lineno">  550</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9d07a9341e0477bbd158578200c71e34" name="a9d07a9341e0477bbd158578200c71e34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9d07a9341e0477bbd158578200c71e34">&#9670;&#160;</a></span>test_randomized_svd_sign_flip_with_transpose()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_svd_sign_flip_with_transpose </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  551</span><span class="keyword">def </span>test_randomized_svd_sign_flip_with_transpose():</div>
<div class="line"><span class="lineno">  552</span>    <span class="comment"># Check if the randomized_svd sign flipping is always done based on u</span></div>
<div class="line"><span class="lineno">  553</span>    <span class="comment"># irrespective of transpose.</span></div>
<div class="line"><span class="lineno">  554</span>    <span class="comment"># See https://github.com/scikit-learn/scikit-learn/issues/5608</span></div>
<div class="line"><span class="lineno">  555</span>    <span class="comment"># for more details.</span></div>
<div class="line"><span class="lineno">  556</span>    <span class="keyword">def </span>max_loading_is_positive(u, v):</div>
<div class="line"><span class="lineno">  557</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  558</span><span class="stringliteral">        returns bool tuple indicating if the values maximising np.abs</span></div>
<div class="line"><span class="lineno">  559</span><span class="stringliteral">        are positive across all rows for u and across all columns for v.</span></div>
<div class="line"><span class="lineno">  560</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  561</span>        u_based = (np.abs(u).max(axis=0) == u.max(axis=0)).all()</div>
<div class="line"><span class="lineno">  562</span>        v_based = (np.abs(v).max(axis=1) == v.max(axis=1)).all()</div>
<div class="line"><span class="lineno">  563</span>        <span class="keywordflow">return</span> u_based, v_based</div>
<div class="line"><span class="lineno">  564</span> </div>
<div class="line"><span class="lineno">  565</span>    mat = np.arange(10 * 8).reshape(10, -1)</div>
<div class="line"><span class="lineno">  566</span> </div>
<div class="line"><span class="lineno">  567</span>    <span class="comment"># Without transpose</span></div>
<div class="line"><span class="lineno">  568</span>    u_flipped, _, v_flipped = randomized_svd(mat, 3, flip_sign=<span class="keyword">True</span>, random_state=0)</div>
<div class="line"><span class="lineno">  569</span>    u_based, v_based = max_loading_is_positive(u_flipped, v_flipped)</div>
<div class="line"><span class="lineno">  570</span>    <span class="keyword">assert</span> u_based</div>
<div class="line"><span class="lineno">  571</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> v_based</div>
<div class="line"><span class="lineno">  572</span> </div>
<div class="line"><span class="lineno">  573</span>    <span class="comment"># With transpose</span></div>
<div class="line"><span class="lineno">  574</span>    u_flipped_with_transpose, _, v_flipped_with_transpose = randomized_svd(</div>
<div class="line"><span class="lineno">  575</span>        mat, 3, flip_sign=<span class="keyword">True</span>, transpose=<span class="keyword">True</span>, random_state=0</div>
<div class="line"><span class="lineno">  576</span>    )</div>
<div class="line"><span class="lineno">  577</span>    u_based, v_based = max_loading_is_positive(</div>
<div class="line"><span class="lineno">  578</span>        u_flipped_with_transpose, v_flipped_with_transpose</div>
<div class="line"><span class="lineno">  579</span>    )</div>
<div class="line"><span class="lineno">  580</span>    <span class="keyword">assert</span> u_based</div>
<div class="line"><span class="lineno">  581</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> v_based</div>
<div class="line"><span class="lineno">  582</span> </div>
<div class="line"><span class="lineno">  583</span> </div>
<div class="line"><span class="lineno">  584</span><span class="preprocessor">@pytest.mark.parametrize(&quot;n&quot;, [50, 100, 300])</span></div>
<div class="line"><span class="lineno">  585</span><span class="preprocessor">@pytest.mark.parametrize(&quot;m&quot;, [50, 100, 300])</span></div>
<div class="line"><span class="lineno">  586</span><span class="preprocessor">@pytest.mark.parametrize(&quot;k&quot;, [10, 20, 50])</span></div>
<div class="line"><span class="lineno">  587</span><span class="preprocessor">@pytest.mark.parametrize(&quot;seed&quot;, range(5)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a813eb4405ad5cb3690d648017c5490be" name="a813eb4405ad5cb3690d648017c5490be"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a813eb4405ad5cb3690d648017c5490be">&#9670;&#160;</a></span>test_randomized_svd_sparse_warnings()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_svd_sparse_warnings </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  499</span><span class="keyword">def </span>test_randomized_svd_sparse_warnings():</div>
<div class="line"><span class="lineno">  500</span>    <span class="comment"># randomized_svd throws a warning for lil and dok matrix</span></div>
<div class="line"><span class="lineno">  501</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno">  502</span>    X = make_low_rank_matrix(50, 20, effective_rank=10, random_state=rng)</div>
<div class="line"><span class="lineno">  503</span>    n_components = 5</div>
<div class="line"><span class="lineno">  504</span>    <span class="keywordflow">for</span> cls <span class="keywordflow">in</span> (sparse.lil_matrix, sparse.dok_matrix):</div>
<div class="line"><span class="lineno">  505</span>        X = cls(X)</div>
<div class="line"><span class="lineno">  506</span>        warn_msg = (</div>
<div class="line"><span class="lineno">  507</span>            <span class="stringliteral">&quot;Calculating SVD of a {} is expensive. &quot;</span></div>
<div class="line"><span class="lineno">  508</span>            <span class="stringliteral">&quot;csr_matrix is more efficient.&quot;</span>.format(cls.__name__)</div>
<div class="line"><span class="lineno">  509</span>        )</div>
<div class="line"><span class="lineno">  510</span>        <span class="keyword">with</span> pytest.warns(sparse.SparseEfficiencyWarning, match=warn_msg):</div>
<div class="line"><span class="lineno">  511</span>            randomized_svd(X, n_components, n_iter=1, power_iteration_normalizer=<span class="stringliteral">&quot;none&quot;</span>)</div>
<div class="line"><span class="lineno">  512</span> </div>
<div class="line"><span class="lineno">  513</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac9df8af838329a008ebe875190007d51" name="ac9df8af838329a008ebe875190007d51"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac9df8af838329a008ebe875190007d51">&#9670;&#160;</a></span>test_randomized_svd_transpose_consistency()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_randomized_svd_transpose_consistency </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  422</span><span class="keyword">def </span>test_randomized_svd_transpose_consistency():</div>
<div class="line"><span class="lineno">  423</span>    <span class="comment"># Check that transposing the design matrix has limited impact</span></div>
<div class="line"><span class="lineno">  424</span>    n_samples = 100</div>
<div class="line"><span class="lineno">  425</span>    n_features = 500</div>
<div class="line"><span class="lineno">  426</span>    rank = 4</div>
<div class="line"><span class="lineno">  427</span>    k = 10</div>
<div class="line"><span class="lineno">  428</span> </div>
<div class="line"><span class="lineno">  429</span>    X = make_low_rank_matrix(</div>
<div class="line"><span class="lineno">  430</span>        n_samples=n_samples,</div>
<div class="line"><span class="lineno">  431</span>        n_features=n_features,</div>
<div class="line"><span class="lineno">  432</span>        effective_rank=rank,</div>
<div class="line"><span class="lineno">  433</span>        tail_strength=0.5,</div>
<div class="line"><span class="lineno">  434</span>        random_state=0,</div>
<div class="line"><span class="lineno">  435</span>    )</div>
<div class="line"><span class="lineno">  436</span>    <span class="keyword">assert</span> X.shape == (n_samples, n_features)</div>
<div class="line"><span class="lineno">  437</span> </div>
<div class="line"><span class="lineno">  438</span>    U1, s1, V1 = randomized_svd(X, k, n_iter=3, transpose=<span class="keyword">False</span>, random_state=0)</div>
<div class="line"><span class="lineno">  439</span>    U2, s2, V2 = randomized_svd(X, k, n_iter=3, transpose=<span class="keyword">True</span>, random_state=0)</div>
<div class="line"><span class="lineno">  440</span>    U3, s3, V3 = randomized_svd(X, k, n_iter=3, transpose=<span class="stringliteral">&quot;auto&quot;</span>, random_state=0)</div>
<div class="line"><span class="lineno">  441</span>    U4, s4, V4 = linalg.svd(X, full_matrices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  442</span> </div>
<div class="line"><span class="lineno">  443</span>    assert_almost_equal(s1, s4[:k], decimal=3)</div>
<div class="line"><span class="lineno">  444</span>    assert_almost_equal(s2, s4[:k], decimal=3)</div>
<div class="line"><span class="lineno">  445</span>    assert_almost_equal(s3, s4[:k], decimal=3)</div>
<div class="line"><span class="lineno">  446</span> </div>
<div class="line"><span class="lineno">  447</span>    assert_almost_equal(np.dot(U1, V1), np.dot(U4[:, :k], V4[:k, :]), decimal=2)</div>
<div class="line"><span class="lineno">  448</span>    assert_almost_equal(np.dot(U2, V2), np.dot(U4[:, :k], V4[:k, :]), decimal=2)</div>
<div class="line"><span class="lineno">  449</span> </div>
<div class="line"><span class="lineno">  450</span>    <span class="comment"># in this case &#39;auto&#39; is equivalent to transpose</span></div>
<div class="line"><span class="lineno">  451</span>    assert_almost_equal(s2, s3)</div>
<div class="line"><span class="lineno">  452</span> </div>
<div class="line"><span class="lineno">  453</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2b4e5f9b7afd5d4076609a746d7fc60f" name="a2b4e5f9b7afd5d4076609a746d7fc60f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b4e5f9b7afd5d4076609a746d7fc60f">&#9670;&#160;</a></span>test_row_norms()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_row_norms </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  314</span><span class="keyword">def </span>test_row_norms(dtype):</div>
<div class="line"><span class="lineno">  315</span>    X = np.random.RandomState(42).randn(100, 100)</div>
<div class="line"><span class="lineno">  316</span>    <span class="keywordflow">if</span> dtype <span class="keywordflow">is</span> np.float32:</div>
<div class="line"><span class="lineno">  317</span>        precision = 4</div>
<div class="line"><span class="lineno">  318</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  319</span>        precision = 5</div>
<div class="line"><span class="lineno">  320</span> </div>
<div class="line"><span class="lineno">  321</span>    X = X.astype(dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  322</span>    sq_norm = (X**2).sum(axis=1)</div>
<div class="line"><span class="lineno">  323</span> </div>
<div class="line"><span class="lineno">  324</span>    assert_array_almost_equal(sq_norm, row_norms(X, squared=<span class="keyword">True</span>), precision)</div>
<div class="line"><span class="lineno">  325</span>    assert_array_almost_equal(np.sqrt(sq_norm), row_norms(X), precision)</div>
<div class="line"><span class="lineno">  326</span> </div>
<div class="line"><span class="lineno">  327</span>    <span class="keywordflow">for</span> csr_index_dtype <span class="keywordflow">in</span> [np.int32, np.int64]:</div>
<div class="line"><span class="lineno">  328</span>        Xcsr = sparse.csr_matrix(X, dtype=dtype)</div>
<div class="line"><span class="lineno">  329</span>        <span class="comment"># csr_matrix will use int32 indices by default,</span></div>
<div class="line"><span class="lineno">  330</span>        <span class="comment"># up-casting those to int64 when necessary</span></div>
<div class="line"><span class="lineno">  331</span>        <span class="keywordflow">if</span> csr_index_dtype <span class="keywordflow">is</span> np.int64:</div>
<div class="line"><span class="lineno">  332</span>            Xcsr.indptr = Xcsr.indptr.astype(csr_index_dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  333</span>            Xcsr.indices = Xcsr.indices.astype(csr_index_dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  334</span>        <span class="keyword">assert</span> Xcsr.indices.dtype == csr_index_dtype</div>
<div class="line"><span class="lineno">  335</span>        <span class="keyword">assert</span> Xcsr.indptr.dtype == csr_index_dtype</div>
<div class="line"><span class="lineno">  336</span>        assert_array_almost_equal(sq_norm, row_norms(Xcsr, squared=<span class="keyword">True</span>), precision)</div>
<div class="line"><span class="lineno">  337</span>        assert_array_almost_equal(np.sqrt(sq_norm), row_norms(Xcsr), precision)</div>
<div class="line"><span class="lineno">  338</span> </div>
<div class="line"><span class="lineno">  339</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad6f4c1e5eb522013391155005d15ace1" name="ad6f4c1e5eb522013391155005d15ace1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad6f4c1e5eb522013391155005d15ace1">&#9670;&#160;</a></span>test_safe_sparse_dot_2d()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_safe_sparse_dot_2d </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A_array_constr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>B_array_constr</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  974</span><span class="keyword">def </span>test_safe_sparse_dot_2d(A_array_constr, B_array_constr):</div>
<div class="line"><span class="lineno">  975</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  976</span> </div>
<div class="line"><span class="lineno">  977</span>    A = rng.random_sample((30, 10))</div>
<div class="line"><span class="lineno">  978</span>    B = rng.random_sample((10, 20))</div>
<div class="line"><span class="lineno">  979</span>    expected = np.dot(A, B)</div>
<div class="line"><span class="lineno">  980</span> </div>
<div class="line"><span class="lineno">  981</span>    A = A_array_constr(A)</div>
<div class="line"><span class="lineno">  982</span>    B = B_array_constr(B)</div>
<div class="line"><span class="lineno">  983</span>    actual = safe_sparse_dot(A, B, dense_output=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  984</span> </div>
<div class="line"><span class="lineno">  985</span>    assert_allclose(actual, expected)</div>
<div class="line"><span class="lineno">  986</span> </div>
<div class="line"><span class="lineno">  987</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a95d4c5d2bc357bbe6e1fc8978147d03b" name="a95d4c5d2bc357bbe6e1fc8978147d03b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a95d4c5d2bc357bbe6e1fc8978147d03b">&#9670;&#160;</a></span>test_safe_sparse_dot_2d_1d()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_safe_sparse_dot_2d_1d </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A_array_constr</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1011</span><span class="keyword">def </span>test_safe_sparse_dot_2d_1d(A_array_constr):</div>
<div class="line"><span class="lineno"> 1012</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno"> 1013</span> </div>
<div class="line"><span class="lineno"> 1014</span>    B = rng.random_sample((10))</div>
<div class="line"><span class="lineno"> 1015</span> </div>
<div class="line"><span class="lineno"> 1016</span>    <span class="comment"># 2D @ 1D</span></div>
<div class="line"><span class="lineno"> 1017</span>    A = rng.random_sample((30, 10))</div>
<div class="line"><span class="lineno"> 1018</span>    expected = np.dot(A, B)</div>
<div class="line"><span class="lineno"> 1019</span>    A = A_array_constr(A)</div>
<div class="line"><span class="lineno"> 1020</span>    actual = safe_sparse_dot(A, B)</div>
<div class="line"><span class="lineno"> 1021</span>    assert_allclose(actual, expected)</div>
<div class="line"><span class="lineno"> 1022</span> </div>
<div class="line"><span class="lineno"> 1023</span>    <span class="comment"># 1D @ 2D</span></div>
<div class="line"><span class="lineno"> 1024</span>    A = rng.random_sample((10, 30))</div>
<div class="line"><span class="lineno"> 1025</span>    expected = np.dot(B, A)</div>
<div class="line"><span class="lineno"> 1026</span>    A = A_array_constr(A)</div>
<div class="line"><span class="lineno"> 1027</span>    actual = safe_sparse_dot(B, A)</div>
<div class="line"><span class="lineno"> 1028</span>    assert_allclose(actual, expected)</div>
<div class="line"><span class="lineno"> 1029</span> </div>
<div class="line"><span class="lineno"> 1030</span> </div>
<div class="line"><span class="lineno"> 1031</span><span class="preprocessor">@pytest.mark.parametrize(&quot;dense_output&quot;, [True, False])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aea29c759b654613b11c01706066bf12c" name="aea29c759b654613b11c01706066bf12c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea29c759b654613b11c01706066bf12c">&#9670;&#160;</a></span>test_safe_sparse_dot_dense_output()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_safe_sparse_dot_dense_output </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dense_output</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1032</span><span class="keyword">def </span>test_safe_sparse_dot_dense_output(dense_output):</div>
<div class="line"><span class="lineno"> 1033</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno"> 1034</span> </div>
<div class="line"><span class="lineno"> 1035</span>    A = sparse.random(30, 10, density=0.1, random_state=rng)</div>
<div class="line"><span class="lineno"> 1036</span>    B = sparse.random(10, 20, density=0.1, random_state=rng)</div>
<div class="line"><span class="lineno"> 1037</span> </div>
<div class="line"><span class="lineno"> 1038</span>    expected = A.dot(B)</div>
<div class="line"><span class="lineno"> 1039</span>    actual = safe_sparse_dot(A, B, dense_output=dense_output)</div>
<div class="line"><span class="lineno"> 1040</span> </div>
<div class="line"><span class="lineno"> 1041</span>    <span class="keyword">assert</span> sparse.issparse(actual) == (<span class="keywordflow">not</span> dense_output)</div>
<div class="line"><span class="lineno"> 1042</span> </div>
<div class="line"><span class="lineno"> 1043</span>    <span class="keywordflow">if</span> dense_output:</div>
<div class="line"><span class="lineno"> 1044</span>        expected = expected.toarray()</div>
<div class="line"><span class="lineno"> 1045</span>    assert_allclose_dense_sparse(actual, expected)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ad4c817c351cad8baff4348aa97aa4bf2" name="ad4c817c351cad8baff4348aa97aa4bf2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad4c817c351cad8baff4348aa97aa4bf2">&#9670;&#160;</a></span>test_safe_sparse_dot_nd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_safe_sparse_dot_nd </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  988</span><span class="keyword">def </span>test_safe_sparse_dot_nd():</div>
<div class="line"><span class="lineno">  989</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  990</span> </div>
<div class="line"><span class="lineno">  991</span>    <span class="comment"># dense ND / sparse</span></div>
<div class="line"><span class="lineno">  992</span>    A = rng.random_sample((2, 3, 4, 5, 6))</div>
<div class="line"><span class="lineno">  993</span>    B = rng.random_sample((6, 7))</div>
<div class="line"><span class="lineno">  994</span>    expected = np.dot(A, B)</div>
<div class="line"><span class="lineno">  995</span>    B = sparse.csr_matrix(B)</div>
<div class="line"><span class="lineno">  996</span>    actual = safe_sparse_dot(A, B)</div>
<div class="line"><span class="lineno">  997</span>    assert_allclose(actual, expected)</div>
<div class="line"><span class="lineno">  998</span> </div>
<div class="line"><span class="lineno">  999</span>    <span class="comment"># sparse / dense ND</span></div>
<div class="line"><span class="lineno"> 1000</span>    A = rng.random_sample((2, 3))</div>
<div class="line"><span class="lineno"> 1001</span>    B = rng.random_sample((4, 5, 3, 6))</div>
<div class="line"><span class="lineno"> 1002</span>    expected = np.dot(A, B)</div>
<div class="line"><span class="lineno"> 1003</span>    A = sparse.csr_matrix(A)</div>
<div class="line"><span class="lineno"> 1004</span>    actual = safe_sparse_dot(A, B)</div>
<div class="line"><span class="lineno"> 1005</span>    assert_allclose(actual, expected)</div>
<div class="line"><span class="lineno"> 1006</span> </div>
<div class="line"><span class="lineno"> 1007</span> </div>
<div class="line"><span class="lineno"> 1008</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1009</span>    <span class="stringliteral">&quot;A_array_constr&quot;</span>, [np.array, sparse.csr_matrix], ids=[<span class="stringliteral">&quot;dense&quot;</span>, <span class="stringliteral">&quot;sparse&quot;</span>]</div>
<div class="line"><span class="lineno"> 1010</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a90dbd353c8a6ff154dc6136d7e55ec13" name="a90dbd353c8a6ff154dc6136d7e55ec13"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a90dbd353c8a6ff154dc6136d7e55ec13">&#9670;&#160;</a></span>test_softmax()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_softmax </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  947</span><span class="keyword">def </span>test_softmax():</div>
<div class="line"><span class="lineno">  948</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  949</span>    X = rng.randn(3, 5)</div>
<div class="line"><span class="lineno">  950</span>    exp_X = np.exp(X)</div>
<div class="line"><span class="lineno">  951</span>    sum_exp_X = np.sum(exp_X, axis=1).reshape((-1, 1))</div>
<div class="line"><span class="lineno">  952</span>    assert_array_almost_equal(softmax(X), exp_X / sum_exp_X)</div>
<div class="line"><span class="lineno">  953</span> </div>
<div class="line"><span class="lineno">  954</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6907af7949f55e5e3a42d99d7894ebdb" name="a6907af7949f55e5e3a42d99d7894ebdb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6907af7949f55e5e3a42d99d7894ebdb">&#9670;&#160;</a></span>test_stable_cumsum()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_stable_cumsum </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  955</span><span class="keyword">def </span>test_stable_cumsum():</div>
<div class="line"><span class="lineno">  956</span>    assert_array_equal(stable_cumsum([1, 2, 3]), np.cumsum([1, 2, 3]))</div>
<div class="line"><span class="lineno">  957</span>    r = np.random.RandomState(0).rand(100000)</div>
<div class="line"><span class="lineno">  958</span>    <span class="keyword">with</span> pytest.warns(RuntimeWarning):</div>
<div class="line"><span class="lineno">  959</span>        stable_cumsum(r, rtol=0, atol=0)</div>
<div class="line"><span class="lineno">  960</span> </div>
<div class="line"><span class="lineno">  961</span>    <span class="comment"># test axis parameter</span></div>
<div class="line"><span class="lineno">  962</span>    A = np.random.RandomState(36).randint(1000, size=(5, 5, 5))</div>
<div class="line"><span class="lineno">  963</span>    assert_array_equal(stable_cumsum(A, axis=0), np.cumsum(A, axis=0))</div>
<div class="line"><span class="lineno">  964</span>    assert_array_equal(stable_cumsum(A, axis=1), np.cumsum(A, axis=1))</div>
<div class="line"><span class="lineno">  965</span>    assert_array_equal(stable_cumsum(A, axis=2), np.cumsum(A, axis=2))</div>
<div class="line"><span class="lineno">  966</span> </div>
<div class="line"><span class="lineno">  967</span> </div>
<div class="line"><span class="lineno">  968</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  969</span>    <span class="stringliteral">&quot;A_array_constr&quot;</span>, [np.array, sparse.csr_matrix], ids=[<span class="stringliteral">&quot;dense&quot;</span>, <span class="stringliteral">&quot;sparse&quot;</span>]</div>
<div class="line"><span class="lineno">  970</span>)</div>
<div class="line"><span class="lineno">  971</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  972</span>    <span class="stringliteral">&quot;B_array_constr&quot;</span>, [np.array, sparse.csr_matrix], ids=[<span class="stringliteral">&quot;dense&quot;</span>, <span class="stringliteral">&quot;sparse&quot;</span>]</div>
<div class="line"><span class="lineno">  973</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a0605caf79879c1fdca6bf9e78883e591" name="a0605caf79879c1fdca6bf9e78883e591"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0605caf79879c1fdca6bf9e78883e591">&#9670;&#160;</a></span>test_svd_flip()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_svd_flip </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  514</span><span class="keyword">def </span>test_svd_flip():</div>
<div class="line"><span class="lineno">  515</span>    <span class="comment"># Check that svd_flip works in both situations, and reconstructs input.</span></div>
<div class="line"><span class="lineno">  516</span>    rs = np.random.RandomState(1999)</div>
<div class="line"><span class="lineno">  517</span>    n_samples = 20</div>
<div class="line"><span class="lineno">  518</span>    n_features = 10</div>
<div class="line"><span class="lineno">  519</span>    X = rs.randn(n_samples, n_features)</div>
<div class="line"><span class="lineno">  520</span> </div>
<div class="line"><span class="lineno">  521</span>    <span class="comment"># Check matrix reconstruction</span></div>
<div class="line"><span class="lineno">  522</span>    U, S, Vt = linalg.svd(X, full_matrices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  523</span>    U1, V1 = svd_flip(U, Vt, u_based_decision=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  524</span>    assert_almost_equal(np.dot(U1 * S, V1), X, decimal=6)</div>
<div class="line"><span class="lineno">  525</span> </div>
<div class="line"><span class="lineno">  526</span>    <span class="comment"># Check transposed matrix reconstruction</span></div>
<div class="line"><span class="lineno">  527</span>    XT = X.T</div>
<div class="line"><span class="lineno">  528</span>    U, S, Vt = linalg.svd(XT, full_matrices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  529</span>    U2, V2 = svd_flip(U, Vt, u_based_decision=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  530</span>    assert_almost_equal(np.dot(U2 * S, V2), XT, decimal=6)</div>
<div class="line"><span class="lineno">  531</span> </div>
<div class="line"><span class="lineno">  532</span>    <span class="comment"># Check that different flip methods are equivalent under reconstruction</span></div>
<div class="line"><span class="lineno">  533</span>    U_flip1, V_flip1 = svd_flip(U, Vt, u_based_decision=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  534</span>    assert_almost_equal(np.dot(U_flip1 * S, V_flip1), XT, decimal=6)</div>
<div class="line"><span class="lineno">  535</span>    U_flip2, V_flip2 = svd_flip(U, Vt, u_based_decision=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  536</span>    assert_almost_equal(np.dot(U_flip2 * S, V_flip2), XT, decimal=6)</div>
<div class="line"><span class="lineno">  537</span> </div>
<div class="line"><span class="lineno">  538</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a47018d758d78c188429652d5e77f9fd3" name="a47018d758d78c188429652d5e77f9fd3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47018d758d78c188429652d5e77f9fd3">&#9670;&#160;</a></span>test_uniform_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_uniform_weights </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   66</span><span class="keyword">def </span>test_uniform_weights():</div>
<div class="line"><span class="lineno">   67</span>    <span class="comment"># with uniform weights, results should be identical to stats.mode</span></div>
<div class="line"><span class="lineno">   68</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">   69</span>    x = rng.randint(10, size=(10, 5))</div>
<div class="line"><span class="lineno">   70</span>    weights = np.ones(x.shape)</div>
<div class="line"><span class="lineno">   71</span> </div>
<div class="line"><span class="lineno">   72</span>    <span class="keywordflow">for</span> axis <span class="keywordflow">in</span> (<span class="keywordtype">None</span>, 0, 1):</div>
<div class="line"><span class="lineno">   73</span>        mode, score = _mode(x, axis)</div>
<div class="line"><span class="lineno">   74</span>        mode2, score2 = weighted_mode(x, weights, axis=axis)</div>
<div class="line"><span class="lineno">   75</span> </div>
<div class="line"><span class="lineno">   76</span>        assert_array_equal(mode, mode2)</div>
<div class="line"><span class="lineno">   77</span>        assert_array_equal(score, score2)</div>
<div class="line"><span class="lineno">   78</span> </div>
<div class="line"><span class="lineno">   79</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a909b2b5d502ced1dbd91670153386f44" name="a909b2b5d502ced1dbd91670153386f44"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a909b2b5d502ced1dbd91670153386f44">&#9670;&#160;</a></span>test_vector_sign_flip()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.utils.tests.test_extmath.test_vector_sign_flip </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  936</span><span class="keyword">def </span>test_vector_sign_flip():</div>
<div class="line"><span class="lineno">  937</span>    <span class="comment"># Testing that sign flip is working &amp; largest value has positive sign</span></div>
<div class="line"><span class="lineno">  938</span>    data = np.random.RandomState(36).randn(5, 5)</div>
<div class="line"><span class="lineno">  939</span>    max_abs_rows = np.argmax(np.abs(data), axis=1)</div>
<div class="line"><span class="lineno">  940</span>    data_flipped = _deterministic_vector_sign_flip(data)</div>
<div class="line"><span class="lineno">  941</span>    max_rows = np.argmax(data_flipped, axis=1)</div>
<div class="line"><span class="lineno">  942</span>    assert_array_equal(max_abs_rows, max_rows)</div>
<div class="line"><span class="lineno">  943</span>    signs = np.sign(data[range(data.shape[0]), max_abs_rows])</div>
<div class="line"><span class="lineno">  944</span>    assert_array_equal(data, data_flipped * signs[:, np.newaxis])</div>
<div class="line"><span class="lineno">  945</span> </div>
<div class="line"><span class="lineno">  946</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
