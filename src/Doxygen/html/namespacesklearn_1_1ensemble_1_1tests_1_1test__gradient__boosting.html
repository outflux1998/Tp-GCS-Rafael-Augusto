<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.ensemble.tests.test_gradient_boosting Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble.html">ensemble</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html">test_gradient_boosting</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.ensemble.tests.test_gradient_boosting Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ad38b6f407d52bae2e5e19cb6d4df99ae" id="r_ad38b6f407d52bae2e5e19cb6d4df99ae"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ad38b6f407d52bae2e5e19cb6d4df99ae">test_classification_toy</a> (loss, global_random_seed)</td></tr>
<tr class="separator:ad38b6f407d52bae2e5e19cb6d4df99ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47bc5b1086c71d9d27717c64294e7092" id="r_a47bc5b1086c71d9d27717c64294e7092"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a47bc5b1086c71d9d27717c64294e7092">test_classification_synthetic</a> (loss, global_random_seed)</td></tr>
<tr class="separator:a47bc5b1086c71d9d27717c64294e7092"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18cc2c979a7391458367e481600391e4" id="r_a18cc2c979a7391458367e481600391e4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a18cc2c979a7391458367e481600391e4">test_regression_dataset</a> (loss, subsample, global_random_seed)</td></tr>
<tr class="separator:a18cc2c979a7391458367e481600391e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef1ff9ace23f69d7586a81349b3dda8d" id="r_aef1ff9ace23f69d7586a81349b3dda8d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#aef1ff9ace23f69d7586a81349b3dda8d">test_iris</a> (subsample, sample_weight, global_random_seed)</td></tr>
<tr class="separator:aef1ff9ace23f69d7586a81349b3dda8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a556de9e7e236b450d470908fb124bb10" id="r_a556de9e7e236b450d470908fb124bb10"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a556de9e7e236b450d470908fb124bb10">test_regression_synthetic</a> (global_random_seed)</td></tr>
<tr class="separator:a556de9e7e236b450d470908fb124bb10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa799603821ab438366d5bc551fd18a77" id="r_aa799603821ab438366d5bc551fd18a77"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#aa799603821ab438366d5bc551fd18a77">test_feature_importances</a> (GradientBoosting, <a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a69bfead7a756e1294b41341d5a380167">X</a>, <a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#af3594f92a4f53c73864a897522f99325">y</a>)</td></tr>
<tr class="separator:aa799603821ab438366d5bc551fd18a77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae439e86cfff5312c44a253b545277b8b" id="r_ae439e86cfff5312c44a253b545277b8b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ae439e86cfff5312c44a253b545277b8b">test_probability_log</a> (global_random_seed)</td></tr>
<tr class="separator:ae439e86cfff5312c44a253b545277b8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56d8fa9e5a774015133df26da47f8e92" id="r_a56d8fa9e5a774015133df26da47f8e92"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a56d8fa9e5a774015133df26da47f8e92">test_single_class_with_sample_weight</a> ()</td></tr>
<tr class="separator:a56d8fa9e5a774015133df26da47f8e92"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6594cc5ba79fa0c841035e115859894b" id="r_a6594cc5ba79fa0c841035e115859894b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a6594cc5ba79fa0c841035e115859894b">test_check_inputs_predict_stages</a> ()</td></tr>
<tr class="separator:a6594cc5ba79fa0c841035e115859894b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f48602bdf05afe5ce89e088129063aa" id="r_a3f48602bdf05afe5ce89e088129063aa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a3f48602bdf05afe5ce89e088129063aa">test_max_feature_regression</a> (global_random_seed)</td></tr>
<tr class="separator:a3f48602bdf05afe5ce89e088129063aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4f6d3b7ef62338e906bea5ef558851c" id="r_ab4f6d3b7ef62338e906bea5ef558851c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ab4f6d3b7ef62338e906bea5ef558851c">test_feature_importance_regression</a> (fetch_california_housing_fxt, global_random_seed)</td></tr>
<tr class="separator:ab4f6d3b7ef62338e906bea5ef558851c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1efe70ea2972d636d1b30a631d203b5" id="r_ae1efe70ea2972d636d1b30a631d203b5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ae1efe70ea2972d636d1b30a631d203b5">test_max_feature_auto</a> ()</td></tr>
<tr class="separator:ae1efe70ea2972d636d1b30a631d203b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97afdb307bd8d4cbf301d5ec7a74f80a" id="r_a97afdb307bd8d4cbf301d5ec7a74f80a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a97afdb307bd8d4cbf301d5ec7a74f80a">test_staged_predict</a> ()</td></tr>
<tr class="separator:a97afdb307bd8d4cbf301d5ec7a74f80a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c1d86353183dbedaa80613ad5741c15" id="r_a7c1d86353183dbedaa80613ad5741c15"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a7c1d86353183dbedaa80613ad5741c15">test_staged_predict_proba</a> ()</td></tr>
<tr class="separator:a7c1d86353183dbedaa80613ad5741c15"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7544989577e8bc882866e53c508c93ad" id="r_a7544989577e8bc882866e53c508c93ad"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a7544989577e8bc882866e53c508c93ad">test_staged_functions_defensive</a> (Estimator, global_random_seed)</td></tr>
<tr class="separator:a7544989577e8bc882866e53c508c93ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae23652f63307db969763ec1ea47cf557" id="r_ae23652f63307db969763ec1ea47cf557"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ae23652f63307db969763ec1ea47cf557">test_serialization</a> ()</td></tr>
<tr class="separator:ae23652f63307db969763ec1ea47cf557"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4d2fab91cc149444dfbc48fa747e73f" id="r_ae4d2fab91cc149444dfbc48fa747e73f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ae4d2fab91cc149444dfbc48fa747e73f">test_degenerate_targets</a> ()</td></tr>
<tr class="separator:ae4d2fab91cc149444dfbc48fa747e73f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05d76f32a2b818775ec0c995ff914625" id="r_a05d76f32a2b818775ec0c995ff914625"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a05d76f32a2b818775ec0c995ff914625">test_quantile_loss</a> (global_random_seed)</td></tr>
<tr class="separator:a05d76f32a2b818775ec0c995ff914625"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf8387891a2997aea30ab9a29362413d" id="r_aaf8387891a2997aea30ab9a29362413d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#aaf8387891a2997aea30ab9a29362413d">test_symbol_labels</a> ()</td></tr>
<tr class="separator:aaf8387891a2997aea30ab9a29362413d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5de5e57dff757f47b733359c207829c4" id="r_a5de5e57dff757f47b733359c207829c4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a5de5e57dff757f47b733359c207829c4">test_float_class_labels</a> ()</td></tr>
<tr class="separator:a5de5e57dff757f47b733359c207829c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65fecab643306f14319fe89530f3a8a8" id="r_a65fecab643306f14319fe89530f3a8a8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a65fecab643306f14319fe89530f3a8a8">test_shape_y</a> ()</td></tr>
<tr class="separator:a65fecab643306f14319fe89530f3a8a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ef631db09225724d3d83337bdfd98d9" id="r_a6ef631db09225724d3d83337bdfd98d9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a6ef631db09225724d3d83337bdfd98d9">test_mem_layout</a> ()</td></tr>
<tr class="separator:a6ef631db09225724d3d83337bdfd98d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bb864748858fd85f0eecd4bb7008b89" id="r_a4bb864748858fd85f0eecd4bb7008b89"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a4bb864748858fd85f0eecd4bb7008b89">test_oob_improvement</a> ()</td></tr>
<tr class="separator:a4bb864748858fd85f0eecd4bb7008b89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34a87fa321d761c6be390c5ba9ab6b8a" id="r_a34a87fa321d761c6be390c5ba9ab6b8a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a34a87fa321d761c6be390c5ba9ab6b8a">test_oob_improvement_raise</a> ()</td></tr>
<tr class="separator:a34a87fa321d761c6be390c5ba9ab6b8a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f35f3bfd38a71bd08db13bb281d1f94" id="r_a6f35f3bfd38a71bd08db13bb281d1f94"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a6f35f3bfd38a71bd08db13bb281d1f94">test_oob_multilcass_iris</a> ()</td></tr>
<tr class="separator:a6f35f3bfd38a71bd08db13bb281d1f94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfd349bfc550c5b84768c3e9d92f95d0" id="r_abfd349bfc550c5b84768c3e9d92f95d0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#abfd349bfc550c5b84768c3e9d92f95d0">test_verbose_output</a> ()</td></tr>
<tr class="separator:abfd349bfc550c5b84768c3e9d92f95d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a258919d04df4427dec9484478a6f9955" id="r_a258919d04df4427dec9484478a6f9955"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a258919d04df4427dec9484478a6f9955">test_more_verbose_output</a> ()</td></tr>
<tr class="separator:a258919d04df4427dec9484478a6f9955"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8fef4cc672e82279f4a4e7e175d240c8" id="r_a8fef4cc672e82279f4a4e7e175d240c8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a8fef4cc672e82279f4a4e7e175d240c8">test_warm_start</a> (Cls, global_random_seed)</td></tr>
<tr class="separator:a8fef4cc672e82279f4a4e7e175d240c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbd577685e0152252d2b187a8a0ad1d5" id="r_acbd577685e0152252d2b187a8a0ad1d5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#acbd577685e0152252d2b187a8a0ad1d5">test_warm_start_n_estimators</a> (Cls, global_random_seed)</td></tr>
<tr class="separator:acbd577685e0152252d2b187a8a0ad1d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6f47941bf2ec22ec7bd609ffbb57e98" id="r_aa6f47941bf2ec22ec7bd609ffbb57e98"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#aa6f47941bf2ec22ec7bd609ffbb57e98">test_warm_start_max_depth</a> (Cls)</td></tr>
<tr class="separator:aa6f47941bf2ec22ec7bd609ffbb57e98"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a955076b35c2311892adde2b08dd7470f" id="r_a955076b35c2311892adde2b08dd7470f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a955076b35c2311892adde2b08dd7470f">test_warm_start_clear</a> (Cls)</td></tr>
<tr class="separator:a955076b35c2311892adde2b08dd7470f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9aadc2f95180c4b4ac84ec6f47db235" id="r_ab9aadc2f95180c4b4ac84ec6f47db235"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ab9aadc2f95180c4b4ac84ec6f47db235">test_warm_start_smaller_n_estimators</a> (Cls)</td></tr>
<tr class="separator:ab9aadc2f95180c4b4ac84ec6f47db235"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a239933d350b43cab0a74a0909667bf2a" id="r_a239933d350b43cab0a74a0909667bf2a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a239933d350b43cab0a74a0909667bf2a">test_warm_start_equal_n_estimators</a> (Cls)</td></tr>
<tr class="separator:a239933d350b43cab0a74a0909667bf2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9512bc9781545027380840ac384b9969" id="r_a9512bc9781545027380840ac384b9969"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a9512bc9781545027380840ac384b9969">test_warm_start_oob_switch</a> (Cls)</td></tr>
<tr class="separator:a9512bc9781545027380840ac384b9969"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb6897558b5a84b8ef8d7c092e3e2f42" id="r_adb6897558b5a84b8ef8d7c092e3e2f42"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#adb6897558b5a84b8ef8d7c092e3e2f42">test_warm_start_oob</a> (Cls)</td></tr>
<tr class="separator:adb6897558b5a84b8ef8d7c092e3e2f42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc9d4bdaec6db4974003e7bbff3a84eb" id="r_abc9d4bdaec6db4974003e7bbff3a84eb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#abc9d4bdaec6db4974003e7bbff3a84eb">test_warm_start_sparse</a> (Cls)</td></tr>
<tr class="separator:abc9d4bdaec6db4974003e7bbff3a84eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a54bfe56027939c1850f1267d16487d" id="r_a4a54bfe56027939c1850f1267d16487d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a4a54bfe56027939c1850f1267d16487d">test_warm_start_fortran</a> (Cls, global_random_seed)</td></tr>
<tr class="separator:a4a54bfe56027939c1850f1267d16487d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9c412d7450aba8c3de5fc37e90fc2bc" id="r_af9c412d7450aba8c3de5fc37e90fc2bc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#af9c412d7450aba8c3de5fc37e90fc2bc">early_stopping_monitor</a> (<a class="el" href="__lapack__subroutines_8h.html#a5325f1842789194c441b272cbf424674">i</a>, <a class="el" href="__lapack__subroutines_8h.html#a20cd275d1dea5cba0a51b3e106f3e130">est</a>, locals)</td></tr>
<tr class="separator:af9c412d7450aba8c3de5fc37e90fc2bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd233d2512db9c628ff349cbe8ad9aff" id="r_afd233d2512db9c628ff349cbe8ad9aff"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#afd233d2512db9c628ff349cbe8ad9aff">test_monitor_early_stopping</a> (Cls)</td></tr>
<tr class="separator:afd233d2512db9c628ff349cbe8ad9aff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a283e96483dd8da92f4637f804c5f189d" id="r_a283e96483dd8da92f4637f804c5f189d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a283e96483dd8da92f4637f804c5f189d">test_complete_classification</a> ()</td></tr>
<tr class="separator:a283e96483dd8da92f4637f804c5f189d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d44a603888943b29e2470eb17bbc24e" id="r_a1d44a603888943b29e2470eb17bbc24e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a1d44a603888943b29e2470eb17bbc24e">test_complete_regression</a> ()</td></tr>
<tr class="separator:a1d44a603888943b29e2470eb17bbc24e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a50fa4219844236417532d0078106e0" id="r_a1a50fa4219844236417532d0078106e0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a1a50fa4219844236417532d0078106e0">test_zero_estimator_reg</a> (global_random_seed)</td></tr>
<tr class="separator:a1a50fa4219844236417532d0078106e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5f3ca057f096f5bbfe575883eec490c" id="r_af5f3ca057f096f5bbfe575883eec490c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#af5f3ca057f096f5bbfe575883eec490c">test_zero_estimator_clf</a> (global_random_seed)</td></tr>
<tr class="separator:af5f3ca057f096f5bbfe575883eec490c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe7cf6361273e0d9c33fc2713cb4418b" id="r_afe7cf6361273e0d9c33fc2713cb4418b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#afe7cf6361273e0d9c33fc2713cb4418b">test_max_leaf_nodes_max_depth</a> (GBEstimator)</td></tr>
<tr class="separator:afe7cf6361273e0d9c33fc2713cb4418b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a127f2ead859bfef4aff1e03fb73f9852" id="r_a127f2ead859bfef4aff1e03fb73f9852"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a127f2ead859bfef4aff1e03fb73f9852">test_min_impurity_decrease</a> (GBEstimator)</td></tr>
<tr class="separator:a127f2ead859bfef4aff1e03fb73f9852"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b7d7019cdeff18eea60cfa6d262297c" id="r_a0b7d7019cdeff18eea60cfa6d262297c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a0b7d7019cdeff18eea60cfa6d262297c">test_warm_start_wo_nestimators_change</a> ()</td></tr>
<tr class="separator:a0b7d7019cdeff18eea60cfa6d262297c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46cb1478c773908456e0978dbd21de32" id="r_a46cb1478c773908456e0978dbd21de32"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a46cb1478c773908456e0978dbd21de32">test_probability_exponential</a> (global_random_seed)</td></tr>
<tr class="separator:a46cb1478c773908456e0978dbd21de32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca5414b2ade1aaabb8f7fd29148fb6fc" id="r_aca5414b2ade1aaabb8f7fd29148fb6fc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#aca5414b2ade1aaabb8f7fd29148fb6fc">test_non_uniform_weights_toy_edge_case_reg</a> ()</td></tr>
<tr class="separator:aca5414b2ade1aaabb8f7fd29148fb6fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe54dfaf3be443c3ef8a37de8266cdce" id="r_abe54dfaf3be443c3ef8a37de8266cdce"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#abe54dfaf3be443c3ef8a37de8266cdce">test_non_uniform_weights_toy_edge_case_clf</a> ()</td></tr>
<tr class="separator:abe54dfaf3be443c3ef8a37de8266cdce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4ba8d487c92139e4edc66c5ff91088e" id="r_aa4ba8d487c92139e4edc66c5ff91088e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#aa4ba8d487c92139e4edc66c5ff91088e">test_sparse_input</a> (EstimatorClass, sparse_matrix)</td></tr>
<tr class="separator:aa4ba8d487c92139e4edc66c5ff91088e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65aec19fb3fb5c666e8ee46e9a912031" id="r_a65aec19fb3fb5c666e8ee46e9a912031"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a65aec19fb3fb5c666e8ee46e9a912031">test_gradient_boosting_early_stopping</a> (GradientBoostingEstimator)</td></tr>
<tr class="separator:a65aec19fb3fb5c666e8ee46e9a912031"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8e3a1785d5bbc3d4e872219a6919dde" id="r_ab8e3a1785d5bbc3d4e872219a6919dde"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ab8e3a1785d5bbc3d4e872219a6919dde">test_gradient_boosting_without_early_stopping</a> ()</td></tr>
<tr class="separator:ab8e3a1785d5bbc3d4e872219a6919dde"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab83900ab5fe352bb477667575a628afc" id="r_ab83900ab5fe352bb477667575a628afc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ab83900ab5fe352bb477667575a628afc">test_gradient_boosting_validation_fraction</a> ()</td></tr>
<tr class="separator:ab83900ab5fe352bb477667575a628afc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a672896d729de60c5bc5f612bd1516606" id="r_a672896d729de60c5bc5f612bd1516606"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a672896d729de60c5bc5f612bd1516606">test_early_stopping_stratified</a> ()</td></tr>
<tr class="separator:a672896d729de60c5bc5f612bd1516606"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01cd1cd63005159831201beec1464901" id="r_a01cd1cd63005159831201beec1464901"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a01cd1cd63005159831201beec1464901">_make_multiclass</a> ()</td></tr>
<tr class="separator:a01cd1cd63005159831201beec1464901"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acee6ac73ee39962e61feec9910620259" id="r_acee6ac73ee39962e61feec9910620259"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#acee6ac73ee39962e61feec9910620259">test_gradient_boosting_with_init</a> (gb, dataset_maker, init_estimator, global_random_seed)</td></tr>
<tr class="separator:acee6ac73ee39962e61feec9910620259"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37ab325c20aa640875f60064b33807e6" id="r_a37ab325c20aa640875f60064b33807e6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a37ab325c20aa640875f60064b33807e6">test_gradient_boosting_with_init_pipeline</a> ()</td></tr>
<tr class="separator:a37ab325c20aa640875f60064b33807e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fde70e78c85ed79831249ee398b55d4" id="r_a5fde70e78c85ed79831249ee398b55d4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a5fde70e78c85ed79831249ee398b55d4">test_early_stopping_n_classes</a> ()</td></tr>
<tr class="separator:a5fde70e78c85ed79831249ee398b55d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8090a414e3454ab43d4334bad2b53d1" id="r_af8090a414e3454ab43d4334bad2b53d1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#af8090a414e3454ab43d4334bad2b53d1">test_gbr_degenerate_feature_importances</a> ()</td></tr>
<tr class="separator:af8090a414e3454ab43d4334bad2b53d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ce48b888db37f7f72c821d8f913a37e" id="r_a6ce48b888db37f7f72c821d8f913a37e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a6ce48b888db37f7f72c821d8f913a37e">test_loss_deprecated</a> ()</td></tr>
<tr class="separator:a6ce48b888db37f7f72c821d8f913a37e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfa196b283a027ba4a2cb5e8cc45beee" id="r_abfa196b283a027ba4a2cb5e8cc45beee"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#abfa196b283a027ba4a2cb5e8cc45beee">test_loss_attribute_deprecation</a> (Estimator)</td></tr>
<tr class="separator:abfa196b283a027ba4a2cb5e8cc45beee"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a183bef0083233fbc81cb51e157001de1" id="r_a183bef0083233fbc81cb51e157001de1"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a183bef0083233fbc81cb51e157001de1">GRADIENT_BOOSTING_ESTIMATORS</a> = [<a class="el" href="classsklearn_1_1ensemble_1_1__gb_1_1_gradient_boosting_classifier.html">GradientBoostingClassifier</a>, <a class="el" href="classsklearn_1_1ensemble_1_1__gb_1_1_gradient_boosting_regressor.html">GradientBoostingRegressor</a>]</td></tr>
<tr class="separator:a183bef0083233fbc81cb51e157001de1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69bfead7a756e1294b41341d5a380167" id="r_a69bfead7a756e1294b41341d5a380167"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a69bfead7a756e1294b41341d5a380167">X</a> = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]</td></tr>
<tr class="separator:a69bfead7a756e1294b41341d5a380167"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3594f92a4f53c73864a897522f99325" id="r_af3594f92a4f53c73864a897522f99325"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#af3594f92a4f53c73864a897522f99325">y</a> = [-1, -1, -1, 1, 1, 1]</td></tr>
<tr class="separator:af3594f92a4f53c73864a897522f99325"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a389908af95528685268175f0a3b941eb" id="r_a389908af95528685268175f0a3b941eb"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a389908af95528685268175f0a3b941eb">T</a> = [[-1, -1], [2, 2], [3, 2]]</td></tr>
<tr class="separator:a389908af95528685268175f0a3b941eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae394850a3c96aebd8a6a380eb727d5d9" id="r_ae394850a3c96aebd8a6a380eb727d5d9"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ae394850a3c96aebd8a6a380eb727d5d9">true_result</a> = [-1, 1, 1]</td></tr>
<tr class="separator:ae394850a3c96aebd8a6a380eb727d5d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6e95944cb36089f6eb2013a34da5643" id="r_ae6e95944cb36089f6eb2013a34da5643"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#ae6e95944cb36089f6eb2013a34da5643">X_reg</a></td></tr>
<tr class="separator:ae6e95944cb36089f6eb2013a34da5643"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba64f90a225de7dc3f2391bf3df0e7cd" id="r_aba64f90a225de7dc3f2391bf3df0e7cd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#aba64f90a225de7dc3f2391bf3df0e7cd">y_reg</a> = scale(y_reg)</td></tr>
<tr class="separator:aba64f90a225de7dc3f2391bf3df0e7cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1517eb7e085d60e24f6f560e5e101ffb" id="r_a1517eb7e085d60e24f6f560e5e101ffb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a1517eb7e085d60e24f6f560e5e101ffb">n_samples</a></td></tr>
<tr class="separator:a1517eb7e085d60e24f6f560e5e101ffb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f8ea910f19c015eac315b17032562cb" id="r_a3f8ea910f19c015eac315b17032562cb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a3f8ea910f19c015eac315b17032562cb">n_features</a></td></tr>
<tr class="separator:a3f8ea910f19c015eac315b17032562cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a195dd4dc83913fb7ae47f75895e9f7e3" id="r_a195dd4dc83913fb7ae47f75895e9f7e3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a195dd4dc83913fb7ae47f75895e9f7e3">n_informative</a></td></tr>
<tr class="separator:a195dd4dc83913fb7ae47f75895e9f7e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf19561605f367813323ea496ba246f8" id="r_acf19561605f367813323ea496ba246f8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#acf19561605f367813323ea496ba246f8">noise</a></td></tr>
<tr class="separator:acf19561605f367813323ea496ba246f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acba7df5897200661784f2508df775039" id="r_acba7df5897200661784f2508df775039"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#acba7df5897200661784f2508df775039">random_state</a></td></tr>
<tr class="separator:acba7df5897200661784f2508df775039"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a930eb2323c5ed86328f5f751d4b18a0f" id="r_a930eb2323c5ed86328f5f751d4b18a0f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a930eb2323c5ed86328f5f751d4b18a0f">rng</a> = np.random.RandomState(0)</td></tr>
<tr class="separator:a930eb2323c5ed86328f5f751d4b18a0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b04784c4b3b41b93960642f4eda368b" id="r_a6b04784c4b3b41b93960642f4eda368b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a6b04784c4b3b41b93960642f4eda368b">iris</a> = datasets.load_iris()</td></tr>
<tr class="separator:a6b04784c4b3b41b93960642f4eda368b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa880220f15c372d7acdefc55f4e33aea" id="r_aa880220f15c372d7acdefc55f4e33aea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#aa880220f15c372d7acdefc55f4e33aea">perm</a> = rng.permutation(iris.target.size)</td></tr>
<tr class="separator:aa880220f15c372d7acdefc55f4e33aea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72590031a568f353a9152f78884786f0" id="r_a72590031a568f353a9152f78884786f0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#a72590031a568f353a9152f78884786f0">data</a></td></tr>
<tr class="separator:a72590031a568f353a9152f78884786f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef43d26423ab767524a149d6fc239510" id="r_aef43d26423ab767524a149d6fc239510"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting.html#aef43d26423ab767524a149d6fc239510">target</a></td></tr>
<tr class="separator:aef43d26423ab767524a149d6fc239510"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Testing for the gradient boosting module (sklearn.ensemble.gradient_boosting).
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a01cd1cd63005159831201beec1464901" name="a01cd1cd63005159831201beec1464901"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01cd1cd63005159831201beec1464901">&#9670;&#160;</a></span>_make_multiclass()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting._make_multiclass </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1218</span><span class="keyword">def </span>_make_multiclass():</div>
<div class="line"><span class="lineno"> 1219</span>    <span class="keywordflow">return</span> make_classification(n_classes=3, n_clusters_per_class=1)</div>
<div class="line"><span class="lineno"> 1220</span> </div>
<div class="line"><span class="lineno"> 1221</span> </div>
<div class="line"><span class="lineno"> 1222</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1223</span>    <span class="stringliteral">&quot;gb, dataset_maker, init_estimator&quot;</span>,</div>
<div class="line"><span class="lineno"> 1224</span>    [</div>
<div class="line"><span class="lineno"> 1225</span>        (GradientBoostingClassifier, make_classification, DummyClassifier),</div>
<div class="line"><span class="lineno"> 1226</span>        (GradientBoostingClassifier, _make_multiclass, DummyClassifier),</div>
<div class="line"><span class="lineno"> 1227</span>        (GradientBoostingRegressor, make_regression, DummyRegressor),</div>
<div class="line"><span class="lineno"> 1228</span>    ],</div>
<div class="line"><span class="lineno"> 1229</span>    ids=[<span class="stringliteral">&quot;binary classification&quot;</span>, <span class="stringliteral">&quot;multiclass classification&quot;</span>, <span class="stringliteral">&quot;regression&quot;</span>],</div>
<div class="line"><span class="lineno"> 1230</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="af9c412d7450aba8c3de5fc37e90fc2bc" name="af9c412d7450aba8c3de5fc37e90fc2bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af9c412d7450aba8c3de5fc37e90fc2bc">&#9670;&#160;</a></span>early_stopping_monitor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.early_stopping_monitor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>i</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>est</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>locals</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns True on the 10th iteration.</pre> <div class="fragment"><div class="line"><span class="lineno">  858</span><span class="keyword">def </span>early_stopping_monitor(i, est, locals):</div>
<div class="line"><span class="lineno">  859</span>    <span class="stringliteral">&quot;&quot;&quot;Returns True on the 10th iteration.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  860</span>    <span class="keywordflow">if</span> i == 9:</div>
<div class="line"><span class="lineno">  861</span>        <span class="keywordflow">return</span> <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  862</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  863</span>        <span class="keywordflow">return</span> <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  864</span> </div>
<div class="line"><span class="lineno">  865</span> </div>
<div class="line"><span class="lineno">  866</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a6594cc5ba79fa0c841035e115859894b" name="a6594cc5ba79fa0c841035e115859894b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6594cc5ba79fa0c841035e115859894b">&#9670;&#160;</a></span>test_check_inputs_predict_stages()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_check_inputs_predict_stages </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  276</span><span class="keyword">def </span>test_check_inputs_predict_stages():</div>
<div class="line"><span class="lineno">  277</span>    <span class="comment"># check that predict_stages through an error if the type of X is not</span></div>
<div class="line"><span class="lineno">  278</span>    <span class="comment"># supported</span></div>
<div class="line"><span class="lineno">  279</span>    x, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  280</span>    x_sparse_csc = csc_matrix(x)</div>
<div class="line"><span class="lineno">  281</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  282</span>    clf.fit(x, y)</div>
<div class="line"><span class="lineno">  283</span>    score = np.zeros((y.shape)).reshape(-1, 1)</div>
<div class="line"><span class="lineno">  284</span>    err_msg = <span class="stringliteral">&quot;When X is a sparse matrix, a CSR format is expected&quot;</span></div>
<div class="line"><span class="lineno">  285</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=err_msg):</div>
<div class="line"><span class="lineno">  286</span>        predict_stages(clf.estimators_, x_sparse_csc, clf.learning_rate, score)</div>
<div class="line"><span class="lineno">  287</span>    x_fortran = np.asfortranarray(x)</div>
<div class="line"><span class="lineno">  288</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;X should be C-ordered np.ndarray&quot;</span>):</div>
<div class="line"><span class="lineno">  289</span>        predict_stages(clf.estimators_, x_fortran, clf.learning_rate, score)</div>
<div class="line"><span class="lineno">  290</span> </div>
<div class="line"><span class="lineno">  291</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a47bc5b1086c71d9d27717c64294e7092" name="a47bc5b1086c71d9d27717c64294e7092"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47bc5b1086c71d9d27717c64294e7092">&#9670;&#160;</a></span>test_classification_synthetic()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_classification_synthetic </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   84</span><span class="keyword">def </span>test_classification_synthetic(loss, global_random_seed):</div>
<div class="line"><span class="lineno">   85</span>    <span class="comment"># Test GradientBoostingClassifier on synthetic dataset used by</span></div>
<div class="line"><span class="lineno">   86</span>    <span class="comment"># Hastie et al. in ESLII - Figure 10.9</span></div>
<div class="line"><span class="lineno">   87</span>    X, y = datasets.make_hastie_10_2(n_samples=12000, random_state=global_random_seed)</div>
<div class="line"><span class="lineno">   88</span> </div>
<div class="line"><span class="lineno">   89</span>    X_train, X_test = X[:2000], X[2000:]</div>
<div class="line"><span class="lineno">   90</span>    y_train, y_test = y[:2000], y[2000:]</div>
<div class="line"><span class="lineno">   91</span> </div>
<div class="line"><span class="lineno">   92</span>    <span class="comment"># Increasing the number of trees should decrease the test error</span></div>
<div class="line"><span class="lineno">   93</span>    common_params = {</div>
<div class="line"><span class="lineno">   94</span>        <span class="stringliteral">&quot;max_depth&quot;</span>: 1,</div>
<div class="line"><span class="lineno">   95</span>        <span class="stringliteral">&quot;learning_rate&quot;</span>: 1.0,</div>
<div class="line"><span class="lineno">   96</span>        <span class="stringliteral">&quot;loss&quot;</span>: loss,</div>
<div class="line"><span class="lineno">   97</span>        <span class="stringliteral">&quot;random_state&quot;</span>: global_random_seed,</div>
<div class="line"><span class="lineno">   98</span>    }</div>
<div class="line"><span class="lineno">   99</span>    gbrt_100_stumps = GradientBoostingClassifier(n_estimators=100, **common_params)</div>
<div class="line"><span class="lineno">  100</span>    gbrt_100_stumps.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  101</span> </div>
<div class="line"><span class="lineno">  102</span>    gbrt_200_stumps = GradientBoostingClassifier(n_estimators=200, **common_params)</div>
<div class="line"><span class="lineno">  103</span>    gbrt_200_stumps.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  104</span> </div>
<div class="line"><span class="lineno">  105</span>    <span class="keyword">assert</span> gbrt_100_stumps.score(X_test, y_test) &lt; gbrt_200_stumps.score(X_test, y_test)</div>
<div class="line"><span class="lineno">  106</span> </div>
<div class="line"><span class="lineno">  107</span>    <span class="comment"># Decision stumps are better suited for this dataset with a large number of</span></div>
<div class="line"><span class="lineno">  108</span>    <span class="comment"># estimators.</span></div>
<div class="line"><span class="lineno">  109</span>    common_params = {</div>
<div class="line"><span class="lineno">  110</span>        <span class="stringliteral">&quot;n_estimators&quot;</span>: 200,</div>
<div class="line"><span class="lineno">  111</span>        <span class="stringliteral">&quot;learning_rate&quot;</span>: 1.0,</div>
<div class="line"><span class="lineno">  112</span>        <span class="stringliteral">&quot;loss&quot;</span>: loss,</div>
<div class="line"><span class="lineno">  113</span>        <span class="stringliteral">&quot;random_state&quot;</span>: global_random_seed,</div>
<div class="line"><span class="lineno">  114</span>    }</div>
<div class="line"><span class="lineno">  115</span>    gbrt_stumps = GradientBoostingClassifier(max_depth=1, **common_params)</div>
<div class="line"><span class="lineno">  116</span>    gbrt_stumps.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  117</span> </div>
<div class="line"><span class="lineno">  118</span>    gbrt_10_nodes = GradientBoostingClassifier(max_leaf_nodes=10, **common_params)</div>
<div class="line"><span class="lineno">  119</span>    gbrt_10_nodes.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  120</span> </div>
<div class="line"><span class="lineno">  121</span>    <span class="keyword">assert</span> gbrt_stumps.score(X_test, y_test) &gt; gbrt_10_nodes.score(X_test, y_test)</div>
<div class="line"><span class="lineno">  122</span> </div>
<div class="line"><span class="lineno">  123</span> </div>
<div class="line"><span class="lineno">  124</span><span class="preprocessor">@pytest.mark.parametrize(&quot;loss&quot;, (&quot;squared_error&quot;, &quot;absolute_error&quot;, &quot;huber&quot;)</span>)</div>
<div class="line"><span class="lineno">  125</span><span class="preprocessor">@pytest.mark.parametrize(&quot;subsample&quot;, (1.0, 0.5)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ad38b6f407d52bae2e5e19cb6d4df99ae" name="ad38b6f407d52bae2e5e19cb6d4df99ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad38b6f407d52bae2e5e19cb6d4df99ae">&#9670;&#160;</a></span>test_classification_toy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_classification_toy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   63</span><span class="keyword">def </span>test_classification_toy(loss, global_random_seed):</div>
<div class="line"><span class="lineno">   64</span>    <span class="comment"># Check classification on a toy dataset.</span></div>
<div class="line"><span class="lineno">   65</span>    clf = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno">   66</span>        loss=loss, n_estimators=10, random_state=global_random_seed</div>
<div class="line"><span class="lineno">   67</span>    )</div>
<div class="line"><span class="lineno">   68</span> </div>
<div class="line"><span class="lineno">   69</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">   70</span>        clf.predict(T)</div>
<div class="line"><span class="lineno">   71</span> </div>
<div class="line"><span class="lineno">   72</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">   73</span>    assert_array_equal(clf.predict(T), true_result)</div>
<div class="line"><span class="lineno">   74</span>    <span class="keyword">assert</span> 10 == len(clf.estimators_)</div>
<div class="line"><span class="lineno">   75</span> </div>
<div class="line"><span class="lineno">   76</span>    log_loss_decrease = clf.train_score_[:-1] - clf.train_score_[1:]</div>
<div class="line"><span class="lineno">   77</span>    <span class="keyword">assert</span> np.any(log_loss_decrease &gt;= 0.0)</div>
<div class="line"><span class="lineno">   78</span> </div>
<div class="line"><span class="lineno">   79</span>    leaves = clf.apply(X)</div>
<div class="line"><span class="lineno">   80</span>    <span class="keyword">assert</span> leaves.shape == (6, 10, 1)</div>
<div class="line"><span class="lineno">   81</span> </div>
<div class="line"><span class="lineno">   82</span> </div>
<div class="line"><span class="lineno">   83</span><span class="preprocessor">@pytest.mark.parametrize(&quot;loss&quot;, (&quot;log_loss&quot;, &quot;exponential&quot;)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a283e96483dd8da92f4637f804c5f189d" name="a283e96483dd8da92f4637f804c5f189d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a283e96483dd8da92f4637f804c5f189d">&#9670;&#160;</a></span>test_complete_classification()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_complete_classification </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  903</span><span class="keyword">def </span>test_complete_classification():</div>
<div class="line"><span class="lineno">  904</span>    <span class="comment"># Test greedy trees with max_depth + 1 leafs.</span></div>
<div class="line"><span class="lineno">  905</span>    <span class="keyword">from</span> sklearn.tree._tree <span class="keyword">import</span> TREE_LEAF</div>
<div class="line"><span class="lineno">  906</span> </div>
<div class="line"><span class="lineno">  907</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  908</span>    k = 4</div>
<div class="line"><span class="lineno">  909</span> </div>
<div class="line"><span class="lineno">  910</span>    est = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno">  911</span>        n_estimators=20, max_depth=<span class="keywordtype">None</span>, random_state=1, max_leaf_nodes=k + 1</div>
<div class="line"><span class="lineno">  912</span>    )</div>
<div class="line"><span class="lineno">  913</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  914</span> </div>
<div class="line"><span class="lineno">  915</span>    tree = est.estimators_[0, 0].tree_</div>
<div class="line"><span class="lineno">  916</span>    <span class="keyword">assert</span> tree.max_depth == k</div>
<div class="line"><span class="lineno">  917</span>    <span class="keyword">assert</span> tree.children_left[tree.children_left == TREE_LEAF].shape[0] == k + 1</div>
<div class="line"><span class="lineno">  918</span> </div>
<div class="line"><span class="lineno">  919</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1d44a603888943b29e2470eb17bbc24e" name="a1d44a603888943b29e2470eb17bbc24e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d44a603888943b29e2470eb17bbc24e">&#9670;&#160;</a></span>test_complete_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_complete_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  920</span><span class="keyword">def </span>test_complete_regression():</div>
<div class="line"><span class="lineno">  921</span>    <span class="comment"># Test greedy trees with max_depth + 1 leafs.</span></div>
<div class="line"><span class="lineno">  922</span>    <span class="keyword">from</span> sklearn.tree._tree <span class="keyword">import</span> TREE_LEAF</div>
<div class="line"><span class="lineno">  923</span> </div>
<div class="line"><span class="lineno">  924</span>    k = 4</div>
<div class="line"><span class="lineno">  925</span> </div>
<div class="line"><span class="lineno">  926</span>    est = GradientBoostingRegressor(</div>
<div class="line"><span class="lineno">  927</span>        n_estimators=20, max_depth=<span class="keywordtype">None</span>, random_state=1, max_leaf_nodes=k + 1</div>
<div class="line"><span class="lineno">  928</span>    )</div>
<div class="line"><span class="lineno">  929</span>    est.fit(X_reg, y_reg)</div>
<div class="line"><span class="lineno">  930</span> </div>
<div class="line"><span class="lineno">  931</span>    tree = est.estimators_[-1, 0].tree_</div>
<div class="line"><span class="lineno">  932</span>    <span class="keyword">assert</span> tree.children_left[tree.children_left == TREE_LEAF].shape[0] == k + 1</div>
<div class="line"><span class="lineno">  933</span> </div>
<div class="line"><span class="lineno">  934</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae4d2fab91cc149444dfbc48fa747e73f" name="ae4d2fab91cc149444dfbc48fa747e73f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4d2fab91cc149444dfbc48fa747e73f">&#9670;&#160;</a></span>test_degenerate_targets()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_degenerate_targets </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  470</span><span class="keyword">def </span>test_degenerate_targets():</div>
<div class="line"><span class="lineno">  471</span>    <span class="comment"># Check if we can fit even though all targets are equal.</span></div>
<div class="line"><span class="lineno">  472</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  473</span> </div>
<div class="line"><span class="lineno">  474</span>    <span class="comment"># classifier should raise exception</span></div>
<div class="line"><span class="lineno">  475</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  476</span>        clf.fit(X, np.ones(len(X)))</div>
<div class="line"><span class="lineno">  477</span> </div>
<div class="line"><span class="lineno">  478</span>    clf = GradientBoostingRegressor(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  479</span>    clf.fit(X, np.ones(len(X)))</div>
<div class="line"><span class="lineno">  480</span>    clf.predict([rng.rand(2)])</div>
<div class="line"><span class="lineno">  481</span>    assert_array_equal(np.ones((1,), dtype=np.float64), clf.predict([rng.rand(2)]))</div>
<div class="line"><span class="lineno">  482</span> </div>
<div class="line"><span class="lineno">  483</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5fde70e78c85ed79831249ee398b55d4" name="a5fde70e78c85ed79831249ee398b55d4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5fde70e78c85ed79831249ee398b55d4">&#9670;&#160;</a></span>test_early_stopping_n_classes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_early_stopping_n_classes </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1283</span><span class="keyword">def </span>test_early_stopping_n_classes():</div>
<div class="line"><span class="lineno"> 1284</span>    <span class="comment"># when doing early stopping (_, , y_train, _ = train_test_split(X, y))</span></div>
<div class="line"><span class="lineno"> 1285</span>    <span class="comment"># there might be classes in y that are missing in y_train. As the init</span></div>
<div class="line"><span class="lineno"> 1286</span>    <span class="comment"># estimator will be trained on y_train, we need to raise an error if this</span></div>
<div class="line"><span class="lineno"> 1287</span>    <span class="comment"># happens.</span></div>
<div class="line"><span class="lineno"> 1288</span> </div>
<div class="line"><span class="lineno"> 1289</span>    X = [[1]] * 10</div>
<div class="line"><span class="lineno"> 1290</span>    y = [0, 0] + [1] * 8  <span class="comment"># only 2 negative class over 10 samples</span></div>
<div class="line"><span class="lineno"> 1291</span>    gb = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno"> 1292</span>        n_iter_no_change=5, random_state=0, validation_fraction=0.8</div>
<div class="line"><span class="lineno"> 1293</span>    )</div>
<div class="line"><span class="lineno"> 1294</span>    <span class="keyword">with</span> pytest.raises(</div>
<div class="line"><span class="lineno"> 1295</span>        ValueError, match=<span class="stringliteral">&quot;The training data after the early stopping split&quot;</span></div>
<div class="line"><span class="lineno"> 1296</span>    ):</div>
<div class="line"><span class="lineno"> 1297</span>        gb.fit(X, y)</div>
<div class="line"><span class="lineno"> 1298</span> </div>
<div class="line"><span class="lineno"> 1299</span>    <span class="comment"># No error if we let training data be big enough</span></div>
<div class="line"><span class="lineno"> 1300</span>    gb = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno"> 1301</span>        n_iter_no_change=5, random_state=0, validation_fraction=0.4</div>
<div class="line"><span class="lineno"> 1302</span>    )</div>
<div class="line"><span class="lineno"> 1303</span> </div>
<div class="line"><span class="lineno"> 1304</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a672896d729de60c5bc5f612bd1516606" name="a672896d729de60c5bc5f612bd1516606"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a672896d729de60c5bc5f612bd1516606">&#9670;&#160;</a></span>test_early_stopping_stratified()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_early_stopping_stratified </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1206</span><span class="keyword">def </span>test_early_stopping_stratified():</div>
<div class="line"><span class="lineno"> 1207</span>    <span class="comment"># Make sure data splitting for early stopping is stratified</span></div>
<div class="line"><span class="lineno"> 1208</span>    X = [[1, 2], [2, 3], [3, 4], [4, 5]]</div>
<div class="line"><span class="lineno"> 1209</span>    y = [0, 0, 0, 1]</div>
<div class="line"><span class="lineno"> 1210</span> </div>
<div class="line"><span class="lineno"> 1211</span>    gbc = GradientBoostingClassifier(n_iter_no_change=5)</div>
<div class="line"><span class="lineno"> 1212</span>    <span class="keyword">with</span> pytest.raises(</div>
<div class="line"><span class="lineno"> 1213</span>        ValueError, match=<span class="stringliteral">&quot;The least populated class in y has only 1 member&quot;</span></div>
<div class="line"><span class="lineno"> 1214</span>    ):</div>
<div class="line"><span class="lineno"> 1215</span>        gbc.fit(X, y)</div>
<div class="line"><span class="lineno"> 1216</span> </div>
<div class="line"><span class="lineno"> 1217</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab4f6d3b7ef62338e906bea5ef558851c" name="ab4f6d3b7ef62338e906bea5ef558851c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab4f6d3b7ef62338e906bea5ef558851c">&#9670;&#160;</a></span>test_feature_importance_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_feature_importance_regression </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fetch_california_housing_fxt</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test that Gini importance is calculated correctly.

This test follows the example from [1]_ (pg. 373).

.. [1] Friedman, J., Hastie, T., &amp; Tibshirani, R. (2001). The elements
   of statistical learning. New York: Springer series in statistics.
</pre> <div class="fragment"><div class="line"><span class="lineno">  314</span>):</div>
<div class="line"><span class="lineno">  315</span>    <span class="stringliteral">&quot;&quot;&quot;Test that Gini importance is calculated correctly.</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral">    This test follows the example from [1]_ (pg. 373).</span></div>
<div class="line"><span class="lineno">  318</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  319</span><span class="stringliteral">    .. [1] Friedman, J., Hastie, T., &amp; Tibshirani, R. (2001). The elements</span></div>
<div class="line"><span class="lineno">  320</span><span class="stringliteral">       of statistical learning. New York: Springer series in statistics.</span></div>
<div class="line"><span class="lineno">  321</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  322</span>    california = fetch_california_housing_fxt()</div>
<div class="line"><span class="lineno">  323</span>    X, y = california.data, california.target</div>
<div class="line"><span class="lineno">  324</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  325</span>        X, y, random_state=global_random_seed</div>
<div class="line"><span class="lineno">  326</span>    )</div>
<div class="line"><span class="lineno">  327</span> </div>
<div class="line"><span class="lineno">  328</span>    reg = GradientBoostingRegressor(</div>
<div class="line"><span class="lineno">  329</span>        loss=<span class="stringliteral">&quot;huber&quot;</span>,</div>
<div class="line"><span class="lineno">  330</span>        learning_rate=0.1,</div>
<div class="line"><span class="lineno">  331</span>        max_leaf_nodes=6,</div>
<div class="line"><span class="lineno">  332</span>        n_estimators=100,</div>
<div class="line"><span class="lineno">  333</span>        random_state=global_random_seed,</div>
<div class="line"><span class="lineno">  334</span>    )</div>
<div class="line"><span class="lineno">  335</span>    reg.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  336</span>    sorted_idx = np.argsort(reg.feature_importances_)[::-1]</div>
<div class="line"><span class="lineno">  337</span>    sorted_features = [california.feature_names[s] <span class="keywordflow">for</span> s <span class="keywordflow">in</span> sorted_idx]</div>
<div class="line"><span class="lineno">  338</span> </div>
<div class="line"><span class="lineno">  339</span>    <span class="comment"># The most important feature is the median income by far.</span></div>
<div class="line"><span class="lineno">  340</span>    <span class="keyword">assert</span> sorted_features[0] == <span class="stringliteral">&quot;MedInc&quot;</span></div>
<div class="line"><span class="lineno">  341</span> </div>
<div class="line"><span class="lineno">  342</span>    <span class="comment"># The three subsequent features are the following. Their relative ordering</span></div>
<div class="line"><span class="lineno">  343</span>    <span class="comment"># might change a bit depending on the randomness of the trees and the</span></div>
<div class="line"><span class="lineno">  344</span>    <span class="comment"># train / test split.</span></div>
<div class="line"><span class="lineno">  345</span>    <span class="keyword">assert</span> set(sorted_features[1:4]) == {<span class="stringliteral">&quot;Longitude&quot;</span>, <span class="stringliteral">&quot;AveOccup&quot;</span>, <span class="stringliteral">&quot;Latitude&quot;</span>}</div>
<div class="line"><span class="lineno">  346</span> </div>
<div class="line"><span class="lineno">  347</span> </div>
<div class="line"><span class="lineno">  348</span><span class="comment"># TODO(1.3): Remove warning filter</span></div>
<div class="line"><span class="lineno">  349</span><span class="preprocessor">@pytest.mark.filterwarnings(&quot;ignore:`max_features=&#39;auto&#39;` has been deprecated in 1.1&quot;)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aa799603821ab438366d5bc551fd18a77" name="aa799603821ab438366d5bc551fd18a77"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa799603821ab438366d5bc551fd18a77">&#9670;&#160;</a></span>test_feature_importances()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_feature_importances </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>GradientBoosting</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  236</span><span class="keyword">def </span>test_feature_importances(GradientBoosting, X, y):</div>
<div class="line"><span class="lineno">  237</span>    <span class="comment"># smoke test to check that the gradient boosting expose an attribute</span></div>
<div class="line"><span class="lineno">  238</span>    <span class="comment"># feature_importances_</span></div>
<div class="line"><span class="lineno">  239</span>    gbdt = GradientBoosting()</div>
<div class="line"><span class="lineno">  240</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> hasattr(gbdt, <span class="stringliteral">&quot;feature_importances_&quot;</span>)</div>
<div class="line"><span class="lineno">  241</span>    gbdt.fit(X, y)</div>
<div class="line"><span class="lineno">  242</span>    <span class="keyword">assert</span> hasattr(gbdt, <span class="stringliteral">&quot;feature_importances_&quot;</span>)</div>
<div class="line"><span class="lineno">  243</span> </div>
<div class="line"><span class="lineno">  244</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5de5e57dff757f47b733359c207829c4" name="a5de5e57dff757f47b733359c207829c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5de5e57dff757f47b733359c207829c4">&#9670;&#160;</a></span>test_float_class_labels()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_float_class_labels </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  520</span><span class="keyword">def </span>test_float_class_labels():</div>
<div class="line"><span class="lineno">  521</span>    <span class="comment"># Test with float class labels.</span></div>
<div class="line"><span class="lineno">  522</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  523</span> </div>
<div class="line"><span class="lineno">  524</span>    float_y = np.asarray(y, dtype=np.float32)</div>
<div class="line"><span class="lineno">  525</span> </div>
<div class="line"><span class="lineno">  526</span>    clf.fit(X, float_y)</div>
<div class="line"><span class="lineno">  527</span>    assert_array_equal(clf.predict(T), np.asarray(true_result, dtype=np.float32))</div>
<div class="line"><span class="lineno">  528</span>    <span class="keyword">assert</span> 100 == len(clf.estimators_)</div>
<div class="line"><span class="lineno">  529</span> </div>
<div class="line"><span class="lineno">  530</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af8090a414e3454ab43d4334bad2b53d1" name="af8090a414e3454ab43d4334bad2b53d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af8090a414e3454ab43d4334bad2b53d1">&#9670;&#160;</a></span>test_gbr_degenerate_feature_importances()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_gbr_degenerate_feature_importances </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1305</span><span class="keyword">def </span>test_gbr_degenerate_feature_importances():</div>
<div class="line"><span class="lineno"> 1306</span>    <span class="comment"># growing an ensemble of single node trees. See #13620</span></div>
<div class="line"><span class="lineno"> 1307</span>    X = np.zeros((10, 10))</div>
<div class="line"><span class="lineno"> 1308</span>    y = np.ones((10,))</div>
<div class="line"><span class="lineno"> 1309</span>    gbr = GradientBoostingRegressor().fit(X, y)</div>
<div class="line"><span class="lineno"> 1310</span>    assert_array_equal(gbr.feature_importances_, np.zeros(10, dtype=np.float64))</div>
<div class="line"><span class="lineno"> 1311</span> </div>
<div class="line"><span class="lineno"> 1312</span> </div>
<div class="line"><span class="lineno"> 1313</span><span class="comment"># TODO(1.3): Remove</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a65aec19fb3fb5c666e8ee46e9a912031" name="a65aec19fb3fb5c666e8ee46e9a912031"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65aec19fb3fb5c666e8ee46e9a912031">&#9670;&#160;</a></span>test_gradient_boosting_early_stopping()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_gradient_boosting_early_stopping </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>GradientBoostingEstimator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1109</span><span class="keyword">def </span>test_gradient_boosting_early_stopping(GradientBoostingEstimator):</div>
<div class="line"><span class="lineno"> 1110</span>    <span class="comment"># Check if early stopping works as expected, that is empirically check that the</span></div>
<div class="line"><span class="lineno"> 1111</span>    <span class="comment"># number of trained estimators is increasing when the tolerance decreases.</span></div>
<div class="line"><span class="lineno"> 1112</span> </div>
<div class="line"><span class="lineno"> 1113</span>    X, y = make_classification(n_samples=1000, random_state=0)</div>
<div class="line"><span class="lineno"> 1114</span>    n_estimators = 1000</div>
<div class="line"><span class="lineno"> 1115</span> </div>
<div class="line"><span class="lineno"> 1116</span>    gb_large_tol = GradientBoostingEstimator(</div>
<div class="line"><span class="lineno"> 1117</span>        n_estimators=n_estimators,</div>
<div class="line"><span class="lineno"> 1118</span>        n_iter_no_change=10,</div>
<div class="line"><span class="lineno"> 1119</span>        learning_rate=0.1,</div>
<div class="line"><span class="lineno"> 1120</span>        max_depth=3,</div>
<div class="line"><span class="lineno"> 1121</span>        random_state=42,</div>
<div class="line"><span class="lineno"> 1122</span>        tol=1e-1,</div>
<div class="line"><span class="lineno"> 1123</span>    )</div>
<div class="line"><span class="lineno"> 1124</span> </div>
<div class="line"><span class="lineno"> 1125</span>    gb_small_tol = GradientBoostingEstimator(</div>
<div class="line"><span class="lineno"> 1126</span>        n_estimators=n_estimators,</div>
<div class="line"><span class="lineno"> 1127</span>        n_iter_no_change=10,</div>
<div class="line"><span class="lineno"> 1128</span>        learning_rate=0.1,</div>
<div class="line"><span class="lineno"> 1129</span>        max_depth=3,</div>
<div class="line"><span class="lineno"> 1130</span>        random_state=42,</div>
<div class="line"><span class="lineno"> 1131</span>        tol=1e-3,</div>
<div class="line"><span class="lineno"> 1132</span>    )</div>
<div class="line"><span class="lineno"> 1133</span> </div>
<div class="line"><span class="lineno"> 1134</span>    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)</div>
<div class="line"><span class="lineno"> 1135</span>    gb_large_tol.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1136</span>    gb_small_tol.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1137</span> </div>
<div class="line"><span class="lineno"> 1138</span>    <span class="keyword">assert</span> gb_large_tol.n_estimators_ &lt; gb_small_tol.n_estimators_ &lt; n_estimators</div>
<div class="line"><span class="lineno"> 1139</span> </div>
<div class="line"><span class="lineno"> 1140</span>    <span class="keyword">assert</span> gb_large_tol.score(X_test, y_test) &gt; 0.7</div>
<div class="line"><span class="lineno"> 1141</span>    <span class="keyword">assert</span> gb_small_tol.score(X_test, y_test) &gt; 0.7</div>
<div class="line"><span class="lineno"> 1142</span> </div>
<div class="line"><span class="lineno"> 1143</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab83900ab5fe352bb477667575a628afc" name="ab83900ab5fe352bb477667575a628afc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab83900ab5fe352bb477667575a628afc">&#9670;&#160;</a></span>test_gradient_boosting_validation_fraction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_gradient_boosting_validation_fraction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1163</span><span class="keyword">def </span>test_gradient_boosting_validation_fraction():</div>
<div class="line"><span class="lineno"> 1164</span>    X, y = make_classification(n_samples=1000, random_state=0)</div>
<div class="line"><span class="lineno"> 1165</span> </div>
<div class="line"><span class="lineno"> 1166</span>    gbc = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno"> 1167</span>        n_estimators=100,</div>
<div class="line"><span class="lineno"> 1168</span>        n_iter_no_change=10,</div>
<div class="line"><span class="lineno"> 1169</span>        validation_fraction=0.1,</div>
<div class="line"><span class="lineno"> 1170</span>        learning_rate=0.1,</div>
<div class="line"><span class="lineno"> 1171</span>        max_depth=3,</div>
<div class="line"><span class="lineno"> 1172</span>        random_state=42,</div>
<div class="line"><span class="lineno"> 1173</span>    )</div>
<div class="line"><span class="lineno"> 1174</span>    gbc2 = clone(gbc).set_params(validation_fraction=0.3)</div>
<div class="line"><span class="lineno"> 1175</span>    gbc3 = clone(gbc).set_params(n_iter_no_change=20)</div>
<div class="line"><span class="lineno"> 1176</span> </div>
<div class="line"><span class="lineno"> 1177</span>    gbr = GradientBoostingRegressor(</div>
<div class="line"><span class="lineno"> 1178</span>        n_estimators=100,</div>
<div class="line"><span class="lineno"> 1179</span>        n_iter_no_change=10,</div>
<div class="line"><span class="lineno"> 1180</span>        learning_rate=0.1,</div>
<div class="line"><span class="lineno"> 1181</span>        max_depth=3,</div>
<div class="line"><span class="lineno"> 1182</span>        validation_fraction=0.1,</div>
<div class="line"><span class="lineno"> 1183</span>        random_state=42,</div>
<div class="line"><span class="lineno"> 1184</span>    )</div>
<div class="line"><span class="lineno"> 1185</span>    gbr2 = clone(gbr).set_params(validation_fraction=0.3)</div>
<div class="line"><span class="lineno"> 1186</span>    gbr3 = clone(gbr).set_params(n_iter_no_change=20)</div>
<div class="line"><span class="lineno"> 1187</span> </div>
<div class="line"><span class="lineno"> 1188</span>    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)</div>
<div class="line"><span class="lineno"> 1189</span>    <span class="comment"># Check if validation_fraction has an effect</span></div>
<div class="line"><span class="lineno"> 1190</span>    gbc.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1191</span>    gbc2.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1192</span>    <span class="keyword">assert</span> gbc.n_estimators_ != gbc2.n_estimators_</div>
<div class="line"><span class="lineno"> 1193</span> </div>
<div class="line"><span class="lineno"> 1194</span>    gbr.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1195</span>    gbr2.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1196</span>    <span class="keyword">assert</span> gbr.n_estimators_ != gbr2.n_estimators_</div>
<div class="line"><span class="lineno"> 1197</span> </div>
<div class="line"><span class="lineno"> 1198</span>    <span class="comment"># Check if n_estimators_ increase monotonically with n_iter_no_change</span></div>
<div class="line"><span class="lineno"> 1199</span>    <span class="comment"># Set validation</span></div>
<div class="line"><span class="lineno"> 1200</span>    gbc3.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1201</span>    gbr3.fit(X_train, y_train)</div>
<div class="line"><span class="lineno"> 1202</span>    <span class="keyword">assert</span> gbr.n_estimators_ &lt; gbr3.n_estimators_</div>
<div class="line"><span class="lineno"> 1203</span>    <span class="keyword">assert</span> gbc.n_estimators_ &lt; gbc3.n_estimators_</div>
<div class="line"><span class="lineno"> 1204</span> </div>
<div class="line"><span class="lineno"> 1205</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="acee6ac73ee39962e61feec9910620259" name="acee6ac73ee39962e61feec9910620259"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acee6ac73ee39962e61feec9910620259">&#9670;&#160;</a></span>test_gradient_boosting_with_init()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_gradient_boosting_with_init </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gb</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dataset_maker</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>init_estimator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1233</span>):</div>
<div class="line"><span class="lineno"> 1234</span>    <span class="comment"># Check that GradientBoostingRegressor works when init is a sklearn</span></div>
<div class="line"><span class="lineno"> 1235</span>    <span class="comment"># estimator.</span></div>
<div class="line"><span class="lineno"> 1236</span>    <span class="comment"># Check that an error is raised if trying to fit with sample weight but</span></div>
<div class="line"><span class="lineno"> 1237</span>    <span class="comment"># initial estimator does not support sample weight</span></div>
<div class="line"><span class="lineno"> 1238</span> </div>
<div class="line"><span class="lineno"> 1239</span>    X, y = dataset_maker()</div>
<div class="line"><span class="lineno"> 1240</span>    sample_weight = np.random.RandomState(global_random_seed).rand(100)</div>
<div class="line"><span class="lineno"> 1241</span> </div>
<div class="line"><span class="lineno"> 1242</span>    <span class="comment"># init supports sample weights</span></div>
<div class="line"><span class="lineno"> 1243</span>    init_est = init_estimator()</div>
<div class="line"><span class="lineno"> 1244</span>    gb(init=init_est).fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1245</span> </div>
<div class="line"><span class="lineno"> 1246</span>    <span class="comment"># init does not support sample weights</span></div>
<div class="line"><span class="lineno"> 1247</span>    init_est = NoSampleWeightWrapper(init_estimator())</div>
<div class="line"><span class="lineno"> 1248</span>    gb(init=init_est).fit(X, y)  <span class="comment"># ok no sample weights</span></div>
<div class="line"><span class="lineno"> 1249</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;estimator.*does not support sample weights&quot;</span>):</div>
<div class="line"><span class="lineno"> 1250</span>        gb(init=init_est).fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1251</span> </div>
<div class="line"><span class="lineno"> 1252</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a37ab325c20aa640875f60064b33807e6" name="a37ab325c20aa640875f60064b33807e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a37ab325c20aa640875f60064b33807e6">&#9670;&#160;</a></span>test_gradient_boosting_with_init_pipeline()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_gradient_boosting_with_init_pipeline </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1253</span><span class="keyword">def </span>test_gradient_boosting_with_init_pipeline():</div>
<div class="line"><span class="lineno"> 1254</span>    <span class="comment"># Check that the init estimator can be a pipeline (see issue #13466)</span></div>
<div class="line"><span class="lineno"> 1255</span> </div>
<div class="line"><span class="lineno"> 1256</span>    X, y = make_regression(random_state=0)</div>
<div class="line"><span class="lineno"> 1257</span>    init = make_pipeline(LinearRegression())</div>
<div class="line"><span class="lineno"> 1258</span>    gb = GradientBoostingRegressor(init=init)</div>
<div class="line"><span class="lineno"> 1259</span>    gb.fit(X, y)  <span class="comment"># pipeline without sample_weight works fine</span></div>
<div class="line"><span class="lineno"> 1260</span> </div>
<div class="line"><span class="lineno"> 1261</span>    <span class="keyword">with</span> pytest.raises(</div>
<div class="line"><span class="lineno"> 1262</span>        ValueError,</div>
<div class="line"><span class="lineno"> 1263</span>        match=<span class="stringliteral">&quot;The initial estimator Pipeline does not support sample weights&quot;</span>,</div>
<div class="line"><span class="lineno"> 1264</span>    ):</div>
<div class="line"><span class="lineno"> 1265</span>        gb.fit(X, y, sample_weight=np.ones(X.shape[0]))</div>
<div class="line"><span class="lineno"> 1266</span> </div>
<div class="line"><span class="lineno"> 1267</span>    <span class="comment"># Passing sample_weight to a pipeline raises a ValueError. This test makes</span></div>
<div class="line"><span class="lineno"> 1268</span>    <span class="comment"># sure we make the distinction between ValueError raised by a pipeline that</span></div>
<div class="line"><span class="lineno"> 1269</span>    <span class="comment"># was passed sample_weight, and a InvalidParameterError raised by a regular</span></div>
<div class="line"><span class="lineno"> 1270</span>    <span class="comment"># estimator whose input checking failed.</span></div>
<div class="line"><span class="lineno"> 1271</span>    invalid_nu = 1.5</div>
<div class="line"><span class="lineno"> 1272</span>    err_msg = (</div>
<div class="line"><span class="lineno"> 1273</span>        <span class="stringliteral">&quot;The &#39;nu&#39; parameter of NuSVR must be a float in the&quot;</span></div>
<div class="line"><span class="lineno"> 1274</span>        f<span class="stringliteral">&quot; range (0.0, 1.0]. Got {invalid_nu} instead.&quot;</span></div>
<div class="line"><span class="lineno"> 1275</span>    )</div>
<div class="line"><span class="lineno"> 1276</span>    <span class="keyword">with</span> pytest.raises(InvalidParameterError, match=re.escape(err_msg)):</div>
<div class="line"><span class="lineno"> 1277</span>        <span class="comment"># Note that NuSVR properly supports sample_weight</span></div>
<div class="line"><span class="lineno"> 1278</span>        init = NuSVR(gamma=<span class="stringliteral">&quot;auto&quot;</span>, nu=invalid_nu)</div>
<div class="line"><span class="lineno"> 1279</span>        gb = GradientBoostingRegressor(init=init)</div>
<div class="line"><span class="lineno"> 1280</span>        gb.fit(X, y, sample_weight=np.ones(X.shape[0]))</div>
<div class="line"><span class="lineno"> 1281</span> </div>
<div class="line"><span class="lineno"> 1282</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab8e3a1785d5bbc3d4e872219a6919dde" name="ab8e3a1785d5bbc3d4e872219a6919dde"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab8e3a1785d5bbc3d4e872219a6919dde">&#9670;&#160;</a></span>test_gradient_boosting_without_early_stopping()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_gradient_boosting_without_early_stopping </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1144</span><span class="keyword">def </span>test_gradient_boosting_without_early_stopping():</div>
<div class="line"><span class="lineno"> 1145</span>    <span class="comment"># When early stopping is not used, the number of trained estimators</span></div>
<div class="line"><span class="lineno"> 1146</span>    <span class="comment"># must be the one specified.</span></div>
<div class="line"><span class="lineno"> 1147</span>    X, y = make_classification(n_samples=1000, random_state=0)</div>
<div class="line"><span class="lineno"> 1148</span> </div>
<div class="line"><span class="lineno"> 1149</span>    gbc = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno"> 1150</span>        n_estimators=50, learning_rate=0.1, max_depth=3, random_state=42</div>
<div class="line"><span class="lineno"> 1151</span>    )</div>
<div class="line"><span class="lineno"> 1152</span>    gbc.fit(X, y)</div>
<div class="line"><span class="lineno"> 1153</span>    gbr = GradientBoostingRegressor(</div>
<div class="line"><span class="lineno"> 1154</span>        n_estimators=30, learning_rate=0.1, max_depth=3, random_state=42</div>
<div class="line"><span class="lineno"> 1155</span>    )</div>
<div class="line"><span class="lineno"> 1156</span>    gbr.fit(X, y)</div>
<div class="line"><span class="lineno"> 1157</span> </div>
<div class="line"><span class="lineno"> 1158</span>    <span class="comment"># The number of trained estimators must be the one specified.</span></div>
<div class="line"><span class="lineno"> 1159</span>    <span class="keyword">assert</span> gbc.n_estimators_ == 50</div>
<div class="line"><span class="lineno"> 1160</span>    <span class="keyword">assert</span> gbr.n_estimators_ == 30</div>
<div class="line"><span class="lineno"> 1161</span> </div>
<div class="line"><span class="lineno"> 1162</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aef1ff9ace23f69d7586a81349b3dda8d" name="aef1ff9ace23f69d7586a81349b3dda8d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef1ff9ace23f69d7586a81349b3dda8d">&#9670;&#160;</a></span>test_iris()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_iris </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>subsample</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  167</span><span class="keyword">def </span>test_iris(subsample, sample_weight, global_random_seed):</div>
<div class="line"><span class="lineno">  168</span>    <span class="keywordflow">if</span> sample_weight == 1:</div>
<div class="line"><span class="lineno">  169</span>        sample_weight = np.ones(len(iris.target))</div>
<div class="line"><span class="lineno">  170</span>    <span class="comment"># Check consistency on dataset iris.</span></div>
<div class="line"><span class="lineno">  171</span>    clf = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno">  172</span>        n_estimators=100,</div>
<div class="line"><span class="lineno">  173</span>        loss=<span class="stringliteral">&quot;log_loss&quot;</span>,</div>
<div class="line"><span class="lineno">  174</span>        random_state=global_random_seed,</div>
<div class="line"><span class="lineno">  175</span>        subsample=subsample,</div>
<div class="line"><span class="lineno">  176</span>    )</div>
<div class="line"><span class="lineno">  177</span>    clf.fit(iris.data, iris.target, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  178</span>    score = clf.score(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  179</span>    <span class="keyword">assert</span> score &gt; 0.9</div>
<div class="line"><span class="lineno">  180</span> </div>
<div class="line"><span class="lineno">  181</span>    leaves = clf.apply(iris.data)</div>
<div class="line"><span class="lineno">  182</span>    <span class="keyword">assert</span> leaves.shape == (150, 100, 3)</div>
<div class="line"><span class="lineno">  183</span> </div>
<div class="line"><span class="lineno">  184</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abfa196b283a027ba4a2cb5e8cc45beee" name="abfa196b283a027ba4a2cb5e8cc45beee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abfa196b283a027ba4a2cb5e8cc45beee">&#9670;&#160;</a></span>test_loss_attribute_deprecation()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_loss_attribute_deprecation </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Estimator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1329</span><span class="keyword">def </span>test_loss_attribute_deprecation(Estimator):</div>
<div class="line"><span class="lineno"> 1330</span>    <span class="comment"># Check that we raise the proper deprecation warning if accessing</span></div>
<div class="line"><span class="lineno"> 1331</span>    <span class="comment"># `loss_`.</span></div>
<div class="line"><span class="lineno"> 1332</span>    X = np.array([[1, 2], [3, 4]])</div>
<div class="line"><span class="lineno"> 1333</span>    y = np.array([1, 0])</div>
<div class="line"><span class="lineno"> 1334</span>    est = Estimator().fit(X, y)</div>
<div class="line"><span class="lineno"> 1335</span> </div>
<div class="line"><span class="lineno"> 1336</span>    <span class="keyword">with</span> pytest.warns(FutureWarning, match=<span class="stringliteral">&quot;`loss_` was deprecated&quot;</span>):</div>
<div class="line"><span class="lineno"> 1337</span>        est.loss_</div>
</div><!-- fragment -->
</div>
</div>
<a id="a6ce48b888db37f7f72c821d8f913a37e" name="a6ce48b888db37f7f72c821d8f913a37e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ce48b888db37f7f72c821d8f913a37e">&#9670;&#160;</a></span>test_loss_deprecated()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_loss_deprecated </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1314</span><span class="keyword">def </span>test_loss_deprecated():</div>
<div class="line"><span class="lineno"> 1315</span>    est1 = GradientBoostingClassifier(loss=<span class="stringliteral">&quot;deviance&quot;</span>, random_state=0)</div>
<div class="line"><span class="lineno"> 1316</span> </div>
<div class="line"><span class="lineno"> 1317</span>    <span class="keyword">with</span> pytest.warns(FutureWarning, match=<span class="stringliteral">r&quot;The loss.* &#39;deviance&#39; was deprecated&quot;</span>):</div>
<div class="line"><span class="lineno"> 1318</span>        est1.fit(X, y)</div>
<div class="line"><span class="lineno"> 1319</span> </div>
<div class="line"><span class="lineno"> 1320</span>    est2 = GradientBoostingClassifier(loss=<span class="stringliteral">&quot;log_loss&quot;</span>, random_state=0)</div>
<div class="line"><span class="lineno"> 1321</span>    est2.fit(X, y)</div>
<div class="line"><span class="lineno"> 1322</span>    assert_allclose(est1.predict(X), est2.predict(X))</div>
<div class="line"><span class="lineno"> 1323</span> </div>
<div class="line"><span class="lineno"> 1324</span> </div>
<div class="line"><span class="lineno"> 1325</span><span class="comment"># TODO(1.3): remove</span></div>
<div class="line"><span class="lineno"> 1326</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1327</span>    <span class="stringliteral">&quot;Estimator&quot;</span>, [GradientBoostingClassifier, GradientBoostingRegressor]</div>
<div class="line"><span class="lineno"> 1328</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae1efe70ea2972d636d1b30a631d203b5" name="ae1efe70ea2972d636d1b30a631d203b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1efe70ea2972d636d1b30a631d203b5">&#9670;&#160;</a></span>test_max_feature_auto()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_max_feature_auto </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  350</span><span class="keyword">def </span>test_max_feature_auto():</div>
<div class="line"><span class="lineno">  351</span>    <span class="comment"># Test if max features is set properly for floats and str.</span></div>
<div class="line"><span class="lineno">  352</span>    X, y = datasets.make_hastie_10_2(n_samples=12000, random_state=1)</div>
<div class="line"><span class="lineno">  353</span>    _, n_features = X.shape</div>
<div class="line"><span class="lineno">  354</span> </div>
<div class="line"><span class="lineno">  355</span>    X_train = X[:2000]</div>
<div class="line"><span class="lineno">  356</span>    y_train = y[:2000]</div>
<div class="line"><span class="lineno">  357</span> </div>
<div class="line"><span class="lineno">  358</span>    gbrt = GradientBoostingClassifier(n_estimators=1, max_features=<span class="stringliteral">&quot;auto&quot;</span>)</div>
<div class="line"><span class="lineno">  359</span>    gbrt.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  360</span>    <span class="keyword">assert</span> gbrt.max_features_ == int(np.sqrt(n_features))</div>
<div class="line"><span class="lineno">  361</span> </div>
<div class="line"><span class="lineno">  362</span>    gbrt = GradientBoostingRegressor(n_estimators=1, max_features=<span class="stringliteral">&quot;auto&quot;</span>)</div>
<div class="line"><span class="lineno">  363</span>    gbrt.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  364</span>    <span class="keyword">assert</span> gbrt.max_features_ == n_features</div>
<div class="line"><span class="lineno">  365</span> </div>
<div class="line"><span class="lineno">  366</span>    gbrt = GradientBoostingRegressor(n_estimators=1, max_features=0.3)</div>
<div class="line"><span class="lineno">  367</span>    gbrt.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  368</span>    <span class="keyword">assert</span> gbrt.max_features_ == int(n_features * 0.3)</div>
<div class="line"><span class="lineno">  369</span> </div>
<div class="line"><span class="lineno">  370</span>    gbrt = GradientBoostingRegressor(n_estimators=1, max_features=<span class="stringliteral">&quot;sqrt&quot;</span>)</div>
<div class="line"><span class="lineno">  371</span>    gbrt.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  372</span>    <span class="keyword">assert</span> gbrt.max_features_ == int(np.sqrt(n_features))</div>
<div class="line"><span class="lineno">  373</span> </div>
<div class="line"><span class="lineno">  374</span>    gbrt = GradientBoostingRegressor(n_estimators=1, max_features=<span class="stringliteral">&quot;log2&quot;</span>)</div>
<div class="line"><span class="lineno">  375</span>    gbrt.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  376</span>    <span class="keyword">assert</span> gbrt.max_features_ == int(np.log2(n_features))</div>
<div class="line"><span class="lineno">  377</span> </div>
<div class="line"><span class="lineno">  378</span>    gbrt = GradientBoostingRegressor(n_estimators=1, max_features=0.01 / X.shape[1])</div>
<div class="line"><span class="lineno">  379</span>    gbrt.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  380</span>    <span class="keyword">assert</span> gbrt.max_features_ == 1</div>
<div class="line"><span class="lineno">  381</span> </div>
<div class="line"><span class="lineno">  382</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3f48602bdf05afe5ce89e088129063aa" name="a3f48602bdf05afe5ce89e088129063aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3f48602bdf05afe5ce89e088129063aa">&#9670;&#160;</a></span>test_max_feature_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_max_feature_regression </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  292</span><span class="keyword">def </span>test_max_feature_regression(global_random_seed):</div>
<div class="line"><span class="lineno">  293</span>    <span class="comment"># Test to make sure random state is set properly.</span></div>
<div class="line"><span class="lineno">  294</span>    X, y = datasets.make_hastie_10_2(n_samples=12000, random_state=global_random_seed)</div>
<div class="line"><span class="lineno">  295</span> </div>
<div class="line"><span class="lineno">  296</span>    X_train, X_test = X[:2000], X[2000:]</div>
<div class="line"><span class="lineno">  297</span>    y_train, y_test = y[:2000], y[2000:]</div>
<div class="line"><span class="lineno">  298</span> </div>
<div class="line"><span class="lineno">  299</span>    gbrt = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno">  300</span>        n_estimators=100,</div>
<div class="line"><span class="lineno">  301</span>        min_samples_split=5,</div>
<div class="line"><span class="lineno">  302</span>        max_depth=2,</div>
<div class="line"><span class="lineno">  303</span>        learning_rate=0.1,</div>
<div class="line"><span class="lineno">  304</span>        max_features=2,</div>
<div class="line"><span class="lineno">  305</span>        random_state=global_random_seed,</div>
<div class="line"><span class="lineno">  306</span>    )</div>
<div class="line"><span class="lineno">  307</span>    gbrt.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  308</span>    log_loss = gbrt._loss(y_test, gbrt.decision_function(X_test))</div>
<div class="line"><span class="lineno">  309</span>    <span class="keyword">assert</span> log_loss &lt; 0.5, <span class="stringliteral">&quot;GB failed with deviance %.4f&quot;</span> % log_loss</div>
<div class="line"><span class="lineno">  310</span> </div>
<div class="line"><span class="lineno">  311</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afe7cf6361273e0d9c33fc2713cb4418b" name="afe7cf6361273e0d9c33fc2713cb4418b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe7cf6361273e0d9c33fc2713cb4418b">&#9670;&#160;</a></span>test_max_leaf_nodes_max_depth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_max_leaf_nodes_max_depth </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>GBEstimator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  978</span><span class="keyword">def </span>test_max_leaf_nodes_max_depth(GBEstimator):</div>
<div class="line"><span class="lineno">  979</span>    <span class="comment"># Test precedence of max_leaf_nodes over max_depth.</span></div>
<div class="line"><span class="lineno">  980</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  981</span> </div>
<div class="line"><span class="lineno">  982</span>    k = 4</div>
<div class="line"><span class="lineno">  983</span> </div>
<div class="line"><span class="lineno">  984</span>    est = GBEstimator(max_depth=1, max_leaf_nodes=k).fit(X, y)</div>
<div class="line"><span class="lineno">  985</span>    tree = est.estimators_[0, 0].tree_</div>
<div class="line"><span class="lineno">  986</span>    <span class="keyword">assert</span> tree.max_depth == 1</div>
<div class="line"><span class="lineno">  987</span> </div>
<div class="line"><span class="lineno">  988</span>    est = GBEstimator(max_depth=1).fit(X, y)</div>
<div class="line"><span class="lineno">  989</span>    tree = est.estimators_[0, 0].tree_</div>
<div class="line"><span class="lineno">  990</span>    <span class="keyword">assert</span> tree.max_depth == 1</div>
<div class="line"><span class="lineno">  991</span> </div>
<div class="line"><span class="lineno">  992</span> </div>
<div class="line"><span class="lineno">  993</span><span class="preprocessor">@pytest.mark.parametrize(&quot;GBEstimator&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a6ef631db09225724d3d83337bdfd98d9" name="a6ef631db09225724d3d83337bdfd98d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ef631db09225724d3d83337bdfd98d9">&#9670;&#160;</a></span>test_mem_layout()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_mem_layout </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  552</span><span class="keyword">def </span>test_mem_layout():</div>
<div class="line"><span class="lineno">  553</span>    <span class="comment"># Test with different memory layouts of X and y</span></div>
<div class="line"><span class="lineno">  554</span>    X_ = np.asfortranarray(X)</div>
<div class="line"><span class="lineno">  555</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  556</span>    clf.fit(X_, y)</div>
<div class="line"><span class="lineno">  557</span>    assert_array_equal(clf.predict(T), true_result)</div>
<div class="line"><span class="lineno">  558</span>    <span class="keyword">assert</span> 100 == len(clf.estimators_)</div>
<div class="line"><span class="lineno">  559</span> </div>
<div class="line"><span class="lineno">  560</span>    X_ = np.ascontiguousarray(X)</div>
<div class="line"><span class="lineno">  561</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  562</span>    clf.fit(X_, y)</div>
<div class="line"><span class="lineno">  563</span>    assert_array_equal(clf.predict(T), true_result)</div>
<div class="line"><span class="lineno">  564</span>    <span class="keyword">assert</span> 100 == len(clf.estimators_)</div>
<div class="line"><span class="lineno">  565</span> </div>
<div class="line"><span class="lineno">  566</span>    y_ = np.asarray(y, dtype=np.int32)</div>
<div class="line"><span class="lineno">  567</span>    y_ = np.ascontiguousarray(y_)</div>
<div class="line"><span class="lineno">  568</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  569</span>    clf.fit(X, y_)</div>
<div class="line"><span class="lineno">  570</span>    assert_array_equal(clf.predict(T), true_result)</div>
<div class="line"><span class="lineno">  571</span>    <span class="keyword">assert</span> 100 == len(clf.estimators_)</div>
<div class="line"><span class="lineno">  572</span> </div>
<div class="line"><span class="lineno">  573</span>    y_ = np.asarray(y, dtype=np.int32)</div>
<div class="line"><span class="lineno">  574</span>    y_ = np.asfortranarray(y_)</div>
<div class="line"><span class="lineno">  575</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  576</span>    clf.fit(X, y_)</div>
<div class="line"><span class="lineno">  577</span>    assert_array_equal(clf.predict(T), true_result)</div>
<div class="line"><span class="lineno">  578</span>    <span class="keyword">assert</span> 100 == len(clf.estimators_)</div>
<div class="line"><span class="lineno">  579</span> </div>
<div class="line"><span class="lineno">  580</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a127f2ead859bfef4aff1e03fb73f9852" name="a127f2ead859bfef4aff1e03fb73f9852"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a127f2ead859bfef4aff1e03fb73f9852">&#9670;&#160;</a></span>test_min_impurity_decrease()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_min_impurity_decrease </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>GBEstimator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  994</span><span class="keyword">def </span>test_min_impurity_decrease(GBEstimator):</div>
<div class="line"><span class="lineno">  995</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  996</span> </div>
<div class="line"><span class="lineno">  997</span>    est = GBEstimator(min_impurity_decrease=0.1)</div>
<div class="line"><span class="lineno">  998</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  999</span>    <span class="keywordflow">for</span> tree <span class="keywordflow">in</span> est.estimators_.flat:</div>
<div class="line"><span class="lineno"> 1000</span>        <span class="comment"># Simply check if the parameter is passed on correctly. Tree tests</span></div>
<div class="line"><span class="lineno"> 1001</span>        <span class="comment"># will suffice for the actual working of this param</span></div>
<div class="line"><span class="lineno"> 1002</span>        <span class="keyword">assert</span> tree.min_impurity_decrease == 0.1</div>
<div class="line"><span class="lineno"> 1003</span> </div>
<div class="line"><span class="lineno"> 1004</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afd233d2512db9c628ff349cbe8ad9aff" name="afd233d2512db9c628ff349cbe8ad9aff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd233d2512db9c628ff349cbe8ad9aff">&#9670;&#160;</a></span>test_monitor_early_stopping()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_monitor_early_stopping </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  867</span><span class="keyword">def </span>test_monitor_early_stopping(Cls):</div>
<div class="line"><span class="lineno">  868</span>    <span class="comment"># Test if monitor return value works.</span></div>
<div class="line"><span class="lineno">  869</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  870</span> </div>
<div class="line"><span class="lineno">  871</span>    est = Cls(n_estimators=20, max_depth=1, random_state=1, subsample=0.5)</div>
<div class="line"><span class="lineno">  872</span>    est.fit(X, y, monitor=early_stopping_monitor)</div>
<div class="line"><span class="lineno">  873</span>    <span class="keyword">assert</span> est.n_estimators == 20  <span class="comment"># this is not altered</span></div>
<div class="line"><span class="lineno">  874</span>    <span class="keyword">assert</span> est.estimators_.shape[0] == 10</div>
<div class="line"><span class="lineno">  875</span>    <span class="keyword">assert</span> est.train_score_.shape[0] == 10</div>
<div class="line"><span class="lineno">  876</span>    <span class="keyword">assert</span> est.oob_improvement_.shape[0] == 10</div>
<div class="line"><span class="lineno">  877</span> </div>
<div class="line"><span class="lineno">  878</span>    <span class="comment"># try refit</span></div>
<div class="line"><span class="lineno">  879</span>    est.set_params(n_estimators=30)</div>
<div class="line"><span class="lineno">  880</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  881</span>    <span class="keyword">assert</span> est.n_estimators == 30</div>
<div class="line"><span class="lineno">  882</span>    <span class="keyword">assert</span> est.estimators_.shape[0] == 30</div>
<div class="line"><span class="lineno">  883</span>    <span class="keyword">assert</span> est.train_score_.shape[0] == 30</div>
<div class="line"><span class="lineno">  884</span> </div>
<div class="line"><span class="lineno">  885</span>    est = Cls(</div>
<div class="line"><span class="lineno">  886</span>        n_estimators=20, max_depth=1, random_state=1, subsample=0.5, warm_start=<span class="keyword">True</span></div>
<div class="line"><span class="lineno">  887</span>    )</div>
<div class="line"><span class="lineno">  888</span>    est.fit(X, y, monitor=early_stopping_monitor)</div>
<div class="line"><span class="lineno">  889</span>    <span class="keyword">assert</span> est.n_estimators == 20</div>
<div class="line"><span class="lineno">  890</span>    <span class="keyword">assert</span> est.estimators_.shape[0] == 10</div>
<div class="line"><span class="lineno">  891</span>    <span class="keyword">assert</span> est.train_score_.shape[0] == 10</div>
<div class="line"><span class="lineno">  892</span>    <span class="keyword">assert</span> est.oob_improvement_.shape[0] == 10</div>
<div class="line"><span class="lineno">  893</span> </div>
<div class="line"><span class="lineno">  894</span>    <span class="comment"># try refit</span></div>
<div class="line"><span class="lineno">  895</span>    est.set_params(n_estimators=30, warm_start=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  896</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  897</span>    <span class="keyword">assert</span> est.n_estimators == 30</div>
<div class="line"><span class="lineno">  898</span>    <span class="keyword">assert</span> est.train_score_.shape[0] == 30</div>
<div class="line"><span class="lineno">  899</span>    <span class="keyword">assert</span> est.estimators_.shape[0] == 30</div>
<div class="line"><span class="lineno">  900</span>    <span class="keyword">assert</span> est.oob_improvement_.shape[0] == 30</div>
<div class="line"><span class="lineno">  901</span> </div>
<div class="line"><span class="lineno">  902</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a258919d04df4427dec9484478a6f9955" name="a258919d04df4427dec9484478a6f9955"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a258919d04df4427dec9484478a6f9955">&#9670;&#160;</a></span>test_more_verbose_output()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_more_verbose_output </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  648</span><span class="keyword">def </span>test_more_verbose_output():</div>
<div class="line"><span class="lineno">  649</span>    <span class="comment"># Check verbose=2 does not cause error.</span></div>
<div class="line"><span class="lineno">  650</span>    <span class="keyword">from</span> io <span class="keyword">import</span> StringIO</div>
<div class="line"><span class="lineno">  651</span>    <span class="keyword">import</span> sys</div>
<div class="line"><span class="lineno">  652</span> </div>
<div class="line"><span class="lineno">  653</span>    old_stdout = sys.stdout</div>
<div class="line"><span class="lineno">  654</span>    sys.stdout = StringIO()</div>
<div class="line"><span class="lineno">  655</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1, verbose=2)</div>
<div class="line"><span class="lineno">  656</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  657</span>    verbose_output = sys.stdout</div>
<div class="line"><span class="lineno">  658</span>    sys.stdout = old_stdout</div>
<div class="line"><span class="lineno">  659</span> </div>
<div class="line"><span class="lineno">  660</span>    <span class="comment"># check output</span></div>
<div class="line"><span class="lineno">  661</span>    verbose_output.seek(0)</div>
<div class="line"><span class="lineno">  662</span>    header = verbose_output.readline().rstrip()</div>
<div class="line"><span class="lineno">  663</span>    <span class="comment"># no OOB</span></div>
<div class="line"><span class="lineno">  664</span>    true_header = <span class="stringliteral">&quot; &quot;</span>.join([<span class="stringliteral">&quot;%10s&quot;</span>] + [<span class="stringliteral">&quot;%16s&quot;</span>] * 2) % (</div>
<div class="line"><span class="lineno">  665</span>        <span class="stringliteral">&quot;Iter&quot;</span>,</div>
<div class="line"><span class="lineno">  666</span>        <span class="stringliteral">&quot;Train Loss&quot;</span>,</div>
<div class="line"><span class="lineno">  667</span>        <span class="stringliteral">&quot;Remaining Time&quot;</span>,</div>
<div class="line"><span class="lineno">  668</span>    )</div>
<div class="line"><span class="lineno">  669</span>    <span class="keyword">assert</span> true_header == header</div>
<div class="line"><span class="lineno">  670</span> </div>
<div class="line"><span class="lineno">  671</span>    n_lines = sum(1 <span class="keywordflow">for</span> l <span class="keywordflow">in</span> verbose_output.readlines())</div>
<div class="line"><span class="lineno">  672</span>    <span class="comment"># 100 lines for n_estimators==100</span></div>
<div class="line"><span class="lineno">  673</span>    <span class="keyword">assert</span> 100 == n_lines</div>
<div class="line"><span class="lineno">  674</span> </div>
<div class="line"><span class="lineno">  675</span> </div>
<div class="line"><span class="lineno">  676</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="abe54dfaf3be443c3ef8a37de8266cdce" name="abe54dfaf3be443c3ef8a37de8266cdce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe54dfaf3be443c3ef8a37de8266cdce">&#9670;&#160;</a></span>test_non_uniform_weights_toy_edge_case_clf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_non_uniform_weights_toy_edge_case_clf </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1050</span><span class="keyword">def </span>test_non_uniform_weights_toy_edge_case_clf():</div>
<div class="line"><span class="lineno"> 1051</span>    X = [[1, 0], [1, 0], [1, 0], [0, 1]]</div>
<div class="line"><span class="lineno"> 1052</span>    y = [0, 0, 1, 0]</div>
<div class="line"><span class="lineno"> 1053</span>    <span class="comment"># ignore the first 2 training samples by setting their weight to 0</span></div>
<div class="line"><span class="lineno"> 1054</span>    sample_weight = [0, 0, 1, 1]</div>
<div class="line"><span class="lineno"> 1055</span>    <span class="keywordflow">for</span> loss <span class="keywordflow">in</span> (<span class="stringliteral">&quot;log_loss&quot;</span>, <span class="stringliteral">&quot;exponential&quot;</span>):</div>
<div class="line"><span class="lineno"> 1056</span>        gb = GradientBoostingClassifier(n_estimators=5, loss=loss)</div>
<div class="line"><span class="lineno"> 1057</span>        gb.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1058</span>        assert_array_equal(gb.predict([[1, 0]]), [1])</div>
<div class="line"><span class="lineno"> 1059</span> </div>
<div class="line"><span class="lineno"> 1060</span> </div>
<div class="line"><span class="lineno"> 1061</span><span class="preprocessor">@skip_if_32bit</span></div>
<div class="line"><span class="lineno"> 1062</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1063</span>    <span class="stringliteral">&quot;EstimatorClass&quot;</span>, (GradientBoostingClassifier, GradientBoostingRegressor)</div>
<div class="line"><span class="lineno"> 1064</span>)</div>
<div class="line"><span class="lineno"> 1065</span><span class="preprocessor">@pytest.mark.parametrize(&quot;sparse_matrix&quot;, (csr_matrix, csc_matrix, coo_matrix)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="aca5414b2ade1aaabb8f7fd29148fb6fc" name="aca5414b2ade1aaabb8f7fd29148fb6fc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca5414b2ade1aaabb8f7fd29148fb6fc">&#9670;&#160;</a></span>test_non_uniform_weights_toy_edge_case_reg()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_non_uniform_weights_toy_edge_case_reg </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1039</span><span class="keyword">def </span>test_non_uniform_weights_toy_edge_case_reg():</div>
<div class="line"><span class="lineno"> 1040</span>    X = [[1, 0], [1, 0], [1, 0], [0, 1]]</div>
<div class="line"><span class="lineno"> 1041</span>    y = [0, 0, 1, 0]</div>
<div class="line"><span class="lineno"> 1042</span>    <span class="comment"># ignore the first 2 training samples by setting their weight to 0</span></div>
<div class="line"><span class="lineno"> 1043</span>    sample_weight = [0, 0, 1, 1]</div>
<div class="line"><span class="lineno"> 1044</span>    <span class="keywordflow">for</span> loss <span class="keywordflow">in</span> (<span class="stringliteral">&quot;huber&quot;</span>, <span class="stringliteral">&quot;squared_error&quot;</span>, <span class="stringliteral">&quot;absolute_error&quot;</span>, <span class="stringliteral">&quot;quantile&quot;</span>):</div>
<div class="line"><span class="lineno"> 1045</span>        gb = GradientBoostingRegressor(learning_rate=1.0, n_estimators=2, loss=loss)</div>
<div class="line"><span class="lineno"> 1046</span>        gb.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno"> 1047</span>        <span class="keyword">assert</span> gb.predict([[1, 0]])[0] &gt; 0.5</div>
<div class="line"><span class="lineno"> 1048</span> </div>
<div class="line"><span class="lineno"> 1049</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4bb864748858fd85f0eecd4bb7008b89" name="a4bb864748858fd85f0eecd4bb7008b89"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4bb864748858fd85f0eecd4bb7008b89">&#9670;&#160;</a></span>test_oob_improvement()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_oob_improvement </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  581</span><span class="keyword">def </span>test_oob_improvement():</div>
<div class="line"><span class="lineno">  582</span>    <span class="comment"># Test if oob improvement has correct shape and regression test.</span></div>
<div class="line"><span class="lineno">  583</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1, subsample=0.5)</div>
<div class="line"><span class="lineno">  584</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  585</span>    <span class="keyword">assert</span> clf.oob_improvement_.shape[0] == 100</div>
<div class="line"><span class="lineno">  586</span>    <span class="comment"># hard-coded regression test - change if modification in OOB computation</span></div>
<div class="line"><span class="lineno">  587</span>    assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  588</span>        clf.oob_improvement_[:5], np.array([0.19, 0.15, 0.12, -0.12, -0.11]), decimal=2</div>
<div class="line"><span class="lineno">  589</span>    )</div>
<div class="line"><span class="lineno">  590</span> </div>
<div class="line"><span class="lineno">  591</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a34a87fa321d761c6be390c5ba9ab6b8a" name="a34a87fa321d761c6be390c5ba9ab6b8a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34a87fa321d761c6be390c5ba9ab6b8a">&#9670;&#160;</a></span>test_oob_improvement_raise()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_oob_improvement_raise </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  592</span><span class="keyword">def </span>test_oob_improvement_raise():</div>
<div class="line"><span class="lineno">  593</span>    <span class="comment"># Test if oob improvement has correct shape.</span></div>
<div class="line"><span class="lineno">  594</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1, subsample=1.0)</div>
<div class="line"><span class="lineno">  595</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  596</span>    <span class="keyword">with</span> pytest.raises(AttributeError):</div>
<div class="line"><span class="lineno">  597</span>        clf.oob_improvement_</div>
<div class="line"><span class="lineno">  598</span> </div>
<div class="line"><span class="lineno">  599</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6f35f3bfd38a71bd08db13bb281d1f94" name="a6f35f3bfd38a71bd08db13bb281d1f94"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6f35f3bfd38a71bd08db13bb281d1f94">&#9670;&#160;</a></span>test_oob_multilcass_iris()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_oob_multilcass_iris </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  600</span><span class="keyword">def </span>test_oob_multilcass_iris():</div>
<div class="line"><span class="lineno">  601</span>    <span class="comment"># Check OOB improvement on multi-class dataset.</span></div>
<div class="line"><span class="lineno">  602</span>    clf = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno">  603</span>        n_estimators=100, loss=<span class="stringliteral">&quot;log_loss&quot;</span>, random_state=1, subsample=0.5</div>
<div class="line"><span class="lineno">  604</span>    )</div>
<div class="line"><span class="lineno">  605</span>    clf.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  606</span>    score = clf.score(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  607</span>    <span class="keyword">assert</span> score &gt; 0.9</div>
<div class="line"><span class="lineno">  608</span>    <span class="keyword">assert</span> clf.oob_improvement_.shape[0] == clf.n_estimators</div>
<div class="line"><span class="lineno">  609</span>    <span class="comment"># hard-coded regression test - change if modification in OOB computation</span></div>
<div class="line"><span class="lineno">  610</span>    <span class="comment"># FIXME: the following snippet does not yield the same results on 32 bits</span></div>
<div class="line"><span class="lineno">  611</span>    <span class="comment"># assert_array_almost_equal(clf.oob_improvement_[:5],</span></div>
<div class="line"><span class="lineno">  612</span>    <span class="comment">#                           np.array([12.68, 10.45, 8.18, 6.43, 5.13]),</span></div>
<div class="line"><span class="lineno">  613</span>    <span class="comment">#                           decimal=2)</span></div>
<div class="line"><span class="lineno">  614</span> </div>
<div class="line"><span class="lineno">  615</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a46cb1478c773908456e0978dbd21de32" name="a46cb1478c773908456e0978dbd21de32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46cb1478c773908456e0978dbd21de32">&#9670;&#160;</a></span>test_probability_exponential()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_probability_exponential </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1015</span><span class="keyword">def </span>test_probability_exponential(global_random_seed):</div>
<div class="line"><span class="lineno"> 1016</span>    <span class="comment"># Predict probabilities.</span></div>
<div class="line"><span class="lineno"> 1017</span>    clf = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno"> 1018</span>        loss=<span class="stringliteral">&quot;exponential&quot;</span>, n_estimators=100, random_state=global_random_seed</div>
<div class="line"><span class="lineno"> 1019</span>    )</div>
<div class="line"><span class="lineno"> 1020</span> </div>
<div class="line"><span class="lineno"> 1021</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno"> 1022</span>        clf.predict_proba(T)</div>
<div class="line"><span class="lineno"> 1023</span> </div>
<div class="line"><span class="lineno"> 1024</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno"> 1025</span>    assert_array_equal(clf.predict(T), true_result)</div>
<div class="line"><span class="lineno"> 1026</span> </div>
<div class="line"><span class="lineno"> 1027</span>    <span class="comment"># check if probabilities are in [0, 1].</span></div>
<div class="line"><span class="lineno"> 1028</span>    y_proba = clf.predict_proba(T)</div>
<div class="line"><span class="lineno"> 1029</span>    <span class="keyword">assert</span> np.all(y_proba &gt;= 0.0)</div>
<div class="line"><span class="lineno"> 1030</span>    <span class="keyword">assert</span> np.all(y_proba &lt;= 1.0)</div>
<div class="line"><span class="lineno"> 1031</span>    score = clf.decision_function(T).ravel()</div>
<div class="line"><span class="lineno"> 1032</span>    assert_allclose(y_proba[:, 1], expit(2 * score))</div>
<div class="line"><span class="lineno"> 1033</span> </div>
<div class="line"><span class="lineno"> 1034</span>    <span class="comment"># derive predictions from probabilities</span></div>
<div class="line"><span class="lineno"> 1035</span>    y_pred = clf.classes_.take(y_proba.argmax(axis=1), axis=0)</div>
<div class="line"><span class="lineno"> 1036</span>    assert_array_equal(y_pred, true_result)</div>
<div class="line"><span class="lineno"> 1037</span> </div>
<div class="line"><span class="lineno"> 1038</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae439e86cfff5312c44a253b545277b8b" name="ae439e86cfff5312c44a253b545277b8b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae439e86cfff5312c44a253b545277b8b">&#9670;&#160;</a></span>test_probability_log()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_probability_log </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  245</span><span class="keyword">def </span>test_probability_log(global_random_seed):</div>
<div class="line"><span class="lineno">  246</span>    <span class="comment"># Predict probabilities.</span></div>
<div class="line"><span class="lineno">  247</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=global_random_seed)</div>
<div class="line"><span class="lineno">  248</span> </div>
<div class="line"><span class="lineno">  249</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  250</span>        clf.predict_proba(T)</div>
<div class="line"><span class="lineno">  251</span> </div>
<div class="line"><span class="lineno">  252</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  253</span>    assert_array_equal(clf.predict(T), true_result)</div>
<div class="line"><span class="lineno">  254</span> </div>
<div class="line"><span class="lineno">  255</span>    <span class="comment"># check if probabilities are in [0, 1].</span></div>
<div class="line"><span class="lineno">  256</span>    y_proba = clf.predict_proba(T)</div>
<div class="line"><span class="lineno">  257</span>    <span class="keyword">assert</span> np.all(y_proba &gt;= 0.0)</div>
<div class="line"><span class="lineno">  258</span>    <span class="keyword">assert</span> np.all(y_proba &lt;= 1.0)</div>
<div class="line"><span class="lineno">  259</span> </div>
<div class="line"><span class="lineno">  260</span>    <span class="comment"># derive predictions from probabilities</span></div>
<div class="line"><span class="lineno">  261</span>    y_pred = clf.classes_.take(y_proba.argmax(axis=1), axis=0)</div>
<div class="line"><span class="lineno">  262</span>    assert_array_equal(y_pred, true_result)</div>
<div class="line"><span class="lineno">  263</span> </div>
<div class="line"><span class="lineno">  264</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a05d76f32a2b818775ec0c995ff914625" name="a05d76f32a2b818775ec0c995ff914625"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a05d76f32a2b818775ec0c995ff914625">&#9670;&#160;</a></span>test_quantile_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_quantile_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  484</span><span class="keyword">def </span>test_quantile_loss(global_random_seed):</div>
<div class="line"><span class="lineno">  485</span>    <span class="comment"># Check if quantile loss with alpha=0.5 equals absolute_error.</span></div>
<div class="line"><span class="lineno">  486</span>    clf_quantile = GradientBoostingRegressor(</div>
<div class="line"><span class="lineno">  487</span>        n_estimators=100,</div>
<div class="line"><span class="lineno">  488</span>        loss=<span class="stringliteral">&quot;quantile&quot;</span>,</div>
<div class="line"><span class="lineno">  489</span>        max_depth=4,</div>
<div class="line"><span class="lineno">  490</span>        alpha=0.5,</div>
<div class="line"><span class="lineno">  491</span>        random_state=global_random_seed,</div>
<div class="line"><span class="lineno">  492</span>    )</div>
<div class="line"><span class="lineno">  493</span> </div>
<div class="line"><span class="lineno">  494</span>    clf_quantile.fit(X_reg, y_reg)</div>
<div class="line"><span class="lineno">  495</span>    y_quantile = clf_quantile.predict(X_reg)</div>
<div class="line"><span class="lineno">  496</span> </div>
<div class="line"><span class="lineno">  497</span>    clf_ae = GradientBoostingRegressor(</div>
<div class="line"><span class="lineno">  498</span>        n_estimators=100,</div>
<div class="line"><span class="lineno">  499</span>        loss=<span class="stringliteral">&quot;absolute_error&quot;</span>,</div>
<div class="line"><span class="lineno">  500</span>        max_depth=4,</div>
<div class="line"><span class="lineno">  501</span>        random_state=global_random_seed,</div>
<div class="line"><span class="lineno">  502</span>    )</div>
<div class="line"><span class="lineno">  503</span> </div>
<div class="line"><span class="lineno">  504</span>    clf_ae.fit(X_reg, y_reg)</div>
<div class="line"><span class="lineno">  505</span>    y_ae = clf_ae.predict(X_reg)</div>
<div class="line"><span class="lineno">  506</span>    assert_allclose(y_quantile, y_ae)</div>
<div class="line"><span class="lineno">  507</span> </div>
<div class="line"><span class="lineno">  508</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a18cc2c979a7391458367e481600391e4" name="a18cc2c979a7391458367e481600391e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18cc2c979a7391458367e481600391e4">&#9670;&#160;</a></span>test_regression_dataset()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_regression_dataset </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>subsample</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  126</span><span class="keyword">def </span>test_regression_dataset(loss, subsample, global_random_seed):</div>
<div class="line"><span class="lineno">  127</span>    <span class="comment"># Check consistency on regression dataset with least squares</span></div>
<div class="line"><span class="lineno">  128</span>    <span class="comment"># and least absolute deviation.</span></div>
<div class="line"><span class="lineno">  129</span>    ones = np.ones(len(y_reg))</div>
<div class="line"><span class="lineno">  130</span>    last_y_pred = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  131</span>    <span class="keywordflow">for</span> sample_weight <span class="keywordflow">in</span> [<span class="keywordtype">None</span>, ones, 2 * ones]:</div>
<div class="line"><span class="lineno">  132</span>        <span class="comment"># learning_rate, max_depth and n_estimators were adjusted to get a mode</span></div>
<div class="line"><span class="lineno">  133</span>        <span class="comment"># that is accurate enough to reach a low MSE on the training set while</span></div>
<div class="line"><span class="lineno">  134</span>        <span class="comment"># keeping the resource used to execute this test low enough.</span></div>
<div class="line"><span class="lineno">  135</span>        reg = GradientBoostingRegressor(</div>
<div class="line"><span class="lineno">  136</span>            n_estimators=30,</div>
<div class="line"><span class="lineno">  137</span>            loss=loss,</div>
<div class="line"><span class="lineno">  138</span>            max_depth=4,</div>
<div class="line"><span class="lineno">  139</span>            subsample=subsample,</div>
<div class="line"><span class="lineno">  140</span>            min_samples_split=2,</div>
<div class="line"><span class="lineno">  141</span>            random_state=global_random_seed,</div>
<div class="line"><span class="lineno">  142</span>            learning_rate=0.5,</div>
<div class="line"><span class="lineno">  143</span>        )</div>
<div class="line"><span class="lineno">  144</span> </div>
<div class="line"><span class="lineno">  145</span>        reg.fit(X_reg, y_reg, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  146</span>        leaves = reg.apply(X_reg)</div>
<div class="line"><span class="lineno">  147</span>        <span class="keyword">assert</span> leaves.shape == (100, 30)</div>
<div class="line"><span class="lineno">  148</span> </div>
<div class="line"><span class="lineno">  149</span>        y_pred = reg.predict(X_reg)</div>
<div class="line"><span class="lineno">  150</span>        mse = mean_squared_error(y_reg, y_pred)</div>
<div class="line"><span class="lineno">  151</span>        <span class="keyword">assert</span> mse &lt; 0.05</div>
<div class="line"><span class="lineno">  152</span> </div>
<div class="line"><span class="lineno">  153</span>        <span class="keywordflow">if</span> last_y_pred <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  154</span>            <span class="comment"># FIXME: We temporarily bypass this test. This is due to the fact</span></div>
<div class="line"><span class="lineno">  155</span>            <span class="comment"># that GBRT with and without `sample_weight` do not use the same</span></div>
<div class="line"><span class="lineno">  156</span>            <span class="comment"># implementation of the median during the initialization with the</span></div>
<div class="line"><span class="lineno">  157</span>            <span class="comment"># `DummyRegressor`. In the future, we should make sure that both</span></div>
<div class="line"><span class="lineno">  158</span>            <span class="comment"># implementations should be the same. See PR #17377 for more.</span></div>
<div class="line"><span class="lineno">  159</span>            <span class="comment"># assert_allclose(last_y_pred, y_pred)</span></div>
<div class="line"><span class="lineno">  160</span>            <span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno">  161</span> </div>
<div class="line"><span class="lineno">  162</span>        last_y_pred = y_pred</div>
<div class="line"><span class="lineno">  163</span> </div>
<div class="line"><span class="lineno">  164</span> </div>
<div class="line"><span class="lineno">  165</span><span class="preprocessor">@pytest.mark.parametrize(&quot;subsample&quot;, (1.0, 0.5)</span>)</div>
<div class="line"><span class="lineno">  166</span><span class="preprocessor">@pytest.mark.parametrize(&quot;sample_weight&quot;, (None, 1)</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a556de9e7e236b450d470908fb124bb10" name="a556de9e7e236b450d470908fb124bb10"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a556de9e7e236b450d470908fb124bb10">&#9670;&#160;</a></span>test_regression_synthetic()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_regression_synthetic </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  185</span><span class="keyword">def </span>test_regression_synthetic(global_random_seed):</div>
<div class="line"><span class="lineno">  186</span>    <span class="comment"># Test on synthetic regression datasets used in Leo Breiman,</span></div>
<div class="line"><span class="lineno">  187</span>    <span class="comment"># `Bagging Predictors?. Machine Learning 24(2): 123-140 (1996).</span></div>
<div class="line"><span class="lineno">  188</span>    random_state = check_random_state(global_random_seed)</div>
<div class="line"><span class="lineno">  189</span>    regression_params = {</div>
<div class="line"><span class="lineno">  190</span>        <span class="stringliteral">&quot;n_estimators&quot;</span>: 100,</div>
<div class="line"><span class="lineno">  191</span>        <span class="stringliteral">&quot;max_depth&quot;</span>: 4,</div>
<div class="line"><span class="lineno">  192</span>        <span class="stringliteral">&quot;min_samples_split&quot;</span>: 2,</div>
<div class="line"><span class="lineno">  193</span>        <span class="stringliteral">&quot;learning_rate&quot;</span>: 0.1,</div>
<div class="line"><span class="lineno">  194</span>        <span class="stringliteral">&quot;loss&quot;</span>: <span class="stringliteral">&quot;squared_error&quot;</span>,</div>
<div class="line"><span class="lineno">  195</span>        <span class="stringliteral">&quot;random_state&quot;</span>: global_random_seed,</div>
<div class="line"><span class="lineno">  196</span>    }</div>
<div class="line"><span class="lineno">  197</span> </div>
<div class="line"><span class="lineno">  198</span>    <span class="comment"># Friedman1</span></div>
<div class="line"><span class="lineno">  199</span>    X, y = datasets.make_friedman1(n_samples=1200, random_state=random_state, noise=1.0)</div>
<div class="line"><span class="lineno">  200</span>    X_train, y_train = X[:200], y[:200]</div>
<div class="line"><span class="lineno">  201</span>    X_test, y_test = X[200:], y[200:]</div>
<div class="line"><span class="lineno">  202</span> </div>
<div class="line"><span class="lineno">  203</span>    clf = GradientBoostingRegressor(**regression_params)</div>
<div class="line"><span class="lineno">  204</span>    clf.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  205</span>    mse = mean_squared_error(y_test, clf.predict(X_test))</div>
<div class="line"><span class="lineno">  206</span>    <span class="keyword">assert</span> mse &lt; 6.5</div>
<div class="line"><span class="lineno">  207</span> </div>
<div class="line"><span class="lineno">  208</span>    <span class="comment"># Friedman2</span></div>
<div class="line"><span class="lineno">  209</span>    X, y = datasets.make_friedman2(n_samples=1200, random_state=random_state)</div>
<div class="line"><span class="lineno">  210</span>    X_train, y_train = X[:200], y[:200]</div>
<div class="line"><span class="lineno">  211</span>    X_test, y_test = X[200:], y[200:]</div>
<div class="line"><span class="lineno">  212</span> </div>
<div class="line"><span class="lineno">  213</span>    clf = GradientBoostingRegressor(**regression_params)</div>
<div class="line"><span class="lineno">  214</span>    clf.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  215</span>    mse = mean_squared_error(y_test, clf.predict(X_test))</div>
<div class="line"><span class="lineno">  216</span>    <span class="keyword">assert</span> mse &lt; 2500.0</div>
<div class="line"><span class="lineno">  217</span> </div>
<div class="line"><span class="lineno">  218</span>    <span class="comment"># Friedman3</span></div>
<div class="line"><span class="lineno">  219</span>    X, y = datasets.make_friedman3(n_samples=1200, random_state=random_state)</div>
<div class="line"><span class="lineno">  220</span>    X_train, y_train = X[:200], y[:200]</div>
<div class="line"><span class="lineno">  221</span>    X_test, y_test = X[200:], y[200:]</div>
<div class="line"><span class="lineno">  222</span> </div>
<div class="line"><span class="lineno">  223</span>    clf = GradientBoostingRegressor(**regression_params)</div>
<div class="line"><span class="lineno">  224</span>    clf.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  225</span>    mse = mean_squared_error(y_test, clf.predict(X_test))</div>
<div class="line"><span class="lineno">  226</span>    <span class="keyword">assert</span> mse &lt; 0.025</div>
<div class="line"><span class="lineno">  227</span> </div>
<div class="line"><span class="lineno">  228</span> </div>
<div class="line"><span class="lineno">  229</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  230</span>    <span class="stringliteral">&quot;GradientBoosting, X, y&quot;</span>,</div>
<div class="line"><span class="lineno">  231</span>    [</div>
<div class="line"><span class="lineno">  232</span>        (GradientBoostingRegressor, X_reg, y_reg),</div>
<div class="line"><span class="lineno">  233</span>        (GradientBoostingClassifier, iris.data, iris.target),</div>
<div class="line"><span class="lineno">  234</span>    ],</div>
<div class="line"><span class="lineno">  235</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae23652f63307db969763ec1ea47cf557" name="ae23652f63307db969763ec1ea47cf557"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae23652f63307db969763ec1ea47cf557">&#9670;&#160;</a></span>test_serialization()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_serialization </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  450</span><span class="keyword">def </span><a class="code hl_namespace" href="namespacetest__serialization.html">test_serialization</a>():</div>
<div class="line"><span class="lineno">  451</span>    <span class="comment"># Check model serialization.</span></div>
<div class="line"><span class="lineno">  452</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  453</span> </div>
<div class="line"><span class="lineno">  454</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  455</span>    assert_array_equal(clf.predict(T), true_result)</div>
<div class="line"><span class="lineno">  456</span>    <span class="keyword">assert</span> 100 == len(clf.estimators_)</div>
<div class="line"><span class="lineno">  457</span> </div>
<div class="line"><span class="lineno">  458</span>    <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  459</span>        <span class="keyword">import</span> cPickle <span class="keyword">as</span> pickle</div>
<div class="line"><span class="lineno">  460</span>    <span class="keywordflow">except</span> ImportError:</div>
<div class="line"><span class="lineno">  461</span>        <span class="keyword">import</span> pickle</div>
<div class="line"><span class="lineno">  462</span> </div>
<div class="line"><span class="lineno">  463</span>    serialized_clf = pickle.dumps(clf, protocol=pickle.HIGHEST_PROTOCOL)</div>
<div class="line"><span class="lineno">  464</span>    clf = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  465</span>    clf = pickle.loads(serialized_clf)</div>
<div class="line"><span class="lineno">  466</span>    assert_array_equal(clf.predict(T), true_result)</div>
<div class="line"><span class="lineno">  467</span>    <span class="keyword">assert</span> 100 == len(clf.estimators_)</div>
<div class="line"><span class="lineno">  468</span> </div>
<div class="line"><span class="lineno">  469</span> </div>
<div class="ttc" id="anamespacetest__serialization_html"><div class="ttname"><a href="namespacetest__serialization.html">test_serialization</a></div><div class="ttdef"><b>Definition</b> test_serialization.py:1</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a65fecab643306f14319fe89530f3a8a8" name="a65fecab643306f14319fe89530f3a8a8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65fecab643306f14319fe89530f3a8a8">&#9670;&#160;</a></span>test_shape_y()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_shape_y </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  531</span><span class="keyword">def </span>test_shape_y():</div>
<div class="line"><span class="lineno">  532</span>    <span class="comment"># Test with float class labels.</span></div>
<div class="line"><span class="lineno">  533</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  534</span> </div>
<div class="line"><span class="lineno">  535</span>    y_ = np.asarray(y, dtype=np.int32)</div>
<div class="line"><span class="lineno">  536</span>    y_ = y_[:, np.newaxis]</div>
<div class="line"><span class="lineno">  537</span> </div>
<div class="line"><span class="lineno">  538</span>    <span class="comment"># This will raise a DataConversionWarning that we want to</span></div>
<div class="line"><span class="lineno">  539</span>    <span class="comment"># &quot;always&quot; raise, elsewhere the warnings gets ignored in the</span></div>
<div class="line"><span class="lineno">  540</span>    <span class="comment"># later tests, and the tests that check for this warning fail</span></div>
<div class="line"><span class="lineno">  541</span>    warn_msg = (</div>
<div class="line"><span class="lineno">  542</span>        <span class="stringliteral">&quot;A column-vector y was passed when a 1d array was expected. &quot;</span></div>
<div class="line"><span class="lineno">  543</span>        <span class="stringliteral">&quot;Please change the shape of y to \\(n_samples, \\), for &quot;</span></div>
<div class="line"><span class="lineno">  544</span>        <span class="stringliteral">&quot;example using ravel().&quot;</span></div>
<div class="line"><span class="lineno">  545</span>    )</div>
<div class="line"><span class="lineno">  546</span>    <span class="keyword">with</span> pytest.warns(DataConversionWarning, match=warn_msg):</div>
<div class="line"><span class="lineno">  547</span>        clf.fit(X, y_)</div>
<div class="line"><span class="lineno">  548</span>    assert_array_equal(clf.predict(T), true_result)</div>
<div class="line"><span class="lineno">  549</span>    <span class="keyword">assert</span> 100 == len(clf.estimators_)</div>
<div class="line"><span class="lineno">  550</span> </div>
<div class="line"><span class="lineno">  551</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a56d8fa9e5a774015133df26da47f8e92" name="a56d8fa9e5a774015133df26da47f8e92"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56d8fa9e5a774015133df26da47f8e92">&#9670;&#160;</a></span>test_single_class_with_sample_weight()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_single_class_with_sample_weight </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  265</span><span class="keyword">def </span>test_single_class_with_sample_weight():</div>
<div class="line"><span class="lineno">  266</span>    sample_weight = [0, 0, 0, 1, 1, 1]</div>
<div class="line"><span class="lineno">  267</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  268</span>    msg = (</div>
<div class="line"><span class="lineno">  269</span>        <span class="stringliteral">&quot;y contains 1 class after sample_weight trimmed classes with &quot;</span></div>
<div class="line"><span class="lineno">  270</span>        <span class="stringliteral">&quot;zero weights, while a minimum of 2 classes are required.&quot;</span></div>
<div class="line"><span class="lineno">  271</span>    )</div>
<div class="line"><span class="lineno">  272</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><span class="lineno">  273</span>        clf.fit(X, y, sample_weight=sample_weight)</div>
<div class="line"><span class="lineno">  274</span> </div>
<div class="line"><span class="lineno">  275</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa4ba8d487c92139e4edc66c5ff91088e" name="aa4ba8d487c92139e4edc66c5ff91088e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa4ba8d487c92139e4edc66c5ff91088e">&#9670;&#160;</a></span>test_sparse_input()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_sparse_input </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>EstimatorClass</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sparse_matrix</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1066</span><span class="keyword">def </span>test_sparse_input(EstimatorClass, sparse_matrix):</div>
<div class="line"><span class="lineno"> 1067</span>    y, X = datasets.make_multilabel_classification(</div>
<div class="line"><span class="lineno"> 1068</span>        random_state=0, n_samples=50, n_features=1, n_classes=20</div>
<div class="line"><span class="lineno"> 1069</span>    )</div>
<div class="line"><span class="lineno"> 1070</span>    y = y[:, 0]</div>
<div class="line"><span class="lineno"> 1071</span>    X_sparse = sparse_matrix(X)</div>
<div class="line"><span class="lineno"> 1072</span> </div>
<div class="line"><span class="lineno"> 1073</span>    dense = EstimatorClass(</div>
<div class="line"><span class="lineno"> 1074</span>        n_estimators=10, random_state=0, max_depth=2, min_impurity_decrease=1e-7</div>
<div class="line"><span class="lineno"> 1075</span>    ).fit(X, y)</div>
<div class="line"><span class="lineno"> 1076</span>    sparse = EstimatorClass(</div>
<div class="line"><span class="lineno"> 1077</span>        n_estimators=10, random_state=0, max_depth=2, min_impurity_decrease=1e-7</div>
<div class="line"><span class="lineno"> 1078</span>    ).fit(X_sparse, y)</div>
<div class="line"><span class="lineno"> 1079</span> </div>
<div class="line"><span class="lineno"> 1080</span>    assert_array_almost_equal(sparse.apply(X), dense.apply(X))</div>
<div class="line"><span class="lineno"> 1081</span>    assert_array_almost_equal(sparse.predict(X), dense.predict(X))</div>
<div class="line"><span class="lineno"> 1082</span>    assert_array_almost_equal(sparse.feature_importances_, dense.feature_importances_)</div>
<div class="line"><span class="lineno"> 1083</span> </div>
<div class="line"><span class="lineno"> 1084</span>    assert_array_almost_equal(sparse.predict(X_sparse), dense.predict(X))</div>
<div class="line"><span class="lineno"> 1085</span>    assert_array_almost_equal(dense.predict(X_sparse), sparse.predict(X))</div>
<div class="line"><span class="lineno"> 1086</span> </div>
<div class="line"><span class="lineno"> 1087</span>    <span class="keywordflow">if</span> issubclass(EstimatorClass, GradientBoostingClassifier):</div>
<div class="line"><span class="lineno"> 1088</span>        assert_array_almost_equal(sparse.predict_proba(X), dense.predict_proba(X))</div>
<div class="line"><span class="lineno"> 1089</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno"> 1090</span>            sparse.predict_log_proba(X), dense.predict_log_proba(X)</div>
<div class="line"><span class="lineno"> 1091</span>        )</div>
<div class="line"><span class="lineno"> 1092</span> </div>
<div class="line"><span class="lineno"> 1093</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno"> 1094</span>            sparse.decision_function(X_sparse), sparse.decision_function(X)</div>
<div class="line"><span class="lineno"> 1095</span>        )</div>
<div class="line"><span class="lineno"> 1096</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno"> 1097</span>            dense.decision_function(X_sparse), sparse.decision_function(X)</div>
<div class="line"><span class="lineno"> 1098</span>        )</div>
<div class="line"><span class="lineno"> 1099</span>        <span class="keywordflow">for</span> res_sparse, res <span class="keywordflow">in</span> zip(</div>
<div class="line"><span class="lineno"> 1100</span>            sparse.staged_decision_function(X_sparse),</div>
<div class="line"><span class="lineno"> 1101</span>            sparse.staged_decision_function(X),</div>
<div class="line"><span class="lineno"> 1102</span>        ):</div>
<div class="line"><span class="lineno"> 1103</span>            assert_array_almost_equal(res_sparse, res)</div>
<div class="line"><span class="lineno"> 1104</span> </div>
<div class="line"><span class="lineno"> 1105</span> </div>
<div class="line"><span class="lineno"> 1106</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno"> 1107</span>    <span class="stringliteral">&quot;GradientBoostingEstimator&quot;</span>, [GradientBoostingClassifier, GradientBoostingRegressor]</div>
<div class="line"><span class="lineno"> 1108</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a7544989577e8bc882866e53c508c93ad" name="a7544989577e8bc882866e53c508c93ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7544989577e8bc882866e53c508c93ad">&#9670;&#160;</a></span>test_staged_functions_defensive()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_staged_functions_defensive </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Estimator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  432</span><span class="keyword">def </span>test_staged_functions_defensive(Estimator, global_random_seed):</div>
<div class="line"><span class="lineno">  433</span>    <span class="comment"># test that staged_functions make defensive copies</span></div>
<div class="line"><span class="lineno">  434</span>    rng = np.random.RandomState(global_random_seed)</div>
<div class="line"><span class="lineno">  435</span>    X = rng.uniform(size=(10, 3))</div>
<div class="line"><span class="lineno">  436</span>    y = (4 * X[:, 0]).astype(int) + 1  <span class="comment"># don&#39;t predict zeros</span></div>
<div class="line"><span class="lineno">  437</span>    estimator = Estimator()</div>
<div class="line"><span class="lineno">  438</span>    estimator.fit(X, y)</div>
<div class="line"><span class="lineno">  439</span>    <span class="keywordflow">for</span> func <span class="keywordflow">in</span> [<span class="stringliteral">&quot;predict&quot;</span>, <span class="stringliteral">&quot;decision_function&quot;</span>, <span class="stringliteral">&quot;predict_proba&quot;</span>]:</div>
<div class="line"><span class="lineno">  440</span>        staged_func = getattr(estimator, <span class="stringliteral">&quot;staged_&quot;</span> + func, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  441</span>        <span class="keywordflow">if</span> staged_func <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  442</span>            <span class="comment"># regressor has no staged_predict_proba</span></div>
<div class="line"><span class="lineno">  443</span>            <span class="keywordflow">continue</span></div>
<div class="line"><span class="lineno">  444</span>        <span class="keyword">with</span> warnings.catch_warnings(record=<span class="keyword">True</span>):</div>
<div class="line"><span class="lineno">  445</span>            staged_result = list(staged_func(X))</div>
<div class="line"><span class="lineno">  446</span>        staged_result[1][:] = 0</div>
<div class="line"><span class="lineno">  447</span>        <span class="keyword">assert</span> np.all(staged_result[0] != 0)</div>
<div class="line"><span class="lineno">  448</span> </div>
<div class="line"><span class="lineno">  449</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a97afdb307bd8d4cbf301d5ec7a74f80a" name="a97afdb307bd8d4cbf301d5ec7a74f80a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a97afdb307bd8d4cbf301d5ec7a74f80a">&#9670;&#160;</a></span>test_staged_predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_staged_predict </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  383</span><span class="keyword">def </span>test_staged_predict():</div>
<div class="line"><span class="lineno">  384</span>    <span class="comment"># Test whether staged decision function eventually gives</span></div>
<div class="line"><span class="lineno">  385</span>    <span class="comment"># the same prediction.</span></div>
<div class="line"><span class="lineno">  386</span>    X, y = datasets.make_friedman1(n_samples=1200, random_state=1, noise=1.0)</div>
<div class="line"><span class="lineno">  387</span>    X_train, y_train = X[:200], y[:200]</div>
<div class="line"><span class="lineno">  388</span>    X_test = X[200:]</div>
<div class="line"><span class="lineno">  389</span>    clf = GradientBoostingRegressor()</div>
<div class="line"><span class="lineno">  390</span>    <span class="comment"># test raise ValueError if not fitted</span></div>
<div class="line"><span class="lineno">  391</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  392</span>        np.fromiter(clf.staged_predict(X_test), dtype=np.float64)</div>
<div class="line"><span class="lineno">  393</span> </div>
<div class="line"><span class="lineno">  394</span>    clf.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  395</span>    y_pred = clf.predict(X_test)</div>
<div class="line"><span class="lineno">  396</span> </div>
<div class="line"><span class="lineno">  397</span>    <span class="comment"># test if prediction for last stage equals ``predict``</span></div>
<div class="line"><span class="lineno">  398</span>    <span class="keywordflow">for</span> y <span class="keywordflow">in</span> clf.staged_predict(X_test):</div>
<div class="line"><span class="lineno">  399</span>        <span class="keyword">assert</span> y.shape == y_pred.shape</div>
<div class="line"><span class="lineno">  400</span> </div>
<div class="line"><span class="lineno">  401</span>    assert_array_almost_equal(y_pred, y)</div>
<div class="line"><span class="lineno">  402</span> </div>
<div class="line"><span class="lineno">  403</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7c1d86353183dbedaa80613ad5741c15" name="a7c1d86353183dbedaa80613ad5741c15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7c1d86353183dbedaa80613ad5741c15">&#9670;&#160;</a></span>test_staged_predict_proba()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_staged_predict_proba </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  404</span><span class="keyword">def </span>test_staged_predict_proba():</div>
<div class="line"><span class="lineno">  405</span>    <span class="comment"># Test whether staged predict proba eventually gives</span></div>
<div class="line"><span class="lineno">  406</span>    <span class="comment"># the same prediction.</span></div>
<div class="line"><span class="lineno">  407</span>    X, y = datasets.make_hastie_10_2(n_samples=1200, random_state=1)</div>
<div class="line"><span class="lineno">  408</span>    X_train, y_train = X[:200], y[:200]</div>
<div class="line"><span class="lineno">  409</span>    X_test, y_test = X[200:], y[200:]</div>
<div class="line"><span class="lineno">  410</span>    clf = GradientBoostingClassifier(n_estimators=20)</div>
<div class="line"><span class="lineno">  411</span>    <span class="comment"># test raise NotFittedError if not</span></div>
<div class="line"><span class="lineno">  412</span>    <span class="keyword">with</span> pytest.raises(NotFittedError):</div>
<div class="line"><span class="lineno">  413</span>        np.fromiter(clf.staged_predict_proba(X_test), dtype=np.float64)</div>
<div class="line"><span class="lineno">  414</span> </div>
<div class="line"><span class="lineno">  415</span>    clf.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  416</span> </div>
<div class="line"><span class="lineno">  417</span>    <span class="comment"># test if prediction for last stage equals ``predict``</span></div>
<div class="line"><span class="lineno">  418</span>    <span class="keywordflow">for</span> y_pred <span class="keywordflow">in</span> clf.staged_predict(X_test):</div>
<div class="line"><span class="lineno">  419</span>        <span class="keyword">assert</span> y_test.shape == y_pred.shape</div>
<div class="line"><span class="lineno">  420</span> </div>
<div class="line"><span class="lineno">  421</span>    assert_array_equal(clf.predict(X_test), y_pred)</div>
<div class="line"><span class="lineno">  422</span> </div>
<div class="line"><span class="lineno">  423</span>    <span class="comment"># test if prediction for last stage equals ``predict_proba``</span></div>
<div class="line"><span class="lineno">  424</span>    <span class="keywordflow">for</span> staged_proba <span class="keywordflow">in</span> clf.staged_predict_proba(X_test):</div>
<div class="line"><span class="lineno">  425</span>        <span class="keyword">assert</span> y_test.shape[0] == staged_proba.shape[0]</div>
<div class="line"><span class="lineno">  426</span>        <span class="keyword">assert</span> 2 == staged_proba.shape[1]</div>
<div class="line"><span class="lineno">  427</span> </div>
<div class="line"><span class="lineno">  428</span>    assert_array_almost_equal(clf.predict_proba(X_test), staged_proba)</div>
<div class="line"><span class="lineno">  429</span> </div>
<div class="line"><span class="lineno">  430</span> </div>
<div class="line"><span class="lineno">  431</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Estimator&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="aaf8387891a2997aea30ab9a29362413d" name="aaf8387891a2997aea30ab9a29362413d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf8387891a2997aea30ab9a29362413d">&#9670;&#160;</a></span>test_symbol_labels()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_symbol_labels </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  509</span><span class="keyword">def </span>test_symbol_labels():</div>
<div class="line"><span class="lineno">  510</span>    <span class="comment"># Test with non-integer class labels.</span></div>
<div class="line"><span class="lineno">  511</span>    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)</div>
<div class="line"><span class="lineno">  512</span> </div>
<div class="line"><span class="lineno">  513</span>    symbol_y = tosequence(map(str, y))</div>
<div class="line"><span class="lineno">  514</span> </div>
<div class="line"><span class="lineno">  515</span>    clf.fit(X, symbol_y)</div>
<div class="line"><span class="lineno">  516</span>    assert_array_equal(clf.predict(T), tosequence(map(str, true_result)))</div>
<div class="line"><span class="lineno">  517</span>    <span class="keyword">assert</span> 100 == len(clf.estimators_)</div>
<div class="line"><span class="lineno">  518</span> </div>
<div class="line"><span class="lineno">  519</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abfd349bfc550c5b84768c3e9d92f95d0" name="abfd349bfc550c5b84768c3e9d92f95d0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abfd349bfc550c5b84768c3e9d92f95d0">&#9670;&#160;</a></span>test_verbose_output()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_verbose_output </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  616</span><span class="keyword">def </span>test_verbose_output():</div>
<div class="line"><span class="lineno">  617</span>    <span class="comment"># Check verbose=1 does not cause error.</span></div>
<div class="line"><span class="lineno">  618</span>    <span class="keyword">from</span> io <span class="keyword">import</span> StringIO</div>
<div class="line"><span class="lineno">  619</span> </div>
<div class="line"><span class="lineno">  620</span>    <span class="keyword">import</span> sys</div>
<div class="line"><span class="lineno">  621</span> </div>
<div class="line"><span class="lineno">  622</span>    old_stdout = sys.stdout</div>
<div class="line"><span class="lineno">  623</span>    sys.stdout = StringIO()</div>
<div class="line"><span class="lineno">  624</span>    clf = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno">  625</span>        n_estimators=100, random_state=1, verbose=1, subsample=0.8</div>
<div class="line"><span class="lineno">  626</span>    )</div>
<div class="line"><span class="lineno">  627</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  628</span>    verbose_output = sys.stdout</div>
<div class="line"><span class="lineno">  629</span>    sys.stdout = old_stdout</div>
<div class="line"><span class="lineno">  630</span> </div>
<div class="line"><span class="lineno">  631</span>    <span class="comment"># check output</span></div>
<div class="line"><span class="lineno">  632</span>    verbose_output.seek(0)</div>
<div class="line"><span class="lineno">  633</span>    header = verbose_output.readline().rstrip()</div>
<div class="line"><span class="lineno">  634</span>    <span class="comment"># with OOB</span></div>
<div class="line"><span class="lineno">  635</span>    true_header = <span class="stringliteral">&quot; &quot;</span>.join([<span class="stringliteral">&quot;%10s&quot;</span>] + [<span class="stringliteral">&quot;%16s&quot;</span>] * 3) % (</div>
<div class="line"><span class="lineno">  636</span>        <span class="stringliteral">&quot;Iter&quot;</span>,</div>
<div class="line"><span class="lineno">  637</span>        <span class="stringliteral">&quot;Train Loss&quot;</span>,</div>
<div class="line"><span class="lineno">  638</span>        <span class="stringliteral">&quot;OOB Improve&quot;</span>,</div>
<div class="line"><span class="lineno">  639</span>        <span class="stringliteral">&quot;Remaining Time&quot;</span>,</div>
<div class="line"><span class="lineno">  640</span>    )</div>
<div class="line"><span class="lineno">  641</span>    <span class="keyword">assert</span> true_header == header</div>
<div class="line"><span class="lineno">  642</span> </div>
<div class="line"><span class="lineno">  643</span>    n_lines = sum(1 <span class="keywordflow">for</span> l <span class="keywordflow">in</span> verbose_output.readlines())</div>
<div class="line"><span class="lineno">  644</span>    <span class="comment"># one for 1-10 and then 9 for 20-100</span></div>
<div class="line"><span class="lineno">  645</span>    <span class="keyword">assert</span> 10 + 9 == n_lines</div>
<div class="line"><span class="lineno">  646</span> </div>
<div class="line"><span class="lineno">  647</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8fef4cc672e82279f4a4e7e175d240c8" name="a8fef4cc672e82279f4a4e7e175d240c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8fef4cc672e82279f4a4e7e175d240c8">&#9670;&#160;</a></span>test_warm_start()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  677</span><span class="keyword">def </span>test_warm_start(Cls, global_random_seed):</div>
<div class="line"><span class="lineno">  678</span>    <span class="comment"># Test if warm start equals fit.</span></div>
<div class="line"><span class="lineno">  679</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=global_random_seed)</div>
<div class="line"><span class="lineno">  680</span>    est = Cls(n_estimators=200, max_depth=1, random_state=global_random_seed)</div>
<div class="line"><span class="lineno">  681</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  682</span> </div>
<div class="line"><span class="lineno">  683</span>    est_ws = Cls(</div>
<div class="line"><span class="lineno">  684</span>        n_estimators=100, max_depth=1, warm_start=<span class="keyword">True</span>, random_state=global_random_seed</div>
<div class="line"><span class="lineno">  685</span>    )</div>
<div class="line"><span class="lineno">  686</span>    est_ws.fit(X, y)</div>
<div class="line"><span class="lineno">  687</span>    est_ws.set_params(n_estimators=200)</div>
<div class="line"><span class="lineno">  688</span>    est_ws.fit(X, y)</div>
<div class="line"><span class="lineno">  689</span> </div>
<div class="line"><span class="lineno">  690</span>    <span class="keywordflow">if</span> Cls <span class="keywordflow">is</span> GradientBoostingRegressor:</div>
<div class="line"><span class="lineno">  691</span>        assert_allclose(est_ws.predict(X), est.predict(X))</div>
<div class="line"><span class="lineno">  692</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  693</span>        <span class="comment"># Random state is preserved and hence predict_proba must also be</span></div>
<div class="line"><span class="lineno">  694</span>        <span class="comment"># same</span></div>
<div class="line"><span class="lineno">  695</span>        assert_array_equal(est_ws.predict(X), est.predict(X))</div>
<div class="line"><span class="lineno">  696</span>        assert_allclose(est_ws.predict_proba(X), est.predict_proba(X))</div>
<div class="line"><span class="lineno">  697</span> </div>
<div class="line"><span class="lineno">  698</span> </div>
<div class="line"><span class="lineno">  699</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a955076b35c2311892adde2b08dd7470f" name="a955076b35c2311892adde2b08dd7470f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a955076b35c2311892adde2b08dd7470f">&#9670;&#160;</a></span>test_warm_start_clear()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start_clear </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  732</span><span class="keyword">def </span>test_warm_start_clear(Cls):</div>
<div class="line"><span class="lineno">  733</span>    <span class="comment"># Test if fit clears state.</span></div>
<div class="line"><span class="lineno">  734</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  735</span>    est = Cls(n_estimators=100, max_depth=1)</div>
<div class="line"><span class="lineno">  736</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  737</span> </div>
<div class="line"><span class="lineno">  738</span>    est_2 = Cls(n_estimators=100, max_depth=1, warm_start=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  739</span>    est_2.fit(X, y)  <span class="comment"># inits state</span></div>
<div class="line"><span class="lineno">  740</span>    est_2.set_params(warm_start=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  741</span>    est_2.fit(X, y)  <span class="comment"># clears old state and equals est</span></div>
<div class="line"><span class="lineno">  742</span> </div>
<div class="line"><span class="lineno">  743</span>    assert_array_almost_equal(est_2.predict(X), est.predict(X))</div>
<div class="line"><span class="lineno">  744</span> </div>
<div class="line"><span class="lineno">  745</span> </div>
<div class="line"><span class="lineno">  746</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a239933d350b43cab0a74a0909667bf2a" name="a239933d350b43cab0a74a0909667bf2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a239933d350b43cab0a74a0909667bf2a">&#9670;&#160;</a></span>test_warm_start_equal_n_estimators()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start_equal_n_estimators </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  758</span><span class="keyword">def </span>test_warm_start_equal_n_estimators(Cls):</div>
<div class="line"><span class="lineno">  759</span>    <span class="comment"># Test if warm start with equal n_estimators does nothing</span></div>
<div class="line"><span class="lineno">  760</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  761</span>    est = Cls(n_estimators=100, max_depth=1)</div>
<div class="line"><span class="lineno">  762</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  763</span> </div>
<div class="line"><span class="lineno">  764</span>    est2 = clone(est)</div>
<div class="line"><span class="lineno">  765</span>    est2.set_params(n_estimators=est.n_estimators, warm_start=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  766</span>    est2.fit(X, y)</div>
<div class="line"><span class="lineno">  767</span> </div>
<div class="line"><span class="lineno">  768</span>    assert_array_almost_equal(est2.predict(X), est.predict(X))</div>
<div class="line"><span class="lineno">  769</span> </div>
<div class="line"><span class="lineno">  770</span> </div>
<div class="line"><span class="lineno">  771</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a4a54bfe56027939c1850f1267d16487d" name="a4a54bfe56027939c1850f1267d16487d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a54bfe56027939c1850f1267d16487d">&#9670;&#160;</a></span>test_warm_start_fortran()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start_fortran </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  839</span><span class="keyword">def </span>test_warm_start_fortran(Cls, global_random_seed):</div>
<div class="line"><span class="lineno">  840</span>    <span class="comment"># Test that feeding a X in Fortran-ordered is giving the same results as</span></div>
<div class="line"><span class="lineno">  841</span>    <span class="comment"># in C-ordered</span></div>
<div class="line"><span class="lineno">  842</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=global_random_seed)</div>
<div class="line"><span class="lineno">  843</span>    est_c = Cls(n_estimators=1, random_state=global_random_seed, warm_start=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  844</span>    est_fortran = Cls(n_estimators=1, random_state=global_random_seed, warm_start=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  845</span> </div>
<div class="line"><span class="lineno">  846</span>    est_c.fit(X, y)</div>
<div class="line"><span class="lineno">  847</span>    est_c.set_params(n_estimators=11)</div>
<div class="line"><span class="lineno">  848</span>    est_c.fit(X, y)</div>
<div class="line"><span class="lineno">  849</span> </div>
<div class="line"><span class="lineno">  850</span>    X_fortran = np.asfortranarray(X)</div>
<div class="line"><span class="lineno">  851</span>    est_fortran.fit(X_fortran, y)</div>
<div class="line"><span class="lineno">  852</span>    est_fortran.set_params(n_estimators=11)</div>
<div class="line"><span class="lineno">  853</span>    est_fortran.fit(X_fortran, y)</div>
<div class="line"><span class="lineno">  854</span> </div>
<div class="line"><span class="lineno">  855</span>    assert_allclose(est_c.predict(X), est_fortran.predict(X))</div>
<div class="line"><span class="lineno">  856</span> </div>
<div class="line"><span class="lineno">  857</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa6f47941bf2ec22ec7bd609ffbb57e98" name="aa6f47941bf2ec22ec7bd609ffbb57e98"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa6f47941bf2ec22ec7bd609ffbb57e98">&#9670;&#160;</a></span>test_warm_start_max_depth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start_max_depth </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  717</span><span class="keyword">def </span>test_warm_start_max_depth(Cls):</div>
<div class="line"><span class="lineno">  718</span>    <span class="comment"># Test if possible to fit trees of different depth in ensemble.</span></div>
<div class="line"><span class="lineno">  719</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  720</span>    est = Cls(n_estimators=100, max_depth=1, warm_start=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  721</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  722</span>    est.set_params(n_estimators=110, max_depth=2)</div>
<div class="line"><span class="lineno">  723</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  724</span> </div>
<div class="line"><span class="lineno">  725</span>    <span class="comment"># last 10 trees have different depth</span></div>
<div class="line"><span class="lineno">  726</span>    <span class="keyword">assert</span> est.estimators_[0, 0].max_depth == 1</div>
<div class="line"><span class="lineno">  727</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(1, 11):</div>
<div class="line"><span class="lineno">  728</span>        <span class="keyword">assert</span> est.estimators_[-i, 0].max_depth == 2</div>
<div class="line"><span class="lineno">  729</span> </div>
<div class="line"><span class="lineno">  730</span> </div>
<div class="line"><span class="lineno">  731</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="acbd577685e0152252d2b187a8a0ad1d5" name="acbd577685e0152252d2b187a8a0ad1d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acbd577685e0152252d2b187a8a0ad1d5">&#9670;&#160;</a></span>test_warm_start_n_estimators()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start_n_estimators </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  700</span><span class="keyword">def </span>test_warm_start_n_estimators(Cls, global_random_seed):</div>
<div class="line"><span class="lineno">  701</span>    <span class="comment"># Test if warm start equals fit - set n_estimators.</span></div>
<div class="line"><span class="lineno">  702</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=global_random_seed)</div>
<div class="line"><span class="lineno">  703</span>    est = Cls(n_estimators=300, max_depth=1, random_state=global_random_seed)</div>
<div class="line"><span class="lineno">  704</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  705</span> </div>
<div class="line"><span class="lineno">  706</span>    est_ws = Cls(</div>
<div class="line"><span class="lineno">  707</span>        n_estimators=100, max_depth=1, warm_start=<span class="keyword">True</span>, random_state=global_random_seed</div>
<div class="line"><span class="lineno">  708</span>    )</div>
<div class="line"><span class="lineno">  709</span>    est_ws.fit(X, y)</div>
<div class="line"><span class="lineno">  710</span>    est_ws.set_params(n_estimators=300)</div>
<div class="line"><span class="lineno">  711</span>    est_ws.fit(X, y)</div>
<div class="line"><span class="lineno">  712</span> </div>
<div class="line"><span class="lineno">  713</span>    assert_allclose(est_ws.predict(X), est.predict(X))</div>
<div class="line"><span class="lineno">  714</span> </div>
<div class="line"><span class="lineno">  715</span> </div>
<div class="line"><span class="lineno">  716</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="adb6897558b5a84b8ef8d7c092e3e2f42" name="adb6897558b5a84b8ef8d7c092e3e2f42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb6897558b5a84b8ef8d7c092e3e2f42">&#9670;&#160;</a></span>test_warm_start_oob()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start_oob </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  786</span><span class="keyword">def </span>test_warm_start_oob(Cls):</div>
<div class="line"><span class="lineno">  787</span>    <span class="comment"># Test if warm start OOB equals fit.</span></div>
<div class="line"><span class="lineno">  788</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  789</span>    est = Cls(n_estimators=200, max_depth=1, subsample=0.5, random_state=1)</div>
<div class="line"><span class="lineno">  790</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  791</span> </div>
<div class="line"><span class="lineno">  792</span>    est_ws = Cls(</div>
<div class="line"><span class="lineno">  793</span>        n_estimators=100, max_depth=1, subsample=0.5, random_state=1, warm_start=<span class="keyword">True</span></div>
<div class="line"><span class="lineno">  794</span>    )</div>
<div class="line"><span class="lineno">  795</span>    est_ws.fit(X, y)</div>
<div class="line"><span class="lineno">  796</span>    est_ws.set_params(n_estimators=200)</div>
<div class="line"><span class="lineno">  797</span>    est_ws.fit(X, y)</div>
<div class="line"><span class="lineno">  798</span> </div>
<div class="line"><span class="lineno">  799</span>    assert_array_almost_equal(est_ws.oob_improvement_[:100], est.oob_improvement_[:100])</div>
<div class="line"><span class="lineno">  800</span> </div>
<div class="line"><span class="lineno">  801</span> </div>
<div class="line"><span class="lineno">  802</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a9512bc9781545027380840ac384b9969" name="a9512bc9781545027380840ac384b9969"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9512bc9781545027380840ac384b9969">&#9670;&#160;</a></span>test_warm_start_oob_switch()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start_oob_switch </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  772</span><span class="keyword">def </span>test_warm_start_oob_switch(Cls):</div>
<div class="line"><span class="lineno">  773</span>    <span class="comment"># Test if oob can be turned on during warm start.</span></div>
<div class="line"><span class="lineno">  774</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  775</span>    est = Cls(n_estimators=100, max_depth=1, warm_start=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  776</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  777</span>    est.set_params(n_estimators=110, subsample=0.5)</div>
<div class="line"><span class="lineno">  778</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  779</span> </div>
<div class="line"><span class="lineno">  780</span>    assert_array_equal(est.oob_improvement_[:100], np.zeros(100))</div>
<div class="line"><span class="lineno">  781</span>    <span class="comment"># the last 10 are not zeros</span></div>
<div class="line"><span class="lineno">  782</span>    assert_array_equal(est.oob_improvement_[-10:] == 0.0, np.zeros(10, dtype=bool))</div>
<div class="line"><span class="lineno">  783</span> </div>
<div class="line"><span class="lineno">  784</span> </div>
<div class="line"><span class="lineno">  785</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ab9aadc2f95180c4b4ac84ec6f47db235" name="ab9aadc2f95180c4b4ac84ec6f47db235"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab9aadc2f95180c4b4ac84ec6f47db235">&#9670;&#160;</a></span>test_warm_start_smaller_n_estimators()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start_smaller_n_estimators </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  747</span><span class="keyword">def </span>test_warm_start_smaller_n_estimators(Cls):</div>
<div class="line"><span class="lineno">  748</span>    <span class="comment"># Test if warm start with smaller n_estimators raises error</span></div>
<div class="line"><span class="lineno">  749</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  750</span>    est = Cls(n_estimators=100, max_depth=1, warm_start=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  751</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  752</span>    est.set_params(n_estimators=99)</div>
<div class="line"><span class="lineno">  753</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  754</span>        est.fit(X, y)</div>
<div class="line"><span class="lineno">  755</span> </div>
<div class="line"><span class="lineno">  756</span> </div>
<div class="line"><span class="lineno">  757</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="abc9d4bdaec6db4974003e7bbff3a84eb" name="abc9d4bdaec6db4974003e7bbff3a84eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abc9d4bdaec6db4974003e7bbff3a84eb">&#9670;&#160;</a></span>test_warm_start_sparse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start_sparse </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Cls</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  803</span><span class="keyword">def </span>test_warm_start_sparse(Cls):</div>
<div class="line"><span class="lineno">  804</span>    <span class="comment"># Test that all sparse matrix types are supported</span></div>
<div class="line"><span class="lineno">  805</span>    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  806</span>    sparse_matrix_type = [csr_matrix, csc_matrix, coo_matrix]</div>
<div class="line"><span class="lineno">  807</span>    est_dense = Cls(</div>
<div class="line"><span class="lineno">  808</span>        n_estimators=100, max_depth=1, subsample=0.5, random_state=1, warm_start=<span class="keyword">True</span></div>
<div class="line"><span class="lineno">  809</span>    )</div>
<div class="line"><span class="lineno">  810</span>    est_dense.fit(X, y)</div>
<div class="line"><span class="lineno">  811</span>    est_dense.predict(X)</div>
<div class="line"><span class="lineno">  812</span>    est_dense.set_params(n_estimators=200)</div>
<div class="line"><span class="lineno">  813</span>    est_dense.fit(X, y)</div>
<div class="line"><span class="lineno">  814</span>    y_pred_dense = est_dense.predict(X)</div>
<div class="line"><span class="lineno">  815</span> </div>
<div class="line"><span class="lineno">  816</span>    <span class="keywordflow">for</span> sparse_constructor <span class="keywordflow">in</span> sparse_matrix_type:</div>
<div class="line"><span class="lineno">  817</span>        X_sparse = sparse_constructor(X)</div>
<div class="line"><span class="lineno">  818</span> </div>
<div class="line"><span class="lineno">  819</span>        est_sparse = Cls(</div>
<div class="line"><span class="lineno">  820</span>            n_estimators=100,</div>
<div class="line"><span class="lineno">  821</span>            max_depth=1,</div>
<div class="line"><span class="lineno">  822</span>            subsample=0.5,</div>
<div class="line"><span class="lineno">  823</span>            random_state=1,</div>
<div class="line"><span class="lineno">  824</span>            warm_start=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  825</span>        )</div>
<div class="line"><span class="lineno">  826</span>        est_sparse.fit(X_sparse, y)</div>
<div class="line"><span class="lineno">  827</span>        est_sparse.predict(X)</div>
<div class="line"><span class="lineno">  828</span>        est_sparse.set_params(n_estimators=200)</div>
<div class="line"><span class="lineno">  829</span>        est_sparse.fit(X_sparse, y)</div>
<div class="line"><span class="lineno">  830</span>        y_pred_sparse = est_sparse.predict(X)</div>
<div class="line"><span class="lineno">  831</span> </div>
<div class="line"><span class="lineno">  832</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  833</span>            est_dense.oob_improvement_[:100], est_sparse.oob_improvement_[:100]</div>
<div class="line"><span class="lineno">  834</span>        )</div>
<div class="line"><span class="lineno">  835</span>        assert_array_almost_equal(y_pred_dense, y_pred_sparse)</div>
<div class="line"><span class="lineno">  836</span> </div>
<div class="line"><span class="lineno">  837</span> </div>
<div class="line"><span class="lineno">  838</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Cls&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a0b7d7019cdeff18eea60cfa6d262297c" name="a0b7d7019cdeff18eea60cfa6d262297c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b7d7019cdeff18eea60cfa6d262297c">&#9670;&#160;</a></span>test_warm_start_wo_nestimators_change()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_warm_start_wo_nestimators_change </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1005</span><span class="keyword">def </span>test_warm_start_wo_nestimators_change():</div>
<div class="line"><span class="lineno"> 1006</span>    <span class="comment"># Test if warm_start does nothing if n_estimators is not changed.</span></div>
<div class="line"><span class="lineno"> 1007</span>    <span class="comment"># Regression test for #3513.</span></div>
<div class="line"><span class="lineno"> 1008</span>    clf = GradientBoostingClassifier(n_estimators=10, warm_start=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1009</span>    clf.fit([[0, 1], [2, 3]], [0, 1])</div>
<div class="line"><span class="lineno"> 1010</span>    <span class="keyword">assert</span> clf.estimators_.shape[0] == 10</div>
<div class="line"><span class="lineno"> 1011</span>    clf.fit([[0, 1], [2, 3]], [0, 1])</div>
<div class="line"><span class="lineno"> 1012</span>    <span class="keyword">assert</span> clf.estimators_.shape[0] == 10</div>
<div class="line"><span class="lineno"> 1013</span> </div>
<div class="line"><span class="lineno"> 1014</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af5f3ca057f096f5bbfe575883eec490c" name="af5f3ca057f096f5bbfe575883eec490c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5f3ca057f096f5bbfe575883eec490c">&#9670;&#160;</a></span>test_zero_estimator_clf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_zero_estimator_clf </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  954</span><span class="keyword">def </span>test_zero_estimator_clf(global_random_seed):</div>
<div class="line"><span class="lineno">  955</span>    <span class="comment"># Test if init=&#39;zero&#39; works for classification.</span></div>
<div class="line"><span class="lineno">  956</span>    X = iris.data</div>
<div class="line"><span class="lineno">  957</span>    y = np.array(iris.target)</div>
<div class="line"><span class="lineno">  958</span> </div>
<div class="line"><span class="lineno">  959</span>    est = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno">  960</span>        n_estimators=20, max_depth=1, random_state=global_random_seed, init=<span class="stringliteral">&quot;zero&quot;</span></div>
<div class="line"><span class="lineno">  961</span>    )</div>
<div class="line"><span class="lineno">  962</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  963</span> </div>
<div class="line"><span class="lineno">  964</span>    <span class="keyword">assert</span> est.score(X, y) &gt; 0.96</div>
<div class="line"><span class="lineno">  965</span> </div>
<div class="line"><span class="lineno">  966</span>    <span class="comment"># binary clf</span></div>
<div class="line"><span class="lineno">  967</span>    mask = y != 0</div>
<div class="line"><span class="lineno">  968</span>    y[mask] = 1</div>
<div class="line"><span class="lineno">  969</span>    y[~mask] = 0</div>
<div class="line"><span class="lineno">  970</span>    est = GradientBoostingClassifier(</div>
<div class="line"><span class="lineno">  971</span>        n_estimators=20, max_depth=1, random_state=global_random_seed, init=<span class="stringliteral">&quot;zero&quot;</span></div>
<div class="line"><span class="lineno">  972</span>    )</div>
<div class="line"><span class="lineno">  973</span>    est.fit(X, y)</div>
<div class="line"><span class="lineno">  974</span>    <span class="keyword">assert</span> est.score(X, y) &gt; 0.96</div>
<div class="line"><span class="lineno">  975</span> </div>
<div class="line"><span class="lineno">  976</span> </div>
<div class="line"><span class="lineno">  977</span><span class="preprocessor">@pytest.mark.parametrize(&quot;GBEstimator&quot;, GRADIENT_BOOSTING_ESTIMATORS)</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a1a50fa4219844236417532d0078106e0" name="a1a50fa4219844236417532d0078106e0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1a50fa4219844236417532d0078106e0">&#9670;&#160;</a></span>test_zero_estimator_reg()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.test_zero_estimator_reg </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_random_seed</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  935</span><span class="keyword">def </span>test_zero_estimator_reg(global_random_seed):</div>
<div class="line"><span class="lineno">  936</span>    <span class="comment"># Test if init=&#39;zero&#39; works for regression by checking that it is better</span></div>
<div class="line"><span class="lineno">  937</span>    <span class="comment"># than a simple baseline.</span></div>
<div class="line"><span class="lineno">  938</span> </div>
<div class="line"><span class="lineno">  939</span>    baseline = DummyRegressor(strategy=<span class="stringliteral">&quot;mean&quot;</span>).fit(X_reg, y_reg)</div>
<div class="line"><span class="lineno">  940</span>    mse_baseline = mean_squared_error(baseline.predict(X_reg), y_reg)</div>
<div class="line"><span class="lineno">  941</span>    est = GradientBoostingRegressor(</div>
<div class="line"><span class="lineno">  942</span>        n_estimators=5,</div>
<div class="line"><span class="lineno">  943</span>        max_depth=1,</div>
<div class="line"><span class="lineno">  944</span>        random_state=global_random_seed,</div>
<div class="line"><span class="lineno">  945</span>        init=<span class="stringliteral">&quot;zero&quot;</span>,</div>
<div class="line"><span class="lineno">  946</span>        learning_rate=0.5,</div>
<div class="line"><span class="lineno">  947</span>    )</div>
<div class="line"><span class="lineno">  948</span>    est.fit(X_reg, y_reg)</div>
<div class="line"><span class="lineno">  949</span>    y_pred = est.predict(X_reg)</div>
<div class="line"><span class="lineno">  950</span>    mse_gbdt = mean_squared_error(y_reg, y_pred)</div>
<div class="line"><span class="lineno">  951</span>    <span class="keyword">assert</span> mse_gbdt &lt; mse_baseline</div>
<div class="line"><span class="lineno">  952</span> </div>
<div class="line"><span class="lineno">  953</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a72590031a568f353a9152f78884786f0" name="a72590031a568f353a9152f78884786f0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a72590031a568f353a9152f78884786f0">&#9670;&#160;</a></span>data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a183bef0083233fbc81cb51e157001de1" name="a183bef0083233fbc81cb51e157001de1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a183bef0083233fbc81cb51e157001de1">&#9670;&#160;</a></span>GRADIENT_BOOSTING_ESTIMATORS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.ensemble.tests.test_gradient_boosting.GRADIENT_BOOSTING_ESTIMATORS = [<a class="el" href="classsklearn_1_1ensemble_1_1__gb_1_1_gradient_boosting_classifier.html">GradientBoostingClassifier</a>, <a class="el" href="classsklearn_1_1ensemble_1_1__gb_1_1_gradient_boosting_regressor.html">GradientBoostingRegressor</a>]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6b04784c4b3b41b93960642f4eda368b" name="a6b04784c4b3b41b93960642f4eda368b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b04784c4b3b41b93960642f4eda368b">&#9670;&#160;</a></span>iris</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.iris = datasets.load_iris()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3f8ea910f19c015eac315b17032562cb" name="a3f8ea910f19c015eac315b17032562cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3f8ea910f19c015eac315b17032562cb">&#9670;&#160;</a></span>n_features</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.n_features</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a195dd4dc83913fb7ae47f75895e9f7e3" name="a195dd4dc83913fb7ae47f75895e9f7e3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a195dd4dc83913fb7ae47f75895e9f7e3">&#9670;&#160;</a></span>n_informative</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.n_informative</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1517eb7e085d60e24f6f560e5e101ffb" name="a1517eb7e085d60e24f6f560e5e101ffb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1517eb7e085d60e24f6f560e5e101ffb">&#9670;&#160;</a></span>n_samples</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.n_samples</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acf19561605f367813323ea496ba246f8" name="acf19561605f367813323ea496ba246f8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acf19561605f367813323ea496ba246f8">&#9670;&#160;</a></span>noise</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.noise</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa880220f15c372d7acdefc55f4e33aea" name="aa880220f15c372d7acdefc55f4e33aea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa880220f15c372d7acdefc55f4e33aea">&#9670;&#160;</a></span>perm</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.perm = rng.permutation(iris.target.size)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acba7df5897200661784f2508df775039" name="acba7df5897200661784f2508df775039"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acba7df5897200661784f2508df775039">&#9670;&#160;</a></span>random_state</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.random_state</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a930eb2323c5ed86328f5f751d4b18a0f" name="a930eb2323c5ed86328f5f751d4b18a0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a930eb2323c5ed86328f5f751d4b18a0f">&#9670;&#160;</a></span>rng</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.rng = np.random.RandomState(0)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a389908af95528685268175f0a3b941eb" name="a389908af95528685268175f0a3b941eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a389908af95528685268175f0a3b941eb">&#9670;&#160;</a></span>T</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.ensemble.tests.test_gradient_boosting.T = [[-1, -1], [2, 2], [3, 2]]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aef43d26423ab767524a149d6fc239510" name="aef43d26423ab767524a149d6fc239510"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef43d26423ab767524a149d6fc239510">&#9670;&#160;</a></span>target</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.target</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae394850a3c96aebd8a6a380eb727d5d9" name="ae394850a3c96aebd8a6a380eb727d5d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae394850a3c96aebd8a6a380eb727d5d9">&#9670;&#160;</a></span>true_result</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.ensemble.tests.test_gradient_boosting.true_result = [-1, 1, 1]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a69bfead7a756e1294b41341d5a380167" name="a69bfead7a756e1294b41341d5a380167"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a69bfead7a756e1294b41341d5a380167">&#9670;&#160;</a></span>X</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.ensemble.tests.test_gradient_boosting.X = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae6e95944cb36089f6eb2013a34da5643" name="ae6e95944cb36089f6eb2013a34da5643"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6e95944cb36089f6eb2013a34da5643">&#9670;&#160;</a></span>X_reg</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.X_reg</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af3594f92a4f53c73864a897522f99325" name="af3594f92a4f53c73864a897522f99325"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af3594f92a4f53c73864a897522f99325">&#9670;&#160;</a></span>y</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">list sklearn.ensemble.tests.test_gradient_boosting.y = [-1, -1, -1, 1, 1, 1]</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aba64f90a225de7dc3f2391bf3df0e7cd" name="aba64f90a225de7dc3f2391bf3df0e7cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba64f90a225de7dc3f2391bf3df0e7cd">&#9670;&#160;</a></span>y_reg</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_gradient_boosting.y_reg = scale(y_reg)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
