<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: scipy.stats._fit Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacescipy.html">scipy</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1stats.html">stats</a></li><li class="navelem"><a class="el" href="namespacescipy_1_1stats_1_1__fit.html">_fit</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">scipy.stats._fit Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classscipy_1_1stats_1_1__fit_1_1_fit_result.html">FitResult</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ad0524a2cd7d61417718d08726ec7feb8" id="r_ad0524a2cd7d61417718d08726ec7feb8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__fit.html#ad0524a2cd7d61417718d08726ec7feb8">_combine_bounds</a> (name, user_bounds, shape_domain, integral)</td></tr>
<tr class="separator:ad0524a2cd7d61417718d08726ec7feb8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec717b294c7a41f2843a4cc2a49cfe15" id="r_aec717b294c7a41f2843a4cc2a49cfe15"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacescipy_1_1stats_1_1__fit.html#aec717b294c7a41f2843a4cc2a49cfe15">fit</a> (dist, data, bounds=None, *guess=None, optimizer=optimize.differential_evolution)</td></tr>
<tr class="separator:aec717b294c7a41f2843a4cc2a49cfe15"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="ad0524a2cd7d61417718d08726ec7feb8" name="ad0524a2cd7d61417718d08726ec7feb8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad0524a2cd7d61417718d08726ec7feb8">&#9670;&#160;</a></span>_combine_bounds()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._fit._combine_bounds </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>user_bounds</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>shape_domain</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>integral</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Intersection of user-defined bounds and distribution PDF/PMF domain</pre> <div class="fragment"><div class="line"><span class="lineno">    7</span><span class="keyword">def </span>_combine_bounds(name, user_bounds, shape_domain, integral):</div>
<div class="line"><span class="lineno">    8</span>    <span class="stringliteral">&quot;&quot;&quot;Intersection of user-defined bounds and distribution PDF/PMF domain&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">    9</span> </div>
<div class="line"><span class="lineno">   10</span>    user_bounds = np.atleast_1d(user_bounds)</div>
<div class="line"><span class="lineno">   11</span> </div>
<div class="line"><span class="lineno">   12</span>    <span class="keywordflow">if</span> user_bounds[0] &gt; user_bounds[1]:</div>
<div class="line"><span class="lineno">   13</span>        message = (f<span class="stringliteral">&quot;There are no values for `{name}` on the interval &quot;</span></div>
<div class="line"><span class="lineno">   14</span>                   f<span class="stringliteral">&quot;{list(user_bounds)}.&quot;</span>)</div>
<div class="line"><span class="lineno">   15</span>        <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">   16</span> </div>
<div class="line"><span class="lineno">   17</span>    bounds = (max(user_bounds[0], shape_domain[0]),</div>
<div class="line"><span class="lineno">   18</span>              min(user_bounds[1], shape_domain[1]))</div>
<div class="line"><span class="lineno">   19</span> </div>
<div class="line"><span class="lineno">   20</span>    <span class="keywordflow">if</span> integral <span class="keywordflow">and</span> (np.ceil(bounds[0]) &gt; np.floor(bounds[1])):</div>
<div class="line"><span class="lineno">   21</span>        message = (f<span class="stringliteral">&quot;There are no integer values for `{name}` on the interval &quot;</span></div>
<div class="line"><span class="lineno">   22</span>                   f<span class="stringliteral">&quot;defined by the user-provided bounds and the domain &quot;</span></div>
<div class="line"><span class="lineno">   23</span>                   <span class="stringliteral">&quot;of the distribution.&quot;</span>)</div>
<div class="line"><span class="lineno">   24</span>        <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">   25</span>    <span class="keywordflow">elif</span> <span class="keywordflow">not</span> integral <span class="keywordflow">and</span> (bounds[0] &gt; bounds[1]):</div>
<div class="line"><span class="lineno">   26</span>        message = (f<span class="stringliteral">&quot;There are no values for `{name}` on the interval &quot;</span></div>
<div class="line"><span class="lineno">   27</span>                   f<span class="stringliteral">&quot;defined by the user-provided bounds and the domain &quot;</span></div>
<div class="line"><span class="lineno">   28</span>                   <span class="stringliteral">&quot;of the distribution.&quot;</span>)</div>
<div class="line"><span class="lineno">   29</span>        <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">   30</span> </div>
<div class="line"><span class="lineno">   31</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.all(np.isfinite(bounds)):</div>
<div class="line"><span class="lineno">   32</span>        message = (f<span class="stringliteral">&quot;The intersection of user-provided bounds for `{name}` &quot;</span></div>
<div class="line"><span class="lineno">   33</span>                   f<span class="stringliteral">&quot;and the domain of the distribution is not finite. Please &quot;</span></div>
<div class="line"><span class="lineno">   34</span>                   f<span class="stringliteral">&quot;provide finite bounds for shape `{name}` in `bounds`.&quot;</span>)</div>
<div class="line"><span class="lineno">   35</span>        <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">   36</span> </div>
<div class="line"><span class="lineno">   37</span>    <span class="keywordflow">return</span> bounds</div>
<div class="line"><span class="lineno">   38</span> </div>
<div class="line"><span class="lineno">   39</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aec717b294c7a41f2843a4cc2a49cfe15" name="aec717b294c7a41f2843a4cc2a49cfe15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec717b294c7a41f2843a4cc2a49cfe15">&#9670;&#160;</a></span>fit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">scipy.stats._fit.fit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dist</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>bounds</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>guess</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>optimizer</em> = <code>optimize.differential_evolution</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Fit a discrete or continuous distribution to data

Given a distribution, data, and bounds on the parameters of the
distribution, return maximum likelihood estimates of the parameters.

Parameters
----------
dist : `scipy.stats.rv_continuous` or `scipy.stats.rv_discrete`
The object representing the distribution to be fit to the data.
data : 1D array_like
The data to which the distribution is to be fit. If the data contain
any of ``np.nan``, ``np.inf``, or -``np.inf``, the fit method will
raise a ``ValueError``.
bounds : dict or sequence of tuples, optional
If a dictionary, each key is the name of a parameter of the
distribution, and the corresponding value is a tuple containing the
lower and upper bound on that parameter.  If the distribution is
defined only for a finite range of values of that parameter, no entry
for that parameter is required; e.g., some distributions have
parameters which must be on the interval [0, 1]. Bounds for parameters
location (``loc``) and scale (``scale``) are optional; by default,
they are fixed to 0 and 1, respectively.

If a sequence, element *i* is a tuple containing the lower and upper
bound on the *i*\ th parameter of the distribution. In this case,
bounds for *all* distribution shape parameters must be provided.
Optionally, bounds for location and scale may follow the
distribution shape parameters.

If a shape is to be held fixed (e.g. if it is known), the
lower and upper bounds may be equal. If a user-provided lower or upper
bound is beyond a bound of the domain for which the distribution is
defined, the bound of the distribution's domain will replace the
user-provided value. Similarly, parameters which must be integral
will be constrained to integral values within the user-provided bounds.
guess : dict or array_like, optional
If a dictionary, each key is the name of a parameter of the
distribution, and the corresponding value is a guess for the value
of the parameter.

If a sequence, element *i* is a guess for the *i*\ th parameter of the
distribution. In this case, guesses for *all* distribution shape
parameters must be provided.

If `guess` is not provided, guesses for the decision variables will
not be passed to the optimizer. If `guess` is provided, guesses for
any missing parameters will be set at the mean of the lower and
upper bounds. Guesses for parameters which must be integral will be
rounded to integral values, and guesses that lie outside the
intersection of the user-provided bounds and the domain of the
distribution will be clipped.
optimizer : callable, optional
`optimizer` is a callable that accepts the following positional
argument.

fun : callable
    The objective function to be optimized. `fun` accepts one argument
    ``x``, candidate shape parameters of the distribution, and returns
    the negative log-likelihood function given ``x``, `dist`, and the
    provided `data`.
    The job of `optimizer` is to find values of the decision variables
    that minimizes `fun`.

`optimizer` must also accepts the following keyword argument.

bounds : sequence of tuples
    The bounds on values of the decision variables; each element will
    be a tuple containing the lower and upper bound on a decision
    variable.

If `guess` is provided, `optimizer` must also accept the following
keyword argument.

x0 : array_like
    The guesses for each decision variable.

If the distribution has any shape parameters that must be integral or
if the distribution is discrete and the location parameter is not
fixed, `optimizer` must also accept the following keyword argument.

integrality : array_like of bools
    For each decision variable, True if the decision variable is
    must be constrained to integer values and False if the decision
    variable is continuous.

`optimizer` must return an object, such as an instance of
`scipy.optimize.OptimizeResult`, which holds the optimal values of
the decision variables in an attribute ``x``. If attributes
``fun``, ``status``, or ``message`` are provided, they will be
included in the result object returned by `fit`.

Returns
-------
result : `~scipy.stats._result_classes.FitResult`
An object with the following fields.

params : namedtuple
    A namedtuple containing the maximum likelihood estimates of the
    shape parameters, location, and (if applicable) scale of the
    distribution.
success : bool or None
    Whether the optimizer considered the optimization to terminate
    successfully or not.
message : str or None
    Any status message provided by the optimizer.

The object has the following method:

nllf(params=None, data=None)
    By default, the negative log-likehood function at the fitted
    `params` for the given `data`. Accepts a tuple containing
    alternative shapes, location, and scale of the distribution and
    an array of alternative data.

plot(ax=None)
    Superposes the PDF/PMF of the fitted distribution over a normalized
    histogram of the data.

See Also
--------
rv_continuous,  rv_discrete

Notes
-----
Optimization is more likely to converge to the maximum likelihood estimate
when the user provides tight bounds containing the maximum likelihood
estimate. For example, when fitting a binomial distribution to data, the
number of experiments underlying each sample may be known, in which case
the corresponding shape parameter ``n`` can be fixed.

Examples
--------
Suppose we wish to fit a distribution to the following data.

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from scipy import stats
&gt;&gt;&gt; rng = np.random.default_rng()
&gt;&gt;&gt; dist = stats.nbinom
&gt;&gt;&gt; shapes = (5, 0.5)
&gt;&gt;&gt; data = dist.rvs(*shapes, size=1000, random_state=rng)

Suppose we do not know how the data were generated, but we suspect that
it follows a negative binomial distribution with parameters *n* and *p*\.
(See `scipy.stats.nbinom`.) We believe that the parameter *n* was fewer
than 30, and we know that the parameter *p* must lie on the interval
[0, 1]. We record this information in a variable `bounds` and pass
this information to `fit`.

&gt;&gt;&gt; bounds = [(0, 30), (0, 1)]
&gt;&gt;&gt; res = stats.fit(dist, data, bounds)

`fit` searches within the user-specified `bounds` for the
values that best match the data (in the sense of maximum likelihood
estimation). In this case, it found shape values similar to those
from which the data were actually generated.

&gt;&gt;&gt; res.params
FitParams(n=5.0, p=0.5028157644634368, loc=0.0)  # may vary

We can visualize the results by superposing the probability mass function
of the distribution (with the shapes fit to the data) over a normalized
histogram of the data.

&gt;&gt;&gt; import matplotlib.pyplot as plt  # matplotlib must be installed to plot
&gt;&gt;&gt; res.plot()
&gt;&gt;&gt; plt.show()

Note that the estimate for *n* was exactly integral; this is because
the domain of the `nbinom` PMF includes only integral *n*, and the `nbinom`
object "knows" that. `nbinom` also knows that the shape *p* must be a
value between 0 and 1. In such a case - when the domain of the distribution
with respect to a parameter is finite - we are not required to specify
bounds for the parameter.

&gt;&gt;&gt; bounds = {'n': (0, 30)}  # omit parameter p using a `dict`
&gt;&gt;&gt; res2 = stats.fit(dist, data, bounds)
&gt;&gt;&gt; res2.params
FitParams(n=5.0, p=0.5016492009232932, loc=0.0)  # may vary

If we wish to force the distribution to be fit with *n* fixed at 6, we can
set both the lower and upper bounds on *n* to 6. Note, however, that the
value of the objective function being optimized is typically worse (higher)
in this case.

&gt;&gt;&gt; bounds = {'n': (6, 6)}  # fix parameter `n`
&gt;&gt;&gt; res3 = stats.fit(dist, data, bounds)
&gt;&gt;&gt; res3.params
FitParams(n=6.0, p=0.5486556076755706, loc=0.0)  # may vary
&gt;&gt;&gt; res3.nllf() &gt; res.nllf()
True  # may vary

Note that the numerical results of the previous examples are typical, but
they may vary because the default optimizer used by `fit`,
`scipy.optimize.differential_evolution`, is stochastic. However, we can
customize the settings used by the optimizer to ensure reproducibility -
or even use a different optimizer entirely - using the `optimizer`
parameter.

&gt;&gt;&gt; from scipy.optimize import differential_evolution
&gt;&gt;&gt; rng = np.random.default_rng(767585560716548)
&gt;&gt;&gt; def optimizer(fun, bounds, *, integrality):
...     return differential_evolution(fun, bounds, strategy='best2bin',
...                                   seed=rng, integrality=integrality)
&gt;&gt;&gt; bounds = [(0, 30), (0, 1)]
&gt;&gt;&gt; res4 = stats.fit(dist, data, bounds, optimizer=optimizer)
&gt;&gt;&gt; res4.params
FitParams(n=5.0, p=0.5015183149259951, loc=0.0)</pre> <div class="fragment"><div class="line"><span class="lineno">  173</span>        optimizer=optimize.differential_evolution):</div>
<div class="line"><span class="lineno">  174</span>    <span class="stringliteral">r&quot;&quot;&quot;Fit a discrete or continuous distribution to data</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">    Given a distribution, data, and bounds on the parameters of the</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">    distribution, return maximum likelihood estimates of the parameters.</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">    dist : `scipy.stats.rv_continuous` or `scipy.stats.rv_discrete`</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">        The object representing the distribution to be fit to the data.</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">    data : 1D array_like</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral">        The data to which the distribution is to be fit. If the data contain</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">        any of ``np.nan``, ``np.inf``, or -``np.inf``, the fit method will</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">        raise a ``ValueError``.</span></div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">    bounds : dict or sequence of tuples, optional</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral">        If a dictionary, each key is the name of a parameter of the</span></div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">        distribution, and the corresponding value is a tuple containing the</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral">        lower and upper bound on that parameter.  If the distribution is</span></div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral">        defined only for a finite range of values of that parameter, no entry</span></div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">        for that parameter is required; e.g., some distributions have</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral">        parameters which must be on the interval [0, 1]. Bounds for parameters</span></div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">        location (``loc``) and scale (``scale``) are optional; by default,</span></div>
<div class="line"><span class="lineno">  195</span><span class="stringliteral">        they are fixed to 0 and 1, respectively.</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral">        If a sequence, element *i* is a tuple containing the lower and upper</span></div>
<div class="line"><span class="lineno">  198</span><span class="stringliteral">        bound on the *i*\ th parameter of the distribution. In this case,</span></div>
<div class="line"><span class="lineno">  199</span><span class="stringliteral">        bounds for *all* distribution shape parameters must be provided.</span></div>
<div class="line"><span class="lineno">  200</span><span class="stringliteral">        Optionally, bounds for location and scale may follow the</span></div>
<div class="line"><span class="lineno">  201</span><span class="stringliteral">        distribution shape parameters.</span></div>
<div class="line"><span class="lineno">  202</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  203</span><span class="stringliteral">        If a shape is to be held fixed (e.g. if it is known), the</span></div>
<div class="line"><span class="lineno">  204</span><span class="stringliteral">        lower and upper bounds may be equal. If a user-provided lower or upper</span></div>
<div class="line"><span class="lineno">  205</span><span class="stringliteral">        bound is beyond a bound of the domain for which the distribution is</span></div>
<div class="line"><span class="lineno">  206</span><span class="stringliteral">        defined, the bound of the distribution&#39;s domain will replace the</span></div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral">        user-provided value. Similarly, parameters which must be integral</span></div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">        will be constrained to integral values within the user-provided bounds.</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">    guess : dict or array_like, optional</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral">        If a dictionary, each key is the name of a parameter of the</span></div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">        distribution, and the corresponding value is a guess for the value</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">        of the parameter.</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">        If a sequence, element *i* is a guess for the *i*\ th parameter of the</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral">        distribution. In this case, guesses for *all* distribution shape</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">        parameters must be provided.</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">        If `guess` is not provided, guesses for the decision variables will</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">        not be passed to the optimizer. If `guess` is provided, guesses for</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">        any missing parameters will be set at the mean of the lower and</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">        upper bounds. Guesses for parameters which must be integral will be</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">        rounded to integral values, and guesses that lie outside the</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">        intersection of the user-provided bounds and the domain of the</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">        distribution will be clipped.</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">    optimizer : callable, optional</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">        `optimizer` is a callable that accepts the following positional</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">        argument.</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">        fun : callable</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">            The objective function to be optimized. `fun` accepts one argument</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral">            ``x``, candidate shape parameters of the distribution, and returns</span></div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">            the negative log-likelihood function given ``x``, `dist`, and the</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">            provided `data`.</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">            The job of `optimizer` is to find values of the decision variables</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">            that minimizes `fun`.</span></div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">        `optimizer` must also accepts the following keyword argument.</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        bounds : sequence of tuples</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">            The bounds on values of the decision variables; each element will</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">            be a tuple containing the lower and upper bound on a decision</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">            variable.</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral">        If `guess` is provided, `optimizer` must also accept the following</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">        keyword argument.</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">        x0 : array_like</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">            The guesses for each decision variable.</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">        If the distribution has any shape parameters that must be integral or</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">        if the distribution is discrete and the location parameter is not</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">        fixed, `optimizer` must also accept the following keyword argument.</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">        integrality : array_like of bools</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">            For each decision variable, True if the decision variable is</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">            must be constrained to integer values and False if the decision</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">            variable is continuous.</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">        `optimizer` must return an object, such as an instance of</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">        `scipy.optimize.OptimizeResult`, which holds the optimal values of</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">        the decision variables in an attribute ``x``. If attributes</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">        ``fun``, ``status``, or ``message`` are provided, they will be</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">        included in the result object returned by `fit`.</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral">    result : `~scipy.stats._result_classes.FitResult`</span></div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">        An object with the following fields.</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">        params : namedtuple</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral">            A namedtuple containing the maximum likelihood estimates of the</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral">            shape parameters, location, and (if applicable) scale of the</span></div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">            distribution.</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral">        success : bool or None</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">            Whether the optimizer considered the optimization to terminate</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">            successfully or not.</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral">        message : str or None</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">            Any status message provided by the optimizer.</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">        The object has the following method:</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">        nllf(params=None, data=None)</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">            By default, the negative log-likehood function at the fitted</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">            `params` for the given `data`. Accepts a tuple containing</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">            alternative shapes, location, and scale of the distribution and</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">            an array of alternative data.</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">        plot(ax=None)</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">            Superposes the PDF/PMF of the fitted distribution over a normalized</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">            histogram of the data.</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">    rv_continuous,  rv_discrete</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">    Optimization is more likely to converge to the maximum likelihood estimate</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">    when the user provides tight bounds containing the maximum likelihood</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">    estimate. For example, when fitting a binomial distribution to data, the</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">    number of experiments underlying each sample may be known, in which case</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">    the corresponding shape parameter ``n`` can be fixed.</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    Suppose we wish to fit a distribution to the following data.</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">    &gt;&gt;&gt; from scipy import stats</span></div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">    &gt;&gt;&gt; rng = np.random.default_rng()</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">    &gt;&gt;&gt; dist = stats.nbinom</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">    &gt;&gt;&gt; shapes = (5, 0.5)</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">    &gt;&gt;&gt; data = dist.rvs(*shapes, size=1000, random_state=rng)</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">    Suppose we do not know how the data were generated, but we suspect that</span></div>
<div class="line"><span class="lineno">  316</span><span class="stringliteral">    it follows a negative binomial distribution with parameters *n* and *p*\.</span></div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral">    (See `scipy.stats.nbinom`.) We believe that the parameter *n* was fewer</span></div>
<div class="line"><span class="lineno">  318</span><span class="stringliteral">    than 30, and we know that the parameter *p* must lie on the interval</span></div>
<div class="line"><span class="lineno">  319</span><span class="stringliteral">    [0, 1]. We record this information in a variable `bounds` and pass</span></div>
<div class="line"><span class="lineno">  320</span><span class="stringliteral">    this information to `fit`.</span></div>
<div class="line"><span class="lineno">  321</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  322</span><span class="stringliteral">    &gt;&gt;&gt; bounds = [(0, 30), (0, 1)]</span></div>
<div class="line"><span class="lineno">  323</span><span class="stringliteral">    &gt;&gt;&gt; res = stats.fit(dist, data, bounds)</span></div>
<div class="line"><span class="lineno">  324</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  325</span><span class="stringliteral">    `fit` searches within the user-specified `bounds` for the</span></div>
<div class="line"><span class="lineno">  326</span><span class="stringliteral">    values that best match the data (in the sense of maximum likelihood</span></div>
<div class="line"><span class="lineno">  327</span><span class="stringliteral">    estimation). In this case, it found shape values similar to those</span></div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral">    from which the data were actually generated.</span></div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">    &gt;&gt;&gt; res.params</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral">    FitParams(n=5.0, p=0.5028157644634368, loc=0.0)  # may vary</span></div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral">    We can visualize the results by superposing the probability mass function</span></div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral">    of the distribution (with the shapes fit to the data) over a normalized</span></div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">    histogram of the data.</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral">    &gt;&gt;&gt; import matplotlib.pyplot as plt  # matplotlib must be installed to plot</span></div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral">    &gt;&gt;&gt; res.plot()</span></div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral">    &gt;&gt;&gt; plt.show()</span></div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral">    Note that the estimate for *n* was exactly integral; this is because</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral">    the domain of the `nbinom` PMF includes only integral *n*, and the `nbinom`</span></div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral">    object &quot;knows&quot; that. `nbinom` also knows that the shape *p* must be a</span></div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">    value between 0 and 1. In such a case - when the domain of the distribution</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral">    with respect to a parameter is finite - we are not required to specify</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">    bounds for the parameter.</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral">    &gt;&gt;&gt; bounds = {&#39;n&#39;: (0, 30)}  # omit parameter p using a `dict`</span></div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">    &gt;&gt;&gt; res2 = stats.fit(dist, data, bounds)</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">    &gt;&gt;&gt; res2.params</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">    FitParams(n=5.0, p=0.5016492009232932, loc=0.0)  # may vary</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral">    If we wish to force the distribution to be fit with *n* fixed at 6, we can</span></div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">    set both the lower and upper bounds on *n* to 6. Note, however, that the</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">    value of the objective function being optimized is typically worse (higher)</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral">    in this case.</span></div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral">    &gt;&gt;&gt; bounds = {&#39;n&#39;: (6, 6)}  # fix parameter `n`</span></div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral">    &gt;&gt;&gt; res3 = stats.fit(dist, data, bounds)</span></div>
<div class="line"><span class="lineno">  360</span><span class="stringliteral">    &gt;&gt;&gt; res3.params</span></div>
<div class="line"><span class="lineno">  361</span><span class="stringliteral">    FitParams(n=6.0, p=0.5486556076755706, loc=0.0)  # may vary</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral">    &gt;&gt;&gt; res3.nllf() &gt; res.nllf()</span></div>
<div class="line"><span class="lineno">  363</span><span class="stringliteral">    True  # may vary</span></div>
<div class="line"><span class="lineno">  364</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  365</span><span class="stringliteral">    Note that the numerical results of the previous examples are typical, but</span></div>
<div class="line"><span class="lineno">  366</span><span class="stringliteral">    they may vary because the default optimizer used by `fit`,</span></div>
<div class="line"><span class="lineno">  367</span><span class="stringliteral">    `scipy.optimize.differential_evolution`, is stochastic. However, we can</span></div>
<div class="line"><span class="lineno">  368</span><span class="stringliteral">    customize the settings used by the optimizer to ensure reproducibility -</span></div>
<div class="line"><span class="lineno">  369</span><span class="stringliteral">    or even use a different optimizer entirely - using the `optimizer`</span></div>
<div class="line"><span class="lineno">  370</span><span class="stringliteral">    parameter.</span></div>
<div class="line"><span class="lineno">  371</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  372</span><span class="stringliteral">    &gt;&gt;&gt; from scipy.optimize import differential_evolution</span></div>
<div class="line"><span class="lineno">  373</span><span class="stringliteral">    &gt;&gt;&gt; rng = np.random.default_rng(767585560716548)</span></div>
<div class="line"><span class="lineno">  374</span><span class="stringliteral">    &gt;&gt;&gt; def optimizer(fun, bounds, *, integrality):</span></div>
<div class="line"><span class="lineno">  375</span><span class="stringliteral">    ...     return differential_evolution(fun, bounds, strategy=&#39;best2bin&#39;,</span></div>
<div class="line"><span class="lineno">  376</span><span class="stringliteral">    ...                                   seed=rng, integrality=integrality)</span></div>
<div class="line"><span class="lineno">  377</span><span class="stringliteral">    &gt;&gt;&gt; bounds = [(0, 30), (0, 1)]</span></div>
<div class="line"><span class="lineno">  378</span><span class="stringliteral">    &gt;&gt;&gt; res4 = stats.fit(dist, data, bounds, optimizer=optimizer)</span></div>
<div class="line"><span class="lineno">  379</span><span class="stringliteral">    &gt;&gt;&gt; res4.params</span></div>
<div class="line"><span class="lineno">  380</span><span class="stringliteral">    FitParams(n=5.0, p=0.5015183149259951, loc=0.0)</span></div>
<div class="line"><span class="lineno">  381</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  382</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  383</span>    <span class="comment"># --- Input Validation / Standardization --- #</span></div>
<div class="line"><span class="lineno">  384</span>    user_bounds = bounds</div>
<div class="line"><span class="lineno">  385</span>    user_guess = guess</div>
<div class="line"><span class="lineno">  386</span> </div>
<div class="line"><span class="lineno">  387</span>    <span class="comment"># distribution input validation and information collection</span></div>
<div class="line"><span class="lineno">  388</span>    <span class="keywordflow">if</span> hasattr(dist, <span class="stringliteral">&quot;pdf&quot;</span>):  <span class="comment"># can&#39;t use isinstance for types</span></div>
<div class="line"><span class="lineno">  389</span>        default_bounds = {<span class="stringliteral">&#39;loc&#39;</span>: (0, 0), <span class="stringliteral">&#39;scale&#39;</span>: (1, 1)}</div>
<div class="line"><span class="lineno">  390</span>        discrete = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  391</span>    <span class="keywordflow">elif</span> hasattr(dist, <span class="stringliteral">&quot;pmf&quot;</span>):</div>
<div class="line"><span class="lineno">  392</span>        default_bounds = {<span class="stringliteral">&#39;loc&#39;</span>: (0, 0)}</div>
<div class="line"><span class="lineno">  393</span>        discrete = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  394</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  395</span>        message = (<span class="stringliteral">&quot;`dist` must be an instance of `rv_continuous` &quot;</span></div>
<div class="line"><span class="lineno">  396</span>                   <span class="stringliteral">&quot;or `rv_discrete.`&quot;</span>)</div>
<div class="line"><span class="lineno">  397</span>        <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">  398</span> </div>
<div class="line"><span class="lineno">  399</span>    <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  400</span>        param_info = dist._param_info()</div>
<div class="line"><span class="lineno">  401</span>    <span class="keywordflow">except</span> AttributeError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  402</span>        message = (f<span class="stringliteral">&quot;Distribution `{dist.name}` is not yet supported by &quot;</span></div>
<div class="line"><span class="lineno">  403</span>                   <span class="stringliteral">&quot;`scipy.stats.fit` because shape information has &quot;</span></div>
<div class="line"><span class="lineno">  404</span>                   <span class="stringliteral">&quot;not been defined.&quot;</span>)</div>
<div class="line"><span class="lineno">  405</span>        <span class="keywordflow">raise</span> ValueError(message) <span class="keyword">from</span> e</div>
<div class="line"><span class="lineno">  406</span> </div>
<div class="line"><span class="lineno">  407</span>    <span class="comment"># data input validation</span></div>
<div class="line"><span class="lineno">  408</span>    data = np.asarray(data)</div>
<div class="line"><span class="lineno">  409</span>    <span class="keywordflow">if</span> data.ndim != 1:</div>
<div class="line"><span class="lineno">  410</span>        message = <span class="stringliteral">&quot;`data` must be exactly one-dimensional.&quot;</span></div>
<div class="line"><span class="lineno">  411</span>        <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">  412</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> (np.issubdtype(data.dtype, np.number)</div>
<div class="line"><span class="lineno">  413</span>            <span class="keywordflow">and</span> np.all(np.isfinite(data))):</div>
<div class="line"><span class="lineno">  414</span>        message = <span class="stringliteral">&quot;All elements of `data` must be finite numbers.&quot;</span></div>
<div class="line"><span class="lineno">  415</span>        <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">  416</span> </div>
<div class="line"><span class="lineno">  417</span>    <span class="comment"># bounds input validation and information collection</span></div>
<div class="line"><span class="lineno">  418</span>    n_params = len(param_info)</div>
<div class="line"><span class="lineno">  419</span>    n_shapes = n_params - (1 <span class="keywordflow">if</span> discrete <span class="keywordflow">else</span> 2)</div>
<div class="line"><span class="lineno">  420</span>    param_list = [param.name <span class="keywordflow">for</span> param <span class="keywordflow">in</span> param_info]</div>
<div class="line"><span class="lineno">  421</span>    param_names = <span class="stringliteral">&quot;, &quot;</span>.join(param_list)</div>
<div class="line"><span class="lineno">  422</span>    shape_names = <span class="stringliteral">&quot;, &quot;</span>.join(param_list[:n_shapes])</div>
<div class="line"><span class="lineno">  423</span> </div>
<div class="line"><span class="lineno">  424</span>    <span class="keywordflow">if</span> user_bounds <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  425</span>        user_bounds = {}</div>
<div class="line"><span class="lineno">  426</span> </div>
<div class="line"><span class="lineno">  427</span>    <span class="keywordflow">if</span> isinstance(user_bounds, dict):</div>
<div class="line"><span class="lineno">  428</span>        default_bounds.update(user_bounds)</div>
<div class="line"><span class="lineno">  429</span>        user_bounds = default_bounds</div>
<div class="line"><span class="lineno">  430</span>        user_bounds_array = np.empty((n_params, 2))</div>
<div class="line"><span class="lineno">  431</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(n_params):</div>
<div class="line"><span class="lineno">  432</span>            param_name = param_info[i].name</div>
<div class="line"><span class="lineno">  433</span>            user_bound = user_bounds.pop(param_name, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  434</span>            <span class="keywordflow">if</span> user_bound <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  435</span>                user_bound = param_info[i].domain</div>
<div class="line"><span class="lineno">  436</span>            user_bounds_array[i] = user_bound</div>
<div class="line"><span class="lineno">  437</span>        <span class="keywordflow">if</span> user_bounds:</div>
<div class="line"><span class="lineno">  438</span>            message = (<span class="stringliteral">&quot;Bounds provided for the following unrecognized &quot;</span></div>
<div class="line"><span class="lineno">  439</span>                       f<span class="stringliteral">&quot;parameters will be ignored: {set(user_bounds)}&quot;</span>)</div>
<div class="line"><span class="lineno">  440</span>            warnings.warn(message, RuntimeWarning, stacklevel=2)</div>
<div class="line"><span class="lineno">  441</span> </div>
<div class="line"><span class="lineno">  442</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  443</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  444</span>            user_bounds = np.asarray(user_bounds, dtype=float)</div>
<div class="line"><span class="lineno">  445</span>            <span class="keywordflow">if</span> user_bounds.size == 0:</div>
<div class="line"><span class="lineno">  446</span>                user_bounds = np.empty((0, 2))</div>
<div class="line"><span class="lineno">  447</span>        <span class="keywordflow">except</span> ValueError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  448</span>            message = (<span class="stringliteral">&quot;Each element of a `bounds` sequence must be a tuple &quot;</span></div>
<div class="line"><span class="lineno">  449</span>                       <span class="stringliteral">&quot;containing two elements: the lower and upper bound of &quot;</span></div>
<div class="line"><span class="lineno">  450</span>                       <span class="stringliteral">&quot;a distribution parameter.&quot;</span>)</div>
<div class="line"><span class="lineno">  451</span>            <span class="keywordflow">raise</span> ValueError(message) <span class="keyword">from</span> e</div>
<div class="line"><span class="lineno">  452</span>        <span class="keywordflow">if</span> (user_bounds.ndim != 2 <span class="keywordflow">or</span> user_bounds.shape[1] != 2):</div>
<div class="line"><span class="lineno">  453</span>            message = (<span class="stringliteral">&quot;Each element of `bounds` must be a tuple specifying &quot;</span></div>
<div class="line"><span class="lineno">  454</span>                       <span class="stringliteral">&quot;the lower and upper bounds of a shape parameter&quot;</span>)</div>
<div class="line"><span class="lineno">  455</span>            <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">  456</span>        <span class="keywordflow">if</span> user_bounds.shape[0] &lt; n_shapes:</div>
<div class="line"><span class="lineno">  457</span>            message = (f<span class="stringliteral">&quot;A `bounds` sequence must contain at least {n_shapes} &quot;</span></div>
<div class="line"><span class="lineno">  458</span>                       <span class="stringliteral">&quot;elements: tuples specifying the lower and upper &quot;</span></div>
<div class="line"><span class="lineno">  459</span>                       f<span class="stringliteral">&quot;bounds of all shape parameters {shape_names}.&quot;</span>)</div>
<div class="line"><span class="lineno">  460</span>            <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">  461</span>        <span class="keywordflow">if</span> user_bounds.shape[0] &gt; n_params:</div>
<div class="line"><span class="lineno">  462</span>            message = (<span class="stringliteral">&quot;A `bounds` sequence may not contain more than &quot;</span></div>
<div class="line"><span class="lineno">  463</span>                       f<span class="stringliteral">&quot;{n_params} elements: tuples specifying the lower and &quot;</span></div>
<div class="line"><span class="lineno">  464</span>                       <span class="stringliteral">&quot;upper bounds of distribution parameters &quot;</span></div>
<div class="line"><span class="lineno">  465</span>                       f<span class="stringliteral">&quot;{param_names}.&quot;</span>)</div>
<div class="line"><span class="lineno">  466</span>            <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">  467</span> </div>
<div class="line"><span class="lineno">  468</span>        user_bounds_array = np.empty((n_params, 2))</div>
<div class="line"><span class="lineno">  469</span>        user_bounds_array[n_shapes:] = list(default_bounds.values())</div>
<div class="line"><span class="lineno">  470</span>        user_bounds_array[:len(user_bounds)] = user_bounds</div>
<div class="line"><span class="lineno">  471</span> </div>
<div class="line"><span class="lineno">  472</span>    user_bounds = user_bounds_array</div>
<div class="line"><span class="lineno">  473</span>    validated_bounds = []</div>
<div class="line"><span class="lineno">  474</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(n_params):</div>
<div class="line"><span class="lineno">  475</span>        name = param_info[i].name</div>
<div class="line"><span class="lineno">  476</span>        user_bound = user_bounds_array[i]</div>
<div class="line"><span class="lineno">  477</span>        param_domain = param_info[i].domain</div>
<div class="line"><span class="lineno">  478</span>        integral = param_info[i].integrality</div>
<div class="line"><span class="lineno">  479</span>        combined = _combine_bounds(name, user_bound, param_domain, integral)</div>
<div class="line"><span class="lineno">  480</span>        validated_bounds.append(combined)</div>
<div class="line"><span class="lineno">  481</span> </div>
<div class="line"><span class="lineno">  482</span>    bounds = np.asarray(validated_bounds)</div>
<div class="line"><span class="lineno">  483</span>    integrality = [param.integrality <span class="keywordflow">for</span> param <span class="keywordflow">in</span> param_info]</div>
<div class="line"><span class="lineno">  484</span> </div>
<div class="line"><span class="lineno">  485</span>    <span class="comment"># guess input validation</span></div>
<div class="line"><span class="lineno">  486</span> </div>
<div class="line"><span class="lineno">  487</span>    <span class="keywordflow">if</span> user_guess <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  488</span>        guess_array = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  489</span>    <span class="keywordflow">elif</span> isinstance(user_guess, dict):</div>
<div class="line"><span class="lineno">  490</span>        default_guess = {param.name: np.mean(bound)</div>
<div class="line"><span class="lineno">  491</span>                         <span class="keywordflow">for</span> param, bound <span class="keywordflow">in</span> zip(param_info, bounds)}</div>
<div class="line"><span class="lineno">  492</span>        unrecognized = set(user_guess) - set(default_guess)</div>
<div class="line"><span class="lineno">  493</span>        <span class="keywordflow">if</span> unrecognized:</div>
<div class="line"><span class="lineno">  494</span>            message = (<span class="stringliteral">&quot;Guesses provided for the following unrecognized &quot;</span></div>
<div class="line"><span class="lineno">  495</span>                       f<span class="stringliteral">&quot;parameters will be ignored: {unrecognized}&quot;</span>)</div>
<div class="line"><span class="lineno">  496</span>            warnings.warn(message, RuntimeWarning, stacklevel=2)</div>
<div class="line"><span class="lineno">  497</span>        default_guess.update(user_guess)</div>
<div class="line"><span class="lineno">  498</span> </div>
<div class="line"><span class="lineno">  499</span>        message = (<span class="stringliteral">&quot;Each element of `guess` must be a scalar &quot;</span></div>
<div class="line"><span class="lineno">  500</span>                   <span class="stringliteral">&quot;guess for a distribution parameter.&quot;</span>)</div>
<div class="line"><span class="lineno">  501</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  502</span>            guess_array = np.asarray([default_guess[param.name]</div>
<div class="line"><span class="lineno">  503</span>                                      <span class="keywordflow">for</span> param <span class="keywordflow">in</span> param_info], dtype=float)</div>
<div class="line"><span class="lineno">  504</span>        <span class="keywordflow">except</span> ValueError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  505</span>            <span class="keywordflow">raise</span> ValueError(message) <span class="keyword">from</span> e</div>
<div class="line"><span class="lineno">  506</span> </div>
<div class="line"><span class="lineno">  507</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  508</span>        message = (<span class="stringliteral">&quot;Each element of `guess` must be a scalar &quot;</span></div>
<div class="line"><span class="lineno">  509</span>                   <span class="stringliteral">&quot;guess for a distribution parameter.&quot;</span>)</div>
<div class="line"><span class="lineno">  510</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  511</span>            user_guess = np.asarray(user_guess, dtype=float)</div>
<div class="line"><span class="lineno">  512</span>        <span class="keywordflow">except</span> ValueError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  513</span>            <span class="keywordflow">raise</span> ValueError(message) <span class="keyword">from</span> e</div>
<div class="line"><span class="lineno">  514</span>        <span class="keywordflow">if</span> user_guess.ndim != 1:</div>
<div class="line"><span class="lineno">  515</span>            <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">  516</span>        <span class="keywordflow">if</span> user_guess.shape[0] &lt; n_shapes:</div>
<div class="line"><span class="lineno">  517</span>            message = (f<span class="stringliteral">&quot;A `guess` sequence must contain at least {n_shapes} &quot;</span></div>
<div class="line"><span class="lineno">  518</span>                       <span class="stringliteral">&quot;elements: scalar guesses for the distribution shape &quot;</span></div>
<div class="line"><span class="lineno">  519</span>                       f<span class="stringliteral">&quot;parameters {shape_names}.&quot;</span>)</div>
<div class="line"><span class="lineno">  520</span>            <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">  521</span>        <span class="keywordflow">if</span> user_guess.shape[0] &gt; n_params:</div>
<div class="line"><span class="lineno">  522</span>            message = (<span class="stringliteral">&quot;A `guess` sequence may not contain more than &quot;</span></div>
<div class="line"><span class="lineno">  523</span>                       f<span class="stringliteral">&quot;{n_params} elements: scalar guesses for the &quot;</span></div>
<div class="line"><span class="lineno">  524</span>                       f<span class="stringliteral">&quot;distribution parameters {param_names}.&quot;</span>)</div>
<div class="line"><span class="lineno">  525</span>            <span class="keywordflow">raise</span> ValueError(message)</div>
<div class="line"><span class="lineno">  526</span> </div>
<div class="line"><span class="lineno">  527</span>        guess_array = np.mean(bounds, axis=1)</div>
<div class="line"><span class="lineno">  528</span>        guess_array[:len(user_guess)] = user_guess</div>
<div class="line"><span class="lineno">  529</span> </div>
<div class="line"><span class="lineno">  530</span>    <span class="keywordflow">if</span> guess_array <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  531</span>        guess_rounded = guess_array.copy()</div>
<div class="line"><span class="lineno">  532</span> </div>
<div class="line"><span class="lineno">  533</span>        guess_rounded[integrality] = np.round(guess_rounded[integrality])</div>
<div class="line"><span class="lineno">  534</span>        rounded = np.where(guess_rounded != guess_array)[0]</div>
<div class="line"><span class="lineno">  535</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> rounded:</div>
<div class="line"><span class="lineno">  536</span>            message = (f<span class="stringliteral">&quot;Guess for parameter `{param_info[i].name}` &quot;</span></div>
<div class="line"><span class="lineno">  537</span>                       f<span class="stringliteral">&quot;rounded from {guess_array[i]} to {guess_rounded[i]}.&quot;</span>)</div>
<div class="line"><span class="lineno">  538</span>            warnings.warn(message, RuntimeWarning, stacklevel=2)</div>
<div class="line"><span class="lineno">  539</span> </div>
<div class="line"><span class="lineno">  540</span>        guess_clipped = np.clip(guess_rounded, bounds[:, 0], bounds[:, 1])</div>
<div class="line"><span class="lineno">  541</span>        clipped = np.where(guess_clipped != guess_rounded)[0]</div>
<div class="line"><span class="lineno">  542</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> clipped:</div>
<div class="line"><span class="lineno">  543</span>            message = (f<span class="stringliteral">&quot;Guess for parameter `{param_info[i].name}` &quot;</span></div>
<div class="line"><span class="lineno">  544</span>                       f<span class="stringliteral">&quot;clipped from {guess_rounded[i]} to &quot;</span></div>
<div class="line"><span class="lineno">  545</span>                       f<span class="stringliteral">&quot;{guess_clipped[i]}.&quot;</span>)</div>
<div class="line"><span class="lineno">  546</span>            warnings.warn(message, RuntimeWarning, stacklevel=2)</div>
<div class="line"><span class="lineno">  547</span> </div>
<div class="line"><span class="lineno">  548</span>        guess = guess_clipped</div>
<div class="line"><span class="lineno">  549</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  550</span>        guess = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  551</span> </div>
<div class="line"><span class="lineno">  552</span>    <span class="comment"># --- MLE Fitting --- #</span></div>
<div class="line"><span class="lineno">  553</span>    <span class="keyword">def </span>nllf(free_params, data=data):  <span class="comment"># bind data NOW</span></div>
<div class="line"><span class="lineno">  554</span>        <span class="keyword">with</span> np.errstate(invalid=<span class="stringliteral">&#39;ignore&#39;</span>, divide=<span class="stringliteral">&#39;ignore&#39;</span>):</div>
<div class="line"><span class="lineno">  555</span>            <span class="keywordflow">return</span> dist._penalized_nnlf(free_params, data)</div>
<div class="line"><span class="lineno">  556</span> </div>
<div class="line"><span class="lineno">  557</span>    <span class="keyword">with</span> np.errstate(invalid=<span class="stringliteral">&#39;ignore&#39;</span>, divide=<span class="stringliteral">&#39;ignore&#39;</span>):</div>
<div class="line"><span class="lineno">  558</span>        kwds = {}</div>
<div class="line"><span class="lineno">  559</span>        <span class="keywordflow">if</span> bounds <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  560</span>            kwds[<span class="stringliteral">&#39;bounds&#39;</span>] = bounds</div>
<div class="line"><span class="lineno">  561</span>        <span class="keywordflow">if</span> np.any(integrality):</div>
<div class="line"><span class="lineno">  562</span>            kwds[<span class="stringliteral">&#39;integrality&#39;</span>] = integrality</div>
<div class="line"><span class="lineno">  563</span>        <span class="keywordflow">if</span> guess <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  564</span>            kwds[<span class="stringliteral">&#39;x0&#39;</span>] = guess</div>
<div class="line"><span class="lineno">  565</span>        res = optimizer(nllf, **kwds)</div>
<div class="line"><span class="lineno">  566</span> </div>
<div class="line"><span class="lineno">  567</span>    <span class="keywordflow">return</span> FitResult(dist, data, discrete, res)</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
