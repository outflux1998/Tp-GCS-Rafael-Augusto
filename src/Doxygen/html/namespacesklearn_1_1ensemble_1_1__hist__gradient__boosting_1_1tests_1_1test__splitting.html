<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.ensemble._hist_gradient_boosting.tests.test_splitting Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble.html">ensemble</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting.html">_hist_gradient_boosting</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html">test_splitting</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ad310153492baae2429d74e2cc07c5b9f" id="r_ad310153492baae2429d74e2cc07c5b9f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html#ad310153492baae2429d74e2cc07c5b9f">test_histogram_split</a> (n_bins)</td></tr>
<tr class="separator:ad310153492baae2429d74e2cc07c5b9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4be5a510f354b591a26a8d84f7853cd" id="r_ac4be5a510f354b591a26a8d84f7853cd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html#ac4be5a510f354b591a26a8d84f7853cd">test_gradient_and_hessian_sanity</a> (constant_hessian)</td></tr>
<tr class="separator:ac4be5a510f354b591a26a8d84f7853cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ee151c765de34292c1df51db20c22f3" id="r_a5ee151c765de34292c1df51db20c22f3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html#a5ee151c765de34292c1df51db20c22f3">test_split_indices</a> ()</td></tr>
<tr class="separator:a5ee151c765de34292c1df51db20c22f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a909241ed1f91cc6b0cc77245e7130baf" id="r_a909241ed1f91cc6b0cc77245e7130baf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html#a909241ed1f91cc6b0cc77245e7130baf">test_min_gain_to_split</a> ()</td></tr>
<tr class="separator:a909241ed1f91cc6b0cc77245e7130baf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa91cd6de14938e8065244b51795ad524" id="r_aa91cd6de14938e8065244b51795ad524"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html#aa91cd6de14938e8065244b51795ad524">test_splitting_missing_values</a> (X_binned, all_gradients, has_missing_values, n_bins_non_missing, expected_split_on_nan, expected_bin_idx, expected_go_to_left)</td></tr>
<tr class="separator:aa91cd6de14938e8065244b51795ad524"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63cb757794d800fd21aec403130cc0ce" id="r_a63cb757794d800fd21aec403130cc0ce"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html#a63cb757794d800fd21aec403130cc0ce">test_splitting_categorical_cat_smooth</a> (X_binned, has_missing_values, n_bins_non_missing)</td></tr>
<tr class="separator:a63cb757794d800fd21aec403130cc0ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed260b9acbf0091d1c5241efcbbd6f21" id="r_aed260b9acbf0091d1c5241efcbbd6f21"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html#aed260b9acbf0091d1c5241efcbbd6f21">_assert_categories_equals_bitset</a> (categories, bitset)</td></tr>
<tr class="separator:aed260b9acbf0091d1c5241efcbbd6f21"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ec2569f446f6e560f4c8c42eb6e068c" id="r_a5ec2569f446f6e560f4c8c42eb6e068c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html#a5ec2569f446f6e560f4c8c42eb6e068c">test_splitting_categorical_sanity</a> (X_binned, all_gradients, expected_categories_left, n_bins_non_missing, missing_values_bin_idx, has_missing_values, expected_missing_go_to_left)</td></tr>
<tr class="separator:a5ec2569f446f6e560f4c8c42eb6e068c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac357a16a913fa0ea1c4f623f78e04223" id="r_ac357a16a913fa0ea1c4f623f78e04223"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html#ac357a16a913fa0ea1c4f623f78e04223">test_split_interaction_constraints</a> ()</td></tr>
<tr class="separator:ac357a16a913fa0ea1c4f623f78e04223"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a696792ace59fb1296104a64e0cbd66bc" id="r_a696792ace59fb1296104a64e0cbd66bc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__splitting.html#a696792ace59fb1296104a64e0cbd66bc">n_threads</a> = _openmp_effective_n_threads()</td></tr>
<tr class="separator:a696792ace59fb1296104a64e0cbd66bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="aed260b9acbf0091d1c5241efcbbd6f21" name="aed260b9acbf0091d1c5241efcbbd6f21"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aed260b9acbf0091d1c5241efcbbd6f21">&#9670;&#160;</a></span>_assert_categories_equals_bitset()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting._assert_categories_equals_bitset </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>categories</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>bitset</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  659</span><span class="keyword">def </span>_assert_categories_equals_bitset(categories, bitset):</div>
<div class="line"><span class="lineno">  660</span>    <span class="comment"># assert that the bitset exactly corresponds to the categories</span></div>
<div class="line"><span class="lineno">  661</span>    <span class="comment"># bitset is assumed to be an array of 8 uint32 elements</span></div>
<div class="line"><span class="lineno">  662</span> </div>
<div class="line"><span class="lineno">  663</span>    <span class="comment"># form bitset from threshold</span></div>
<div class="line"><span class="lineno">  664</span>    expected_bitset = np.zeros(8, dtype=np.uint32)</div>
<div class="line"><span class="lineno">  665</span>    <span class="keywordflow">for</span> cat <span class="keywordflow">in</span> categories:</div>
<div class="line"><span class="lineno">  666</span>        idx = cat // 32</div>
<div class="line"><span class="lineno">  667</span>        shift = cat % 32</div>
<div class="line"><span class="lineno">  668</span>        expected_bitset[idx] |= 1 &lt;&lt; shift</div>
<div class="line"><span class="lineno">  669</span> </div>
<div class="line"><span class="lineno">  670</span>    <span class="comment"># check for equality</span></div>
<div class="line"><span class="lineno">  671</span>    assert_array_equal(expected_bitset, bitset)</div>
<div class="line"><span class="lineno">  672</span> </div>
<div class="line"><span class="lineno">  673</span> </div>
<div class="line"><span class="lineno">  674</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  675</span>    <span class="stringliteral">&quot;X_binned, all_gradients, expected_categories_left, n_bins_non_missing,&quot;</span></div>
<div class="line"><span class="lineno">  676</span>    <span class="stringliteral">&quot;missing_values_bin_idx, has_missing_values, expected_missing_go_to_left&quot;</span>,</div>
<div class="line"><span class="lineno">  677</span>    [</div>
<div class="line"><span class="lineno">  678</span>        <span class="comment"># 4 categories</span></div>
<div class="line"><span class="lineno">  679</span>        (</div>
<div class="line"><span class="lineno">  680</span>            [0, 1, 2, 3] * 11,  <span class="comment"># X_binned</span></div>
<div class="line"><span class="lineno">  681</span>            [10, 1, 10, 10] * 11,  <span class="comment"># all_gradients</span></div>
<div class="line"><span class="lineno">  682</span>            [1],  <span class="comment"># expected_categories_left</span></div>
<div class="line"><span class="lineno">  683</span>            4,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  684</span>            4,  <span class="comment"># missing_values_bin_idx</span></div>
<div class="line"><span class="lineno">  685</span>            <span class="keyword">False</span>,  <span class="comment"># has_missing_values</span></div>
<div class="line"><span class="lineno">  686</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  687</span>        ),  <span class="comment"># expected_missing_go_to_left, unchecked</span></div>
<div class="line"><span class="lineno">  688</span>        <span class="comment"># Make sure that the categories that are on the right (second half) of</span></div>
<div class="line"><span class="lineno">  689</span>        <span class="comment"># the sorted categories array can still go in the left child. In this</span></div>
<div class="line"><span class="lineno">  690</span>        <span class="comment"># case, the best split was found when scanning from right to left.</span></div>
<div class="line"><span class="lineno">  691</span>        (</div>
<div class="line"><span class="lineno">  692</span>            [0, 1, 2, 3] * 11,  <span class="comment"># X_binned</span></div>
<div class="line"><span class="lineno">  693</span>            [10, 10, 10, 1] * 11,  <span class="comment"># all_gradients</span></div>
<div class="line"><span class="lineno">  694</span>            [3],  <span class="comment"># expected_categories_left</span></div>
<div class="line"><span class="lineno">  695</span>            4,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  696</span>            4,  <span class="comment"># missing_values_bin_idx</span></div>
<div class="line"><span class="lineno">  697</span>            <span class="keyword">False</span>,  <span class="comment"># has_missing_values</span></div>
<div class="line"><span class="lineno">  698</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  699</span>        ),  <span class="comment"># expected_missing_go_to_left, unchecked</span></div>
<div class="line"><span class="lineno">  700</span>        <span class="comment"># categories that don&#39;t respect MIN_CAT_SUPPORT (cat 4) are always</span></div>
<div class="line"><span class="lineno">  701</span>        <span class="comment"># mapped to the right child</span></div>
<div class="line"><span class="lineno">  702</span>        (</div>
<div class="line"><span class="lineno">  703</span>            [0, 1, 2, 3] * 11 + [4] * 5,  <span class="comment"># X_binned</span></div>
<div class="line"><span class="lineno">  704</span>            [10, 10, 10, 1] * 11 + [10] * 5,  <span class="comment"># all_gradients</span></div>
<div class="line"><span class="lineno">  705</span>            [3],  <span class="comment"># expected_categories_left</span></div>
<div class="line"><span class="lineno">  706</span>            4,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  707</span>            4,  <span class="comment"># missing_values_bin_idx</span></div>
<div class="line"><span class="lineno">  708</span>            <span class="keyword">False</span>,  <span class="comment"># has_missing_values</span></div>
<div class="line"><span class="lineno">  709</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  710</span>        ),  <span class="comment"># expected_missing_go_to_left, unchecked</span></div>
<div class="line"><span class="lineno">  711</span>        <span class="comment"># categories that don&#39;t respect MIN_CAT_SUPPORT are always mapped to</span></div>
<div class="line"><span class="lineno">  712</span>        <span class="comment"># the right child: in this case a more sensible split could have been</span></div>
<div class="line"><span class="lineno">  713</span>        <span class="comment"># 3, 4 - 0, 1, 2</span></div>
<div class="line"><span class="lineno">  714</span>        <span class="comment"># But the split is still 3 - 0, 1, 2, 4. this is because we only scan</span></div>
<div class="line"><span class="lineno">  715</span>        <span class="comment"># up to the middle of the sorted category array (0, 1, 2, 3), and</span></div>
<div class="line"><span class="lineno">  716</span>        <span class="comment"># because we exclude cat 4 in this array.</span></div>
<div class="line"><span class="lineno">  717</span>        (</div>
<div class="line"><span class="lineno">  718</span>            [0, 1, 2, 3] * 11 + [4] * 5,  <span class="comment"># X_binned</span></div>
<div class="line"><span class="lineno">  719</span>            [10, 10, 10, 1] * 11 + [1] * 5,  <span class="comment"># all_gradients</span></div>
<div class="line"><span class="lineno">  720</span>            [3],  <span class="comment"># expected_categories_left</span></div>
<div class="line"><span class="lineno">  721</span>            4,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  722</span>            4,  <span class="comment"># missing_values_bin_idx</span></div>
<div class="line"><span class="lineno">  723</span>            <span class="keyword">False</span>,  <span class="comment"># has_missing_values</span></div>
<div class="line"><span class="lineno">  724</span>            <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  725</span>        ),  <span class="comment"># expected_missing_go_to_left, unchecked</span></div>
<div class="line"><span class="lineno">  726</span>        <span class="comment"># 4 categories with missing values that go to the right</span></div>
<div class="line"><span class="lineno">  727</span>        (</div>
<div class="line"><span class="lineno">  728</span>            [0, 1, 2] * 11 + [9] * 11,  <span class="comment"># X_binned</span></div>
<div class="line"><span class="lineno">  729</span>            [10, 1, 10] * 11 + [10] * 11,  <span class="comment"># all_gradients</span></div>
<div class="line"><span class="lineno">  730</span>            [1],  <span class="comment"># expected_categories_left</span></div>
<div class="line"><span class="lineno">  731</span>            3,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  732</span>            9,  <span class="comment"># missing_values_bin_idx</span></div>
<div class="line"><span class="lineno">  733</span>            <span class="keyword">True</span>,  <span class="comment"># has_missing_values</span></div>
<div class="line"><span class="lineno">  734</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  735</span>        ),  <span class="comment"># expected_missing_go_to_left</span></div>
<div class="line"><span class="lineno">  736</span>        <span class="comment"># 4 categories with missing values that go to the left</span></div>
<div class="line"><span class="lineno">  737</span>        (</div>
<div class="line"><span class="lineno">  738</span>            [0, 1, 2] * 11 + [9] * 11,  <span class="comment"># X_binned</span></div>
<div class="line"><span class="lineno">  739</span>            [10, 1, 10] * 11 + [1] * 11,  <span class="comment"># all_gradients</span></div>
<div class="line"><span class="lineno">  740</span>            [1, 9],  <span class="comment"># expected_categories_left</span></div>
<div class="line"><span class="lineno">  741</span>            3,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  742</span>            9,  <span class="comment"># missing_values_bin_idx</span></div>
<div class="line"><span class="lineno">  743</span>            <span class="keyword">True</span>,  <span class="comment"># has_missing_values</span></div>
<div class="line"><span class="lineno">  744</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  745</span>        ),  <span class="comment"># expected_missing_go_to_left</span></div>
<div class="line"><span class="lineno">  746</span>        <span class="comment"># split is on the missing value</span></div>
<div class="line"><span class="lineno">  747</span>        (</div>
<div class="line"><span class="lineno">  748</span>            [0, 1, 2, 3, 4] * 11 + [255] * 12,  <span class="comment"># X_binned</span></div>
<div class="line"><span class="lineno">  749</span>            [10, 10, 10, 10, 10] * 11 + [1] * 12,  <span class="comment"># all_gradients</span></div>
<div class="line"><span class="lineno">  750</span>            [255],  <span class="comment"># expected_categories_left</span></div>
<div class="line"><span class="lineno">  751</span>            5,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  752</span>            255,  <span class="comment"># missing_values_bin_idx</span></div>
<div class="line"><span class="lineno">  753</span>            <span class="keyword">True</span>,  <span class="comment"># has_missing_values</span></div>
<div class="line"><span class="lineno">  754</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  755</span>        ),  <span class="comment"># expected_missing_go_to_left</span></div>
<div class="line"><span class="lineno">  756</span>        <span class="comment"># split on even categories</span></div>
<div class="line"><span class="lineno">  757</span>        (</div>
<div class="line"><span class="lineno">  758</span>            list(range(60)) * 12,  <span class="comment"># X_binned</span></div>
<div class="line"><span class="lineno">  759</span>            [10, 1] * 360,  <span class="comment"># all_gradients</span></div>
<div class="line"><span class="lineno">  760</span>            list(range(1, 60, 2)),  <span class="comment"># expected_categories_left</span></div>
<div class="line"><span class="lineno">  761</span>            59,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  762</span>            59,  <span class="comment"># missing_values_bin_idx</span></div>
<div class="line"><span class="lineno">  763</span>            <span class="keyword">True</span>,  <span class="comment"># has_missing_values</span></div>
<div class="line"><span class="lineno">  764</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  765</span>        ),  <span class="comment"># expected_missing_go_to_left</span></div>
<div class="line"><span class="lineno">  766</span>        <span class="comment"># split on every 8 categories</span></div>
<div class="line"><span class="lineno">  767</span>        (</div>
<div class="line"><span class="lineno">  768</span>            list(range(256)) * 12,  <span class="comment"># X_binned</span></div>
<div class="line"><span class="lineno">  769</span>            [10, 10, 10, 10, 10, 10, 10, 1] * 384,  <span class="comment"># all_gradients</span></div>
<div class="line"><span class="lineno">  770</span>            list(range(7, 256, 8)),  <span class="comment"># expected_categories_left</span></div>
<div class="line"><span class="lineno">  771</span>            255,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  772</span>            255,  <span class="comment"># missing_values_bin_idx</span></div>
<div class="line"><span class="lineno">  773</span>            <span class="keyword">True</span>,  <span class="comment"># has_missing_values</span></div>
<div class="line"><span class="lineno">  774</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  775</span>        ),  <span class="comment"># expected_missing_go_to_left</span></div>
<div class="line"><span class="lineno">  776</span>    ],</div>
<div class="line"><span class="lineno">  777</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ac4be5a510f354b591a26a8d84f7853cd" name="ac4be5a510f354b591a26a8d84f7853cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac4be5a510f354b591a26a8d84f7853cd">&#9670;&#160;</a></span>test_gradient_and_hessian_sanity()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting.test_gradient_and_hessian_sanity </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>constant_hessian</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   97</span><span class="keyword">def </span>test_gradient_and_hessian_sanity(constant_hessian):</div>
<div class="line"><span class="lineno">   98</span>    <span class="comment"># This test checks that the values of gradients and hessians are</span></div>
<div class="line"><span class="lineno">   99</span>    <span class="comment"># consistent in different places:</span></div>
<div class="line"><span class="lineno">  100</span>    <span class="comment"># - in split_info: si.sum_gradient_left + si.sum_gradient_right must be</span></div>
<div class="line"><span class="lineno">  101</span>    <span class="comment">#   equal to the gradient at the node. Same for hessians.</span></div>
<div class="line"><span class="lineno">  102</span>    <span class="comment"># - in the histograms: summing &#39;sum_gradients&#39; over the bins must be</span></div>
<div class="line"><span class="lineno">  103</span>    <span class="comment">#   constant across all features, and those sums must be equal to the</span></div>
<div class="line"><span class="lineno">  104</span>    <span class="comment">#   node&#39;s gradient. Same for hessians.</span></div>
<div class="line"><span class="lineno">  105</span> </div>
<div class="line"><span class="lineno">  106</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno">  107</span> </div>
<div class="line"><span class="lineno">  108</span>    n_bins = 10</div>
<div class="line"><span class="lineno">  109</span>    n_features = 20</div>
<div class="line"><span class="lineno">  110</span>    n_samples = 500</div>
<div class="line"><span class="lineno">  111</span>    l2_regularization = 0.0</div>
<div class="line"><span class="lineno">  112</span>    min_hessian_to_split = 1e-3</div>
<div class="line"><span class="lineno">  113</span>    min_samples_leaf = 1</div>
<div class="line"><span class="lineno">  114</span>    min_gain_to_split = 0.0</div>
<div class="line"><span class="lineno">  115</span> </div>
<div class="line"><span class="lineno">  116</span>    X_binned = rng.randint(</div>
<div class="line"><span class="lineno">  117</span>        0, n_bins, size=(n_samples, n_features), dtype=X_BINNED_DTYPE</div>
<div class="line"><span class="lineno">  118</span>    )</div>
<div class="line"><span class="lineno">  119</span>    X_binned = np.asfortranarray(X_binned)</div>
<div class="line"><span class="lineno">  120</span>    sample_indices = np.arange(n_samples, dtype=np.uint32)</div>
<div class="line"><span class="lineno">  121</span>    all_gradients = rng.randn(n_samples).astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">  122</span>    sum_gradients = all_gradients.sum()</div>
<div class="line"><span class="lineno">  123</span>    <span class="keywordflow">if</span> constant_hessian:</div>
<div class="line"><span class="lineno">  124</span>        all_hessians = np.ones(1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  125</span>        sum_hessians = 1 * n_samples</div>
<div class="line"><span class="lineno">  126</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  127</span>        all_hessians = rng.lognormal(size=n_samples).astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">  128</span>        sum_hessians = all_hessians.sum()</div>
<div class="line"><span class="lineno">  129</span> </div>
<div class="line"><span class="lineno">  130</span>    builder = HistogramBuilder(</div>
<div class="line"><span class="lineno">  131</span>        X_binned, n_bins, all_gradients, all_hessians, constant_hessian, n_threads</div>
<div class="line"><span class="lineno">  132</span>    )</div>
<div class="line"><span class="lineno">  133</span>    n_bins_non_missing = np.array([n_bins - 1] * X_binned.shape[1], dtype=np.uint32)</div>
<div class="line"><span class="lineno">  134</span>    has_missing_values = np.array([<span class="keyword">False</span>] * X_binned.shape[1], dtype=np.uint8)</div>
<div class="line"><span class="lineno">  135</span>    monotonic_cst = np.array(</div>
<div class="line"><span class="lineno">  136</span>        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8</div>
<div class="line"><span class="lineno">  137</span>    )</div>
<div class="line"><span class="lineno">  138</span>    is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)</div>
<div class="line"><span class="lineno">  139</span>    missing_values_bin_idx = n_bins - 1</div>
<div class="line"><span class="lineno">  140</span>    splitter = Splitter(</div>
<div class="line"><span class="lineno">  141</span>        X_binned,</div>
<div class="line"><span class="lineno">  142</span>        n_bins_non_missing,</div>
<div class="line"><span class="lineno">  143</span>        missing_values_bin_idx,</div>
<div class="line"><span class="lineno">  144</span>        has_missing_values,</div>
<div class="line"><span class="lineno">  145</span>        is_categorical,</div>
<div class="line"><span class="lineno">  146</span>        monotonic_cst,</div>
<div class="line"><span class="lineno">  147</span>        l2_regularization,</div>
<div class="line"><span class="lineno">  148</span>        min_hessian_to_split,</div>
<div class="line"><span class="lineno">  149</span>        min_samples_leaf,</div>
<div class="line"><span class="lineno">  150</span>        min_gain_to_split,</div>
<div class="line"><span class="lineno">  151</span>        constant_hessian,</div>
<div class="line"><span class="lineno">  152</span>    )</div>
<div class="line"><span class="lineno">  153</span> </div>
<div class="line"><span class="lineno">  154</span>    hists_parent = builder.compute_histograms_brute(sample_indices)</div>
<div class="line"><span class="lineno">  155</span>    value_parent = compute_node_value(</div>
<div class="line"><span class="lineno">  156</span>        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization</div>
<div class="line"><span class="lineno">  157</span>    )</div>
<div class="line"><span class="lineno">  158</span>    si_parent = splitter.find_node_split(</div>
<div class="line"><span class="lineno">  159</span>        n_samples, hists_parent, sum_gradients, sum_hessians, value_parent</div>
<div class="line"><span class="lineno">  160</span>    )</div>
<div class="line"><span class="lineno">  161</span>    sample_indices_left, sample_indices_right, _ = splitter.split_indices(</div>
<div class="line"><span class="lineno">  162</span>        si_parent, sample_indices</div>
<div class="line"><span class="lineno">  163</span>    )</div>
<div class="line"><span class="lineno">  164</span> </div>
<div class="line"><span class="lineno">  165</span>    hists_left = builder.compute_histograms_brute(sample_indices_left)</div>
<div class="line"><span class="lineno">  166</span>    value_left = compute_node_value(</div>
<div class="line"><span class="lineno">  167</span>        si_parent.sum_gradient_left,</div>
<div class="line"><span class="lineno">  168</span>        si_parent.sum_hessian_left,</div>
<div class="line"><span class="lineno">  169</span>        -np.inf,</div>
<div class="line"><span class="lineno">  170</span>        np.inf,</div>
<div class="line"><span class="lineno">  171</span>        l2_regularization,</div>
<div class="line"><span class="lineno">  172</span>    )</div>
<div class="line"><span class="lineno">  173</span>    hists_right = builder.compute_histograms_brute(sample_indices_right)</div>
<div class="line"><span class="lineno">  174</span>    value_right = compute_node_value(</div>
<div class="line"><span class="lineno">  175</span>        si_parent.sum_gradient_right,</div>
<div class="line"><span class="lineno">  176</span>        si_parent.sum_hessian_right,</div>
<div class="line"><span class="lineno">  177</span>        -np.inf,</div>
<div class="line"><span class="lineno">  178</span>        np.inf,</div>
<div class="line"><span class="lineno">  179</span>        l2_regularization,</div>
<div class="line"><span class="lineno">  180</span>    )</div>
<div class="line"><span class="lineno">  181</span>    si_left = splitter.find_node_split(</div>
<div class="line"><span class="lineno">  182</span>        n_samples,</div>
<div class="line"><span class="lineno">  183</span>        hists_left,</div>
<div class="line"><span class="lineno">  184</span>        si_parent.sum_gradient_left,</div>
<div class="line"><span class="lineno">  185</span>        si_parent.sum_hessian_left,</div>
<div class="line"><span class="lineno">  186</span>        value_left,</div>
<div class="line"><span class="lineno">  187</span>    )</div>
<div class="line"><span class="lineno">  188</span>    si_right = splitter.find_node_split(</div>
<div class="line"><span class="lineno">  189</span>        n_samples,</div>
<div class="line"><span class="lineno">  190</span>        hists_right,</div>
<div class="line"><span class="lineno">  191</span>        si_parent.sum_gradient_right,</div>
<div class="line"><span class="lineno">  192</span>        si_parent.sum_hessian_right,</div>
<div class="line"><span class="lineno">  193</span>        value_right,</div>
<div class="line"><span class="lineno">  194</span>    )</div>
<div class="line"><span class="lineno">  195</span> </div>
<div class="line"><span class="lineno">  196</span>    <span class="comment"># make sure that si.sum_gradient_left + si.sum_gradient_right have their</span></div>
<div class="line"><span class="lineno">  197</span>    <span class="comment"># expected value, same for hessians</span></div>
<div class="line"><span class="lineno">  198</span>    <span class="keywordflow">for</span> si, indices <span class="keywordflow">in</span> (</div>
<div class="line"><span class="lineno">  199</span>        (si_parent, sample_indices),</div>
<div class="line"><span class="lineno">  200</span>        (si_left, sample_indices_left),</div>
<div class="line"><span class="lineno">  201</span>        (si_right, sample_indices_right),</div>
<div class="line"><span class="lineno">  202</span>    ):</div>
<div class="line"><span class="lineno">  203</span>        gradient = si.sum_gradient_right + si.sum_gradient_left</div>
<div class="line"><span class="lineno">  204</span>        expected_gradient = all_gradients[indices].sum()</div>
<div class="line"><span class="lineno">  205</span>        hessian = si.sum_hessian_right + si.sum_hessian_left</div>
<div class="line"><span class="lineno">  206</span>        <span class="keywordflow">if</span> constant_hessian:</div>
<div class="line"><span class="lineno">  207</span>            expected_hessian = indices.shape[0] * all_hessians[0]</div>
<div class="line"><span class="lineno">  208</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  209</span>            expected_hessian = all_hessians[indices].sum()</div>
<div class="line"><span class="lineno">  210</span> </div>
<div class="line"><span class="lineno">  211</span>        <span class="keyword">assert</span> np.isclose(gradient, expected_gradient)</div>
<div class="line"><span class="lineno">  212</span>        <span class="keyword">assert</span> np.isclose(hessian, expected_hessian)</div>
<div class="line"><span class="lineno">  213</span> </div>
<div class="line"><span class="lineno">  214</span>    <span class="comment"># make sure sum of gradients in histograms are the same for all features,</span></div>
<div class="line"><span class="lineno">  215</span>    <span class="comment"># and make sure they&#39;re equal to their expected value</span></div>
<div class="line"><span class="lineno">  216</span>    hists_parent = np.asarray(hists_parent, dtype=HISTOGRAM_DTYPE)</div>
<div class="line"><span class="lineno">  217</span>    hists_left = np.asarray(hists_left, dtype=HISTOGRAM_DTYPE)</div>
<div class="line"><span class="lineno">  218</span>    hists_right = np.asarray(hists_right, dtype=HISTOGRAM_DTYPE)</div>
<div class="line"><span class="lineno">  219</span>    <span class="keywordflow">for</span> hists, indices <span class="keywordflow">in</span> (</div>
<div class="line"><span class="lineno">  220</span>        (hists_parent, sample_indices),</div>
<div class="line"><span class="lineno">  221</span>        (hists_left, sample_indices_left),</div>
<div class="line"><span class="lineno">  222</span>        (hists_right, sample_indices_right),</div>
<div class="line"><span class="lineno">  223</span>    ):</div>
<div class="line"><span class="lineno">  224</span>        <span class="comment"># note: gradients and hessians have shape (n_features,),</span></div>
<div class="line"><span class="lineno">  225</span>        <span class="comment"># we&#39;re comparing them to *scalars*. This has the benefit of also</span></div>
<div class="line"><span class="lineno">  226</span>        <span class="comment"># making sure that all the entries are equal across features.</span></div>
<div class="line"><span class="lineno">  227</span>        gradients = hists[<span class="stringliteral">&quot;sum_gradients&quot;</span>].sum(axis=1)  <span class="comment"># shape = (n_features,)</span></div>
<div class="line"><span class="lineno">  228</span>        expected_gradient = all_gradients[indices].sum()  <span class="comment"># scalar</span></div>
<div class="line"><span class="lineno">  229</span>        hessians = hists[<span class="stringliteral">&quot;sum_hessians&quot;</span>].sum(axis=1)</div>
<div class="line"><span class="lineno">  230</span>        <span class="keywordflow">if</span> constant_hessian:</div>
<div class="line"><span class="lineno">  231</span>            <span class="comment"># 0 is not the actual hessian, but it&#39;s not computed in this case</span></div>
<div class="line"><span class="lineno">  232</span>            expected_hessian = 0.0</div>
<div class="line"><span class="lineno">  233</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  234</span>            expected_hessian = all_hessians[indices].sum()</div>
<div class="line"><span class="lineno">  235</span> </div>
<div class="line"><span class="lineno">  236</span>        <span class="keyword">assert</span> np.allclose(gradients, expected_gradient)</div>
<div class="line"><span class="lineno">  237</span>        <span class="keyword">assert</span> np.allclose(hessians, expected_hessian)</div>
<div class="line"><span class="lineno">  238</span> </div>
<div class="line"><span class="lineno">  239</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad310153492baae2429d74e2cc07c5b9f" name="ad310153492baae2429d74e2cc07c5b9f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad310153492baae2429d74e2cc07c5b9f">&#9670;&#160;</a></span>test_histogram_split()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting.test_histogram_split </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_bins</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   21</span><span class="keyword">def </span>test_histogram_split(n_bins):</div>
<div class="line"><span class="lineno">   22</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno">   23</span>    feature_idx = 0</div>
<div class="line"><span class="lineno">   24</span>    l2_regularization = 0</div>
<div class="line"><span class="lineno">   25</span>    min_hessian_to_split = 1e-3</div>
<div class="line"><span class="lineno">   26</span>    min_samples_leaf = 1</div>
<div class="line"><span class="lineno">   27</span>    min_gain_to_split = 0.0</div>
<div class="line"><span class="lineno">   28</span>    X_binned = np.asfortranarray(</div>
<div class="line"><span class="lineno">   29</span>        rng.randint(0, n_bins - 1, size=(int(1e4), 1)), dtype=X_BINNED_DTYPE</div>
<div class="line"><span class="lineno">   30</span>    )</div>
<div class="line"><span class="lineno">   31</span>    binned_feature = X_binned.T[feature_idx]</div>
<div class="line"><span class="lineno">   32</span>    sample_indices = np.arange(binned_feature.shape[0], dtype=np.uint32)</div>
<div class="line"><span class="lineno">   33</span>    ordered_hessians = np.ones_like(binned_feature, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">   34</span>    all_hessians = ordered_hessians</div>
<div class="line"><span class="lineno">   35</span>    sum_hessians = all_hessians.sum()</div>
<div class="line"><span class="lineno">   36</span>    hessians_are_constant = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">   37</span> </div>
<div class="line"><span class="lineno">   38</span>    <span class="keywordflow">for</span> true_bin <span class="keywordflow">in</span> range(1, n_bins - 2):</div>
<div class="line"><span class="lineno">   39</span>        <span class="keywordflow">for</span> sign <span class="keywordflow">in</span> [-1, 1]:</div>
<div class="line"><span class="lineno">   40</span>            ordered_gradients = np.full_like(binned_feature, sign, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">   41</span>            ordered_gradients[binned_feature &lt;= true_bin] *= -1</div>
<div class="line"><span class="lineno">   42</span>            all_gradients = ordered_gradients</div>
<div class="line"><span class="lineno">   43</span>            sum_gradients = all_gradients.sum()</div>
<div class="line"><span class="lineno">   44</span> </div>
<div class="line"><span class="lineno">   45</span>            builder = HistogramBuilder(</div>
<div class="line"><span class="lineno">   46</span>                X_binned,</div>
<div class="line"><span class="lineno">   47</span>                n_bins,</div>
<div class="line"><span class="lineno">   48</span>                all_gradients,</div>
<div class="line"><span class="lineno">   49</span>                all_hessians,</div>
<div class="line"><span class="lineno">   50</span>                hessians_are_constant,</div>
<div class="line"><span class="lineno">   51</span>                n_threads,</div>
<div class="line"><span class="lineno">   52</span>            )</div>
<div class="line"><span class="lineno">   53</span>            n_bins_non_missing = np.array(</div>
<div class="line"><span class="lineno">   54</span>                [n_bins - 1] * X_binned.shape[1], dtype=np.uint32</div>
<div class="line"><span class="lineno">   55</span>            )</div>
<div class="line"><span class="lineno">   56</span>            has_missing_values = np.array([<span class="keyword">False</span>] * X_binned.shape[1], dtype=np.uint8)</div>
<div class="line"><span class="lineno">   57</span>            monotonic_cst = np.array(</div>
<div class="line"><span class="lineno">   58</span>                [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8</div>
<div class="line"><span class="lineno">   59</span>            )</div>
<div class="line"><span class="lineno">   60</span>            is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)</div>
<div class="line"><span class="lineno">   61</span>            missing_values_bin_idx = n_bins - 1</div>
<div class="line"><span class="lineno">   62</span>            splitter = Splitter(</div>
<div class="line"><span class="lineno">   63</span>                X_binned,</div>
<div class="line"><span class="lineno">   64</span>                n_bins_non_missing,</div>
<div class="line"><span class="lineno">   65</span>                missing_values_bin_idx,</div>
<div class="line"><span class="lineno">   66</span>                has_missing_values,</div>
<div class="line"><span class="lineno">   67</span>                is_categorical,</div>
<div class="line"><span class="lineno">   68</span>                monotonic_cst,</div>
<div class="line"><span class="lineno">   69</span>                l2_regularization,</div>
<div class="line"><span class="lineno">   70</span>                min_hessian_to_split,</div>
<div class="line"><span class="lineno">   71</span>                min_samples_leaf,</div>
<div class="line"><span class="lineno">   72</span>                min_gain_to_split,</div>
<div class="line"><span class="lineno">   73</span>                hessians_are_constant,</div>
<div class="line"><span class="lineno">   74</span>            )</div>
<div class="line"><span class="lineno">   75</span> </div>
<div class="line"><span class="lineno">   76</span>            histograms = builder.compute_histograms_brute(sample_indices)</div>
<div class="line"><span class="lineno">   77</span>            value = compute_node_value(</div>
<div class="line"><span class="lineno">   78</span>                sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization</div>
<div class="line"><span class="lineno">   79</span>            )</div>
<div class="line"><span class="lineno">   80</span>            split_info = splitter.find_node_split(</div>
<div class="line"><span class="lineno">   81</span>                sample_indices.shape[0], histograms, sum_gradients, sum_hessians, value</div>
<div class="line"><span class="lineno">   82</span>            )</div>
<div class="line"><span class="lineno">   83</span> </div>
<div class="line"><span class="lineno">   84</span>            <span class="keyword">assert</span> split_info.bin_idx == true_bin</div>
<div class="line"><span class="lineno">   85</span>            <span class="keyword">assert</span> split_info.gain &gt;= 0</div>
<div class="line"><span class="lineno">   86</span>            <span class="keyword">assert</span> split_info.feature_idx == feature_idx</div>
<div class="line"><span class="lineno">   87</span>            <span class="keyword">assert</span> (</div>
<div class="line"><span class="lineno">   88</span>                split_info.n_samples_left + split_info.n_samples_right</div>
<div class="line"><span class="lineno">   89</span>                == sample_indices.shape[0]</div>
<div class="line"><span class="lineno">   90</span>            )</div>
<div class="line"><span class="lineno">   91</span>            <span class="comment"># Constant hessian: 1. per sample.</span></div>
<div class="line"><span class="lineno">   92</span>            <span class="keyword">assert</span> split_info.n_samples_left == split_info.sum_hessian_left</div>
<div class="line"><span class="lineno">   93</span> </div>
<div class="line"><span class="lineno">   94</span> </div>
<div class="line"><span class="lineno">   95</span><span class="preprocessor">@skip_if_32bit</span></div>
<div class="line"><span class="lineno">   96</span><span class="preprocessor">@pytest.mark.parametrize(&quot;constant_hessian&quot;, [True, False])</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="a909241ed1f91cc6b0cc77245e7130baf" name="a909241ed1f91cc6b0cc77245e7130baf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a909241ed1f91cc6b0cc77245e7130baf">&#9670;&#160;</a></span>test_min_gain_to_split()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting.test_min_gain_to_split </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  326</span><span class="keyword">def </span>test_min_gain_to_split():</div>
<div class="line"><span class="lineno">  327</span>    <span class="comment"># Try to split a pure node (all gradients are equal, same for hessians)</span></div>
<div class="line"><span class="lineno">  328</span>    <span class="comment"># with min_gain_to_split = 0 and make sure that the node is not split (best</span></div>
<div class="line"><span class="lineno">  329</span>    <span class="comment"># possible gain = -1). Note: before the strict inequality comparison, this</span></div>
<div class="line"><span class="lineno">  330</span>    <span class="comment"># test would fail because the node would be split with a gain of 0.</span></div>
<div class="line"><span class="lineno">  331</span>    rng = np.random.RandomState(42)</div>
<div class="line"><span class="lineno">  332</span>    l2_regularization = 0</div>
<div class="line"><span class="lineno">  333</span>    min_hessian_to_split = 0</div>
<div class="line"><span class="lineno">  334</span>    min_samples_leaf = 1</div>
<div class="line"><span class="lineno">  335</span>    min_gain_to_split = 0.0</div>
<div class="line"><span class="lineno">  336</span>    n_bins = 255</div>
<div class="line"><span class="lineno">  337</span>    n_samples = 100</div>
<div class="line"><span class="lineno">  338</span>    X_binned = np.asfortranarray(</div>
<div class="line"><span class="lineno">  339</span>        rng.randint(0, n_bins, size=(n_samples, 1)), dtype=X_BINNED_DTYPE</div>
<div class="line"><span class="lineno">  340</span>    )</div>
<div class="line"><span class="lineno">  341</span>    binned_feature = X_binned[:, 0]</div>
<div class="line"><span class="lineno">  342</span>    sample_indices = np.arange(n_samples, dtype=np.uint32)</div>
<div class="line"><span class="lineno">  343</span>    all_hessians = np.ones_like(binned_feature, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  344</span>    all_gradients = np.ones_like(binned_feature, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  345</span>    sum_gradients = all_gradients.sum()</div>
<div class="line"><span class="lineno">  346</span>    sum_hessians = all_hessians.sum()</div>
<div class="line"><span class="lineno">  347</span>    hessians_are_constant = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  348</span> </div>
<div class="line"><span class="lineno">  349</span>    builder = HistogramBuilder(</div>
<div class="line"><span class="lineno">  350</span>        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads</div>
<div class="line"><span class="lineno">  351</span>    )</div>
<div class="line"><span class="lineno">  352</span>    n_bins_non_missing = np.array([n_bins - 1] * X_binned.shape[1], dtype=np.uint32)</div>
<div class="line"><span class="lineno">  353</span>    has_missing_values = np.array([<span class="keyword">False</span>] * X_binned.shape[1], dtype=np.uint8)</div>
<div class="line"><span class="lineno">  354</span>    monotonic_cst = np.array(</div>
<div class="line"><span class="lineno">  355</span>        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8</div>
<div class="line"><span class="lineno">  356</span>    )</div>
<div class="line"><span class="lineno">  357</span>    is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)</div>
<div class="line"><span class="lineno">  358</span>    missing_values_bin_idx = n_bins - 1</div>
<div class="line"><span class="lineno">  359</span>    splitter = Splitter(</div>
<div class="line"><span class="lineno">  360</span>        X_binned,</div>
<div class="line"><span class="lineno">  361</span>        n_bins_non_missing,</div>
<div class="line"><span class="lineno">  362</span>        missing_values_bin_idx,</div>
<div class="line"><span class="lineno">  363</span>        has_missing_values,</div>
<div class="line"><span class="lineno">  364</span>        is_categorical,</div>
<div class="line"><span class="lineno">  365</span>        monotonic_cst,</div>
<div class="line"><span class="lineno">  366</span>        l2_regularization,</div>
<div class="line"><span class="lineno">  367</span>        min_hessian_to_split,</div>
<div class="line"><span class="lineno">  368</span>        min_samples_leaf,</div>
<div class="line"><span class="lineno">  369</span>        min_gain_to_split,</div>
<div class="line"><span class="lineno">  370</span>        hessians_are_constant,</div>
<div class="line"><span class="lineno">  371</span>    )</div>
<div class="line"><span class="lineno">  372</span> </div>
<div class="line"><span class="lineno">  373</span>    histograms = builder.compute_histograms_brute(sample_indices)</div>
<div class="line"><span class="lineno">  374</span>    value = compute_node_value(</div>
<div class="line"><span class="lineno">  375</span>        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization</div>
<div class="line"><span class="lineno">  376</span>    )</div>
<div class="line"><span class="lineno">  377</span>    split_info = splitter.find_node_split(</div>
<div class="line"><span class="lineno">  378</span>        n_samples, histograms, sum_gradients, sum_hessians, value</div>
<div class="line"><span class="lineno">  379</span>    )</div>
<div class="line"><span class="lineno">  380</span>    <span class="keyword">assert</span> split_info.gain == -1</div>
<div class="line"><span class="lineno">  381</span> </div>
<div class="line"><span class="lineno">  382</span> </div>
<div class="line"><span class="lineno">  383</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  384</span>    <span class="stringliteral">&quot;X_binned, all_gradients, has_missing_values, n_bins_non_missing, &quot;</span></div>
<div class="line"><span class="lineno">  385</span>    <span class="stringliteral">&quot; expected_split_on_nan, expected_bin_idx, expected_go_to_left&quot;</span>,</div>
<div class="line"><span class="lineno">  386</span>    [</div>
<div class="line"><span class="lineno">  387</span>        <span class="comment"># basic sanity check with no missing values: given the gradient</span></div>
<div class="line"><span class="lineno">  388</span>        <span class="comment"># values, the split must occur on bin_idx=3</span></div>
<div class="line"><span class="lineno">  389</span>        (</div>
<div class="line"><span class="lineno">  390</span>            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  <span class="comment"># X_binned</span></div>
<div class="line"><span class="lineno">  391</span>            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],  <span class="comment"># gradients</span></div>
<div class="line"><span class="lineno">  392</span>            <span class="keyword">False</span>,  <span class="comment"># no missing values</span></div>
<div class="line"><span class="lineno">  393</span>            10,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  394</span>            <span class="keyword">False</span>,  <span class="comment"># don&#39;t split on nans</span></div>
<div class="line"><span class="lineno">  395</span>            3,  <span class="comment"># expected_bin_idx</span></div>
<div class="line"><span class="lineno">  396</span>            <span class="stringliteral">&quot;not_applicable&quot;</span>,</div>
<div class="line"><span class="lineno">  397</span>        ),</div>
<div class="line"><span class="lineno">  398</span>        <span class="comment"># We replace 2 samples by NaNs (bin_idx=8)</span></div>
<div class="line"><span class="lineno">  399</span>        <span class="comment"># These 2 samples were mapped to the left node before, so they should</span></div>
<div class="line"><span class="lineno">  400</span>        <span class="comment"># be mapped to left node again</span></div>
<div class="line"><span class="lineno">  401</span>        <span class="comment"># Notice how the bin_idx threshold changes from 3 to 1.</span></div>
<div class="line"><span class="lineno">  402</span>        (</div>
<div class="line"><span class="lineno">  403</span>            [8, 0, 1, 8, 2, 3, 4, 5, 6, 7],  <span class="comment"># 8 &lt;=&gt; missing</span></div>
<div class="line"><span class="lineno">  404</span>            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],</div>
<div class="line"><span class="lineno">  405</span>            <span class="keyword">True</span>,  <span class="comment"># missing values</span></div>
<div class="line"><span class="lineno">  406</span>            8,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  407</span>            <span class="keyword">False</span>,  <span class="comment"># don&#39;t split on nans</span></div>
<div class="line"><span class="lineno">  408</span>            1,  <span class="comment"># cut on bin_idx=1</span></div>
<div class="line"><span class="lineno">  409</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  410</span>        ),  <span class="comment"># missing values go to left</span></div>
<div class="line"><span class="lineno">  411</span>        <span class="comment"># same as above, but with non-consecutive missing_values_bin</span></div>
<div class="line"><span class="lineno">  412</span>        (</div>
<div class="line"><span class="lineno">  413</span>            [9, 0, 1, 9, 2, 3, 4, 5, 6, 7],  <span class="comment"># 9 &lt;=&gt; missing</span></div>
<div class="line"><span class="lineno">  414</span>            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],</div>
<div class="line"><span class="lineno">  415</span>            <span class="keyword">True</span>,  <span class="comment"># missing values</span></div>
<div class="line"><span class="lineno">  416</span>            8,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  417</span>            <span class="keyword">False</span>,  <span class="comment"># don&#39;t split on nans</span></div>
<div class="line"><span class="lineno">  418</span>            1,  <span class="comment"># cut on bin_idx=1</span></div>
<div class="line"><span class="lineno">  419</span>            <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  420</span>        ),  <span class="comment"># missing values go to left</span></div>
<div class="line"><span class="lineno">  421</span>        <span class="comment"># this time replacing 2 samples that were on the right.</span></div>
<div class="line"><span class="lineno">  422</span>        (</div>
<div class="line"><span class="lineno">  423</span>            [0, 1, 2, 3, 8, 4, 8, 5, 6, 7],  <span class="comment"># 8 &lt;=&gt; missing</span></div>
<div class="line"><span class="lineno">  424</span>            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],</div>
<div class="line"><span class="lineno">  425</span>            <span class="keyword">True</span>,  <span class="comment"># missing values</span></div>
<div class="line"><span class="lineno">  426</span>            8,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  427</span>            <span class="keyword">False</span>,  <span class="comment"># don&#39;t split on nans</span></div>
<div class="line"><span class="lineno">  428</span>            3,  <span class="comment"># cut on bin_idx=3 (like in first case)</span></div>
<div class="line"><span class="lineno">  429</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  430</span>        ),  <span class="comment"># missing values go to right</span></div>
<div class="line"><span class="lineno">  431</span>        <span class="comment"># same as above, but with non-consecutive missing_values_bin</span></div>
<div class="line"><span class="lineno">  432</span>        (</div>
<div class="line"><span class="lineno">  433</span>            [0, 1, 2, 3, 9, 4, 9, 5, 6, 7],  <span class="comment"># 9 &lt;=&gt; missing</span></div>
<div class="line"><span class="lineno">  434</span>            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],</div>
<div class="line"><span class="lineno">  435</span>            <span class="keyword">True</span>,  <span class="comment"># missing values</span></div>
<div class="line"><span class="lineno">  436</span>            8,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  437</span>            <span class="keyword">False</span>,  <span class="comment"># don&#39;t split on nans</span></div>
<div class="line"><span class="lineno">  438</span>            3,  <span class="comment"># cut on bin_idx=3 (like in first case)</span></div>
<div class="line"><span class="lineno">  439</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  440</span>        ),  <span class="comment"># missing values go to right</span></div>
<div class="line"><span class="lineno">  441</span>        <span class="comment"># For the following cases, split_on_nans is True (we replace all of</span></div>
<div class="line"><span class="lineno">  442</span>        <span class="comment"># the samples with nans, instead of just 2).</span></div>
<div class="line"><span class="lineno">  443</span>        (</div>
<div class="line"><span class="lineno">  444</span>            [0, 1, 2, 3, 4, 4, 4, 4, 4, 4],  <span class="comment"># 4 &lt;=&gt; missing</span></div>
<div class="line"><span class="lineno">  445</span>            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],</div>
<div class="line"><span class="lineno">  446</span>            <span class="keyword">True</span>,  <span class="comment"># missing values</span></div>
<div class="line"><span class="lineno">  447</span>            4,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  448</span>            <span class="keyword">True</span>,  <span class="comment"># split on nans</span></div>
<div class="line"><span class="lineno">  449</span>            3,  <span class="comment"># cut on bin_idx=3</span></div>
<div class="line"><span class="lineno">  450</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  451</span>        ),  <span class="comment"># missing values go to right</span></div>
<div class="line"><span class="lineno">  452</span>        <span class="comment"># same as above, but with non-consecutive missing_values_bin</span></div>
<div class="line"><span class="lineno">  453</span>        (</div>
<div class="line"><span class="lineno">  454</span>            [0, 1, 2, 3, 9, 9, 9, 9, 9, 9],  <span class="comment"># 9 &lt;=&gt; missing</span></div>
<div class="line"><span class="lineno">  455</span>            [1, 1, 1, 1, 1, 1, 5, 5, 5, 5],</div>
<div class="line"><span class="lineno">  456</span>            <span class="keyword">True</span>,  <span class="comment"># missing values</span></div>
<div class="line"><span class="lineno">  457</span>            4,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  458</span>            <span class="keyword">True</span>,  <span class="comment"># split on nans</span></div>
<div class="line"><span class="lineno">  459</span>            3,  <span class="comment"># cut on bin_idx=3</span></div>
<div class="line"><span class="lineno">  460</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  461</span>        ),  <span class="comment"># missing values go to right</span></div>
<div class="line"><span class="lineno">  462</span>        (</div>
<div class="line"><span class="lineno">  463</span>            [6, 6, 6, 6, 0, 1, 2, 3, 4, 5],  <span class="comment"># 6 &lt;=&gt; missing</span></div>
<div class="line"><span class="lineno">  464</span>            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],</div>
<div class="line"><span class="lineno">  465</span>            <span class="keyword">True</span>,  <span class="comment"># missing values</span></div>
<div class="line"><span class="lineno">  466</span>            6,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  467</span>            <span class="keyword">True</span>,  <span class="comment"># split on nans</span></div>
<div class="line"><span class="lineno">  468</span>            5,  <span class="comment"># cut on bin_idx=5</span></div>
<div class="line"><span class="lineno">  469</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  470</span>        ),  <span class="comment"># missing values go to right</span></div>
<div class="line"><span class="lineno">  471</span>        <span class="comment"># same as above, but with non-consecutive missing_values_bin</span></div>
<div class="line"><span class="lineno">  472</span>        (</div>
<div class="line"><span class="lineno">  473</span>            [9, 9, 9, 9, 0, 1, 2, 3, 4, 5],  <span class="comment"># 9 &lt;=&gt; missing</span></div>
<div class="line"><span class="lineno">  474</span>            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],</div>
<div class="line"><span class="lineno">  475</span>            <span class="keyword">True</span>,  <span class="comment"># missing values</span></div>
<div class="line"><span class="lineno">  476</span>            6,  <span class="comment"># n_bins_non_missing</span></div>
<div class="line"><span class="lineno">  477</span>            <span class="keyword">True</span>,  <span class="comment"># split on nans</span></div>
<div class="line"><span class="lineno">  478</span>            5,  <span class="comment"># cut on bin_idx=5</span></div>
<div class="line"><span class="lineno">  479</span>            <span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  480</span>        ),  <span class="comment"># missing values go to right</span></div>
<div class="line"><span class="lineno">  481</span>    ],</div>
<div class="line"><span class="lineno">  482</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a5ee151c765de34292c1df51db20c22f3" name="a5ee151c765de34292c1df51db20c22f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ee151c765de34292c1df51db20c22f3">&#9670;&#160;</a></span>test_split_indices()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting.test_split_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  240</span><span class="keyword">def </span>test_split_indices():</div>
<div class="line"><span class="lineno">  241</span>    <span class="comment"># Check that split_indices returns the correct splits and that</span></div>
<div class="line"><span class="lineno">  242</span>    <span class="comment"># splitter.partition is consistent with what is returned.</span></div>
<div class="line"><span class="lineno">  243</span>    rng = np.random.RandomState(421)</div>
<div class="line"><span class="lineno">  244</span> </div>
<div class="line"><span class="lineno">  245</span>    n_bins = 5</div>
<div class="line"><span class="lineno">  246</span>    n_samples = 10</div>
<div class="line"><span class="lineno">  247</span>    l2_regularization = 0.0</div>
<div class="line"><span class="lineno">  248</span>    min_hessian_to_split = 1e-3</div>
<div class="line"><span class="lineno">  249</span>    min_samples_leaf = 1</div>
<div class="line"><span class="lineno">  250</span>    min_gain_to_split = 0.0</div>
<div class="line"><span class="lineno">  251</span> </div>
<div class="line"><span class="lineno">  252</span>    <span class="comment"># split will happen on feature 1 and on bin 3</span></div>
<div class="line"><span class="lineno">  253</span>    X_binned = [</div>
<div class="line"><span class="lineno">  254</span>        [0, 0],</div>
<div class="line"><span class="lineno">  255</span>        [0, 3],</div>
<div class="line"><span class="lineno">  256</span>        [0, 4],</div>
<div class="line"><span class="lineno">  257</span>        [0, 0],</div>
<div class="line"><span class="lineno">  258</span>        [0, 0],</div>
<div class="line"><span class="lineno">  259</span>        [0, 0],</div>
<div class="line"><span class="lineno">  260</span>        [0, 0],</div>
<div class="line"><span class="lineno">  261</span>        [0, 4],</div>
<div class="line"><span class="lineno">  262</span>        [0, 0],</div>
<div class="line"><span class="lineno">  263</span>        [0, 4],</div>
<div class="line"><span class="lineno">  264</span>    ]</div>
<div class="line"><span class="lineno">  265</span>    X_binned = np.asfortranarray(X_binned, dtype=X_BINNED_DTYPE)</div>
<div class="line"><span class="lineno">  266</span>    sample_indices = np.arange(n_samples, dtype=np.uint32)</div>
<div class="line"><span class="lineno">  267</span>    all_gradients = rng.randn(n_samples).astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">  268</span>    all_hessians = np.ones(1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  269</span>    sum_gradients = all_gradients.sum()</div>
<div class="line"><span class="lineno">  270</span>    sum_hessians = 1 * n_samples</div>
<div class="line"><span class="lineno">  271</span>    hessians_are_constant = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  272</span> </div>
<div class="line"><span class="lineno">  273</span>    builder = HistogramBuilder(</div>
<div class="line"><span class="lineno">  274</span>        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads</div>
<div class="line"><span class="lineno">  275</span>    )</div>
<div class="line"><span class="lineno">  276</span>    n_bins_non_missing = np.array([n_bins] * X_binned.shape[1], dtype=np.uint32)</div>
<div class="line"><span class="lineno">  277</span>    has_missing_values = np.array([<span class="keyword">False</span>] * X_binned.shape[1], dtype=np.uint8)</div>
<div class="line"><span class="lineno">  278</span>    monotonic_cst = np.array(</div>
<div class="line"><span class="lineno">  279</span>        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8</div>
<div class="line"><span class="lineno">  280</span>    )</div>
<div class="line"><span class="lineno">  281</span>    is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)</div>
<div class="line"><span class="lineno">  282</span>    missing_values_bin_idx = n_bins - 1</div>
<div class="line"><span class="lineno">  283</span>    splitter = Splitter(</div>
<div class="line"><span class="lineno">  284</span>        X_binned,</div>
<div class="line"><span class="lineno">  285</span>        n_bins_non_missing,</div>
<div class="line"><span class="lineno">  286</span>        missing_values_bin_idx,</div>
<div class="line"><span class="lineno">  287</span>        has_missing_values,</div>
<div class="line"><span class="lineno">  288</span>        is_categorical,</div>
<div class="line"><span class="lineno">  289</span>        monotonic_cst,</div>
<div class="line"><span class="lineno">  290</span>        l2_regularization,</div>
<div class="line"><span class="lineno">  291</span>        min_hessian_to_split,</div>
<div class="line"><span class="lineno">  292</span>        min_samples_leaf,</div>
<div class="line"><span class="lineno">  293</span>        min_gain_to_split,</div>
<div class="line"><span class="lineno">  294</span>        hessians_are_constant,</div>
<div class="line"><span class="lineno">  295</span>    )</div>
<div class="line"><span class="lineno">  296</span> </div>
<div class="line"><span class="lineno">  297</span>    <span class="keyword">assert</span> np.all(sample_indices == splitter.partition)</div>
<div class="line"><span class="lineno">  298</span> </div>
<div class="line"><span class="lineno">  299</span>    histograms = builder.compute_histograms_brute(sample_indices)</div>
<div class="line"><span class="lineno">  300</span>    value = compute_node_value(</div>
<div class="line"><span class="lineno">  301</span>        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization</div>
<div class="line"><span class="lineno">  302</span>    )</div>
<div class="line"><span class="lineno">  303</span>    si_root = splitter.find_node_split(</div>
<div class="line"><span class="lineno">  304</span>        n_samples, histograms, sum_gradients, sum_hessians, value</div>
<div class="line"><span class="lineno">  305</span>    )</div>
<div class="line"><span class="lineno">  306</span> </div>
<div class="line"><span class="lineno">  307</span>    <span class="comment"># sanity checks for best split</span></div>
<div class="line"><span class="lineno">  308</span>    <span class="keyword">assert</span> si_root.feature_idx == 1</div>
<div class="line"><span class="lineno">  309</span>    <span class="keyword">assert</span> si_root.bin_idx == 3</div>
<div class="line"><span class="lineno">  310</span> </div>
<div class="line"><span class="lineno">  311</span>    samples_left, samples_right, position_right = splitter.split_indices(</div>
<div class="line"><span class="lineno">  312</span>        si_root, splitter.partition</div>
<div class="line"><span class="lineno">  313</span>    )</div>
<div class="line"><span class="lineno">  314</span>    <span class="keyword">assert</span> set(samples_left) == set([0, 1, 3, 4, 5, 6, 8])</div>
<div class="line"><span class="lineno">  315</span>    <span class="keyword">assert</span> set(samples_right) == set([2, 7, 9])</div>
<div class="line"><span class="lineno">  316</span> </div>
<div class="line"><span class="lineno">  317</span>    <span class="keyword">assert</span> list(samples_left) == list(splitter.partition[:position_right])</div>
<div class="line"><span class="lineno">  318</span>    <span class="keyword">assert</span> list(samples_right) == list(splitter.partition[position_right:])</div>
<div class="line"><span class="lineno">  319</span> </div>
<div class="line"><span class="lineno">  320</span>    <span class="comment"># Check that the resulting split indices sizes are consistent with the</span></div>
<div class="line"><span class="lineno">  321</span>    <span class="comment"># count statistics anticipated when looking for the best split.</span></div>
<div class="line"><span class="lineno">  322</span>    <span class="keyword">assert</span> samples_left.shape[0] == si_root.n_samples_left</div>
<div class="line"><span class="lineno">  323</span>    <span class="keyword">assert</span> samples_right.shape[0] == si_root.n_samples_right</div>
<div class="line"><span class="lineno">  324</span> </div>
<div class="line"><span class="lineno">  325</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac357a16a913fa0ea1c4f623f78e04223" name="ac357a16a913fa0ea1c4f623f78e04223"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac357a16a913fa0ea1c4f623f78e04223">&#9670;&#160;</a></span>test_split_interaction_constraints()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting.test_split_interaction_constraints </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that allowed_features are respected.</pre> <div class="fragment"><div class="line"><span class="lineno">  861</span><span class="keyword">def </span>test_split_interaction_constraints():</div>
<div class="line"><span class="lineno">  862</span>    <span class="stringliteral">&quot;&quot;&quot;Check that allowed_features are respected.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  863</span>    n_features = 4</div>
<div class="line"><span class="lineno">  864</span>    <span class="comment"># features 1 and 2 are not allowed to be split on</span></div>
<div class="line"><span class="lineno">  865</span>    allowed_features = np.array([0, 3], dtype=np.uint32)</div>
<div class="line"><span class="lineno">  866</span>    n_bins = 5</div>
<div class="line"><span class="lineno">  867</span>    n_samples = 10</div>
<div class="line"><span class="lineno">  868</span>    l2_regularization = 0.0</div>
<div class="line"><span class="lineno">  869</span>    min_hessian_to_split = 1e-3</div>
<div class="line"><span class="lineno">  870</span>    min_samples_leaf = 1</div>
<div class="line"><span class="lineno">  871</span>    min_gain_to_split = 0.0</div>
<div class="line"><span class="lineno">  872</span> </div>
<div class="line"><span class="lineno">  873</span>    sample_indices = np.arange(n_samples, dtype=np.uint32)</div>
<div class="line"><span class="lineno">  874</span>    all_hessians = np.ones(1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  875</span>    sum_hessians = n_samples</div>
<div class="line"><span class="lineno">  876</span>    hessians_are_constant = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  877</span> </div>
<div class="line"><span class="lineno">  878</span>    split_features = []</div>
<div class="line"><span class="lineno">  879</span> </div>
<div class="line"><span class="lineno">  880</span>    <span class="comment"># The loop is to ensure that we split at least once on each allowed feature (0, 3).</span></div>
<div class="line"><span class="lineno">  881</span>    <span class="comment"># This is tracked by split_features and checked at the end.</span></div>
<div class="line"><span class="lineno">  882</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(10):</div>
<div class="line"><span class="lineno">  883</span>        rng = np.random.RandomState(919 + i)</div>
<div class="line"><span class="lineno">  884</span>        X_binned = np.asfortranarray(</div>
<div class="line"><span class="lineno">  885</span>            rng.randint(0, n_bins - 1, size=(n_samples, n_features)),</div>
<div class="line"><span class="lineno">  886</span>            dtype=X_BINNED_DTYPE,</div>
<div class="line"><span class="lineno">  887</span>        )</div>
<div class="line"><span class="lineno">  888</span>        X_binned = np.asfortranarray(X_binned, dtype=X_BINNED_DTYPE)</div>
<div class="line"><span class="lineno">  889</span> </div>
<div class="line"><span class="lineno">  890</span>        <span class="comment"># Make feature 1 very important</span></div>
<div class="line"><span class="lineno">  891</span>        all_gradients = (10 * X_binned[:, 1] + rng.randn(n_samples)).astype(G_H_DTYPE)</div>
<div class="line"><span class="lineno">  892</span>        sum_gradients = all_gradients.sum()</div>
<div class="line"><span class="lineno">  893</span> </div>
<div class="line"><span class="lineno">  894</span>        builder = HistogramBuilder(</div>
<div class="line"><span class="lineno">  895</span>            X_binned,</div>
<div class="line"><span class="lineno">  896</span>            n_bins,</div>
<div class="line"><span class="lineno">  897</span>            all_gradients,</div>
<div class="line"><span class="lineno">  898</span>            all_hessians,</div>
<div class="line"><span class="lineno">  899</span>            hessians_are_constant,</div>
<div class="line"><span class="lineno">  900</span>            n_threads,</div>
<div class="line"><span class="lineno">  901</span>        )</div>
<div class="line"><span class="lineno">  902</span>        n_bins_non_missing = np.array([n_bins] * X_binned.shape[1], dtype=np.uint32)</div>
<div class="line"><span class="lineno">  903</span>        has_missing_values = np.array([<span class="keyword">False</span>] * X_binned.shape[1], dtype=np.uint8)</div>
<div class="line"><span class="lineno">  904</span>        monotonic_cst = np.array(</div>
<div class="line"><span class="lineno">  905</span>            [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8</div>
<div class="line"><span class="lineno">  906</span>        )</div>
<div class="line"><span class="lineno">  907</span>        is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)</div>
<div class="line"><span class="lineno">  908</span>        missing_values_bin_idx = n_bins - 1</div>
<div class="line"><span class="lineno">  909</span>        splitter = Splitter(</div>
<div class="line"><span class="lineno">  910</span>            X_binned,</div>
<div class="line"><span class="lineno">  911</span>            n_bins_non_missing,</div>
<div class="line"><span class="lineno">  912</span>            missing_values_bin_idx,</div>
<div class="line"><span class="lineno">  913</span>            has_missing_values,</div>
<div class="line"><span class="lineno">  914</span>            is_categorical,</div>
<div class="line"><span class="lineno">  915</span>            monotonic_cst,</div>
<div class="line"><span class="lineno">  916</span>            l2_regularization,</div>
<div class="line"><span class="lineno">  917</span>            min_hessian_to_split,</div>
<div class="line"><span class="lineno">  918</span>            min_samples_leaf,</div>
<div class="line"><span class="lineno">  919</span>            min_gain_to_split,</div>
<div class="line"><span class="lineno">  920</span>            hessians_are_constant,</div>
<div class="line"><span class="lineno">  921</span>        )</div>
<div class="line"><span class="lineno">  922</span> </div>
<div class="line"><span class="lineno">  923</span>        <span class="keyword">assert</span> np.all(sample_indices == splitter.partition)</div>
<div class="line"><span class="lineno">  924</span> </div>
<div class="line"><span class="lineno">  925</span>        histograms = builder.compute_histograms_brute(sample_indices)</div>
<div class="line"><span class="lineno">  926</span>        value = compute_node_value(</div>
<div class="line"><span class="lineno">  927</span>            sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization</div>
<div class="line"><span class="lineno">  928</span>        )</div>
<div class="line"><span class="lineno">  929</span> </div>
<div class="line"><span class="lineno">  930</span>        <span class="comment"># with all features allowed, feature 1 should be split on as it is the most</span></div>
<div class="line"><span class="lineno">  931</span>        <span class="comment"># important one by construction of the gradients</span></div>
<div class="line"><span class="lineno">  932</span>        si_root = splitter.find_node_split(</div>
<div class="line"><span class="lineno">  933</span>            n_samples,</div>
<div class="line"><span class="lineno">  934</span>            histograms,</div>
<div class="line"><span class="lineno">  935</span>            sum_gradients,</div>
<div class="line"><span class="lineno">  936</span>            sum_hessians,</div>
<div class="line"><span class="lineno">  937</span>            value,</div>
<div class="line"><span class="lineno">  938</span>            allowed_features=<span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  939</span>        )</div>
<div class="line"><span class="lineno">  940</span>        <span class="keyword">assert</span> si_root.feature_idx == 1</div>
<div class="line"><span class="lineno">  941</span> </div>
<div class="line"><span class="lineno">  942</span>        <span class="comment"># only features 0 and 3 are allowed to be split on</span></div>
<div class="line"><span class="lineno">  943</span>        si_root = splitter.find_node_split(</div>
<div class="line"><span class="lineno">  944</span>            n_samples,</div>
<div class="line"><span class="lineno">  945</span>            histograms,</div>
<div class="line"><span class="lineno">  946</span>            sum_gradients,</div>
<div class="line"><span class="lineno">  947</span>            sum_hessians,</div>
<div class="line"><span class="lineno">  948</span>            value,</div>
<div class="line"><span class="lineno">  949</span>            allowed_features=allowed_features,</div>
<div class="line"><span class="lineno">  950</span>        )</div>
<div class="line"><span class="lineno">  951</span>        split_features.append(si_root.feature_idx)</div>
<div class="line"><span class="lineno">  952</span>        <span class="keyword">assert</span> si_root.feature_idx <span class="keywordflow">in</span> allowed_features</div>
<div class="line"><span class="lineno">  953</span> </div>
<div class="line"><span class="lineno">  954</span>    <span class="comment"># make sure feature 0 and feature 3 are split on in the constraint setting</span></div>
<div class="line"><span class="lineno">  955</span>    <span class="keyword">assert</span> set(allowed_features) == set(split_features)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a63cb757794d800fd21aec403130cc0ce" name="a63cb757794d800fd21aec403130cc0ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a63cb757794d800fd21aec403130cc0ce">&#9670;&#160;</a></span>test_splitting_categorical_cat_smooth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting.test_splitting_categorical_cat_smooth </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_binned</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_missing_values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_bins_non_missing</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  600</span>):</div>
<div class="line"><span class="lineno">  601</span>    <span class="comment"># Checks categorical splits are correct when the MIN_CAT_SUPPORT constraint</span></div>
<div class="line"><span class="lineno">  602</span>    <span class="comment"># isn&#39;t respected: there are no splits</span></div>
<div class="line"><span class="lineno">  603</span> </div>
<div class="line"><span class="lineno">  604</span>    n_bins = max(X_binned) + 1</div>
<div class="line"><span class="lineno">  605</span>    n_samples = len(X_binned)</div>
<div class="line"><span class="lineno">  606</span>    X_binned = np.array([X_binned], dtype=X_BINNED_DTYPE).T</div>
<div class="line"><span class="lineno">  607</span>    X_binned = np.asfortranarray(X_binned)</div>
<div class="line"><span class="lineno">  608</span> </div>
<div class="line"><span class="lineno">  609</span>    l2_regularization = 0.0</div>
<div class="line"><span class="lineno">  610</span>    min_hessian_to_split = 1e-3</div>
<div class="line"><span class="lineno">  611</span>    min_samples_leaf = 1</div>
<div class="line"><span class="lineno">  612</span>    min_gain_to_split = 0.0</div>
<div class="line"><span class="lineno">  613</span> </div>
<div class="line"><span class="lineno">  614</span>    sample_indices = np.arange(n_samples, dtype=np.uint32)</div>
<div class="line"><span class="lineno">  615</span>    all_gradients = np.ones(n_samples, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  616</span>    has_missing_values = np.array([has_missing_values], dtype=np.uint8)</div>
<div class="line"><span class="lineno">  617</span>    all_hessians = np.ones(1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  618</span>    sum_gradients = all_gradients.sum()</div>
<div class="line"><span class="lineno">  619</span>    sum_hessians = n_samples</div>
<div class="line"><span class="lineno">  620</span>    hessians_are_constant = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  621</span> </div>
<div class="line"><span class="lineno">  622</span>    builder = HistogramBuilder(</div>
<div class="line"><span class="lineno">  623</span>        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads</div>
<div class="line"><span class="lineno">  624</span>    )</div>
<div class="line"><span class="lineno">  625</span> </div>
<div class="line"><span class="lineno">  626</span>    n_bins_non_missing = np.array([n_bins_non_missing], dtype=np.uint32)</div>
<div class="line"><span class="lineno">  627</span>    monotonic_cst = np.array(</div>
<div class="line"><span class="lineno">  628</span>        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8</div>
<div class="line"><span class="lineno">  629</span>    )</div>
<div class="line"><span class="lineno">  630</span>    is_categorical = np.ones_like(monotonic_cst, dtype=np.uint8)</div>
<div class="line"><span class="lineno">  631</span>    missing_values_bin_idx = n_bins - 1</div>
<div class="line"><span class="lineno">  632</span> </div>
<div class="line"><span class="lineno">  633</span>    splitter = Splitter(</div>
<div class="line"><span class="lineno">  634</span>        X_binned,</div>
<div class="line"><span class="lineno">  635</span>        n_bins_non_missing,</div>
<div class="line"><span class="lineno">  636</span>        missing_values_bin_idx,</div>
<div class="line"><span class="lineno">  637</span>        has_missing_values,</div>
<div class="line"><span class="lineno">  638</span>        is_categorical,</div>
<div class="line"><span class="lineno">  639</span>        monotonic_cst,</div>
<div class="line"><span class="lineno">  640</span>        l2_regularization,</div>
<div class="line"><span class="lineno">  641</span>        min_hessian_to_split,</div>
<div class="line"><span class="lineno">  642</span>        min_samples_leaf,</div>
<div class="line"><span class="lineno">  643</span>        min_gain_to_split,</div>
<div class="line"><span class="lineno">  644</span>        hessians_are_constant,</div>
<div class="line"><span class="lineno">  645</span>    )</div>
<div class="line"><span class="lineno">  646</span> </div>
<div class="line"><span class="lineno">  647</span>    histograms = builder.compute_histograms_brute(sample_indices)</div>
<div class="line"><span class="lineno">  648</span>    value = compute_node_value(</div>
<div class="line"><span class="lineno">  649</span>        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization</div>
<div class="line"><span class="lineno">  650</span>    )</div>
<div class="line"><span class="lineno">  651</span>    split_info = splitter.find_node_split(</div>
<div class="line"><span class="lineno">  652</span>        n_samples, histograms, sum_gradients, sum_hessians, value</div>
<div class="line"><span class="lineno">  653</span>    )</div>
<div class="line"><span class="lineno">  654</span> </div>
<div class="line"><span class="lineno">  655</span>    <span class="comment"># no split found</span></div>
<div class="line"><span class="lineno">  656</span>    <span class="keyword">assert</span> split_info.gain == -1</div>
<div class="line"><span class="lineno">  657</span> </div>
<div class="line"><span class="lineno">  658</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5ec2569f446f6e560f4c8c42eb6e068c" name="a5ec2569f446f6e560f4c8c42eb6e068c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ec2569f446f6e560f4c8c42eb6e068c">&#9670;&#160;</a></span>test_splitting_categorical_sanity()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting.test_splitting_categorical_sanity </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_binned</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>all_gradients</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>expected_categories_left</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_bins_non_missing</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>missing_values_bin_idx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_missing_values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>expected_missing_go_to_left</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  786</span>):</div>
<div class="line"><span class="lineno">  787</span>    <span class="comment"># Tests various combinations of categorical splits</span></div>
<div class="line"><span class="lineno">  788</span> </div>
<div class="line"><span class="lineno">  789</span>    n_samples = len(X_binned)</div>
<div class="line"><span class="lineno">  790</span>    n_bins = max(X_binned) + 1</div>
<div class="line"><span class="lineno">  791</span> </div>
<div class="line"><span class="lineno">  792</span>    X_binned = np.array(X_binned, dtype=X_BINNED_DTYPE).reshape(-1, 1)</div>
<div class="line"><span class="lineno">  793</span>    X_binned = np.asfortranarray(X_binned)</div>
<div class="line"><span class="lineno">  794</span> </div>
<div class="line"><span class="lineno">  795</span>    l2_regularization = 0.0</div>
<div class="line"><span class="lineno">  796</span>    min_hessian_to_split = 1e-3</div>
<div class="line"><span class="lineno">  797</span>    min_samples_leaf = 1</div>
<div class="line"><span class="lineno">  798</span>    min_gain_to_split = 0.0</div>
<div class="line"><span class="lineno">  799</span> </div>
<div class="line"><span class="lineno">  800</span>    sample_indices = np.arange(n_samples, dtype=np.uint32)</div>
<div class="line"><span class="lineno">  801</span>    all_gradients = np.array(all_gradients, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  802</span>    all_hessians = np.ones(1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  803</span>    has_missing_values = np.array([has_missing_values], dtype=np.uint8)</div>
<div class="line"><span class="lineno">  804</span>    sum_gradients = all_gradients.sum()</div>
<div class="line"><span class="lineno">  805</span>    sum_hessians = n_samples</div>
<div class="line"><span class="lineno">  806</span>    hessians_are_constant = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  807</span> </div>
<div class="line"><span class="lineno">  808</span>    builder = HistogramBuilder(</div>
<div class="line"><span class="lineno">  809</span>        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads</div>
<div class="line"><span class="lineno">  810</span>    )</div>
<div class="line"><span class="lineno">  811</span> </div>
<div class="line"><span class="lineno">  812</span>    n_bins_non_missing = np.array([n_bins_non_missing], dtype=np.uint32)</div>
<div class="line"><span class="lineno">  813</span>    monotonic_cst = np.array(</div>
<div class="line"><span class="lineno">  814</span>        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8</div>
<div class="line"><span class="lineno">  815</span>    )</div>
<div class="line"><span class="lineno">  816</span>    is_categorical = np.ones_like(monotonic_cst, dtype=np.uint8)</div>
<div class="line"><span class="lineno">  817</span> </div>
<div class="line"><span class="lineno">  818</span>    splitter = Splitter(</div>
<div class="line"><span class="lineno">  819</span>        X_binned,</div>
<div class="line"><span class="lineno">  820</span>        n_bins_non_missing,</div>
<div class="line"><span class="lineno">  821</span>        missing_values_bin_idx,</div>
<div class="line"><span class="lineno">  822</span>        has_missing_values,</div>
<div class="line"><span class="lineno">  823</span>        is_categorical,</div>
<div class="line"><span class="lineno">  824</span>        monotonic_cst,</div>
<div class="line"><span class="lineno">  825</span>        l2_regularization,</div>
<div class="line"><span class="lineno">  826</span>        min_hessian_to_split,</div>
<div class="line"><span class="lineno">  827</span>        min_samples_leaf,</div>
<div class="line"><span class="lineno">  828</span>        min_gain_to_split,</div>
<div class="line"><span class="lineno">  829</span>        hessians_are_constant,</div>
<div class="line"><span class="lineno">  830</span>    )</div>
<div class="line"><span class="lineno">  831</span> </div>
<div class="line"><span class="lineno">  832</span>    histograms = builder.compute_histograms_brute(sample_indices)</div>
<div class="line"><span class="lineno">  833</span> </div>
<div class="line"><span class="lineno">  834</span>    value = compute_node_value(</div>
<div class="line"><span class="lineno">  835</span>        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization</div>
<div class="line"><span class="lineno">  836</span>    )</div>
<div class="line"><span class="lineno">  837</span>    split_info = splitter.find_node_split(</div>
<div class="line"><span class="lineno">  838</span>        n_samples, histograms, sum_gradients, sum_hessians, value</div>
<div class="line"><span class="lineno">  839</span>    )</div>
<div class="line"><span class="lineno">  840</span> </div>
<div class="line"><span class="lineno">  841</span>    <span class="keyword">assert</span> split_info.is_categorical</div>
<div class="line"><span class="lineno">  842</span>    <span class="keyword">assert</span> split_info.gain &gt; 0</div>
<div class="line"><span class="lineno">  843</span>    _assert_categories_equals_bitset(</div>
<div class="line"><span class="lineno">  844</span>        expected_categories_left, split_info.left_cat_bitset</div>
<div class="line"><span class="lineno">  845</span>    )</div>
<div class="line"><span class="lineno">  846</span>    <span class="keywordflow">if</span> has_missing_values:</div>
<div class="line"><span class="lineno">  847</span>        <span class="keyword">assert</span> split_info.missing_go_to_left == expected_missing_go_to_left</div>
<div class="line"><span class="lineno">  848</span>    <span class="comment"># If there is no missing value during training, the flag missing_go_to_left</span></div>
<div class="line"><span class="lineno">  849</span>    <span class="comment"># is set later in the grower.</span></div>
<div class="line"><span class="lineno">  850</span> </div>
<div class="line"><span class="lineno">  851</span>    <span class="comment"># make sure samples are split correctly</span></div>
<div class="line"><span class="lineno">  852</span>    samples_left, samples_right, _ = splitter.split_indices(</div>
<div class="line"><span class="lineno">  853</span>        split_info, splitter.partition</div>
<div class="line"><span class="lineno">  854</span>    )</div>
<div class="line"><span class="lineno">  855</span> </div>
<div class="line"><span class="lineno">  856</span>    left_mask = np.isin(X_binned.ravel(), expected_categories_left)</div>
<div class="line"><span class="lineno">  857</span>    assert_array_equal(sample_indices[left_mask], samples_left)</div>
<div class="line"><span class="lineno">  858</span>    assert_array_equal(sample_indices[~left_mask], samples_right)</div>
<div class="line"><span class="lineno">  859</span> </div>
<div class="line"><span class="lineno">  860</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa91cd6de14938e8065244b51795ad524" name="aa91cd6de14938e8065244b51795ad524"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa91cd6de14938e8065244b51795ad524">&#9670;&#160;</a></span>test_splitting_missing_values()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting.test_splitting_missing_values </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X_binned</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>all_gradients</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_missing_values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_bins_non_missing</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>expected_split_on_nan</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>expected_bin_idx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>expected_go_to_left</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  491</span>):</div>
<div class="line"><span class="lineno">  492</span>    <span class="comment"># Make sure missing values are properly supported.</span></div>
<div class="line"><span class="lineno">  493</span>    <span class="comment"># we build an artificial example with gradients such that the best split</span></div>
<div class="line"><span class="lineno">  494</span>    <span class="comment"># is on bin_idx=3, when there are no missing values.</span></div>
<div class="line"><span class="lineno">  495</span>    <span class="comment"># Then we introduce missing values and:</span></div>
<div class="line"><span class="lineno">  496</span>    <span class="comment">#   - make sure the chosen bin is correct (find_best_bin()): it&#39;s</span></div>
<div class="line"><span class="lineno">  497</span>    <span class="comment">#     still the same split, even though the index of the bin may change</span></div>
<div class="line"><span class="lineno">  498</span>    <span class="comment">#   - make sure the missing values are mapped to the correct child</span></div>
<div class="line"><span class="lineno">  499</span>    <span class="comment">#     (split_indices())</span></div>
<div class="line"><span class="lineno">  500</span> </div>
<div class="line"><span class="lineno">  501</span>    n_bins = max(X_binned) + 1</div>
<div class="line"><span class="lineno">  502</span>    n_samples = len(X_binned)</div>
<div class="line"><span class="lineno">  503</span>    l2_regularization = 0.0</div>
<div class="line"><span class="lineno">  504</span>    min_hessian_to_split = 1e-3</div>
<div class="line"><span class="lineno">  505</span>    min_samples_leaf = 1</div>
<div class="line"><span class="lineno">  506</span>    min_gain_to_split = 0.0</div>
<div class="line"><span class="lineno">  507</span> </div>
<div class="line"><span class="lineno">  508</span>    sample_indices = np.arange(n_samples, dtype=np.uint32)</div>
<div class="line"><span class="lineno">  509</span>    X_binned = np.array(X_binned, dtype=X_BINNED_DTYPE).reshape(-1, 1)</div>
<div class="line"><span class="lineno">  510</span>    X_binned = np.asfortranarray(X_binned)</div>
<div class="line"><span class="lineno">  511</span>    all_gradients = np.array(all_gradients, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  512</span>    has_missing_values = np.array([has_missing_values], dtype=np.uint8)</div>
<div class="line"><span class="lineno">  513</span>    all_hessians = np.ones(1, dtype=G_H_DTYPE)</div>
<div class="line"><span class="lineno">  514</span>    sum_gradients = all_gradients.sum()</div>
<div class="line"><span class="lineno">  515</span>    sum_hessians = 1 * n_samples</div>
<div class="line"><span class="lineno">  516</span>    hessians_are_constant = <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  517</span> </div>
<div class="line"><span class="lineno">  518</span>    builder = HistogramBuilder(</div>
<div class="line"><span class="lineno">  519</span>        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads</div>
<div class="line"><span class="lineno">  520</span>    )</div>
<div class="line"><span class="lineno">  521</span> </div>
<div class="line"><span class="lineno">  522</span>    n_bins_non_missing = np.array([n_bins_non_missing], dtype=np.uint32)</div>
<div class="line"><span class="lineno">  523</span>    monotonic_cst = np.array(</div>
<div class="line"><span class="lineno">  524</span>        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8</div>
<div class="line"><span class="lineno">  525</span>    )</div>
<div class="line"><span class="lineno">  526</span>    is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)</div>
<div class="line"><span class="lineno">  527</span>    missing_values_bin_idx = n_bins - 1</div>
<div class="line"><span class="lineno">  528</span>    splitter = Splitter(</div>
<div class="line"><span class="lineno">  529</span>        X_binned,</div>
<div class="line"><span class="lineno">  530</span>        n_bins_non_missing,</div>
<div class="line"><span class="lineno">  531</span>        missing_values_bin_idx,</div>
<div class="line"><span class="lineno">  532</span>        has_missing_values,</div>
<div class="line"><span class="lineno">  533</span>        is_categorical,</div>
<div class="line"><span class="lineno">  534</span>        monotonic_cst,</div>
<div class="line"><span class="lineno">  535</span>        l2_regularization,</div>
<div class="line"><span class="lineno">  536</span>        min_hessian_to_split,</div>
<div class="line"><span class="lineno">  537</span>        min_samples_leaf,</div>
<div class="line"><span class="lineno">  538</span>        min_gain_to_split,</div>
<div class="line"><span class="lineno">  539</span>        hessians_are_constant,</div>
<div class="line"><span class="lineno">  540</span>    )</div>
<div class="line"><span class="lineno">  541</span> </div>
<div class="line"><span class="lineno">  542</span>    histograms = builder.compute_histograms_brute(sample_indices)</div>
<div class="line"><span class="lineno">  543</span>    value = compute_node_value(</div>
<div class="line"><span class="lineno">  544</span>        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization</div>
<div class="line"><span class="lineno">  545</span>    )</div>
<div class="line"><span class="lineno">  546</span>    split_info = splitter.find_node_split(</div>
<div class="line"><span class="lineno">  547</span>        n_samples, histograms, sum_gradients, sum_hessians, value</div>
<div class="line"><span class="lineno">  548</span>    )</div>
<div class="line"><span class="lineno">  549</span> </div>
<div class="line"><span class="lineno">  550</span>    <span class="keyword">assert</span> split_info.bin_idx == expected_bin_idx</div>
<div class="line"><span class="lineno">  551</span>    <span class="keywordflow">if</span> has_missing_values:</div>
<div class="line"><span class="lineno">  552</span>        <span class="keyword">assert</span> split_info.missing_go_to_left == expected_go_to_left</div>
<div class="line"><span class="lineno">  553</span> </div>
<div class="line"><span class="lineno">  554</span>    split_on_nan = split_info.bin_idx == n_bins_non_missing[0] - 1</div>
<div class="line"><span class="lineno">  555</span>    <span class="keyword">assert</span> split_on_nan == expected_split_on_nan</div>
<div class="line"><span class="lineno">  556</span> </div>
<div class="line"><span class="lineno">  557</span>    <span class="comment"># Make sure the split is properly computed.</span></div>
<div class="line"><span class="lineno">  558</span>    <span class="comment"># This also make sure missing values are properly assigned to the correct</span></div>
<div class="line"><span class="lineno">  559</span>    <span class="comment"># child in split_indices()</span></div>
<div class="line"><span class="lineno">  560</span>    samples_left, samples_right, _ = splitter.split_indices(</div>
<div class="line"><span class="lineno">  561</span>        split_info, splitter.partition</div>
<div class="line"><span class="lineno">  562</span>    )</div>
<div class="line"><span class="lineno">  563</span> </div>
<div class="line"><span class="lineno">  564</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> expected_split_on_nan:</div>
<div class="line"><span class="lineno">  565</span>        <span class="comment"># When we don&#39;t split on nans, the split should always be the same.</span></div>
<div class="line"><span class="lineno">  566</span>        <span class="keyword">assert</span> set(samples_left) == set([0, 1, 2, 3])</div>
<div class="line"><span class="lineno">  567</span>        <span class="keyword">assert</span> set(samples_right) == set([4, 5, 6, 7, 8, 9])</div>
<div class="line"><span class="lineno">  568</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  569</span>        <span class="comment"># When we split on nans, samples with missing values are always mapped</span></div>
<div class="line"><span class="lineno">  570</span>        <span class="comment"># to the right child.</span></div>
<div class="line"><span class="lineno">  571</span>        missing_samples_indices = np.flatnonzero(</div>
<div class="line"><span class="lineno">  572</span>            np.array(X_binned) == missing_values_bin_idx</div>
<div class="line"><span class="lineno">  573</span>        )</div>
<div class="line"><span class="lineno">  574</span>        non_missing_samples_indices = np.flatnonzero(</div>
<div class="line"><span class="lineno">  575</span>            np.array(X_binned) != missing_values_bin_idx</div>
<div class="line"><span class="lineno">  576</span>        )</div>
<div class="line"><span class="lineno">  577</span> </div>
<div class="line"><span class="lineno">  578</span>        <span class="keyword">assert</span> set(samples_right) == set(missing_samples_indices)</div>
<div class="line"><span class="lineno">  579</span>        <span class="keyword">assert</span> set(samples_left) == set(non_missing_samples_indices)</div>
<div class="line"><span class="lineno">  580</span> </div>
<div class="line"><span class="lineno">  581</span> </div>
<div class="line"><span class="lineno">  582</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  583</span>    <span class="stringliteral">&quot;X_binned, has_missing_values, n_bins_non_missing, &quot;</span>,</div>
<div class="line"><span class="lineno">  584</span>    [</div>
<div class="line"><span class="lineno">  585</span>        <span class="comment"># one category</span></div>
<div class="line"><span class="lineno">  586</span>        ([0] * 20, <span class="keyword">False</span>, 1),</div>
<div class="line"><span class="lineno">  587</span>        <span class="comment"># all categories appear less than MIN_CAT_SUPPORT (hardcoded to 10)</span></div>
<div class="line"><span class="lineno">  588</span>        ([0] * 9 + [1] * 8, <span class="keyword">False</span>, 2),</div>
<div class="line"><span class="lineno">  589</span>        <span class="comment"># only one category appears more than MIN_CAT_SUPPORT</span></div>
<div class="line"><span class="lineno">  590</span>        ([0] * 12 + [1] * 8, <span class="keyword">False</span>, 2),</div>
<div class="line"><span class="lineno">  591</span>        <span class="comment"># missing values + category appear less than MIN_CAT_SUPPORT</span></div>
<div class="line"><span class="lineno">  592</span>        <span class="comment"># 9 is missing</span></div>
<div class="line"><span class="lineno">  593</span>        ([0] * 9 + [1] * 8 + [9] * 4, <span class="keyword">True</span>, 2),</div>
<div class="line"><span class="lineno">  594</span>        <span class="comment"># no non-missing category</span></div>
<div class="line"><span class="lineno">  595</span>        ([9] * 11, <span class="keyword">True</span>, 0),</div>
<div class="line"><span class="lineno">  596</span>    ],</div>
<div class="line"><span class="lineno">  597</span>)</div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a696792ace59fb1296104a64e0cbd66bc" name="a696792ace59fb1296104a64e0cbd66bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a696792ace59fb1296104a64e0cbd66bc">&#9670;&#160;</a></span>n_threads</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble._hist_gradient_boosting.tests.test_splitting.n_threads = _openmp_effective_n_threads()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
