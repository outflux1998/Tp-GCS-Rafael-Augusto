<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.manifold._locally_linear Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1manifold.html">manifold</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1manifold_1_1__locally__linear.html">_locally_linear</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.manifold._locally_linear Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1manifold_1_1__locally__linear_1_1_locally_linear_embedding.html">LocallyLinearEmbedding</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a54d10d8b2cb41cf4a6bb1ce465336f70" id="r_a54d10d8b2cb41cf4a6bb1ce465336f70"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1manifold_1_1__locally__linear.html#a54d10d8b2cb41cf4a6bb1ce465336f70">barycenter_weights</a> (X, Y, indices, reg=1e-3)</td></tr>
<tr class="separator:a54d10d8b2cb41cf4a6bb1ce465336f70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28d74ad2b04cf9efd21547a612bcdc0a" id="r_a28d74ad2b04cf9efd21547a612bcdc0a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1manifold_1_1__locally__linear.html#a28d74ad2b04cf9efd21547a612bcdc0a">barycenter_kneighbors_graph</a> (X, n_neighbors, reg=1e-3, n_jobs=None)</td></tr>
<tr class="separator:a28d74ad2b04cf9efd21547a612bcdc0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9628b4f26e82cee77c287a7fc60516b" id="r_ae9628b4f26e82cee77c287a7fc60516b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1manifold_1_1__locally__linear.html#ae9628b4f26e82cee77c287a7fc60516b">null_space</a> (M, <a class="el" href="__blas__subroutines_8h.html#afa8f30d4cfebc7d1efb06e7d245eff5a">k</a>, k_skip=1, eigen_solver=&quot;arpack&quot;, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-6, max_iter=100, random_state=None)</td></tr>
<tr class="separator:ae9628b4f26e82cee77c287a7fc60516b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a15c512a68e3cdb13bc4425baf8c6d553" id="r_a15c512a68e3cdb13bc4425baf8c6d553"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1manifold_1_1__locally__linear.html#a15c512a68e3cdb13bc4425baf8c6d553">locally_linear_embedding</a> (X, *n_neighbors, n_components, reg=1e-3, eigen_solver=&quot;auto&quot;, <a class="el" href="__lapack__subroutines_8h.html#a0357339a1a1f7b51953875ca01447445">tol</a>=1e-6, max_iter=100, method=&quot;standard&quot;, hessian_tol=1e-4, modified_tol=1e-12, random_state=None, n_jobs=None)</td></tr>
<tr class="separator:a15c512a68e3cdb13bc4425baf8c6d553"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Locally Linear Embedding</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a28d74ad2b04cf9efd21547a612bcdc0a" name="a28d74ad2b04cf9efd21547a612bcdc0a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a28d74ad2b04cf9efd21547a612bcdc0a">&#9670;&#160;</a></span>barycenter_kneighbors_graph()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.manifold._locally_linear.barycenter_kneighbors_graph </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_neighbors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>reg</em> = <code>1e-3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_jobs</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Computes the barycenter weighted graph of k-Neighbors for points in X

Parameters
----------
X : {array-like, NearestNeighbors}
    Sample data, shape = (n_samples, n_features), in the form of a
    numpy array or a NearestNeighbors object.

n_neighbors : int
    Number of neighbors for each sample.

reg : float, default=1e-3
    Amount of regularization when solving the least-squares
    problem. Only relevant if mode='barycenter'. If None, use the
    default.

n_jobs : int or None, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.

Returns
-------
A : sparse matrix in CSR format, shape = [n_samples, n_samples]
    A[i, j] is assigned the weight of edge that connects i to j.

See Also
--------
sklearn.neighbors.kneighbors_graph
sklearn.neighbors.radius_neighbors_graph
</pre> <div class="fragment"><div class="line"><span class="lineno">   83</span><span class="keyword">def </span>barycenter_kneighbors_graph(X, n_neighbors, reg=1e-3, n_jobs=None):</div>
<div class="line"><span class="lineno">   84</span>    <span class="stringliteral">&quot;&quot;&quot;Computes the barycenter weighted graph of k-Neighbors for points in X</span></div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">    X : {array-like, NearestNeighbors}</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">        Sample data, shape = (n_samples, n_features), in the form of a</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">        numpy array or a NearestNeighbors object.</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral">    n_neighbors : int</span></div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral">        Number of neighbors for each sample.</span></div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral">    reg : float, default=1e-3</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral">        Amount of regularization when solving the least-squares</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral">        problem. Only relevant if mode=&#39;barycenter&#39;. If None, use the</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">        default.</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">    n_jobs : int or None, default=None</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">        The number of parallel jobs to run for neighbors search.</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span></div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">        for more details.</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">    A : sparse matrix in CSR format, shape = [n_samples, n_samples]</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">        A[i, j] is assigned the weight of edge that connects i to j.</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral">    See Also</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral">    sklearn.neighbors.kneighbors_graph</span></div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">    sklearn.neighbors.radius_neighbors_graph</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  116</span>    knn = NearestNeighbors(n_neighbors=n_neighbors + 1, n_jobs=n_jobs).fit(X)</div>
<div class="line"><span class="lineno">  117</span>    X = knn._fit_X</div>
<div class="line"><span class="lineno">  118</span>    n_samples = knn.n_samples_fit_</div>
<div class="line"><span class="lineno">  119</span>    ind = knn.kneighbors(X, return_distance=<span class="keyword">False</span>)[:, 1:]</div>
<div class="line"><span class="lineno">  120</span>    data = barycenter_weights(X, X, ind, reg=reg)</div>
<div class="line"><span class="lineno">  121</span>    indptr = np.arange(0, n_samples * n_neighbors + 1, n_neighbors)</div>
<div class="line"><span class="lineno">  122</span>    <span class="keywordflow">return</span> csr_matrix((data.ravel(), ind.ravel(), indptr), shape=(n_samples, n_samples))</div>
<div class="line"><span class="lineno">  123</span> </div>
<div class="line"><span class="lineno">  124</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a54d10d8b2cb41cf4a6bb1ce465336f70" name="a54d10d8b2cb41cf4a6bb1ce465336f70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54d10d8b2cb41cf4a6bb1ce465336f70">&#9670;&#160;</a></span>barycenter_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.manifold._locally_linear.barycenter_weights </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>reg</em> = <code>1e-3</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute barycenter weights of X from Y along the first axis

We estimate the weights to assign to each point in Y[indices] to recover
the point X[i]. The barycenter weights sum to 1.

Parameters
----------
X : array-like, shape (n_samples, n_dim)

Y : array-like, shape (n_samples, n_dim)

indices : array-like, shape (n_samples, n_dim)
        Indices of the points in Y used to compute the barycenter

reg : float, default=1e-3
    Amount of regularization to add for the problem to be
    well-posed in the case of n_neighbors &gt; n_dim

Returns
-------
B : array-like, shape (n_samples, n_neighbors)

Notes
-----
See developers note for more information.
</pre> <div class="fragment"><div class="line"><span class="lineno">   29</span><span class="keyword">def </span>barycenter_weights(X, Y, indices, reg=1e-3):</div>
<div class="line"><span class="lineno">   30</span>    <span class="stringliteral">&quot;&quot;&quot;Compute barycenter weights of X from Y along the first axis</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">    We estimate the weights to assign to each point in Y[indices] to recover</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral">    the point X[i]. The barycenter weights sum to 1.</span></div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral">    X : array-like, shape (n_samples, n_dim)</span></div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">    Y : array-like, shape (n_samples, n_dim)</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">    indices : array-like, shape (n_samples, n_dim)</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral">            Indices of the points in Y used to compute the barycenter</span></div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">    reg : float, default=1e-3</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral">        Amount of regularization to add for the problem to be</span></div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">        well-posed in the case of n_neighbors &gt; n_dim</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   48</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">    B : array-like, shape (n_samples, n_neighbors)</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">    Notes</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">    -----</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral">    See developers note for more information.</span></div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   56</span>    X = check_array(X, dtype=FLOAT_DTYPES)</div>
<div class="line"><span class="lineno">   57</span>    Y = check_array(Y, dtype=FLOAT_DTYPES)</div>
<div class="line"><span class="lineno">   58</span>    indices = check_array(indices, dtype=int)</div>
<div class="line"><span class="lineno">   59</span> </div>
<div class="line"><span class="lineno">   60</span>    n_samples, n_neighbors = indices.shape</div>
<div class="line"><span class="lineno">   61</span>    <span class="keyword">assert</span> X.shape[0] == n_samples</div>
<div class="line"><span class="lineno">   62</span> </div>
<div class="line"><span class="lineno">   63</span>    B = np.empty((n_samples, n_neighbors), dtype=X.dtype)</div>
<div class="line"><span class="lineno">   64</span>    v = np.ones(n_neighbors, dtype=X.dtype)</div>
<div class="line"><span class="lineno">   65</span> </div>
<div class="line"><span class="lineno">   66</span>    <span class="comment"># this might raise a LinalgError if G is singular and has trace</span></div>
<div class="line"><span class="lineno">   67</span>    <span class="comment"># zero</span></div>
<div class="line"><span class="lineno">   68</span>    <span class="keywordflow">for</span> i, ind <span class="keywordflow">in</span> enumerate(indices):</div>
<div class="line"><span class="lineno">   69</span>        A = Y[ind]</div>
<div class="line"><span class="lineno">   70</span>        C = A - X[i]  <span class="comment"># broadcasting</span></div>
<div class="line"><span class="lineno">   71</span>        G = np.dot(C, C.T)</div>
<div class="line"><span class="lineno">   72</span>        trace = np.trace(G)</div>
<div class="line"><span class="lineno">   73</span>        <span class="keywordflow">if</span> trace &gt; 0:</div>
<div class="line"><span class="lineno">   74</span>            R = reg * trace</div>
<div class="line"><span class="lineno">   75</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   76</span>            R = reg</div>
<div class="line"><span class="lineno">   77</span>        G.flat[:: n_neighbors + 1] += R</div>
<div class="line"><span class="lineno">   78</span>        w = solve(G, v, assume_a=<span class="stringliteral">&quot;pos&quot;</span>)</div>
<div class="line"><span class="lineno">   79</span>        B[i, :] = w / np.sum(w)</div>
<div class="line"><span class="lineno">   80</span>    <span class="keywordflow">return</span> B</div>
<div class="line"><span class="lineno">   81</span> </div>
<div class="line"><span class="lineno">   82</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a15c512a68e3cdb13bc4425baf8c6d553" name="a15c512a68e3cdb13bc4425baf8c6d553"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a15c512a68e3cdb13bc4425baf8c6d553">&#9670;&#160;</a></span>locally_linear_embedding()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.manifold._locally_linear.locally_linear_embedding </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>n_neighbors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_components</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>reg</em> = <code>1e-3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>eigen_solver</em> = <code>&quot;auto&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-6</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em> = <code>&quot;standard&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hessian_tol</em> = <code>1e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>modified_tol</em> = <code>1e-12</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_jobs</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Perform a Locally Linear Embedding analysis on the data.

Read more in the :ref:`User Guide &lt;locally_linear_embedding&gt;`.

Parameters
----------
X : {array-like, NearestNeighbors}
    Sample data, shape = (n_samples, n_features), in the form of a
    numpy array or a NearestNeighbors object.

n_neighbors : int
    Number of neighbors to consider for each point.

n_components : int
    Number of coordinates for the manifold.

reg : float, default=1e-3
    Regularization constant, multiplies the trace of the local covariance
    matrix of the distances.

eigen_solver : {'auto', 'arpack', 'dense'}, default='auto'
    auto : algorithm will attempt to choose the best method for input data

    arpack : use arnoldi iteration in shift-invert mode.
                For this method, M may be a dense matrix, sparse matrix,
                or general linear operator.
                Warning: ARPACK can be unstable for some problems.  It is
                best to try several random seeds in order to check results.

    dense  : use standard dense matrix operations for the eigenvalue
                decomposition.  For this method, M must be an array
                or matrix type.  This method should be avoided for
                large problems.

tol : float, default=1e-6
    Tolerance for 'arpack' method
    Not used if eigen_solver=='dense'.

max_iter : int, default=100
    Maximum number of iterations for the arpack solver.

method : {'standard', 'hessian', 'modified', 'ltsa'}, default='standard'
    standard : use the standard locally linear embedding algorithm.
               see reference [1]_
    hessian  : use the Hessian eigenmap method.  This method requires
               n_neighbors &gt; n_components * (1 + (n_components + 1) / 2.
               see reference [2]_
    modified : use the modified locally linear embedding algorithm.
               see reference [3]_
    ltsa     : use local tangent space alignment algorithm
               see reference [4]_

hessian_tol : float, default=1e-4
    Tolerance for Hessian eigenmapping method.
    Only used if method == 'hessian'.

modified_tol : float, default=1e-12
    Tolerance for modified LLE method.
    Only used if method == 'modified'.

random_state : int, RandomState instance, default=None
    Determines the random number generator when ``solver`` == 'arpack'.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

n_jobs : int or None, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.

Returns
-------
Y : array-like, shape [n_samples, n_components]
    Embedding vectors.

squared_error : float
    Reconstruction error for the embedding vectors. Equivalent to
    ``norm(Y - W Y, 'fro')**2``, where W are the reconstruction weights.

References
----------

.. [1] Roweis, S. &amp; Saul, L. Nonlinear dimensionality reduction
    by locally linear embedding.  Science 290:2323 (2000).
.. [2] Donoho, D. &amp; Grimes, C. Hessian eigenmaps: Locally
    linear embedding techniques for high-dimensional data.
    Proc Natl Acad Sci U S A.  100:5591 (2003).
.. [3] `Zhang, Z. &amp; Wang, J. MLLE: Modified Locally Linear
    Embedding Using Multiple Weights.
    &lt;https://citeseerx.ist.psu.edu/doc_view/pid/0b060fdbd92cbcc66b383bcaa9ba5e5e624d7ee3&gt;`_
.. [4] Zhang, Z. &amp; Zha, H. Principal manifolds and nonlinear
    dimensionality reduction via tangent space alignment.
    Journal of Shanghai Univ.  8:406 (2004)
</pre> <div class="fragment"><div class="line"><span class="lineno">  215</span>):</div>
<div class="line"><span class="lineno">  216</span>    <span class="stringliteral">&quot;&quot;&quot;Perform a Locally Linear Embedding analysis on the data.</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;locally_linear_embedding&gt;`.</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">    X : {array-like, NearestNeighbors}</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">        Sample data, shape = (n_samples, n_features), in the form of a</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">        numpy array or a NearestNeighbors object.</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">    n_neighbors : int</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral">        Number of neighbors to consider for each point.</span></div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">    n_components : int</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">        Number of coordinates for the manifold.</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">    reg : float, default=1e-3</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">        Regularization constant, multiplies the trace of the local covariance</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">        matrix of the distances.</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  236</span><span class="stringliteral">    eigen_solver : {&#39;auto&#39;, &#39;arpack&#39;, &#39;dense&#39;}, default=&#39;auto&#39;</span></div>
<div class="line"><span class="lineno">  237</span><span class="stringliteral">        auto : algorithm will attempt to choose the best method for input data</span></div>
<div class="line"><span class="lineno">  238</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  239</span><span class="stringliteral">        arpack : use arnoldi iteration in shift-invert mode.</span></div>
<div class="line"><span class="lineno">  240</span><span class="stringliteral">                    For this method, M may be a dense matrix, sparse matrix,</span></div>
<div class="line"><span class="lineno">  241</span><span class="stringliteral">                    or general linear operator.</span></div>
<div class="line"><span class="lineno">  242</span><span class="stringliteral">                    Warning: ARPACK can be unstable for some problems.  It is</span></div>
<div class="line"><span class="lineno">  243</span><span class="stringliteral">                    best to try several random seeds in order to check results.</span></div>
<div class="line"><span class="lineno">  244</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">        dense  : use standard dense matrix operations for the eigenvalue</span></div>
<div class="line"><span class="lineno">  246</span><span class="stringliteral">                    decomposition.  For this method, M must be an array</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral">                    or matrix type.  This method should be avoided for</span></div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">                    large problems.</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">    tol : float, default=1e-6</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">        Tolerance for &#39;arpack&#39; method</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">        Not used if eigen_solver==&#39;dense&#39;.</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">    max_iter : int, default=100</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">        Maximum number of iterations for the arpack solver.</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">    method : {&#39;standard&#39;, &#39;hessian&#39;, &#39;modified&#39;, &#39;ltsa&#39;}, default=&#39;standard&#39;</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">        standard : use the standard locally linear embedding algorithm.</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">                   see reference [1]_</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral">        hessian  : use the Hessian eigenmap method.  This method requires</span></div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">                   n_neighbors &gt; n_components * (1 + (n_components + 1) / 2.</span></div>
<div class="line"><span class="lineno">  262</span><span class="stringliteral">                   see reference [2]_</span></div>
<div class="line"><span class="lineno">  263</span><span class="stringliteral">        modified : use the modified locally linear embedding algorithm.</span></div>
<div class="line"><span class="lineno">  264</span><span class="stringliteral">                   see reference [3]_</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">        ltsa     : use local tangent space alignment algorithm</span></div>
<div class="line"><span class="lineno">  266</span><span class="stringliteral">                   see reference [4]_</span></div>
<div class="line"><span class="lineno">  267</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  268</span><span class="stringliteral">    hessian_tol : float, default=1e-4</span></div>
<div class="line"><span class="lineno">  269</span><span class="stringliteral">        Tolerance for Hessian eigenmapping method.</span></div>
<div class="line"><span class="lineno">  270</span><span class="stringliteral">        Only used if method == &#39;hessian&#39;.</span></div>
<div class="line"><span class="lineno">  271</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral">    modified_tol : float, default=1e-12</span></div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">        Tolerance for modified LLE method.</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral">        Only used if method == &#39;modified&#39;.</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">    random_state : int, RandomState instance, default=None</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral">        Determines the random number generator when ``solver`` == &#39;arpack&#39;.</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">        Pass an int for reproducible results across multiple function calls.</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    n_jobs : int or None, default=None</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">        The number of parallel jobs to run for neighbors search.</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">        for more details.</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">    Y : array-like, shape [n_samples, n_components]</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral">        Embedding vectors.</span></div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  292</span><span class="stringliteral">    squared_error : float</span></div>
<div class="line"><span class="lineno">  293</span><span class="stringliteral">        Reconstruction error for the embedding vectors. Equivalent to</span></div>
<div class="line"><span class="lineno">  294</span><span class="stringliteral">        ``norm(Y - W Y, &#39;fro&#39;)**2``, where W are the reconstruction weights.</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">    .. [1] Roweis, S. &amp; Saul, L. Nonlinear dimensionality reduction</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">        by locally linear embedding.  Science 290:2323 (2000).</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">    .. [2] Donoho, D. &amp; Grimes, C. Hessian eigenmaps: Locally</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">        linear embedding techniques for high-dimensional data.</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">        Proc Natl Acad Sci U S A.  100:5591 (2003).</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">    .. [3] `Zhang, Z. &amp; Wang, J. MLLE: Modified Locally Linear</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">        Embedding Using Multiple Weights.</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">        &lt;https://citeseerx.ist.psu.edu/doc_view/pid/0b060fdbd92cbcc66b383bcaa9ba5e5e624d7ee3&gt;`_</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">    .. [4] Zhang, Z. &amp; Zha, H. Principal manifolds and nonlinear</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">        dimensionality reduction via tangent space alignment.</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">        Journal of Shanghai Univ.  8:406 (2004)</span></div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  311</span>    <span class="keywordflow">if</span> eigen_solver <span class="keywordflow">not</span> <span class="keywordflow">in</span> (<span class="stringliteral">&quot;auto&quot;</span>, <span class="stringliteral">&quot;arpack&quot;</span>, <span class="stringliteral">&quot;dense&quot;</span>):</div>
<div class="line"><span class="lineno">  312</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;unrecognized eigen_solver &#39;%s&#39;&quot;</span> % eigen_solver)</div>
<div class="line"><span class="lineno">  313</span> </div>
<div class="line"><span class="lineno">  314</span>    <span class="keywordflow">if</span> method <span class="keywordflow">not</span> <span class="keywordflow">in</span> (<span class="stringliteral">&quot;standard&quot;</span>, <span class="stringliteral">&quot;hessian&quot;</span>, <span class="stringliteral">&quot;modified&quot;</span>, <span class="stringliteral">&quot;ltsa&quot;</span>):</div>
<div class="line"><span class="lineno">  315</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;unrecognized method &#39;%s&#39;&quot;</span> % method)</div>
<div class="line"><span class="lineno">  316</span> </div>
<div class="line"><span class="lineno">  317</span>    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1, n_jobs=n_jobs)</div>
<div class="line"><span class="lineno">  318</span>    nbrs.fit(X)</div>
<div class="line"><span class="lineno">  319</span>    X = nbrs._fit_X</div>
<div class="line"><span class="lineno">  320</span> </div>
<div class="line"><span class="lineno">  321</span>    N, d_in = X.shape</div>
<div class="line"><span class="lineno">  322</span> </div>
<div class="line"><span class="lineno">  323</span>    <span class="keywordflow">if</span> n_components &gt; d_in:</div>
<div class="line"><span class="lineno">  324</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  325</span>            <span class="stringliteral">&quot;output dimension must be less than or equal to input dimension&quot;</span></div>
<div class="line"><span class="lineno">  326</span>        )</div>
<div class="line"><span class="lineno">  327</span>    <span class="keywordflow">if</span> n_neighbors &gt;= N:</div>
<div class="line"><span class="lineno">  328</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  329</span>            <span class="stringliteral">&quot;Expected n_neighbors &lt;= n_samples,  but n_samples = %d, n_neighbors = %d&quot;</span></div>
<div class="line"><span class="lineno">  330</span>            % (N, n_neighbors)</div>
<div class="line"><span class="lineno">  331</span>        )</div>
<div class="line"><span class="lineno">  332</span> </div>
<div class="line"><span class="lineno">  333</span>    <span class="keywordflow">if</span> n_neighbors &lt;= 0:</div>
<div class="line"><span class="lineno">  334</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;n_neighbors must be positive&quot;</span>)</div>
<div class="line"><span class="lineno">  335</span> </div>
<div class="line"><span class="lineno">  336</span>    M_sparse = eigen_solver != <span class="stringliteral">&quot;dense&quot;</span></div>
<div class="line"><span class="lineno">  337</span> </div>
<div class="line"><span class="lineno">  338</span>    <span class="keywordflow">if</span> method == <span class="stringliteral">&quot;standard&quot;</span>:</div>
<div class="line"><span class="lineno">  339</span>        W = barycenter_kneighbors_graph(</div>
<div class="line"><span class="lineno">  340</span>            nbrs, n_neighbors=n_neighbors, reg=reg, n_jobs=n_jobs</div>
<div class="line"><span class="lineno">  341</span>        )</div>
<div class="line"><span class="lineno">  342</span> </div>
<div class="line"><span class="lineno">  343</span>        <span class="comment"># we&#39;ll compute M = (I-W)&#39;(I-W)</span></div>
<div class="line"><span class="lineno">  344</span>        <span class="comment"># depending on the solver, we&#39;ll do this differently</span></div>
<div class="line"><span class="lineno">  345</span>        <span class="keywordflow">if</span> M_sparse:</div>
<div class="line"><span class="lineno">  346</span>            M = eye(*W.shape, format=W.format) - W</div>
<div class="line"><span class="lineno">  347</span>            M = (M.T * M).tocsr()</div>
<div class="line"><span class="lineno">  348</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  349</span>            M = (W.T * W - W.T - W).toarray()</div>
<div class="line"><span class="lineno">  350</span>            M.flat[:: M.shape[0] + 1] += 1  <span class="comment"># W = W - I = W - I</span></div>
<div class="line"><span class="lineno">  351</span> </div>
<div class="line"><span class="lineno">  352</span>    <span class="keywordflow">elif</span> method == <span class="stringliteral">&quot;hessian&quot;</span>:</div>
<div class="line"><span class="lineno">  353</span>        dp = n_components * (n_components + 1) // 2</div>
<div class="line"><span class="lineno">  354</span> </div>
<div class="line"><span class="lineno">  355</span>        <span class="keywordflow">if</span> n_neighbors &lt;= n_components + dp:</div>
<div class="line"><span class="lineno">  356</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  357</span>                <span class="stringliteral">&quot;for method=&#39;hessian&#39;, n_neighbors must be &quot;</span></div>
<div class="line"><span class="lineno">  358</span>                <span class="stringliteral">&quot;greater than &quot;</span></div>
<div class="line"><span class="lineno">  359</span>                <span class="stringliteral">&quot;[n_components * (n_components + 3) / 2]&quot;</span></div>
<div class="line"><span class="lineno">  360</span>            )</div>
<div class="line"><span class="lineno">  361</span> </div>
<div class="line"><span class="lineno">  362</span>        neighbors = nbrs.kneighbors(</div>
<div class="line"><span class="lineno">  363</span>            X, n_neighbors=n_neighbors + 1, return_distance=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  364</span>        )</div>
<div class="line"><span class="lineno">  365</span>        neighbors = neighbors[:, 1:]</div>
<div class="line"><span class="lineno">  366</span> </div>
<div class="line"><span class="lineno">  367</span>        Yi = np.empty((n_neighbors, 1 + n_components + dp), dtype=np.float64)</div>
<div class="line"><span class="lineno">  368</span>        Yi[:, 0] = 1</div>
<div class="line"><span class="lineno">  369</span> </div>
<div class="line"><span class="lineno">  370</span>        M = np.zeros((N, N), dtype=np.float64)</div>
<div class="line"><span class="lineno">  371</span> </div>
<div class="line"><span class="lineno">  372</span>        use_svd = n_neighbors &gt; d_in</div>
<div class="line"><span class="lineno">  373</span> </div>
<div class="line"><span class="lineno">  374</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(N):</div>
<div class="line"><span class="lineno">  375</span>            Gi = X[neighbors[i]]</div>
<div class="line"><span class="lineno">  376</span>            Gi -= Gi.mean(0)</div>
<div class="line"><span class="lineno">  377</span> </div>
<div class="line"><span class="lineno">  378</span>            <span class="comment"># build Hessian estimator</span></div>
<div class="line"><span class="lineno">  379</span>            <span class="keywordflow">if</span> use_svd:</div>
<div class="line"><span class="lineno">  380</span>                U = svd(Gi, full_matrices=0)[0]</div>
<div class="line"><span class="lineno">  381</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  382</span>                Ci = np.dot(Gi, Gi.T)</div>
<div class="line"><span class="lineno">  383</span>                U = eigh(Ci)[1][:, ::-1]</div>
<div class="line"><span class="lineno">  384</span> </div>
<div class="line"><span class="lineno">  385</span>            Yi[:, 1 : 1 + n_components] = U[:, :n_components]</div>
<div class="line"><span class="lineno">  386</span> </div>
<div class="line"><span class="lineno">  387</span>            j = 1 + n_components</div>
<div class="line"><span class="lineno">  388</span>            <span class="keywordflow">for</span> k <span class="keywordflow">in</span> range(n_components):</div>
<div class="line"><span class="lineno">  389</span>                Yi[:, j : j + n_components - k] = U[:, k : k + 1] * U[:, k:n_components]</div>
<div class="line"><span class="lineno">  390</span>                j += n_components - k</div>
<div class="line"><span class="lineno">  391</span> </div>
<div class="line"><span class="lineno">  392</span>            Q, R = qr(Yi)</div>
<div class="line"><span class="lineno">  393</span> </div>
<div class="line"><span class="lineno">  394</span>            w = Q[:, n_components + 1 :]</div>
<div class="line"><span class="lineno">  395</span>            S = w.sum(0)</div>
<div class="line"><span class="lineno">  396</span> </div>
<div class="line"><span class="lineno">  397</span>            S[np.where(abs(S) &lt; hessian_tol)] = 1</div>
<div class="line"><span class="lineno">  398</span>            w /= S</div>
<div class="line"><span class="lineno">  399</span> </div>
<div class="line"><span class="lineno">  400</span>            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])</div>
<div class="line"><span class="lineno">  401</span>            M[nbrs_x, nbrs_y] += np.dot(w, w.T)</div>
<div class="line"><span class="lineno">  402</span> </div>
<div class="line"><span class="lineno">  403</span>        <span class="keywordflow">if</span> M_sparse:</div>
<div class="line"><span class="lineno">  404</span>            M = csr_matrix(M)</div>
<div class="line"><span class="lineno">  405</span> </div>
<div class="line"><span class="lineno">  406</span>    <span class="keywordflow">elif</span> method == <span class="stringliteral">&quot;modified&quot;</span>:</div>
<div class="line"><span class="lineno">  407</span>        <span class="keywordflow">if</span> n_neighbors &lt; n_components:</div>
<div class="line"><span class="lineno">  408</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;modified LLE requires n_neighbors &gt;= n_components&quot;</span>)</div>
<div class="line"><span class="lineno">  409</span> </div>
<div class="line"><span class="lineno">  410</span>        neighbors = nbrs.kneighbors(</div>
<div class="line"><span class="lineno">  411</span>            X, n_neighbors=n_neighbors + 1, return_distance=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  412</span>        )</div>
<div class="line"><span class="lineno">  413</span>        neighbors = neighbors[:, 1:]</div>
<div class="line"><span class="lineno">  414</span> </div>
<div class="line"><span class="lineno">  415</span>        <span class="comment"># find the eigenvectors and eigenvalues of each local covariance</span></div>
<div class="line"><span class="lineno">  416</span>        <span class="comment"># matrix. We want V[i] to be a [n_neighbors x n_neighbors] matrix,</span></div>
<div class="line"><span class="lineno">  417</span>        <span class="comment"># where the columns are eigenvectors</span></div>
<div class="line"><span class="lineno">  418</span>        V = np.zeros((N, n_neighbors, n_neighbors))</div>
<div class="line"><span class="lineno">  419</span>        nev = min(d_in, n_neighbors)</div>
<div class="line"><span class="lineno">  420</span>        evals = np.zeros([N, nev])</div>
<div class="line"><span class="lineno">  421</span> </div>
<div class="line"><span class="lineno">  422</span>        <span class="comment"># choose the most efficient way to find the eigenvectors</span></div>
<div class="line"><span class="lineno">  423</span>        use_svd = n_neighbors &gt; d_in</div>
<div class="line"><span class="lineno">  424</span> </div>
<div class="line"><span class="lineno">  425</span>        <span class="keywordflow">if</span> use_svd:</div>
<div class="line"><span class="lineno">  426</span>            <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(N):</div>
<div class="line"><span class="lineno">  427</span>                X_nbrs = X[neighbors[i]] - X[i]</div>
<div class="line"><span class="lineno">  428</span>                V[i], evals[i], _ = svd(X_nbrs, full_matrices=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  429</span>            evals **= 2</div>
<div class="line"><span class="lineno">  430</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  431</span>            <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(N):</div>
<div class="line"><span class="lineno">  432</span>                X_nbrs = X[neighbors[i]] - X[i]</div>
<div class="line"><span class="lineno">  433</span>                C_nbrs = np.dot(X_nbrs, X_nbrs.T)</div>
<div class="line"><span class="lineno">  434</span>                evi, vi = eigh(C_nbrs)</div>
<div class="line"><span class="lineno">  435</span>                evals[i] = evi[::-1]</div>
<div class="line"><span class="lineno">  436</span>                V[i] = vi[:, ::-1]</div>
<div class="line"><span class="lineno">  437</span> </div>
<div class="line"><span class="lineno">  438</span>        <span class="comment"># find regularized weights: this is like normal LLE.</span></div>
<div class="line"><span class="lineno">  439</span>        <span class="comment"># because we&#39;ve already computed the SVD of each covariance matrix,</span></div>
<div class="line"><span class="lineno">  440</span>        <span class="comment"># it&#39;s faster to use this rather than np.linalg.solve</span></div>
<div class="line"><span class="lineno">  441</span>        reg = 1e-3 * evals.sum(1)</div>
<div class="line"><span class="lineno">  442</span> </div>
<div class="line"><span class="lineno">  443</span>        tmp = np.dot(V.transpose(0, 2, 1), np.ones(n_neighbors))</div>
<div class="line"><span class="lineno">  444</span>        tmp[:, :nev] /= evals + reg[:, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  445</span>        tmp[:, nev:] /= reg[:, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  446</span> </div>
<div class="line"><span class="lineno">  447</span>        w_reg = np.zeros((N, n_neighbors))</div>
<div class="line"><span class="lineno">  448</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(N):</div>
<div class="line"><span class="lineno">  449</span>            w_reg[i] = np.dot(V[i], tmp[i])</div>
<div class="line"><span class="lineno">  450</span>        w_reg /= w_reg.sum(1)[:, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  451</span> </div>
<div class="line"><span class="lineno">  452</span>        <span class="comment"># calculate eta: the median of the ratio of small to large eigenvalues</span></div>
<div class="line"><span class="lineno">  453</span>        <span class="comment"># across the points.  This is used to determine s_i, below</span></div>
<div class="line"><span class="lineno">  454</span>        rho = evals[:, n_components:].sum(1) / evals[:, :n_components].sum(1)</div>
<div class="line"><span class="lineno">  455</span>        eta = np.median(rho)</div>
<div class="line"><span class="lineno">  456</span> </div>
<div class="line"><span class="lineno">  457</span>        <span class="comment"># find s_i, the size of the &quot;almost null space&quot; for each point:</span></div>
<div class="line"><span class="lineno">  458</span>        <span class="comment"># this is the size of the largest set of eigenvalues</span></div>
<div class="line"><span class="lineno">  459</span>        <span class="comment"># such that Sum[v; v in set]/Sum[v; v not in set] &lt; eta</span></div>
<div class="line"><span class="lineno">  460</span>        s_range = np.zeros(N, dtype=int)</div>
<div class="line"><span class="lineno">  461</span>        evals_cumsum = stable_cumsum(evals, 1)</div>
<div class="line"><span class="lineno">  462</span>        eta_range = evals_cumsum[:, -1:] / evals_cumsum[:, :-1] - 1</div>
<div class="line"><span class="lineno">  463</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(N):</div>
<div class="line"><span class="lineno">  464</span>            s_range[i] = np.searchsorted(eta_range[i, ::-1], eta)</div>
<div class="line"><span class="lineno">  465</span>        s_range += n_neighbors - nev  <span class="comment"># number of zero eigenvalues</span></div>
<div class="line"><span class="lineno">  466</span> </div>
<div class="line"><span class="lineno">  467</span>        <span class="comment"># Now calculate M.</span></div>
<div class="line"><span class="lineno">  468</span>        <span class="comment"># This is the [N x N] matrix whose null space is the desired embedding</span></div>
<div class="line"><span class="lineno">  469</span>        M = np.zeros((N, N), dtype=np.float64)</div>
<div class="line"><span class="lineno">  470</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(N):</div>
<div class="line"><span class="lineno">  471</span>            s_i = s_range[i]</div>
<div class="line"><span class="lineno">  472</span> </div>
<div class="line"><span class="lineno">  473</span>            <span class="comment"># select bottom s_i eigenvectors and calculate alpha</span></div>
<div class="line"><span class="lineno">  474</span>            Vi = V[i, :, n_neighbors - s_i :]</div>
<div class="line"><span class="lineno">  475</span>            alpha_i = np.linalg.norm(Vi.sum(0)) / np.sqrt(s_i)</div>
<div class="line"><span class="lineno">  476</span> </div>
<div class="line"><span class="lineno">  477</span>            <span class="comment"># compute Householder matrix which satisfies</span></div>
<div class="line"><span class="lineno">  478</span>            <span class="comment">#  Hi*Vi.T*ones(n_neighbors) = alpha_i*ones(s)</span></div>
<div class="line"><span class="lineno">  479</span>            <span class="comment"># using prescription from paper</span></div>
<div class="line"><span class="lineno">  480</span>            h = np.full(s_i, alpha_i) - np.dot(Vi.T, np.ones(n_neighbors))</div>
<div class="line"><span class="lineno">  481</span> </div>
<div class="line"><span class="lineno">  482</span>            norm_h = np.linalg.norm(h)</div>
<div class="line"><span class="lineno">  483</span>            <span class="keywordflow">if</span> norm_h &lt; modified_tol:</div>
<div class="line"><span class="lineno">  484</span>                h *= 0</div>
<div class="line"><span class="lineno">  485</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  486</span>                h /= norm_h</div>
<div class="line"><span class="lineno">  487</span> </div>
<div class="line"><span class="lineno">  488</span>            <span class="comment"># Householder matrix is</span></div>
<div class="line"><span class="lineno">  489</span>            <span class="comment">#  &gt;&gt; Hi = np.identity(s_i) - 2*np.outer(h,h)</span></div>
<div class="line"><span class="lineno">  490</span>            <span class="comment"># Then the weight matrix is</span></div>
<div class="line"><span class="lineno">  491</span>            <span class="comment">#  &gt;&gt; Wi = np.dot(Vi,Hi) + (1-alpha_i) * w_reg[i,:,None]</span></div>
<div class="line"><span class="lineno">  492</span>            <span class="comment"># We do this much more efficiently:</span></div>
<div class="line"><span class="lineno">  493</span>            Wi = Vi - 2 * np.outer(np.dot(Vi, h), h) + (1 - alpha_i) * w_reg[i, :, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  494</span> </div>
<div class="line"><span class="lineno">  495</span>            <span class="comment"># Update M as follows:</span></div>
<div class="line"><span class="lineno">  496</span>            <span class="comment"># &gt;&gt; W_hat = np.zeros( (N,s_i) )</span></div>
<div class="line"><span class="lineno">  497</span>            <span class="comment"># &gt;&gt; W_hat[neighbors[i],:] = Wi</span></div>
<div class="line"><span class="lineno">  498</span>            <span class="comment"># &gt;&gt; W_hat[i] -= 1</span></div>
<div class="line"><span class="lineno">  499</span>            <span class="comment"># &gt;&gt; M += np.dot(W_hat,W_hat.T)</span></div>
<div class="line"><span class="lineno">  500</span>            <span class="comment"># We can do this much more efficiently:</span></div>
<div class="line"><span class="lineno">  501</span>            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])</div>
<div class="line"><span class="lineno">  502</span>            M[nbrs_x, nbrs_y] += np.dot(Wi, Wi.T)</div>
<div class="line"><span class="lineno">  503</span>            Wi_sum1 = Wi.sum(1)</div>
<div class="line"><span class="lineno">  504</span>            M[i, neighbors[i]] -= Wi_sum1</div>
<div class="line"><span class="lineno">  505</span>            M[neighbors[i], i] -= Wi_sum1</div>
<div class="line"><span class="lineno">  506</span>            M[i, i] += s_i</div>
<div class="line"><span class="lineno">  507</span> </div>
<div class="line"><span class="lineno">  508</span>        <span class="keywordflow">if</span> M_sparse:</div>
<div class="line"><span class="lineno">  509</span>            M = csr_matrix(M)</div>
<div class="line"><span class="lineno">  510</span> </div>
<div class="line"><span class="lineno">  511</span>    <span class="keywordflow">elif</span> method == <span class="stringliteral">&quot;ltsa&quot;</span>:</div>
<div class="line"><span class="lineno">  512</span>        neighbors = nbrs.kneighbors(</div>
<div class="line"><span class="lineno">  513</span>            X, n_neighbors=n_neighbors + 1, return_distance=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  514</span>        )</div>
<div class="line"><span class="lineno">  515</span>        neighbors = neighbors[:, 1:]</div>
<div class="line"><span class="lineno">  516</span> </div>
<div class="line"><span class="lineno">  517</span>        M = np.zeros((N, N))</div>
<div class="line"><span class="lineno">  518</span> </div>
<div class="line"><span class="lineno">  519</span>        use_svd = n_neighbors &gt; d_in</div>
<div class="line"><span class="lineno">  520</span> </div>
<div class="line"><span class="lineno">  521</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(N):</div>
<div class="line"><span class="lineno">  522</span>            Xi = X[neighbors[i]]</div>
<div class="line"><span class="lineno">  523</span>            Xi -= Xi.mean(0)</div>
<div class="line"><span class="lineno">  524</span> </div>
<div class="line"><span class="lineno">  525</span>            <span class="comment"># compute n_components largest eigenvalues of Xi * Xi^T</span></div>
<div class="line"><span class="lineno">  526</span>            <span class="keywordflow">if</span> use_svd:</div>
<div class="line"><span class="lineno">  527</span>                v = svd(Xi, full_matrices=<span class="keyword">True</span>)[0]</div>
<div class="line"><span class="lineno">  528</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  529</span>                Ci = np.dot(Xi, Xi.T)</div>
<div class="line"><span class="lineno">  530</span>                v = eigh(Ci)[1][:, ::-1]</div>
<div class="line"><span class="lineno">  531</span> </div>
<div class="line"><span class="lineno">  532</span>            Gi = np.zeros((n_neighbors, n_components + 1))</div>
<div class="line"><span class="lineno">  533</span>            Gi[:, 1:] = v[:, :n_components]</div>
<div class="line"><span class="lineno">  534</span>            Gi[:, 0] = 1.0 / np.sqrt(n_neighbors)</div>
<div class="line"><span class="lineno">  535</span> </div>
<div class="line"><span class="lineno">  536</span>            GiGiT = np.dot(Gi, Gi.T)</div>
<div class="line"><span class="lineno">  537</span> </div>
<div class="line"><span class="lineno">  538</span>            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])</div>
<div class="line"><span class="lineno">  539</span>            M[nbrs_x, nbrs_y] -= GiGiT</div>
<div class="line"><span class="lineno">  540</span>            M[neighbors[i], neighbors[i]] += 1</div>
<div class="line"><span class="lineno">  541</span> </div>
<div class="line"><span class="lineno">  542</span>    <span class="keywordflow">return</span> null_space(</div>
<div class="line"><span class="lineno">  543</span>        M,</div>
<div class="line"><span class="lineno">  544</span>        n_components,</div>
<div class="line"><span class="lineno">  545</span>        k_skip=1,</div>
<div class="line"><span class="lineno">  546</span>        eigen_solver=eigen_solver,</div>
<div class="line"><span class="lineno">  547</span>        tol=tol,</div>
<div class="line"><span class="lineno">  548</span>        max_iter=max_iter,</div>
<div class="line"><span class="lineno">  549</span>        random_state=random_state,</div>
<div class="line"><span class="lineno">  550</span>    )</div>
<div class="line"><span class="lineno">  551</span> </div>
<div class="line"><span class="lineno">  552</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae9628b4f26e82cee77c287a7fc60516b" name="ae9628b4f26e82cee77c287a7fc60516b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9628b4f26e82cee77c287a7fc60516b">&#9670;&#160;</a></span>null_space()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.manifold._locally_linear.null_space </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>M</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>k_skip</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>eigen_solver</em> = <code>&quot;arpack&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>1e-6</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Find the null space of a matrix M.

Parameters
----------
M : {array, matrix, sparse matrix, LinearOperator}
    Input covariance matrix: should be symmetric positive semi-definite

k : int
    Number of eigenvalues/vectors to return

k_skip : int, default=1
    Number of low eigenvalues to skip.

eigen_solver : {'auto', 'arpack', 'dense'}, default='arpack'
    auto : algorithm will attempt to choose the best method for input data
    arpack : use arnoldi iteration in shift-invert mode.
                For this method, M may be a dense matrix, sparse matrix,
                or general linear operator.
                Warning: ARPACK can be unstable for some problems.  It is
                best to try several random seeds in order to check results.
    dense  : use standard dense matrix operations for the eigenvalue
                decomposition.  For this method, M must be an array
                or matrix type.  This method should be avoided for
                large problems.

tol : float, default=1e-6
    Tolerance for 'arpack' method.
    Not used if eigen_solver=='dense'.

max_iter : int, default=100
    Maximum number of iterations for 'arpack' method.
    Not used if eigen_solver=='dense'

random_state : int, RandomState instance, default=None
    Determines the random number generator when ``solver`` == 'arpack'.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.
</pre> <div class="fragment"><div class="line"><span class="lineno">  127</span>):</div>
<div class="line"><span class="lineno">  128</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral">    Find the null space of a matrix M.</span></div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">    M : {array, matrix, sparse matrix, LinearOperator}</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">        Input covariance matrix: should be symmetric positive semi-definite</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">    k : int</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">        Number of eigenvalues/vectors to return</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral">    k_skip : int, default=1</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">        Number of low eigenvalues to skip.</span></div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">    eigen_solver : {&#39;auto&#39;, &#39;arpack&#39;, &#39;dense&#39;}, default=&#39;arpack&#39;</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">        auto : algorithm will attempt to choose the best method for input data</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">        arpack : use arnoldi iteration in shift-invert mode.</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">                    For this method, M may be a dense matrix, sparse matrix,</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">                    or general linear operator.</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">                    Warning: ARPACK can be unstable for some problems.  It is</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">                    best to try several random seeds in order to check results.</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">        dense  : use standard dense matrix operations for the eigenvalue</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">                    decomposition.  For this method, M must be an array</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">                    or matrix type.  This method should be avoided for</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">                    large problems.</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">    tol : float, default=1e-6</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">        Tolerance for &#39;arpack&#39; method.</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">        Not used if eigen_solver==&#39;dense&#39;.</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">    max_iter : int, default=100</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">        Maximum number of iterations for &#39;arpack&#39; method.</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">        Not used if eigen_solver==&#39;dense&#39;</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">    random_state : int, RandomState instance, default=None</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">        Determines the random number generator when ``solver`` == &#39;arpack&#39;.</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        Pass an int for reproducible results across multiple function calls.</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  167</span>    <span class="keywordflow">if</span> eigen_solver == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><span class="lineno">  168</span>        <span class="keywordflow">if</span> M.shape[0] &gt; 200 <span class="keywordflow">and</span> k + k_skip &lt; 10:</div>
<div class="line"><span class="lineno">  169</span>            eigen_solver = <span class="stringliteral">&quot;arpack&quot;</span></div>
<div class="line"><span class="lineno">  170</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  171</span>            eigen_solver = <span class="stringliteral">&quot;dense&quot;</span></div>
<div class="line"><span class="lineno">  172</span> </div>
<div class="line"><span class="lineno">  173</span>    <span class="keywordflow">if</span> eigen_solver == <span class="stringliteral">&quot;arpack&quot;</span>:</div>
<div class="line"><span class="lineno">  174</span>        v0 = _init_arpack_v0(M.shape[0], random_state)</div>
<div class="line"><span class="lineno">  175</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno">  176</span>            eigen_values, eigen_vectors = eigsh(</div>
<div class="line"><span class="lineno">  177</span>                M, k + k_skip, sigma=0.0, tol=tol, maxiter=max_iter, v0=v0</div>
<div class="line"><span class="lineno">  178</span>            )</div>
<div class="line"><span class="lineno">  179</span>        <span class="keywordflow">except</span> RuntimeError <span class="keyword">as</span> e:</div>
<div class="line"><span class="lineno">  180</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  181</span>                <span class="stringliteral">&quot;Error in determining null-space with ARPACK. Error message: &quot;</span></div>
<div class="line"><span class="lineno">  182</span>                <span class="stringliteral">&quot;&#39;%s&#39;. Note that eigen_solver=&#39;arpack&#39; can fail when the &quot;</span></div>
<div class="line"><span class="lineno">  183</span>                <span class="stringliteral">&quot;weight matrix is singular or otherwise ill-behaved. In that &quot;</span></div>
<div class="line"><span class="lineno">  184</span>                <span class="stringliteral">&quot;case, eigen_solver=&#39;dense&#39; is recommended. See online &quot;</span></div>
<div class="line"><span class="lineno">  185</span>                <span class="stringliteral">&quot;documentation for more information.&quot;</span> % e</div>
<div class="line"><span class="lineno">  186</span>            ) <span class="keyword">from</span> e</div>
<div class="line"><span class="lineno">  187</span> </div>
<div class="line"><span class="lineno">  188</span>        <span class="keywordflow">return</span> eigen_vectors[:, k_skip:], np.sum(eigen_values[k_skip:])</div>
<div class="line"><span class="lineno">  189</span>    <span class="keywordflow">elif</span> eigen_solver == <span class="stringliteral">&quot;dense&quot;</span>:</div>
<div class="line"><span class="lineno">  190</span>        <span class="keywordflow">if</span> hasattr(M, <span class="stringliteral">&quot;toarray&quot;</span>):</div>
<div class="line"><span class="lineno">  191</span>            M = M.toarray()</div>
<div class="line"><span class="lineno">  192</span>        eigen_values, eigen_vectors = eigh(</div>
<div class="line"><span class="lineno">  193</span>            M, eigvals=(k_skip, k + k_skip - 1), overwrite_a=<span class="keyword">True</span></div>
<div class="line"><span class="lineno">  194</span>        )</div>
<div class="line"><span class="lineno">  195</span>        index = np.argsort(np.abs(eigen_values))</div>
<div class="line"><span class="lineno">  196</span>        <span class="keywordflow">return</span> eigen_vectors[:, index], np.sum(eigen_values)</div>
<div class="line"><span class="lineno">  197</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  198</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Unrecognized eigen_solver &#39;%s&#39;&quot;</span> % eigen_solver)</div>
<div class="line"><span class="lineno">  199</span> </div>
<div class="line"><span class="lineno">  200</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
