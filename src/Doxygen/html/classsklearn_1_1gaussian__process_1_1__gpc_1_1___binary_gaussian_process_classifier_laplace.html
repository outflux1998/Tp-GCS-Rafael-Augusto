<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1gaussian__process.html">gaussian_process</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1gaussian__process_1_1__gpc.html">_gpc</a></li><li class="navelem"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html">_BinaryGaussianProcessClassifierLaplace</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.png" usemap="#sklearn.gaussian_5Fprocess._5Fgpc._5FBinaryGaussianProcessClassifierLaplace_map" alt=""/>
  <map id="sklearn.gaussian_5Fprocess._5Fgpc._5FBinaryGaussianProcessClassifierLaplace_map" name="sklearn.gaussian_5Fprocess._5Fgpc._5FBinaryGaussianProcessClassifierLaplace_map">
<area href="classsklearn_1_1base_1_1_base_estimator.html" alt="sklearn.base.BaseEstimator" shape="rect" coords="0,0,435,24"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a0a3ce663076c6963ed727512538e6eb4" id="r_a0a3ce663076c6963ed727512538e6eb4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a0a3ce663076c6963ed727512538e6eb4">__init__</a> (self, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a05b3a6520191f5374d95cd12d46cd60a">kernel</a>=None, *<a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a44deb6e9571be1145e3e2cf4228fca9c">optimizer</a>=&quot;fmin_l_bfgs_b&quot;, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a1e033db2c979b3021980c95fd2fa5826">n_restarts_optimizer</a>=0, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#af82f13e8d69852d75c8cdefba8d4797f">max_iter_predict</a>=100, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#aee2915a0ad31f8dcfcd487a36e7ba0ab">warm_start</a>=False, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#af7432b4bed96e32fb20d5589c1cabf36">copy_X_train</a>=True, <a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#ab31b3e0a96af9585d53a300626da0bf0">random_state</a>=None)</td></tr>
<tr class="separator:a0a3ce663076c6963ed727512538e6eb4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae67dd48f0c6e0310c59b235aad8d10b3" id="r_ae67dd48f0c6e0310c59b235aad8d10b3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#ae67dd48f0c6e0310c59b235aad8d10b3">fit</a> (self, X, y)</td></tr>
<tr class="separator:ae67dd48f0c6e0310c59b235aad8d10b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6bb3022c2a82c87ed0b9447e5f0e8e29" id="r_a6bb3022c2a82c87ed0b9447e5f0e8e29"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a6bb3022c2a82c87ed0b9447e5f0e8e29">predict</a> (self, X)</td></tr>
<tr class="separator:a6bb3022c2a82c87ed0b9447e5f0e8e29"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af38bcd8f6f15205189cb1b89c2e2c128" id="r_af38bcd8f6f15205189cb1b89c2e2c128"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#af38bcd8f6f15205189cb1b89c2e2c128">predict_proba</a> (self, X)</td></tr>
<tr class="separator:af38bcd8f6f15205189cb1b89c2e2c128"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d1847f696d50e568d0586a81bc69697" id="r_a2d1847f696d50e568d0586a81bc69697"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a2d1847f696d50e568d0586a81bc69697">log_marginal_likelihood</a> (self, <a class="el" href="__lapack__subroutines_8h.html#a68abd7cf2689a313136b50c232300582">theta</a>=None, eval_gradient=False, clone_kernel=True)</td></tr>
<tr class="separator:a2d1847f696d50e568d0586a81bc69697"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:a5c3e0c802dfacfbaceafb925c411b211 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a5c3e0c802dfacfbaceafb925c411b211"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a5c3e0c802dfacfbaceafb925c411b211">get_params</a> (self, deep=True)</td></tr>
<tr class="separator:a5c3e0c802dfacfbaceafb925c411b211 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8177e7086e8cbed1fec2bcdae9202c1 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_af8177e7086e8cbed1fec2bcdae9202c1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#af8177e7086e8cbed1fec2bcdae9202c1">set_params</a> (self, **params)</td></tr>
<tr class="separator:af8177e7086e8cbed1fec2bcdae9202c1 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5da47f044a7f6bc188b93722cad7a4c inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ad5da47f044a7f6bc188b93722cad7a4c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ad5da47f044a7f6bc188b93722cad7a4c">__repr__</a> (self, N_CHAR_MAX=700)</td></tr>
<tr class="separator:ad5da47f044a7f6bc188b93722cad7a4c inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f3d56fd989ef4230f70670d6128549e inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a1f3d56fd989ef4230f70670d6128549e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a1f3d56fd989ef4230f70670d6128549e">__getstate__</a> (self)</td></tr>
<tr class="separator:a1f3d56fd989ef4230f70670d6128549e inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e30cf35986d0ed01728b435e83bd427 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a4e30cf35986d0ed01728b435e83bd427"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a4e30cf35986d0ed01728b435e83bd427">__setstate__</a> (self, state)</td></tr>
<tr class="separator:a4e30cf35986d0ed01728b435e83bd427 inherit pub_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a05b3a6520191f5374d95cd12d46cd60a" id="r_a05b3a6520191f5374d95cd12d46cd60a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a05b3a6520191f5374d95cd12d46cd60a">kernel</a></td></tr>
<tr class="separator:a05b3a6520191f5374d95cd12d46cd60a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44deb6e9571be1145e3e2cf4228fca9c" id="r_a44deb6e9571be1145e3e2cf4228fca9c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a44deb6e9571be1145e3e2cf4228fca9c">optimizer</a></td></tr>
<tr class="separator:a44deb6e9571be1145e3e2cf4228fca9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e033db2c979b3021980c95fd2fa5826" id="r_a1e033db2c979b3021980c95fd2fa5826"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a1e033db2c979b3021980c95fd2fa5826">n_restarts_optimizer</a></td></tr>
<tr class="separator:a1e033db2c979b3021980c95fd2fa5826"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af82f13e8d69852d75c8cdefba8d4797f" id="r_af82f13e8d69852d75c8cdefba8d4797f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#af82f13e8d69852d75c8cdefba8d4797f">max_iter_predict</a></td></tr>
<tr class="separator:af82f13e8d69852d75c8cdefba8d4797f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee2915a0ad31f8dcfcd487a36e7ba0ab" id="r_aee2915a0ad31f8dcfcd487a36e7ba0ab"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#aee2915a0ad31f8dcfcd487a36e7ba0ab">warm_start</a></td></tr>
<tr class="separator:aee2915a0ad31f8dcfcd487a36e7ba0ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7432b4bed96e32fb20d5589c1cabf36" id="r_af7432b4bed96e32fb20d5589c1cabf36"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#af7432b4bed96e32fb20d5589c1cabf36">copy_X_train</a></td></tr>
<tr class="separator:af7432b4bed96e32fb20d5589c1cabf36"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab31b3e0a96af9585d53a300626da0bf0" id="r_ab31b3e0a96af9585d53a300626da0bf0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#ab31b3e0a96af9585d53a300626da0bf0">random_state</a></td></tr>
<tr class="separator:ab31b3e0a96af9585d53a300626da0bf0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb35aba00ca1252d9b2bcacb06afec31" id="r_adb35aba00ca1252d9b2bcacb06afec31"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#adb35aba00ca1252d9b2bcacb06afec31">kernel_</a></td></tr>
<tr class="separator:adb35aba00ca1252d9b2bcacb06afec31"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa940f97befc3a8dc8daab15ef7362589" id="r_aa940f97befc3a8dc8daab15ef7362589"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#aa940f97befc3a8dc8daab15ef7362589">rng</a></td></tr>
<tr class="separator:aa940f97befc3a8dc8daab15ef7362589"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5d43244056cab31101e9a920cf333b2" id="r_ab5d43244056cab31101e9a920cf333b2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#ab5d43244056cab31101e9a920cf333b2">X_train_</a></td></tr>
<tr class="separator:ab5d43244056cab31101e9a920cf333b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad3cedd3592b66c776d38ad01f4e88d7" id="r_aad3cedd3592b66c776d38ad01f4e88d7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#aad3cedd3592b66c776d38ad01f4e88d7">y_train_</a></td></tr>
<tr class="separator:aad3cedd3592b66c776d38ad01f4e88d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43109a03a8e89b9ad5cfdae7b38d9d63" id="r_a43109a03a8e89b9ad5cfdae7b38d9d63"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a43109a03a8e89b9ad5cfdae7b38d9d63">classes_</a></td></tr>
<tr class="separator:a43109a03a8e89b9ad5cfdae7b38d9d63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8aaf94f17dca002381b43707d2a6952f" id="r_a8aaf94f17dca002381b43707d2a6952f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a8aaf94f17dca002381b43707d2a6952f">log_marginal_likelihood_value_</a></td></tr>
<tr class="separator:a8aaf94f17dca002381b43707d2a6952f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af37266e91ba0aeb022ab2f5e6c6456f4" id="r_af37266e91ba0aeb022ab2f5e6c6456f4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#af37266e91ba0aeb022ab2f5e6c6456f4">pi_</a></td></tr>
<tr class="separator:af37266e91ba0aeb022ab2f5e6c6456f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf8ccc7291c944cbefb42368c343dc29" id="r_adf8ccc7291c944cbefb42368c343dc29"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#adf8ccc7291c944cbefb42368c343dc29">W_sr_</a></td></tr>
<tr class="separator:adf8ccc7291c944cbefb42368c343dc29"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6b1bb96318c23bfaff0ac519e6593eb" id="r_ae6b1bb96318c23bfaff0ac519e6593eb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#ae6b1bb96318c23bfaff0ac519e6593eb">L_</a></td></tr>
<tr class="separator:ae6b1bb96318c23bfaff0ac519e6593eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e6f3f870000aae1a6bfa5ad39f423f5" id="r_a0e6f3f870000aae1a6bfa5ad39f423f5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a0e6f3f870000aae1a6bfa5ad39f423f5">f_cached</a></td></tr>
<tr class="separator:a0e6f3f870000aae1a6bfa5ad39f423f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:a66d54a0fbf5710ff325104e2d2c9d7b0 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator" id="r_a66d54a0fbf5710ff325104e2d2c9d7b0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a66d54a0fbf5710ff325104e2d2c9d7b0">n_features_in_</a></td></tr>
<tr class="separator:a66d54a0fbf5710ff325104e2d2c9d7b0 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ad6c8c0f63c0b4c97c501765e93cc78 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator" id="r_a2ad6c8c0f63c0b4c97c501765e93cc78"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a2ad6c8c0f63c0b4c97c501765e93cc78">feature_names_in_</a></td></tr>
<tr class="separator:a2ad6c8c0f63c0b4c97c501765e93cc78 inherit pub_attribs_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-methods" name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:ae22c241f608617256861933a6ab3a2fd" id="r_ae22c241f608617256861933a6ab3a2fd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#ae22c241f608617256861933a6ab3a2fd">_posterior_mode</a> (self, K, return_temporaries=False)</td></tr>
<tr class="separator:ae22c241f608617256861933a6ab3a2fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d0ff980a6f428ec6bf5860e54380525" id="r_a7d0ff980a6f428ec6bf5860e54380525"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1gaussian__process_1_1__gpc_1_1___binary_gaussian_process_classifier_laplace.html#a7d0ff980a6f428ec6bf5860e54380525">_constrained_optimization</a> (self, obj_func, initial_theta, bounds)</td></tr>
<tr class="separator:a7d0ff980a6f428ec6bf5860e54380525"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:ab7620691376c89dd6b11583a7ec88056 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ab7620691376c89dd6b11583a7ec88056"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ab7620691376c89dd6b11583a7ec88056">_get_param_names</a> (cls)</td></tr>
<tr class="separator:ab7620691376c89dd6b11583a7ec88056 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8c4c3c1db15de8e006c18fce6b8bad3 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ad8c4c3c1db15de8e006c18fce6b8bad3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ad8c4c3c1db15de8e006c18fce6b8bad3">_more_tags</a> (self)</td></tr>
<tr class="separator:ad8c4c3c1db15de8e006c18fce6b8bad3 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17c0074e0a07bf88909d50bbd89a2735 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a17c0074e0a07bf88909d50bbd89a2735"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a17c0074e0a07bf88909d50bbd89a2735">_get_tags</a> (self)</td></tr>
<tr class="separator:a17c0074e0a07bf88909d50bbd89a2735 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeced67fac6e13c3a6e7f6866e83c02f5 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_aeced67fac6e13c3a6e7f6866e83c02f5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#aeced67fac6e13c3a6e7f6866e83c02f5">_check_n_features</a> (self, X, reset)</td></tr>
<tr class="separator:aeced67fac6e13c3a6e7f6866e83c02f5 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a167be2ae43526843680356c2b2712125 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a167be2ae43526843680356c2b2712125"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a167be2ae43526843680356c2b2712125">_check_feature_names</a> (self, X, *reset)</td></tr>
<tr class="separator:a167be2ae43526843680356c2b2712125 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a846c04fab4a234189ebac04e5ed9b8a6 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a846c04fab4a234189ebac04e5ed9b8a6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a846c04fab4a234189ebac04e5ed9b8a6">_validate_data</a> (self, X=&quot;no_validation&quot;, y=&quot;no_validation&quot;, reset=True, validate_separately=False, **check_params)</td></tr>
<tr class="separator:a846c04fab4a234189ebac04e5ed9b8a6 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8f8e87d8b09ffa6ac9a38403510b839 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_aa8f8e87d8b09ffa6ac9a38403510b839"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#aa8f8e87d8b09ffa6ac9a38403510b839">_validate_params</a> (self)</td></tr>
<tr class="separator:aa8f8e87d8b09ffa6ac9a38403510b839 inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f2a9aeff923062d9b8d64ff8ae9a15f inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a1f2a9aeff923062d9b8d64ff8ae9a15f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a1f2a9aeff923062d9b8d64ff8ae9a15f">_repr_html_</a> (self)</td></tr>
<tr class="separator:a1f2a9aeff923062d9b8d64ff8ae9a15f inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab49884d0348bb8bf19b65d1d68cffcaf inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_ab49884d0348bb8bf19b65d1d68cffcaf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#ab49884d0348bb8bf19b65d1d68cffcaf">_repr_html_inner</a> (self)</td></tr>
<tr class="separator:ab49884d0348bb8bf19b65d1d68cffcaf inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1dde4ef8aac627f20f205e41a0b14efc inherit pro_methods_classsklearn_1_1base_1_1_base_estimator" id="r_a1dde4ef8aac627f20f205e41a0b14efc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#a1dde4ef8aac627f20f205e41a0b14efc">_repr_mimebundle_</a> (self, **kwargs)</td></tr>
<tr class="separator:a1dde4ef8aac627f20f205e41a0b14efc inherit pro_methods_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="inherited" name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pro_attribs_classsklearn_1_1base_1_1_base_estimator"><td colspan="2" onclick="javascript:toggleInherit('pro_attribs_classsklearn_1_1base_1_1_base_estimator')"><img src="closed.png" alt="-"/>&#160;Protected Attributes inherited from <a class="el" href="classsklearn_1_1base_1_1_base_estimator.html">sklearn.base.BaseEstimator</a></td></tr>
<tr class="memitem:aa788e7d07aae196ad4045be35ec03ebd inherit pro_attribs_classsklearn_1_1base_1_1_base_estimator" id="r_aa788e7d07aae196ad4045be35ec03ebd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1base_1_1_base_estimator.html#aa788e7d07aae196ad4045be35ec03ebd">_parameter_constraints</a></td></tr>
<tr class="separator:aa788e7d07aae196ad4045be35ec03ebd inherit pro_attribs_classsklearn_1_1base_1_1_base_estimator"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Binary Gaussian process classification based on Laplace approximation.

The implementation is based on Algorithm 3.1, 3.2, and 5.1 from [RW2006]_.

Internally, the Laplace approximation is used for approximating the
non-Gaussian posterior by a Gaussian.

Currently, the implementation is restricted to using the logistic link
function.

.. versionadded:: 0.18

Parameters
----------
kernel : kernel instance, default=None
    The kernel specifying the covariance function of the GP. If None is
    passed, the kernel "1.0 * RBF(1.0)" is used as default. Note that
    the kernel's hyperparameters are optimized during fitting.

optimizer : 'fmin_l_bfgs_b' or callable, default='fmin_l_bfgs_b'
    Can either be one of the internally supported optimizers for optimizing
    the kernel's parameters, specified by a string, or an externally
    defined optimizer passed as a callable. If a callable is passed, it
    must have the  signature::

        def optimizer(obj_func, initial_theta, bounds):
            # * 'obj_func' is the objective function to be maximized, which
            #   takes the hyperparameters theta as parameter and an
            #   optional flag eval_gradient, which determines if the
            #   gradient is returned additionally to the function value
            # * 'initial_theta': the initial value for theta, which can be
            #   used by local optimizers
            # * 'bounds': the bounds on the values of theta
            ....
            # Returned are the best found hyperparameters theta and
            # the corresponding value of the target function.
            return theta_opt, func_min

    Per default, the 'L-BFGS-B' algorithm from scipy.optimize.minimize
    is used. If None is passed, the kernel's parameters are kept fixed.
    Available internal optimizers are::

        'fmin_l_bfgs_b'

n_restarts_optimizer : int, default=0
    The number of restarts of the optimizer for finding the kernel's
    parameters which maximize the log-marginal likelihood. The first run
    of the optimizer is performed from the kernel's initial parameters,
    the remaining ones (if any) from thetas sampled log-uniform randomly
    from the space of allowed theta-values. If greater than 0, all bounds
    must be finite. Note that n_restarts_optimizer=0 implies that one
    run is performed.

max_iter_predict : int, default=100
    The maximum number of iterations in Newton's method for approximating
    the posterior during predict. Smaller values will reduce computation
    time at the cost of worse results.

warm_start : bool, default=False
    If warm-starts are enabled, the solution of the last Newton iteration
    on the Laplace approximation of the posterior mode is used as
    initialization for the next call of _posterior_mode(). This can speed
    up convergence when _posterior_mode is called several times on similar
    problems as in hyperparameter optimization. See :term:`the Glossary
    &lt;warm_start&gt;`.

copy_X_train : bool, default=True
    If True, a persistent copy of the training data is stored in the
    object. Otherwise, just a reference to the training data is stored,
    which might cause predictions to change if the data is modified
    externally.

random_state : int, RandomState instance or None, default=None
    Determines random number generation used to initialize the centers.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Attributes
----------
X_train_ : array-like of shape (n_samples, n_features) or list of object
    Feature vectors or other representations of training data (also
    required for prediction).

y_train_ : array-like of shape (n_samples,)
    Target values in training data (also required for prediction)

classes_ : array-like of shape (n_classes,)
    Unique class labels.

kernel_ : kernl instance
    The kernel used for prediction. The structure of the kernel is the
    same as the one passed as parameter but with optimized hyperparameters

L_ : array-like of shape (n_samples, n_samples)
    Lower-triangular Cholesky decomposition of the kernel in X_train_

pi_ : array-like of shape (n_samples,)
    The probabilities of the positive class for the training points
    X_train_

W_sr_ : array-like of shape (n_samples,)
    Square root of W, the Hessian of log-likelihood of the latent function
    values for the observed labels. Since W is diagonal, only the diagonal
    of sqrt(W) is stored.

log_marginal_likelihood_value_ : float
    The log-marginal-likelihood of ``self.kernel_.theta``

References
----------
.. [RW2006] `Carl E. Rasmussen and Christopher K.I. Williams,
   "Gaussian Processes for Machine Learning",
   MIT Press 2006 &lt;https://www.gaussianprocess.org/gpml/chapters/RW.pdf&gt;`_
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a0a3ce663076c6963ed727512538e6eb4" name="a0a3ce663076c6963ed727512538e6eb4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a3ce663076c6963ed727512538e6eb4">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>kernel</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>optimizer</em> = <code>&quot;fmin_l_bfgs_b&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_restarts_optimizer</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_iter_predict</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>warm_start</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>copy_X_train</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  163</span>    ):</div>
<div class="line"><span class="lineno">  164</span>        self.kernel = kernel</div>
<div class="line"><span class="lineno">  165</span>        self.optimizer = optimizer</div>
<div class="line"><span class="lineno">  166</span>        self.n_restarts_optimizer = n_restarts_optimizer</div>
<div class="line"><span class="lineno">  167</span>        self.max_iter_predict = max_iter_predict</div>
<div class="line"><span class="lineno">  168</span>        self.warm_start = warm_start</div>
<div class="line"><span class="lineno">  169</span>        self.copy_X_train = copy_X_train</div>
<div class="line"><span class="lineno">  170</span>        self.random_state = random_state</div>
<div class="line"><span class="lineno">  171</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a7d0ff980a6f428ec6bf5860e54380525" name="a7d0ff980a6f428ec6bf5860e54380525"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d0ff980a6f428ec6bf5860e54380525">&#9670;&#160;</a></span>_constrained_optimization()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace._constrained_optimization </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>obj_func</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>initial_theta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>bounds</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  472</span>    <span class="keyword">def </span>_constrained_optimization(self, obj_func, initial_theta, bounds):</div>
<div class="line"><span class="lineno">  473</span>        <span class="keywordflow">if</span> self.optimizer == <span class="stringliteral">&quot;fmin_l_bfgs_b&quot;</span>:</div>
<div class="line"><span class="lineno">  474</span>            opt_res = scipy.optimize.minimize(</div>
<div class="line"><span class="lineno">  475</span>                obj_func, initial_theta, method=<span class="stringliteral">&quot;L-BFGS-B&quot;</span>, jac=<span class="keyword">True</span>, bounds=bounds</div>
<div class="line"><span class="lineno">  476</span>            )</div>
<div class="line"><span class="lineno">  477</span>            _check_optimize_result(<span class="stringliteral">&quot;lbfgs&quot;</span>, opt_res)</div>
<div class="line"><span class="lineno">  478</span>            theta_opt, func_min = opt_res.x, opt_res.fun</div>
<div class="line"><span class="lineno">  479</span>        <span class="keywordflow">elif</span> callable(self.optimizer):</div>
<div class="line"><span class="lineno">  480</span>            theta_opt, func_min = self.optimizer(obj_func, initial_theta, bounds=bounds)</div>
<div class="line"><span class="lineno">  481</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  482</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Unknown optimizer %s.&quot;</span> % self.optimizer)</div>
<div class="line"><span class="lineno">  483</span> </div>
<div class="line"><span class="lineno">  484</span>        <span class="keywordflow">return</span> theta_opt, func_min</div>
<div class="line"><span class="lineno">  485</span> </div>
<div class="line"><span class="lineno">  486</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae22c241f608617256861933a6ab3a2fd" name="ae22c241f608617256861933a6ab3a2fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae22c241f608617256861933a6ab3a2fd">&#9670;&#160;</a></span>_posterior_mode()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace._posterior_mode </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>K</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_temporaries</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Mode-finding for binary Laplace GPC and fixed kernel.

This approximates the posterior of the latent function values for given
inputs and target observations with a Gaussian approximation and uses
Newton's iteration to find the mode of this approximation.
</pre> <div class="fragment"><div class="line"><span class="lineno">  414</span>    <span class="keyword">def </span>_posterior_mode(self, K, return_temporaries=False):</div>
<div class="line"><span class="lineno">  415</span>        <span class="stringliteral">&quot;&quot;&quot;Mode-finding for binary Laplace GPC and fixed kernel.</span></div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral">        This approximates the posterior of the latent function values for given</span></div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">        inputs and target observations with a Gaussian approximation and uses</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">        Newton&#39;s iteration to find the mode of this approximation.</span></div>
<div class="line"><span class="lineno">  420</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  421</span>        <span class="comment"># Based on Algorithm 3.1 of GPML</span></div>
<div class="line"><span class="lineno">  422</span> </div>
<div class="line"><span class="lineno">  423</span>        <span class="comment"># If warm_start are enabled, we reuse the last solution for the</span></div>
<div class="line"><span class="lineno">  424</span>        <span class="comment"># posterior mode as initialization; otherwise, we initialize with 0</span></div>
<div class="line"><span class="lineno">  425</span>        <span class="keywordflow">if</span> (</div>
<div class="line"><span class="lineno">  426</span>            self.warm_start</div>
<div class="line"><span class="lineno">  427</span>            <span class="keywordflow">and</span> hasattr(self, <span class="stringliteral">&quot;f_cached&quot;</span>)</div>
<div class="line"><span class="lineno">  428</span>            <span class="keywordflow">and</span> self.f_cached.shape == self.y_train_.shape</div>
<div class="line"><span class="lineno">  429</span>        ):</div>
<div class="line"><span class="lineno">  430</span>            f = self.f_cached</div>
<div class="line"><span class="lineno">  431</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  432</span>            f = np.zeros_like(self.y_train_, dtype=np.float64)</div>
<div class="line"><span class="lineno">  433</span> </div>
<div class="line"><span class="lineno">  434</span>        <span class="comment"># Use Newton&#39;s iteration method to find mode of Laplace approximation</span></div>
<div class="line"><span class="lineno">  435</span>        log_marginal_likelihood = -np.inf</div>
<div class="line"><span class="lineno">  436</span>        <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(self.max_iter_predict):</div>
<div class="line"><span class="lineno">  437</span>            <span class="comment"># Line 4</span></div>
<div class="line"><span class="lineno">  438</span>            pi = expit(f)</div>
<div class="line"><span class="lineno">  439</span>            W = pi * (1 - pi)</div>
<div class="line"><span class="lineno">  440</span>            <span class="comment"># Line 5</span></div>
<div class="line"><span class="lineno">  441</span>            W_sr = np.sqrt(W)</div>
<div class="line"><span class="lineno">  442</span>            W_sr_K = W_sr[:, np.newaxis] * K</div>
<div class="line"><span class="lineno">  443</span>            B = np.eye(W.shape[0]) + W_sr_K * W_sr</div>
<div class="line"><span class="lineno">  444</span>            L = cholesky(B, lower=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  445</span>            <span class="comment"># Line 6</span></div>
<div class="line"><span class="lineno">  446</span>            b = W * f + (self.y_train_ - pi)</div>
<div class="line"><span class="lineno">  447</span>            <span class="comment"># Line 7</span></div>
<div class="line"><span class="lineno">  448</span>            a = b - W_sr * cho_solve((L, <span class="keyword">True</span>), W_sr_K.dot(b))</div>
<div class="line"><span class="lineno">  449</span>            <span class="comment"># Line 8</span></div>
<div class="line"><span class="lineno">  450</span>            f = K.dot(a)</div>
<div class="line"><span class="lineno">  451</span> </div>
<div class="line"><span class="lineno">  452</span>            <span class="comment"># Line 10: Compute log marginal likelihood in loop and use as</span></div>
<div class="line"><span class="lineno">  453</span>            <span class="comment">#          convergence criterion</span></div>
<div class="line"><span class="lineno">  454</span>            lml = (</div>
<div class="line"><span class="lineno">  455</span>                -0.5 * a.T.dot(f)</div>
<div class="line"><span class="lineno">  456</span>                - np.log1p(np.exp(-(self.y_train_ * 2 - 1) * f)).sum()</div>
<div class="line"><span class="lineno">  457</span>                - np.log(np.diag(L)).sum()</div>
<div class="line"><span class="lineno">  458</span>            )</div>
<div class="line"><span class="lineno">  459</span>            <span class="comment"># Check if we have converged (log marginal likelihood does</span></div>
<div class="line"><span class="lineno">  460</span>            <span class="comment"># not decrease)</span></div>
<div class="line"><span class="lineno">  461</span>            <span class="comment"># XXX: more complex convergence criterion</span></div>
<div class="line"><span class="lineno">  462</span>            <span class="keywordflow">if</span> lml - log_marginal_likelihood &lt; 1e-10:</div>
<div class="line"><span class="lineno">  463</span>                <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno">  464</span>            log_marginal_likelihood = lml</div>
<div class="line"><span class="lineno">  465</span> </div>
<div class="line"><span class="lineno">  466</span>        self.f_cached = f  <span class="comment"># Remember solution for later warm-starts</span></div>
<div class="line"><span class="lineno">  467</span>        <span class="keywordflow">if</span> return_temporaries:</div>
<div class="line"><span class="lineno">  468</span>            <span class="keywordflow">return</span> log_marginal_likelihood, (pi, W_sr, L, b, a)</div>
<div class="line"><span class="lineno">  469</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  470</span>            <span class="keywordflow">return</span> log_marginal_likelihood</div>
<div class="line"><span class="lineno">  471</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae67dd48f0c6e0310c59b235aad8d10b3" name="ae67dd48f0c6e0310c59b235aad8d10b3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae67dd48f0c6e0310c59b235aad8d10b3">&#9670;&#160;</a></span>fit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.fit </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Fit Gaussian process classification model.

Parameters
----------
X : array-like of shape (n_samples, n_features) or list of object
    Feature vectors or other representations of training data.

y : array-like of shape (n_samples,)
    Target values, must be binary.

Returns
-------
self : returns an instance of self.
</pre> <div class="fragment"><div class="line"><span class="lineno">  172</span>    <span class="keyword">def </span>fit(self, X, y):</div>
<div class="line"><span class="lineno">  173</span>        <span class="stringliteral">&quot;&quot;&quot;Fit Gaussian process classification model.</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">        X : array-like of shape (n_samples, n_features) or list of object</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral">            Feature vectors or other representations of training data.</span></div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">        y : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">            Target values, must be binary.</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">        self : returns an instance of self.</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  187</span>        <span class="keywordflow">if</span> self.kernel <span class="keywordflow">is</span> <span class="keywordtype">None</span>:  <span class="comment"># Use an RBF kernel as default</span></div>
<div class="line"><span class="lineno">  188</span>            self.kernel_ = C(1.0, constant_value_bounds=<span class="stringliteral">&quot;fixed&quot;</span>) * RBF(</div>
<div class="line"><span class="lineno">  189</span>                1.0, length_scale_bounds=<span class="stringliteral">&quot;fixed&quot;</span></div>
<div class="line"><span class="lineno">  190</span>            )</div>
<div class="line"><span class="lineno">  191</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  192</span>            self.kernel_ = clone(self.kernel)</div>
<div class="line"><span class="lineno">  193</span> </div>
<div class="line"><span class="lineno">  194</span>        self.rng = check_random_state(self.random_state)</div>
<div class="line"><span class="lineno">  195</span> </div>
<div class="line"><span class="lineno">  196</span>        self.X_train_ = np.copy(X) <span class="keywordflow">if</span> self.copy_X_train <span class="keywordflow">else</span> X</div>
<div class="line"><span class="lineno">  197</span> </div>
<div class="line"><span class="lineno">  198</span>        <span class="comment"># Encode class labels and check that it is a binary classification</span></div>
<div class="line"><span class="lineno">  199</span>        <span class="comment"># problem</span></div>
<div class="line"><span class="lineno">  200</span>        label_encoder = LabelEncoder()</div>
<div class="line"><span class="lineno">  201</span>        self.y_train_ = label_encoder.fit_transform(y)</div>
<div class="line"><span class="lineno">  202</span>        self.classes_ = label_encoder.classes_</div>
<div class="line"><span class="lineno">  203</span>        <span class="keywordflow">if</span> self.classes_.size &gt; 2:</div>
<div class="line"><span class="lineno">  204</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  205</span>                <span class="stringliteral">&quot;%s supports only binary classification. y contains classes %s&quot;</span></div>
<div class="line"><span class="lineno">  206</span>                % (self.__class__.__name__, self.classes_)</div>
<div class="line"><span class="lineno">  207</span>            )</div>
<div class="line"><span class="lineno">  208</span>        <span class="keywordflow">elif</span> self.classes_.size == 1:</div>
<div class="line"><span class="lineno">  209</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  210</span>                <span class="stringliteral">&quot;{0:s} requires 2 classes; got {1:d} class&quot;</span>.format(</div>
<div class="line"><span class="lineno">  211</span>                    self.__class__.__name__, self.classes_.size</div>
<div class="line"><span class="lineno">  212</span>                )</div>
<div class="line"><span class="lineno">  213</span>            )</div>
<div class="line"><span class="lineno">  214</span> </div>
<div class="line"><span class="lineno">  215</span>        <span class="keywordflow">if</span> self.optimizer <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> self.kernel_.n_dims &gt; 0:</div>
<div class="line"><span class="lineno">  216</span>            <span class="comment"># Choose hyperparameters based on maximizing the log-marginal</span></div>
<div class="line"><span class="lineno">  217</span>            <span class="comment"># likelihood (potentially starting from several initial values)</span></div>
<div class="line"><span class="lineno">  218</span>            <span class="keyword">def </span>obj_func(theta, eval_gradient=True):</div>
<div class="line"><span class="lineno">  219</span>                <span class="keywordflow">if</span> eval_gradient:</div>
<div class="line"><span class="lineno">  220</span>                    lml, grad = self.log_marginal_likelihood(</div>
<div class="line"><span class="lineno">  221</span>                        theta, eval_gradient=<span class="keyword">True</span>, clone_kernel=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  222</span>                    )</div>
<div class="line"><span class="lineno">  223</span>                    <span class="keywordflow">return</span> -lml, -grad</div>
<div class="line"><span class="lineno">  224</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  225</span>                    <span class="keywordflow">return</span> -self.log_marginal_likelihood(theta, clone_kernel=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  226</span> </div>
<div class="line"><span class="lineno">  227</span>            <span class="comment"># First optimize starting from theta specified in kernel</span></div>
<div class="line"><span class="lineno">  228</span>            optima = [</div>
<div class="line"><span class="lineno">  229</span>                self._constrained_optimization(</div>
<div class="line"><span class="lineno">  230</span>                    obj_func, self.kernel_.theta, self.kernel_.bounds</div>
<div class="line"><span class="lineno">  231</span>                )</div>
<div class="line"><span class="lineno">  232</span>            ]</div>
<div class="line"><span class="lineno">  233</span> </div>
<div class="line"><span class="lineno">  234</span>            <span class="comment"># Additional runs are performed from log-uniform chosen initial</span></div>
<div class="line"><span class="lineno">  235</span>            <span class="comment"># theta</span></div>
<div class="line"><span class="lineno">  236</span>            <span class="keywordflow">if</span> self.n_restarts_optimizer &gt; 0:</div>
<div class="line"><span class="lineno">  237</span>                <span class="keywordflow">if</span> <span class="keywordflow">not</span> np.isfinite(self.kernel_.bounds).all():</div>
<div class="line"><span class="lineno">  238</span>                    <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  239</span>                        <span class="stringliteral">&quot;Multiple optimizer restarts (n_restarts_optimizer&gt;0) &quot;</span></div>
<div class="line"><span class="lineno">  240</span>                        <span class="stringliteral">&quot;requires that all bounds are finite.&quot;</span></div>
<div class="line"><span class="lineno">  241</span>                    )</div>
<div class="line"><span class="lineno">  242</span>                bounds = self.kernel_.bounds</div>
<div class="line"><span class="lineno">  243</span>                <span class="keywordflow">for</span> iteration <span class="keywordflow">in</span> range(self.n_restarts_optimizer):</div>
<div class="line"><span class="lineno">  244</span>                    theta_initial = np.exp(self.rng.uniform(bounds[:, 0], bounds[:, 1]))</div>
<div class="line"><span class="lineno">  245</span>                    optima.append(</div>
<div class="line"><span class="lineno">  246</span>                        self._constrained_optimization(obj_func, theta_initial, bounds)</div>
<div class="line"><span class="lineno">  247</span>                    )</div>
<div class="line"><span class="lineno">  248</span>            <span class="comment"># Select result from run with minimal (negative) log-marginal</span></div>
<div class="line"><span class="lineno">  249</span>            <span class="comment"># likelihood</span></div>
<div class="line"><span class="lineno">  250</span>            lml_values = list(map(itemgetter(1), optima))</div>
<div class="line"><span class="lineno">  251</span>            self.kernel_.theta = optima[np.argmin(lml_values)][0]</div>
<div class="line"><span class="lineno">  252</span>            self.kernel_._check_bounds_params()</div>
<div class="line"><span class="lineno">  253</span> </div>
<div class="line"><span class="lineno">  254</span>            self.log_marginal_likelihood_value_ = -np.min(lml_values)</div>
<div class="line"><span class="lineno">  255</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  256</span>            self.log_marginal_likelihood_value_ = self.log_marginal_likelihood(</div>
<div class="line"><span class="lineno">  257</span>                self.kernel_.theta</div>
<div class="line"><span class="lineno">  258</span>            )</div>
<div class="line"><span class="lineno">  259</span> </div>
<div class="line"><span class="lineno">  260</span>        <span class="comment"># Precompute quantities required for predictions which are independent</span></div>
<div class="line"><span class="lineno">  261</span>        <span class="comment"># of actual query points</span></div>
<div class="line"><span class="lineno">  262</span>        K = self.kernel_(self.X_train_)</div>
<div class="line"><span class="lineno">  263</span> </div>
<div class="line"><span class="lineno">  264</span>        _, (self.pi_, self.W_sr_, self.L_, _, _) = self._posterior_mode(</div>
<div class="line"><span class="lineno">  265</span>            K, return_temporaries=<span class="keyword">True</span></div>
<div class="line"><span class="lineno">  266</span>        )</div>
<div class="line"><span class="lineno">  267</span> </div>
<div class="line"><span class="lineno">  268</span>        <span class="keywordflow">return</span> self</div>
<div class="line"><span class="lineno">  269</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2d1847f696d50e568d0586a81bc69697" name="a2d1847f696d50e568d0586a81bc69697"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d1847f696d50e568d0586a81bc69697">&#9670;&#160;</a></span>log_marginal_likelihood()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.log_marginal_likelihood </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>theta</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>eval_gradient</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clone_kernel</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns log-marginal likelihood of theta for training data.

Parameters
----------
theta : array-like of shape (n_kernel_params,), default=None
    Kernel hyperparameters for which the log-marginal likelihood is
    evaluated. If None, the precomputed log_marginal_likelihood
    of ``self.kernel_.theta`` is returned.

eval_gradient : bool, default=False
    If True, the gradient of the log-marginal likelihood with respect
    to the kernel hyperparameters at position theta is returned
    additionally. If True, theta must not be None.

clone_kernel : bool, default=True
    If True, the kernel attribute is copied. If False, the kernel
    attribute is modified, but may result in a performance improvement.

Returns
-------
log_likelihood : float
    Log-marginal likelihood of theta for training data.

log_likelihood_gradient : ndarray of shape (n_kernel_params,), \
        optional
    Gradient of the log-marginal likelihood with respect to the kernel
    hyperparameters at position theta.
    Only returned when `eval_gradient` is True.
</pre> <div class="fragment"><div class="line"><span class="lineno">  337</span>    ):</div>
<div class="line"><span class="lineno">  338</span>        <span class="stringliteral">&quot;&quot;&quot;Returns log-marginal likelihood of theta for training data.</span></div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  341</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  342</span><span class="stringliteral">        theta : array-like of shape (n_kernel_params,), default=None</span></div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral">            Kernel hyperparameters for which the log-marginal likelihood is</span></div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">            evaluated. If None, the precomputed log_marginal_likelihood</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral">            of ``self.kernel_.theta`` is returned.</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">        eval_gradient : bool, default=False</span></div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral">            If True, the gradient of the log-marginal likelihood with respect</span></div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">            to the kernel hyperparameters at position theta is returned</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">            additionally. If True, theta must not be None.</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral">        clone_kernel : bool, default=True</span></div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral">            If True, the kernel attribute is copied. If False, the kernel</span></div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">            attribute is modified, but may result in a performance improvement.</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral">        log_likelihood : float</span></div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral">            Log-marginal likelihood of theta for training data.</span></div>
<div class="line"><span class="lineno">  360</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  361</span><span class="stringliteral">        log_likelihood_gradient : ndarray of shape (n_kernel_params,), \</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral">                optional</span></div>
<div class="line"><span class="lineno">  363</span><span class="stringliteral">            Gradient of the log-marginal likelihood with respect to the kernel</span></div>
<div class="line"><span class="lineno">  364</span><span class="stringliteral">            hyperparameters at position theta.</span></div>
<div class="line"><span class="lineno">  365</span><span class="stringliteral">            Only returned when `eval_gradient` is True.</span></div>
<div class="line"><span class="lineno">  366</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  367</span>        <span class="keywordflow">if</span> theta <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  368</span>            <span class="keywordflow">if</span> eval_gradient:</div>
<div class="line"><span class="lineno">  369</span>                <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Gradient can only be evaluated for theta!=None&quot;</span>)</div>
<div class="line"><span class="lineno">  370</span>            <span class="keywordflow">return</span> self.log_marginal_likelihood_value_</div>
<div class="line"><span class="lineno">  371</span> </div>
<div class="line"><span class="lineno">  372</span>        <span class="keywordflow">if</span> clone_kernel:</div>
<div class="line"><span class="lineno">  373</span>            kernel = self.kernel_.clone_with_theta(theta)</div>
<div class="line"><span class="lineno">  374</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  375</span>            kernel = self.kernel_</div>
<div class="line"><span class="lineno">  376</span>            kernel.theta = theta</div>
<div class="line"><span class="lineno">  377</span> </div>
<div class="line"><span class="lineno">  378</span>        <span class="keywordflow">if</span> eval_gradient:</div>
<div class="line"><span class="lineno">  379</span>            K, K_gradient = kernel(self.X_train_, eval_gradient=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  380</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  381</span>            K = kernel(self.X_train_)</div>
<div class="line"><span class="lineno">  382</span> </div>
<div class="line"><span class="lineno">  383</span>        <span class="comment"># Compute log-marginal-likelihood Z and also store some temporaries</span></div>
<div class="line"><span class="lineno">  384</span>        <span class="comment"># which can be reused for computing Z&#39;s gradient</span></div>
<div class="line"><span class="lineno">  385</span>        Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  386</span> </div>
<div class="line"><span class="lineno">  387</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> eval_gradient:</div>
<div class="line"><span class="lineno">  388</span>            <span class="keywordflow">return</span> Z</div>
<div class="line"><span class="lineno">  389</span> </div>
<div class="line"><span class="lineno">  390</span>        <span class="comment"># Compute gradient based on Algorithm 5.1 of GPML</span></div>
<div class="line"><span class="lineno">  391</span>        d_Z = np.empty(theta.shape[0])</div>
<div class="line"><span class="lineno">  392</span>        <span class="comment"># XXX: Get rid of the np.diag() in the next line</span></div>
<div class="line"><span class="lineno">  393</span>        R = W_sr[:, np.newaxis] * cho_solve((L, <span class="keyword">True</span>), np.diag(W_sr))  <span class="comment"># Line 7</span></div>
<div class="line"><span class="lineno">  394</span>        C = solve(L, W_sr[:, np.newaxis] * K)  <span class="comment"># Line 8</span></div>
<div class="line"><span class="lineno">  395</span>        <span class="comment"># Line 9: (use einsum to compute np.diag(C.T.dot(C))))</span></div>
<div class="line"><span class="lineno">  396</span>        s_2 = (</div>
<div class="line"><span class="lineno">  397</span>            -0.5</div>
<div class="line"><span class="lineno">  398</span>            * (np.diag(K) - np.einsum(<span class="stringliteral">&quot;ij, ij -&gt; j&quot;</span>, C, C))</div>
<div class="line"><span class="lineno">  399</span>            * (pi * (1 - pi) * (1 - 2 * pi))</div>
<div class="line"><span class="lineno">  400</span>        )  <span class="comment"># third derivative</span></div>
<div class="line"><span class="lineno">  401</span> </div>
<div class="line"><span class="lineno">  402</span>        <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(d_Z.shape[0]):</div>
<div class="line"><span class="lineno">  403</span>            C = K_gradient[:, :, j]  <span class="comment"># Line 11</span></div>
<div class="line"><span class="lineno">  404</span>            <span class="comment"># Line 12: (R.T.ravel().dot(C.ravel()) = np.trace(R.dot(C)))</span></div>
<div class="line"><span class="lineno">  405</span>            s_1 = 0.5 * a.T.dot(C).dot(a) - 0.5 * R.T.ravel().dot(C.ravel())</div>
<div class="line"><span class="lineno">  406</span> </div>
<div class="line"><span class="lineno">  407</span>            b = C.dot(self.y_train_ - pi)  <span class="comment"># Line 13</span></div>
<div class="line"><span class="lineno">  408</span>            s_3 = b - K.dot(R.dot(b))  <span class="comment"># Line 14</span></div>
<div class="line"><span class="lineno">  409</span> </div>
<div class="line"><span class="lineno">  410</span>            d_Z[j] = s_1 + s_2.T.dot(s_3)  <span class="comment"># Line 15</span></div>
<div class="line"><span class="lineno">  411</span> </div>
<div class="line"><span class="lineno">  412</span>        <span class="keywordflow">return</span> Z, d_Z</div>
<div class="line"><span class="lineno">  413</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6bb3022c2a82c87ed0b9447e5f0e8e29" name="a6bb3022c2a82c87ed0b9447e5f0e8e29"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6bb3022c2a82c87ed0b9447e5f0e8e29">&#9670;&#160;</a></span>predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.predict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Perform classification on an array of test vectors X.

Parameters
----------
X : array-like of shape (n_samples, n_features) or list of object
    Query points where the GP is evaluated for classification.

Returns
-------
C : ndarray of shape (n_samples,)
    Predicted target values for X, values are from ``classes_``
</pre> <div class="fragment"><div class="line"><span class="lineno">  270</span>    <span class="keyword">def </span>predict(self, X):</div>
<div class="line"><span class="lineno">  271</span>        <span class="stringliteral">&quot;&quot;&quot;Perform classification on an array of test vectors X.</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">        X : array-like of shape (n_samples, n_features) or list of object</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">            Query points where the GP is evaluated for classification.</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">        C : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">            Predicted target values for X, values are from ``classes_``</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  283</span>        check_is_fitted(self)</div>
<div class="line"><span class="lineno">  284</span> </div>
<div class="line"><span class="lineno">  285</span>        <span class="comment"># As discussed on Section 3.4.2 of GPML, for making hard binary</span></div>
<div class="line"><span class="lineno">  286</span>        <span class="comment"># decisions, it is enough to compute the MAP of the posterior and</span></div>
<div class="line"><span class="lineno">  287</span>        <span class="comment"># pass it through the link function</span></div>
<div class="line"><span class="lineno">  288</span>        K_star = self.kernel_(self.X_train_, X)  <span class="comment"># K_star =k(x_star)</span></div>
<div class="line"><span class="lineno">  289</span>        f_star = K_star.T.dot(self.y_train_ - self.pi_)  <span class="comment"># Algorithm 3.2,Line 4</span></div>
<div class="line"><span class="lineno">  290</span> </div>
<div class="line"><span class="lineno">  291</span>        <span class="keywordflow">return</span> np.where(f_star &gt; 0, self.classes_[1], self.classes_[0])</div>
<div class="line"><span class="lineno">  292</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af38bcd8f6f15205189cb1b89c2e2c128" name="af38bcd8f6f15205189cb1b89c2e2c128"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af38bcd8f6f15205189cb1b89c2e2c128">&#9670;&#160;</a></span>predict_proba()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.predict_proba </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return probability estimates for the test vector X.

Parameters
----------
X : array-like of shape (n_samples, n_features) or list of object
    Query points where the GP is evaluated for classification.

Returns
-------
C : array-like of shape (n_samples, n_classes)
    Returns the probability of the samples for each class in
    the model. The columns correspond to the classes in sorted
    order, as they appear in the attribute ``classes_``.
</pre> <div class="fragment"><div class="line"><span class="lineno">  293</span>    <span class="keyword">def </span>predict_proba(self, X):</div>
<div class="line"><span class="lineno">  294</span>        <span class="stringliteral">&quot;&quot;&quot;Return probability estimates for the test vector X.</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">        X : array-like of shape (n_samples, n_features) or list of object</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">            Query points where the GP is evaluated for classification.</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">        C : array-like of shape (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">            Returns the probability of the samples for each class in</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">            the model. The columns correspond to the classes in sorted</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">            order, as they appear in the attribute ``classes_``.</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  308</span>        check_is_fitted(self)</div>
<div class="line"><span class="lineno">  309</span> </div>
<div class="line"><span class="lineno">  310</span>        <span class="comment"># Based on Algorithm 3.2 of GPML</span></div>
<div class="line"><span class="lineno">  311</span>        K_star = self.kernel_(self.X_train_, X)  <span class="comment"># K_star =k(x_star)</span></div>
<div class="line"><span class="lineno">  312</span>        f_star = K_star.T.dot(self.y_train_ - self.pi_)  <span class="comment"># Line 4</span></div>
<div class="line"><span class="lineno">  313</span>        v = solve(self.L_, self.W_sr_[:, np.newaxis] * K_star)  <span class="comment"># Line 5</span></div>
<div class="line"><span class="lineno">  314</span>        <span class="comment"># Line 6 (compute np.diag(v.T.dot(v)) via einsum)</span></div>
<div class="line"><span class="lineno">  315</span>        var_f_star = self.kernel_.diag(X) - np.einsum(<span class="stringliteral">&quot;ij,ij-&gt;j&quot;</span>, v, v)</div>
<div class="line"><span class="lineno">  316</span> </div>
<div class="line"><span class="lineno">  317</span>        <span class="comment"># Line 7:</span></div>
<div class="line"><span class="lineno">  318</span>        <span class="comment"># Approximate \int log(z) * N(z | f_star, var_f_star)</span></div>
<div class="line"><span class="lineno">  319</span>        <span class="comment"># Approximation is due to Williams &amp; Barber, &quot;Bayesian Classification</span></div>
<div class="line"><span class="lineno">  320</span>        <span class="comment"># with Gaussian Processes&quot;, Appendix A: Approximate the logistic</span></div>
<div class="line"><span class="lineno">  321</span>        <span class="comment"># sigmoid by a linear combination of 5 error functions.</span></div>
<div class="line"><span class="lineno">  322</span>        <span class="comment"># For information on how this integral can be computed see</span></div>
<div class="line"><span class="lineno">  323</span>        <span class="comment"># blitiri.blogspot.de/2012/11/gaussian-integral-of-error-function.html</span></div>
<div class="line"><span class="lineno">  324</span>        alpha = 1 / (2 * var_f_star)</div>
<div class="line"><span class="lineno">  325</span>        gamma = LAMBDAS * f_star</div>
<div class="line"><span class="lineno">  326</span>        integrals = (</div>
<div class="line"><span class="lineno">  327</span>            np.sqrt(np.pi / alpha)</div>
<div class="line"><span class="lineno">  328</span>            * erf(gamma * np.sqrt(alpha / (alpha + LAMBDAS**2)))</div>
<div class="line"><span class="lineno">  329</span>            / (2 * np.sqrt(var_f_star * 2 * np.pi))</div>
<div class="line"><span class="lineno">  330</span>        )</div>
<div class="line"><span class="lineno">  331</span>        pi_star = (COEFS * integrals).sum(axis=0) + 0.5 * COEFS.sum()</div>
<div class="line"><span class="lineno">  332</span> </div>
<div class="line"><span class="lineno">  333</span>        <span class="keywordflow">return</span> np.vstack((1 - pi_star, pi_star)).T</div>
<div class="line"><span class="lineno">  334</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a43109a03a8e89b9ad5cfdae7b38d9d63" name="a43109a03a8e89b9ad5cfdae7b38d9d63"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a43109a03a8e89b9ad5cfdae7b38d9d63">&#9670;&#160;</a></span>classes_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.classes_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af7432b4bed96e32fb20d5589c1cabf36" name="af7432b4bed96e32fb20d5589c1cabf36"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af7432b4bed96e32fb20d5589c1cabf36">&#9670;&#160;</a></span>copy_X_train</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.copy_X_train</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0e6f3f870000aae1a6bfa5ad39f423f5" name="a0e6f3f870000aae1a6bfa5ad39f423f5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e6f3f870000aae1a6bfa5ad39f423f5">&#9670;&#160;</a></span>f_cached</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.f_cached</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a05b3a6520191f5374d95cd12d46cd60a" name="a05b3a6520191f5374d95cd12d46cd60a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a05b3a6520191f5374d95cd12d46cd60a">&#9670;&#160;</a></span>kernel</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.kernel</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adb35aba00ca1252d9b2bcacb06afec31" name="adb35aba00ca1252d9b2bcacb06afec31"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb35aba00ca1252d9b2bcacb06afec31">&#9670;&#160;</a></span>kernel_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.kernel_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae6b1bb96318c23bfaff0ac519e6593eb" name="ae6b1bb96318c23bfaff0ac519e6593eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6b1bb96318c23bfaff0ac519e6593eb">&#9670;&#160;</a></span>L_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.L_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8aaf94f17dca002381b43707d2a6952f" name="a8aaf94f17dca002381b43707d2a6952f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8aaf94f17dca002381b43707d2a6952f">&#9670;&#160;</a></span>log_marginal_likelihood_value_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.log_marginal_likelihood_value_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af82f13e8d69852d75c8cdefba8d4797f" name="af82f13e8d69852d75c8cdefba8d4797f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af82f13e8d69852d75c8cdefba8d4797f">&#9670;&#160;</a></span>max_iter_predict</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.max_iter_predict</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a1e033db2c979b3021980c95fd2fa5826" name="a1e033db2c979b3021980c95fd2fa5826"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e033db2c979b3021980c95fd2fa5826">&#9670;&#160;</a></span>n_restarts_optimizer</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.n_restarts_optimizer</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a44deb6e9571be1145e3e2cf4228fca9c" name="a44deb6e9571be1145e3e2cf4228fca9c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44deb6e9571be1145e3e2cf4228fca9c">&#9670;&#160;</a></span>optimizer</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.optimizer</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af37266e91ba0aeb022ab2f5e6c6456f4" name="af37266e91ba0aeb022ab2f5e6c6456f4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af37266e91ba0aeb022ab2f5e6c6456f4">&#9670;&#160;</a></span>pi_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.pi_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab31b3e0a96af9585d53a300626da0bf0" name="ab31b3e0a96af9585d53a300626da0bf0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab31b3e0a96af9585d53a300626da0bf0">&#9670;&#160;</a></span>random_state</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.random_state</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa940f97befc3a8dc8daab15ef7362589" name="aa940f97befc3a8dc8daab15ef7362589"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa940f97befc3a8dc8daab15ef7362589">&#9670;&#160;</a></span>rng</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.rng</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adf8ccc7291c944cbefb42368c343dc29" name="adf8ccc7291c944cbefb42368c343dc29"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adf8ccc7291c944cbefb42368c343dc29">&#9670;&#160;</a></span>W_sr_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.W_sr_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aee2915a0ad31f8dcfcd487a36e7ba0ab" name="aee2915a0ad31f8dcfcd487a36e7ba0ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee2915a0ad31f8dcfcd487a36e7ba0ab">&#9670;&#160;</a></span>warm_start</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.warm_start</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab5d43244056cab31101e9a920cf333b2" name="ab5d43244056cab31101e9a920cf333b2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab5d43244056cab31101e9a920cf333b2">&#9670;&#160;</a></span>X_train_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.X_train_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aad3cedd3592b66c776d38ad01f4e88d7" name="aad3cedd3592b66c776d38ad01f4e88d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aad3cedd3592b66c776d38ad01f4e88d7">&#9670;&#160;</a></span>y_train_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.gaussian_process._gpc._BinaryGaussianProcessClassifierLaplace.y_train_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/rafael/Documents/GitHub/PUC-GCES-PY/Tp-GCS-Rafael-Augusto/venv/lib/python3.9/site-packages/sklearn/gaussian_process/<a class="el" href="__gpc_8py.html">_gpc.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
