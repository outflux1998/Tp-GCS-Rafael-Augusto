<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.ensemble.tests.test_bagging Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble.html">ensemble</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests.html">tests</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html">test_bagging</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.ensemble.tests.test_bagging Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1ensemble_1_1tests_1_1test__bagging_1_1_dummy_size_estimator.html">DummySizeEstimator</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1ensemble_1_1tests_1_1test__bagging_1_1_dummy_zero_estimator.html">DummyZeroEstimator</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ae8035dd162ae6187ba95acd61ba7bec0" id="r_ae8035dd162ae6187ba95acd61ba7bec0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#ae8035dd162ae6187ba95acd61ba7bec0">test_classification</a> ()</td></tr>
<tr class="separator:ae8035dd162ae6187ba95acd61ba7bec0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec09a257f968189083517950a262f57a" id="r_aec09a257f968189083517950a262f57a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#aec09a257f968189083517950a262f57a">test_sparse_classification</a> (sparse_format, params, method)</td></tr>
<tr class="separator:aec09a257f968189083517950a262f57a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c5b3b53d3af8d71c1ec3cd2c8018e59" id="r_a4c5b3b53d3af8d71c1ec3cd2c8018e59"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a4c5b3b53d3af8d71c1ec3cd2c8018e59">test_regression</a> ()</td></tr>
<tr class="separator:a4c5b3b53d3af8d71c1ec3cd2c8018e59"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a71b3badbdbdea2daeb407bd5f59a4c50" id="r_a71b3badbdbdea2daeb407bd5f59a4c50"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a71b3badbdbdea2daeb407bd5f59a4c50">test_sparse_regression</a> ()</td></tr>
<tr class="separator:a71b3badbdbdea2daeb407bd5f59a4c50"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a436245d25043d8e01dc96518641481ae" id="r_a436245d25043d8e01dc96518641481ae"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a436245d25043d8e01dc96518641481ae">test_bootstrap_samples</a> ()</td></tr>
<tr class="separator:a436245d25043d8e01dc96518641481ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4fbe25eb94a518d5e32337d8aa284c1" id="r_ae4fbe25eb94a518d5e32337d8aa284c1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#ae4fbe25eb94a518d5e32337d8aa284c1">test_bootstrap_features</a> ()</td></tr>
<tr class="separator:ae4fbe25eb94a518d5e32337d8aa284c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02d125fed33e13114587bf443259cf3d" id="r_a02d125fed33e13114587bf443259cf3d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a02d125fed33e13114587bf443259cf3d">test_probability</a> ()</td></tr>
<tr class="separator:a02d125fed33e13114587bf443259cf3d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e95027f0dfcbfcd849566be0f814e01" id="r_a9e95027f0dfcbfcd849566be0f814e01"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a9e95027f0dfcbfcd849566be0f814e01">test_oob_score_classification</a> ()</td></tr>
<tr class="separator:a9e95027f0dfcbfcd849566be0f814e01"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2957246ba9ecd0c5f921d864c0e71904" id="r_a2957246ba9ecd0c5f921d864c0e71904"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a2957246ba9ecd0c5f921d864c0e71904">test_oob_score_regression</a> ()</td></tr>
<tr class="separator:a2957246ba9ecd0c5f921d864c0e71904"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59dd0edb3a0342ab2e6e4c2a7b6e2587" id="r_a59dd0edb3a0342ab2e6e4c2a7b6e2587"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a59dd0edb3a0342ab2e6e4c2a7b6e2587">test_single_estimator</a> ()</td></tr>
<tr class="separator:a59dd0edb3a0342ab2e6e4c2a7b6e2587"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3dc21f8e4efecb1a007d37989e31356" id="r_ae3dc21f8e4efecb1a007d37989e31356"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#ae3dc21f8e4efecb1a007d37989e31356">test_error</a> ()</td></tr>
<tr class="separator:ae3dc21f8e4efecb1a007d37989e31356"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cd630c927282efac212b1e3beae4491" id="r_a0cd630c927282efac212b1e3beae4491"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a0cd630c927282efac212b1e3beae4491">test_parallel_classification</a> ()</td></tr>
<tr class="separator:a0cd630c927282efac212b1e3beae4491"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b45fb4c90b531ee1e0656b156cbd0f3" id="r_a0b45fb4c90b531ee1e0656b156cbd0f3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a0b45fb4c90b531ee1e0656b156cbd0f3">test_parallel_regression</a> ()</td></tr>
<tr class="separator:a0b45fb4c90b531ee1e0656b156cbd0f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa71f6b11bbf8bcadc62e8712aacb075e" id="r_aa71f6b11bbf8bcadc62e8712aacb075e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#aa71f6b11bbf8bcadc62e8712aacb075e">test_gridsearch</a> ()</td></tr>
<tr class="separator:aa71f6b11bbf8bcadc62e8712aacb075e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfae59bc4357096757e6e263cf5db91c" id="r_abfae59bc4357096757e6e263cf5db91c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#abfae59bc4357096757e6e263cf5db91c">test_estimator</a> ()</td></tr>
<tr class="separator:abfae59bc4357096757e6e263cf5db91c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b27c6f414780ab91b53b9cdae9f0027" id="r_a0b27c6f414780ab91b53b9cdae9f0027"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a0b27c6f414780ab91b53b9cdae9f0027">test_bagging_with_pipeline</a> ()</td></tr>
<tr class="separator:a0b27c6f414780ab91b53b9cdae9f0027"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1f67662391a23843cb27b0ea67329b7" id="r_ab1f67662391a23843cb27b0ea67329b7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#ab1f67662391a23843cb27b0ea67329b7">test_bagging_sample_weight_unsupported_but_passed</a> ()</td></tr>
<tr class="separator:ab1f67662391a23843cb27b0ea67329b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33503f39cd8d808307f0dd28cb85325d" id="r_a33503f39cd8d808307f0dd28cb85325d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a33503f39cd8d808307f0dd28cb85325d">test_warm_start</a> (random_state=42)</td></tr>
<tr class="separator:a33503f39cd8d808307f0dd28cb85325d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfc4e648a376c3336b380b82bd0aaaab" id="r_abfc4e648a376c3336b380b82bd0aaaab"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#abfc4e648a376c3336b380b82bd0aaaab">test_warm_start_smaller_n_estimators</a> ()</td></tr>
<tr class="separator:abfc4e648a376c3336b380b82bd0aaaab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a6ecaa5ab2f452f6129fa51796f9b97" id="r_a0a6ecaa5ab2f452f6129fa51796f9b97"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a0a6ecaa5ab2f452f6129fa51796f9b97">test_warm_start_equal_n_estimators</a> ()</td></tr>
<tr class="separator:a0a6ecaa5ab2f452f6129fa51796f9b97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d26c8fee91aa128c0a77fd7fb202968" id="r_a7d26c8fee91aa128c0a77fd7fb202968"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a7d26c8fee91aa128c0a77fd7fb202968">test_warm_start_equivalence</a> ()</td></tr>
<tr class="separator:a7d26c8fee91aa128c0a77fd7fb202968"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54ef54a11f2d9dfa310133726d530435" id="r_a54ef54a11f2d9dfa310133726d530435"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a54ef54a11f2d9dfa310133726d530435">test_warm_start_with_oob_score_fails</a> ()</td></tr>
<tr class="separator:a54ef54a11f2d9dfa310133726d530435"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe9385dd7cd9e2aadfad0b8b92835a12" id="r_afe9385dd7cd9e2aadfad0b8b92835a12"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#afe9385dd7cd9e2aadfad0b8b92835a12">test_oob_score_removed_on_warm_start</a> ()</td></tr>
<tr class="separator:afe9385dd7cd9e2aadfad0b8b92835a12"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd51d24be1d7e89cd370caab58d9362b" id="r_afd51d24be1d7e89cd370caab58d9362b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#afd51d24be1d7e89cd370caab58d9362b">test_oob_score_consistency</a> ()</td></tr>
<tr class="separator:afd51d24be1d7e89cd370caab58d9362b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae847405962a9e23d07d4826094ac51d" id="r_aae847405962a9e23d07d4826094ac51d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#aae847405962a9e23d07d4826094ac51d">test_estimators_samples</a> ()</td></tr>
<tr class="separator:aae847405962a9e23d07d4826094ac51d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a598bf80af9124518a58a0c405a436e44" id="r_a598bf80af9124518a58a0c405a436e44"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a598bf80af9124518a58a0c405a436e44">test_estimators_samples_deterministic</a> ()</td></tr>
<tr class="separator:a598bf80af9124518a58a0c405a436e44"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4484e6bc5823b35796cfe5e64ad5a7c" id="r_af4484e6bc5823b35796cfe5e64ad5a7c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#af4484e6bc5823b35796cfe5e64ad5a7c">test_max_samples_consistency</a> ()</td></tr>
<tr class="separator:af4484e6bc5823b35796cfe5e64ad5a7c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad08ff58c73c8df950ed091e052d0d9cb" id="r_ad08ff58c73c8df950ed091e052d0d9cb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#ad08ff58c73c8df950ed091e052d0d9cb">test_set_oob_score_label_encoding</a> ()</td></tr>
<tr class="separator:ad08ff58c73c8df950ed091e052d0d9cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a6b2426138d776a3add567b5b92b3f1" id="r_a3a6b2426138d776a3add567b5b92b3f1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a3a6b2426138d776a3add567b5b92b3f1">replace</a> (X)</td></tr>
<tr class="separator:a3a6b2426138d776a3add567b5b92b3f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd75e61500091a1a1e6f4ca6795b5778" id="r_abd75e61500091a1a1e6f4ca6795b5778"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#abd75e61500091a1a1e6f4ca6795b5778">test_bagging_regressor_with_missing_inputs</a> ()</td></tr>
<tr class="separator:abd75e61500091a1a1e6f4ca6795b5778"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae920a17e401fbd19b4fd7947a28fd10b" id="r_ae920a17e401fbd19b4fd7947a28fd10b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#ae920a17e401fbd19b4fd7947a28fd10b">test_bagging_classifier_with_missing_inputs</a> ()</td></tr>
<tr class="separator:ae920a17e401fbd19b4fd7947a28fd10b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48d792adc7b6d5bd4f23bbe840ad96c9" id="r_a48d792adc7b6d5bd4f23bbe840ad96c9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a48d792adc7b6d5bd4f23bbe840ad96c9">test_bagging_small_max_features</a> ()</td></tr>
<tr class="separator:a48d792adc7b6d5bd4f23bbe840ad96c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68cd2254ac15b93c6a3d6e3627520037" id="r_a68cd2254ac15b93c6a3d6e3627520037"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a68cd2254ac15b93c6a3d6e3627520037">test_bagging_get_estimators_indices</a> ()</td></tr>
<tr class="separator:a68cd2254ac15b93c6a3d6e3627520037"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41e76362e31e0214a2585ddeb349d814" id="r_a41e76362e31e0214a2585ddeb349d814"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a41e76362e31e0214a2585ddeb349d814">test_base_estimator_argument_deprecated</a> (Bagging, Estimator)</td></tr>
<tr class="separator:a41e76362e31e0214a2585ddeb349d814"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1eacd42f4b4eefca483858f2e1297f85" id="r_a1eacd42f4b4eefca483858f2e1297f85"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a1eacd42f4b4eefca483858f2e1297f85">test_base_estimator_property_deprecated</a> (Bagging)</td></tr>
<tr class="separator:a1eacd42f4b4eefca483858f2e1297f85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1b6a0c7c32788f55ec6ab49d8bcf9b7" id="r_ae1b6a0c7c32788f55ec6ab49d8bcf9b7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#ae1b6a0c7c32788f55ec6ab49d8bcf9b7">test_deprecated_base_estimator_has_decision_function</a> ()</td></tr>
<tr class="separator:ae1b6a0c7c32788f55ec6ab49d8bcf9b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:ad78f45042ab1fbcc64028354993dbaa0" id="r_ad78f45042ab1fbcc64028354993dbaa0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#ad78f45042ab1fbcc64028354993dbaa0">rng</a> = check_random_state(0)</td></tr>
<tr class="separator:ad78f45042ab1fbcc64028354993dbaa0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0148cf0d14cd2495375f129e7fb25bb" id="r_ad0148cf0d14cd2495375f129e7fb25bb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#ad0148cf0d14cd2495375f129e7fb25bb">iris</a> = load_iris()</td></tr>
<tr class="separator:ad0148cf0d14cd2495375f129e7fb25bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af1b765b0ebc92d1f54114f8a5bb4390a" id="r_af1b765b0ebc92d1f54114f8a5bb4390a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#af1b765b0ebc92d1f54114f8a5bb4390a">perm</a> = rng.permutation(iris.target.size)</td></tr>
<tr class="separator:af1b765b0ebc92d1f54114f8a5bb4390a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92c2e3112ebad73576bae1d5a11a2bf9" id="r_a92c2e3112ebad73576bae1d5a11a2bf9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a92c2e3112ebad73576bae1d5a11a2bf9">data</a></td></tr>
<tr class="separator:a92c2e3112ebad73576bae1d5a11a2bf9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a571fa8957d9173ed6c13a6c990d310f2" id="r_a571fa8957d9173ed6c13a6c990d310f2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a571fa8957d9173ed6c13a6c990d310f2">target</a></td></tr>
<tr class="separator:a571fa8957d9173ed6c13a6c990d310f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4456ee1ac662c59334b709bcb47fc354" id="r_a4456ee1ac662c59334b709bcb47fc354"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a4456ee1ac662c59334b709bcb47fc354">diabetes</a> = load_diabetes()</td></tr>
<tr class="separator:a4456ee1ac662c59334b709bcb47fc354"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a650a307a13be64422532838847922e9a" id="r_a650a307a13be64422532838847922e9a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a650a307a13be64422532838847922e9a">data_type_</a></td></tr>
<tr class="separator:a650a307a13be64422532838847922e9a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4cfbbd659c511ea4f2a0e205098d7f96" id="r_a4cfbbd659c511ea4f2a0e205098d7f96"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1ensemble_1_1tests_1_1test__bagging.html#a4cfbbd659c511ea4f2a0e205098d7f96">_sample_indices</a></td></tr>
<tr class="separator:a4cfbbd659c511ea4f2a0e205098d7f96"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Testing for the bagging ensemble module (sklearn.ensemble.bagging).
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a3a6b2426138d776a3add567b5b92b3f1" name="a3a6b2426138d776a3add567b5b92b3f1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3a6b2426138d776a3add567b5b92b3f1">&#9670;&#160;</a></span>replace()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.replace </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  818</span><span class="keyword">def </span>replace(X):</div>
<div class="line"><span class="lineno">  819</span>    X = X.astype(<span class="stringliteral">&quot;float&quot;</span>, copy=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  820</span>    X[~np.isfinite(X)] = 0</div>
<div class="line"><span class="lineno">  821</span>    <span class="keywordflow">return</span> X</div>
<div class="line"><span class="lineno">  822</span> </div>
<div class="line"><span class="lineno">  823</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae920a17e401fbd19b4fd7947a28fd10b" name="ae920a17e401fbd19b4fd7947a28fd10b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae920a17e401fbd19b4fd7947a28fd10b">&#9670;&#160;</a></span>test_bagging_classifier_with_missing_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_bagging_classifier_with_missing_inputs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  865</span><span class="keyword">def </span>test_bagging_classifier_with_missing_inputs():</div>
<div class="line"><span class="lineno">  866</span>    <span class="comment"># Check that BaggingClassifier can accept X with missing/infinite data</span></div>
<div class="line"><span class="lineno">  867</span>    X = np.array(</div>
<div class="line"><span class="lineno">  868</span>        [</div>
<div class="line"><span class="lineno">  869</span>            [1, 3, 5],</div>
<div class="line"><span class="lineno">  870</span>            [2, <span class="keywordtype">None</span>, 6],</div>
<div class="line"><span class="lineno">  871</span>            [2, np.nan, 6],</div>
<div class="line"><span class="lineno">  872</span>            [2, np.inf, 6],</div>
<div class="line"><span class="lineno">  873</span>            [2, np.NINF, 6],</div>
<div class="line"><span class="lineno">  874</span>        ]</div>
<div class="line"><span class="lineno">  875</span>    )</div>
<div class="line"><span class="lineno">  876</span>    y = np.array([3, 6, 6, 6, 6])</div>
<div class="line"><span class="lineno">  877</span>    classifier = DecisionTreeClassifier()</div>
<div class="line"><span class="lineno">  878</span>    pipeline = make_pipeline(FunctionTransformer(replace), classifier)</div>
<div class="line"><span class="lineno">  879</span>    pipeline.fit(X, y).predict(X)</div>
<div class="line"><span class="lineno">  880</span>    bagging_classifier = BaggingClassifier(pipeline)</div>
<div class="line"><span class="lineno">  881</span>    bagging_classifier.fit(X, y)</div>
<div class="line"><span class="lineno">  882</span>    y_hat = bagging_classifier.predict(X)</div>
<div class="line"><span class="lineno">  883</span>    <span class="keyword">assert</span> y.shape == y_hat.shape</div>
<div class="line"><span class="lineno">  884</span>    bagging_classifier.predict_log_proba(X)</div>
<div class="line"><span class="lineno">  885</span>    bagging_classifier.predict_proba(X)</div>
<div class="line"><span class="lineno">  886</span> </div>
<div class="line"><span class="lineno">  887</span>    <span class="comment"># Verify that exceptions can be raised by wrapper classifier</span></div>
<div class="line"><span class="lineno">  888</span>    classifier = DecisionTreeClassifier()</div>
<div class="line"><span class="lineno">  889</span>    pipeline = make_pipeline(classifier)</div>
<div class="line"><span class="lineno">  890</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  891</span>        pipeline.fit(X, y)</div>
<div class="line"><span class="lineno">  892</span>    bagging_classifier = BaggingClassifier(pipeline)</div>
<div class="line"><span class="lineno">  893</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  894</span>        bagging_classifier.fit(X, y)</div>
<div class="line"><span class="lineno">  895</span> </div>
<div class="line"><span class="lineno">  896</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a68cd2254ac15b93c6a3d6e3627520037" name="a68cd2254ac15b93c6a3d6e3627520037"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68cd2254ac15b93c6a3d6e3627520037">&#9670;&#160;</a></span>test_bagging_get_estimators_indices()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_bagging_get_estimators_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  907</span><span class="keyword">def </span>test_bagging_get_estimators_indices():</div>
<div class="line"><span class="lineno">  908</span>    <span class="comment"># Check that Bagging estimator can generate sample indices properly</span></div>
<div class="line"><span class="lineno">  909</span>    <span class="comment"># Non-regression test for:</span></div>
<div class="line"><span class="lineno">  910</span>    <span class="comment"># https://github.com/scikit-learn/scikit-learn/issues/16436</span></div>
<div class="line"><span class="lineno">  911</span> </div>
<div class="line"><span class="lineno">  912</span>    rng = np.random.RandomState(0)</div>
<div class="line"><span class="lineno">  913</span>    X = rng.randn(13, 4)</div>
<div class="line"><span class="lineno">  914</span>    y = np.arange(13)</div>
<div class="line"><span class="lineno">  915</span> </div>
<div class="line"><span class="lineno">  916</span>    <span class="keyword">class </span>MyEstimator(DecisionTreeRegressor):</div>
<div class="line"><span class="lineno">  917</span>        <span class="stringliteral">&quot;&quot;&quot;An estimator which stores y indices information at fit.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  918</span> </div>
<div class="line"><span class="lineno">  919</span>        <span class="keyword">def </span>fit(self, X, y):</div>
<div class="line"><span class="lineno">  920</span>            self._sample_indices = y</div>
<div class="line"><span class="lineno">  921</span> </div>
<div class="line"><span class="lineno">  922</span>    clf = BaggingRegressor(estimator=MyEstimator(), n_estimators=1, random_state=0)</div>
<div class="line"><span class="lineno">  923</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  924</span> </div>
<div class="line"><span class="lineno">  925</span>    assert_array_equal(clf.estimators_[0]._sample_indices, clf.estimators_samples_[0])</div>
<div class="line"><span class="lineno">  926</span> </div>
<div class="line"><span class="lineno">  927</span> </div>
<div class="line"><span class="lineno">  928</span><span class="comment"># TODO(1.4): remove in 1.4</span></div>
<div class="line"><span class="lineno">  929</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  930</span>    <span class="stringliteral">&quot;Bagging, Estimator&quot;</span>,</div>
<div class="line"><span class="lineno">  931</span>    [</div>
<div class="line"><span class="lineno">  932</span>        (BaggingClassifier, DecisionTreeClassifier),</div>
<div class="line"><span class="lineno">  933</span>        (BaggingRegressor, DecisionTreeRegressor),</div>
<div class="line"><span class="lineno">  934</span>    ],</div>
<div class="line"><span class="lineno">  935</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="abd75e61500091a1a1e6f4ca6795b5778" name="abd75e61500091a1a1e6f4ca6795b5778"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd75e61500091a1a1e6f4ca6795b5778">&#9670;&#160;</a></span>test_bagging_regressor_with_missing_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_bagging_regressor_with_missing_inputs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  824</span><span class="keyword">def </span>test_bagging_regressor_with_missing_inputs():</div>
<div class="line"><span class="lineno">  825</span>    <span class="comment"># Check that BaggingRegressor can accept X with missing/infinite data</span></div>
<div class="line"><span class="lineno">  826</span>    X = np.array(</div>
<div class="line"><span class="lineno">  827</span>        [</div>
<div class="line"><span class="lineno">  828</span>            [1, 3, 5],</div>
<div class="line"><span class="lineno">  829</span>            [2, <span class="keywordtype">None</span>, 6],</div>
<div class="line"><span class="lineno">  830</span>            [2, np.nan, 6],</div>
<div class="line"><span class="lineno">  831</span>            [2, np.inf, 6],</div>
<div class="line"><span class="lineno">  832</span>            [2, np.NINF, 6],</div>
<div class="line"><span class="lineno">  833</span>        ]</div>
<div class="line"><span class="lineno">  834</span>    )</div>
<div class="line"><span class="lineno">  835</span>    y_values = [</div>
<div class="line"><span class="lineno">  836</span>        np.array([2, 3, 3, 3, 3]),</div>
<div class="line"><span class="lineno">  837</span>        np.array(</div>
<div class="line"><span class="lineno">  838</span>            [</div>
<div class="line"><span class="lineno">  839</span>                [2, 1, 9],</div>
<div class="line"><span class="lineno">  840</span>                [3, 6, 8],</div>
<div class="line"><span class="lineno">  841</span>                [3, 6, 8],</div>
<div class="line"><span class="lineno">  842</span>                [3, 6, 8],</div>
<div class="line"><span class="lineno">  843</span>                [3, 6, 8],</div>
<div class="line"><span class="lineno">  844</span>            ]</div>
<div class="line"><span class="lineno">  845</span>        ),</div>
<div class="line"><span class="lineno">  846</span>    ]</div>
<div class="line"><span class="lineno">  847</span>    <span class="keywordflow">for</span> y <span class="keywordflow">in</span> y_values:</div>
<div class="line"><span class="lineno">  848</span>        regressor = DecisionTreeRegressor()</div>
<div class="line"><span class="lineno">  849</span>        pipeline = make_pipeline(FunctionTransformer(replace), regressor)</div>
<div class="line"><span class="lineno">  850</span>        pipeline.fit(X, y).predict(X)</div>
<div class="line"><span class="lineno">  851</span>        bagging_regressor = BaggingRegressor(pipeline)</div>
<div class="line"><span class="lineno">  852</span>        y_hat = bagging_regressor.fit(X, y).predict(X)</div>
<div class="line"><span class="lineno">  853</span>        <span class="keyword">assert</span> y.shape == y_hat.shape</div>
<div class="line"><span class="lineno">  854</span> </div>
<div class="line"><span class="lineno">  855</span>        <span class="comment"># Verify that exceptions can be raised by wrapper regressor</span></div>
<div class="line"><span class="lineno">  856</span>        regressor = DecisionTreeRegressor()</div>
<div class="line"><span class="lineno">  857</span>        pipeline = make_pipeline(regressor)</div>
<div class="line"><span class="lineno">  858</span>        <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  859</span>            pipeline.fit(X, y)</div>
<div class="line"><span class="lineno">  860</span>        bagging_regressor = BaggingRegressor(pipeline)</div>
<div class="line"><span class="lineno">  861</span>        <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  862</span>            bagging_regressor.fit(X, y)</div>
<div class="line"><span class="lineno">  863</span> </div>
<div class="line"><span class="lineno">  864</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab1f67662391a23843cb27b0ea67329b7" name="ab1f67662391a23843cb27b0ea67329b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1f67662391a23843cb27b0ea67329b7">&#9670;&#160;</a></span>test_bagging_sample_weight_unsupported_but_passed()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_bagging_sample_weight_unsupported_but_passed </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  589</span><span class="keyword">def </span>test_bagging_sample_weight_unsupported_but_passed():</div>
<div class="line"><span class="lineno">  590</span>    estimator = BaggingClassifier(DummyZeroEstimator())</div>
<div class="line"><span class="lineno">  591</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  592</span> </div>
<div class="line"><span class="lineno">  593</span>    estimator.fit(iris.data, iris.target).predict(iris.data)</div>
<div class="line"><span class="lineno">  594</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  595</span>        estimator.fit(</div>
<div class="line"><span class="lineno">  596</span>            iris.data,</div>
<div class="line"><span class="lineno">  597</span>            iris.target,</div>
<div class="line"><span class="lineno">  598</span>            sample_weight=rng.randint(10, size=(iris.data.shape[0])),</div>
<div class="line"><span class="lineno">  599</span>        )</div>
<div class="line"><span class="lineno">  600</span> </div>
<div class="line"><span class="lineno">  601</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a48d792adc7b6d5bd4f23bbe840ad96c9" name="a48d792adc7b6d5bd4f23bbe840ad96c9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a48d792adc7b6d5bd4f23bbe840ad96c9">&#9670;&#160;</a></span>test_bagging_small_max_features()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_bagging_small_max_features </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  897</span><span class="keyword">def </span>test_bagging_small_max_features():</div>
<div class="line"><span class="lineno">  898</span>    <span class="comment"># Check that Bagging estimator can accept low fractional max_features</span></div>
<div class="line"><span class="lineno">  899</span> </div>
<div class="line"><span class="lineno">  900</span>    X = np.array([[1, 2], [3, 4]])</div>
<div class="line"><span class="lineno">  901</span>    y = np.array([1, 0])</div>
<div class="line"><span class="lineno">  902</span> </div>
<div class="line"><span class="lineno">  903</span>    bagging = BaggingClassifier(LogisticRegression(), max_features=0.3, random_state=1)</div>
<div class="line"><span class="lineno">  904</span>    bagging.fit(X, y)</div>
<div class="line"><span class="lineno">  905</span> </div>
<div class="line"><span class="lineno">  906</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0b27c6f414780ab91b53b9cdae9f0027" name="a0b27c6f414780ab91b53b9cdae9f0027"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b27c6f414780ab91b53b9cdae9f0027">&#9670;&#160;</a></span>test_bagging_with_pipeline()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_bagging_with_pipeline </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  572</span><span class="keyword">def </span>test_bagging_with_pipeline():</div>
<div class="line"><span class="lineno">  573</span>    estimator = BaggingClassifier(</div>
<div class="line"><span class="lineno">  574</span>        make_pipeline(SelectKBest(k=1), DecisionTreeClassifier()), max_features=2</div>
<div class="line"><span class="lineno">  575</span>    )</div>
<div class="line"><span class="lineno">  576</span>    estimator.fit(iris.data, iris.target)</div>
<div class="line"><span class="lineno">  577</span>    <span class="keyword">assert</span> isinstance(estimator[0].steps[-1][1].random_state, int)</div>
<div class="line"><span class="lineno">  578</span> </div>
<div class="line"><span class="lineno">  579</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a41e76362e31e0214a2585ddeb349d814" name="a41e76362e31e0214a2585ddeb349d814"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a41e76362e31e0214a2585ddeb349d814">&#9670;&#160;</a></span>test_base_estimator_argument_deprecated()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_base_estimator_argument_deprecated </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Bagging</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Estimator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  936</span><span class="keyword">def </span>test_base_estimator_argument_deprecated(Bagging, Estimator):</div>
<div class="line"><span class="lineno">  937</span>    X = np.array([[1, 2], [3, 4]])</div>
<div class="line"><span class="lineno">  938</span>    y = np.array([1, 0])</div>
<div class="line"><span class="lineno">  939</span>    model = Bagging(base_estimator=Estimator(), n_estimators=10)</div>
<div class="line"><span class="lineno">  940</span> </div>
<div class="line"><span class="lineno">  941</span>    warn_msg = (</div>
<div class="line"><span class="lineno">  942</span>        <span class="stringliteral">&quot;`base_estimator` was renamed to `estimator` in version 1.2 and &quot;</span></div>
<div class="line"><span class="lineno">  943</span>        <span class="stringliteral">&quot;will be removed in 1.4.&quot;</span></div>
<div class="line"><span class="lineno">  944</span>    )</div>
<div class="line"><span class="lineno">  945</span>    <span class="keyword">with</span> pytest.warns(FutureWarning, match=warn_msg):</div>
<div class="line"><span class="lineno">  946</span>        model.fit(X, y)</div>
<div class="line"><span class="lineno">  947</span> </div>
<div class="line"><span class="lineno">  948</span> </div>
<div class="line"><span class="lineno">  949</span><span class="comment"># TODO(1.4): remove in 1.4</span></div>
<div class="line"><span class="lineno">  950</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">  951</span>    <span class="stringliteral">&quot;Bagging&quot;</span>,</div>
<div class="line"><span class="lineno">  952</span>    [BaggingClassifier, BaggingClassifier],</div>
<div class="line"><span class="lineno">  953</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="a1eacd42f4b4eefca483858f2e1297f85" name="a1eacd42f4b4eefca483858f2e1297f85"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1eacd42f4b4eefca483858f2e1297f85">&#9670;&#160;</a></span>test_base_estimator_property_deprecated()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_base_estimator_property_deprecated </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Bagging</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  954</span><span class="keyword">def </span>test_base_estimator_property_deprecated(Bagging):</div>
<div class="line"><span class="lineno">  955</span>    X = np.array([[1, 2], [3, 4]])</div>
<div class="line"><span class="lineno">  956</span>    y = np.array([1, 0])</div>
<div class="line"><span class="lineno">  957</span>    model = Bagging()</div>
<div class="line"><span class="lineno">  958</span>    model.fit(X, y)</div>
<div class="line"><span class="lineno">  959</span> </div>
<div class="line"><span class="lineno">  960</span>    warn_msg = (</div>
<div class="line"><span class="lineno">  961</span>        <span class="stringliteral">&quot;Attribute `base_estimator_` was deprecated in version 1.2 and &quot;</span></div>
<div class="line"><span class="lineno">  962</span>        <span class="stringliteral">&quot;will be removed in 1.4. Use `estimator_` instead.&quot;</span></div>
<div class="line"><span class="lineno">  963</span>    )</div>
<div class="line"><span class="lineno">  964</span>    <span class="keyword">with</span> pytest.warns(FutureWarning, match=warn_msg):</div>
<div class="line"><span class="lineno">  965</span>        model.base_estimator_</div>
<div class="line"><span class="lineno">  966</span> </div>
<div class="line"><span class="lineno">  967</span> </div>
<div class="line"><span class="lineno">  968</span><span class="comment"># TODO(1.4): remove</span></div>
</div><!-- fragment -->
</div>
</div>
<a id="ae4fbe25eb94a518d5e32337d8aa284c1" name="ae4fbe25eb94a518d5e32337d8aa284c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4fbe25eb94a518d5e32337d8aa284c1">&#9670;&#160;</a></span>test_bootstrap_features()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_bootstrap_features </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  286</span><span class="keyword">def </span>test_bootstrap_features():</div>
<div class="line"><span class="lineno">  287</span>    <span class="comment"># Test that bootstrapping features may generate duplicate features.</span></div>
<div class="line"><span class="lineno">  288</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  289</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  290</span>        diabetes.data, diabetes.target, random_state=rng</div>
<div class="line"><span class="lineno">  291</span>    )</div>
<div class="line"><span class="lineno">  292</span> </div>
<div class="line"><span class="lineno">  293</span>    ensemble = BaggingRegressor(</div>
<div class="line"><span class="lineno">  294</span>        estimator=DecisionTreeRegressor(),</div>
<div class="line"><span class="lineno">  295</span>        max_features=1.0,</div>
<div class="line"><span class="lineno">  296</span>        bootstrap_features=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  297</span>        random_state=rng,</div>
<div class="line"><span class="lineno">  298</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  299</span> </div>
<div class="line"><span class="lineno">  300</span>    <span class="keywordflow">for</span> features <span class="keywordflow">in</span> ensemble.estimators_features_:</div>
<div class="line"><span class="lineno">  301</span>        <span class="keyword">assert</span> diabetes.data.shape[1] == np.unique(features).shape[0]</div>
<div class="line"><span class="lineno">  302</span> </div>
<div class="line"><span class="lineno">  303</span>    ensemble = BaggingRegressor(</div>
<div class="line"><span class="lineno">  304</span>        estimator=DecisionTreeRegressor(),</div>
<div class="line"><span class="lineno">  305</span>        max_features=1.0,</div>
<div class="line"><span class="lineno">  306</span>        bootstrap_features=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  307</span>        random_state=rng,</div>
<div class="line"><span class="lineno">  308</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  309</span> </div>
<div class="line"><span class="lineno">  310</span>    <span class="keywordflow">for</span> features <span class="keywordflow">in</span> ensemble.estimators_features_:</div>
<div class="line"><span class="lineno">  311</span>        <span class="keyword">assert</span> diabetes.data.shape[1] &gt; np.unique(features).shape[0]</div>
<div class="line"><span class="lineno">  312</span> </div>
<div class="line"><span class="lineno">  313</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a436245d25043d8e01dc96518641481ae" name="a436245d25043d8e01dc96518641481ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a436245d25043d8e01dc96518641481ae">&#9670;&#160;</a></span>test_bootstrap_samples()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_bootstrap_samples </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  244</span><span class="keyword">def </span>test_bootstrap_samples():</div>
<div class="line"><span class="lineno">  245</span>    <span class="comment"># Test that bootstrapping samples generate non-perfect base estimators.</span></div>
<div class="line"><span class="lineno">  246</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  247</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  248</span>        diabetes.data, diabetes.target, random_state=rng</div>
<div class="line"><span class="lineno">  249</span>    )</div>
<div class="line"><span class="lineno">  250</span> </div>
<div class="line"><span class="lineno">  251</span>    estimator = DecisionTreeRegressor().fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  252</span> </div>
<div class="line"><span class="lineno">  253</span>    <span class="comment"># without bootstrap, all trees are perfect on the training set</span></div>
<div class="line"><span class="lineno">  254</span>    ensemble = BaggingRegressor(</div>
<div class="line"><span class="lineno">  255</span>        estimator=DecisionTreeRegressor(),</div>
<div class="line"><span class="lineno">  256</span>        max_samples=1.0,</div>
<div class="line"><span class="lineno">  257</span>        bootstrap=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  258</span>        random_state=rng,</div>
<div class="line"><span class="lineno">  259</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  260</span> </div>
<div class="line"><span class="lineno">  261</span>    <span class="keyword">assert</span> estimator.score(X_train, y_train) == ensemble.score(X_train, y_train)</div>
<div class="line"><span class="lineno">  262</span> </div>
<div class="line"><span class="lineno">  263</span>    <span class="comment"># with bootstrap, trees are no longer perfect on the training set</span></div>
<div class="line"><span class="lineno">  264</span>    ensemble = BaggingRegressor(</div>
<div class="line"><span class="lineno">  265</span>        estimator=DecisionTreeRegressor(),</div>
<div class="line"><span class="lineno">  266</span>        max_samples=1.0,</div>
<div class="line"><span class="lineno">  267</span>        bootstrap=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  268</span>        random_state=rng,</div>
<div class="line"><span class="lineno">  269</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  270</span> </div>
<div class="line"><span class="lineno">  271</span>    <span class="keyword">assert</span> estimator.score(X_train, y_train) &gt; ensemble.score(X_train, y_train)</div>
<div class="line"><span class="lineno">  272</span> </div>
<div class="line"><span class="lineno">  273</span>    <span class="comment"># check that each sampling correspond to a complete bootstrap resample.</span></div>
<div class="line"><span class="lineno">  274</span>    <span class="comment"># the size of each bootstrap should be the same as the input data but</span></div>
<div class="line"><span class="lineno">  275</span>    <span class="comment"># the data should be different (checked using the hash of the data).</span></div>
<div class="line"><span class="lineno">  276</span>    ensemble = BaggingRegressor(estimator=DummySizeEstimator(), bootstrap=<span class="keyword">True</span>).fit(</div>
<div class="line"><span class="lineno">  277</span>        X_train, y_train</div>
<div class="line"><span class="lineno">  278</span>    )</div>
<div class="line"><span class="lineno">  279</span>    training_hash = []</div>
<div class="line"><span class="lineno">  280</span>    <span class="keywordflow">for</span> estimator <span class="keywordflow">in</span> ensemble.estimators_:</div>
<div class="line"><span class="lineno">  281</span>        <span class="keyword">assert</span> estimator.training_size_ == X_train.shape[0]</div>
<div class="line"><span class="lineno">  282</span>        training_hash.append(estimator.training_hash_)</div>
<div class="line"><span class="lineno">  283</span>    <span class="keyword">assert</span> len(set(training_hash)) == len(training_hash)</div>
<div class="line"><span class="lineno">  284</span> </div>
<div class="line"><span class="lineno">  285</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae8035dd162ae6187ba95acd61ba7bec0" name="ae8035dd162ae6187ba95acd61ba7bec0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae8035dd162ae6187ba95acd61ba7bec0">&#9670;&#160;</a></span>test_classification()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_classification </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   52</span><span class="keyword">def </span>test_classification():</div>
<div class="line"><span class="lineno">   53</span>    <span class="comment"># Check classification for various parameter settings.</span></div>
<div class="line"><span class="lineno">   54</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">   55</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">   56</span>        iris.data, iris.target, random_state=rng</div>
<div class="line"><span class="lineno">   57</span>    )</div>
<div class="line"><span class="lineno">   58</span>    grid = ParameterGrid(</div>
<div class="line"><span class="lineno">   59</span>        {</div>
<div class="line"><span class="lineno">   60</span>            <span class="stringliteral">&quot;max_samples&quot;</span>: [0.5, 1.0],</div>
<div class="line"><span class="lineno">   61</span>            <span class="stringliteral">&quot;max_features&quot;</span>: [1, 4],</div>
<div class="line"><span class="lineno">   62</span>            <span class="stringliteral">&quot;bootstrap&quot;</span>: [<span class="keyword">True</span>, <span class="keyword">False</span>],</div>
<div class="line"><span class="lineno">   63</span>            <span class="stringliteral">&quot;bootstrap_features&quot;</span>: [<span class="keyword">True</span>, <span class="keyword">False</span>],</div>
<div class="line"><span class="lineno">   64</span>        }</div>
<div class="line"><span class="lineno">   65</span>    )</div>
<div class="line"><span class="lineno">   66</span>    estimators = [</div>
<div class="line"><span class="lineno">   67</span>        <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">   68</span>        DummyClassifier(),</div>
<div class="line"><span class="lineno">   69</span>        Perceptron(max_iter=20),</div>
<div class="line"><span class="lineno">   70</span>        DecisionTreeClassifier(max_depth=2),</div>
<div class="line"><span class="lineno">   71</span>        KNeighborsClassifier(),</div>
<div class="line"><span class="lineno">   72</span>        SVC(),</div>
<div class="line"><span class="lineno">   73</span>    ]</div>
<div class="line"><span class="lineno">   74</span>    <span class="comment"># Try different parameter settings with different base classifiers without</span></div>
<div class="line"><span class="lineno">   75</span>    <span class="comment"># doing the full cartesian product to keep the test durations low.</span></div>
<div class="line"><span class="lineno">   76</span>    <span class="keywordflow">for</span> params, estimator <span class="keywordflow">in</span> zip(grid, cycle(estimators)):</div>
<div class="line"><span class="lineno">   77</span>        BaggingClassifier(</div>
<div class="line"><span class="lineno">   78</span>            estimator=estimator,</div>
<div class="line"><span class="lineno">   79</span>            random_state=rng,</div>
<div class="line"><span class="lineno">   80</span>            n_estimators=2,</div>
<div class="line"><span class="lineno">   81</span>            **params,</div>
<div class="line"><span class="lineno">   82</span>        ).fit(X_train, y_train).predict(X_test)</div>
<div class="line"><span class="lineno">   83</span> </div>
<div class="line"><span class="lineno">   84</span> </div>
<div class="line"><span class="lineno">   85</span><span class="preprocessor">@pytest.mark.parametrize</span>(</div>
<div class="line"><span class="lineno">   86</span>    <span class="stringliteral">&quot;sparse_format, params, method&quot;</span>,</div>
<div class="line"><span class="lineno">   87</span>    product(</div>
<div class="line"><span class="lineno">   88</span>        [csc_matrix, csr_matrix],</div>
<div class="line"><span class="lineno">   89</span>        [</div>
<div class="line"><span class="lineno">   90</span>            {</div>
<div class="line"><span class="lineno">   91</span>                <span class="stringliteral">&quot;max_samples&quot;</span>: 0.5,</div>
<div class="line"><span class="lineno">   92</span>                <span class="stringliteral">&quot;max_features&quot;</span>: 2,</div>
<div class="line"><span class="lineno">   93</span>                <span class="stringliteral">&quot;bootstrap&quot;</span>: <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">   94</span>                <span class="stringliteral">&quot;bootstrap_features&quot;</span>: <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">   95</span>            },</div>
<div class="line"><span class="lineno">   96</span>            {</div>
<div class="line"><span class="lineno">   97</span>                <span class="stringliteral">&quot;max_samples&quot;</span>: 1.0,</div>
<div class="line"><span class="lineno">   98</span>                <span class="stringliteral">&quot;max_features&quot;</span>: 4,</div>
<div class="line"><span class="lineno">   99</span>                <span class="stringliteral">&quot;bootstrap&quot;</span>: <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  100</span>                <span class="stringliteral">&quot;bootstrap_features&quot;</span>: <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  101</span>            },</div>
<div class="line"><span class="lineno">  102</span>            {<span class="stringliteral">&quot;max_features&quot;</span>: 2, <span class="stringliteral">&quot;bootstrap&quot;</span>: <span class="keyword">False</span>, <span class="stringliteral">&quot;bootstrap_features&quot;</span>: <span class="keyword">True</span>},</div>
<div class="line"><span class="lineno">  103</span>            {<span class="stringliteral">&quot;max_samples&quot;</span>: 0.5, <span class="stringliteral">&quot;bootstrap&quot;</span>: <span class="keyword">True</span>, <span class="stringliteral">&quot;bootstrap_features&quot;</span>: <span class="keyword">False</span>},</div>
<div class="line"><span class="lineno">  104</span>        ],</div>
<div class="line"><span class="lineno">  105</span>        [<span class="stringliteral">&quot;predict&quot;</span>, <span class="stringliteral">&quot;predict_proba&quot;</span>, <span class="stringliteral">&quot;predict_log_proba&quot;</span>, <span class="stringliteral">&quot;decision_function&quot;</span>],</div>
<div class="line"><span class="lineno">  106</span>    ),</div>
<div class="line"><span class="lineno">  107</span>)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae1b6a0c7c32788f55ec6ab49d8bcf9b7" name="ae1b6a0c7c32788f55ec6ab49d8bcf9b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1b6a0c7c32788f55ec6ab49d8bcf9b7">&#9670;&#160;</a></span>test_deprecated_base_estimator_has_decision_function()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_deprecated_base_estimator_has_decision_function </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Check that `BaggingClassifier` delegate to classifier with
`decision_function`.</pre> <div class="fragment"><div class="line"><span class="lineno">  969</span><span class="keyword">def </span>test_deprecated_base_estimator_has_decision_function():</div>
<div class="line"><span class="lineno">  970</span>    <span class="stringliteral">&quot;&quot;&quot;Check that `BaggingClassifier` delegate to classifier with</span></div>
<div class="line"><span class="lineno">  971</span><span class="stringliteral">    `decision_function`.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  972</span>    iris = load_iris()</div>
<div class="line"><span class="lineno">  973</span>    X, y = iris.data, iris.target</div>
<div class="line"><span class="lineno">  974</span>    clf = BaggingClassifier(base_estimator=SVC())</div>
<div class="line"><span class="lineno">  975</span>    <span class="keyword">assert</span> hasattr(clf, <span class="stringliteral">&quot;decision_function&quot;</span>)</div>
<div class="line"><span class="lineno">  976</span>    warn_msg = (</div>
<div class="line"><span class="lineno">  977</span>        <span class="stringliteral">&quot;`base_estimator` was renamed to `estimator` in version 1.2 and &quot;</span></div>
<div class="line"><span class="lineno">  978</span>        <span class="stringliteral">&quot;will be removed in 1.4.&quot;</span></div>
<div class="line"><span class="lineno">  979</span>    )</div>
<div class="line"><span class="lineno">  980</span>    <span class="keyword">with</span> pytest.warns(FutureWarning, match=warn_msg):</div>
<div class="line"><span class="lineno">  981</span>        y_decision = clf.fit(X, y).decision_function(X)</div>
<div class="line"><span class="lineno">  982</span>    <span class="keyword">assert</span> y_decision.shape == (150, 3)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ae3dc21f8e4efecb1a007d37989e31356" name="ae3dc21f8e4efecb1a007d37989e31356"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae3dc21f8e4efecb1a007d37989e31356">&#9670;&#160;</a></span>test_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_error </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  442</span><span class="keyword">def </span>test_error():</div>
<div class="line"><span class="lineno">  443</span>    <span class="comment"># Test support of decision_function</span></div>
<div class="line"><span class="lineno">  444</span>    X, y = iris.data, iris.target</div>
<div class="line"><span class="lineno">  445</span>    base = DecisionTreeClassifier()</div>
<div class="line"><span class="lineno">  446</span>    <span class="keyword">assert</span> <span class="keywordflow">not</span> hasattr(BaggingClassifier(base).fit(X, y), <span class="stringliteral">&quot;decision_function&quot;</span>)</div>
<div class="line"><span class="lineno">  447</span> </div>
<div class="line"><span class="lineno">  448</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abfae59bc4357096757e6e263cf5db91c" name="abfae59bc4357096757e6e263cf5db91c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abfae59bc4357096757e6e263cf5db91c">&#9670;&#160;</a></span>test_estimator()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_estimator </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  528</span><span class="keyword">def </span>test_estimator():</div>
<div class="line"><span class="lineno">  529</span>    <span class="comment"># Check estimator and its default values.</span></div>
<div class="line"><span class="lineno">  530</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  531</span> </div>
<div class="line"><span class="lineno">  532</span>    <span class="comment"># Classification</span></div>
<div class="line"><span class="lineno">  533</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  534</span>        iris.data, iris.target, random_state=rng</div>
<div class="line"><span class="lineno">  535</span>    )</div>
<div class="line"><span class="lineno">  536</span> </div>
<div class="line"><span class="lineno">  537</span>    ensemble = BaggingClassifier(<span class="keywordtype">None</span>, n_jobs=3, random_state=0).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  538</span> </div>
<div class="line"><span class="lineno">  539</span>    <span class="keyword">assert</span> isinstance(ensemble.estimator_, DecisionTreeClassifier)</div>
<div class="line"><span class="lineno">  540</span> </div>
<div class="line"><span class="lineno">  541</span>    ensemble = BaggingClassifier(</div>
<div class="line"><span class="lineno">  542</span>        DecisionTreeClassifier(), n_jobs=3, random_state=0</div>
<div class="line"><span class="lineno">  543</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  544</span> </div>
<div class="line"><span class="lineno">  545</span>    <span class="keyword">assert</span> isinstance(ensemble.estimator_, DecisionTreeClassifier)</div>
<div class="line"><span class="lineno">  546</span> </div>
<div class="line"><span class="lineno">  547</span>    ensemble = BaggingClassifier(Perceptron(), n_jobs=3, random_state=0).fit(</div>
<div class="line"><span class="lineno">  548</span>        X_train, y_train</div>
<div class="line"><span class="lineno">  549</span>    )</div>
<div class="line"><span class="lineno">  550</span> </div>
<div class="line"><span class="lineno">  551</span>    <span class="keyword">assert</span> isinstance(ensemble.estimator_, Perceptron)</div>
<div class="line"><span class="lineno">  552</span> </div>
<div class="line"><span class="lineno">  553</span>    <span class="comment"># Regression</span></div>
<div class="line"><span class="lineno">  554</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  555</span>        diabetes.data, diabetes.target, random_state=rng</div>
<div class="line"><span class="lineno">  556</span>    )</div>
<div class="line"><span class="lineno">  557</span> </div>
<div class="line"><span class="lineno">  558</span>    ensemble = BaggingRegressor(<span class="keywordtype">None</span>, n_jobs=3, random_state=0).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  559</span> </div>
<div class="line"><span class="lineno">  560</span>    <span class="keyword">assert</span> isinstance(ensemble.estimator_, DecisionTreeRegressor)</div>
<div class="line"><span class="lineno">  561</span> </div>
<div class="line"><span class="lineno">  562</span>    ensemble = BaggingRegressor(DecisionTreeRegressor(), n_jobs=3, random_state=0).fit(</div>
<div class="line"><span class="lineno">  563</span>        X_train, y_train</div>
<div class="line"><span class="lineno">  564</span>    )</div>
<div class="line"><span class="lineno">  565</span> </div>
<div class="line"><span class="lineno">  566</span>    <span class="keyword">assert</span> isinstance(ensemble.estimator_, DecisionTreeRegressor)</div>
<div class="line"><span class="lineno">  567</span> </div>
<div class="line"><span class="lineno">  568</span>    ensemble = BaggingRegressor(SVR(), n_jobs=3, random_state=0).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  569</span>    <span class="keyword">assert</span> isinstance(ensemble.estimator_, SVR)</div>
<div class="line"><span class="lineno">  570</span> </div>
<div class="line"><span class="lineno">  571</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aae847405962a9e23d07d4826094ac51d" name="aae847405962a9e23d07d4826094ac51d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae847405962a9e23d07d4826094ac51d">&#9670;&#160;</a></span>test_estimators_samples()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_estimators_samples </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  710</span><span class="keyword">def </span>test_estimators_samples():</div>
<div class="line"><span class="lineno">  711</span>    <span class="comment"># Check that format of estimators_samples_ is correct and that results</span></div>
<div class="line"><span class="lineno">  712</span>    <span class="comment"># generated at fit time can be identically reproduced at a later time</span></div>
<div class="line"><span class="lineno">  713</span>    <span class="comment"># using data saved in object attributes.</span></div>
<div class="line"><span class="lineno">  714</span>    X, y = make_hastie_10_2(n_samples=200, random_state=1)</div>
<div class="line"><span class="lineno">  715</span>    bagging = BaggingClassifier(</div>
<div class="line"><span class="lineno">  716</span>        LogisticRegression(),</div>
<div class="line"><span class="lineno">  717</span>        max_samples=0.5,</div>
<div class="line"><span class="lineno">  718</span>        max_features=0.5,</div>
<div class="line"><span class="lineno">  719</span>        random_state=1,</div>
<div class="line"><span class="lineno">  720</span>        bootstrap=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  721</span>    )</div>
<div class="line"><span class="lineno">  722</span>    bagging.fit(X, y)</div>
<div class="line"><span class="lineno">  723</span> </div>
<div class="line"><span class="lineno">  724</span>    <span class="comment"># Get relevant attributes</span></div>
<div class="line"><span class="lineno">  725</span>    estimators_samples = bagging.estimators_samples_</div>
<div class="line"><span class="lineno">  726</span>    estimators_features = bagging.estimators_features_</div>
<div class="line"><span class="lineno">  727</span>    estimators = bagging.estimators_</div>
<div class="line"><span class="lineno">  728</span> </div>
<div class="line"><span class="lineno">  729</span>    <span class="comment"># Test for correct formatting</span></div>
<div class="line"><span class="lineno">  730</span>    <span class="keyword">assert</span> len(estimators_samples) == len(estimators)</div>
<div class="line"><span class="lineno">  731</span>    <span class="keyword">assert</span> len(estimators_samples[0]) == len(X) // 2</div>
<div class="line"><span class="lineno">  732</span>    <span class="keyword">assert</span> estimators_samples[0].dtype.kind == <span class="stringliteral">&quot;i&quot;</span></div>
<div class="line"><span class="lineno">  733</span> </div>
<div class="line"><span class="lineno">  734</span>    <span class="comment"># Re-fit single estimator to test for consistent sampling</span></div>
<div class="line"><span class="lineno">  735</span>    estimator_index = 0</div>
<div class="line"><span class="lineno">  736</span>    estimator_samples = estimators_samples[estimator_index]</div>
<div class="line"><span class="lineno">  737</span>    estimator_features = estimators_features[estimator_index]</div>
<div class="line"><span class="lineno">  738</span>    estimator = estimators[estimator_index]</div>
<div class="line"><span class="lineno">  739</span> </div>
<div class="line"><span class="lineno">  740</span>    X_train = (X[estimator_samples])[:, estimator_features]</div>
<div class="line"><span class="lineno">  741</span>    y_train = y[estimator_samples]</div>
<div class="line"><span class="lineno">  742</span> </div>
<div class="line"><span class="lineno">  743</span>    orig_coefs = estimator.coef_</div>
<div class="line"><span class="lineno">  744</span>    estimator.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  745</span>    new_coefs = estimator.coef_</div>
<div class="line"><span class="lineno">  746</span> </div>
<div class="line"><span class="lineno">  747</span>    assert_array_almost_equal(orig_coefs, new_coefs)</div>
<div class="line"><span class="lineno">  748</span> </div>
<div class="line"><span class="lineno">  749</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a598bf80af9124518a58a0c405a436e44" name="a598bf80af9124518a58a0c405a436e44"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a598bf80af9124518a58a0c405a436e44">&#9670;&#160;</a></span>test_estimators_samples_deterministic()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_estimators_samples_deterministic </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  750</span><span class="keyword">def </span>test_estimators_samples_deterministic():</div>
<div class="line"><span class="lineno">  751</span>    <span class="comment"># This test is a regression test to check that with a random step</span></div>
<div class="line"><span class="lineno">  752</span>    <span class="comment"># (e.g. SparseRandomProjection) and a given random state, the results</span></div>
<div class="line"><span class="lineno">  753</span>    <span class="comment"># generated at fit time can be identically reproduced at a later time using</span></div>
<div class="line"><span class="lineno">  754</span>    <span class="comment"># data saved in object attributes. Check issue #9524 for full discussion.</span></div>
<div class="line"><span class="lineno">  755</span> </div>
<div class="line"><span class="lineno">  756</span>    iris = load_iris()</div>
<div class="line"><span class="lineno">  757</span>    X, y = iris.data, iris.target</div>
<div class="line"><span class="lineno">  758</span> </div>
<div class="line"><span class="lineno">  759</span>    base_pipeline = make_pipeline(</div>
<div class="line"><span class="lineno">  760</span>        SparseRandomProjection(n_components=2), LogisticRegression()</div>
<div class="line"><span class="lineno">  761</span>    )</div>
<div class="line"><span class="lineno">  762</span>    clf = BaggingClassifier(estimator=base_pipeline, max_samples=0.5, random_state=0)</div>
<div class="line"><span class="lineno">  763</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  764</span>    pipeline_estimator_coef = clf.estimators_[0].steps[-1][1].coef_.copy()</div>
<div class="line"><span class="lineno">  765</span> </div>
<div class="line"><span class="lineno">  766</span>    estimator = clf.estimators_[0]</div>
<div class="line"><span class="lineno">  767</span>    estimator_sample = clf.estimators_samples_[0]</div>
<div class="line"><span class="lineno">  768</span>    estimator_feature = clf.estimators_features_[0]</div>
<div class="line"><span class="lineno">  769</span> </div>
<div class="line"><span class="lineno">  770</span>    X_train = (X[estimator_sample])[:, estimator_feature]</div>
<div class="line"><span class="lineno">  771</span>    y_train = y[estimator_sample]</div>
<div class="line"><span class="lineno">  772</span> </div>
<div class="line"><span class="lineno">  773</span>    estimator.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  774</span>    assert_array_equal(estimator.steps[-1][1].coef_, pipeline_estimator_coef)</div>
<div class="line"><span class="lineno">  775</span> </div>
<div class="line"><span class="lineno">  776</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa71f6b11bbf8bcadc62e8712aacb075e" name="aa71f6b11bbf8bcadc62e8712aacb075e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa71f6b11bbf8bcadc62e8712aacb075e">&#9670;&#160;</a></span>test_gridsearch()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_gridsearch </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  516</span><span class="keyword">def </span>test_gridsearch():</div>
<div class="line"><span class="lineno">  517</span>    <span class="comment"># Check that bagging ensembles can be grid-searched.</span></div>
<div class="line"><span class="lineno">  518</span>    <span class="comment"># Transform iris into a binary classification task</span></div>
<div class="line"><span class="lineno">  519</span>    X, y = iris.data, iris.target</div>
<div class="line"><span class="lineno">  520</span>    y[y == 2] = 1</div>
<div class="line"><span class="lineno">  521</span> </div>
<div class="line"><span class="lineno">  522</span>    <span class="comment"># Grid search with scoring based on decision_function</span></div>
<div class="line"><span class="lineno">  523</span>    parameters = {<span class="stringliteral">&quot;n_estimators&quot;</span>: (1, 2), <span class="stringliteral">&quot;estimator__C&quot;</span>: (1, 2)}</div>
<div class="line"><span class="lineno">  524</span> </div>
<div class="line"><span class="lineno">  525</span>    GridSearchCV(BaggingClassifier(SVC()), parameters, scoring=<span class="stringliteral">&quot;roc_auc&quot;</span>).fit(X, y)</div>
<div class="line"><span class="lineno">  526</span> </div>
<div class="line"><span class="lineno">  527</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af4484e6bc5823b35796cfe5e64ad5a7c" name="af4484e6bc5823b35796cfe5e64ad5a7c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4484e6bc5823b35796cfe5e64ad5a7c">&#9670;&#160;</a></span>test_max_samples_consistency()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_max_samples_consistency </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  777</span><span class="keyword">def </span>test_max_samples_consistency():</div>
<div class="line"><span class="lineno">  778</span>    <span class="comment"># Make sure validated max_samples and original max_samples are identical</span></div>
<div class="line"><span class="lineno">  779</span>    <span class="comment"># when valid integer max_samples supplied by user</span></div>
<div class="line"><span class="lineno">  780</span>    max_samples = 100</div>
<div class="line"><span class="lineno">  781</span>    X, y = make_hastie_10_2(n_samples=2 * max_samples, random_state=1)</div>
<div class="line"><span class="lineno">  782</span>    bagging = BaggingClassifier(</div>
<div class="line"><span class="lineno">  783</span>        KNeighborsClassifier(),</div>
<div class="line"><span class="lineno">  784</span>        max_samples=max_samples,</div>
<div class="line"><span class="lineno">  785</span>        max_features=0.5,</div>
<div class="line"><span class="lineno">  786</span>        random_state=1,</div>
<div class="line"><span class="lineno">  787</span>    )</div>
<div class="line"><span class="lineno">  788</span>    bagging.fit(X, y)</div>
<div class="line"><span class="lineno">  789</span>    <span class="keyword">assert</span> bagging._max_samples == max_samples</div>
<div class="line"><span class="lineno">  790</span> </div>
<div class="line"><span class="lineno">  791</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9e95027f0dfcbfcd849566be0f814e01" name="a9e95027f0dfcbfcd849566be0f814e01"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e95027f0dfcbfcd849566be0f814e01">&#9670;&#160;</a></span>test_oob_score_classification()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_oob_score_classification </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  349</span><span class="keyword">def </span>test_oob_score_classification():</div>
<div class="line"><span class="lineno">  350</span>    <span class="comment"># Check that oob prediction is a good estimation of the generalization</span></div>
<div class="line"><span class="lineno">  351</span>    <span class="comment"># error.</span></div>
<div class="line"><span class="lineno">  352</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  353</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  354</span>        iris.data, iris.target, random_state=rng</div>
<div class="line"><span class="lineno">  355</span>    )</div>
<div class="line"><span class="lineno">  356</span> </div>
<div class="line"><span class="lineno">  357</span>    <span class="keywordflow">for</span> estimator <span class="keywordflow">in</span> [DecisionTreeClassifier(), SVC()]:</div>
<div class="line"><span class="lineno">  358</span>        clf = BaggingClassifier(</div>
<div class="line"><span class="lineno">  359</span>            estimator=estimator,</div>
<div class="line"><span class="lineno">  360</span>            n_estimators=100,</div>
<div class="line"><span class="lineno">  361</span>            bootstrap=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  362</span>            oob_score=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  363</span>            random_state=rng,</div>
<div class="line"><span class="lineno">  364</span>        ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  365</span> </div>
<div class="line"><span class="lineno">  366</span>        test_score = clf.score(X_test, y_test)</div>
<div class="line"><span class="lineno">  367</span> </div>
<div class="line"><span class="lineno">  368</span>        <span class="keyword">assert</span> abs(test_score - clf.oob_score_) &lt; 0.1</div>
<div class="line"><span class="lineno">  369</span> </div>
<div class="line"><span class="lineno">  370</span>        <span class="comment"># Test with few estimators</span></div>
<div class="line"><span class="lineno">  371</span>        warn_msg = (</div>
<div class="line"><span class="lineno">  372</span>            <span class="stringliteral">&quot;Some inputs do not have OOB scores. This probably means too few &quot;</span></div>
<div class="line"><span class="lineno">  373</span>            <span class="stringliteral">&quot;estimators were used to compute any reliable oob estimates.&quot;</span></div>
<div class="line"><span class="lineno">  374</span>        )</div>
<div class="line"><span class="lineno">  375</span>        <span class="keyword">with</span> pytest.warns(UserWarning, match=warn_msg):</div>
<div class="line"><span class="lineno">  376</span>            clf = BaggingClassifier(</div>
<div class="line"><span class="lineno">  377</span>                estimator=estimator,</div>
<div class="line"><span class="lineno">  378</span>                n_estimators=1,</div>
<div class="line"><span class="lineno">  379</span>                bootstrap=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  380</span>                oob_score=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  381</span>                random_state=rng,</div>
<div class="line"><span class="lineno">  382</span>            )</div>
<div class="line"><span class="lineno">  383</span>            clf.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  384</span> </div>
<div class="line"><span class="lineno">  385</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afd51d24be1d7e89cd370caab58d9362b" name="afd51d24be1d7e89cd370caab58d9362b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd51d24be1d7e89cd370caab58d9362b">&#9670;&#160;</a></span>test_oob_score_consistency()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_oob_score_consistency </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  696</span><span class="keyword">def </span>test_oob_score_consistency():</div>
<div class="line"><span class="lineno">  697</span>    <span class="comment"># Make sure OOB scores are identical when random_state, estimator, and</span></div>
<div class="line"><span class="lineno">  698</span>    <span class="comment"># training data are fixed and fitting is done twice</span></div>
<div class="line"><span class="lineno">  699</span>    X, y = make_hastie_10_2(n_samples=200, random_state=1)</div>
<div class="line"><span class="lineno">  700</span>    bagging = BaggingClassifier(</div>
<div class="line"><span class="lineno">  701</span>        KNeighborsClassifier(),</div>
<div class="line"><span class="lineno">  702</span>        max_samples=0.5,</div>
<div class="line"><span class="lineno">  703</span>        max_features=0.5,</div>
<div class="line"><span class="lineno">  704</span>        oob_score=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  705</span>        random_state=1,</div>
<div class="line"><span class="lineno">  706</span>    )</div>
<div class="line"><span class="lineno">  707</span>    <span class="keyword">assert</span> bagging.fit(X, y).oob_score_ == bagging.fit(X, y).oob_score_</div>
<div class="line"><span class="lineno">  708</span> </div>
<div class="line"><span class="lineno">  709</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2957246ba9ecd0c5f921d864c0e71904" name="a2957246ba9ecd0c5f921d864c0e71904"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2957246ba9ecd0c5f921d864c0e71904">&#9670;&#160;</a></span>test_oob_score_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_oob_score_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  386</span><span class="keyword">def </span>test_oob_score_regression():</div>
<div class="line"><span class="lineno">  387</span>    <span class="comment"># Check that oob prediction is a good estimation of the generalization</span></div>
<div class="line"><span class="lineno">  388</span>    <span class="comment"># error.</span></div>
<div class="line"><span class="lineno">  389</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  390</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  391</span>        diabetes.data, diabetes.target, random_state=rng</div>
<div class="line"><span class="lineno">  392</span>    )</div>
<div class="line"><span class="lineno">  393</span> </div>
<div class="line"><span class="lineno">  394</span>    clf = BaggingRegressor(</div>
<div class="line"><span class="lineno">  395</span>        estimator=DecisionTreeRegressor(),</div>
<div class="line"><span class="lineno">  396</span>        n_estimators=50,</div>
<div class="line"><span class="lineno">  397</span>        bootstrap=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  398</span>        oob_score=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  399</span>        random_state=rng,</div>
<div class="line"><span class="lineno">  400</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  401</span> </div>
<div class="line"><span class="lineno">  402</span>    test_score = clf.score(X_test, y_test)</div>
<div class="line"><span class="lineno">  403</span> </div>
<div class="line"><span class="lineno">  404</span>    <span class="keyword">assert</span> abs(test_score - clf.oob_score_) &lt; 0.1</div>
<div class="line"><span class="lineno">  405</span> </div>
<div class="line"><span class="lineno">  406</span>    <span class="comment"># Test with few estimators</span></div>
<div class="line"><span class="lineno">  407</span>    warn_msg = (</div>
<div class="line"><span class="lineno">  408</span>        <span class="stringliteral">&quot;Some inputs do not have OOB scores. This probably means too few &quot;</span></div>
<div class="line"><span class="lineno">  409</span>        <span class="stringliteral">&quot;estimators were used to compute any reliable oob estimates.&quot;</span></div>
<div class="line"><span class="lineno">  410</span>    )</div>
<div class="line"><span class="lineno">  411</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=warn_msg):</div>
<div class="line"><span class="lineno">  412</span>        regr = BaggingRegressor(</div>
<div class="line"><span class="lineno">  413</span>            estimator=DecisionTreeRegressor(),</div>
<div class="line"><span class="lineno">  414</span>            n_estimators=1,</div>
<div class="line"><span class="lineno">  415</span>            bootstrap=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  416</span>            oob_score=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  417</span>            random_state=rng,</div>
<div class="line"><span class="lineno">  418</span>        )</div>
<div class="line"><span class="lineno">  419</span>        regr.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  420</span> </div>
<div class="line"><span class="lineno">  421</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afe9385dd7cd9e2aadfad0b8b92835a12" name="afe9385dd7cd9e2aadfad0b8b92835a12"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe9385dd7cd9e2aadfad0b8b92835a12">&#9670;&#160;</a></span>test_oob_score_removed_on_warm_start()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_oob_score_removed_on_warm_start </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  683</span><span class="keyword">def </span>test_oob_score_removed_on_warm_start():</div>
<div class="line"><span class="lineno">  684</span>    X, y = make_hastie_10_2(n_samples=100, random_state=1)</div>
<div class="line"><span class="lineno">  685</span> </div>
<div class="line"><span class="lineno">  686</span>    clf = BaggingClassifier(n_estimators=5, oob_score=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  687</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  688</span> </div>
<div class="line"><span class="lineno">  689</span>    clf.set_params(warm_start=<span class="keyword">True</span>, oob_score=<span class="keyword">False</span>, n_estimators=10)</div>
<div class="line"><span class="lineno">  690</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  691</span> </div>
<div class="line"><span class="lineno">  692</span>    <span class="keyword">with</span> pytest.raises(AttributeError):</div>
<div class="line"><span class="lineno">  693</span>        getattr(clf, <span class="stringliteral">&quot;oob_score_&quot;</span>)</div>
<div class="line"><span class="lineno">  694</span> </div>
<div class="line"><span class="lineno">  695</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0cd630c927282efac212b1e3beae4491" name="a0cd630c927282efac212b1e3beae4491"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0cd630c927282efac212b1e3beae4491">&#9670;&#160;</a></span>test_parallel_classification()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_parallel_classification </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  449</span><span class="keyword">def </span>test_parallel_classification():</div>
<div class="line"><span class="lineno">  450</span>    <span class="comment"># Check parallel classification.</span></div>
<div class="line"><span class="lineno">  451</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  452</span>        iris.data, iris.target, random_state=0</div>
<div class="line"><span class="lineno">  453</span>    )</div>
<div class="line"><span class="lineno">  454</span> </div>
<div class="line"><span class="lineno">  455</span>    ensemble = BaggingClassifier(</div>
<div class="line"><span class="lineno">  456</span>        DecisionTreeClassifier(), n_jobs=3, random_state=0</div>
<div class="line"><span class="lineno">  457</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  458</span> </div>
<div class="line"><span class="lineno">  459</span>    <span class="comment"># predict_proba</span></div>
<div class="line"><span class="lineno">  460</span>    y1 = ensemble.predict_proba(X_test)</div>
<div class="line"><span class="lineno">  461</span>    ensemble.set_params(n_jobs=1)</div>
<div class="line"><span class="lineno">  462</span>    y2 = ensemble.predict_proba(X_test)</div>
<div class="line"><span class="lineno">  463</span>    assert_array_almost_equal(y1, y2)</div>
<div class="line"><span class="lineno">  464</span> </div>
<div class="line"><span class="lineno">  465</span>    ensemble = BaggingClassifier(</div>
<div class="line"><span class="lineno">  466</span>        DecisionTreeClassifier(), n_jobs=1, random_state=0</div>
<div class="line"><span class="lineno">  467</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  468</span> </div>
<div class="line"><span class="lineno">  469</span>    y3 = ensemble.predict_proba(X_test)</div>
<div class="line"><span class="lineno">  470</span>    assert_array_almost_equal(y1, y3)</div>
<div class="line"><span class="lineno">  471</span> </div>
<div class="line"><span class="lineno">  472</span>    <span class="comment"># decision_function</span></div>
<div class="line"><span class="lineno">  473</span>    ensemble = BaggingClassifier(</div>
<div class="line"><span class="lineno">  474</span>        SVC(decision_function_shape=<span class="stringliteral">&quot;ovr&quot;</span>), n_jobs=3, random_state=0</div>
<div class="line"><span class="lineno">  475</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  476</span> </div>
<div class="line"><span class="lineno">  477</span>    decisions1 = ensemble.decision_function(X_test)</div>
<div class="line"><span class="lineno">  478</span>    ensemble.set_params(n_jobs=1)</div>
<div class="line"><span class="lineno">  479</span>    decisions2 = ensemble.decision_function(X_test)</div>
<div class="line"><span class="lineno">  480</span>    assert_array_almost_equal(decisions1, decisions2)</div>
<div class="line"><span class="lineno">  481</span> </div>
<div class="line"><span class="lineno">  482</span>    ensemble = BaggingClassifier(</div>
<div class="line"><span class="lineno">  483</span>        SVC(decision_function_shape=<span class="stringliteral">&quot;ovr&quot;</span>), n_jobs=1, random_state=0</div>
<div class="line"><span class="lineno">  484</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  485</span> </div>
<div class="line"><span class="lineno">  486</span>    decisions3 = ensemble.decision_function(X_test)</div>
<div class="line"><span class="lineno">  487</span>    assert_array_almost_equal(decisions1, decisions3)</div>
<div class="line"><span class="lineno">  488</span> </div>
<div class="line"><span class="lineno">  489</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0b45fb4c90b531ee1e0656b156cbd0f3" name="a0b45fb4c90b531ee1e0656b156cbd0f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b45fb4c90b531ee1e0656b156cbd0f3">&#9670;&#160;</a></span>test_parallel_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_parallel_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  490</span><span class="keyword">def </span>test_parallel_regression():</div>
<div class="line"><span class="lineno">  491</span>    <span class="comment"># Check parallel regression.</span></div>
<div class="line"><span class="lineno">  492</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  493</span> </div>
<div class="line"><span class="lineno">  494</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  495</span>        diabetes.data, diabetes.target, random_state=rng</div>
<div class="line"><span class="lineno">  496</span>    )</div>
<div class="line"><span class="lineno">  497</span> </div>
<div class="line"><span class="lineno">  498</span>    ensemble = BaggingRegressor(DecisionTreeRegressor(), n_jobs=3, random_state=0).fit(</div>
<div class="line"><span class="lineno">  499</span>        X_train, y_train</div>
<div class="line"><span class="lineno">  500</span>    )</div>
<div class="line"><span class="lineno">  501</span> </div>
<div class="line"><span class="lineno">  502</span>    ensemble.set_params(n_jobs=1)</div>
<div class="line"><span class="lineno">  503</span>    y1 = ensemble.predict(X_test)</div>
<div class="line"><span class="lineno">  504</span>    ensemble.set_params(n_jobs=2)</div>
<div class="line"><span class="lineno">  505</span>    y2 = ensemble.predict(X_test)</div>
<div class="line"><span class="lineno">  506</span>    assert_array_almost_equal(y1, y2)</div>
<div class="line"><span class="lineno">  507</span> </div>
<div class="line"><span class="lineno">  508</span>    ensemble = BaggingRegressor(DecisionTreeRegressor(), n_jobs=1, random_state=0).fit(</div>
<div class="line"><span class="lineno">  509</span>        X_train, y_train</div>
<div class="line"><span class="lineno">  510</span>    )</div>
<div class="line"><span class="lineno">  511</span> </div>
<div class="line"><span class="lineno">  512</span>    y3 = ensemble.predict(X_test)</div>
<div class="line"><span class="lineno">  513</span>    assert_array_almost_equal(y1, y3)</div>
<div class="line"><span class="lineno">  514</span> </div>
<div class="line"><span class="lineno">  515</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a02d125fed33e13114587bf443259cf3d" name="a02d125fed33e13114587bf443259cf3d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a02d125fed33e13114587bf443259cf3d">&#9670;&#160;</a></span>test_probability()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_probability </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  314</span><span class="keyword">def </span>test_probability():</div>
<div class="line"><span class="lineno">  315</span>    <span class="comment"># Predict probabilities.</span></div>
<div class="line"><span class="lineno">  316</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  317</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  318</span>        iris.data, iris.target, random_state=rng</div>
<div class="line"><span class="lineno">  319</span>    )</div>
<div class="line"><span class="lineno">  320</span> </div>
<div class="line"><span class="lineno">  321</span>    <span class="keyword">with</span> np.errstate(divide=<span class="stringliteral">&quot;ignore&quot;</span>, invalid=<span class="stringliteral">&quot;ignore&quot;</span>):</div>
<div class="line"><span class="lineno">  322</span>        <span class="comment"># Normal case</span></div>
<div class="line"><span class="lineno">  323</span>        ensemble = BaggingClassifier(</div>
<div class="line"><span class="lineno">  324</span>            estimator=DecisionTreeClassifier(), random_state=rng</div>
<div class="line"><span class="lineno">  325</span>        ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  326</span> </div>
<div class="line"><span class="lineno">  327</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  328</span>            np.sum(ensemble.predict_proba(X_test), axis=1), np.ones(len(X_test))</div>
<div class="line"><span class="lineno">  329</span>        )</div>
<div class="line"><span class="lineno">  330</span> </div>
<div class="line"><span class="lineno">  331</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  332</span>            ensemble.predict_proba(X_test), np.exp(ensemble.predict_log_proba(X_test))</div>
<div class="line"><span class="lineno">  333</span>        )</div>
<div class="line"><span class="lineno">  334</span> </div>
<div class="line"><span class="lineno">  335</span>        <span class="comment"># Degenerate case, where some classes are missing</span></div>
<div class="line"><span class="lineno">  336</span>        ensemble = BaggingClassifier(</div>
<div class="line"><span class="lineno">  337</span>            estimator=LogisticRegression(), random_state=rng, max_samples=5</div>
<div class="line"><span class="lineno">  338</span>        ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  339</span> </div>
<div class="line"><span class="lineno">  340</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  341</span>            np.sum(ensemble.predict_proba(X_test), axis=1), np.ones(len(X_test))</div>
<div class="line"><span class="lineno">  342</span>        )</div>
<div class="line"><span class="lineno">  343</span> </div>
<div class="line"><span class="lineno">  344</span>        assert_array_almost_equal(</div>
<div class="line"><span class="lineno">  345</span>            ensemble.predict_proba(X_test), np.exp(ensemble.predict_log_proba(X_test))</div>
<div class="line"><span class="lineno">  346</span>        )</div>
<div class="line"><span class="lineno">  347</span> </div>
<div class="line"><span class="lineno">  348</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4c5b3b53d3af8d71c1ec3cd2c8018e59" name="a4c5b3b53d3af8d71c1ec3cd2c8018e59"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c5b3b53d3af8d71c1ec3cd2c8018e59">&#9670;&#160;</a></span>test_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  149</span><span class="keyword">def </span>test_regression():</div>
<div class="line"><span class="lineno">  150</span>    <span class="comment"># Check regression for various parameter settings.</span></div>
<div class="line"><span class="lineno">  151</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  152</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  153</span>        diabetes.data[:50], diabetes.target[:50], random_state=rng</div>
<div class="line"><span class="lineno">  154</span>    )</div>
<div class="line"><span class="lineno">  155</span>    grid = ParameterGrid(</div>
<div class="line"><span class="lineno">  156</span>        {</div>
<div class="line"><span class="lineno">  157</span>            <span class="stringliteral">&quot;max_samples&quot;</span>: [0.5, 1.0],</div>
<div class="line"><span class="lineno">  158</span>            <span class="stringliteral">&quot;max_features&quot;</span>: [0.5, 1.0],</div>
<div class="line"><span class="lineno">  159</span>            <span class="stringliteral">&quot;bootstrap&quot;</span>: [<span class="keyword">True</span>, <span class="keyword">False</span>],</div>
<div class="line"><span class="lineno">  160</span>            <span class="stringliteral">&quot;bootstrap_features&quot;</span>: [<span class="keyword">True</span>, <span class="keyword">False</span>],</div>
<div class="line"><span class="lineno">  161</span>        }</div>
<div class="line"><span class="lineno">  162</span>    )</div>
<div class="line"><span class="lineno">  163</span> </div>
<div class="line"><span class="lineno">  164</span>    <span class="keywordflow">for</span> estimator <span class="keywordflow">in</span> [</div>
<div class="line"><span class="lineno">  165</span>        <span class="keywordtype">None</span>,</div>
<div class="line"><span class="lineno">  166</span>        DummyRegressor(),</div>
<div class="line"><span class="lineno">  167</span>        DecisionTreeRegressor(),</div>
<div class="line"><span class="lineno">  168</span>        KNeighborsRegressor(),</div>
<div class="line"><span class="lineno">  169</span>        SVR(),</div>
<div class="line"><span class="lineno">  170</span>    ]:</div>
<div class="line"><span class="lineno">  171</span>        <span class="keywordflow">for</span> params <span class="keywordflow">in</span> grid:</div>
<div class="line"><span class="lineno">  172</span>            BaggingRegressor(estimator=estimator, random_state=rng, **params).fit(</div>
<div class="line"><span class="lineno">  173</span>                X_train, y_train</div>
<div class="line"><span class="lineno">  174</span>            ).predict(X_test)</div>
<div class="line"><span class="lineno">  175</span> </div>
<div class="line"><span class="lineno">  176</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad08ff58c73c8df950ed091e052d0d9cb" name="ad08ff58c73c8df950ed091e052d0d9cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad08ff58c73c8df950ed091e052d0d9cb">&#9670;&#160;</a></span>test_set_oob_score_label_encoding()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_set_oob_score_label_encoding </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  792</span><span class="keyword">def </span>test_set_oob_score_label_encoding():</div>
<div class="line"><span class="lineno">  793</span>    <span class="comment"># Make sure the oob_score doesn&#39;t change when the labels change</span></div>
<div class="line"><span class="lineno">  794</span>    <span class="comment"># See: https://github.com/scikit-learn/scikit-learn/issues/8933</span></div>
<div class="line"><span class="lineno">  795</span>    random_state = 5</div>
<div class="line"><span class="lineno">  796</span>    X = [[-1], [0], [1]] * 5</div>
<div class="line"><span class="lineno">  797</span>    Y1 = [<span class="stringliteral">&quot;A&quot;</span>, <span class="stringliteral">&quot;B&quot;</span>, <span class="stringliteral">&quot;C&quot;</span>] * 5</div>
<div class="line"><span class="lineno">  798</span>    Y2 = [-1, 0, 1] * 5</div>
<div class="line"><span class="lineno">  799</span>    Y3 = [0, 1, 2] * 5</div>
<div class="line"><span class="lineno">  800</span>    x1 = (</div>
<div class="line"><span class="lineno">  801</span>        BaggingClassifier(oob_score=<span class="keyword">True</span>, random_state=random_state)</div>
<div class="line"><span class="lineno">  802</span>        .fit(X, Y1)</div>
<div class="line"><span class="lineno">  803</span>        .oob_score_</div>
<div class="line"><span class="lineno">  804</span>    )</div>
<div class="line"><span class="lineno">  805</span>    x2 = (</div>
<div class="line"><span class="lineno">  806</span>        BaggingClassifier(oob_score=<span class="keyword">True</span>, random_state=random_state)</div>
<div class="line"><span class="lineno">  807</span>        .fit(X, Y2)</div>
<div class="line"><span class="lineno">  808</span>        .oob_score_</div>
<div class="line"><span class="lineno">  809</span>    )</div>
<div class="line"><span class="lineno">  810</span>    x3 = (</div>
<div class="line"><span class="lineno">  811</span>        BaggingClassifier(oob_score=<span class="keyword">True</span>, random_state=random_state)</div>
<div class="line"><span class="lineno">  812</span>        .fit(X, Y3)</div>
<div class="line"><span class="lineno">  813</span>        .oob_score_</div>
<div class="line"><span class="lineno">  814</span>    )</div>
<div class="line"><span class="lineno">  815</span>    <span class="keyword">assert</span> [x1, x2] == [x3, x3]</div>
<div class="line"><span class="lineno">  816</span> </div>
<div class="line"><span class="lineno">  817</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a59dd0edb3a0342ab2e6e4c2a7b6e2587" name="a59dd0edb3a0342ab2e6e4c2a7b6e2587"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59dd0edb3a0342ab2e6e4c2a7b6e2587">&#9670;&#160;</a></span>test_single_estimator()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_single_estimator </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  422</span><span class="keyword">def </span>test_single_estimator():</div>
<div class="line"><span class="lineno">  423</span>    <span class="comment"># Check singleton ensembles.</span></div>
<div class="line"><span class="lineno">  424</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  425</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  426</span>        diabetes.data, diabetes.target, random_state=rng</div>
<div class="line"><span class="lineno">  427</span>    )</div>
<div class="line"><span class="lineno">  428</span> </div>
<div class="line"><span class="lineno">  429</span>    clf1 = BaggingRegressor(</div>
<div class="line"><span class="lineno">  430</span>        estimator=KNeighborsRegressor(),</div>
<div class="line"><span class="lineno">  431</span>        n_estimators=1,</div>
<div class="line"><span class="lineno">  432</span>        bootstrap=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  433</span>        bootstrap_features=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  434</span>        random_state=rng,</div>
<div class="line"><span class="lineno">  435</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  436</span> </div>
<div class="line"><span class="lineno">  437</span>    clf2 = KNeighborsRegressor().fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  438</span> </div>
<div class="line"><span class="lineno">  439</span>    assert_array_almost_equal(clf1.predict(X_test), clf2.predict(X_test))</div>
<div class="line"><span class="lineno">  440</span> </div>
<div class="line"><span class="lineno">  441</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aec09a257f968189083517950a262f57a" name="aec09a257f968189083517950a262f57a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec09a257f968189083517950a262f57a">&#9670;&#160;</a></span>test_sparse_classification()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_sparse_classification </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sparse_format</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  108</span><span class="keyword">def </span>test_sparse_classification(sparse_format, params, method):</div>
<div class="line"><span class="lineno">  109</span>    <span class="comment"># Check classification for various parameter settings on sparse input.</span></div>
<div class="line"><span class="lineno">  110</span> </div>
<div class="line"><span class="lineno">  111</span>    <span class="keyword">class </span>CustomSVC(SVC):</div>
<div class="line"><span class="lineno">  112</span>        <span class="stringliteral">&quot;&quot;&quot;SVC variant that records the nature of the training set&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  113</span> </div>
<div class="line"><span class="lineno">  114</span>        <span class="keyword">def </span>fit(self, X, y):</div>
<div class="line"><span class="lineno">  115</span>            super().fit(X, y)</div>
<div class="line"><span class="lineno">  116</span>            self.data_type_ = type(X)</div>
<div class="line"><span class="lineno">  117</span>            <span class="keywordflow">return</span> self</div>
<div class="line"><span class="lineno">  118</span> </div>
<div class="line"><span class="lineno">  119</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  120</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  121</span>        scale(iris.data), iris.target, random_state=rng</div>
<div class="line"><span class="lineno">  122</span>    )</div>
<div class="line"><span class="lineno">  123</span> </div>
<div class="line"><span class="lineno">  124</span>    X_train_sparse = sparse_format(X_train)</div>
<div class="line"><span class="lineno">  125</span>    X_test_sparse = sparse_format(X_test)</div>
<div class="line"><span class="lineno">  126</span>    <span class="comment"># Trained on sparse format</span></div>
<div class="line"><span class="lineno">  127</span>    sparse_classifier = BaggingClassifier(</div>
<div class="line"><span class="lineno">  128</span>        estimator=CustomSVC(kernel=<span class="stringliteral">&quot;linear&quot;</span>, decision_function_shape=<span class="stringliteral">&quot;ovr&quot;</span>),</div>
<div class="line"><span class="lineno">  129</span>        random_state=1,</div>
<div class="line"><span class="lineno">  130</span>        **params,</div>
<div class="line"><span class="lineno">  131</span>    ).fit(X_train_sparse, y_train)</div>
<div class="line"><span class="lineno">  132</span>    sparse_results = getattr(sparse_classifier, method)(X_test_sparse)</div>
<div class="line"><span class="lineno">  133</span> </div>
<div class="line"><span class="lineno">  134</span>    <span class="comment"># Trained on dense format</span></div>
<div class="line"><span class="lineno">  135</span>    dense_classifier = BaggingClassifier(</div>
<div class="line"><span class="lineno">  136</span>        estimator=CustomSVC(kernel=<span class="stringliteral">&quot;linear&quot;</span>, decision_function_shape=<span class="stringliteral">&quot;ovr&quot;</span>),</div>
<div class="line"><span class="lineno">  137</span>        random_state=1,</div>
<div class="line"><span class="lineno">  138</span>        **params,</div>
<div class="line"><span class="lineno">  139</span>    ).fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  140</span>    dense_results = getattr(dense_classifier, method)(X_test)</div>
<div class="line"><span class="lineno">  141</span>    assert_array_almost_equal(sparse_results, dense_results)</div>
<div class="line"><span class="lineno">  142</span> </div>
<div class="line"><span class="lineno">  143</span>    sparse_type = type(X_train_sparse)</div>
<div class="line"><span class="lineno">  144</span>    types = [i.data_type_ <span class="keywordflow">for</span> i <span class="keywordflow">in</span> sparse_classifier.estimators_]</div>
<div class="line"><span class="lineno">  145</span> </div>
<div class="line"><span class="lineno">  146</span>    <span class="keyword">assert</span> all([t == sparse_type <span class="keywordflow">for</span> t <span class="keywordflow">in</span> types])</div>
<div class="line"><span class="lineno">  147</span> </div>
<div class="line"><span class="lineno">  148</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a71b3badbdbdea2daeb407bd5f59a4c50" name="a71b3badbdbdea2daeb407bd5f59a4c50"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a71b3badbdbdea2daeb407bd5f59a4c50">&#9670;&#160;</a></span>test_sparse_regression()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_sparse_regression </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  177</span><span class="keyword">def </span>test_sparse_regression():</div>
<div class="line"><span class="lineno">  178</span>    <span class="comment"># Check regression for various parameter settings on sparse input.</span></div>
<div class="line"><span class="lineno">  179</span>    rng = check_random_state(0)</div>
<div class="line"><span class="lineno">  180</span>    X_train, X_test, y_train, y_test = train_test_split(</div>
<div class="line"><span class="lineno">  181</span>        diabetes.data[:50], diabetes.target[:50], random_state=rng</div>
<div class="line"><span class="lineno">  182</span>    )</div>
<div class="line"><span class="lineno">  183</span> </div>
<div class="line"><span class="lineno">  184</span>    <span class="keyword">class </span>CustomSVR(SVR):</div>
<div class="line"><span class="lineno">  185</span>        <span class="stringliteral">&quot;&quot;&quot;SVC variant that records the nature of the training set&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  186</span> </div>
<div class="line"><span class="lineno">  187</span>        <span class="keyword">def </span>fit(self, X, y):</div>
<div class="line"><span class="lineno">  188</span>            super().fit(X, y)</div>
<div class="line"><span class="lineno">  189</span>            self.data_type_ = type(X)</div>
<div class="line"><span class="lineno">  190</span>            <span class="keywordflow">return</span> self</div>
<div class="line"><span class="lineno">  191</span> </div>
<div class="line"><span class="lineno">  192</span>    parameter_sets = [</div>
<div class="line"><span class="lineno">  193</span>        {</div>
<div class="line"><span class="lineno">  194</span>            <span class="stringliteral">&quot;max_samples&quot;</span>: 0.5,</div>
<div class="line"><span class="lineno">  195</span>            <span class="stringliteral">&quot;max_features&quot;</span>: 2,</div>
<div class="line"><span class="lineno">  196</span>            <span class="stringliteral">&quot;bootstrap&quot;</span>: <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  197</span>            <span class="stringliteral">&quot;bootstrap_features&quot;</span>: <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  198</span>        },</div>
<div class="line"><span class="lineno">  199</span>        {</div>
<div class="line"><span class="lineno">  200</span>            <span class="stringliteral">&quot;max_samples&quot;</span>: 1.0,</div>
<div class="line"><span class="lineno">  201</span>            <span class="stringliteral">&quot;max_features&quot;</span>: 4,</div>
<div class="line"><span class="lineno">  202</span>            <span class="stringliteral">&quot;bootstrap&quot;</span>: <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  203</span>            <span class="stringliteral">&quot;bootstrap_features&quot;</span>: <span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  204</span>        },</div>
<div class="line"><span class="lineno">  205</span>        {<span class="stringliteral">&quot;max_features&quot;</span>: 2, <span class="stringliteral">&quot;bootstrap&quot;</span>: <span class="keyword">False</span>, <span class="stringliteral">&quot;bootstrap_features&quot;</span>: <span class="keyword">True</span>},</div>
<div class="line"><span class="lineno">  206</span>        {<span class="stringliteral">&quot;max_samples&quot;</span>: 0.5, <span class="stringliteral">&quot;bootstrap&quot;</span>: <span class="keyword">True</span>, <span class="stringliteral">&quot;bootstrap_features&quot;</span>: <span class="keyword">False</span>},</div>
<div class="line"><span class="lineno">  207</span>    ]</div>
<div class="line"><span class="lineno">  208</span> </div>
<div class="line"><span class="lineno">  209</span>    <span class="keywordflow">for</span> sparse_format <span class="keywordflow">in</span> [csc_matrix, csr_matrix]:</div>
<div class="line"><span class="lineno">  210</span>        X_train_sparse = sparse_format(X_train)</div>
<div class="line"><span class="lineno">  211</span>        X_test_sparse = sparse_format(X_test)</div>
<div class="line"><span class="lineno">  212</span>        <span class="keywordflow">for</span> params <span class="keywordflow">in</span> parameter_sets:</div>
<div class="line"><span class="lineno">  213</span> </div>
<div class="line"><span class="lineno">  214</span>            <span class="comment"># Trained on sparse format</span></div>
<div class="line"><span class="lineno">  215</span>            sparse_classifier = BaggingRegressor(</div>
<div class="line"><span class="lineno">  216</span>                estimator=CustomSVR(), random_state=1, **params</div>
<div class="line"><span class="lineno">  217</span>            ).fit(X_train_sparse, y_train)</div>
<div class="line"><span class="lineno">  218</span>            sparse_results = sparse_classifier.predict(X_test_sparse)</div>
<div class="line"><span class="lineno">  219</span> </div>
<div class="line"><span class="lineno">  220</span>            <span class="comment"># Trained on dense format</span></div>
<div class="line"><span class="lineno">  221</span>            dense_results = (</div>
<div class="line"><span class="lineno">  222</span>                BaggingRegressor(estimator=CustomSVR(), random_state=1, **params)</div>
<div class="line"><span class="lineno">  223</span>                .fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  224</span>                .predict(X_test)</div>
<div class="line"><span class="lineno">  225</span>            )</div>
<div class="line"><span class="lineno">  226</span> </div>
<div class="line"><span class="lineno">  227</span>            sparse_type = type(X_train_sparse)</div>
<div class="line"><span class="lineno">  228</span>            types = [i.data_type_ <span class="keywordflow">for</span> i <span class="keywordflow">in</span> sparse_classifier.estimators_]</div>
<div class="line"><span class="lineno">  229</span> </div>
<div class="line"><span class="lineno">  230</span>            assert_array_almost_equal(sparse_results, dense_results)</div>
<div class="line"><span class="lineno">  231</span>            <span class="keyword">assert</span> all([t == sparse_type <span class="keywordflow">for</span> t <span class="keywordflow">in</span> types])</div>
<div class="line"><span class="lineno">  232</span>            assert_array_almost_equal(sparse_results, dense_results)</div>
<div class="line"><span class="lineno">  233</span> </div>
<div class="line"><span class="lineno">  234</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a33503f39cd8d808307f0dd28cb85325d" name="a33503f39cd8d808307f0dd28cb85325d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a33503f39cd8d808307f0dd28cb85325d">&#9670;&#160;</a></span>test_warm_start()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_warm_start </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>random_state</em> = <code>42</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  602</span><span class="keyword">def </span>test_warm_start(random_state=42):</div>
<div class="line"><span class="lineno">  603</span>    <span class="comment"># Test if fitting incrementally with warm start gives a forest of the</span></div>
<div class="line"><span class="lineno">  604</span>    <span class="comment"># right size and the same results as a normal fit.</span></div>
<div class="line"><span class="lineno">  605</span>    X, y = make_hastie_10_2(n_samples=20, random_state=1)</div>
<div class="line"><span class="lineno">  606</span> </div>
<div class="line"><span class="lineno">  607</span>    clf_ws = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  608</span>    <span class="keywordflow">for</span> n_estimators <span class="keywordflow">in</span> [5, 10]:</div>
<div class="line"><span class="lineno">  609</span>        <span class="keywordflow">if</span> clf_ws <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  610</span>            clf_ws = BaggingClassifier(</div>
<div class="line"><span class="lineno">  611</span>                n_estimators=n_estimators, random_state=random_state, warm_start=<span class="keyword">True</span></div>
<div class="line"><span class="lineno">  612</span>            )</div>
<div class="line"><span class="lineno">  613</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  614</span>            clf_ws.set_params(n_estimators=n_estimators)</div>
<div class="line"><span class="lineno">  615</span>        clf_ws.fit(X, y)</div>
<div class="line"><span class="lineno">  616</span>        <span class="keyword">assert</span> len(clf_ws) == n_estimators</div>
<div class="line"><span class="lineno">  617</span> </div>
<div class="line"><span class="lineno">  618</span>    clf_no_ws = BaggingClassifier(</div>
<div class="line"><span class="lineno">  619</span>        n_estimators=10, random_state=random_state, warm_start=<span class="keyword">False</span></div>
<div class="line"><span class="lineno">  620</span>    )</div>
<div class="line"><span class="lineno">  621</span>    clf_no_ws.fit(X, y)</div>
<div class="line"><span class="lineno">  622</span> </div>
<div class="line"><span class="lineno">  623</span>    <span class="keyword">assert</span> set([tree.random_state <span class="keywordflow">for</span> tree <span class="keywordflow">in</span> clf_ws]) == set(</div>
<div class="line"><span class="lineno">  624</span>        [tree.random_state <span class="keywordflow">for</span> tree <span class="keywordflow">in</span> clf_no_ws]</div>
<div class="line"><span class="lineno">  625</span>    )</div>
<div class="line"><span class="lineno">  626</span> </div>
<div class="line"><span class="lineno">  627</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0a6ecaa5ab2f452f6129fa51796f9b97" name="a0a6ecaa5ab2f452f6129fa51796f9b97"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a6ecaa5ab2f452f6129fa51796f9b97">&#9670;&#160;</a></span>test_warm_start_equal_n_estimators()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_warm_start_equal_n_estimators </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  638</span><span class="keyword">def </span>test_warm_start_equal_n_estimators():</div>
<div class="line"><span class="lineno">  639</span>    <span class="comment"># Test that nothing happens when fitting without increasing n_estimators</span></div>
<div class="line"><span class="lineno">  640</span>    X, y = make_hastie_10_2(n_samples=20, random_state=1)</div>
<div class="line"><span class="lineno">  641</span>    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43)</div>
<div class="line"><span class="lineno">  642</span> </div>
<div class="line"><span class="lineno">  643</span>    clf = BaggingClassifier(n_estimators=5, warm_start=<span class="keyword">True</span>, random_state=83)</div>
<div class="line"><span class="lineno">  644</span>    clf.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  645</span> </div>
<div class="line"><span class="lineno">  646</span>    y_pred = clf.predict(X_test)</div>
<div class="line"><span class="lineno">  647</span>    <span class="comment"># modify X to nonsense values, this should not change anything</span></div>
<div class="line"><span class="lineno">  648</span>    X_train += 1.0</div>
<div class="line"><span class="lineno">  649</span> </div>
<div class="line"><span class="lineno">  650</span>    warn_msg = <span class="stringliteral">&quot;Warm-start fitting without increasing n_estimators does not&quot;</span></div>
<div class="line"><span class="lineno">  651</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=warn_msg):</div>
<div class="line"><span class="lineno">  652</span>        clf.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  653</span>    assert_array_equal(y_pred, clf.predict(X_test))</div>
<div class="line"><span class="lineno">  654</span> </div>
<div class="line"><span class="lineno">  655</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7d26c8fee91aa128c0a77fd7fb202968" name="a7d26c8fee91aa128c0a77fd7fb202968"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d26c8fee91aa128c0a77fd7fb202968">&#9670;&#160;</a></span>test_warm_start_equivalence()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_warm_start_equivalence </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  656</span><span class="keyword">def </span>test_warm_start_equivalence():</div>
<div class="line"><span class="lineno">  657</span>    <span class="comment"># warm started classifier with 5+5 estimators should be equivalent to</span></div>
<div class="line"><span class="lineno">  658</span>    <span class="comment"># one classifier with 10 estimators</span></div>
<div class="line"><span class="lineno">  659</span>    X, y = make_hastie_10_2(n_samples=20, random_state=1)</div>
<div class="line"><span class="lineno">  660</span>    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43)</div>
<div class="line"><span class="lineno">  661</span> </div>
<div class="line"><span class="lineno">  662</span>    clf_ws = BaggingClassifier(n_estimators=5, warm_start=<span class="keyword">True</span>, random_state=3141)</div>
<div class="line"><span class="lineno">  663</span>    clf_ws.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  664</span>    clf_ws.set_params(n_estimators=10)</div>
<div class="line"><span class="lineno">  665</span>    clf_ws.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  666</span>    y1 = clf_ws.predict(X_test)</div>
<div class="line"><span class="lineno">  667</span> </div>
<div class="line"><span class="lineno">  668</span>    clf = BaggingClassifier(n_estimators=10, warm_start=<span class="keyword">False</span>, random_state=3141)</div>
<div class="line"><span class="lineno">  669</span>    clf.fit(X_train, y_train)</div>
<div class="line"><span class="lineno">  670</span>    y2 = clf.predict(X_test)</div>
<div class="line"><span class="lineno">  671</span> </div>
<div class="line"><span class="lineno">  672</span>    assert_array_almost_equal(y1, y2)</div>
<div class="line"><span class="lineno">  673</span> </div>
<div class="line"><span class="lineno">  674</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abfc4e648a376c3336b380b82bd0aaaab" name="abfc4e648a376c3336b380b82bd0aaaab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abfc4e648a376c3336b380b82bd0aaaab">&#9670;&#160;</a></span>test_warm_start_smaller_n_estimators()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_warm_start_smaller_n_estimators </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  628</span><span class="keyword">def </span>test_warm_start_smaller_n_estimators():</div>
<div class="line"><span class="lineno">  629</span>    <span class="comment"># Test if warm start&#39;ed second fit with smaller n_estimators raises error.</span></div>
<div class="line"><span class="lineno">  630</span>    X, y = make_hastie_10_2(n_samples=20, random_state=1)</div>
<div class="line"><span class="lineno">  631</span>    clf = BaggingClassifier(n_estimators=5, warm_start=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  632</span>    clf.fit(X, y)</div>
<div class="line"><span class="lineno">  633</span>    clf.set_params(n_estimators=4)</div>
<div class="line"><span class="lineno">  634</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  635</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  636</span> </div>
<div class="line"><span class="lineno">  637</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a54ef54a11f2d9dfa310133726d530435" name="a54ef54a11f2d9dfa310133726d530435"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54ef54a11f2d9dfa310133726d530435">&#9670;&#160;</a></span>test_warm_start_with_oob_score_fails()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.test_warm_start_with_oob_score_fails </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">  675</span><span class="keyword">def </span>test_warm_start_with_oob_score_fails():</div>
<div class="line"><span class="lineno">  676</span>    <span class="comment"># Check using oob_score and warm_start simultaneously fails</span></div>
<div class="line"><span class="lineno">  677</span>    X, y = make_hastie_10_2(n_samples=20, random_state=1)</div>
<div class="line"><span class="lineno">  678</span>    clf = BaggingClassifier(n_estimators=5, warm_start=<span class="keyword">True</span>, oob_score=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  679</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><span class="lineno">  680</span>        clf.fit(X, y)</div>
<div class="line"><span class="lineno">  681</span> </div>
<div class="line"><span class="lineno">  682</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a4cfbbd659c511ea4f2a0e205098d7f96" name="a4cfbbd659c511ea4f2a0e205098d7f96"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4cfbbd659c511ea4f2a0e205098d7f96">&#9670;&#160;</a></span>_sample_indices</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging._sample_indices</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a92c2e3112ebad73576bae1d5a11a2bf9" name="a92c2e3112ebad73576bae1d5a11a2bf9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a92c2e3112ebad73576bae1d5a11a2bf9">&#9670;&#160;</a></span>data</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.data</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a650a307a13be64422532838847922e9a" name="a650a307a13be64422532838847922e9a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a650a307a13be64422532838847922e9a">&#9670;&#160;</a></span>data_type_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.data_type_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4456ee1ac662c59334b709bcb47fc354" name="a4456ee1ac662c59334b709bcb47fc354"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4456ee1ac662c59334b709bcb47fc354">&#9670;&#160;</a></span>diabetes</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.diabetes = load_diabetes()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad0148cf0d14cd2495375f129e7fb25bb" name="ad0148cf0d14cd2495375f129e7fb25bb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad0148cf0d14cd2495375f129e7fb25bb">&#9670;&#160;</a></span>iris</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.iris = load_iris()</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af1b765b0ebc92d1f54114f8a5bb4390a" name="af1b765b0ebc92d1f54114f8a5bb4390a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af1b765b0ebc92d1f54114f8a5bb4390a">&#9670;&#160;</a></span>perm</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.perm = rng.permutation(iris.target.size)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad78f45042ab1fbcc64028354993dbaa0" name="ad78f45042ab1fbcc64028354993dbaa0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad78f45042ab1fbcc64028354993dbaa0">&#9670;&#160;</a></span>rng</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.rng = check_random_state(0)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a571fa8957d9173ed6c13a6c990d310f2" name="a571fa8957d9173ed6c13a6c990d310f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a571fa8957d9173ed6c13a6c990d310f2">&#9670;&#160;</a></span>target</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.ensemble.tests.test_bagging.target</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
