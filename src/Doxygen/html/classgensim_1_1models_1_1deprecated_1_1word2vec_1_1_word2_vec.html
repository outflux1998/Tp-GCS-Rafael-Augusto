<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: gensim.models.deprecated.word2vec.Word2Vec Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacegensim.html">gensim</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models.html">models</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1deprecated.html">deprecated</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html">word2vec</a></li><li class="navelem"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html">Word2Vec</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">gensim.models.deprecated.word2vec.Word2Vec Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for gensim.models.deprecated.word2vec.Word2Vec:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.png" usemap="#gensim.models.deprecated.word2vec.Word2Vec_map" alt=""/>
  <map id="gensim.models.deprecated.word2vec.Word2Vec_map" name="gensim.models.deprecated.word2vec.Word2Vec_map">
<area href="classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load.html" alt="gensim.models.deprecated.old_saveload.SaveLoad" shape="rect" coords="320,56,630,80"/>
<area href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html" alt="gensim.models.deprecated.doc2vec.Doc2Vec" shape="rect" coords="0,168,310,192"/>
<area href="classgensim_1_1models_1_1deprecated_1_1fasttext_1_1_fast_text.html" alt="gensim.models.deprecated.fasttext.FastText" shape="rect" coords="320,168,630,192"/>
<area href="classgensim_1_1models_1_1deprecated_1_1fasttext__wrapper_1_1_fast_text.html" alt="gensim.models.deprecated.fasttext_wrapper.FastText" shape="rect" coords="640,168,950,192"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a178c3f5d28ba68c0679c7dda01214e1e" id="r_a178c3f5d28ba68c0679c7dda01214e1e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a178c3f5d28ba68c0679c7dda01214e1e">__init__</a> (self, sentences=None, size=100, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ad5b7b7b57e7e1b04ba087be8bab8e9b5">alpha</a>=0.025, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a9c69ef884587ba5a6a5c4aa2f7e4cac9">window</a>=5, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a661da677ae378913d1dc06cd9fc03f05">min_count</a>=5, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ab2320590f7860127643e742b511d2193">max_vocab_size</a>=None, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ae36d9c7a38b2ed20216787c2e01db434">sample</a>=1e-3, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a0ef7cff1a5adbcd13121c33a36a186a1">seed</a>=1, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a35896f1194793e23dcd6b07c15afd2de">workers</a>=3, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a2b873bc13d474b6e7779b82b65db2412">min_alpha</a>=0.0001, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a807d4bdeaf4f66d6d608182d4a271a32">sg</a>=0, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a182ec4c63dbee365dbab6bf61a2305d3">hs</a>=0, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a36df321e5a08d7a451dd429fe3d02a43">negative</a>=5, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a0cdb4b56553d8c515af91d88b8c016f9">cbow_mean</a>=1, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ad365734c0659876a4aa86fb63eb5cbe5">hashfxn</a>=hash, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a8e802f047465da17ae5aa210351ccf32">iter</a>=5, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a8d6b5089b464073f9f57231eca4a0176">null_word</a>=0, trim_rule=None, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ae5f6f0ab1533b6bfb3b29fa457ac1dc1">sorted_vocab</a>=1, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ac896e71155684d2c3750e1b26d32ab42">batch_words</a>=<a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html#acb33d2c07d8e0fad27410b3afe6df02d">MAX_WORDS_IN_BATCH</a>, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ac301339237350d9be571efccddfba2d9">compute_loss</a>=False)</td></tr>
<tr class="separator:a178c3f5d28ba68c0679c7dda01214e1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a282d586646a3a5b1cf9bb288830fac8d" id="r_a282d586646a3a5b1cf9bb288830fac8d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a282d586646a3a5b1cf9bb288830fac8d">initialize_word_vectors</a> (self)</td></tr>
<tr class="separator:a282d586646a3a5b1cf9bb288830fac8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a730365e47b7d5b5920d5e46e165a93cf" id="r_a730365e47b7d5b5920d5e46e165a93cf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a730365e47b7d5b5920d5e46e165a93cf">make_cum_table</a> (self, power=0.75, domain=2 **31 - 1)</td></tr>
<tr class="separator:a730365e47b7d5b5920d5e46e165a93cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a1210ba9b71122cfea0c166507d285a" id="r_a0a1210ba9b71122cfea0c166507d285a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a0a1210ba9b71122cfea0c166507d285a">create_binary_tree</a> (self)</td></tr>
<tr class="separator:a0a1210ba9b71122cfea0c166507d285a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20ec78d32708db215ee1459af4616925" id="r_a20ec78d32708db215ee1459af4616925"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a20ec78d32708db215ee1459af4616925">build_vocab</a> (self, sentences, keep_raw_vocab=False, trim_rule=None, progress_per=10000, update=False)</td></tr>
<tr class="separator:a20ec78d32708db215ee1459af4616925"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a291c3f305485f17cac80311440ef302e" id="r_a291c3f305485f17cac80311440ef302e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a291c3f305485f17cac80311440ef302e">build_vocab_from_freq</a> (self, word_freq, keep_raw_vocab=False, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a83a1d09f4d3c3aeba695230883948458">corpus_count</a>=None, trim_rule=None, update=False)</td></tr>
<tr class="separator:a291c3f305485f17cac80311440ef302e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace7363a9f93585cb79053e9404fdfa55" id="r_ace7363a9f93585cb79053e9404fdfa55"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ace7363a9f93585cb79053e9404fdfa55">scan_vocab</a> (self, sentences, progress_per=10000, trim_rule=None)</td></tr>
<tr class="separator:ace7363a9f93585cb79053e9404fdfa55"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a203a669c4c0194ad70b207c0f12244cd" id="r_a203a669c4c0194ad70b207c0f12244cd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a203a669c4c0194ad70b207c0f12244cd">scale_vocab</a> (self, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a661da677ae378913d1dc06cd9fc03f05">min_count</a>=None, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ae36d9c7a38b2ed20216787c2e01db434">sample</a>=None, dry_run=False, keep_raw_vocab=False, trim_rule=None, update=False)</td></tr>
<tr class="separator:a203a669c4c0194ad70b207c0f12244cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e071ce6bde7b7d500eb3c655ec23f96" id="r_a0e071ce6bde7b7d500eb3c655ec23f96"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a0e071ce6bde7b7d500eb3c655ec23f96">finalize_vocab</a> (self, update=False)</td></tr>
<tr class="separator:a0e071ce6bde7b7d500eb3c655ec23f96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38cdd5a0f8b001b2ebebe8211a2945f2" id="r_a38cdd5a0f8b001b2ebebe8211a2945f2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a38cdd5a0f8b001b2ebebe8211a2945f2">sort_vocab</a> (self)</td></tr>
<tr class="separator:a38cdd5a0f8b001b2ebebe8211a2945f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a403dda4524ed2fe4ebd0b8f667d3c137" id="r_a403dda4524ed2fe4ebd0b8f667d3c137"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a403dda4524ed2fe4ebd0b8f667d3c137">reset_from</a> (self, other_model)</td></tr>
<tr class="separator:a403dda4524ed2fe4ebd0b8f667d3c137"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a003023ab4e9d8589831a6ec57bdc110d" id="r_a003023ab4e9d8589831a6ec57bdc110d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a003023ab4e9d8589831a6ec57bdc110d">train</a> (self, sentences, total_examples=None, total_words=None, epochs=None, start_alpha=None, end_alpha=None, word_count=0, queue_factor=2, report_delay=1.0, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ac301339237350d9be571efccddfba2d9">compute_loss</a>=None)</td></tr>
<tr class="separator:a003023ab4e9d8589831a6ec57bdc110d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46b237aaa31eafbc1d68910bc5703ea0" id="r_a46b237aaa31eafbc1d68910bc5703ea0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a46b237aaa31eafbc1d68910bc5703ea0">score</a> (self, sentences, total_sentences=<a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html#ad226751260da61bc5831d7c01f788543">int</a>(1e6), chunksize=100, queue_factor=2, report_delay=1)</td></tr>
<tr class="separator:a46b237aaa31eafbc1d68910bc5703ea0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a4f4af9850c3566c4cd5b0810ec6ab3" id="r_a2a4f4af9850c3566c4cd5b0810ec6ab3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a2a4f4af9850c3566c4cd5b0810ec6ab3">clear_sims</a> (self)</td></tr>
<tr class="separator:a2a4f4af9850c3566c4cd5b0810ec6ab3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6796999ea3d2c2488445a5d23f3ae6af" id="r_a6796999ea3d2c2488445a5d23f3ae6af"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a6796999ea3d2c2488445a5d23f3ae6af">update_weights</a> (self)</td></tr>
<tr class="separator:a6796999ea3d2c2488445a5d23f3ae6af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afeec0020070ee92f12b5cb034fa3ef1c" id="r_afeec0020070ee92f12b5cb034fa3ef1c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#afeec0020070ee92f12b5cb034fa3ef1c">reset_weights</a> (self)</td></tr>
<tr class="separator:afeec0020070ee92f12b5cb034fa3ef1c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad34a45c9a14d1ef5e2aed2a559f2ab39" id="r_ad34a45c9a14d1ef5e2aed2a559f2ab39"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ad34a45c9a14d1ef5e2aed2a559f2ab39">seeded_vector</a> (self, seed_string)</td></tr>
<tr class="separator:ad34a45c9a14d1ef5e2aed2a559f2ab39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5ff73e9a7224127ccf824a9714da46f" id="r_ae5ff73e9a7224127ccf824a9714da46f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ae5ff73e9a7224127ccf824a9714da46f">intersect_word2vec_format</a> (self, fname, lockf=0.0, <a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html#ad0b897897ce2f11d5d259f33f227f7a0">binary</a>=False, encoding='utf8', unicode_errors='strict')</td></tr>
<tr class="separator:ae5ff73e9a7224127ccf824a9714da46f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0db4b18dd564a599c7b6a053a48b9833" id="r_a0db4b18dd564a599c7b6a053a48b9833"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a0db4b18dd564a599c7b6a053a48b9833">most_similar</a> (self, positive=None, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a36df321e5a08d7a451dd429fe3d02a43">negative</a>=None, topn=10, restrict_vocab=None, indexer=None)</td></tr>
<tr class="separator:a0db4b18dd564a599c7b6a053a48b9833"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d2cc1e2aee82041a2fd2da7d8f2d44d" id="r_a2d2cc1e2aee82041a2fd2da7d8f2d44d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a2d2cc1e2aee82041a2fd2da7d8f2d44d">wmdistance</a> (self, document1, document2)</td></tr>
<tr class="separator:a2d2cc1e2aee82041a2fd2da7d8f2d44d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c36b062b6091bdf5d08b7af9da0c99b" id="r_a9c36b062b6091bdf5d08b7af9da0c99b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a9c36b062b6091bdf5d08b7af9da0c99b">most_similar_cosmul</a> (self, positive=None, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a36df321e5a08d7a451dd429fe3d02a43">negative</a>=None, topn=10)</td></tr>
<tr class="separator:a9c36b062b6091bdf5d08b7af9da0c99b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc467f19c1596df5f236823c432a7ec0" id="r_abc467f19c1596df5f236823c432a7ec0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#abc467f19c1596df5f236823c432a7ec0">similar_by_word</a> (self, word, topn=10, restrict_vocab=None)</td></tr>
<tr class="separator:abc467f19c1596df5f236823c432a7ec0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13c5163154358cc6b81db18dd290a23c" id="r_a13c5163154358cc6b81db18dd290a23c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a13c5163154358cc6b81db18dd290a23c">similar_by_vector</a> (self, vector, topn=10, restrict_vocab=None)</td></tr>
<tr class="separator:a13c5163154358cc6b81db18dd290a23c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabfe886666a12d07d98e79c6ecb97b56" id="r_aabfe886666a12d07d98e79c6ecb97b56"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#aabfe886666a12d07d98e79c6ecb97b56">doesnt_match</a> (self, words)</td></tr>
<tr class="separator:aabfe886666a12d07d98e79c6ecb97b56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79134fae83e39b8eab5728fe12b2c845" id="r_a79134fae83e39b8eab5728fe12b2c845"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a79134fae83e39b8eab5728fe12b2c845">__getitem__</a> (self, words)</td></tr>
<tr class="separator:a79134fae83e39b8eab5728fe12b2c845"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07f3a3a2ca508c32b0eef594af3f6432" id="r_a07f3a3a2ca508c32b0eef594af3f6432"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a07f3a3a2ca508c32b0eef594af3f6432">__contains__</a> (self, word)</td></tr>
<tr class="separator:a07f3a3a2ca508c32b0eef594af3f6432"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09e28d7ee12c14e57ff44ec00daca759" id="r_a09e28d7ee12c14e57ff44ec00daca759"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a09e28d7ee12c14e57ff44ec00daca759">similarity</a> (self, w1, w2)</td></tr>
<tr class="separator:a09e28d7ee12c14e57ff44ec00daca759"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeec149756fb8bfc7a5b17ca2d1a4412d" id="r_aeec149756fb8bfc7a5b17ca2d1a4412d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#aeec149756fb8bfc7a5b17ca2d1a4412d">n_similarity</a> (self, ws1, ws2)</td></tr>
<tr class="separator:aeec149756fb8bfc7a5b17ca2d1a4412d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d5aac418f5ae000da72deffadda6dce" id="r_a4d5aac418f5ae000da72deffadda6dce"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a4d5aac418f5ae000da72deffadda6dce">predict_output_word</a> (self, context_words_list, topn=10)</td></tr>
<tr class="separator:a4d5aac418f5ae000da72deffadda6dce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4da3aff2a0b5f95ce296883e3a44e15" id="r_ab4da3aff2a0b5f95ce296883e3a44e15"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ab4da3aff2a0b5f95ce296883e3a44e15">init_sims</a> (self, replace=False)</td></tr>
<tr class="separator:ab4da3aff2a0b5f95ce296883e3a44e15"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a914cbd0210390139ad483de1921c8796" id="r_a914cbd0210390139ad483de1921c8796"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a914cbd0210390139ad483de1921c8796">estimate_memory</a> (self, vocab_size=None, report=None)</td></tr>
<tr class="separator:a914cbd0210390139ad483de1921c8796"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89405ca2a4689b887fdcb13296193d6b" id="r_a89405ca2a4689b887fdcb13296193d6b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a89405ca2a4689b887fdcb13296193d6b">accuracy</a> (self, questions, restrict_vocab=30000, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a0db4b18dd564a599c7b6a053a48b9833">most_similar</a>=None, case_insensitive=True)</td></tr>
<tr class="separator:a89405ca2a4689b887fdcb13296193d6b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1bf677fbfda9b15496a8f3847fe38f33" id="r_a1bf677fbfda9b15496a8f3847fe38f33"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a1bf677fbfda9b15496a8f3847fe38f33">evaluate_word_pairs</a> (self, pairs, delimiter='\t', restrict_vocab=300000, case_insensitive=True, dummy4unknown=False)</td></tr>
<tr class="separator:a1bf677fbfda9b15496a8f3847fe38f33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0d13d79533ffbc6ad4f21239d1f857e" id="r_af0d13d79533ffbc6ad4f21239d1f857e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#af0d13d79533ffbc6ad4f21239d1f857e">__str__</a> (self)</td></tr>
<tr class="separator:af0d13d79533ffbc6ad4f21239d1f857e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bf3471d2e1cd453054eac61b23549af" id="r_a4bf3471d2e1cd453054eac61b23549af"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a4bf3471d2e1cd453054eac61b23549af">delete_temporary_training_data</a> (self, replace_word_vectors_with_normalized=False)</td></tr>
<tr class="separator:a4bf3471d2e1cd453054eac61b23549af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adefc32ee1839e2493a273ade54056bcc" id="r_adefc32ee1839e2493a273ade54056bcc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#adefc32ee1839e2493a273ade54056bcc">save</a> (self, *<a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html#a18eabe1e89d13a9a285a7ebc46197302">args</a>, **kwargs)</td></tr>
<tr class="separator:adefc32ee1839e2493a273ade54056bcc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8583caa3d60a6b61390797f2d8a7e22e" id="r_a8583caa3d60a6b61390797f2d8a7e22e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a8583caa3d60a6b61390797f2d8a7e22e">load</a> (cls, *<a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html#a18eabe1e89d13a9a285a7ebc46197302">args</a>, **kwargs)</td></tr>
<tr class="separator:a8583caa3d60a6b61390797f2d8a7e22e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c5ee55d8e2236035a7aae64a71c356d" id="r_a9c5ee55d8e2236035a7aae64a71c356d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a9c5ee55d8e2236035a7aae64a71c356d">load_word2vec_format</a> (cls, fname, fvocab=None, <a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html#ad0b897897ce2f11d5d259f33f227f7a0">binary</a>=False, encoding='utf8', unicode_errors='strict', limit=None, datatype=REAL)</td></tr>
<tr class="separator:a9c5ee55d8e2236035a7aae64a71c356d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f167a500ca1147e950c0dc19600399e" id="r_a7f167a500ca1147e950c0dc19600399e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a7f167a500ca1147e950c0dc19600399e">save_word2vec_format</a> (self, fname, fvocab=None, <a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html#ad0b897897ce2f11d5d259f33f227f7a0">binary</a>=False)</td></tr>
<tr class="separator:a7f167a500ca1147e950c0dc19600399e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03e63bf8549e574112c4fd586626a616" id="r_a03e63bf8549e574112c4fd586626a616"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a03e63bf8549e574112c4fd586626a616">get_latest_training_loss</a> (self)</td></tr>
<tr class="separator:a03e63bf8549e574112c4fd586626a616"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-static-methods" name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:aa0a2b258d0a467cb656d29dfcc2055b9" id="r_aa0a2b258d0a467cb656d29dfcc2055b9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#aa0a2b258d0a467cb656d29dfcc2055b9">log_accuracy</a> (section)</td></tr>
<tr class="separator:aa0a2b258d0a467cb656d29dfcc2055b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a153458f09ea85c30547622f3f8c975fd" id="r_a153458f09ea85c30547622f3f8c975fd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a153458f09ea85c30547622f3f8c975fd">log_evaluate_word_pairs</a> (pearson, spearman, oov, pairs)</td></tr>
<tr class="separator:a153458f09ea85c30547622f3f8c975fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:acd356181bce61ebae608daa6851e8b53" id="r_acd356181bce61ebae608daa6851e8b53"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#acd356181bce61ebae608daa6851e8b53">load</a></td></tr>
<tr class="separator:acd356181bce61ebae608daa6851e8b53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a807d4bdeaf4f66d6d608182d4a271a32" id="r_a807d4bdeaf4f66d6d608182d4a271a32"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a807d4bdeaf4f66d6d608182d4a271a32">sg</a></td></tr>
<tr class="separator:a807d4bdeaf4f66d6d608182d4a271a32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35a0f5cab3794c8785ede91eb858e0ef" id="r_a35a0f5cab3794c8785ede91eb858e0ef"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a35a0f5cab3794c8785ede91eb858e0ef">cum_table</a></td></tr>
<tr class="separator:a35a0f5cab3794c8785ede91eb858e0ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f83596f0bd8ef7e88cbfee7a3f2f737" id="r_a3f83596f0bd8ef7e88cbfee7a3f2f737"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a3f83596f0bd8ef7e88cbfee7a3f2f737">vector_size</a></td></tr>
<tr class="separator:a3f83596f0bd8ef7e88cbfee7a3f2f737"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86d88570be4beb2d83e2349b7d349a52" id="r_a86d88570be4beb2d83e2349b7d349a52"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a86d88570be4beb2d83e2349b7d349a52">layer1_size</a></td></tr>
<tr class="separator:a86d88570be4beb2d83e2349b7d349a52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5b7b7b57e7e1b04ba087be8bab8e9b5" id="r_ad5b7b7b57e7e1b04ba087be8bab8e9b5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ad5b7b7b57e7e1b04ba087be8bab8e9b5">alpha</a></td></tr>
<tr class="separator:ad5b7b7b57e7e1b04ba087be8bab8e9b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a505e949f46853473e09dd8cbe090035d" id="r_a505e949f46853473e09dd8cbe090035d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a505e949f46853473e09dd8cbe090035d">min_alpha_yet_reached</a></td></tr>
<tr class="separator:a505e949f46853473e09dd8cbe090035d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c69ef884587ba5a6a5c4aa2f7e4cac9" id="r_a9c69ef884587ba5a6a5c4aa2f7e4cac9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a9c69ef884587ba5a6a5c4aa2f7e4cac9">window</a></td></tr>
<tr class="separator:a9c69ef884587ba5a6a5c4aa2f7e4cac9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2320590f7860127643e742b511d2193" id="r_ab2320590f7860127643e742b511d2193"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ab2320590f7860127643e742b511d2193">max_vocab_size</a></td></tr>
<tr class="separator:ab2320590f7860127643e742b511d2193"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ef7cff1a5adbcd13121c33a36a186a1" id="r_a0ef7cff1a5adbcd13121c33a36a186a1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a0ef7cff1a5adbcd13121c33a36a186a1">seed</a></td></tr>
<tr class="separator:a0ef7cff1a5adbcd13121c33a36a186a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa73d2f2a1fc0a469ac6dda92e4021a23" id="r_aa73d2f2a1fc0a469ac6dda92e4021a23"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#aa73d2f2a1fc0a469ac6dda92e4021a23">random</a></td></tr>
<tr class="separator:aa73d2f2a1fc0a469ac6dda92e4021a23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a661da677ae378913d1dc06cd9fc03f05" id="r_a661da677ae378913d1dc06cd9fc03f05"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a661da677ae378913d1dc06cd9fc03f05">min_count</a></td></tr>
<tr class="separator:a661da677ae378913d1dc06cd9fc03f05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae36d9c7a38b2ed20216787c2e01db434" id="r_ae36d9c7a38b2ed20216787c2e01db434"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ae36d9c7a38b2ed20216787c2e01db434">sample</a></td></tr>
<tr class="separator:ae36d9c7a38b2ed20216787c2e01db434"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35896f1194793e23dcd6b07c15afd2de" id="r_a35896f1194793e23dcd6b07c15afd2de"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a35896f1194793e23dcd6b07c15afd2de">workers</a></td></tr>
<tr class="separator:a35896f1194793e23dcd6b07c15afd2de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b873bc13d474b6e7779b82b65db2412" id="r_a2b873bc13d474b6e7779b82b65db2412"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a2b873bc13d474b6e7779b82b65db2412">min_alpha</a></td></tr>
<tr class="separator:a2b873bc13d474b6e7779b82b65db2412"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a182ec4c63dbee365dbab6bf61a2305d3" id="r_a182ec4c63dbee365dbab6bf61a2305d3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a182ec4c63dbee365dbab6bf61a2305d3">hs</a></td></tr>
<tr class="separator:a182ec4c63dbee365dbab6bf61a2305d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a36df321e5a08d7a451dd429fe3d02a43" id="r_a36df321e5a08d7a451dd429fe3d02a43"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a36df321e5a08d7a451dd429fe3d02a43">negative</a></td></tr>
<tr class="separator:a36df321e5a08d7a451dd429fe3d02a43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cdb4b56553d8c515af91d88b8c016f9" id="r_a0cdb4b56553d8c515af91d88b8c016f9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a0cdb4b56553d8c515af91d88b8c016f9">cbow_mean</a></td></tr>
<tr class="separator:a0cdb4b56553d8c515af91d88b8c016f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad365734c0659876a4aa86fb63eb5cbe5" id="r_ad365734c0659876a4aa86fb63eb5cbe5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ad365734c0659876a4aa86fb63eb5cbe5">hashfxn</a></td></tr>
<tr class="separator:ad365734c0659876a4aa86fb63eb5cbe5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e802f047465da17ae5aa210351ccf32" id="r_a8e802f047465da17ae5aa210351ccf32"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a8e802f047465da17ae5aa210351ccf32">iter</a></td></tr>
<tr class="separator:a8e802f047465da17ae5aa210351ccf32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d6b5089b464073f9f57231eca4a0176" id="r_a8d6b5089b464073f9f57231eca4a0176"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a8d6b5089b464073f9f57231eca4a0176">null_word</a></td></tr>
<tr class="separator:a8d6b5089b464073f9f57231eca4a0176"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96991775ad40f0ac7e1ddb3004d2499b" id="r_a96991775ad40f0ac7e1ddb3004d2499b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a96991775ad40f0ac7e1ddb3004d2499b">train_count</a></td></tr>
<tr class="separator:a96991775ad40f0ac7e1ddb3004d2499b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af258b5e0dcd596af2e84ee9a98a560bd" id="r_af258b5e0dcd596af2e84ee9a98a560bd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#af258b5e0dcd596af2e84ee9a98a560bd">total_train_time</a></td></tr>
<tr class="separator:af258b5e0dcd596af2e84ee9a98a560bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5f6f0ab1533b6bfb3b29fa457ac1dc1" id="r_ae5f6f0ab1533b6bfb3b29fa457ac1dc1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ae5f6f0ab1533b6bfb3b29fa457ac1dc1">sorted_vocab</a></td></tr>
<tr class="separator:ae5f6f0ab1533b6bfb3b29fa457ac1dc1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac896e71155684d2c3750e1b26d32ab42" id="r_ac896e71155684d2c3750e1b26d32ab42"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ac896e71155684d2c3750e1b26d32ab42">batch_words</a></td></tr>
<tr class="separator:ac896e71155684d2c3750e1b26d32ab42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6aae204318deb7dcceddb1646c9fb147" id="r_a6aae204318deb7dcceddb1646c9fb147"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a6aae204318deb7dcceddb1646c9fb147">model_trimmed_post_training</a></td></tr>
<tr class="separator:a6aae204318deb7dcceddb1646c9fb147"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac301339237350d9be571efccddfba2d9" id="r_ac301339237350d9be571efccddfba2d9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ac301339237350d9be571efccddfba2d9">compute_loss</a></td></tr>
<tr class="separator:ac301339237350d9be571efccddfba2d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a462761f9480c36c5a4c3a4325f0ea4d5" id="r_a462761f9480c36c5a4c3a4325f0ea4d5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a462761f9480c36c5a4c3a4325f0ea4d5">running_training_loss</a></td></tr>
<tr class="separator:a462761f9480c36c5a4c3a4325f0ea4d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06a5f0f7953d07f4b34dd192957d34e2" id="r_a06a5f0f7953d07f4b34dd192957d34e2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a06a5f0f7953d07f4b34dd192957d34e2">wv</a></td></tr>
<tr class="separator:a06a5f0f7953d07f4b34dd192957d34e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83a1d09f4d3c3aeba695230883948458" id="r_a83a1d09f4d3c3aeba695230883948458"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a83a1d09f4d3c3aeba695230883948458">corpus_count</a></td></tr>
<tr class="separator:a83a1d09f4d3c3aeba695230883948458"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace6c962a54d5a0322f801bf9572c55ca" id="r_ace6c962a54d5a0322f801bf9572c55ca"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ace6c962a54d5a0322f801bf9572c55ca">raw_vocab</a></td></tr>
<tr class="separator:ace6c962a54d5a0322f801bf9572c55ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5756633df3413ea7443ccfcd7629e454" id="r_a5756633df3413ea7443ccfcd7629e454"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a5756633df3413ea7443ccfcd7629e454">syn1</a></td></tr>
<tr class="separator:a5756633df3413ea7443ccfcd7629e454"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13750aead744559e1baec8783f058e90" id="r_a13750aead744559e1baec8783f058e90"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a13750aead744559e1baec8783f058e90">syn1neg</a></td></tr>
<tr class="separator:a13750aead744559e1baec8783f058e90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25a83cf6b93053af9de0aca65178bf38" id="r_a25a83cf6b93053af9de0aca65178bf38"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a25a83cf6b93053af9de0aca65178bf38">syn0_lockf</a></td></tr>
<tr class="separator:a25a83cf6b93053af9de0aca65178bf38"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-methods" name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:a96724b978e041ba4d68a3167d191de39" id="r_a96724b978e041ba4d68a3167d191de39"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a96724b978e041ba4d68a3167d191de39">_do_train_job</a> (self, sentences, <a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ad5b7b7b57e7e1b04ba087be8bab8e9b5">alpha</a>, inits)</td></tr>
<tr class="separator:a96724b978e041ba4d68a3167d191de39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01e39fecb2ffe52348c1b779b44f91e5" id="r_a01e39fecb2ffe52348c1b779b44f91e5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#a01e39fecb2ffe52348c1b779b44f91e5">_raw_word_count</a> (self, job)</td></tr>
<tr class="separator:a01e39fecb2ffe52348c1b779b44f91e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade0e52e92ceeeb970b20e06c1f107d04" id="r_ade0e52e92ceeeb970b20e06c1f107d04"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ade0e52e92ceeeb970b20e06c1f107d04">_minimize_model</a> (self, save_syn1=False, save_syn1neg=False, save_syn0_lockf=False)</td></tr>
<tr class="separator:ade0e52e92ceeeb970b20e06c1f107d04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade3ea07ba90367b71bb3f33a9fe38d08" id="r_ade3ea07ba90367b71bb3f33a9fe38d08"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1word2vec_1_1_word2_vec.html#ade3ea07ba90367b71bb3f33a9fe38d08">_load_specials</a> (self, *<a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html#a18eabe1e89d13a9a285a7ebc46197302">args</a>, **kwargs)</td></tr>
<tr class="separator:ade3ea07ba90367b71bb3f33a9fe38d08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load.html">gensim.models.deprecated.old_saveload.SaveLoad</a></td></tr>
<tr class="memitem:a8796e653965511e42898ab920a09b3a3 inherit pro_methods_classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load" id="r_a8796e653965511e42898ab920a09b3a3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load.html#a8796e653965511e42898ab920a09b3a3">_smart_save</a> (self, fname, separately=None, sep_limit=10 *1024 **2, ignore=frozenset(), pickle_protocol=2)</td></tr>
<tr class="separator:a8796e653965511e42898ab920a09b3a3 inherit pro_methods_classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0c92e3f3769517c1e1138aca821d6fb inherit pro_methods_classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load" id="r_aa0c92e3f3769517c1e1138aca821d6fb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load.html#aa0c92e3f3769517c1e1138aca821d6fb">_save_specials</a> (self, fname, separately, sep_limit, ignore, pickle_protocol, compress, subname)</td></tr>
<tr class="separator:aa0c92e3f3769517c1e1138aca821d6fb inherit pro_methods_classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="inherited" name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pro_static_methods_classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load"><td colspan="2" onclick="javascript:toggleInherit('pro_static_methods_classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load')"><img src="closed.png" alt="-"/>&#160;Static Protected Member Functions inherited from <a class="el" href="classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load.html">gensim.models.deprecated.old_saveload.SaveLoad</a></td></tr>
<tr class="memitem:a66482d68804bf9af505bf15ca28a2422 inherit pro_static_methods_classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load" id="r_a66482d68804bf9af505bf15ca28a2422"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load.html#a66482d68804bf9af505bf15ca28a2422">_adapt_by_suffix</a> (fname)</td></tr>
<tr class="separator:a66482d68804bf9af505bf15ca28a2422 inherit pro_static_methods_classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Class for training, using and evaluating neural networks described in https://code.google.com/p/word2vec/

If you're finished training a model (=no more updates, only querying)
then switch to the :mod:`gensim.models.KeyedVectors` instance in wv

The model can be stored/loaded via its `save()` and `load()` methods, or stored/loaded in a format
compatible with the original word2vec implementation via `wv.save_word2vec_format()`
and `KeyedVectors.load_word2vec_format()`.</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a178c3f5d28ba68c0679c7dda01214e1e" name="a178c3f5d28ba68c0679c7dda01214e1e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a178c3f5d28ba68c0679c7dda01214e1e">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>size</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.025</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>window</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_count</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_vocab_size</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample</em> = <code>1e-3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>seed</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>workers</em> = <code>3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_alpha</em> = <code>0.0001</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sg</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hs</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>negative</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cbow_mean</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hashfxn</em> = <code>hash</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>iter</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>null_word</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>trim_rule</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sorted_vocab</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_words</em> = <code><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html#acb33d2c07d8e0fad27410b3afe6df02d">MAX_WORDS_IN_BATCH</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>compute_loss</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Initialize the model from an iterable of `sentences`. Each sentence is a
list of words (unicode strings) that will be used for training.

The `sentences` iterable can be simply a list, but for larger corpora,
consider an iterable that streams the sentences directly from disk/network.
See :class:`BrownCorpus`, :class:`Text8Corpus` or :class:`LineSentence` in
this module for such examples.

If you don't supply `sentences`, the model is left uninitialized -- use if
you plan to initialize it in some other way.

`sg` defines the training algorithm. By default (`sg=0`), CBOW is used.
Otherwise (`sg=1`), skip-gram is employed.

`size` is the dimensionality of the feature vectors.

`window` is the maximum distance between the current and predicted word within a sentence.

`alpha` is the initial learning rate (will linearly drop to `min_alpha` as training progresses).

`seed` = for the random number generator. Initial vectors for each
word are seeded with a hash of the concatenation of word + str(seed).
Note that for a fully deterministically-reproducible run, you must also limit the model to
a single worker thread, to eliminate ordering jitter from OS thread scheduling. (In Python
3, reproducibility between interpreter launches also requires use of the PYTHONHASHSEED
environment variable to control hash randomization.)

`min_count` = ignore all words with total frequency lower than this.

`max_vocab_size` = limit RAM during vocabulary building; if there are more unique
words than this, then prune the infrequent ones. Every 10 million word types
need about 1GB of RAM. Set to `None` for no limit (default).

`sample` = threshold for configuring which higher-frequency words are randomly downsampled;
    default is 1e-3, useful range is (0, 1e-5).

`workers` = use this many worker threads to train the model (=faster training with multicore machines).

`hs` = if 1, hierarchical softmax will be used for model training.
If set to 0 (default), and `negative` is non-zero, negative sampling will be used.

`negative` = if &gt; 0, negative sampling will be used, the int for negative
specifies how many "noise words" should be drawn (usually between 5-20).
Default is 5. If set to 0, no negative samping is used.

`cbow_mean` = if 0, use the sum of the context word vectors. If 1 (default), use the mean.
Only applies when cbow is used.

`hashfxn` = hash function to use to randomly initialize weights, for increased
training reproducibility. Default is Python's rudimentary built in hash function.

`iter` = number of iterations (epochs) over the corpus. Default is 5.

`trim_rule` = vocabulary trimming rule, specifies whether certain words should remain
in the vocabulary, be trimmed away, or handled using the default (discard if word count &lt; min_count).
Can be None (min_count will be used), or a callable that accepts parameters (word, count, min_count) and
returns either `utils.RULE_DISCARD`, `utils.RULE_KEEP` or `utils.RULE_DEFAULT`.
Note: The rule, if given, is only used to prune vocabulary during build_vocab() and is not stored as part
of the model.

`sorted_vocab` = if 1 (default), sort the vocabulary by descending frequency before
assigning word indexes.

`batch_words` = target size (in words) for batches of examples passed to worker threads (and
thus cython routines). Default is 10000. (Larger batches will be passed if individual
texts are longer than 10000 words, but the standard cython code truncates to that maximum.)</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#aaf106320d200b23f7bbe1c9d085f8959">gensim.models.deprecated.doc2vec.Doc2Vec</a>, and <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext_1_1_fast_text.html#af5e1504fe25826dcb0e90af9cbe84756">gensim.models.deprecated.fasttext.FastText</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  515</span>                 trim_rule=<span class="keywordtype">None</span>, sorted_vocab=1, batch_words=MAX_WORDS_IN_BATCH, compute_loss=<span class="keyword">False</span>):</div>
<div class="line"><span class="lineno">  516</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  517</span><span class="stringliteral">        Initialize the model from an iterable of `sentences`. Each sentence is a</span></div>
<div class="line"><span class="lineno">  518</span><span class="stringliteral">        list of words (unicode strings) that will be used for training.</span></div>
<div class="line"><span class="lineno">  519</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  520</span><span class="stringliteral">        The `sentences` iterable can be simply a list, but for larger corpora,</span></div>
<div class="line"><span class="lineno">  521</span><span class="stringliteral">        consider an iterable that streams the sentences directly from disk/network.</span></div>
<div class="line"><span class="lineno">  522</span><span class="stringliteral">        See :class:`BrownCorpus`, :class:`Text8Corpus` or :class:`LineSentence` in</span></div>
<div class="line"><span class="lineno">  523</span><span class="stringliteral">        this module for such examples.</span></div>
<div class="line"><span class="lineno">  524</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  525</span><span class="stringliteral">        If you don&#39;t supply `sentences`, the model is left uninitialized -- use if</span></div>
<div class="line"><span class="lineno">  526</span><span class="stringliteral">        you plan to initialize it in some other way.</span></div>
<div class="line"><span class="lineno">  527</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  528</span><span class="stringliteral">        `sg` defines the training algorithm. By default (`sg=0`), CBOW is used.</span></div>
<div class="line"><span class="lineno">  529</span><span class="stringliteral">        Otherwise (`sg=1`), skip-gram is employed.</span></div>
<div class="line"><span class="lineno">  530</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  531</span><span class="stringliteral">        `size` is the dimensionality of the feature vectors.</span></div>
<div class="line"><span class="lineno">  532</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  533</span><span class="stringliteral">        `window` is the maximum distance between the current and predicted word within a sentence.</span></div>
<div class="line"><span class="lineno">  534</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  535</span><span class="stringliteral">        `alpha` is the initial learning rate (will linearly drop to `min_alpha` as training progresses).</span></div>
<div class="line"><span class="lineno">  536</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  537</span><span class="stringliteral">        `seed` = for the random number generator. Initial vectors for each</span></div>
<div class="line"><span class="lineno">  538</span><span class="stringliteral">        word are seeded with a hash of the concatenation of word + str(seed).</span></div>
<div class="line"><span class="lineno">  539</span><span class="stringliteral">        Note that for a fully deterministically-reproducible run, you must also limit the model to</span></div>
<div class="line"><span class="lineno">  540</span><span class="stringliteral">        a single worker thread, to eliminate ordering jitter from OS thread scheduling. (In Python</span></div>
<div class="line"><span class="lineno">  541</span><span class="stringliteral">        3, reproducibility between interpreter launches also requires use of the PYTHONHASHSEED</span></div>
<div class="line"><span class="lineno">  542</span><span class="stringliteral">        environment variable to control hash randomization.)</span></div>
<div class="line"><span class="lineno">  543</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  544</span><span class="stringliteral">        `min_count` = ignore all words with total frequency lower than this.</span></div>
<div class="line"><span class="lineno">  545</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  546</span><span class="stringliteral">        `max_vocab_size` = limit RAM during vocabulary building; if there are more unique</span></div>
<div class="line"><span class="lineno">  547</span><span class="stringliteral">        words than this, then prune the infrequent ones. Every 10 million word types</span></div>
<div class="line"><span class="lineno">  548</span><span class="stringliteral">        need about 1GB of RAM. Set to `None` for no limit (default).</span></div>
<div class="line"><span class="lineno">  549</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  550</span><span class="stringliteral">        `sample` = threshold for configuring which higher-frequency words are randomly downsampled;</span></div>
<div class="line"><span class="lineno">  551</span><span class="stringliteral">            default is 1e-3, useful range is (0, 1e-5).</span></div>
<div class="line"><span class="lineno">  552</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  553</span><span class="stringliteral">        `workers` = use this many worker threads to train the model (=faster training with multicore machines).</span></div>
<div class="line"><span class="lineno">  554</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  555</span><span class="stringliteral">        `hs` = if 1, hierarchical softmax will be used for model training.</span></div>
<div class="line"><span class="lineno">  556</span><span class="stringliteral">        If set to 0 (default), and `negative` is non-zero, negative sampling will be used.</span></div>
<div class="line"><span class="lineno">  557</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  558</span><span class="stringliteral">        `negative` = if &gt; 0, negative sampling will be used, the int for negative</span></div>
<div class="line"><span class="lineno">  559</span><span class="stringliteral">        specifies how many &quot;noise words&quot; should be drawn (usually between 5-20).</span></div>
<div class="line"><span class="lineno">  560</span><span class="stringliteral">        Default is 5. If set to 0, no negative samping is used.</span></div>
<div class="line"><span class="lineno">  561</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  562</span><span class="stringliteral">        `cbow_mean` = if 0, use the sum of the context word vectors. If 1 (default), use the mean.</span></div>
<div class="line"><span class="lineno">  563</span><span class="stringliteral">        Only applies when cbow is used.</span></div>
<div class="line"><span class="lineno">  564</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  565</span><span class="stringliteral">        `hashfxn` = hash function to use to randomly initialize weights, for increased</span></div>
<div class="line"><span class="lineno">  566</span><span class="stringliteral">        training reproducibility. Default is Python&#39;s rudimentary built in hash function.</span></div>
<div class="line"><span class="lineno">  567</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  568</span><span class="stringliteral">        `iter` = number of iterations (epochs) over the corpus. Default is 5.</span></div>
<div class="line"><span class="lineno">  569</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  570</span><span class="stringliteral">        `trim_rule` = vocabulary trimming rule, specifies whether certain words should remain</span></div>
<div class="line"><span class="lineno">  571</span><span class="stringliteral">        in the vocabulary, be trimmed away, or handled using the default (discard if word count &lt; min_count).</span></div>
<div class="line"><span class="lineno">  572</span><span class="stringliteral">        Can be None (min_count will be used), or a callable that accepts parameters (word, count, min_count) and</span></div>
<div class="line"><span class="lineno">  573</span><span class="stringliteral">        returns either `utils.RULE_DISCARD`, `utils.RULE_KEEP` or `utils.RULE_DEFAULT`.</span></div>
<div class="line"><span class="lineno">  574</span><span class="stringliteral">        Note: The rule, if given, is only used to prune vocabulary during build_vocab() and is not stored as part</span></div>
<div class="line"><span class="lineno">  575</span><span class="stringliteral">        of the model.</span></div>
<div class="line"><span class="lineno">  576</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  577</span><span class="stringliteral">        `sorted_vocab` = if 1 (default), sort the vocabulary by descending frequency before</span></div>
<div class="line"><span class="lineno">  578</span><span class="stringliteral">        assigning word indexes.</span></div>
<div class="line"><span class="lineno">  579</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  580</span><span class="stringliteral">        `batch_words` = target size (in words) for batches of examples passed to worker threads (and</span></div>
<div class="line"><span class="lineno">  581</span><span class="stringliteral">        thus cython routines). Default is 10000. (Larger batches will be passed if individual</span></div>
<div class="line"><span class="lineno">  582</span><span class="stringliteral">        texts are longer than 10000 words, but the standard cython code truncates to that maximum.)</span></div>
<div class="line"><span class="lineno">  583</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  584</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  585</span> </div>
<div class="line"><span class="lineno">  586</span>        self.load = call_on_class_only</div>
<div class="line"><span class="lineno">  587</span> </div>
<div class="line"><span class="lineno">  588</span>        self.initialize_word_vectors()</div>
<div class="line"><span class="lineno">  589</span>        self.sg = int(sg)</div>
<div class="line"><span class="lineno">  590</span>        self.cum_table = <span class="keywordtype">None</span>  <span class="comment"># for negative sampling</span></div>
<div class="line"><span class="lineno">  591</span>        self.vector_size = int(size)</div>
<div class="line"><span class="lineno">  592</span>        self.layer1_size = int(size)</div>
<div class="line"><span class="lineno">  593</span>        <span class="keywordflow">if</span> size % 4 != 0:</div>
<div class="line"><span class="lineno">  594</span>            logger.warning(<span class="stringliteral">&quot;consider setting layer size to a multiple of 4 for greater performance&quot;</span>)</div>
<div class="line"><span class="lineno">  595</span>        self.alpha = float(alpha)</div>
<div class="line"><span class="lineno">  596</span>        self.min_alpha_yet_reached = float(alpha)  <span class="comment"># To warn user if alpha increases</span></div>
<div class="line"><span class="lineno">  597</span>        self.window = int(window)</div>
<div class="line"><span class="lineno">  598</span>        self.max_vocab_size = max_vocab_size</div>
<div class="line"><span class="lineno">  599</span>        self.seed = seed</div>
<div class="line"><span class="lineno">  600</span>        self.random = random.RandomState(seed)</div>
<div class="line"><span class="lineno">  601</span>        self.min_count = min_count</div>
<div class="line"><span class="lineno">  602</span>        self.sample = sample</div>
<div class="line"><span class="lineno">  603</span>        self.workers = int(workers)</div>
<div class="line"><span class="lineno">  604</span>        self.min_alpha = float(min_alpha)</div>
<div class="line"><span class="lineno">  605</span>        self.hs = hs</div>
<div class="line"><span class="lineno">  606</span>        self.negative = negative</div>
<div class="line"><span class="lineno">  607</span>        self.cbow_mean = int(cbow_mean)</div>
<div class="line"><span class="lineno">  608</span>        self.hashfxn = hashfxn</div>
<div class="line"><span class="lineno">  609</span>        self.iter = iter</div>
<div class="line"><span class="lineno">  610</span>        self.null_word = null_word</div>
<div class="line"><span class="lineno">  611</span>        self.train_count = 0</div>
<div class="line"><span class="lineno">  612</span>        self.total_train_time = 0</div>
<div class="line"><span class="lineno">  613</span>        self.sorted_vocab = sorted_vocab</div>
<div class="line"><span class="lineno">  614</span>        self.batch_words = batch_words</div>
<div class="line"><span class="lineno">  615</span>        self.model_trimmed_post_training = <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  616</span>        self.compute_loss = compute_loss</div>
<div class="line"><span class="lineno">  617</span>        self.running_training_loss = 0</div>
<div class="line"><span class="lineno">  618</span>        <span class="keywordflow">if</span> sentences <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  619</span>            <span class="keywordflow">if</span> isinstance(sentences, GeneratorType):</div>
<div class="line"><span class="lineno">  620</span>                <span class="keywordflow">raise</span> TypeError(<span class="stringliteral">&quot;You can&#39;t pass a generator as the sentences argument. Try an iterator.&quot;</span>)</div>
<div class="line"><span class="lineno">  621</span>            self.build_vocab(sentences, trim_rule=trim_rule)</div>
<div class="line"><span class="lineno">  622</span>            self.train(</div>
<div class="line"><span class="lineno">  623</span>                sentences, total_examples=self.corpus_count, epochs=self.iter,</div>
<div class="line"><span class="lineno">  624</span>                start_alpha=self.alpha, end_alpha=self.min_alpha</div>
<div class="line"><span class="lineno">  625</span>            )</div>
<div class="line"><span class="lineno">  626</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  627</span>            <span class="keywordflow">if</span> trim_rule <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  628</span>                logger.warning(</div>
<div class="line"><span class="lineno">  629</span>                    <span class="stringliteral">&quot;The rule, if given, is only used to prune vocabulary during build_vocab() &quot;</span></div>
<div class="line"><span class="lineno">  630</span>                    <span class="stringliteral">&quot;and is not stored as part of the model. Model initialized without sentences. &quot;</span></div>
<div class="line"><span class="lineno">  631</span>                    <span class="stringliteral">&quot;trim_rule provided, if any, will be ignored.&quot;</span></div>
<div class="line"><span class="lineno">  632</span>                )</div>
<div class="line"><span class="lineno">  633</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a07f3a3a2ca508c32b0eef594af3f6432" name="a07f3a3a2ca508c32b0eef594af3f6432"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07f3a3a2ca508c32b0eef594af3f6432">&#9670;&#160;</a></span>__contains__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.__contains__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.__contains__() instead.
Refer to the documentation for `gensim.models.KeyedVectors.__contains__`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1476</span>    <span class="keyword">def </span>__contains__(self, word):</div>
<div class="line"><span class="lineno"> 1477</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1478</span><span class="stringliteral">        Deprecated. Use self.wv.__contains__() instead.</span></div>
<div class="line"><span class="lineno"> 1479</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.__contains__`</span></div>
<div class="line"><span class="lineno"> 1480</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1481</span>        <span class="keywordflow">return</span> self.wv.__contains__(word)</div>
<div class="line"><span class="lineno"> 1482</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a79134fae83e39b8eab5728fe12b2c845" name="a79134fae83e39b8eab5728fe12b2c845"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a79134fae83e39b8eab5728fe12b2c845">&#9670;&#160;</a></span>__getitem__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.__getitem__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>words</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.__getitem__() instead.
Refer to the documentation for `gensim.models.KeyedVectors.__getitem__`
</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext_1_1_fast_text.html#aa7b7acd389e36fc84707f8fe302db90d">gensim.models.deprecated.fasttext.FastText</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1469</span>    <span class="keyword">def </span>__getitem__(self, words):</div>
<div class="line"><span class="lineno"> 1470</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1471</span><span class="stringliteral">        Deprecated. Use self.wv.__getitem__() instead.</span></div>
<div class="line"><span class="lineno"> 1472</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.__getitem__`</span></div>
<div class="line"><span class="lineno"> 1473</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1474</span>        <span class="keywordflow">return</span> self.wv.__getitem__(words)</div>
<div class="line"><span class="lineno"> 1475</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af0d13d79533ffbc6ad4f21239d1f857e" name="af0d13d79533ffbc6ad4f21239d1f857e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0d13d79533ffbc6ad4f21239d1f857e">&#9670;&#160;</a></span>__str__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.__str__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#ab2c34b0cb047e4e396a00c28262a0e57">gensim.models.deprecated.doc2vec.Doc2Vec</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1576</span>    <span class="keyword">def </span>__str__(self):</div>
<div class="line"><span class="lineno"> 1577</span>        <span class="keywordflow">return</span> <span class="stringliteral">&quot;%s(vocab=%s, size=%s, alpha=%s)&quot;</span> % (</div>
<div class="line"><span class="lineno"> 1578</span>            self.__class__.__name__, len(self.wv.index2word), self.vector_size, self.alpha</div>
<div class="line"><span class="lineno"> 1579</span>        )</div>
<div class="line"><span class="lineno"> 1580</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a96724b978e041ba4d68a3167d191de39" name="a96724b978e041ba4d68a3167d191de39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96724b978e041ba4d68a3167d191de39">&#9670;&#160;</a></span>_do_train_job()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec._do_train_job </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inits</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Train a single batch of sentences. Return 2-tuple `(effective word count after
ignoring unknown words and sentence length trimming, total word count)`.
</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#a6b4474ef5995431eaaa4d6448a97e413">gensim.models.deprecated.doc2vec.Doc2Vec</a>, and <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext_1_1_fast_text.html#a69b9fc163371c8de9320c73aa57bce20">gensim.models.deprecated.fasttext.FastText</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  966</span>    <span class="keyword">def </span>_do_train_job(self, sentences, alpha, inits):</div>
<div class="line"><span class="lineno">  967</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  968</span><span class="stringliteral">        Train a single batch of sentences. Return 2-tuple `(effective word count after</span></div>
<div class="line"><span class="lineno">  969</span><span class="stringliteral">        ignoring unknown words and sentence length trimming, total word count)`.</span></div>
<div class="line"><span class="lineno">  970</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  971</span>        work, neu1 = inits</div>
<div class="line"><span class="lineno">  972</span>        tally = 0</div>
<div class="line"><span class="lineno">  973</span>        <span class="keywordflow">if</span> self.sg:</div>
<div class="line"><span class="lineno">  974</span>            tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)</div>
<div class="line"><span class="lineno">  975</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  976</span>            tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)</div>
<div class="line"><span class="lineno">  977</span>        <span class="keywordflow">return</span> tally, self._raw_word_count(sentences)</div>
<div class="line"><span class="lineno">  978</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ade3ea07ba90367b71bb3f33a9fe38d08" name="ade3ea07ba90367b71bb3f33a9fe38d08"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade3ea07ba90367b71bb3f33a9fe38d08">&#9670;&#160;</a></span>_load_specials()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec._load_specials </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>fname</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>mmap</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Loads any attributes that were stored specially, and gives the same opportunity
to recursively included :class:`~gensim.utils.SaveLoad` instances.

Parameters
----------
fname : str
    Path to file that contains needed object.
mmap : str
    Memory-map option.
compress : bool
    Set to True if file is compressed.
subname : str
    ...</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load.html#ac940f2c59f223025c4020e3e3917bc2b">gensim.models.deprecated.old_saveload.SaveLoad</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1642</span>    <span class="keyword">def </span>_load_specials(self, *args, **kwargs):</div>
<div class="line"><span class="lineno"> 1643</span>        super(Word2Vec, self)._load_specials(*args, **kwargs)</div>
<div class="line"><span class="lineno"> 1644</span>        <span class="comment"># loading from a pre-KeyedVectors word2vec model</span></div>
<div class="line"><span class="lineno"> 1645</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(self, <span class="stringliteral">&#39;wv&#39;</span>):</div>
<div class="line"><span class="lineno"> 1646</span>            wv = KeyedVectors()</div>
<div class="line"><span class="lineno"> 1647</span>            wv.syn0 = self.__dict__.get(<span class="stringliteral">&#39;syn0&#39;</span>, [])</div>
<div class="line"><span class="lineno"> 1648</span>            wv.syn0norm = self.__dict__.get(<span class="stringliteral">&#39;syn0norm&#39;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno"> 1649</span>            wv.vocab = self.__dict__.get(<span class="stringliteral">&#39;vocab&#39;</span>, {})</div>
<div class="line"><span class="lineno"> 1650</span>            wv.index2word = self.__dict__.get(<span class="stringliteral">&#39;index2word&#39;</span>, [])</div>
<div class="line"><span class="lineno"> 1651</span>            self.wv = wv</div>
<div class="line"><span class="lineno"> 1652</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ade0e52e92ceeeb970b20e06c1f107d04" name="ade0e52e92ceeeb970b20e06c1f107d04"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ade0e52e92ceeeb970b20e06c1f107d04">&#9670;&#160;</a></span>_minimize_model()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec._minimize_model </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>save_syn1</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>save_syn1neg</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>save_syn0_lockf</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1581</span>    <span class="keyword">def </span>_minimize_model(self, save_syn1=False, save_syn1neg=False, save_syn0_lockf=False):</div>
<div class="line"><span class="lineno"> 1582</span>        warnings.warn(</div>
<div class="line"><span class="lineno"> 1583</span>            <span class="stringliteral">&quot;This method would be deprecated in the future. &quot;</span></div>
<div class="line"><span class="lineno"> 1584</span>            <span class="stringliteral">&quot;Keep just_word_vectors = model.wv to retain just the KeyedVectors instance &quot;</span></div>
<div class="line"><span class="lineno"> 1585</span>            <span class="stringliteral">&quot;for read-only querying of word vectors.&quot;</span></div>
<div class="line"><span class="lineno"> 1586</span>        )</div>
<div class="line"><span class="lineno"> 1587</span>        <span class="keywordflow">if</span> save_syn1 <span class="keywordflow">and</span> save_syn1neg <span class="keywordflow">and</span> save_syn0_lockf:</div>
<div class="line"><span class="lineno"> 1588</span>            <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno"> 1589</span>        <span class="keywordflow">if</span> hasattr(self, <span class="stringliteral">&#39;syn1&#39;</span>) <span class="keywordflow">and</span> <span class="keywordflow">not</span> save_syn1:</div>
<div class="line"><span class="lineno"> 1590</span>            del self.syn1</div>
<div class="line"><span class="lineno"> 1591</span>        <span class="keywordflow">if</span> hasattr(self, <span class="stringliteral">&#39;syn1neg&#39;</span>) <span class="keywordflow">and</span> <span class="keywordflow">not</span> save_syn1neg:</div>
<div class="line"><span class="lineno"> 1592</span>            del self.syn1neg</div>
<div class="line"><span class="lineno"> 1593</span>        <span class="keywordflow">if</span> hasattr(self, <span class="stringliteral">&#39;syn0_lockf&#39;</span>) <span class="keywordflow">and</span> <span class="keywordflow">not</span> save_syn0_lockf:</div>
<div class="line"><span class="lineno"> 1594</span>            del self.syn0_lockf</div>
<div class="line"><span class="lineno"> 1595</span>        self.model_trimmed_post_training = <span class="keyword">True</span></div>
<div class="line"><span class="lineno"> 1596</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a01e39fecb2ffe52348c1b779b44f91e5" name="a01e39fecb2ffe52348c1b779b44f91e5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01e39fecb2ffe52348c1b779b44f91e5">&#9670;&#160;</a></span>_raw_word_count()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec._raw_word_count </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>job</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Return the number of words in a given job.</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#adb9d89483ab808e977311f2562f4d84a">gensim.models.deprecated.doc2vec.Doc2Vec</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  979</span>    <span class="keyword">def </span>_raw_word_count(self, job):</div>
<div class="line"><span class="lineno">  980</span>        <span class="stringliteral">&quot;&quot;&quot;Return the number of words in a given job.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  981</span>        <span class="keywordflow">return</span> sum(len(sentence) <span class="keywordflow">for</span> sentence <span class="keywordflow">in</span> job)</div>
<div class="line"><span class="lineno">  982</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a89405ca2a4689b887fdcb13296193d6b" name="a89405ca2a4689b887fdcb13296193d6b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a89405ca2a4689b887fdcb13296193d6b">&#9670;&#160;</a></span>accuracy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.accuracy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>questions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>restrict_vocab</em> = <code>30000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>most_similar</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>case_insensitive</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1556</span>    <span class="keyword">def </span>accuracy(self, questions, restrict_vocab=30000, most_similar=None, case_insensitive=True):</div>
<div class="line"><span class="lineno"> 1557</span>        most_similar = most_similar <span class="keywordflow">or</span> KeyedVectors.most_similar</div>
<div class="line"><span class="lineno"> 1558</span>        <span class="keywordflow">return</span> self.wv.accuracy(questions, restrict_vocab, most_similar, case_insensitive)</div>
<div class="line"><span class="lineno"> 1559</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a20ec78d32708db215ee1459af4616925" name="a20ec78d32708db215ee1459af4616925"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20ec78d32708db215ee1459af4616925">&#9670;&#160;</a></span>build_vocab()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.build_vocab </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>keep_raw_vocab</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>trim_rule</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>progress_per</em> = <code>10000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>update</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Build vocabulary from a sequence of sentences (can be a once-only generator stream).
Each sentence must be a list of unicode strings.
</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext_1_1_fast_text.html#ac070fcda20ce58d4e801f9161daae632">gensim.models.deprecated.fasttext.FastText</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  696</span>    <span class="keyword">def </span>build_vocab(self, sentences, keep_raw_vocab=False, trim_rule=None, progress_per=10000, update=False):</div>
<div class="line"><span class="lineno">  697</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  698</span><span class="stringliteral">        Build vocabulary from a sequence of sentences (can be a once-only generator stream).</span></div>
<div class="line"><span class="lineno">  699</span><span class="stringliteral">        Each sentence must be a list of unicode strings.</span></div>
<div class="line"><span class="lineno">  700</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  701</span>        self.scan_vocab(sentences, progress_per=progress_per, trim_rule=trim_rule)  <span class="comment"># initial survey</span></div>
<div class="line"><span class="lineno">  702</span>        <span class="comment"># trim by min_count &amp; precalculate downsampling</span></div>
<div class="line"><span class="lineno">  703</span>        self.scale_vocab(keep_raw_vocab=keep_raw_vocab, trim_rule=trim_rule, update=update)</div>
<div class="line"><span class="lineno">  704</span>        self.finalize_vocab(update=update)  <span class="comment"># build tables &amp; arrays</span></div>
<div class="line"><span class="lineno">  705</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a291c3f305485f17cac80311440ef302e" name="a291c3f305485f17cac80311440ef302e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a291c3f305485f17cac80311440ef302e">&#9670;&#160;</a></span>build_vocab_from_freq()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.build_vocab_from_freq </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_freq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>keep_raw_vocab</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>corpus_count</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>trim_rule</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>update</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Build vocabulary from a dictionary of word frequencies.
Build model vocabulary from a passed dictionary that contains (word,word count).
Words must be of type unicode strings.

Parameters
----------
`word_freq` : dict
    Word,Word_Count dictionary.
`keep_raw_vocab` : bool
    If not true, delete the raw vocabulary after the scaling is done and free up RAM.
`corpus_count`: int
    Even if no corpus is provided, this argument can set corpus_count explicitly.
`trim_rule` = vocabulary trimming rule, specifies whether certain words should remain
in the vocabulary, be trimmed away, or handled using the default (discard if word count &lt; min_count).
Can be None (min_count will be used), or a callable that accepts parameters (word, count, min_count) and
returns either `utils.RULE_DISCARD`, `utils.RULE_KEEP` or `utils.RULE_DEFAULT`.
`update`: bool
    If true, the new provided words in `word_freq` dict will be added to model's vocab.

Returns
--------
None

Examples
--------

.. sourcecode:: pycon

    &gt;&gt;&gt; from gensim.models.word2vec import Word2Vec
    &gt;&gt;&gt; model = Word2Vec()
    &gt;&gt;&gt; model.build_vocab_from_freq({"Word1": 15, "Word2": 20})</pre> <div class="fragment"><div class="line"><span class="lineno">  706</span>    <span class="keyword">def </span>build_vocab_from_freq(self, word_freq, keep_raw_vocab=False, corpus_count=None, trim_rule=None, update=False):</div>
<div class="line"><span class="lineno">  707</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  708</span><span class="stringliteral">        Build vocabulary from a dictionary of word frequencies.</span></div>
<div class="line"><span class="lineno">  709</span><span class="stringliteral">        Build model vocabulary from a passed dictionary that contains (word,word count).</span></div>
<div class="line"><span class="lineno">  710</span><span class="stringliteral">        Words must be of type unicode strings.</span></div>
<div class="line"><span class="lineno">  711</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  712</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  713</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  714</span><span class="stringliteral">        `word_freq` : dict</span></div>
<div class="line"><span class="lineno">  715</span><span class="stringliteral">            Word,Word_Count dictionary.</span></div>
<div class="line"><span class="lineno">  716</span><span class="stringliteral">        `keep_raw_vocab` : bool</span></div>
<div class="line"><span class="lineno">  717</span><span class="stringliteral">            If not true, delete the raw vocabulary after the scaling is done and free up RAM.</span></div>
<div class="line"><span class="lineno">  718</span><span class="stringliteral">        `corpus_count`: int</span></div>
<div class="line"><span class="lineno">  719</span><span class="stringliteral">            Even if no corpus is provided, this argument can set corpus_count explicitly.</span></div>
<div class="line"><span class="lineno">  720</span><span class="stringliteral">        `trim_rule` = vocabulary trimming rule, specifies whether certain words should remain</span></div>
<div class="line"><span class="lineno">  721</span><span class="stringliteral">        in the vocabulary, be trimmed away, or handled using the default (discard if word count &lt; min_count).</span></div>
<div class="line"><span class="lineno">  722</span><span class="stringliteral">        Can be None (min_count will be used), or a callable that accepts parameters (word, count, min_count) and</span></div>
<div class="line"><span class="lineno">  723</span><span class="stringliteral">        returns either `utils.RULE_DISCARD`, `utils.RULE_KEEP` or `utils.RULE_DEFAULT`.</span></div>
<div class="line"><span class="lineno">  724</span><span class="stringliteral">        `update`: bool</span></div>
<div class="line"><span class="lineno">  725</span><span class="stringliteral">            If true, the new provided words in `word_freq` dict will be added to model&#39;s vocab.</span></div>
<div class="line"><span class="lineno">  726</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  727</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  728</span><span class="stringliteral">        --------</span></div>
<div class="line"><span class="lineno">  729</span><span class="stringliteral">        None</span></div>
<div class="line"><span class="lineno">  730</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  731</span><span class="stringliteral">        Examples</span></div>
<div class="line"><span class="lineno">  732</span><span class="stringliteral">        --------</span></div>
<div class="line"><span class="lineno">  733</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  734</span><span class="stringliteral">        .. sourcecode:: pycon</span></div>
<div class="line"><span class="lineno">  735</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  736</span><span class="stringliteral">            &gt;&gt;&gt; from gensim.models.word2vec import Word2Vec</span></div>
<div class="line"><span class="lineno">  737</span><span class="stringliteral">            &gt;&gt;&gt; model = Word2Vec()</span></div>
<div class="line"><span class="lineno">  738</span><span class="stringliteral">            &gt;&gt;&gt; model.build_vocab_from_freq({&quot;Word1&quot;: 15, &quot;Word2&quot;: 20})</span></div>
<div class="line"><span class="lineno">  739</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  740</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  741</span>        logger.info(<span class="stringliteral">&quot;Processing provided word frequencies&quot;</span>)</div>
<div class="line"><span class="lineno">  742</span>        <span class="comment"># Instead of scanning text, this will assign provided word frequencies dictionary(word_freq)</span></div>
<div class="line"><span class="lineno">  743</span>        <span class="comment"># to be directly the raw vocab</span></div>
<div class="line"><span class="lineno">  744</span>        raw_vocab = word_freq</div>
<div class="line"><span class="lineno">  745</span>        logger.info(</div>
<div class="line"><span class="lineno">  746</span>            <span class="stringliteral">&quot;collected %i different raw word, with total frequency of %i&quot;</span>,</div>
<div class="line"><span class="lineno">  747</span>            len(raw_vocab), sum(itervalues(raw_vocab))</div>
<div class="line"><span class="lineno">  748</span>        )</div>
<div class="line"><span class="lineno">  749</span> </div>
<div class="line"><span class="lineno">  750</span>        <span class="comment"># Since no sentences are provided, this is to control the corpus_count</span></div>
<div class="line"><span class="lineno">  751</span>        self.corpus_count = corpus_count <span class="keywordflow">if</span> corpus_count <span class="keywordflow">else</span> 0</div>
<div class="line"><span class="lineno">  752</span>        self.raw_vocab = raw_vocab</div>
<div class="line"><span class="lineno">  753</span> </div>
<div class="line"><span class="lineno">  754</span>        <span class="comment"># trim by min_count &amp; precalculate downsampling</span></div>
<div class="line"><span class="lineno">  755</span>        self.scale_vocab(keep_raw_vocab=keep_raw_vocab, trim_rule=trim_rule, update=update)</div>
<div class="line"><span class="lineno">  756</span>        self.finalize_vocab(update=update)  <span class="comment"># build tables &amp; arrays</span></div>
<div class="line"><span class="lineno">  757</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2a4f4af9850c3566c4cd5b0810ec6ab3" name="a2a4f4af9850c3566c4cd5b0810ec6ab3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2a4f4af9850c3566c4cd5b0810ec6ab3">&#9670;&#160;</a></span>clear_sims()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.clear_sims </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Removes all L2-normalized vectors for words from the model.
You will have to recompute them using init_sims method.
</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#a332771ed6132f4ad0deaf225ef9dacc8">gensim.models.deprecated.doc2vec.Doc2Vec</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1315</span>    <span class="keyword">def </span>clear_sims(self):</div>
<div class="line"><span class="lineno"> 1316</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1317</span><span class="stringliteral">        Removes all L2-normalized vectors for words from the model.</span></div>
<div class="line"><span class="lineno"> 1318</span><span class="stringliteral">        You will have to recompute them using init_sims method.</span></div>
<div class="line"><span class="lineno"> 1319</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1320</span> </div>
<div class="line"><span class="lineno"> 1321</span>        self.wv.syn0norm = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1322</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0a1210ba9b71122cfea0c166507d285a" name="a0a1210ba9b71122cfea0c166507d285a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a1210ba9b71122cfea0c166507d285a">&#9670;&#160;</a></span>create_binary_tree()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.create_binary_tree </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Create a binary Huffman tree using stored vocabulary word counts. Frequent words
will have shorter binary codes. Called internally from `build_vocab()`.</pre> <div class="fragment"><div class="line"><span class="lineno">  662</span>    <span class="keyword">def </span>create_binary_tree(self):</div>
<div class="line"><span class="lineno">  663</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  664</span><span class="stringliteral">        Create a binary Huffman tree using stored vocabulary word counts. Frequent words</span></div>
<div class="line"><span class="lineno">  665</span><span class="stringliteral">        will have shorter binary codes. Called internally from `build_vocab()`.</span></div>
<div class="line"><span class="lineno">  666</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  667</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  668</span>        logger.info(<span class="stringliteral">&quot;constructing a huffman tree from %i words&quot;</span>, len(self.wv.vocab))</div>
<div class="line"><span class="lineno">  669</span> </div>
<div class="line"><span class="lineno">  670</span>        <span class="comment"># build the huffman tree</span></div>
<div class="line"><span class="lineno">  671</span>        heap = list(itervalues(self.wv.vocab))</div>
<div class="line"><span class="lineno">  672</span>        heapq.heapify(heap)</div>
<div class="line"><span class="lineno">  673</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(self.wv.vocab) - 1):</div>
<div class="line"><span class="lineno">  674</span>            min1, min2 = heapq.heappop(heap), heapq.heappop(heap)</div>
<div class="line"><span class="lineno">  675</span>            heapq.heappush(</div>
<div class="line"><span class="lineno">  676</span>                heap, Vocab(count=min1.count + min2.count, index=i + len(self.wv.vocab), left=min1, right=min2)</div>
<div class="line"><span class="lineno">  677</span>            )</div>
<div class="line"><span class="lineno">  678</span> </div>
<div class="line"><span class="lineno">  679</span>        <span class="comment"># recurse over the tree, assigning a binary code to each vocabulary word</span></div>
<div class="line"><span class="lineno">  680</span>        <span class="keywordflow">if</span> heap:</div>
<div class="line"><span class="lineno">  681</span>            max_depth, stack = 0, [(heap[0], [], [])]</div>
<div class="line"><span class="lineno">  682</span>            <span class="keywordflow">while</span> stack:</div>
<div class="line"><span class="lineno">  683</span>                node, codes, points = stack.pop()</div>
<div class="line"><span class="lineno">  684</span>                <span class="keywordflow">if</span> node.index &lt; len(self.wv.vocab):</div>
<div class="line"><span class="lineno">  685</span>                    <span class="comment"># leaf node =&gt; store its path from the root</span></div>
<div class="line"><span class="lineno">  686</span>                    node.code, node.point = codes, points</div>
<div class="line"><span class="lineno">  687</span>                    max_depth = max(len(codes), max_depth)</div>
<div class="line"><span class="lineno">  688</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  689</span>                    <span class="comment"># inner node =&gt; continue recursion</span></div>
<div class="line"><span class="lineno">  690</span>                    points = array(list(points) + [node.index - len(self.wv.vocab)], dtype=uint32)</div>
<div class="line"><span class="lineno">  691</span>                    stack.append((node.left, array(list(codes) + [0], dtype=uint8), points))</div>
<div class="line"><span class="lineno">  692</span>                    stack.append((node.right, array(list(codes) + [1], dtype=uint8), points))</div>
<div class="line"><span class="lineno">  693</span> </div>
<div class="line"><span class="lineno">  694</span>            logger.info(<span class="stringliteral">&quot;built huffman tree with maximum node depth %i&quot;</span>, max_depth)</div>
<div class="line"><span class="lineno">  695</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4bf3471d2e1cd453054eac61b23549af" name="a4bf3471d2e1cd453054eac61b23549af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4bf3471d2e1cd453054eac61b23549af">&#9670;&#160;</a></span>delete_temporary_training_data()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.delete_temporary_training_data </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>replace_word_vectors_with_normalized</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Discard parameters that are used in training and score. Use if you're sure you're done training a model.
If `replace_word_vectors_with_normalized` is set, forget the original vectors and only keep the normalized
ones = saves lots of memory!
</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#a323717acbedfc0d11d529e16f7f5c67d">gensim.models.deprecated.doc2vec.Doc2Vec</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1597</span>    <span class="keyword">def </span>delete_temporary_training_data(self, replace_word_vectors_with_normalized=False):</div>
<div class="line"><span class="lineno"> 1598</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1599</span><span class="stringliteral">        Discard parameters that are used in training and score. Use if you&#39;re sure you&#39;re done training a model.</span></div>
<div class="line"><span class="lineno"> 1600</span><span class="stringliteral">        If `replace_word_vectors_with_normalized` is set, forget the original vectors and only keep the normalized</span></div>
<div class="line"><span class="lineno"> 1601</span><span class="stringliteral">        ones = saves lots of memory!</span></div>
<div class="line"><span class="lineno"> 1602</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1603</span>        <span class="keywordflow">if</span> replace_word_vectors_with_normalized:</div>
<div class="line"><span class="lineno"> 1604</span>            self.init_sims(replace=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1605</span>        self._minimize_model()</div>
<div class="line"><span class="lineno"> 1606</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aabfe886666a12d07d98e79c6ecb97b56" name="aabfe886666a12d07d98e79c6ecb97b56"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aabfe886666a12d07d98e79c6ecb97b56">&#9670;&#160;</a></span>doesnt_match()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.doesnt_match </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>words</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.doesnt_match() instead.
Refer to the documentation for `gensim.models.KeyedVectors.doesnt_match`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1462</span>    <span class="keyword">def </span>doesnt_match(self, words):</div>
<div class="line"><span class="lineno"> 1463</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1464</span><span class="stringliteral">        Deprecated. Use self.wv.doesnt_match() instead.</span></div>
<div class="line"><span class="lineno"> 1465</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.doesnt_match`</span></div>
<div class="line"><span class="lineno"> 1466</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1467</span>        <span class="keywordflow">return</span> self.wv.doesnt_match(words)</div>
<div class="line"><span class="lineno"> 1468</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a914cbd0210390139ad483de1921c8796" name="a914cbd0210390139ad483de1921c8796"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a914cbd0210390139ad483de1921c8796">&#9670;&#160;</a></span>estimate_memory()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.estimate_memory </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vocab_size</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>report</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Estimate required memory for a model using current settings and provided vocabulary size.</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#a619810390e6d1456e6a2713e68a1f8c2">gensim.models.deprecated.doc2vec.Doc2Vec</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1535</span>    <span class="keyword">def </span>estimate_memory(self, vocab_size=None, report=None):</div>
<div class="line"><span class="lineno"> 1536</span>        <span class="stringliteral">&quot;&quot;&quot;Estimate required memory for a model using current settings and provided vocabulary size.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1537</span>        vocab_size = vocab_size <span class="keywordflow">or</span> len(self.wv.vocab)</div>
<div class="line"><span class="lineno"> 1538</span>        report = report <span class="keywordflow">or</span> {}</div>
<div class="line"><span class="lineno"> 1539</span>        report[<span class="stringliteral">&#39;vocab&#39;</span>] = vocab_size * (700 <span class="keywordflow">if</span> self.hs <span class="keywordflow">else</span> 500)</div>
<div class="line"><span class="lineno"> 1540</span>        report[<span class="stringliteral">&#39;syn0&#39;</span>] = vocab_size * self.vector_size * <a class="code hl_namespace" href="namespacedtype.html">dtype</a>(REAL).itemsize</div>
<div class="line"><span class="lineno"> 1541</span>        <span class="keywordflow">if</span> self.hs:</div>
<div class="line"><span class="lineno"> 1542</span>            report[<span class="stringliteral">&#39;syn1&#39;</span>] = vocab_size * self.layer1_size * <a class="code hl_namespace" href="namespacedtype.html">dtype</a>(REAL).itemsize</div>
<div class="line"><span class="lineno"> 1543</span>        <span class="keywordflow">if</span> self.negative:</div>
<div class="line"><span class="lineno"> 1544</span>            report[<span class="stringliteral">&#39;syn1neg&#39;</span>] = vocab_size * self.layer1_size * <a class="code hl_namespace" href="namespacedtype.html">dtype</a>(REAL).itemsize</div>
<div class="line"><span class="lineno"> 1545</span>        report[<span class="stringliteral">&#39;total&#39;</span>] = sum(report.values())</div>
<div class="line"><span class="lineno"> 1546</span>        logger.info(</div>
<div class="line"><span class="lineno"> 1547</span>            <span class="stringliteral">&quot;estimated required memory for %i words and %i dimensions: %i bytes&quot;</span>,</div>
<div class="line"><span class="lineno"> 1548</span>            vocab_size, self.vector_size, report[<span class="stringliteral">&#39;total&#39;</span>]</div>
<div class="line"><span class="lineno"> 1549</span>        )</div>
<div class="line"><span class="lineno"> 1550</span>        <span class="keywordflow">return</span> report</div>
<div class="line"><span class="lineno"> 1551</span> </div>
<div class="ttc" id="anamespacedtype_html"><div class="ttname"><a href="namespacedtype.html">dtype</a></div><div class="ttdef"><b>Definition</b> dtype.py:1</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a1bf677fbfda9b15496a8f3847fe38f33" name="a1bf677fbfda9b15496a8f3847fe38f33"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1bf677fbfda9b15496a8f3847fe38f33">&#9670;&#160;</a></span>evaluate_word_pairs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.evaluate_word_pairs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pairs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>delimiter</em> = <code>'\t'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>restrict_vocab</em> = <code>300000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>case_insensitive</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dummy4unknown</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.evaluate_word_pairs() instead.
Refer to the documentation for `gensim.models.KeyedVectors.evaluate_word_pairs`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1569</span>                            case_insensitive=<span class="keyword">True</span>, dummy4unknown=<span class="keyword">False</span>):</div>
<div class="line"><span class="lineno"> 1570</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1571</span><span class="stringliteral">        Deprecated. Use self.wv.evaluate_word_pairs() instead.</span></div>
<div class="line"><span class="lineno"> 1572</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.evaluate_word_pairs`</span></div>
<div class="line"><span class="lineno"> 1573</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1574</span>        <span class="keywordflow">return</span> self.wv.evaluate_word_pairs(pairs, delimiter, restrict_vocab, case_insensitive, dummy4unknown)</div>
<div class="line"><span class="lineno"> 1575</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0e071ce6bde7b7d500eb3c655ec23f96" name="a0e071ce6bde7b7d500eb3c655ec23f96"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e071ce6bde7b7d500eb3c655ec23f96">&#9670;&#160;</a></span>finalize_vocab()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.finalize_vocab </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>update</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Build tables and model weights based on final vocabulary settings.</pre> <div class="fragment"><div class="line"><span class="lineno">  922</span>    <span class="keyword">def </span>finalize_vocab(self, update=False):</div>
<div class="line"><span class="lineno">  923</span>        <span class="stringliteral">&quot;&quot;&quot;Build tables and model weights based on final vocabulary settings.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  924</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.wv.index2word:</div>
<div class="line"><span class="lineno">  925</span>            self.scale_vocab()</div>
<div class="line"><span class="lineno">  926</span>        <span class="keywordflow">if</span> self.sorted_vocab <span class="keywordflow">and</span> <span class="keywordflow">not</span> update:</div>
<div class="line"><span class="lineno">  927</span>            self.sort_vocab()</div>
<div class="line"><span class="lineno">  928</span>        <span class="keywordflow">if</span> self.hs:</div>
<div class="line"><span class="lineno">  929</span>            <span class="comment"># add info about each word&#39;s Huffman encoding</span></div>
<div class="line"><span class="lineno">  930</span>            self.create_binary_tree()</div>
<div class="line"><span class="lineno">  931</span>        <span class="keywordflow">if</span> self.negative:</div>
<div class="line"><span class="lineno">  932</span>            <span class="comment"># build the table for drawing random words (for negative sampling)</span></div>
<div class="line"><span class="lineno">  933</span>            self.make_cum_table()</div>
<div class="line"><span class="lineno">  934</span>        <span class="keywordflow">if</span> self.null_word:</div>
<div class="line"><span class="lineno">  935</span>            <span class="comment"># create null pseudo-word for padding when using concatenative L1 (run-of-words)</span></div>
<div class="line"><span class="lineno">  936</span>            <span class="comment"># this word is only ever input  never predicted  so count, huffman-point, etc doesn&#39;t matter</span></div>
<div class="line"><span class="lineno">  937</span>            word, v = <span class="stringliteral">&#39;\0&#39;</span>, Vocab(count=1, sample_int=0)</div>
<div class="line"><span class="lineno">  938</span>            v.index = len(self.wv.vocab)</div>
<div class="line"><span class="lineno">  939</span>            self.wv.index2word.append(word)</div>
<div class="line"><span class="lineno">  940</span>            self.wv.vocab[word] = v</div>
<div class="line"><span class="lineno">  941</span>        <span class="comment"># set initial input/projection and hidden weights</span></div>
<div class="line"><span class="lineno">  942</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> update:</div>
<div class="line"><span class="lineno">  943</span>            self.reset_weights()</div>
<div class="line"><span class="lineno">  944</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  945</span>            self.update_weights()</div>
<div class="line"><span class="lineno">  946</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a03e63bf8549e574112c4fd586626a616" name="a03e63bf8549e574112c4fd586626a616"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a03e63bf8549e574112c4fd586626a616">&#9670;&#160;</a></span>get_latest_training_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.get_latest_training_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1663</span>    <span class="keyword">def </span>get_latest_training_loss(self):</div>
<div class="line"><span class="lineno"> 1664</span>        <span class="keywordflow">return</span> self.running_training_loss</div>
<div class="line"><span class="lineno"> 1665</span> </div>
<div class="line"><span class="lineno"> 1666</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab4da3aff2a0b5f95ce296883e3a44e15" name="ab4da3aff2a0b5f95ce296883e3a44e15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab4da3aff2a0b5f95ce296883e3a44e15">&#9670;&#160;</a></span>init_sims()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.init_sims </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>replace</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">init_sims() resides in KeyedVectors because it deals with syn0 mainly, but because syn1 is not an attribute
of KeyedVectors, it has to be deleted in this class, and the normalizing of syn0 happens inside of KeyedVectors
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1526</span>    <span class="keyword">def </span>init_sims(self, replace=False):</div>
<div class="line"><span class="lineno"> 1527</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1528</span><span class="stringliteral">        init_sims() resides in KeyedVectors because it deals with syn0 mainly, but because syn1 is not an attribute</span></div>
<div class="line"><span class="lineno"> 1529</span><span class="stringliteral">        of KeyedVectors, it has to be deleted in this class, and the normalizing of syn0 happens inside of KeyedVectors</span></div>
<div class="line"><span class="lineno"> 1530</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1531</span>        <span class="keywordflow">if</span> replace <span class="keywordflow">and</span> hasattr(self, <span class="stringliteral">&#39;syn1&#39;</span>):</div>
<div class="line"><span class="lineno"> 1532</span>            del self.syn1</div>
<div class="line"><span class="lineno"> 1533</span>        <span class="keywordflow">return</span> self.wv.init_sims(replace)</div>
<div class="line"><span class="lineno"> 1534</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a282d586646a3a5b1cf9bb288830fac8d" name="a282d586646a3a5b1cf9bb288830fac8d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a282d586646a3a5b1cf9bb288830fac8d">&#9670;&#160;</a></span>initialize_word_vectors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.initialize_word_vectors </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext_1_1_fast_text.html#a879a44847ecb891a062993d9a0b85b32">gensim.models.deprecated.fasttext.FastText</a>, and <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext__wrapper_1_1_fast_text.html#a472a9ba192b400c90c7196ff4ea39be9">gensim.models.deprecated.fasttext_wrapper.FastText</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  634</span>    <span class="keyword">def </span>initialize_word_vectors(self):</div>
<div class="line"><span class="lineno">  635</span>        self.wv = KeyedVectors()</div>
<div class="line"><span class="lineno">  636</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae5ff73e9a7224127ccf824a9714da46f" name="ae5ff73e9a7224127ccf824a9714da46f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5ff73e9a7224127ccf824a9714da46f">&#9670;&#160;</a></span>intersect_word2vec_format()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.intersect_word2vec_format </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fname</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>lockf</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>binary</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>encoding</em> = <code>'utf8'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>unicode_errors</em> = <code>'strict'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Merge the input-hidden weight matrix from the original C word2vec-tool format
given, where it intersects with the current vocabulary. (No words are added to the
existing vocabulary, but intersecting words adopt the file's weights, and
non-intersecting words are left alone.)

`binary` is a boolean indicating whether the data is in binary word2vec format.

`lockf` is a lock-factor value to be set for any imported word-vectors; the
default value of 0.0 prevents further updating of the vector during subsequent
training. Use 1.0 to allow further training updates of merged vectors.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1377</span>    <span class="keyword">def </span>intersect_word2vec_format(self, fname, lockf=0.0, binary=False, encoding=&#39;utf8&#39;, unicode_errors=&#39;strict&#39;):</div>
<div class="line"><span class="lineno"> 1378</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1379</span><span class="stringliteral">        Merge the input-hidden weight matrix from the original C word2vec-tool format</span></div>
<div class="line"><span class="lineno"> 1380</span><span class="stringliteral">        given, where it intersects with the current vocabulary. (No words are added to the</span></div>
<div class="line"><span class="lineno"> 1381</span><span class="stringliteral">        existing vocabulary, but intersecting words adopt the file&#39;s weights, and</span></div>
<div class="line"><span class="lineno"> 1382</span><span class="stringliteral">        non-intersecting words are left alone.)</span></div>
<div class="line"><span class="lineno"> 1383</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1384</span><span class="stringliteral">        `binary` is a boolean indicating whether the data is in binary word2vec format.</span></div>
<div class="line"><span class="lineno"> 1385</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1386</span><span class="stringliteral">        `lockf` is a lock-factor value to be set for any imported word-vectors; the</span></div>
<div class="line"><span class="lineno"> 1387</span><span class="stringliteral">        default value of 0.0 prevents further updating of the vector during subsequent</span></div>
<div class="line"><span class="lineno"> 1388</span><span class="stringliteral">        training. Use 1.0 to allow further training updates of merged vectors.</span></div>
<div class="line"><span class="lineno"> 1389</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1390</span>        overlap_count = 0</div>
<div class="line"><span class="lineno"> 1391</span>        logger.info(<span class="stringliteral">&quot;loading projection weights from %s&quot;</span>, fname)</div>
<div class="line"><span class="lineno"> 1392</span>        <span class="keyword">with</span> utils.open(fname, <span class="stringliteral">&#39;rb&#39;</span>) <span class="keyword">as</span> fin:</div>
<div class="line"><span class="lineno"> 1393</span>            header = utils.to_unicode(fin.readline(), encoding=encoding)</div>
<div class="line"><span class="lineno"> 1394</span>            vocab_size, vector_size = (int(x) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> header.split())  <span class="comment"># throws for invalid file format</span></div>
<div class="line"><span class="lineno"> 1395</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> vector_size == self.vector_size:</div>
<div class="line"><span class="lineno"> 1396</span>                <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;incompatible vector size %d in file %s&quot;</span> % (vector_size, fname))</div>
<div class="line"><span class="lineno"> 1397</span>                <span class="comment"># TOCONSIDER: maybe mismatched vectors still useful enough to merge (truncating/padding)?</span></div>
<div class="line"><span class="lineno"> 1398</span>            <span class="keywordflow">if</span> binary:</div>
<div class="line"><span class="lineno"> 1399</span>                binary_len = <a class="code hl_namespace" href="namespacedtype.html">dtype</a>(REAL).itemsize * vector_size</div>
<div class="line"><span class="lineno"> 1400</span>                <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(vocab_size):</div>
<div class="line"><span class="lineno"> 1401</span>                    <span class="comment"># mixed text and binary: read text first, then binary</span></div>
<div class="line"><span class="lineno"> 1402</span>                    word = []</div>
<div class="line"><span class="lineno"> 1403</span>                    <span class="keywordflow">while</span> <span class="keyword">True</span>:</div>
<div class="line"><span class="lineno"> 1404</span>                        ch = fin.read(1)</div>
<div class="line"><span class="lineno"> 1405</span>                        <span class="keywordflow">if</span> ch == b<span class="stringliteral">&#39; &#39;</span>:</div>
<div class="line"><span class="lineno"> 1406</span>                            <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno"> 1407</span>                        <span class="keywordflow">if</span> ch != b<span class="stringliteral">&#39;\n&#39;</span>:  <span class="comment"># ignore newlines in front of words (some binary files have)</span></div>
<div class="line"><span class="lineno"> 1408</span>                            word.append(ch)</div>
<div class="line"><span class="lineno"> 1409</span>                    word = utils.to_unicode(b<span class="stringliteral">&#39;&#39;</span>.join(word), encoding=encoding, errors=unicode_errors)</div>
<div class="line"><span class="lineno"> 1410</span>                    weights = fromstring(fin.read(binary_len), dtype=REAL)</div>
<div class="line"><span class="lineno"> 1411</span>                    <span class="keywordflow">if</span> word <span class="keywordflow">in</span> self.wv.vocab:</div>
<div class="line"><span class="lineno"> 1412</span>                        overlap_count += 1</div>
<div class="line"><span class="lineno"> 1413</span>                        self.wv.syn0[self.wv.vocab[word].index] = weights</div>
<div class="line"><span class="lineno"> 1414</span>                        self.syn0_lockf[self.wv.vocab[word].index] = lockf  <span class="comment"># lock-factor: 0.0 stops further changes</span></div>
<div class="line"><span class="lineno"> 1415</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1416</span>                <span class="keywordflow">for</span> line_no, line <span class="keywordflow">in</span> enumerate(fin):</div>
<div class="line"><span class="lineno"> 1417</span>                    parts = utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split(<span class="stringliteral">&quot; &quot;</span>)</div>
<div class="line"><span class="lineno"> 1418</span>                    <span class="keywordflow">if</span> len(parts) != vector_size + 1:</div>
<div class="line"><span class="lineno"> 1419</span>                        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;invalid vector on line %s (is this really the text format?)&quot;</span> % line_no)</div>
<div class="line"><span class="lineno"> 1420</span>                    word, weights = parts[0], [REAL(x) <span class="keywordflow">for</span> x <span class="keywordflow">in</span> parts[1:]]</div>
<div class="line"><span class="lineno"> 1421</span>                    <span class="keywordflow">if</span> word <span class="keywordflow">in</span> self.wv.vocab:</div>
<div class="line"><span class="lineno"> 1422</span>                        overlap_count += 1</div>
<div class="line"><span class="lineno"> 1423</span>                        self.wv.syn0[self.wv.vocab[word].index] = weights</div>
<div class="line"><span class="lineno"> 1424</span>                        self.syn0_lockf[self.wv.vocab[word].index] = lockf  <span class="comment"># lock-factor: 0.0 stops further changes</span></div>
<div class="line"><span class="lineno"> 1425</span>        logger.info(<span class="stringliteral">&quot;merged %d vectors into %s matrix from %s&quot;</span>, overlap_count, self.wv.syn0.shape, fname)</div>
<div class="line"><span class="lineno"> 1426</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a8583caa3d60a6b61390797f2d8a7e22e" name="a8583caa3d60a6b61390797f2d8a7e22e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8583caa3d60a6b61390797f2d8a7e22e">&#9670;&#160;</a></span>load()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.load </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>fname</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>mmap</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Load a previously saved object (using :meth:`~gensim.utils.SaveLoad.save`) from file.

Parameters
----------
fname : str
    Path to file that contains needed object.
mmap : str, optional
    Memory-map option.  If the object was saved with large arrays stored separately, you can load these arrays
    via mmap (shared memory) using `mmap='r'.
    If the file being loaded is compressed (either '.gz' or '.bz2'), then `mmap=None` **must be** set.

See Also
--------
:meth:`~gensim.utils.SaveLoad.save`

Returns
-------
object
    Object loaded from `fname`.

Raises
------
IOError
    When methods are called on instance (should be called from class).</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load.html#afdf30c017c94754b927bc74f6985c500">gensim.models.deprecated.old_saveload.SaveLoad</a>.</p>

<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext__wrapper_1_1_fast_text.html#acb634503d9eace29a5456cd070785dbe">gensim.models.deprecated.fasttext_wrapper.FastText</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1616</span>    <span class="keyword">def </span>load(cls, *args, **kwargs):</div>
<div class="line"><span class="lineno"> 1617</span>        model = super(Word2Vec, cls).load(*args, **kwargs)</div>
<div class="line"><span class="lineno"> 1618</span>        <span class="comment"># update older models</span></div>
<div class="line"><span class="lineno"> 1619</span>        <span class="keywordflow">if</span> hasattr(model, <span class="stringliteral">&#39;table&#39;</span>):</div>
<div class="line"><span class="lineno"> 1620</span>            delattr(model, <span class="stringliteral">&#39;table&#39;</span>)  <span class="comment"># discard in favor of cum_table</span></div>
<div class="line"><span class="lineno"> 1621</span>        <span class="keywordflow">if</span> model.negative <span class="keywordflow">and</span> hasattr(model.wv, <span class="stringliteral">&#39;index2word&#39;</span>):</div>
<div class="line"><span class="lineno"> 1622</span>            model.make_cum_table()  <span class="comment"># rebuild cum_table from vocabulary</span></div>
<div class="line"><span class="lineno"> 1623</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(model, <span class="stringliteral">&#39;corpus_count&#39;</span>):</div>
<div class="line"><span class="lineno"> 1624</span>            model.corpus_count = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1625</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(model, <span class="stringliteral">&#39;corpus_total_words&#39;</span>):</div>
<div class="line"><span class="lineno"> 1626</span>            model.corpus_total_words = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1627</span>        <span class="keywordflow">for</span> v <span class="keywordflow">in</span> model.wv.vocab.values():</div>
<div class="line"><span class="lineno"> 1628</span>            <span class="keywordflow">if</span> hasattr(v, <span class="stringliteral">&#39;sample_int&#39;</span>):</div>
<div class="line"><span class="lineno"> 1629</span>                <span class="keywordflow">break</span>  <span class="comment"># already 0.12.0+ style int probabilities</span></div>
<div class="line"><span class="lineno"> 1630</span>            <span class="keywordflow">elif</span> hasattr(v, <span class="stringliteral">&#39;sample_probability&#39;</span>):</div>
<div class="line"><span class="lineno"> 1631</span>                v.sample_int = int(round(v.sample_probability * 2**32))</div>
<div class="line"><span class="lineno"> 1632</span>                del v.sample_probability</div>
<div class="line"><span class="lineno"> 1633</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(model, <span class="stringliteral">&#39;syn0_lockf&#39;</span>) <span class="keywordflow">and</span> hasattr(model, <span class="stringliteral">&#39;syn0&#39;</span>):</div>
<div class="line"><span class="lineno"> 1634</span>            model.syn0_lockf = ones(len(model.wv.syn0), dtype=REAL)</div>
<div class="line"><span class="lineno"> 1635</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(model, <span class="stringliteral">&#39;random&#39;</span>):</div>
<div class="line"><span class="lineno"> 1636</span>            model.random = random.RandomState(model.seed)</div>
<div class="line"><span class="lineno"> 1637</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(model, <span class="stringliteral">&#39;train_count&#39;</span>):</div>
<div class="line"><span class="lineno"> 1638</span>            model.train_count = 0</div>
<div class="line"><span class="lineno"> 1639</span>            model.total_train_time = 0</div>
<div class="line"><span class="lineno"> 1640</span>        <span class="keywordflow">return</span> model</div>
<div class="line"><span class="lineno"> 1641</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9c5ee55d8e2236035a7aae64a71c356d" name="a9c5ee55d8e2236035a7aae64a71c356d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c5ee55d8e2236035a7aae64a71c356d">&#9670;&#160;</a></span>load_word2vec_format()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.load_word2vec_format </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fname</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fvocab</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>binary</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>encoding</em> = <code>'utf8'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>unicode_errors</em> = <code>'strict'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>limit</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>datatype</em> = <code>REAL</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use gensim.models.KeyedVectors.load_word2vec_format instead.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1655</span>                         limit=<span class="keywordtype">None</span>, datatype=REAL):</div>
<div class="line"><span class="lineno"> 1656</span>        <span class="stringliteral">&quot;&quot;&quot;Deprecated. Use gensim.models.KeyedVectors.load_word2vec_format instead.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1657</span>        <span class="keywordflow">raise</span> DeprecationWarning(<span class="stringliteral">&quot;Deprecated. Use gensim.models.KeyedVectors.load_word2vec_format instead.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1658</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa0a2b258d0a467cb656d29dfcc2055b9" name="aa0a2b258d0a467cb656d29dfcc2055b9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0a2b258d0a467cb656d29dfcc2055b9">&#9670;&#160;</a></span>log_accuracy()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.log_accuracy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>section</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno"> 1553</span>    <span class="keyword">def </span>log_accuracy(section):</div>
<div class="line"><span class="lineno"> 1554</span>        <span class="keywordflow">return</span> KeyedVectors.log_accuracy(section)</div>
<div class="line"><span class="lineno"> 1555</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a153458f09ea85c30547622f3f8c975fd" name="a153458f09ea85c30547622f3f8c975fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a153458f09ea85c30547622f3f8c975fd">&#9670;&#160;</a></span>log_evaluate_word_pairs()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.log_evaluate_word_pairs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pearson</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>spearman</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>oov</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pairs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.log_evaluate_word_pairs() instead.
Refer to the documentation for `gensim.models.KeyedVectors.log_evaluate_word_pairs`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1561</span>    <span class="keyword">def </span>log_evaluate_word_pairs(pearson, spearman, oov, pairs):</div>
<div class="line"><span class="lineno"> 1562</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1563</span><span class="stringliteral">        Deprecated. Use self.wv.log_evaluate_word_pairs() instead.</span></div>
<div class="line"><span class="lineno"> 1564</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.log_evaluate_word_pairs`</span></div>
<div class="line"><span class="lineno"> 1565</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1566</span>        <span class="keywordflow">return</span> KeyedVectors.log_evaluate_word_pairs(pearson, spearman, oov, pairs)</div>
<div class="line"><span class="lineno"> 1567</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a730365e47b7d5b5920d5e46e165a93cf" name="a730365e47b7d5b5920d5e46e165a93cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a730365e47b7d5b5920d5e46e165a93cf">&#9670;&#160;</a></span>make_cum_table()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.make_cum_table </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>power</em> = <code>0.75</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>domain</em> = <code>2**31&#160;-&#160;1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Create a cumulative-distribution table using stored vocabulary word counts for
drawing random words in the negative-sampling training routines.

To draw a word index, choose a random integer up to the maximum value in the
table (cum_table[-1]), then finding that integer's sorted insertion point
(as if by bisect_left or ndarray.searchsorted()). That insertion point is the
drawn index, coming up in proportion equal to the increment at that slot.

Called internally from 'build_vocab()'.
</pre> <div class="fragment"><div class="line"><span class="lineno">  637</span>    <span class="keyword">def </span>make_cum_table(self, power=0.75, domain=2**31 - 1):</div>
<div class="line"><span class="lineno">  638</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  639</span><span class="stringliteral">        Create a cumulative-distribution table using stored vocabulary word counts for</span></div>
<div class="line"><span class="lineno">  640</span><span class="stringliteral">        drawing random words in the negative-sampling training routines.</span></div>
<div class="line"><span class="lineno">  641</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  642</span><span class="stringliteral">        To draw a word index, choose a random integer up to the maximum value in the</span></div>
<div class="line"><span class="lineno">  643</span><span class="stringliteral">        table (cum_table[-1]), then finding that integer&#39;s sorted insertion point</span></div>
<div class="line"><span class="lineno">  644</span><span class="stringliteral">        (as if by bisect_left or ndarray.searchsorted()). That insertion point is the</span></div>
<div class="line"><span class="lineno">  645</span><span class="stringliteral">        drawn index, coming up in proportion equal to the increment at that slot.</span></div>
<div class="line"><span class="lineno">  646</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  647</span><span class="stringliteral">        Called internally from &#39;build_vocab()&#39;.</span></div>
<div class="line"><span class="lineno">  648</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  649</span>        vocab_size = len(self.wv.index2word)</div>
<div class="line"><span class="lineno">  650</span>        self.cum_table = zeros(vocab_size, dtype=uint32)</div>
<div class="line"><span class="lineno">  651</span>        <span class="comment"># compute sum of all power (Z in paper)</span></div>
<div class="line"><span class="lineno">  652</span>        train_words_pow = 0.0</div>
<div class="line"><span class="lineno">  653</span>        <span class="keywordflow">for</span> word_index <span class="keywordflow">in</span> range(vocab_size):</div>
<div class="line"><span class="lineno">  654</span>            train_words_pow += self.wv.vocab[self.wv.index2word[word_index]].count**power</div>
<div class="line"><span class="lineno">  655</span>        cumulative = 0.0</div>
<div class="line"><span class="lineno">  656</span>        <span class="keywordflow">for</span> word_index <span class="keywordflow">in</span> range(vocab_size):</div>
<div class="line"><span class="lineno">  657</span>            cumulative += self.wv.vocab[self.wv.index2word[word_index]].count**power</div>
<div class="line"><span class="lineno">  658</span>            self.cum_table[word_index] = round(cumulative / train_words_pow * domain)</div>
<div class="line"><span class="lineno">  659</span>        <span class="keywordflow">if</span> len(self.cum_table) &gt; 0:</div>
<div class="line"><span class="lineno">  660</span>            <span class="keyword">assert</span> self.cum_table[-1] == domain</div>
<div class="line"><span class="lineno">  661</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0db4b18dd564a599c7b6a053a48b9833" name="a0db4b18dd564a599c7b6a053a48b9833"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0db4b18dd564a599c7b6a053a48b9833">&#9670;&#160;</a></span>most_similar()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.most_similar </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>positive</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>negative</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>topn</em> = <code>10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>restrict_vocab</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>indexer</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.most_similar() instead.
Refer to the documentation for `gensim.models.KeyedVectors.most_similar`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1427</span>    <span class="keyword">def </span>most_similar(self, positive=None, negative=None, topn=10, restrict_vocab=None, indexer=None):</div>
<div class="line"><span class="lineno"> 1428</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1429</span><span class="stringliteral">        Deprecated. Use self.wv.most_similar() instead.</span></div>
<div class="line"><span class="lineno"> 1430</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.most_similar`</span></div>
<div class="line"><span class="lineno"> 1431</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1432</span>        <span class="keywordflow">return</span> self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)</div>
<div class="line"><span class="lineno"> 1433</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9c36b062b6091bdf5d08b7af9da0c99b" name="a9c36b062b6091bdf5d08b7af9da0c99b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c36b062b6091bdf5d08b7af9da0c99b">&#9670;&#160;</a></span>most_similar_cosmul()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.most_similar_cosmul </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>positive</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>negative</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>topn</em> = <code>10</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.most_similar_cosmul() instead.
Refer to the documentation for `gensim.models.KeyedVectors.most_similar_cosmul`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1441</span>    <span class="keyword">def </span>most_similar_cosmul(self, positive=None, negative=None, topn=10):</div>
<div class="line"><span class="lineno"> 1442</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1443</span><span class="stringliteral">        Deprecated. Use self.wv.most_similar_cosmul() instead.</span></div>
<div class="line"><span class="lineno"> 1444</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.most_similar_cosmul`</span></div>
<div class="line"><span class="lineno"> 1445</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1446</span>        <span class="keywordflow">return</span> self.wv.most_similar_cosmul(positive, negative, topn)</div>
<div class="line"><span class="lineno"> 1447</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aeec149756fb8bfc7a5b17ca2d1a4412d" name="aeec149756fb8bfc7a5b17ca2d1a4412d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeec149756fb8bfc7a5b17ca2d1a4412d">&#9670;&#160;</a></span>n_similarity()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.n_similarity </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ws1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ws2</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.n_similarity() instead.
Refer to the documentation for `gensim.models.KeyedVectors.n_similarity`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1490</span>    <span class="keyword">def </span>n_similarity(self, ws1, ws2):</div>
<div class="line"><span class="lineno"> 1491</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1492</span><span class="stringliteral">        Deprecated. Use self.wv.n_similarity() instead.</span></div>
<div class="line"><span class="lineno"> 1493</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.n_similarity`</span></div>
<div class="line"><span class="lineno"> 1494</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1495</span>        <span class="keywordflow">return</span> self.wv.n_similarity(ws1, ws2)</div>
<div class="line"><span class="lineno"> 1496</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4d5aac418f5ae000da72deffadda6dce" name="a4d5aac418f5ae000da72deffadda6dce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4d5aac418f5ae000da72deffadda6dce">&#9670;&#160;</a></span>predict_output_word()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.predict_output_word </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>context_words_list</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>topn</em> = <code>10</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Report the probability distribution of the center word given the context words
as input to the trained model.</pre> <div class="fragment"><div class="line"><span class="lineno"> 1497</span>    <span class="keyword">def </span>predict_output_word(self, context_words_list, topn=10):</div>
<div class="line"><span class="lineno"> 1498</span>        <span class="stringliteral">&quot;&quot;&quot;Report the probability distribution of the center word given the context words</span></div>
<div class="line"><span class="lineno"> 1499</span><span class="stringliteral">        as input to the trained model.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1500</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.negative:</div>
<div class="line"><span class="lineno"> 1501</span>            <span class="keywordflow">raise</span> RuntimeError(</div>
<div class="line"><span class="lineno"> 1502</span>                <span class="stringliteral">&quot;We have currently only implemented predict_output_word for the negative sampling scheme, &quot;</span></div>
<div class="line"><span class="lineno"> 1503</span>                <span class="stringliteral">&quot;so you need to have run word2vec with negative &gt; 0 for this to work.&quot;</span></div>
<div class="line"><span class="lineno"> 1504</span>            )</div>
<div class="line"><span class="lineno"> 1505</span> </div>
<div class="line"><span class="lineno"> 1506</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(self.wv, <span class="stringliteral">&#39;syn0&#39;</span>) <span class="keywordflow">or</span> <span class="keywordflow">not</span> hasattr(self, <span class="stringliteral">&#39;syn1neg&#39;</span>):</div>
<div class="line"><span class="lineno"> 1507</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;Parameters required for predicting the output words not found.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1508</span> </div>
<div class="line"><span class="lineno"> 1509</span>        word_vocabs = [self.wv.vocab[w] <span class="keywordflow">for</span> w <span class="keywordflow">in</span> context_words_list <span class="keywordflow">if</span> w <span class="keywordflow">in</span> self.wv.vocab]</div>
<div class="line"><span class="lineno"> 1510</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> word_vocabs:</div>
<div class="line"><span class="lineno"> 1511</span>            warnings.warn(<span class="stringliteral">&quot;All the input context words are out-of-vocabulary for the current model.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1512</span>            <span class="keywordflow">return</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1513</span> </div>
<div class="line"><span class="lineno"> 1514</span>        word2_indices = [word.index <span class="keywordflow">for</span> word <span class="keywordflow">in</span> word_vocabs]</div>
<div class="line"><span class="lineno"> 1515</span> </div>
<div class="line"><span class="lineno"> 1516</span>        l1 = np_sum(self.wv.syn0[word2_indices], axis=0)</div>
<div class="line"><span class="lineno"> 1517</span>        <span class="keywordflow">if</span> word2_indices <span class="keywordflow">and</span> self.cbow_mean:</div>
<div class="line"><span class="lineno"> 1518</span>            l1 /= len(word2_indices)</div>
<div class="line"><span class="lineno"> 1519</span> </div>
<div class="line"><span class="lineno"> 1520</span>        prob_values = exp(dot(l1, self.syn1neg.T))  <span class="comment"># propagate hidden -&gt; output and take softmax to get probabilities</span></div>
<div class="line"><span class="lineno"> 1521</span>        prob_values /= sum(prob_values)</div>
<div class="line"><span class="lineno"> 1522</span>        top_indices = matutils.argsort(prob_values, topn=topn, reverse=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno"> 1523</span>        <span class="comment"># returning the most probable output words with their probabilities</span></div>
<div class="line"><span class="lineno"> 1524</span>        <span class="keywordflow">return</span> [(self.wv.index2word[index1], prob_values[index1]) <span class="keywordflow">for</span> index1 <span class="keywordflow">in</span> top_indices]</div>
<div class="line"><span class="lineno"> 1525</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a403dda4524ed2fe4ebd0b8f667d3c137" name="a403dda4524ed2fe4ebd0b8f667d3c137"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a403dda4524ed2fe4ebd0b8f667d3c137">&#9670;&#160;</a></span>reset_from()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.reset_from </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>other_model</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Borrow shareable pre-built structures (like vocab) from the other_model. Useful
if testing multiple models in parallel on the same corpus.
</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#a6774f705e520972908bd97aa6d1b6629">gensim.models.deprecated.doc2vec.Doc2Vec</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  955</span>    <span class="keyword">def </span>reset_from(self, other_model):</div>
<div class="line"><span class="lineno">  956</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  957</span><span class="stringliteral">        Borrow shareable pre-built structures (like vocab) from the other_model. Useful</span></div>
<div class="line"><span class="lineno">  958</span><span class="stringliteral">        if testing multiple models in parallel on the same corpus.</span></div>
<div class="line"><span class="lineno">  959</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  960</span>        self.wv.vocab = other_model.wv.vocab</div>
<div class="line"><span class="lineno">  961</span>        self.wv.index2word = other_model.wv.index2word</div>
<div class="line"><span class="lineno">  962</span>        self.cum_table = other_model.cum_table</div>
<div class="line"><span class="lineno">  963</span>        self.corpus_count = other_model.corpus_count</div>
<div class="line"><span class="lineno">  964</span>        self.reset_weights()</div>
<div class="line"><span class="lineno">  965</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afeec0020070ee92f12b5cb034fa3ef1c" name="afeec0020070ee92f12b5cb034fa3ef1c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afeec0020070ee92f12b5cb034fa3ef1c">&#9670;&#160;</a></span>reset_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.reset_weights </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Reset all projection weights to an initial (untrained) state, but keep the existing vocabulary.</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#affd0d4c12e13f83618351da1fbe9bfc2">gensim.models.deprecated.doc2vec.Doc2Vec</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1355</span>    <span class="keyword">def </span>reset_weights(self):</div>
<div class="line"><span class="lineno"> 1356</span>        <span class="stringliteral">&quot;&quot;&quot;Reset all projection weights to an initial (untrained) state, but keep the existing vocabulary.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1357</span>        logger.info(<span class="stringliteral">&quot;resetting layer weights&quot;</span>)</div>
<div class="line"><span class="lineno"> 1358</span>        self.wv.syn0 = empty((len(self.wv.vocab), self.vector_size), dtype=REAL)</div>
<div class="line"><span class="lineno"> 1359</span>        <span class="comment"># randomize weights vector by vector, rather than materializing a huge random matrix in RAM at once</span></div>
<div class="line"><span class="lineno"> 1360</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(self.wv.vocab)):</div>
<div class="line"><span class="lineno"> 1361</span>            <span class="comment"># construct deterministic seed from word AND seed argument</span></div>
<div class="line"><span class="lineno"> 1362</span>            self.wv.syn0[i] = self.seeded_vector(self.wv.index2word[i] + str(self.seed))</div>
<div class="line"><span class="lineno"> 1363</span>        <span class="keywordflow">if</span> self.hs:</div>
<div class="line"><span class="lineno"> 1364</span>            self.syn1 = zeros((len(self.wv.vocab), self.layer1_size), dtype=REAL)</div>
<div class="line"><span class="lineno"> 1365</span>        <span class="keywordflow">if</span> self.negative:</div>
<div class="line"><span class="lineno"> 1366</span>            self.syn1neg = zeros((len(self.wv.vocab), self.layer1_size), dtype=REAL)</div>
<div class="line"><span class="lineno"> 1367</span>        self.wv.syn0norm = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1368</span> </div>
<div class="line"><span class="lineno"> 1369</span>        self.syn0_lockf = ones(len(self.wv.vocab), dtype=REAL)  <span class="comment"># zeros suppress learning</span></div>
<div class="line"><span class="lineno"> 1370</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="adefc32ee1839e2493a273ade54056bcc" name="adefc32ee1839e2493a273ade54056bcc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adefc32ee1839e2493a273ade54056bcc">&#9670;&#160;</a></span>save()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.save </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>fname_or_handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>separately</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Save the object to file.

Parameters
----------
fname_or_handle : str or file-like
    Path to output file or already opened file-like object. If the object is a file handle,
    no special array handling will be performed, all attributes will be saved to the same file.
separately : list of str or None, optional
    If None -  automatically detect large numpy/scipy.sparse arrays in the object being stored, and store
    them into separate files. This avoids pickle memory errors and allows mmap'ing large arrays
    back on load efficiently.
    If list of str - this attributes will be stored in separate files, the automatic check
    is not performed in this case.
sep_limit : int
    Limit for automatic separation.
ignore : frozenset of str
    Attributes that shouldn't be serialize/store.
pickle_protocol : int
    Protocol number for pickle.

See Also
--------
:meth:`~gensim.utils.SaveLoad.load`</pre> 
<p>Reimplemented from <a class="el" href="classgensim_1_1models_1_1deprecated_1_1old__saveload_1_1_save_load.html#a2148ec8529f86755a637070c910c0276">gensim.models.deprecated.old_saveload.SaveLoad</a>.</p>

<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext_1_1_fast_text.html#a2a93769e47da3d1cd34868f5cc8e51ab">gensim.models.deprecated.fasttext.FastText</a>, and <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext__wrapper_1_1_fast_text.html#ada94395bc26222dd24e42ca55d652d86">gensim.models.deprecated.fasttext_wrapper.FastText</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1607</span>    <span class="keyword">def </span>save(self, *args, **kwargs):</div>
<div class="line"><span class="lineno"> 1608</span>        <span class="comment"># don&#39;t bother storing the cached normalized vectors, recalculable table</span></div>
<div class="line"><span class="lineno"> 1609</span>        kwargs[<span class="stringliteral">&#39;ignore&#39;</span>] = kwargs.get(<span class="stringliteral">&#39;ignore&#39;</span>, [<span class="stringliteral">&#39;syn0norm&#39;</span>, <span class="stringliteral">&#39;table&#39;</span>, <span class="stringliteral">&#39;cum_table&#39;</span>])</div>
<div class="line"><span class="lineno"> 1610</span> </div>
<div class="line"><span class="lineno"> 1611</span>        super(Word2Vec, self).save(*args, **kwargs)</div>
<div class="line"><span class="lineno"> 1612</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a7f167a500ca1147e950c0dc19600399e" name="a7f167a500ca1147e950c0dc19600399e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7f167a500ca1147e950c0dc19600399e">&#9670;&#160;</a></span>save_word2vec_format()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.save_word2vec_format </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fname</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fvocab</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>binary</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use model.wv.save_word2vec_format instead.</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#a5e4dd2c973a198318fdee0bbcaa84cc7">gensim.models.deprecated.doc2vec.Doc2Vec</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1659</span>    <span class="keyword">def </span>save_word2vec_format(self, fname, fvocab=None, binary=False):</div>
<div class="line"><span class="lineno"> 1660</span>        <span class="stringliteral">&quot;&quot;&quot;Deprecated. Use model.wv.save_word2vec_format instead.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1661</span>        <span class="keywordflow">raise</span> DeprecationWarning(<span class="stringliteral">&quot;Deprecated. Use model.wv.save_word2vec_format instead.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1662</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a203a669c4c0194ad70b207c0f12244cd" name="a203a669c4c0194ad70b207c0f12244cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a203a669c4c0194ad70b207c0f12244cd">&#9670;&#160;</a></span>scale_vocab()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.scale_vocab </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_count</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dry_run</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>keep_raw_vocab</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>trim_rule</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>update</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Apply vocabulary settings for `min_count` (discarding less-frequent words)
and `sample` (controlling the downsampling of more-frequent words).

Calling with `dry_run=True` will only simulate the provided settings and
report the size of the retained vocabulary, effective corpus length, and
estimated memory requirements. Results are both printed via logging and
returned as a dict.

Delete the raw vocabulary after the scaling is done to free up RAM,
unless `keep_raw_vocab` is set.</pre> <div class="fragment"><div class="line"><span class="lineno">  797</span>                    keep_raw_vocab=<span class="keyword">False</span>, trim_rule=<span class="keywordtype">None</span>, update=<span class="keyword">False</span>):</div>
<div class="line"><span class="lineno">  798</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  799</span><span class="stringliteral">        Apply vocabulary settings for `min_count` (discarding less-frequent words)</span></div>
<div class="line"><span class="lineno">  800</span><span class="stringliteral">        and `sample` (controlling the downsampling of more-frequent words).</span></div>
<div class="line"><span class="lineno">  801</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  802</span><span class="stringliteral">        Calling with `dry_run=True` will only simulate the provided settings and</span></div>
<div class="line"><span class="lineno">  803</span><span class="stringliteral">        report the size of the retained vocabulary, effective corpus length, and</span></div>
<div class="line"><span class="lineno">  804</span><span class="stringliteral">        estimated memory requirements. Results are both printed via logging and</span></div>
<div class="line"><span class="lineno">  805</span><span class="stringliteral">        returned as a dict.</span></div>
<div class="line"><span class="lineno">  806</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  807</span><span class="stringliteral">        Delete the raw vocabulary after the scaling is done to free up RAM,</span></div>
<div class="line"><span class="lineno">  808</span><span class="stringliteral">        unless `keep_raw_vocab` is set.</span></div>
<div class="line"><span class="lineno">  809</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  810</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  811</span>        min_count = min_count <span class="keywordflow">or</span> self.min_count</div>
<div class="line"><span class="lineno">  812</span>        sample = sample <span class="keywordflow">or</span> self.sample</div>
<div class="line"><span class="lineno">  813</span>        drop_total = drop_unique = 0</div>
<div class="line"><span class="lineno">  814</span> </div>
<div class="line"><span class="lineno">  815</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> update:</div>
<div class="line"><span class="lineno">  816</span>            logger.info(<span class="stringliteral">&quot;Loading a fresh vocabulary&quot;</span>)</div>
<div class="line"><span class="lineno">  817</span>            retain_total, retain_words = 0, []</div>
<div class="line"><span class="lineno">  818</span>            <span class="comment"># Discard words less-frequent than min_count</span></div>
<div class="line"><span class="lineno">  819</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> dry_run:</div>
<div class="line"><span class="lineno">  820</span>                self.wv.index2word = []</div>
<div class="line"><span class="lineno">  821</span>                <span class="comment"># make stored settings match these applied settings</span></div>
<div class="line"><span class="lineno">  822</span>                self.min_count = min_count</div>
<div class="line"><span class="lineno">  823</span>                self.sample = sample</div>
<div class="line"><span class="lineno">  824</span>                self.wv.vocab = {}</div>
<div class="line"><span class="lineno">  825</span> </div>
<div class="line"><span class="lineno">  826</span>            <span class="keywordflow">for</span> word, v <span class="keywordflow">in</span> iteritems(self.raw_vocab):</div>
<div class="line"><span class="lineno">  827</span>                <span class="keywordflow">if</span> keep_vocab_item(word, v, min_count, trim_rule=trim_rule):</div>
<div class="line"><span class="lineno">  828</span>                    retain_words.append(word)</div>
<div class="line"><span class="lineno">  829</span>                    retain_total += v</div>
<div class="line"><span class="lineno">  830</span>                    <span class="keywordflow">if</span> <span class="keywordflow">not</span> dry_run:</div>
<div class="line"><span class="lineno">  831</span>                        self.wv.vocab[word] = Vocab(count=v, index=len(self.wv.index2word))</div>
<div class="line"><span class="lineno">  832</span>                        self.wv.index2word.append(word)</div>
<div class="line"><span class="lineno">  833</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  834</span>                    drop_unique += 1</div>
<div class="line"><span class="lineno">  835</span>                    drop_total += v</div>
<div class="line"><span class="lineno">  836</span>            original_unique_total = len(retain_words) + drop_unique</div>
<div class="line"><span class="lineno">  837</span>            retain_unique_pct = len(retain_words) * 100 / max(original_unique_total, 1)</div>
<div class="line"><span class="lineno">  838</span>            logger.info(</div>
<div class="line"><span class="lineno">  839</span>                <span class="stringliteral">&quot;min_count=%d retains %i unique words (%i%% of original %i, drops %i)&quot;</span>,</div>
<div class="line"><span class="lineno">  840</span>                min_count, len(retain_words), retain_unique_pct, original_unique_total, drop_unique</div>
<div class="line"><span class="lineno">  841</span>            )</div>
<div class="line"><span class="lineno">  842</span>            original_total = retain_total + drop_total</div>
<div class="line"><span class="lineno">  843</span>            retain_pct = retain_total * 100 / max(original_total, 1)</div>
<div class="line"><span class="lineno">  844</span>            logger.info(</div>
<div class="line"><span class="lineno">  845</span>                <span class="stringliteral">&quot;min_count=%d leaves %i word corpus (%i%% of original %i, drops %i)&quot;</span>,</div>
<div class="line"><span class="lineno">  846</span>                min_count, retain_total, retain_pct, original_total, drop_total</div>
<div class="line"><span class="lineno">  847</span>            )</div>
<div class="line"><span class="lineno">  848</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  849</span>            logger.info(<span class="stringliteral">&quot;Updating model with new vocabulary&quot;</span>)</div>
<div class="line"><span class="lineno">  850</span>            new_total = pre_exist_total = 0</div>
<div class="line"><span class="lineno">  851</span>            new_words = pre_exist_words = []</div>
<div class="line"><span class="lineno">  852</span>            <span class="keywordflow">for</span> word, v <span class="keywordflow">in</span> iteritems(self.raw_vocab):</div>
<div class="line"><span class="lineno">  853</span>                <span class="keywordflow">if</span> keep_vocab_item(word, v, min_count, trim_rule=trim_rule):</div>
<div class="line"><span class="lineno">  854</span>                    <span class="keywordflow">if</span> word <span class="keywordflow">in</span> self.wv.vocab:</div>
<div class="line"><span class="lineno">  855</span>                        pre_exist_words.append(word)</div>
<div class="line"><span class="lineno">  856</span>                        pre_exist_total += v</div>
<div class="line"><span class="lineno">  857</span>                        <span class="keywordflow">if</span> <span class="keywordflow">not</span> dry_run:</div>
<div class="line"><span class="lineno">  858</span>                            self.wv.vocab[word].count += v</div>
<div class="line"><span class="lineno">  859</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  860</span>                        new_words.append(word)</div>
<div class="line"><span class="lineno">  861</span>                        new_total += v</div>
<div class="line"><span class="lineno">  862</span>                        <span class="keywordflow">if</span> <span class="keywordflow">not</span> dry_run:</div>
<div class="line"><span class="lineno">  863</span>                            self.wv.vocab[word] = Vocab(count=v, index=len(self.wv.index2word))</div>
<div class="line"><span class="lineno">  864</span>                            self.wv.index2word.append(word)</div>
<div class="line"><span class="lineno">  865</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  866</span>                    drop_unique += 1</div>
<div class="line"><span class="lineno">  867</span>                    drop_total += v</div>
<div class="line"><span class="lineno">  868</span>            original_unique_total = len(pre_exist_words) + len(new_words) + drop_unique</div>
<div class="line"><span class="lineno">  869</span>            pre_exist_unique_pct = len(pre_exist_words) * 100 / max(original_unique_total, 1)</div>
<div class="line"><span class="lineno">  870</span>            new_unique_pct = len(new_words) * 100 / max(original_unique_total, 1)</div>
<div class="line"><span class="lineno">  871</span>            logger.info(</div>
<div class="line"><span class="lineno">  872</span>                <span class="stringliteral">&quot;New added %i unique words (%i%% of original %i) &quot;</span></div>
<div class="line"><span class="lineno">  873</span>                <span class="stringliteral">&quot;and increased the count of %i pre-existing words (%i%% of original %i)&quot;</span>,</div>
<div class="line"><span class="lineno">  874</span>                len(new_words), new_unique_pct, original_unique_total, len(pre_exist_words),</div>
<div class="line"><span class="lineno">  875</span>                pre_exist_unique_pct, original_unique_total</div>
<div class="line"><span class="lineno">  876</span>            )</div>
<div class="line"><span class="lineno">  877</span>            retain_words = new_words + pre_exist_words</div>
<div class="line"><span class="lineno">  878</span>            retain_total = new_total + pre_exist_total</div>
<div class="line"><span class="lineno">  879</span> </div>
<div class="line"><span class="lineno">  880</span>        <span class="comment"># Precalculate each vocabulary item&#39;s threshold for sampling</span></div>
<div class="line"><span class="lineno">  881</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> sample:</div>
<div class="line"><span class="lineno">  882</span>            <span class="comment"># no words downsampled</span></div>
<div class="line"><span class="lineno">  883</span>            threshold_count = retain_total</div>
<div class="line"><span class="lineno">  884</span>        <span class="keywordflow">elif</span> sample &lt; 1.0:</div>
<div class="line"><span class="lineno">  885</span>            <span class="comment"># traditional meaning: set parameter as proportion of total</span></div>
<div class="line"><span class="lineno">  886</span>            threshold_count = sample * retain_total</div>
<div class="line"><span class="lineno">  887</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  888</span>            <span class="comment"># new shorthand: sample &gt;= 1 means downsample all words with higher count than sample</span></div>
<div class="line"><span class="lineno">  889</span>            threshold_count = int(sample * (3 + sqrt(5)) / 2)</div>
<div class="line"><span class="lineno">  890</span> </div>
<div class="line"><span class="lineno">  891</span>        downsample_total, downsample_unique = 0, 0</div>
<div class="line"><span class="lineno">  892</span>        <span class="keywordflow">for</span> w <span class="keywordflow">in</span> retain_words:</div>
<div class="line"><span class="lineno">  893</span>            v = self.raw_vocab[w]</div>
<div class="line"><span class="lineno">  894</span>            word_probability = (sqrt(v / threshold_count) + 1) * (threshold_count / v)</div>
<div class="line"><span class="lineno">  895</span>            <span class="keywordflow">if</span> word_probability &lt; 1.0:</div>
<div class="line"><span class="lineno">  896</span>                downsample_unique += 1</div>
<div class="line"><span class="lineno">  897</span>                downsample_total += word_probability * v</div>
<div class="line"><span class="lineno">  898</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  899</span>                word_probability = 1.0</div>
<div class="line"><span class="lineno">  900</span>                downsample_total += v</div>
<div class="line"><span class="lineno">  901</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> dry_run:</div>
<div class="line"><span class="lineno">  902</span>                self.wv.vocab[w].sample_int = int(round(word_probability * 2**32))</div>
<div class="line"><span class="lineno">  903</span> </div>
<div class="line"><span class="lineno">  904</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> dry_run <span class="keywordflow">and</span> <span class="keywordflow">not</span> keep_raw_vocab:</div>
<div class="line"><span class="lineno">  905</span>            logger.info(<span class="stringliteral">&quot;deleting the raw counts dictionary of %i items&quot;</span>, len(self.raw_vocab))</div>
<div class="line"><span class="lineno">  906</span>            self.raw_vocab = defaultdict(int)</div>
<div class="line"><span class="lineno">  907</span> </div>
<div class="line"><span class="lineno">  908</span>        logger.info(<span class="stringliteral">&quot;sample=%g downsamples %i most-common words&quot;</span>, sample, downsample_unique)</div>
<div class="line"><span class="lineno">  909</span>        logger.info(</div>
<div class="line"><span class="lineno">  910</span>            <span class="stringliteral">&quot;downsampling leaves estimated %i word corpus (%.1f%% of prior %i)&quot;</span>,</div>
<div class="line"><span class="lineno">  911</span>            downsample_total, downsample_total * 100.0 / max(retain_total, 1), retain_total</div>
<div class="line"><span class="lineno">  912</span>        )</div>
<div class="line"><span class="lineno">  913</span> </div>
<div class="line"><span class="lineno">  914</span>        <span class="comment"># return from each step: words-affected, resulting-corpus-size, extra memory estimates</span></div>
<div class="line"><span class="lineno">  915</span>        report_values = {</div>
<div class="line"><span class="lineno">  916</span>            <span class="stringliteral">&#39;drop_unique&#39;</span>: drop_unique, <span class="stringliteral">&#39;retain_total&#39;</span>: retain_total, <span class="stringliteral">&#39;downsample_unique&#39;</span>: downsample_unique,</div>
<div class="line"><span class="lineno">  917</span>            <span class="stringliteral">&#39;downsample_total&#39;</span>: int(downsample_total), <span class="stringliteral">&#39;memory&#39;</span>: self.estimate_memory(vocab_size=len(retain_words))</div>
<div class="line"><span class="lineno">  918</span>        }</div>
<div class="line"><span class="lineno">  919</span> </div>
<div class="line"><span class="lineno">  920</span>        <span class="keywordflow">return</span> report_values</div>
<div class="line"><span class="lineno">  921</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ace7363a9f93585cb79053e9404fdfa55" name="ace7363a9f93585cb79053e9404fdfa55"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace7363a9f93585cb79053e9404fdfa55">&#9670;&#160;</a></span>scan_vocab()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.scan_vocab </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>progress_per</em> = <code>10000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>trim_rule</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Do an initial scan of all words appearing in sentences.</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html#ac1007926466907d409f2152ad3893905">gensim.models.deprecated.doc2vec.Doc2Vec</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  758</span>    <span class="keyword">def </span>scan_vocab(self, sentences, progress_per=10000, trim_rule=None):</div>
<div class="line"><span class="lineno">  759</span>        <span class="stringliteral">&quot;&quot;&quot;Do an initial scan of all words appearing in sentences.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  760</span>        logger.info(<span class="stringliteral">&quot;collecting all words and their counts&quot;</span>)</div>
<div class="line"><span class="lineno">  761</span>        sentence_no = -1</div>
<div class="line"><span class="lineno">  762</span>        total_words = 0</div>
<div class="line"><span class="lineno">  763</span>        min_reduce = 1</div>
<div class="line"><span class="lineno">  764</span>        vocab = defaultdict(int)</div>
<div class="line"><span class="lineno">  765</span>        checked_string_types = 0</div>
<div class="line"><span class="lineno">  766</span>        <span class="keywordflow">for</span> sentence_no, sentence <span class="keywordflow">in</span> enumerate(sentences):</div>
<div class="line"><span class="lineno">  767</span>            <span class="keywordflow">if</span> <span class="keywordflow">not</span> checked_string_types:</div>
<div class="line"><span class="lineno">  768</span>                <span class="keywordflow">if</span> isinstance(sentence, string_types):</div>
<div class="line"><span class="lineno">  769</span>                    logger.warning(</div>
<div class="line"><span class="lineno">  770</span>                        <span class="stringliteral">&quot;Each &#39;sentences&#39; item should be a list of words (usually unicode strings). &quot;</span></div>
<div class="line"><span class="lineno">  771</span>                        <span class="stringliteral">&quot;First item here is instead plain %s.&quot;</span>,</div>
<div class="line"><span class="lineno">  772</span>                        type(sentence)</div>
<div class="line"><span class="lineno">  773</span>                    )</div>
<div class="line"><span class="lineno">  774</span>                checked_string_types += 1</div>
<div class="line"><span class="lineno">  775</span>            <span class="keywordflow">if</span> sentence_no % progress_per == 0:</div>
<div class="line"><span class="lineno">  776</span>                logger.info(</div>
<div class="line"><span class="lineno">  777</span>                    <span class="stringliteral">&quot;PROGRESS: at sentence #%i, processed %i words, keeping %i word types&quot;</span>,</div>
<div class="line"><span class="lineno">  778</span>                    sentence_no, total_words, len(vocab)</div>
<div class="line"><span class="lineno">  779</span>                )</div>
<div class="line"><span class="lineno">  780</span>            <span class="keywordflow">for</span> word <span class="keywordflow">in</span> sentence:</div>
<div class="line"><span class="lineno">  781</span>                vocab[word] += 1</div>
<div class="line"><span class="lineno">  782</span>            total_words += len(sentence)</div>
<div class="line"><span class="lineno">  783</span> </div>
<div class="line"><span class="lineno">  784</span>            <span class="keywordflow">if</span> self.max_vocab_size <span class="keywordflow">and</span> len(vocab) &gt; self.max_vocab_size:</div>
<div class="line"><span class="lineno">  785</span>                utils.prune_vocab(vocab, min_reduce, trim_rule=trim_rule)</div>
<div class="line"><span class="lineno">  786</span>                min_reduce += 1</div>
<div class="line"><span class="lineno">  787</span> </div>
<div class="line"><span class="lineno">  788</span>        logger.info(</div>
<div class="line"><span class="lineno">  789</span>            <span class="stringliteral">&quot;collected %i word types from a corpus of %i raw words and %i sentences&quot;</span>,</div>
<div class="line"><span class="lineno">  790</span>            len(vocab), total_words, sentence_no + 1</div>
<div class="line"><span class="lineno">  791</span>        )</div>
<div class="line"><span class="lineno">  792</span>        self.corpus_count = sentence_no + 1</div>
<div class="line"><span class="lineno">  793</span>        self.raw_vocab = vocab</div>
<div class="line"><span class="lineno">  794</span>        <span class="keywordflow">return</span> total_words</div>
<div class="line"><span class="lineno">  795</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a46b237aaa31eafbc1d68910bc5703ea0" name="a46b237aaa31eafbc1d68910bc5703ea0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46b237aaa31eafbc1d68910bc5703ea0">&#9670;&#160;</a></span>score()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.score </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_sentences</em> = <code><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1word2vec.html#ad226751260da61bc5831d7c01f788543">int</a>(1e6)</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>chunksize</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>queue_factor</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>report_delay</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Score the log probability for a sequence of sentences (can be a once-only generator stream).
Each sentence must be a list of unicode strings.
This does not change the fitted model in any way (see Word2Vec.train() for that).

We have currently only implemented score for the hierarchical softmax scheme,
so you need to have run word2vec with hs=1 and negative=0 for this to work.

Note that you should specify total_sentences; we'll run into problems if you ask to
score more than this number of sentences but it is inefficient to set the value too high.

See the article by [#taddy]_ and the gensim demo at [#deepir]_ for examples of
how to use such scores in document classification.

.. [#taddy] Taddy, Matt.  Document Classification by Inversion of Distributed Language Representations,
            in Proceedings of the 2015 Conference of the Association of Computational Linguistics.
.. [#deepir] https://github.com/piskvorky/gensim/blob/develop/docs/notebooks/deepir.ipynb</pre> <div class="fragment"><div class="line"><span class="lineno"> 1199</span>    <span class="keyword">def </span>score(self, sentences, total_sentences=int(1e6), chunksize=100, queue_factor=2, report_delay=1):</div>
<div class="line"><span class="lineno"> 1200</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1201</span><span class="stringliteral">        Score the log probability for a sequence of sentences (can be a once-only generator stream).</span></div>
<div class="line"><span class="lineno"> 1202</span><span class="stringliteral">        Each sentence must be a list of unicode strings.</span></div>
<div class="line"><span class="lineno"> 1203</span><span class="stringliteral">        This does not change the fitted model in any way (see Word2Vec.train() for that).</span></div>
<div class="line"><span class="lineno"> 1204</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1205</span><span class="stringliteral">        We have currently only implemented score for the hierarchical softmax scheme,</span></div>
<div class="line"><span class="lineno"> 1206</span><span class="stringliteral">        so you need to have run word2vec with hs=1 and negative=0 for this to work.</span></div>
<div class="line"><span class="lineno"> 1207</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1208</span><span class="stringliteral">        Note that you should specify total_sentences; we&#39;ll run into problems if you ask to</span></div>
<div class="line"><span class="lineno"> 1209</span><span class="stringliteral">        score more than this number of sentences but it is inefficient to set the value too high.</span></div>
<div class="line"><span class="lineno"> 1210</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1211</span><span class="stringliteral">        See the article by [#taddy]_ and the gensim demo at [#deepir]_ for examples of</span></div>
<div class="line"><span class="lineno"> 1212</span><span class="stringliteral">        how to use such scores in document classification.</span></div>
<div class="line"><span class="lineno"> 1213</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1214</span><span class="stringliteral">        .. [#taddy] Taddy, Matt.  Document Classification by Inversion of Distributed Language Representations,</span></div>
<div class="line"><span class="lineno"> 1215</span><span class="stringliteral">                    in Proceedings of the 2015 Conference of the Association of Computational Linguistics.</span></div>
<div class="line"><span class="lineno"> 1216</span><span class="stringliteral">        .. [#deepir] https://github.com/piskvorky/gensim/blob/develop/docs/notebooks/deepir.ipynb</span></div>
<div class="line"><span class="lineno"> 1217</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1218</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1219</span>        logger.info(</div>
<div class="line"><span class="lineno"> 1220</span>            <span class="stringliteral">&quot;scoring sentences with %i workers on %i vocabulary and %i features, &quot;</span></div>
<div class="line"><span class="lineno"> 1221</span>            <span class="stringliteral">&quot;using sg=%s hs=%s sample=%s and negative=%s&quot;</span>,</div>
<div class="line"><span class="lineno"> 1222</span>            self.workers, len(self.wv.vocab), self.layer1_size, self.sg, self.hs, self.sample, self.negative</div>
<div class="line"><span class="lineno"> 1223</span>        )</div>
<div class="line"><span class="lineno"> 1224</span> </div>
<div class="line"><span class="lineno"> 1225</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.wv.vocab:</div>
<div class="line"><span class="lineno"> 1226</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;you must first build vocabulary before scoring new data&quot;</span>)</div>
<div class="line"><span class="lineno"> 1227</span> </div>
<div class="line"><span class="lineno"> 1228</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.hs:</div>
<div class="line"><span class="lineno"> 1229</span>            <span class="keywordflow">raise</span> RuntimeError(</div>
<div class="line"><span class="lineno"> 1230</span>                <span class="stringliteral">&quot;We have currently only implemented score for the hierarchical softmax scheme, &quot;</span></div>
<div class="line"><span class="lineno"> 1231</span>                <span class="stringliteral">&quot;so you need to have run word2vec with hs=1 and negative=0 for this to work.&quot;</span></div>
<div class="line"><span class="lineno"> 1232</span>            )</div>
<div class="line"><span class="lineno"> 1233</span> </div>
<div class="line"><span class="lineno"> 1234</span>        <span class="keyword">def </span>worker_loop():</div>
<div class="line"><span class="lineno"> 1235</span>            <span class="stringliteral">&quot;&quot;&quot;Compute log probability for each sentence, lifting lists of sentences from the jobs queue.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1236</span>            work = zeros(1, dtype=REAL)  <span class="comment"># for sg hs, we actually only need one memory loc (running sum)</span></div>
<div class="line"><span class="lineno"> 1237</span>            neu1 = matutils.zeros_aligned(self.layer1_size, dtype=REAL)</div>
<div class="line"><span class="lineno"> 1238</span>            <span class="keywordflow">while</span> <span class="keyword">True</span>:</div>
<div class="line"><span class="lineno"> 1239</span>                job = job_queue.get()</div>
<div class="line"><span class="lineno"> 1240</span>                <span class="keywordflow">if</span> job <span class="keywordflow">is</span> <span class="keywordtype">None</span>:  <span class="comment"># signal to finish</span></div>
<div class="line"><span class="lineno"> 1241</span>                    <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno"> 1242</span>                ns = 0</div>
<div class="line"><span class="lineno"> 1243</span>                <span class="keywordflow">for</span> sentence_id, sentence <span class="keywordflow">in</span> job:</div>
<div class="line"><span class="lineno"> 1244</span>                    <span class="keywordflow">if</span> sentence_id &gt;= total_sentences:</div>
<div class="line"><span class="lineno"> 1245</span>                        <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno"> 1246</span>                    <span class="keywordflow">if</span> self.sg:</div>
<div class="line"><span class="lineno"> 1247</span>                        score = score_sentence_sg(self, sentence, work)</div>
<div class="line"><span class="lineno"> 1248</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1249</span>                        score = score_sentence_cbow(self, sentence, work, neu1)</div>
<div class="line"><span class="lineno"> 1250</span>                    sentence_scores[sentence_id] = score</div>
<div class="line"><span class="lineno"> 1251</span>                    ns += 1</div>
<div class="line"><span class="lineno"> 1252</span>                progress_queue.put(ns)  <span class="comment"># report progress</span></div>
<div class="line"><span class="lineno"> 1253</span> </div>
<div class="line"><span class="lineno"> 1254</span>        start, next_report = default_timer(), 1.0</div>
<div class="line"><span class="lineno"> 1255</span>        <span class="comment"># buffer ahead only a limited number of jobs.. this is the reason we can&#39;t simply use ThreadPool :(</span></div>
<div class="line"><span class="lineno"> 1256</span>        job_queue = Queue(maxsize=queue_factor * self.workers)</div>
<div class="line"><span class="lineno"> 1257</span>        progress_queue = Queue(maxsize=(queue_factor + 1) * self.workers)</div>
<div class="line"><span class="lineno"> 1258</span> </div>
<div class="line"><span class="lineno"> 1259</span>        workers = [threading.Thread(target=worker_loop) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(self.workers)]</div>
<div class="line"><span class="lineno"> 1260</span>        <span class="keywordflow">for</span> thread <span class="keywordflow">in</span> workers:</div>
<div class="line"><span class="lineno"> 1261</span>            thread.daemon = <span class="keyword">True</span>  <span class="comment"># make interrupting the process with ctrl+c easier</span></div>
<div class="line"><span class="lineno"> 1262</span>            thread.start()</div>
<div class="line"><span class="lineno"> 1263</span> </div>
<div class="line"><span class="lineno"> 1264</span>        sentence_count = 0</div>
<div class="line"><span class="lineno"> 1265</span>        sentence_scores = matutils.zeros_aligned(total_sentences, dtype=REAL)</div>
<div class="line"><span class="lineno"> 1266</span> </div>
<div class="line"><span class="lineno"> 1267</span>        push_done = <span class="keyword">False</span></div>
<div class="line"><span class="lineno"> 1268</span>        done_jobs = 0</div>
<div class="line"><span class="lineno"> 1269</span>        jobs_source = enumerate(utils.grouper(enumerate(sentences), chunksize))</div>
<div class="line"><span class="lineno"> 1270</span> </div>
<div class="line"><span class="lineno"> 1271</span>        <span class="comment"># fill jobs queue with (id, sentence) job items</span></div>
<div class="line"><span class="lineno"> 1272</span>        <span class="keywordflow">while</span> <span class="keyword">True</span>:</div>
<div class="line"><span class="lineno"> 1273</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno"> 1274</span>                job_no, items = next(jobs_source)</div>
<div class="line"><span class="lineno"> 1275</span>                <span class="keywordflow">if</span> (job_no - 1) * chunksize &gt; total_sentences:</div>
<div class="line"><span class="lineno"> 1276</span>                    logger.warning(</div>
<div class="line"><span class="lineno"> 1277</span>                        <span class="stringliteral">&quot;terminating after %i sentences (set higher total_sentences if you want more).&quot;</span>,</div>
<div class="line"><span class="lineno"> 1278</span>                        total_sentences</div>
<div class="line"><span class="lineno"> 1279</span>                    )</div>
<div class="line"><span class="lineno"> 1280</span>                    job_no -= 1</div>
<div class="line"><span class="lineno"> 1281</span>                    <span class="keywordflow">raise</span> StopIteration()</div>
<div class="line"><span class="lineno"> 1282</span>                logger.debug(<span class="stringliteral">&quot;putting job #%i in the queue&quot;</span>, job_no)</div>
<div class="line"><span class="lineno"> 1283</span>                job_queue.put(items)</div>
<div class="line"><span class="lineno"> 1284</span>            <span class="keywordflow">except</span> StopIteration:</div>
<div class="line"><span class="lineno"> 1285</span>                logger.info(<span class="stringliteral">&quot;reached end of input; waiting to finish %i outstanding jobs&quot;</span>, job_no - done_jobs + 1)</div>
<div class="line"><span class="lineno"> 1286</span>                <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(self.workers):</div>
<div class="line"><span class="lineno"> 1287</span>                    job_queue.put(<span class="keywordtype">None</span>)  <span class="comment"># give the workers heads up that they can finish -- no more work!</span></div>
<div class="line"><span class="lineno"> 1288</span>                push_done = <span class="keyword">True</span></div>
<div class="line"><span class="lineno"> 1289</span>            <span class="keywordflow">try</span>:</div>
<div class="line"><span class="lineno"> 1290</span>                <span class="keywordflow">while</span> done_jobs &lt; (job_no + 1) <span class="keywordflow">or</span> <span class="keywordflow">not</span> push_done:</div>
<div class="line"><span class="lineno"> 1291</span>                    ns = progress_queue.get(push_done)  <span class="comment"># only block after all jobs pushed</span></div>
<div class="line"><span class="lineno"> 1292</span>                    sentence_count += ns</div>
<div class="line"><span class="lineno"> 1293</span>                    done_jobs += 1</div>
<div class="line"><span class="lineno"> 1294</span>                    elapsed = default_timer() - start</div>
<div class="line"><span class="lineno"> 1295</span>                    <span class="keywordflow">if</span> elapsed &gt;= next_report:</div>
<div class="line"><span class="lineno"> 1296</span>                        logger.info(</div>
<div class="line"><span class="lineno"> 1297</span>                            <span class="stringliteral">&quot;PROGRESS: at %.2f%% sentences, %.0f sentences/s&quot;</span>,</div>
<div class="line"><span class="lineno"> 1298</span>                            100.0 * sentence_count, sentence_count / elapsed</div>
<div class="line"><span class="lineno"> 1299</span>                        )</div>
<div class="line"><span class="lineno"> 1300</span>                        next_report = elapsed + report_delay  <span class="comment"># don&#39;t flood log, wait report_delay seconds</span></div>
<div class="line"><span class="lineno"> 1301</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1302</span>                    <span class="comment"># loop ended by job count; really done</span></div>
<div class="line"><span class="lineno"> 1303</span>                    <span class="keywordflow">break</span></div>
<div class="line"><span class="lineno"> 1304</span>            <span class="keywordflow">except</span> Empty:</div>
<div class="line"><span class="lineno"> 1305</span>                <span class="keywordflow">pass</span>  <span class="comment"># already out of loop; continue to next push</span></div>
<div class="line"><span class="lineno"> 1306</span> </div>
<div class="line"><span class="lineno"> 1307</span>        elapsed = default_timer() - start</div>
<div class="line"><span class="lineno"> 1308</span>        self.clear_sims()</div>
<div class="line"><span class="lineno"> 1309</span>        logger.info(</div>
<div class="line"><span class="lineno"> 1310</span>            <span class="stringliteral">&quot;scoring %i sentences took %.1fs, %.0f sentences/s&quot;</span>,</div>
<div class="line"><span class="lineno"> 1311</span>            sentence_count, elapsed, sentence_count / elapsed</div>
<div class="line"><span class="lineno"> 1312</span>        )</div>
<div class="line"><span class="lineno"> 1313</span>        <span class="keywordflow">return</span> sentence_scores[:sentence_count]</div>
<div class="line"><span class="lineno"> 1314</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ad34a45c9a14d1ef5e2aed2a559f2ab39" name="ad34a45c9a14d1ef5e2aed2a559f2ab39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad34a45c9a14d1ef5e2aed2a559f2ab39">&#9670;&#160;</a></span>seeded_vector()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.seeded_vector </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>seed_string</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Create one 'random' vector (but deterministic by seed_string)</pre> <div class="fragment"><div class="line"><span class="lineno"> 1371</span>    <span class="keyword">def </span>seeded_vector(self, seed_string):</div>
<div class="line"><span class="lineno"> 1372</span>        <span class="stringliteral">&quot;&quot;&quot;Create one &#39;random&#39; vector (but deterministic by seed_string)&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1373</span>        <span class="comment"># Note: built-in hash() may vary by Python version or even (in Py3.x) per launch</span></div>
<div class="line"><span class="lineno"> 1374</span>        once = random.RandomState(self.hashfxn(seed_string) &amp; 0xffffffff)</div>
<div class="line"><span class="lineno"> 1375</span>        <span class="keywordflow">return</span> (once.rand(self.vector_size) - 0.5) / self.vector_size</div>
<div class="line"><span class="lineno"> 1376</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a13c5163154358cc6b81db18dd290a23c" name="a13c5163154358cc6b81db18dd290a23c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a13c5163154358cc6b81db18dd290a23c">&#9670;&#160;</a></span>similar_by_vector()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.similar_by_vector </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vector</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>topn</em> = <code>10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>restrict_vocab</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.similar_by_vector() instead.
Refer to the documentation for `gensim.models.KeyedVectors.similar_by_vector`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1455</span>    <span class="keyword">def </span>similar_by_vector(self, vector, topn=10, restrict_vocab=None):</div>
<div class="line"><span class="lineno"> 1456</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1457</span><span class="stringliteral">        Deprecated. Use self.wv.similar_by_vector() instead.</span></div>
<div class="line"><span class="lineno"> 1458</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.similar_by_vector`</span></div>
<div class="line"><span class="lineno"> 1459</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1460</span>        <span class="keywordflow">return</span> self.wv.similar_by_vector(vector, topn, restrict_vocab)</div>
<div class="line"><span class="lineno"> 1461</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abc467f19c1596df5f236823c432a7ec0" name="abc467f19c1596df5f236823c432a7ec0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abc467f19c1596df5f236823c432a7ec0">&#9670;&#160;</a></span>similar_by_word()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.similar_by_word </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>topn</em> = <code>10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>restrict_vocab</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.similar_by_word() instead.
Refer to the documentation for `gensim.models.KeyedVectors.similar_by_word`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1448</span>    <span class="keyword">def </span>similar_by_word(self, word, topn=10, restrict_vocab=None):</div>
<div class="line"><span class="lineno"> 1449</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1450</span><span class="stringliteral">        Deprecated. Use self.wv.similar_by_word() instead.</span></div>
<div class="line"><span class="lineno"> 1451</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.similar_by_word`</span></div>
<div class="line"><span class="lineno"> 1452</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1453</span>        <span class="keywordflow">return</span> self.wv.similar_by_word(word, topn, restrict_vocab)</div>
<div class="line"><span class="lineno"> 1454</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a09e28d7ee12c14e57ff44ec00daca759" name="a09e28d7ee12c14e57ff44ec00daca759"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a09e28d7ee12c14e57ff44ec00daca759">&#9670;&#160;</a></span>similarity()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.similarity </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w2</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.similarity() instead.
Refer to the documentation for `gensim.models.KeyedVectors.similarity`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1483</span>    <span class="keyword">def </span>similarity(self, w1, w2):</div>
<div class="line"><span class="lineno"> 1484</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1485</span><span class="stringliteral">        Deprecated. Use self.wv.similarity() instead.</span></div>
<div class="line"><span class="lineno"> 1486</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.similarity`</span></div>
<div class="line"><span class="lineno"> 1487</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1488</span>        <span class="keywordflow">return</span> self.wv.similarity(w1, w2)</div>
<div class="line"><span class="lineno"> 1489</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a38cdd5a0f8b001b2ebebe8211a2945f2" name="a38cdd5a0f8b001b2ebebe8211a2945f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38cdd5a0f8b001b2ebebe8211a2945f2">&#9670;&#160;</a></span>sort_vocab()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.sort_vocab </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Sort the vocabulary so the most frequent words have the lowest indexes.</pre> <div class="fragment"><div class="line"><span class="lineno">  947</span>    <span class="keyword">def </span>sort_vocab(self):</div>
<div class="line"><span class="lineno">  948</span>        <span class="stringliteral">&quot;&quot;&quot;Sort the vocabulary so the most frequent words have the lowest indexes.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  949</span>        <span class="keywordflow">if</span> len(self.wv.syn0):</div>
<div class="line"><span class="lineno">  950</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;cannot sort vocabulary after model weights already initialized.&quot;</span>)</div>
<div class="line"><span class="lineno">  951</span>        self.wv.index2word.sort(key=<span class="keyword">lambda</span> word: self.wv.vocab[word].count, reverse=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  952</span>        <span class="keywordflow">for</span> i, word <span class="keywordflow">in</span> enumerate(self.wv.index2word):</div>
<div class="line"><span class="lineno">  953</span>            self.wv.vocab[word].index = i</div>
<div class="line"><span class="lineno">  954</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a003023ab4e9d8589831a6ec57bdc110d" name="a003023ab4e9d8589831a6ec57bdc110d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a003023ab4e9d8589831a6ec57bdc110d">&#9670;&#160;</a></span>train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sentences</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_examples</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_words</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>epochs</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>start_alpha</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>end_alpha</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_count</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>queue_factor</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>report_delay</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>compute_loss</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update the model's neural weights from a sequence of sentences (can be a once-only generator stream).
For Word2Vec, each sentence must be a list of unicode strings. (Subclasses may accept other examples.)

To support linear learning-rate decay from (initial) alpha to min_alpha, and accurate
progres-percentage logging, either total_examples (count of sentences) or total_words (count of
raw words in sentences) MUST be provided. (If the corpus is the same as was provided to
`build_vocab()`, the count of examples in that corpus will be available in the model's
`corpus_count` property.)

To avoid common mistakes around the model's ability to do multiple training passes itself, an
explicit `epochs` argument MUST be provided. In the common and recommended case, where `train()`
is only called once, the model's cached `iter` value should be supplied as `epochs` value.
</pre> 
<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext__wrapper_1_1_fast_text.html#a42ba395c8978776e231e70712acfacac">gensim.models.deprecated.fasttext_wrapper.FastText</a>, and <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext_1_1_fast_text.html#ab6f1a60237b72f462dc2274fa5c62a6e">gensim.models.deprecated.fasttext.FastText</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  985</span>              queue_factor=2, report_delay=1.0, compute_loss=<span class="keywordtype">None</span>):</div>
<div class="line"><span class="lineno">  986</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  987</span><span class="stringliteral">        Update the model&#39;s neural weights from a sequence of sentences (can be a once-only generator stream).</span></div>
<div class="line"><span class="lineno">  988</span><span class="stringliteral">        For Word2Vec, each sentence must be a list of unicode strings. (Subclasses may accept other examples.)</span></div>
<div class="line"><span class="lineno">  989</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  990</span><span class="stringliteral">        To support linear learning-rate decay from (initial) alpha to min_alpha, and accurate</span></div>
<div class="line"><span class="lineno">  991</span><span class="stringliteral">        progres-percentage logging, either total_examples (count of sentences) or total_words (count of</span></div>
<div class="line"><span class="lineno">  992</span><span class="stringliteral">        raw words in sentences) MUST be provided. (If the corpus is the same as was provided to</span></div>
<div class="line"><span class="lineno">  993</span><span class="stringliteral">        `build_vocab()`, the count of examples in that corpus will be available in the model&#39;s</span></div>
<div class="line"><span class="lineno">  994</span><span class="stringliteral">        `corpus_count` property.)</span></div>
<div class="line"><span class="lineno">  995</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  996</span><span class="stringliteral">        To avoid common mistakes around the model&#39;s ability to do multiple training passes itself, an</span></div>
<div class="line"><span class="lineno">  997</span><span class="stringliteral">        explicit `epochs` argument MUST be provided. In the common and recommended case, where `train()`</span></div>
<div class="line"><span class="lineno">  998</span><span class="stringliteral">        is only called once, the model&#39;s cached `iter` value should be supplied as `epochs` value.</span></div>
<div class="line"><span class="lineno">  999</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1000</span>        <span class="keywordflow">if</span> self.model_trimmed_post_training:</div>
<div class="line"><span class="lineno"> 1001</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;Parameters for training were discarded using model_trimmed_post_training method&quot;</span>)</div>
<div class="line"><span class="lineno"> 1002</span> </div>
<div class="line"><span class="lineno"> 1003</span>        <span class="keywordflow">if</span> compute_loss:</div>
<div class="line"><span class="lineno"> 1004</span>            self.compute_loss = compute_loss</div>
<div class="line"><span class="lineno"> 1005</span>        self.running_training_loss = 0</div>
<div class="line"><span class="lineno"> 1006</span> </div>
<div class="line"><span class="lineno"> 1007</span>        logger.info(</div>
<div class="line"><span class="lineno"> 1008</span>            <span class="stringliteral">&quot;training model with %i workers on %i vocabulary and %i features, &quot;</span></div>
<div class="line"><span class="lineno"> 1009</span>            <span class="stringliteral">&quot;using sg=%s hs=%s sample=%s negative=%s window=%s&quot;</span>,</div>
<div class="line"><span class="lineno"> 1010</span>            self.workers, len(self.wv.vocab), self.layer1_size, self.sg,</div>
<div class="line"><span class="lineno"> 1011</span>            self.hs, self.sample, self.negative, self.window</div>
<div class="line"><span class="lineno"> 1012</span>        )</div>
<div class="line"><span class="lineno"> 1013</span> </div>
<div class="line"><span class="lineno"> 1014</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.wv.vocab:</div>
<div class="line"><span class="lineno"> 1015</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;you must first build vocabulary before training the model&quot;</span>)</div>
<div class="line"><span class="lineno"> 1016</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> len(self.wv.syn0):</div>
<div class="line"><span class="lineno"> 1017</span>            <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&quot;you must first finalize vocabulary before training the model&quot;</span>)</div>
<div class="line"><span class="lineno"> 1018</span> </div>
<div class="line"><span class="lineno"> 1019</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(self, <span class="stringliteral">&#39;corpus_count&#39;</span>):</div>
<div class="line"><span class="lineno"> 1020</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1021</span>                <span class="stringliteral">&quot;The number of sentences in the training corpus is missing. &quot;</span></div>
<div class="line"><span class="lineno"> 1022</span>                <span class="stringliteral">&quot;Did you load the model via KeyedVectors.load_word2vec_format?&quot;</span></div>
<div class="line"><span class="lineno"> 1023</span>                <span class="stringliteral">&quot;Models loaded via load_word2vec_format don&#39;t support further training. &quot;</span></div>
<div class="line"><span class="lineno"> 1024</span>                <span class="stringliteral">&quot;Instead start with a blank model, scan_vocab on the new corpus, &quot;</span></div>
<div class="line"><span class="lineno"> 1025</span>                <span class="stringliteral">&quot;intersect_word2vec_format with the old model, then train.&quot;</span></div>
<div class="line"><span class="lineno"> 1026</span>            )</div>
<div class="line"><span class="lineno"> 1027</span> </div>
<div class="line"><span class="lineno"> 1028</span>        <span class="keywordflow">if</span> total_words <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> total_examples <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1029</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1030</span>                <span class="stringliteral">&quot;You must specify either total_examples or total_words, for proper alpha and progress calculations. &quot;</span></div>
<div class="line"><span class="lineno"> 1031</span>                <span class="stringliteral">&quot;The usual value is total_examples=model.corpus_count.&quot;</span></div>
<div class="line"><span class="lineno"> 1032</span>            )</div>
<div class="line"><span class="lineno"> 1033</span>        <span class="keywordflow">if</span> epochs <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1034</span>            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;You must specify an explict epochs count. The usual value is epochs=model.iter.&quot;</span>)</div>
<div class="line"><span class="lineno"> 1035</span>        start_alpha = start_alpha <span class="keywordflow">or</span> self.alpha</div>
<div class="line"><span class="lineno"> 1036</span>        end_alpha = end_alpha <span class="keywordflow">or</span> self.min_alpha</div>
<div class="line"><span class="lineno"> 1037</span> </div>
<div class="line"><span class="lineno"> 1038</span>        job_tally = 0</div>
<div class="line"><span class="lineno"> 1039</span> </div>
<div class="line"><span class="lineno"> 1040</span>        <span class="keywordflow">if</span> epochs &gt; 1:</div>
<div class="line"><span class="lineno"> 1041</span>            sentences = utils.RepeatCorpusNTimes(sentences, epochs)</div>
<div class="line"><span class="lineno"> 1042</span>            total_words = total_words <span class="keywordflow">and</span> total_words * epochs</div>
<div class="line"><span class="lineno"> 1043</span>            total_examples = total_examples <span class="keywordflow">and</span> total_examples * epochs</div>
<div class="line"><span class="lineno"> 1044</span> </div>
<div class="line"><span class="lineno"> 1045</span>        <span class="keyword">def </span>worker_loop():</div>
<div class="line"><span class="lineno"> 1046</span>            <span class="stringliteral">&quot;&quot;&quot;Train the model, lifting lists of sentences from the job_queue.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1047</span>            work = matutils.zeros_aligned(self.layer1_size, dtype=REAL)  <span class="comment"># per-thread private work memory</span></div>
<div class="line"><span class="lineno"> 1048</span>            neu1 = matutils.zeros_aligned(self.layer1_size, dtype=REAL)</div>
<div class="line"><span class="lineno"> 1049</span>            jobs_processed = 0</div>
<div class="line"><span class="lineno"> 1050</span>            <span class="keywordflow">while</span> <span class="keyword">True</span>:</div>
<div class="line"><span class="lineno"> 1051</span>                job = job_queue.get()</div>
<div class="line"><span class="lineno"> 1052</span>                <span class="keywordflow">if</span> job <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno"> 1053</span>                    progress_queue.put(<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno"> 1054</span>                    <span class="keywordflow">break</span>  <span class="comment"># no more jobs =&gt; quit this worker</span></div>
<div class="line"><span class="lineno"> 1055</span>                sentences, alpha = job</div>
<div class="line"><span class="lineno"> 1056</span>                tally, raw_tally = self._do_train_job(sentences, alpha, (work, neu1))</div>
<div class="line"><span class="lineno"> 1057</span>                progress_queue.put((len(sentences), tally, raw_tally))  <span class="comment"># report back progress</span></div>
<div class="line"><span class="lineno"> 1058</span>                jobs_processed += 1</div>
<div class="line"><span class="lineno"> 1059</span>            logger.debug(<span class="stringliteral">&quot;worker exiting, processed %i jobs&quot;</span>, jobs_processed)</div>
<div class="line"><span class="lineno"> 1060</span> </div>
<div class="line"><span class="lineno"> 1061</span>        <span class="keyword">def </span>job_producer():</div>
<div class="line"><span class="lineno"> 1062</span>            <span class="stringliteral">&quot;&quot;&quot;Fill jobs queue using the input `sentences` iterator.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1063</span>            job_batch, batch_size = [], 0</div>
<div class="line"><span class="lineno"> 1064</span>            pushed_words, pushed_examples = 0, 0</div>
<div class="line"><span class="lineno"> 1065</span>            next_alpha = start_alpha</div>
<div class="line"><span class="lineno"> 1066</span>            <span class="keywordflow">if</span> next_alpha &gt; self.min_alpha_yet_reached:</div>
<div class="line"><span class="lineno"> 1067</span>                logger.warning(<span class="stringliteral">&quot;Effective &#39;alpha&#39; higher than previous training cycles&quot;</span>)</div>
<div class="line"><span class="lineno"> 1068</span>            self.min_alpha_yet_reached = next_alpha</div>
<div class="line"><span class="lineno"> 1069</span>            job_no = 0</div>
<div class="line"><span class="lineno"> 1070</span> </div>
<div class="line"><span class="lineno"> 1071</span>            <span class="keywordflow">for</span> sent_idx, sentence <span class="keywordflow">in</span> enumerate(sentences):</div>
<div class="line"><span class="lineno"> 1072</span>                sentence_length = self._raw_word_count([sentence])</div>
<div class="line"><span class="lineno"> 1073</span> </div>
<div class="line"><span class="lineno"> 1074</span>                <span class="comment"># can we fit this sentence into the existing job batch?</span></div>
<div class="line"><span class="lineno"> 1075</span>                <span class="keywordflow">if</span> batch_size + sentence_length &lt;= self.batch_words:</div>
<div class="line"><span class="lineno"> 1076</span>                    <span class="comment"># yes =&gt; add it to the current job</span></div>
<div class="line"><span class="lineno"> 1077</span>                    job_batch.append(sentence)</div>
<div class="line"><span class="lineno"> 1078</span>                    batch_size += sentence_length</div>
<div class="line"><span class="lineno"> 1079</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1080</span>                    <span class="comment"># no =&gt; submit the existing job</span></div>
<div class="line"><span class="lineno"> 1081</span>                    logger.debug(</div>
<div class="line"><span class="lineno"> 1082</span>                        <span class="stringliteral">&quot;queueing job #%i (%i words, %i sentences) at alpha %.05f&quot;</span>,</div>
<div class="line"><span class="lineno"> 1083</span>                        job_no, batch_size, len(job_batch), next_alpha</div>
<div class="line"><span class="lineno"> 1084</span>                    )</div>
<div class="line"><span class="lineno"> 1085</span>                    job_no += 1</div>
<div class="line"><span class="lineno"> 1086</span>                    job_queue.put((job_batch, next_alpha))</div>
<div class="line"><span class="lineno"> 1087</span> </div>
<div class="line"><span class="lineno"> 1088</span>                    <span class="comment"># update the learning rate for the next job</span></div>
<div class="line"><span class="lineno"> 1089</span>                    <span class="keywordflow">if</span> end_alpha &lt; next_alpha:</div>
<div class="line"><span class="lineno"> 1090</span>                        <span class="keywordflow">if</span> total_examples:</div>
<div class="line"><span class="lineno"> 1091</span>                            <span class="comment"># examples-based decay</span></div>
<div class="line"><span class="lineno"> 1092</span>                            pushed_examples += len(job_batch)</div>
<div class="line"><span class="lineno"> 1093</span>                            progress = 1.0 * pushed_examples / total_examples</div>
<div class="line"><span class="lineno"> 1094</span>                        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1095</span>                            <span class="comment"># words-based decay</span></div>
<div class="line"><span class="lineno"> 1096</span>                            pushed_words += self._raw_word_count(job_batch)</div>
<div class="line"><span class="lineno"> 1097</span>                            progress = 1.0 * pushed_words / total_words</div>
<div class="line"><span class="lineno"> 1098</span>                        next_alpha = start_alpha - (start_alpha - end_alpha) * progress</div>
<div class="line"><span class="lineno"> 1099</span>                        next_alpha = max(end_alpha, next_alpha)</div>
<div class="line"><span class="lineno"> 1100</span> </div>
<div class="line"><span class="lineno"> 1101</span>                    <span class="comment"># add the sentence that didn&#39;t fit as the first item of a new job</span></div>
<div class="line"><span class="lineno"> 1102</span>                    job_batch, batch_size = [sentence], sentence_length</div>
<div class="line"><span class="lineno"> 1103</span> </div>
<div class="line"><span class="lineno"> 1104</span>            <span class="comment"># add the last job too (may be significantly smaller than batch_words)</span></div>
<div class="line"><span class="lineno"> 1105</span>            <span class="keywordflow">if</span> job_batch:</div>
<div class="line"><span class="lineno"> 1106</span>                logger.debug(</div>
<div class="line"><span class="lineno"> 1107</span>                    <span class="stringliteral">&quot;queueing job #%i (%i words, %i sentences) at alpha %.05f&quot;</span>,</div>
<div class="line"><span class="lineno"> 1108</span>                    job_no, batch_size, len(job_batch), next_alpha</div>
<div class="line"><span class="lineno"> 1109</span>                )</div>
<div class="line"><span class="lineno"> 1110</span>                job_no += 1</div>
<div class="line"><span class="lineno"> 1111</span>                job_queue.put((job_batch, next_alpha))</div>
<div class="line"><span class="lineno"> 1112</span> </div>
<div class="line"><span class="lineno"> 1113</span>            <span class="keywordflow">if</span> job_no == 0 <span class="keywordflow">and</span> self.train_count == 0:</div>
<div class="line"><span class="lineno"> 1114</span>                logger.warning(</div>
<div class="line"><span class="lineno"> 1115</span>                    <span class="stringliteral">&quot;train() called with an empty iterator (if not intended, &quot;</span></div>
<div class="line"><span class="lineno"> 1116</span>                    <span class="stringliteral">&quot;be sure to provide a corpus that offers restartable iteration = an iterable).&quot;</span></div>
<div class="line"><span class="lineno"> 1117</span>                )</div>
<div class="line"><span class="lineno"> 1118</span> </div>
<div class="line"><span class="lineno"> 1119</span>            <span class="comment"># give the workers heads up that they can finish -- no more work!</span></div>
<div class="line"><span class="lineno"> 1120</span>            <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(self.workers):</div>
<div class="line"><span class="lineno"> 1121</span>                job_queue.put(<span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno"> 1122</span>            logger.debug(<span class="stringliteral">&quot;job loop exiting, total %i jobs&quot;</span>, job_no)</div>
<div class="line"><span class="lineno"> 1123</span> </div>
<div class="line"><span class="lineno"> 1124</span>        <span class="comment"># buffer ahead only a limited number of jobs.. this is the reason we can&#39;t simply use ThreadPool :(</span></div>
<div class="line"><span class="lineno"> 1125</span>        job_queue = Queue(maxsize=queue_factor * self.workers)</div>
<div class="line"><span class="lineno"> 1126</span>        progress_queue = Queue(maxsize=(queue_factor + 1) * self.workers)</div>
<div class="line"><span class="lineno"> 1127</span> </div>
<div class="line"><span class="lineno"> 1128</span>        workers = [threading.Thread(target=worker_loop) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(self.workers)]</div>
<div class="line"><span class="lineno"> 1129</span>        unfinished_worker_count = len(workers)</div>
<div class="line"><span class="lineno"> 1130</span>        workers.append(threading.Thread(target=job_producer))</div>
<div class="line"><span class="lineno"> 1131</span> </div>
<div class="line"><span class="lineno"> 1132</span>        <span class="keywordflow">for</span> thread <span class="keywordflow">in</span> workers:</div>
<div class="line"><span class="lineno"> 1133</span>            thread.daemon = <span class="keyword">True</span>  <span class="comment"># make interrupting the process with ctrl+c easier</span></div>
<div class="line"><span class="lineno"> 1134</span>            thread.start()</div>
<div class="line"><span class="lineno"> 1135</span> </div>
<div class="line"><span class="lineno"> 1136</span>        example_count, trained_word_count, raw_word_count = 0, 0, word_count</div>
<div class="line"><span class="lineno"> 1137</span>        start, next_report = default_timer() - 0.00001, 1.0</div>
<div class="line"><span class="lineno"> 1138</span> </div>
<div class="line"><span class="lineno"> 1139</span>        <span class="keywordflow">while</span> unfinished_worker_count &gt; 0:</div>
<div class="line"><span class="lineno"> 1140</span>            report = progress_queue.get()  <span class="comment"># blocks if workers too slow</span></div>
<div class="line"><span class="lineno"> 1141</span>            <span class="keywordflow">if</span> report <span class="keywordflow">is</span> <span class="keywordtype">None</span>:  <span class="comment"># a thread reporting that it finished</span></div>
<div class="line"><span class="lineno"> 1142</span>                unfinished_worker_count -= 1</div>
<div class="line"><span class="lineno"> 1143</span>                logger.info(<span class="stringliteral">&quot;worker thread finished; awaiting finish of %i more threads&quot;</span>, unfinished_worker_count)</div>
<div class="line"><span class="lineno"> 1144</span>                <span class="keywordflow">continue</span></div>
<div class="line"><span class="lineno"> 1145</span>            examples, trained_words, raw_words = report</div>
<div class="line"><span class="lineno"> 1146</span>            job_tally += 1</div>
<div class="line"><span class="lineno"> 1147</span> </div>
<div class="line"><span class="lineno"> 1148</span>            <span class="comment"># update progress stats</span></div>
<div class="line"><span class="lineno"> 1149</span>            example_count += examples</div>
<div class="line"><span class="lineno"> 1150</span>            trained_word_count += trained_words  <span class="comment"># only words in vocab &amp; sampled</span></div>
<div class="line"><span class="lineno"> 1151</span>            raw_word_count += raw_words</div>
<div class="line"><span class="lineno"> 1152</span> </div>
<div class="line"><span class="lineno"> 1153</span>            <span class="comment"># log progress once every report_delay seconds</span></div>
<div class="line"><span class="lineno"> 1154</span>            elapsed = default_timer() - start</div>
<div class="line"><span class="lineno"> 1155</span>            <span class="keywordflow">if</span> elapsed &gt;= next_report:</div>
<div class="line"><span class="lineno"> 1156</span>                <span class="keywordflow">if</span> total_examples:</div>
<div class="line"><span class="lineno"> 1157</span>                    <span class="comment"># examples-based progress %</span></div>
<div class="line"><span class="lineno"> 1158</span>                    logger.info(</div>
<div class="line"><span class="lineno"> 1159</span>                        <span class="stringliteral">&quot;PROGRESS: at %.2f%% examples, %.0f words/s, in_qsize %i, out_qsize %i&quot;</span>,</div>
<div class="line"><span class="lineno"> 1160</span>                        100.0 * example_count / total_examples, trained_word_count / elapsed,</div>
<div class="line"><span class="lineno"> 1161</span>                        utils.qsize(job_queue), utils.qsize(progress_queue)</div>
<div class="line"><span class="lineno"> 1162</span>                    )</div>
<div class="line"><span class="lineno"> 1163</span>                <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1164</span>                    <span class="comment"># words-based progress %</span></div>
<div class="line"><span class="lineno"> 1165</span>                    logger.info(</div>
<div class="line"><span class="lineno"> 1166</span>                        <span class="stringliteral">&quot;PROGRESS: at %.2f%% words, %.0f words/s, in_qsize %i, out_qsize %i&quot;</span>,</div>
<div class="line"><span class="lineno"> 1167</span>                        100.0 * raw_word_count / total_words, trained_word_count / elapsed,</div>
<div class="line"><span class="lineno"> 1168</span>                        utils.qsize(job_queue), utils.qsize(progress_queue)</div>
<div class="line"><span class="lineno"> 1169</span>                    )</div>
<div class="line"><span class="lineno"> 1170</span>                next_report = elapsed + report_delay</div>
<div class="line"><span class="lineno"> 1171</span> </div>
<div class="line"><span class="lineno"> 1172</span>        <span class="comment"># all done; report the final stats</span></div>
<div class="line"><span class="lineno"> 1173</span>        elapsed = default_timer() - start</div>
<div class="line"><span class="lineno"> 1174</span>        logger.info(</div>
<div class="line"><span class="lineno"> 1175</span>            <span class="stringliteral">&quot;training on %i raw words (%i effective words) took %.1fs, %.0f effective words/s&quot;</span>,</div>
<div class="line"><span class="lineno"> 1176</span>            raw_word_count, trained_word_count, elapsed, trained_word_count / elapsed</div>
<div class="line"><span class="lineno"> 1177</span>        )</div>
<div class="line"><span class="lineno"> 1178</span>        <span class="keywordflow">if</span> job_tally &lt; 10 * self.workers:</div>
<div class="line"><span class="lineno"> 1179</span>            logger.warning(</div>
<div class="line"><span class="lineno"> 1180</span>                <span class="stringliteral">&quot;under 10 jobs per worker: consider setting a smaller `batch_words&#39; for smoother alpha decay&quot;</span></div>
<div class="line"><span class="lineno"> 1181</span>            )</div>
<div class="line"><span class="lineno"> 1182</span> </div>
<div class="line"><span class="lineno"> 1183</span>        <span class="comment"># check that the input corpus hasn&#39;t changed during iteration</span></div>
<div class="line"><span class="lineno"> 1184</span>        <span class="keywordflow">if</span> total_examples <span class="keywordflow">and</span> total_examples != example_count:</div>
<div class="line"><span class="lineno"> 1185</span>            logger.warning(</div>
<div class="line"><span class="lineno"> 1186</span>                <span class="stringliteral">&quot;supplied example count (%i) did not equal expected count (%i)&quot;</span>, example_count, total_examples</div>
<div class="line"><span class="lineno"> 1187</span>            )</div>
<div class="line"><span class="lineno"> 1188</span>        <span class="keywordflow">if</span> total_words <span class="keywordflow">and</span> total_words != raw_word_count:</div>
<div class="line"><span class="lineno"> 1189</span>            logger.warning(</div>
<div class="line"><span class="lineno"> 1190</span>                <span class="stringliteral">&quot;supplied raw word count (%i) did not equal expected count (%i)&quot;</span>, raw_word_count, total_words</div>
<div class="line"><span class="lineno"> 1191</span>            )</div>
<div class="line"><span class="lineno"> 1192</span> </div>
<div class="line"><span class="lineno"> 1193</span>        self.train_count += 1  <span class="comment"># number of times train() has been called</span></div>
<div class="line"><span class="lineno"> 1194</span>        self.total_train_time += elapsed</div>
<div class="line"><span class="lineno"> 1195</span>        self.clear_sims()</div>
<div class="line"><span class="lineno"> 1196</span>        <span class="keywordflow">return</span> trained_word_count</div>
<div class="line"><span class="lineno"> 1197</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6796999ea3d2c2488445a5d23f3ae6af" name="a6796999ea3d2c2488445a5d23f3ae6af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6796999ea3d2c2488445a5d23f3ae6af">&#9670;&#160;</a></span>update_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.update_weights </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Copy all the existing weights, and reset the weights for the newly
added vocabulary.
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1323</span>    <span class="keyword">def </span>update_weights(self):</div>
<div class="line"><span class="lineno"> 1324</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1325</span><span class="stringliteral">        Copy all the existing weights, and reset the weights for the newly</span></div>
<div class="line"><span class="lineno"> 1326</span><span class="stringliteral">        added vocabulary.</span></div>
<div class="line"><span class="lineno"> 1327</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1328</span>        logger.info(<span class="stringliteral">&quot;updating layer weights&quot;</span>)</div>
<div class="line"><span class="lineno"> 1329</span>        gained_vocab = len(self.wv.vocab) - len(self.wv.syn0)</div>
<div class="line"><span class="lineno"> 1330</span>        newsyn0 = empty((gained_vocab, self.vector_size), dtype=REAL)</div>
<div class="line"><span class="lineno"> 1331</span> </div>
<div class="line"><span class="lineno"> 1332</span>        <span class="comment"># randomize the remaining words</span></div>
<div class="line"><span class="lineno"> 1333</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(self.wv.syn0), len(self.wv.vocab)):</div>
<div class="line"><span class="lineno"> 1334</span>            <span class="comment"># construct deterministic seed from word AND seed argument</span></div>
<div class="line"><span class="lineno"> 1335</span>            newsyn0[i - len(self.wv.syn0)] = self.seeded_vector(self.wv.index2word[i] + str(self.seed))</div>
<div class="line"><span class="lineno"> 1336</span> </div>
<div class="line"><span class="lineno"> 1337</span>        <span class="comment"># Raise an error if an online update is run before initial training on a corpus</span></div>
<div class="line"><span class="lineno"> 1338</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> len(self.wv.syn0):</div>
<div class="line"><span class="lineno"> 1339</span>            <span class="keywordflow">raise</span> RuntimeError(</div>
<div class="line"><span class="lineno"> 1340</span>                <span class="stringliteral">&quot;You cannot do an online vocabulary-update of a model which has no prior vocabulary. &quot;</span></div>
<div class="line"><span class="lineno"> 1341</span>                <span class="stringliteral">&quot;First build the vocabulary of your model with a corpus before doing an online update.&quot;</span></div>
<div class="line"><span class="lineno"> 1342</span>            )</div>
<div class="line"><span class="lineno"> 1343</span> </div>
<div class="line"><span class="lineno"> 1344</span>        self.wv.syn0 = vstack([self.wv.syn0, newsyn0])</div>
<div class="line"><span class="lineno"> 1345</span> </div>
<div class="line"><span class="lineno"> 1346</span>        <span class="keywordflow">if</span> self.hs:</div>
<div class="line"><span class="lineno"> 1347</span>            self.syn1 = vstack([self.syn1, zeros((gained_vocab, self.layer1_size), dtype=REAL)])</div>
<div class="line"><span class="lineno"> 1348</span>        <span class="keywordflow">if</span> self.negative:</div>
<div class="line"><span class="lineno"> 1349</span>            self.syn1neg = vstack([self.syn1neg, zeros((gained_vocab, self.layer1_size), dtype=REAL)])</div>
<div class="line"><span class="lineno"> 1350</span>        self.wv.syn0norm = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno"> 1351</span> </div>
<div class="line"><span class="lineno"> 1352</span>        <span class="comment"># do not suppress learning for already learned words</span></div>
<div class="line"><span class="lineno"> 1353</span>        self.syn0_lockf = ones(len(self.wv.vocab), dtype=REAL)  <span class="comment"># zeros suppress learning</span></div>
<div class="line"><span class="lineno"> 1354</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2d2cc1e2aee82041a2fd2da7d8f2d44d" name="a2d2cc1e2aee82041a2fd2da7d8f2d44d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d2cc1e2aee82041a2fd2da7d8f2d44d">&#9670;&#160;</a></span>wmdistance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.wmdistance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>document1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>document2</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Deprecated. Use self.wv.wmdistance() instead.
Refer to the documentation for `gensim.models.KeyedVectors.wmdistance`
</pre> <div class="fragment"><div class="line"><span class="lineno"> 1434</span>    <span class="keyword">def </span>wmdistance(self, document1, document2):</div>
<div class="line"><span class="lineno"> 1435</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1436</span><span class="stringliteral">        Deprecated. Use self.wv.wmdistance() instead.</span></div>
<div class="line"><span class="lineno"> 1437</span><span class="stringliteral">        Refer to the documentation for `gensim.models.KeyedVectors.wmdistance`</span></div>
<div class="line"><span class="lineno"> 1438</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1439</span>        <span class="keywordflow">return</span> self.wv.wmdistance(document1, document2)</div>
<div class="line"><span class="lineno"> 1440</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="ad5b7b7b57e7e1b04ba087be8bab8e9b5" name="ad5b7b7b57e7e1b04ba087be8bab8e9b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad5b7b7b57e7e1b04ba087be8bab8e9b5">&#9670;&#160;</a></span>alpha</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.alpha</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac896e71155684d2c3750e1b26d32ab42" name="ac896e71155684d2c3750e1b26d32ab42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac896e71155684d2c3750e1b26d32ab42">&#9670;&#160;</a></span>batch_words</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.batch_words</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0cdb4b56553d8c515af91d88b8c016f9" name="a0cdb4b56553d8c515af91d88b8c016f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0cdb4b56553d8c515af91d88b8c016f9">&#9670;&#160;</a></span>cbow_mean</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.cbow_mean</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac301339237350d9be571efccddfba2d9" name="ac301339237350d9be571efccddfba2d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac301339237350d9be571efccddfba2d9">&#9670;&#160;</a></span>compute_loss</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.compute_loss</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a83a1d09f4d3c3aeba695230883948458" name="a83a1d09f4d3c3aeba695230883948458"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83a1d09f4d3c3aeba695230883948458">&#9670;&#160;</a></span>corpus_count</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.corpus_count</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a35a0f5cab3794c8785ede91eb858e0ef" name="a35a0f5cab3794c8785ede91eb858e0ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a35a0f5cab3794c8785ede91eb858e0ef">&#9670;&#160;</a></span>cum_table</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.cum_table</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad365734c0659876a4aa86fb63eb5cbe5" name="ad365734c0659876a4aa86fb63eb5cbe5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad365734c0659876a4aa86fb63eb5cbe5">&#9670;&#160;</a></span>hashfxn</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.hashfxn</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a182ec4c63dbee365dbab6bf61a2305d3" name="a182ec4c63dbee365dbab6bf61a2305d3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a182ec4c63dbee365dbab6bf61a2305d3">&#9670;&#160;</a></span>hs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.hs</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8e802f047465da17ae5aa210351ccf32" name="a8e802f047465da17ae5aa210351ccf32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e802f047465da17ae5aa210351ccf32">&#9670;&#160;</a></span>iter</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.iter</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a86d88570be4beb2d83e2349b7d349a52" name="a86d88570be4beb2d83e2349b7d349a52"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a86d88570be4beb2d83e2349b7d349a52">&#9670;&#160;</a></span>layer1_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.layer1_size</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acd356181bce61ebae608daa6851e8b53" name="acd356181bce61ebae608daa6851e8b53"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd356181bce61ebae608daa6851e8b53">&#9670;&#160;</a></span>load</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.load</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reimplemented in <a class="el" href="classgensim_1_1models_1_1deprecated_1_1fasttext__wrapper_1_1_fast_text.html#acb634503d9eace29a5456cd070785dbe">gensim.models.deprecated.fasttext_wrapper.FastText</a>.</p>

</div>
</div>
<a id="ab2320590f7860127643e742b511d2193" name="ab2320590f7860127643e742b511d2193"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab2320590f7860127643e742b511d2193">&#9670;&#160;</a></span>max_vocab_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.max_vocab_size</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2b873bc13d474b6e7779b82b65db2412" name="a2b873bc13d474b6e7779b82b65db2412"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b873bc13d474b6e7779b82b65db2412">&#9670;&#160;</a></span>min_alpha</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.min_alpha</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a505e949f46853473e09dd8cbe090035d" name="a505e949f46853473e09dd8cbe090035d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a505e949f46853473e09dd8cbe090035d">&#9670;&#160;</a></span>min_alpha_yet_reached</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.min_alpha_yet_reached</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a661da677ae378913d1dc06cd9fc03f05" name="a661da677ae378913d1dc06cd9fc03f05"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a661da677ae378913d1dc06cd9fc03f05">&#9670;&#160;</a></span>min_count</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.min_count</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6aae204318deb7dcceddb1646c9fb147" name="a6aae204318deb7dcceddb1646c9fb147"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6aae204318deb7dcceddb1646c9fb147">&#9670;&#160;</a></span>model_trimmed_post_training</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.model_trimmed_post_training</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a36df321e5a08d7a451dd429fe3d02a43" name="a36df321e5a08d7a451dd429fe3d02a43"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a36df321e5a08d7a451dd429fe3d02a43">&#9670;&#160;</a></span>negative</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.negative</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8d6b5089b464073f9f57231eca4a0176" name="a8d6b5089b464073f9f57231eca4a0176"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d6b5089b464073f9f57231eca4a0176">&#9670;&#160;</a></span>null_word</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.null_word</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aa73d2f2a1fc0a469ac6dda92e4021a23" name="aa73d2f2a1fc0a469ac6dda92e4021a23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa73d2f2a1fc0a469ac6dda92e4021a23">&#9670;&#160;</a></span>random</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.random</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ace6c962a54d5a0322f801bf9572c55ca" name="ace6c962a54d5a0322f801bf9572c55ca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace6c962a54d5a0322f801bf9572c55ca">&#9670;&#160;</a></span>raw_vocab</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.raw_vocab</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a462761f9480c36c5a4c3a4325f0ea4d5" name="a462761f9480c36c5a4c3a4325f0ea4d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a462761f9480c36c5a4c3a4325f0ea4d5">&#9670;&#160;</a></span>running_training_loss</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.running_training_loss</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae36d9c7a38b2ed20216787c2e01db434" name="ae36d9c7a38b2ed20216787c2e01db434"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae36d9c7a38b2ed20216787c2e01db434">&#9670;&#160;</a></span>sample</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.sample</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0ef7cff1a5adbcd13121c33a36a186a1" name="a0ef7cff1a5adbcd13121c33a36a186a1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0ef7cff1a5adbcd13121c33a36a186a1">&#9670;&#160;</a></span>seed</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.seed</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a807d4bdeaf4f66d6d608182d4a271a32" name="a807d4bdeaf4f66d6d608182d4a271a32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a807d4bdeaf4f66d6d608182d4a271a32">&#9670;&#160;</a></span>sg</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.sg</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae5f6f0ab1533b6bfb3b29fa457ac1dc1" name="ae5f6f0ab1533b6bfb3b29fa457ac1dc1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5f6f0ab1533b6bfb3b29fa457ac1dc1">&#9670;&#160;</a></span>sorted_vocab</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.sorted_vocab</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a25a83cf6b93053af9de0aca65178bf38" name="a25a83cf6b93053af9de0aca65178bf38"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25a83cf6b93053af9de0aca65178bf38">&#9670;&#160;</a></span>syn0_lockf</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.syn0_lockf</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5756633df3413ea7443ccfcd7629e454" name="a5756633df3413ea7443ccfcd7629e454"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5756633df3413ea7443ccfcd7629e454">&#9670;&#160;</a></span>syn1</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.syn1</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a13750aead744559e1baec8783f058e90" name="a13750aead744559e1baec8783f058e90"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a13750aead744559e1baec8783f058e90">&#9670;&#160;</a></span>syn1neg</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.syn1neg</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af258b5e0dcd596af2e84ee9a98a560bd" name="af258b5e0dcd596af2e84ee9a98a560bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af258b5e0dcd596af2e84ee9a98a560bd">&#9670;&#160;</a></span>total_train_time</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.total_train_time</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a96991775ad40f0ac7e1ddb3004d2499b" name="a96991775ad40f0ac7e1ddb3004d2499b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96991775ad40f0ac7e1ddb3004d2499b">&#9670;&#160;</a></span>train_count</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.train_count</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3f83596f0bd8ef7e88cbfee7a3f2f737" name="a3f83596f0bd8ef7e88cbfee7a3f2f737"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3f83596f0bd8ef7e88cbfee7a3f2f737">&#9670;&#160;</a></span>vector_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.vector_size</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9c69ef884587ba5a6a5c4aa2f7e4cac9" name="a9c69ef884587ba5a6a5c4aa2f7e4cac9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c69ef884587ba5a6a5c4aa2f7e4cac9">&#9670;&#160;</a></span>window</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.window</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a35896f1194793e23dcd6b07c15afd2de" name="a35896f1194793e23dcd6b07c15afd2de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a35896f1194793e23dcd6b07c15afd2de">&#9670;&#160;</a></span>workers</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.workers</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a06a5f0f7953d07f4b34dd192957d34e2" name="a06a5f0f7953d07f4b34dd192957d34e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06a5f0f7953d07f4b34dd192957d34e2">&#9670;&#160;</a></span>wv</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.word2vec.Word2Vec.wv</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/rafael/Documents/GitHub/PUC-GCES-PY/Tp-GCS-Rafael-Augusto/venv/lib/python3.9/site-packages/gensim/models/deprecated/<a class="el" href="deprecated_2word2vec_8py.html">word2vec.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
