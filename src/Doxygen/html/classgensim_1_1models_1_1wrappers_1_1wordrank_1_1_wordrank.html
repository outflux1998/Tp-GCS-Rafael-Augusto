<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: gensim.models.wrappers.wordrank.Wordrank Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacegensim.html">gensim</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models.html">models</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1wrappers.html">wrappers</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1wrappers_1_1wordrank.html">wordrank</a></li><li class="navelem"><a class="el" href="classgensim_1_1models_1_1wrappers_1_1wordrank_1_1_wordrank.html">Wordrank</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classgensim_1_1models_1_1wrappers_1_1wordrank_1_1_wordrank-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">gensim.models.wrappers.wordrank.Wordrank Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for gensim.models.wrappers.wordrank.Wordrank:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classgensim_1_1models_1_1wrappers_1_1wordrank_1_1_wordrank.png" alt=""/>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a07255bb7fb5afd56dc4f4d313743beb9" id="r_a07255bb7fb5afd56dc4f4d313743beb9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1wrappers_1_1wordrank_1_1_wordrank.html#a07255bb7fb5afd56dc4f4d313743beb9">train</a> (cls, wr_path, corpus_file, out_name, size=100, window=15, symmetric=1, min_count=5, max_vocab_size=0, sgd_num=100, lrate=0.001, period=10, <a class="el" href="__lapack__subroutines_8h.html#a60590d91febfcb54d88443940cd5f23e">iter</a>=90, epsilon=0.75, dump_period=10, reg=0, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>=100, beta=99, loss='hinge', memory=4.0, np=1, cleanup_files=False, sorted_vocab=1, ensemble=0)</td></tr>
<tr class="separator:a07255bb7fb5afd56dc4f4d313743beb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a087bed6a06d9cb8a40a189c57163cc91" id="r_a087bed6a06d9cb8a40a189c57163cc91"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1wrappers_1_1wordrank_1_1_wordrank.html#a087bed6a06d9cb8a40a189c57163cc91">load_wordrank_model</a> (cls, model_file, vocab_file=None, context_file=None, sorted_vocab=1, ensemble=1)</td></tr>
<tr class="separator:a087bed6a06d9cb8a40a189c57163cc91"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a277ecf1385156df4e2e8a3c3060d9ada" id="r_a277ecf1385156df4e2e8a3c3060d9ada"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1wrappers_1_1wordrank_1_1_wordrank.html#a277ecf1385156df4e2e8a3c3060d9ada">sort_embeddings</a> (self, vocab_file)</td></tr>
<tr class="separator:a277ecf1385156df4e2e8a3c3060d9ada"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42ba5dc40f730744dd679da9a76a50f0" id="r_a42ba5dc40f730744dd679da9a76a50f0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1wrappers_1_1wordrank_1_1_wordrank.html#a42ba5dc40f730744dd679da9a76a50f0">ensemble_embedding</a> (self, word_embedding, context_embedding)</td></tr>
<tr class="separator:a42ba5dc40f730744dd679da9a76a50f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a71eacd5815e233f25c679fddd989afd9" id="r_a71eacd5815e233f25c679fddd989afd9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1wrappers_1_1wordrank_1_1_wordrank.html#a71eacd5815e233f25c679fddd989afd9">index2word</a></td></tr>
<tr class="separator:a71eacd5815e233f25c679fddd989afd9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1a87a5d78e6be2394273061090fc722" id="r_ad1a87a5d78e6be2394273061090fc722"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1wrappers_1_1wordrank_1_1_wordrank.html#ad1a87a5d78e6be2394273061090fc722">syn0</a></td></tr>
<tr class="separator:ad1a87a5d78e6be2394273061090fc722"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Python wrapper using `Wordrank implementation &lt;https://bitbucket.org/shihaoji/wordrank/&gt;`_

Communication between Wordrank and Python takes place by working with data
files on disk and calling the Wordrank binary and glove's helper binaries
(for preparing training data) with subprocess module.

Warnings
--------
This is **only** python wrapper for `Wordrank implementation &lt;https://bitbucket.org/shihaoji/wordrank/&gt;`_,
you need to install original implementation first and pass the path to wordrank dir to ``wr_path``.</pre> </div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a42ba5dc40f730744dd679da9a76a50f0" name="a42ba5dc40f730744dd679da9a76a50f0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a42ba5dc40f730744dd679da9a76a50f0">&#9670;&#160;</a></span>ensemble_embedding()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.wrappers.wordrank.Wordrank.ensemble_embedding </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_embedding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>context_embedding</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Replace current syn0 with the sum of context and word embeddings.

Parameters
----------
word_embedding : str
    Path to word embeddings in GloVe format.
context_embedding : str
    Path to context embeddings in word2vec_format.

Returns
-------
numpy.ndarray
    Matrix with new embeddings.</pre> <div class="fragment"><div class="line"><span class="lineno">  300</span>    <span class="keyword">def </span>ensemble_embedding(self, word_embedding, context_embedding):</div>
<div class="line"><span class="lineno">  301</span>        <span class="stringliteral">&quot;&quot;&quot;Replace current syn0 with the sum of context and word embeddings.</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral">        word_embedding : str</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">            Path to word embeddings in GloVe format.</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">        context_embedding : str</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">            Path to context embeddings in word2vec_format.</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">        Returns</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">        -------</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral">        numpy.ndarray</span></div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">            Matrix with new embeddings.</span></div>
<div class="line"><span class="lineno">  314</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  315</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  316</span>        glove2word2vec(context_embedding, context_embedding + <span class="stringliteral">&#39;.w2vformat&#39;</span>)</div>
<div class="line"><span class="lineno">  317</span>        w_emb = KeyedVectors.load_word2vec_format(<span class="stringliteral">&#39;%s.w2vformat&#39;</span> % word_embedding)</div>
<div class="line"><span class="lineno">  318</span>        c_emb = KeyedVectors.load_word2vec_format(<span class="stringliteral">&#39;%s.w2vformat&#39;</span> % context_embedding)</div>
<div class="line"><span class="lineno">  319</span>        <span class="comment"># compare vocab words using keys of dict vocab</span></div>
<div class="line"><span class="lineno">  320</span>        <span class="keyword">assert</span> set(w_emb.vocab) == set(c_emb.vocab), <span class="stringliteral">&#39;Vocabs are not same for both embeddings&#39;</span></div>
<div class="line"><span class="lineno">  321</span> </div>
<div class="line"><span class="lineno">  322</span>        <span class="comment"># sort context embedding to have words in same order as word embedding</span></div>
<div class="line"><span class="lineno">  323</span>        prev_c_emb = copy.deepcopy(c_emb.syn0)</div>
<div class="line"><span class="lineno">  324</span>        <span class="keywordflow">for</span> word_id, word <span class="keywordflow">in</span> enumerate(w_emb.index2word):</div>
<div class="line"><span class="lineno">  325</span>            c_emb.syn0[word_id] = prev_c_emb[c_emb.vocab[word].index]</div>
<div class="line"><span class="lineno">  326</span>        <span class="comment"># add vectors of the two embeddings</span></div>
<div class="line"><span class="lineno">  327</span>        new_emb = w_emb.syn0 + c_emb.syn0</div>
<div class="line"><span class="lineno">  328</span>        self.syn0 = new_emb</div>
<div class="line"><span class="lineno">  329</span>        <span class="keywordflow">return</span> new_emb</div>
</div><!-- fragment -->
</div>
</div>
<a id="a087bed6a06d9cb8a40a189c57163cc91" name="a087bed6a06d9cb8a40a189c57163cc91"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a087bed6a06d9cb8a40a189c57163cc91">&#9670;&#160;</a></span>load_wordrank_model()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.wrappers.wordrank.Wordrank.load_wordrank_model </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_file</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vocab_file</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>context_file</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sorted_vocab</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ensemble</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Load model from `model_file`.

Parameters
----------
model_file : str
    Path to model in GloVe format.
vocab_file : str, optional
    Path to file with vocabulary.
context_file : str, optional
    Path to file with context-embedding in word2vec_format.
sorted_vocab : {0, 1}, optional
    If 1 - sort the vocabulary by descending frequency before assigning word indexes, otherwise - do nothing.
ensemble : {0, 1}, optional
    If 1 - use ensemble of word and context vectors.</pre> <div class="fragment"><div class="line"><span class="lineno">  245</span>    <span class="keyword">def </span>load_wordrank_model(cls, model_file, vocab_file=None, context_file=None, sorted_vocab=1, ensemble=1):</div>
<div class="line"><span class="lineno">  246</span>        <span class="stringliteral">&quot;&quot;&quot;Load model from `model_file`.</span></div>
<div class="line"><span class="lineno">  247</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  248</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  249</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral">        model_file : str</span></div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">            Path to model in GloVe format.</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">        vocab_file : str, optional</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral">            Path to file with vocabulary.</span></div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">        context_file : str, optional</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">            Path to file with context-embedding in word2vec_format.</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">        sorted_vocab : {0, 1}, optional</span></div>
<div class="line"><span class="lineno">  257</span><span class="stringliteral">            If 1 - sort the vocabulary by descending frequency before assigning word indexes, otherwise - do nothing.</span></div>
<div class="line"><span class="lineno">  258</span><span class="stringliteral">        ensemble : {0, 1}, optional</span></div>
<div class="line"><span class="lineno">  259</span><span class="stringliteral">            If 1 - use ensemble of word and context vectors.</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  262</span>        glove2word2vec(model_file, model_file + <span class="stringliteral">&#39;.w2vformat&#39;</span>)</div>
<div class="line"><span class="lineno">  263</span>        model = cls.load_word2vec_format(<span class="stringliteral">&#39;%s.w2vformat&#39;</span> % model_file)</div>
<div class="line"><span class="lineno">  264</span>        <span class="keywordflow">if</span> ensemble <span class="keywordflow">and</span> context_file:</div>
<div class="line"><span class="lineno">  265</span>            model.ensemble_embedding(model_file, context_file)</div>
<div class="line"><span class="lineno">  266</span>        <span class="keywordflow">if</span> sorted_vocab <span class="keywordflow">and</span> vocab_file:</div>
<div class="line"><span class="lineno">  267</span>            model.sort_embeddings(vocab_file)</div>
<div class="line"><span class="lineno">  268</span>        <span class="keywordflow">return</span> model</div>
<div class="line"><span class="lineno">  269</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a277ecf1385156df4e2e8a3c3060d9ada" name="a277ecf1385156df4e2e8a3c3060d9ada"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a277ecf1385156df4e2e8a3c3060d9ada">&#9670;&#160;</a></span>sort_embeddings()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.wrappers.wordrank.Wordrank.sort_embeddings </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vocab_file</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Sort embeddings according to word frequency.

Parameters
----------
vocab_file : str
    Path to file with vocabulary.</pre> <div class="fragment"><div class="line"><span class="lineno">  270</span>    <span class="keyword">def </span>sort_embeddings(self, vocab_file):</div>
<div class="line"><span class="lineno">  271</span>        <span class="stringliteral">&quot;&quot;&quot;Sort embeddings according to word frequency.</span></div>
<div class="line"><span class="lineno">  272</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  273</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">  274</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">        vocab_file : str</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">            Path to file with vocabulary.</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  279</span>        counts = {}</div>
<div class="line"><span class="lineno">  280</span>        vocab_size = len(self.vocab)</div>
<div class="line"><span class="lineno">  281</span>        prev_syn0 = copy.deepcopy(self.syn0)</div>
<div class="line"><span class="lineno">  282</span>        prev_vocab = copy.deepcopy(self.vocab)</div>
<div class="line"><span class="lineno">  283</span>        self.index2word = []</div>
<div class="line"><span class="lineno">  284</span> </div>
<div class="line"><span class="lineno">  285</span>        <span class="comment"># sort embeddings using frequency sorted vocab file in wordrank</span></div>
<div class="line"><span class="lineno">  286</span>        <span class="keyword">with</span> utils.open(vocab_file, <span class="stringliteral">&#39;rb&#39;</span>) <span class="keyword">as</span> fin:</div>
<div class="line"><span class="lineno">  287</span>            <span class="keywordflow">for</span> index, line <span class="keywordflow">in</span> enumerate(fin):</div>
<div class="line"><span class="lineno">  288</span>                word, count = utils.to_unicode(line).strip(), vocab_size - index</div>
<div class="line"><span class="lineno">  289</span>                <span class="comment"># store word with it&#39;s count in a dict</span></div>
<div class="line"><span class="lineno">  290</span>                counts[word] = int(count)</div>
<div class="line"><span class="lineno">  291</span>                <span class="comment"># build new index2word with frequency sorted words</span></div>
<div class="line"><span class="lineno">  292</span>                self.index2word.append(word)</div>
<div class="line"><span class="lineno">  293</span>        <span class="keyword">assert</span> len(self.index2word) == vocab_size, <span class="stringliteral">&#39;mismatch between vocab sizes&#39;</span></div>
<div class="line"><span class="lineno">  294</span> </div>
<div class="line"><span class="lineno">  295</span>        <span class="keywordflow">for</span> word_id, word <span class="keywordflow">in</span> enumerate(self.index2word):</div>
<div class="line"><span class="lineno">  296</span>            self.syn0[word_id] = prev_syn0[prev_vocab[word].index]</div>
<div class="line"><span class="lineno">  297</span>            self.vocab[word].index = word_id</div>
<div class="line"><span class="lineno">  298</span>            self.vocab[word].count = counts[word]</div>
<div class="line"><span class="lineno">  299</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a07255bb7fb5afd56dc4f4d313743beb9" name="a07255bb7fb5afd56dc4f4d313743beb9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07255bb7fb5afd56dc4f4d313743beb9">&#9670;&#160;</a></span>train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.wrappers.wordrank.Wordrank.train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>wr_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>corpus_file</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>out_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>size</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>window</em> = <code>15</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>symmetric</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_count</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>max_vocab_size</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sgd_num</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>lrate</em> = <code>0.001</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>period</em> = <code>10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>iter</em> = <code>90</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>epsilon</em> = <code>0.75</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dump_period</em> = <code>10</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>reg</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>beta</em> = <code>99</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss</em> = <code>'hinge'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>memory</em> = <code>4.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>np</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cleanup_files</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sorted_vocab</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ensemble</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Train model.

Parameters
----------
wr_path : str
    Absolute path to the Wordrank directory.
corpus_file : str
    Path to corpus file, expected space-separated tokens in a each line format.
out_name : str
    Name of the directory which will be created (in wordrank folder) to save embeddings and training data:
        * ``model_word_current_&lt;iter&gt;.txt`` - Word Embeddings saved after every dump_period.
        * ``model_context_current_&lt;iter&gt;.txt`` - Context Embeddings saved after every dump_period.
        * ``meta/vocab.txt`` - vocab file.
        * ``meta/wiki.toy`` - word-word concurrence values.
size : int, optional
    Dimensionality of the feature vectors.
window : int, optional
    Number of context words to the left (and to the right, if `symmetric = 1`).
symmetric : {0, 1}, optional
    If 1 - using symmetric windows, if 0 - will use only left context words.
min_count : int, optional
    Ignore all words with total frequency lower than `min_count`.
max_vocab_size : int, optional
    Upper bound on vocabulary size, i.e. keep the &lt;int&gt; most frequent words. If 0 - no limit.
sgd_num : int, optional
    Number of SGD taken for each data point.
lrate : float, optional
    Learning rate (attention: too high diverges, give Nan).
period : int, optional
    Period of xi variable updates.
iter : int, optional
    Number of iterations (epochs) over the corpus.
epsilon : float, optional
    Power scaling value for weighting function.
dump_period : int, optional
    Period after which embeddings should be dumped.
reg : int, optional
    Value of regularization parameter.
alpha : int, optional
    Alpha parameter of gamma distribution.
beta : int, optional
    Beta parameter of gamma distribution.
loss : {"logistic", "hinge"}, optional
    Name of the loss function.
memory : float, optional
    Soft limit for memory consumption, in GB.
np : int, optional
    Number of process to execute (mpirun option).
cleanup_files : bool, optional
    If True, delete directory and files used by this wrapper.
sorted_vocab : {0, 1}, optional
    If 1 - sort the vocabulary by descending frequency before assigning word indexes, otherwise - do nothing.
ensemble : {0, 1}, optional
    If 1 - use ensemble of word and context vectors.</pre> <div class="fragment"><div class="line"><span class="lineno">   84</span>              beta=99, loss=<span class="stringliteral">&#39;hinge&#39;</span>, memory=4.0, np=1, cleanup_files=<span class="keyword">False</span>, sorted_vocab=1, ensemble=0):</div>
<div class="line"><span class="lineno">   85</span>        <span class="stringliteral">&quot;&quot;&quot;Train model.</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">        ----------</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">        wr_path : str</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">            Absolute path to the Wordrank directory.</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">        corpus_file : str</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral">            Path to corpus file, expected space-separated tokens in a each line format.</span></div>
<div class="line"><span class="lineno">   93</span><span class="stringliteral">        out_name : str</span></div>
<div class="line"><span class="lineno">   94</span><span class="stringliteral">            Name of the directory which will be created (in wordrank folder) to save embeddings and training data:</span></div>
<div class="line"><span class="lineno">   95</span><span class="stringliteral">                * ``model_word_current_&lt;iter&gt;.txt`` - Word Embeddings saved after every dump_period.</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral">                * ``model_context_current_&lt;iter&gt;.txt`` - Context Embeddings saved after every dump_period.</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral">                * ``meta/vocab.txt`` - vocab file.</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">                * ``meta/wiki.toy`` - word-word concurrence values.</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">        size : int, optional</span></div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">            Dimensionality of the feature vectors.</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">        window : int, optional</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral">            Number of context words to the left (and to the right, if `symmetric = 1`).</span></div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">        symmetric : {0, 1}, optional</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">            If 1 - using symmetric windows, if 0 - will use only left context words.</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral">        min_count : int, optional</span></div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral">            Ignore all words with total frequency lower than `min_count`.</span></div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral">        max_vocab_size : int, optional</span></div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">            Upper bound on vocabulary size, i.e. keep the &lt;int&gt; most frequent words. If 0 - no limit.</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">        sgd_num : int, optional</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral">            Number of SGD taken for each data point.</span></div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral">        lrate : float, optional</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral">            Learning rate (attention: too high diverges, give Nan).</span></div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral">        period : int, optional</span></div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">            Period of xi variable updates.</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">        iter : int, optional</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral">            Number of iterations (epochs) over the corpus.</span></div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">        epsilon : float, optional</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">            Power scaling value for weighting function.</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral">        dump_period : int, optional</span></div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral">            Period after which embeddings should be dumped.</span></div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral">        reg : int, optional</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">            Value of regularization parameter.</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">        alpha : int, optional</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">            Alpha parameter of gamma distribution.</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral">        beta : int, optional</span></div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral">            Beta parameter of gamma distribution.</span></div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral">        loss : {&quot;logistic&quot;, &quot;hinge&quot;}, optional</span></div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral">            Name of the loss function.</span></div>
<div class="line"><span class="lineno">  129</span><span class="stringliteral">        memory : float, optional</span></div>
<div class="line"><span class="lineno">  130</span><span class="stringliteral">            Soft limit for memory consumption, in GB.</span></div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">        np : int, optional</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral">            Number of process to execute (mpirun option).</span></div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">        cleanup_files : bool, optional</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">            If True, delete directory and files used by this wrapper.</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">        sorted_vocab : {0, 1}, optional</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">            If 1 - sort the vocabulary by descending frequency before assigning word indexes, otherwise - do nothing.</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">        ensemble : {0, 1}, optional</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">            If 1 - use ensemble of word and context vectors.</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  141</span> </div>
<div class="line"><span class="lineno">  142</span>        <span class="comment"># prepare training data (cooccurrence matrix and vocab)</span></div>
<div class="line"><span class="lineno">  143</span>        model_dir = os.path.join(wr_path, out_name)</div>
<div class="line"><span class="lineno">  144</span>        meta_dir = os.path.join(model_dir, <span class="stringliteral">&#39;meta&#39;</span>)</div>
<div class="line"><span class="lineno">  145</span>        os.makedirs(meta_dir)</div>
<div class="line"><span class="lineno">  146</span>        logger.info(<span class="stringliteral">&quot;Dumped data will be stored in &#39;%s&#39;&quot;</span>, model_dir)</div>
<div class="line"><span class="lineno">  147</span>        copyfile(corpus_file, os.path.join(meta_dir, corpus_file.split(<span class="stringliteral">&#39;/&#39;</span>)[-1]))</div>
<div class="line"><span class="lineno">  148</span> </div>
<div class="line"><span class="lineno">  149</span>        vocab_file = os.path.join(meta_dir, <span class="stringliteral">&#39;vocab.txt&#39;</span>)</div>
<div class="line"><span class="lineno">  150</span>        temp_vocab_file = os.path.join(meta_dir, <span class="stringliteral">&#39;tempvocab.txt&#39;</span>)</div>
<div class="line"><span class="lineno">  151</span>        cooccurrence_file = os.path.join(meta_dir, <span class="stringliteral">&#39;cooccurrence&#39;</span>)</div>
<div class="line"><span class="lineno">  152</span>        cooccurrence_shuf_file = os.path.join(meta_dir, <span class="stringliteral">&#39;wiki.toy&#39;</span>)</div>
<div class="line"><span class="lineno">  153</span>        meta_file = os.path.join(meta_dir, <span class="stringliteral">&#39;meta&#39;</span>)</div>
<div class="line"><span class="lineno">  154</span> </div>
<div class="line"><span class="lineno">  155</span>        cmd_vocab_count = [</div>
<div class="line"><span class="lineno">  156</span>            os.path.join(wr_path, <span class="stringliteral">&#39;glove&#39;</span>, <span class="stringliteral">&#39;vocab_count&#39;</span>),</div>
<div class="line"><span class="lineno">  157</span>            <span class="stringliteral">&#39;-min-count&#39;</span>, str(min_count), <span class="stringliteral">&#39;-max-vocab&#39;</span>, str(max_vocab_size)</div>
<div class="line"><span class="lineno">  158</span>        ]</div>
<div class="line"><span class="lineno">  159</span>        cmd_cooccurence_count = [</div>
<div class="line"><span class="lineno">  160</span>            os.path.join(wr_path, <span class="stringliteral">&#39;glove&#39;</span>, <span class="stringliteral">&#39;cooccur&#39;</span>), <span class="stringliteral">&#39;-memory&#39;</span>, str(memory),</div>
<div class="line"><span class="lineno">  161</span>            <span class="stringliteral">&#39;-vocab-file&#39;</span>, temp_vocab_file, <span class="stringliteral">&#39;-window-size&#39;</span>, str(window), <span class="stringliteral">&#39;-symmetric&#39;</span>, str(symmetric)</div>
<div class="line"><span class="lineno">  162</span>        ]</div>
<div class="line"><span class="lineno">  163</span>        cmd_shuffle_cooccurences = [os.path.join(wr_path, <span class="stringliteral">&#39;glove&#39;</span>, <span class="stringliteral">&#39;shuffle&#39;</span>), <span class="stringliteral">&#39;-memory&#39;</span>, str(memory)]</div>
<div class="line"><span class="lineno">  164</span>        cmd_del_vocab_freq = [<span class="stringliteral">&#39;cut&#39;</span>, <span class="stringliteral">&#39;-d&#39;</span>, <span class="stringliteral">&quot; &quot;</span>, <span class="stringliteral">&#39;-f&#39;</span>, <span class="stringliteral">&#39;1&#39;</span>, temp_vocab_file]</div>
<div class="line"><span class="lineno">  165</span> </div>
<div class="line"><span class="lineno">  166</span>        commands = [cmd_vocab_count, cmd_cooccurence_count, cmd_shuffle_cooccurences]</div>
<div class="line"><span class="lineno">  167</span>        input_fnames = [</div>
<div class="line"><span class="lineno">  168</span>            os.path.join(meta_dir, os.path.split(corpus_file)[-1]),</div>
<div class="line"><span class="lineno">  169</span>            os.path.join(meta_dir, os.path.split(corpus_file)[-1]),</div>
<div class="line"><span class="lineno">  170</span>            cooccurrence_file</div>
<div class="line"><span class="lineno">  171</span>        ]</div>
<div class="line"><span class="lineno">  172</span>        output_fnames = [temp_vocab_file, cooccurrence_file, cooccurrence_shuf_file]</div>
<div class="line"><span class="lineno">  173</span> </div>
<div class="line"><span class="lineno">  174</span>        logger.info(<span class="stringliteral">&quot;Prepare training data (%s) using glove code&quot;</span>, <span class="stringliteral">&quot;, &quot;</span>.join(input_fnames))</div>
<div class="line"><span class="lineno">  175</span>        <span class="keywordflow">for</span> command, input_fname, output_fname <span class="keywordflow">in</span> zip(commands, input_fnames, output_fnames):</div>
<div class="line"><span class="lineno">  176</span>            <span class="keyword">with</span> utils.open(input_fname, <span class="stringliteral">&#39;rb&#39;</span>) <span class="keyword">as</span> r:</div>
<div class="line"><span class="lineno">  177</span>                <span class="keyword">with</span> utils.open(output_fname, <span class="stringliteral">&#39;wb&#39;</span>) <span class="keyword">as</span> w:</div>
<div class="line"><span class="lineno">  178</span>                    utils.check_output(w, args=command, stdin=r)</div>
<div class="line"><span class="lineno">  179</span> </div>
<div class="line"><span class="lineno">  180</span>        logger.info(<span class="stringliteral">&quot;Deleting frequencies from vocab file&quot;</span>)</div>
<div class="line"><span class="lineno">  181</span>        <span class="keyword">with</span> utils.open(vocab_file, <span class="stringliteral">&#39;wb&#39;</span>) <span class="keyword">as</span> w:</div>
<div class="line"><span class="lineno">  182</span>            utils.check_output(w, args=cmd_del_vocab_freq)</div>
<div class="line"><span class="lineno">  183</span> </div>
<div class="line"><span class="lineno">  184</span>        <span class="keyword">with</span> utils.open(vocab_file, <span class="stringliteral">&#39;rb&#39;</span>) <span class="keyword">as</span> f:</div>
<div class="line"><span class="lineno">  185</span>            numwords = sum(1 <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> f)</div>
<div class="line"><span class="lineno">  186</span>        <span class="keyword">with</span> utils.open(cooccurrence_shuf_file, <span class="stringliteral">&#39;rb&#39;</span>) <span class="keyword">as</span> f:</div>
<div class="line"><span class="lineno">  187</span>            numlines = sum(1 <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> f)</div>
<div class="line"><span class="lineno">  188</span>        <span class="keyword">with</span> utils.open(meta_file, <span class="stringliteral">&#39;wb&#39;</span>) <span class="keyword">as</span> f:</div>
<div class="line"><span class="lineno">  189</span>            meta_info = <span class="stringliteral">&quot;{0} {1}\n{2} {3}\n{4} {5}&quot;</span>.format(</div>
<div class="line"><span class="lineno">  190</span>                numwords, numwords, numlines, cooccurrence_shuf_file.split(<span class="stringliteral">&#39;/&#39;</span>)[-1],</div>
<div class="line"><span class="lineno">  191</span>                numwords, vocab_file.split(<span class="stringliteral">&#39;/&#39;</span>)[-1]</div>
<div class="line"><span class="lineno">  192</span>            )</div>
<div class="line"><span class="lineno">  193</span>            f.write(meta_info.encode(<span class="stringliteral">&#39;utf-8&#39;</span>))</div>
<div class="line"><span class="lineno">  194</span> </div>
<div class="line"><span class="lineno">  195</span>        <span class="keywordflow">if</span> iter % dump_period == 0:</div>
<div class="line"><span class="lineno">  196</span>            iter += 1</div>
<div class="line"><span class="lineno">  197</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  198</span>            logger.warning(</div>
<div class="line"><span class="lineno">  199</span>                <span class="stringliteral">&quot;Resultant embedding will be from %d iterations rather than the input %d iterations, &quot;</span></div>
<div class="line"><span class="lineno">  200</span>                <span class="stringliteral">&quot;as wordrank dumps the embedding only at dump_period intervals. &quot;</span></div>
<div class="line"><span class="lineno">  201</span>                <span class="stringliteral">&quot;Input an appropriate combination of parameters (iter, dump_period) &quot;</span></div>
<div class="line"><span class="lineno">  202</span>                <span class="stringliteral">&quot;such that \&quot;iter mod dump_period\&quot; is zero.&quot;</span>,</div>
<div class="line"><span class="lineno">  203</span>                iter - (iter % dump_period), iter</div>
<div class="line"><span class="lineno">  204</span>            )</div>
<div class="line"><span class="lineno">  205</span> </div>
<div class="line"><span class="lineno">  206</span>        wr_args = {</div>
<div class="line"><span class="lineno">  207</span>            <span class="stringliteral">&#39;path&#39;</span>: meta_dir,</div>
<div class="line"><span class="lineno">  208</span>            <span class="stringliteral">&#39;nthread&#39;</span>: multiprocessing.cpu_count(),</div>
<div class="line"><span class="lineno">  209</span>            <span class="stringliteral">&#39;sgd_num&#39;</span>: sgd_num,</div>
<div class="line"><span class="lineno">  210</span>            <span class="stringliteral">&#39;lrate&#39;</span>: lrate,</div>
<div class="line"><span class="lineno">  211</span>            <span class="stringliteral">&#39;period&#39;</span>: period,</div>
<div class="line"><span class="lineno">  212</span>            <span class="stringliteral">&#39;iter&#39;</span>: iter,</div>
<div class="line"><span class="lineno">  213</span>            <span class="stringliteral">&#39;epsilon&#39;</span>: epsilon,</div>
<div class="line"><span class="lineno">  214</span>            <span class="stringliteral">&#39;dump_prefix&#39;</span>: <span class="stringliteral">&#39;model&#39;</span>,</div>
<div class="line"><span class="lineno">  215</span>            <span class="stringliteral">&#39;dump_period&#39;</span>: dump_period,</div>
<div class="line"><span class="lineno">  216</span>            <span class="stringliteral">&#39;dim&#39;</span>: size,</div>
<div class="line"><span class="lineno">  217</span>            <span class="stringliteral">&#39;reg&#39;</span>: reg,</div>
<div class="line"><span class="lineno">  218</span>            <span class="stringliteral">&#39;alpha&#39;</span>: alpha,</div>
<div class="line"><span class="lineno">  219</span>            <span class="stringliteral">&#39;beta&#39;</span>: beta,</div>
<div class="line"><span class="lineno">  220</span>            <span class="stringliteral">&#39;loss&#39;</span>: loss</div>
<div class="line"><span class="lineno">  221</span>        }</div>
<div class="line"><span class="lineno">  222</span> </div>
<div class="line"><span class="lineno">  223</span>        <span class="comment"># run wordrank executable with wr_args</span></div>
<div class="line"><span class="lineno">  224</span>        cmd = [<span class="stringliteral">&#39;mpirun&#39;</span>, <span class="stringliteral">&#39;-np&#39;</span>, str(np), os.path.join(wr_path, <span class="stringliteral">&#39;wordrank&#39;</span>)]</div>
<div class="line"><span class="lineno">  225</span>        <span class="keywordflow">for</span> option, value <span class="keywordflow">in</span> wr_args.items():</div>
<div class="line"><span class="lineno">  226</span>            cmd.append(<span class="stringliteral">&#39;--%s&#39;</span> % option)</div>
<div class="line"><span class="lineno">  227</span>            cmd.append(str(value))</div>
<div class="line"><span class="lineno">  228</span>        logger.info(<span class="stringliteral">&quot;Running wordrank binary&quot;</span>)</div>
<div class="line"><span class="lineno">  229</span>        utils.check_output(args=cmd)</div>
<div class="line"><span class="lineno">  230</span> </div>
<div class="line"><span class="lineno">  231</span>        <span class="comment"># use embeddings from max. iteration&#39;s dump</span></div>
<div class="line"><span class="lineno">  232</span>        max_iter_dump = iter - (iter % dump_period)</div>
<div class="line"><span class="lineno">  233</span>        os.rename(<span class="stringliteral">&#39;model_word_%d.txt&#39;</span> % max_iter_dump, os.path.join(model_dir, <span class="stringliteral">&#39;wordrank.words&#39;</span>))</div>
<div class="line"><span class="lineno">  234</span>        os.rename(<span class="stringliteral">&#39;model_context_%d.txt&#39;</span> % max_iter_dump, os.path.join(model_dir, <span class="stringliteral">&#39;wordrank.contexts&#39;</span>))</div>
<div class="line"><span class="lineno">  235</span>        model = cls.load_wordrank_model(</div>
<div class="line"><span class="lineno">  236</span>            os.path.join(model_dir, <span class="stringliteral">&#39;wordrank.words&#39;</span>), vocab_file,</div>
<div class="line"><span class="lineno">  237</span>            os.path.join(model_dir, <span class="stringliteral">&#39;wordrank.contexts&#39;</span>), sorted_vocab, ensemble</div>
<div class="line"><span class="lineno">  238</span>        )</div>
<div class="line"><span class="lineno">  239</span> </div>
<div class="line"><span class="lineno">  240</span>        <span class="keywordflow">if</span> cleanup_files:</div>
<div class="line"><span class="lineno">  241</span>            rmtree(model_dir)</div>
<div class="line"><span class="lineno">  242</span>        <span class="keywordflow">return</span> model</div>
<div class="line"><span class="lineno">  243</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a71eacd5815e233f25c679fddd989afd9" name="a71eacd5815e233f25c679fddd989afd9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a71eacd5815e233f25c679fddd989afd9">&#9670;&#160;</a></span>index2word</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.wrappers.wordrank.Wordrank.index2word</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad1a87a5d78e6be2394273061090fc722" name="ad1a87a5d78e6be2394273061090fc722"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad1a87a5d78e6be2394273061090fc722">&#9670;&#160;</a></span>syn0</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.wrappers.wordrank.Wordrank.syn0</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/rafael/Documents/GitHub/PUC-GCES-PY/Tp-GCS-Rafael-Augusto/venv/lib/python3.9/site-packages/gensim/models/wrappers/<a class="el" href="wordrank_8py.html">wordrank.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
