<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.calibration Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1calibration.html">calibration</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">sklearn.calibration Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1calibration_1_1___calibrated_classifier.html">_CalibratedClassifier</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1calibration_1_1___sigmoid_calibration.html">_SigmoidCalibration</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1calibration_1_1_calibrated_classifier_c_v.html">CalibratedClassifierCV</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsklearn_1_1calibration_1_1_calibration_display.html">CalibrationDisplay</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a571a6d44764643fd897c4f3fd2d0a5c8" id="r_a571a6d44764643fd897c4f3fd2d0a5c8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1calibration.html#a571a6d44764643fd897c4f3fd2d0a5c8">_fit_classifier_calibrator_pair</a> (estimator, X, y, train, test, supports_sw, method, classes, sample_weight=None, **fit_params)</td></tr>
<tr class="separator:a571a6d44764643fd897c4f3fd2d0a5c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38df482a0f165be5186954e1c8248843" id="r_a38df482a0f165be5186954e1c8248843"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1calibration.html#a38df482a0f165be5186954e1c8248843">_get_prediction_method</a> (clf)</td></tr>
<tr class="separator:a38df482a0f165be5186954e1c8248843"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a091f82025abb8d5df92d8457ced85314" id="r_a091f82025abb8d5df92d8457ced85314"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1calibration.html#a091f82025abb8d5df92d8457ced85314">_compute_predictions</a> (pred_method, method_name, X, n_classes)</td></tr>
<tr class="separator:a091f82025abb8d5df92d8457ced85314"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37b168ee9a0c3d0f68a5bba458e35541" id="r_a37b168ee9a0c3d0f68a5bba458e35541"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1calibration.html#a37b168ee9a0c3d0f68a5bba458e35541">_fit_calibrator</a> (clf, predictions, y, classes, method, sample_weight=None)</td></tr>
<tr class="separator:a37b168ee9a0c3d0f68a5bba458e35541"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2cf175f28d439463ff08de2ec1d9df0f" id="r_a2cf175f28d439463ff08de2ec1d9df0f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1calibration.html#a2cf175f28d439463ff08de2ec1d9df0f">_sigmoid_calibration</a> (predictions, y, sample_weight=None)</td></tr>
<tr class="separator:a2cf175f28d439463ff08de2ec1d9df0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae22395cc576d9471757fca2ba2d44209" id="r_ae22395cc576d9471757fca2ba2d44209"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1calibration.html#ae22395cc576d9471757fca2ba2d44209">calibration_curve</a> (y_true, y_prob, *pos_label=None, normalize=&quot;deprecated&quot;, n_bins=5, strategy=&quot;uniform&quot;)</td></tr>
<tr class="separator:ae22395cc576d9471757fca2ba2d44209"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Calibration of predicted probabilities.</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a091f82025abb8d5df92d8457ced85314" name="a091f82025abb8d5df92d8457ced85314"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a091f82025abb8d5df92d8457ced85314">&#9670;&#160;</a></span>_compute_predictions()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.calibration._compute_predictions </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pred_method</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_classes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Return predictions for `X` and reshape binary outputs to shape
(n_samples, 1).

Parameters
----------
pred_method : callable
    Prediction method.

method_name: str
    Name of the prediction method

X : array-like or None
    Data used to obtain predictions.

n_classes : int
    Number of classes present.

Returns
-------
predictions : array-like, shape (X.shape[0], len(clf.classes_))
    The predictions. Note if there are 2 classes, array is of shape
    (X.shape[0], 1).
</pre> <div class="fragment"><div class="line"><span class="lineno">  618</span><span class="keyword">def </span>_compute_predictions(pred_method, method_name, X, n_classes):</div>
<div class="line"><span class="lineno">  619</span>    <span class="stringliteral">&quot;&quot;&quot;Return predictions for `X` and reshape binary outputs to shape</span></div>
<div class="line"><span class="lineno">  620</span><span class="stringliteral">    (n_samples, 1).</span></div>
<div class="line"><span class="lineno">  621</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  622</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  623</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  624</span><span class="stringliteral">    pred_method : callable</span></div>
<div class="line"><span class="lineno">  625</span><span class="stringliteral">        Prediction method.</span></div>
<div class="line"><span class="lineno">  626</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  627</span><span class="stringliteral">    method_name: str</span></div>
<div class="line"><span class="lineno">  628</span><span class="stringliteral">        Name of the prediction method</span></div>
<div class="line"><span class="lineno">  629</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  630</span><span class="stringliteral">    X : array-like or None</span></div>
<div class="line"><span class="lineno">  631</span><span class="stringliteral">        Data used to obtain predictions.</span></div>
<div class="line"><span class="lineno">  632</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  633</span><span class="stringliteral">    n_classes : int</span></div>
<div class="line"><span class="lineno">  634</span><span class="stringliteral">        Number of classes present.</span></div>
<div class="line"><span class="lineno">  635</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  636</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  637</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  638</span><span class="stringliteral">    predictions : array-like, shape (X.shape[0], len(clf.classes_))</span></div>
<div class="line"><span class="lineno">  639</span><span class="stringliteral">        The predictions. Note if there are 2 classes, array is of shape</span></div>
<div class="line"><span class="lineno">  640</span><span class="stringliteral">        (X.shape[0], 1).</span></div>
<div class="line"><span class="lineno">  641</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  642</span>    predictions = pred_method(X=X)</div>
<div class="line"><span class="lineno">  643</span> </div>
<div class="line"><span class="lineno">  644</span>    <span class="keywordflow">if</span> method_name == <span class="stringliteral">&quot;decision_function&quot;</span>:</div>
<div class="line"><span class="lineno">  645</span>        <span class="keywordflow">if</span> predictions.ndim == 1:</div>
<div class="line"><span class="lineno">  646</span>            predictions = predictions[:, np.newaxis]</div>
<div class="line"><span class="lineno">  647</span>    <span class="keywordflow">elif</span> method_name == <span class="stringliteral">&quot;predict_proba&quot;</span>:</div>
<div class="line"><span class="lineno">  648</span>        <span class="keywordflow">if</span> n_classes == 2:</div>
<div class="line"><span class="lineno">  649</span>            predictions = predictions[:, 1:]</div>
<div class="line"><span class="lineno">  650</span>    <span class="keywordflow">else</span>:  <span class="comment"># pragma: no cover</span></div>
<div class="line"><span class="lineno">  651</span>        <span class="comment"># this branch should be unreachable.</span></div>
<div class="line"><span class="lineno">  652</span>        <span class="keywordflow">raise</span> ValueError(f<span class="stringliteral">&quot;Invalid prediction method: {method_name}&quot;</span>)</div>
<div class="line"><span class="lineno">  653</span>    <span class="keywordflow">return</span> predictions</div>
<div class="line"><span class="lineno">  654</span> </div>
<div class="line"><span class="lineno">  655</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a37b168ee9a0c3d0f68a5bba458e35541" name="a37b168ee9a0c3d0f68a5bba458e35541"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a37b168ee9a0c3d0f68a5bba458e35541">&#9670;&#160;</a></span>_fit_calibrator()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.calibration._fit_calibrator </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>predictions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>classes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Fit calibrator(s) and return a `_CalibratedClassifier`
instance.

`n_classes` (i.e. `len(clf.classes_)`) calibrators are fitted.
However, if `n_classes` equals 2, one calibrator is fitted.

Parameters
----------
clf : estimator instance
    Fitted classifier.

predictions : array-like, shape (n_samples, n_classes) or (n_samples, 1) \
                when binary.
    Raw predictions returned by the un-calibrated base classifier.

y : array-like, shape (n_samples,)
    The targets.

classes : ndarray, shape (n_classes,)
    All the prediction classes.

method : {'sigmoid', 'isotonic'}
    The method to use for calibration.

sample_weight : ndarray, shape (n_samples,), default=None
    Sample weights. If None, then samples are equally weighted.

Returns
-------
pipeline : _CalibratedClassifier instance
</pre> <div class="fragment"><div class="line"><span class="lineno">  656</span><span class="keyword">def </span>_fit_calibrator(clf, predictions, y, classes, method, sample_weight=None):</div>
<div class="line"><span class="lineno">  657</span>    <span class="stringliteral">&quot;&quot;&quot;Fit calibrator(s) and return a `_CalibratedClassifier`</span></div>
<div class="line"><span class="lineno">  658</span><span class="stringliteral">    instance.</span></div>
<div class="line"><span class="lineno">  659</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  660</span><span class="stringliteral">    `n_classes` (i.e. `len(clf.classes_)`) calibrators are fitted.</span></div>
<div class="line"><span class="lineno">  661</span><span class="stringliteral">    However, if `n_classes` equals 2, one calibrator is fitted.</span></div>
<div class="line"><span class="lineno">  662</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  663</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  664</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  665</span><span class="stringliteral">    clf : estimator instance</span></div>
<div class="line"><span class="lineno">  666</span><span class="stringliteral">        Fitted classifier.</span></div>
<div class="line"><span class="lineno">  667</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  668</span><span class="stringliteral">    predictions : array-like, shape (n_samples, n_classes) or (n_samples, 1) \</span></div>
<div class="line"><span class="lineno">  669</span><span class="stringliteral">                    when binary.</span></div>
<div class="line"><span class="lineno">  670</span><span class="stringliteral">        Raw predictions returned by the un-calibrated base classifier.</span></div>
<div class="line"><span class="lineno">  671</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  672</span><span class="stringliteral">    y : array-like, shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  673</span><span class="stringliteral">        The targets.</span></div>
<div class="line"><span class="lineno">  674</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  675</span><span class="stringliteral">    classes : ndarray, shape (n_classes,)</span></div>
<div class="line"><span class="lineno">  676</span><span class="stringliteral">        All the prediction classes.</span></div>
<div class="line"><span class="lineno">  677</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  678</span><span class="stringliteral">    method : {&#39;sigmoid&#39;, &#39;isotonic&#39;}</span></div>
<div class="line"><span class="lineno">  679</span><span class="stringliteral">        The method to use for calibration.</span></div>
<div class="line"><span class="lineno">  680</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  681</span><span class="stringliteral">    sample_weight : ndarray, shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  682</span><span class="stringliteral">        Sample weights. If None, then samples are equally weighted.</span></div>
<div class="line"><span class="lineno">  683</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  684</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  685</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  686</span><span class="stringliteral">    pipeline : _CalibratedClassifier instance</span></div>
<div class="line"><span class="lineno">  687</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  688</span>    Y = label_binarize(y, classes=classes)</div>
<div class="line"><span class="lineno">  689</span>    label_encoder = LabelEncoder().fit(classes)</div>
<div class="line"><span class="lineno">  690</span>    pos_class_indices = label_encoder.transform(clf.classes_)</div>
<div class="line"><span class="lineno">  691</span>    calibrators = []</div>
<div class="line"><span class="lineno">  692</span>    <span class="keywordflow">for</span> class_idx, this_pred <span class="keywordflow">in</span> zip(pos_class_indices, predictions.T):</div>
<div class="line"><span class="lineno">  693</span>        <span class="keywordflow">if</span> method == <span class="stringliteral">&quot;isotonic&quot;</span>:</div>
<div class="line"><span class="lineno">  694</span>            calibrator = IsotonicRegression(out_of_bounds=<span class="stringliteral">&quot;clip&quot;</span>)</div>
<div class="line"><span class="lineno">  695</span>        <span class="keywordflow">else</span>:  <span class="comment"># &quot;sigmoid&quot;</span></div>
<div class="line"><span class="lineno">  696</span>            calibrator = _SigmoidCalibration()</div>
<div class="line"><span class="lineno">  697</span>        calibrator.fit(this_pred, Y[:, class_idx], sample_weight)</div>
<div class="line"><span class="lineno">  698</span>        calibrators.append(calibrator)</div>
<div class="line"><span class="lineno">  699</span> </div>
<div class="line"><span class="lineno">  700</span>    pipeline = _CalibratedClassifier(clf, calibrators, method=method, classes=classes)</div>
<div class="line"><span class="lineno">  701</span>    <span class="keywordflow">return</span> pipeline</div>
<div class="line"><span class="lineno">  702</span> </div>
<div class="line"><span class="lineno">  703</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a571a6d44764643fd897c4f3fd2d0a5c8" name="a571a6d44764643fd897c4f3fd2d0a5c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a571a6d44764643fd897c4f3fd2d0a5c8">&#9670;&#160;</a></span>_fit_classifier_calibrator_pair()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.calibration._fit_classifier_calibrator_pair </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>estimator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>train</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>test</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>supports_sw</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>method</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>classes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>fit_params</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Fit a classifier/calibration pair on a given train/test split.

Fit the classifier on the train set, compute its predictions on the test
set and use the predictions as input to fit the calibrator along with the
test labels.

Parameters
----------
estimator : estimator instance
    Cloned base estimator.

X : array-like, shape (n_samples, n_features)
    Sample data.

y : array-like, shape (n_samples,)
    Targets.

train : ndarray, shape (n_train_indices,)
    Indices of the training subset.

test : ndarray, shape (n_test_indices,)
    Indices of the testing subset.

supports_sw : bool
    Whether or not the `estimator` supports sample weights.

method : {'sigmoid', 'isotonic'}
    Method to use for calibration.

classes : ndarray, shape (n_classes,)
    The target classes.

sample_weight : array-like, default=None
    Sample weights for `X`.

**fit_params : dict
    Parameters to pass to the `fit` method of the underlying
    classifier.

Returns
-------
calibrated_classifier : _CalibratedClassifier instance
</pre> <div class="fragment"><div class="line"><span class="lineno">  526</span>):</div>
<div class="line"><span class="lineno">  527</span>    <span class="stringliteral">&quot;&quot;&quot;Fit a classifier/calibration pair on a given train/test split.</span></div>
<div class="line"><span class="lineno">  528</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  529</span><span class="stringliteral">    Fit the classifier on the train set, compute its predictions on the test</span></div>
<div class="line"><span class="lineno">  530</span><span class="stringliteral">    set and use the predictions as input to fit the calibrator along with the</span></div>
<div class="line"><span class="lineno">  531</span><span class="stringliteral">    test labels.</span></div>
<div class="line"><span class="lineno">  532</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  533</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  534</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  535</span><span class="stringliteral">    estimator : estimator instance</span></div>
<div class="line"><span class="lineno">  536</span><span class="stringliteral">        Cloned base estimator.</span></div>
<div class="line"><span class="lineno">  537</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  538</span><span class="stringliteral">    X : array-like, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  539</span><span class="stringliteral">        Sample data.</span></div>
<div class="line"><span class="lineno">  540</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  541</span><span class="stringliteral">    y : array-like, shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  542</span><span class="stringliteral">        Targets.</span></div>
<div class="line"><span class="lineno">  543</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  544</span><span class="stringliteral">    train : ndarray, shape (n_train_indices,)</span></div>
<div class="line"><span class="lineno">  545</span><span class="stringliteral">        Indices of the training subset.</span></div>
<div class="line"><span class="lineno">  546</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  547</span><span class="stringliteral">    test : ndarray, shape (n_test_indices,)</span></div>
<div class="line"><span class="lineno">  548</span><span class="stringliteral">        Indices of the testing subset.</span></div>
<div class="line"><span class="lineno">  549</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  550</span><span class="stringliteral">    supports_sw : bool</span></div>
<div class="line"><span class="lineno">  551</span><span class="stringliteral">        Whether or not the `estimator` supports sample weights.</span></div>
<div class="line"><span class="lineno">  552</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  553</span><span class="stringliteral">    method : {&#39;sigmoid&#39;, &#39;isotonic&#39;}</span></div>
<div class="line"><span class="lineno">  554</span><span class="stringliteral">        Method to use for calibration.</span></div>
<div class="line"><span class="lineno">  555</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  556</span><span class="stringliteral">    classes : ndarray, shape (n_classes,)</span></div>
<div class="line"><span class="lineno">  557</span><span class="stringliteral">        The target classes.</span></div>
<div class="line"><span class="lineno">  558</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  559</span><span class="stringliteral">    sample_weight : array-like, default=None</span></div>
<div class="line"><span class="lineno">  560</span><span class="stringliteral">        Sample weights for `X`.</span></div>
<div class="line"><span class="lineno">  561</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  562</span><span class="stringliteral">    **fit_params : dict</span></div>
<div class="line"><span class="lineno">  563</span><span class="stringliteral">        Parameters to pass to the `fit` method of the underlying</span></div>
<div class="line"><span class="lineno">  564</span><span class="stringliteral">        classifier.</span></div>
<div class="line"><span class="lineno">  565</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  566</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  567</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  568</span><span class="stringliteral">    calibrated_classifier : _CalibratedClassifier instance</span></div>
<div class="line"><span class="lineno">  569</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  570</span>    fit_params_train = _check_fit_params(X, fit_params, train)</div>
<div class="line"><span class="lineno">  571</span>    X_train, y_train = _safe_indexing(X, train), _safe_indexing(y, train)</div>
<div class="line"><span class="lineno">  572</span>    X_test, y_test = _safe_indexing(X, test), _safe_indexing(y, test)</div>
<div class="line"><span class="lineno">  573</span> </div>
<div class="line"><span class="lineno">  574</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> supports_sw:</div>
<div class="line"><span class="lineno">  575</span>        sw_train = _safe_indexing(sample_weight, train)</div>
<div class="line"><span class="lineno">  576</span>        estimator.fit(X_train, y_train, sample_weight=sw_train, **fit_params_train)</div>
<div class="line"><span class="lineno">  577</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  578</span>        estimator.fit(X_train, y_train, **fit_params_train)</div>
<div class="line"><span class="lineno">  579</span> </div>
<div class="line"><span class="lineno">  580</span>    n_classes = len(classes)</div>
<div class="line"><span class="lineno">  581</span>    pred_method, method_name = _get_prediction_method(estimator)</div>
<div class="line"><span class="lineno">  582</span>    predictions = _compute_predictions(pred_method, method_name, X_test, n_classes)</div>
<div class="line"><span class="lineno">  583</span> </div>
<div class="line"><span class="lineno">  584</span>    sw_test = <span class="keywordtype">None</span> <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> _safe_indexing(sample_weight, test)</div>
<div class="line"><span class="lineno">  585</span>    calibrated_classifier = _fit_calibrator(</div>
<div class="line"><span class="lineno">  586</span>        estimator, predictions, y_test, classes, method, sample_weight=sw_test</div>
<div class="line"><span class="lineno">  587</span>    )</div>
<div class="line"><span class="lineno">  588</span>    <span class="keywordflow">return</span> calibrated_classifier</div>
<div class="line"><span class="lineno">  589</span> </div>
<div class="line"><span class="lineno">  590</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a38df482a0f165be5186954e1c8248843" name="a38df482a0f165be5186954e1c8248843"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38df482a0f165be5186954e1c8248843">&#9670;&#160;</a></span>_get_prediction_method()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.calibration._get_prediction_method </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clf</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Return prediction method.

`decision_function` method of `clf` returned, if it
exists, otherwise `predict_proba` method returned.

Parameters
----------
clf : Estimator instance
    Fitted classifier to obtain the prediction method from.

Returns
-------
prediction_method : callable
    The prediction method.
method_name : str
    The name of the prediction method.
</pre> <div class="fragment"><div class="line"><span class="lineno">  591</span><span class="keyword">def </span>_get_prediction_method(clf):</div>
<div class="line"><span class="lineno">  592</span>    <span class="stringliteral">&quot;&quot;&quot;Return prediction method.</span></div>
<div class="line"><span class="lineno">  593</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  594</span><span class="stringliteral">    `decision_function` method of `clf` returned, if it</span></div>
<div class="line"><span class="lineno">  595</span><span class="stringliteral">    exists, otherwise `predict_proba` method returned.</span></div>
<div class="line"><span class="lineno">  596</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  597</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  598</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  599</span><span class="stringliteral">    clf : Estimator instance</span></div>
<div class="line"><span class="lineno">  600</span><span class="stringliteral">        Fitted classifier to obtain the prediction method from.</span></div>
<div class="line"><span class="lineno">  601</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  602</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  603</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  604</span><span class="stringliteral">    prediction_method : callable</span></div>
<div class="line"><span class="lineno">  605</span><span class="stringliteral">        The prediction method.</span></div>
<div class="line"><span class="lineno">  606</span><span class="stringliteral">    method_name : str</span></div>
<div class="line"><span class="lineno">  607</span><span class="stringliteral">        The name of the prediction method.</span></div>
<div class="line"><span class="lineno">  608</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  609</span>    <span class="keywordflow">if</span> hasattr(clf, <span class="stringliteral">&quot;decision_function&quot;</span>):</div>
<div class="line"><span class="lineno">  610</span>        method = getattr(clf, <span class="stringliteral">&quot;decision_function&quot;</span>)</div>
<div class="line"><span class="lineno">  611</span>        <span class="keywordflow">return</span> method, <span class="stringliteral">&quot;decision_function&quot;</span></div>
<div class="line"><span class="lineno">  612</span> </div>
<div class="line"><span class="lineno">  613</span>    <span class="keywordflow">if</span> hasattr(clf, <span class="stringliteral">&quot;predict_proba&quot;</span>):</div>
<div class="line"><span class="lineno">  614</span>        method = getattr(clf, <span class="stringliteral">&quot;predict_proba&quot;</span>)</div>
<div class="line"><span class="lineno">  615</span>        <span class="keywordflow">return</span> method, <span class="stringliteral">&quot;predict_proba&quot;</span></div>
<div class="line"><span class="lineno">  616</span> </div>
<div class="line"><span class="lineno">  617</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2cf175f28d439463ff08de2ec1d9df0f" name="a2cf175f28d439463ff08de2ec1d9df0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2cf175f28d439463ff08de2ec1d9df0f">&#9670;&#160;</a></span>_sigmoid_calibration()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.calibration._sigmoid_calibration </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>predictions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sample_weight</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Probability Calibration with sigmoid method (Platt 2000)

Parameters
----------
predictions : ndarray of shape (n_samples,)
    The decision function or predict proba for the samples.

y : ndarray of shape (n_samples,)
    The targets.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights. If None, then samples are equally weighted.

Returns
-------
a : float
    The slope.

b : float
    The intercept.

References
----------
Platt, "Probabilistic Outputs for Support Vector Machines"
</pre> <div class="fragment"><div class="line"><span class="lineno">  785</span><span class="keyword">def </span>_sigmoid_calibration(predictions, y, sample_weight=None):</div>
<div class="line"><span class="lineno">  786</span>    <span class="stringliteral">&quot;&quot;&quot;Probability Calibration with sigmoid method (Platt 2000)</span></div>
<div class="line"><span class="lineno">  787</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  788</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  789</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  790</span><span class="stringliteral">    predictions : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  791</span><span class="stringliteral">        The decision function or predict proba for the samples.</span></div>
<div class="line"><span class="lineno">  792</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  793</span><span class="stringliteral">    y : ndarray of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  794</span><span class="stringliteral">        The targets.</span></div>
<div class="line"><span class="lineno">  795</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  796</span><span class="stringliteral">    sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><span class="lineno">  797</span><span class="stringliteral">        Sample weights. If None, then samples are equally weighted.</span></div>
<div class="line"><span class="lineno">  798</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  799</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  800</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  801</span><span class="stringliteral">    a : float</span></div>
<div class="line"><span class="lineno">  802</span><span class="stringliteral">        The slope.</span></div>
<div class="line"><span class="lineno">  803</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  804</span><span class="stringliteral">    b : float</span></div>
<div class="line"><span class="lineno">  805</span><span class="stringliteral">        The intercept.</span></div>
<div class="line"><span class="lineno">  806</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  807</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  808</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  809</span><span class="stringliteral">    Platt, &quot;Probabilistic Outputs for Support Vector Machines&quot;</span></div>
<div class="line"><span class="lineno">  810</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  811</span>    predictions = column_or_1d(predictions)</div>
<div class="line"><span class="lineno">  812</span>    y = column_or_1d(y)</div>
<div class="line"><span class="lineno">  813</span> </div>
<div class="line"><span class="lineno">  814</span>    F = predictions  <span class="comment"># F follows Platt&#39;s notations</span></div>
<div class="line"><span class="lineno">  815</span> </div>
<div class="line"><span class="lineno">  816</span>    <span class="comment"># Bayesian priors (see Platt end of section 2.2):</span></div>
<div class="line"><span class="lineno">  817</span>    <span class="comment"># It corresponds to the number of samples, taking into account the</span></div>
<div class="line"><span class="lineno">  818</span>    <span class="comment"># `sample_weight`.</span></div>
<div class="line"><span class="lineno">  819</span>    mask_negative_samples = y &lt;= 0</div>
<div class="line"><span class="lineno">  820</span>    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  821</span>        prior0 = (sample_weight[mask_negative_samples]).sum()</div>
<div class="line"><span class="lineno">  822</span>        prior1 = (sample_weight[~mask_negative_samples]).sum()</div>
<div class="line"><span class="lineno">  823</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  824</span>        prior0 = float(np.sum(mask_negative_samples))</div>
<div class="line"><span class="lineno">  825</span>        prior1 = y.shape[0] - prior0</div>
<div class="line"><span class="lineno">  826</span>    T = np.zeros_like(y, dtype=np.float64)</div>
<div class="line"><span class="lineno">  827</span>    T[y &gt; 0] = (prior1 + 1.0) / (prior1 + 2.0)</div>
<div class="line"><span class="lineno">  828</span>    T[y &lt;= 0] = 1.0 / (prior0 + 2.0)</div>
<div class="line"><span class="lineno">  829</span>    T1 = 1.0 - T</div>
<div class="line"><span class="lineno">  830</span> </div>
<div class="line"><span class="lineno">  831</span>    <span class="keyword">def </span>objective(AB):</div>
<div class="line"><span class="lineno">  832</span>        <span class="comment"># From Platt (beginning of Section 2.2)</span></div>
<div class="line"><span class="lineno">  833</span>        P = expit(-(AB[0] * F + AB[1]))</div>
<div class="line"><span class="lineno">  834</span>        loss = -(xlogy(T, P) + xlogy(T1, 1.0 - P))</div>
<div class="line"><span class="lineno">  835</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  836</span>            <span class="keywordflow">return</span> (sample_weight * loss).sum()</div>
<div class="line"><span class="lineno">  837</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  838</span>            <span class="keywordflow">return</span> loss.sum()</div>
<div class="line"><span class="lineno">  839</span> </div>
<div class="line"><span class="lineno">  840</span>    <span class="keyword">def </span>grad(AB):</div>
<div class="line"><span class="lineno">  841</span>        <span class="comment"># gradient of the objective function</span></div>
<div class="line"><span class="lineno">  842</span>        P = expit(-(AB[0] * F + AB[1]))</div>
<div class="line"><span class="lineno">  843</span>        TEP_minus_T1P = T - P</div>
<div class="line"><span class="lineno">  844</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  845</span>            TEP_minus_T1P *= sample_weight</div>
<div class="line"><span class="lineno">  846</span>        dA = np.dot(TEP_minus_T1P, F)</div>
<div class="line"><span class="lineno">  847</span>        dB = np.sum(TEP_minus_T1P)</div>
<div class="line"><span class="lineno">  848</span>        <span class="keywordflow">return</span> np.array([dA, dB])</div>
<div class="line"><span class="lineno">  849</span> </div>
<div class="line"><span class="lineno">  850</span>    AB0 = np.array([0.0, log((prior0 + 1.0) / (prior1 + 1.0))])</div>
<div class="line"><span class="lineno">  851</span>    AB_ = fmin_bfgs(objective, AB0, fprime=grad, disp=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  852</span>    <span class="keywordflow">return</span> AB_[0], AB_[1]</div>
<div class="line"><span class="lineno">  853</span> </div>
<div class="line"><span class="lineno">  854</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae22395cc576d9471757fca2ba2d44209" name="ae22395cc576d9471757fca2ba2d44209"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae22395cc576d9471757fca2ba2d44209">&#9670;&#160;</a></span>calibration_curve()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.calibration.calibration_curve </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_prob</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>pos_label</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize</em> = <code>&quot;deprecated&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_bins</em> = <code>5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>strategy</em> = <code>&quot;uniform&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute true and predicted probabilities for a calibration curve.

The method assumes the inputs come from a binary classifier, and
discretize the [0, 1] interval into bins.

Calibration curves may also be referred to as reliability diagrams.

Read more in the :ref:`User Guide &lt;calibration&gt;`.

Parameters
----------
y_true : array-like of shape (n_samples,)
    True targets.

y_prob : array-like of shape (n_samples,)
    Probabilities of the positive class.

pos_label : int or str, default=None
    The label of the positive class.

    .. versionadded:: 1.1

normalize : bool, default="deprecated"
    Whether y_prob needs to be normalized into the [0, 1] interval, i.e.
    is not a proper probability. If True, the smallest value in y_prob
    is linearly mapped onto 0 and the largest one onto 1.

    .. deprecated:: 1.1
        The normalize argument is deprecated in v1.1 and will be removed in v1.3.
        Explicitly normalizing `y_prob` will reproduce this behavior, but it is
        recommended that a proper probability is used (i.e. a classifier's
        `predict_proba` positive class).

n_bins : int, default=5
    Number of bins to discretize the [0, 1] interval. A bigger number
    requires more data. Bins with no samples (i.e. without
    corresponding values in `y_prob`) will not be returned, thus the
    returned arrays may have less than `n_bins` values.

strategy : {'uniform', 'quantile'}, default='uniform'
    Strategy used to define the widths of the bins.

    uniform
        The bins have identical widths.
    quantile
        The bins have the same number of samples and depend on `y_prob`.

Returns
-------
prob_true : ndarray of shape (n_bins,) or smaller
    The proportion of samples whose class is the positive class, in each
    bin (fraction of positives).

prob_pred : ndarray of shape (n_bins,) or smaller
    The mean predicted probability in each bin.

References
----------
Alexandru Niculescu-Mizil and Rich Caruana (2005) Predicting Good
Probabilities With Supervised Learning, in Proceedings of the 22nd
International Conference on Machine Learning (ICML).
See section 4 (Qualitative Analysis of Predictions).

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.calibration import calibration_curve
&gt;&gt;&gt; y_true = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1])
&gt;&gt;&gt; y_pred = np.array([0.1, 0.2, 0.3, 0.4, 0.65, 0.7, 0.8, 0.9,  1.])
&gt;&gt;&gt; prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=3)
&gt;&gt;&gt; prob_true
array([0. , 0.5, 1. ])
&gt;&gt;&gt; prob_pred
array([0.2  , 0.525, 0.85 ])
</pre> <div class="fragment"><div class="line"><span class="lineno">  918</span>):</div>
<div class="line"><span class="lineno">  919</span>    <span class="stringliteral">&quot;&quot;&quot;Compute true and predicted probabilities for a calibration curve.</span></div>
<div class="line"><span class="lineno">  920</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  921</span><span class="stringliteral">    The method assumes the inputs come from a binary classifier, and</span></div>
<div class="line"><span class="lineno">  922</span><span class="stringliteral">    discretize the [0, 1] interval into bins.</span></div>
<div class="line"><span class="lineno">  923</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  924</span><span class="stringliteral">    Calibration curves may also be referred to as reliability diagrams.</span></div>
<div class="line"><span class="lineno">  925</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  926</span><span class="stringliteral">    Read more in the :ref:`User Guide &lt;calibration&gt;`.</span></div>
<div class="line"><span class="lineno">  927</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  928</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  929</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  930</span><span class="stringliteral">    y_true : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  931</span><span class="stringliteral">        True targets.</span></div>
<div class="line"><span class="lineno">  932</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  933</span><span class="stringliteral">    y_prob : array-like of shape (n_samples,)</span></div>
<div class="line"><span class="lineno">  934</span><span class="stringliteral">        Probabilities of the positive class.</span></div>
<div class="line"><span class="lineno">  935</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  936</span><span class="stringliteral">    pos_label : int or str, default=None</span></div>
<div class="line"><span class="lineno">  937</span><span class="stringliteral">        The label of the positive class.</span></div>
<div class="line"><span class="lineno">  938</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  939</span><span class="stringliteral">        .. versionadded:: 1.1</span></div>
<div class="line"><span class="lineno">  940</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  941</span><span class="stringliteral">    normalize : bool, default=&quot;deprecated&quot;</span></div>
<div class="line"><span class="lineno">  942</span><span class="stringliteral">        Whether y_prob needs to be normalized into the [0, 1] interval, i.e.</span></div>
<div class="line"><span class="lineno">  943</span><span class="stringliteral">        is not a proper probability. If True, the smallest value in y_prob</span></div>
<div class="line"><span class="lineno">  944</span><span class="stringliteral">        is linearly mapped onto 0 and the largest one onto 1.</span></div>
<div class="line"><span class="lineno">  945</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  946</span><span class="stringliteral">        .. deprecated:: 1.1</span></div>
<div class="line"><span class="lineno">  947</span><span class="stringliteral">            The normalize argument is deprecated in v1.1 and will be removed in v1.3.</span></div>
<div class="line"><span class="lineno">  948</span><span class="stringliteral">            Explicitly normalizing `y_prob` will reproduce this behavior, but it is</span></div>
<div class="line"><span class="lineno">  949</span><span class="stringliteral">            recommended that a proper probability is used (i.e. a classifier&#39;s</span></div>
<div class="line"><span class="lineno">  950</span><span class="stringliteral">            `predict_proba` positive class).</span></div>
<div class="line"><span class="lineno">  951</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  952</span><span class="stringliteral">    n_bins : int, default=5</span></div>
<div class="line"><span class="lineno">  953</span><span class="stringliteral">        Number of bins to discretize the [0, 1] interval. A bigger number</span></div>
<div class="line"><span class="lineno">  954</span><span class="stringliteral">        requires more data. Bins with no samples (i.e. without</span></div>
<div class="line"><span class="lineno">  955</span><span class="stringliteral">        corresponding values in `y_prob`) will not be returned, thus the</span></div>
<div class="line"><span class="lineno">  956</span><span class="stringliteral">        returned arrays may have less than `n_bins` values.</span></div>
<div class="line"><span class="lineno">  957</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  958</span><span class="stringliteral">    strategy : {&#39;uniform&#39;, &#39;quantile&#39;}, default=&#39;uniform&#39;</span></div>
<div class="line"><span class="lineno">  959</span><span class="stringliteral">        Strategy used to define the widths of the bins.</span></div>
<div class="line"><span class="lineno">  960</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  961</span><span class="stringliteral">        uniform</span></div>
<div class="line"><span class="lineno">  962</span><span class="stringliteral">            The bins have identical widths.</span></div>
<div class="line"><span class="lineno">  963</span><span class="stringliteral">        quantile</span></div>
<div class="line"><span class="lineno">  964</span><span class="stringliteral">            The bins have the same number of samples and depend on `y_prob`.</span></div>
<div class="line"><span class="lineno">  965</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  966</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  967</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  968</span><span class="stringliteral">    prob_true : ndarray of shape (n_bins,) or smaller</span></div>
<div class="line"><span class="lineno">  969</span><span class="stringliteral">        The proportion of samples whose class is the positive class, in each</span></div>
<div class="line"><span class="lineno">  970</span><span class="stringliteral">        bin (fraction of positives).</span></div>
<div class="line"><span class="lineno">  971</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  972</span><span class="stringliteral">    prob_pred : ndarray of shape (n_bins,) or smaller</span></div>
<div class="line"><span class="lineno">  973</span><span class="stringliteral">        The mean predicted probability in each bin.</span></div>
<div class="line"><span class="lineno">  974</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  975</span><span class="stringliteral">    References</span></div>
<div class="line"><span class="lineno">  976</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  977</span><span class="stringliteral">    Alexandru Niculescu-Mizil and Rich Caruana (2005) Predicting Good</span></div>
<div class="line"><span class="lineno">  978</span><span class="stringliteral">    Probabilities With Supervised Learning, in Proceedings of the 22nd</span></div>
<div class="line"><span class="lineno">  979</span><span class="stringliteral">    International Conference on Machine Learning (ICML).</span></div>
<div class="line"><span class="lineno">  980</span><span class="stringliteral">    See section 4 (Qualitative Analysis of Predictions).</span></div>
<div class="line"><span class="lineno">  981</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  982</span><span class="stringliteral">    Examples</span></div>
<div class="line"><span class="lineno">  983</span><span class="stringliteral">    --------</span></div>
<div class="line"><span class="lineno">  984</span><span class="stringliteral">    &gt;&gt;&gt; import numpy as np</span></div>
<div class="line"><span class="lineno">  985</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.calibration import calibration_curve</span></div>
<div class="line"><span class="lineno">  986</span><span class="stringliteral">    &gt;&gt;&gt; y_true = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1])</span></div>
<div class="line"><span class="lineno">  987</span><span class="stringliteral">    &gt;&gt;&gt; y_pred = np.array([0.1, 0.2, 0.3, 0.4, 0.65, 0.7, 0.8, 0.9,  1.])</span></div>
<div class="line"><span class="lineno">  988</span><span class="stringliteral">    &gt;&gt;&gt; prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=3)</span></div>
<div class="line"><span class="lineno">  989</span><span class="stringliteral">    &gt;&gt;&gt; prob_true</span></div>
<div class="line"><span class="lineno">  990</span><span class="stringliteral">    array([0. , 0.5, 1. ])</span></div>
<div class="line"><span class="lineno">  991</span><span class="stringliteral">    &gt;&gt;&gt; prob_pred</span></div>
<div class="line"><span class="lineno">  992</span><span class="stringliteral">    array([0.2  , 0.525, 0.85 ])</span></div>
<div class="line"><span class="lineno">  993</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  994</span>    y_true = column_or_1d(y_true)</div>
<div class="line"><span class="lineno">  995</span>    y_prob = column_or_1d(y_prob)</div>
<div class="line"><span class="lineno">  996</span>    check_consistent_length(y_true, y_prob)</div>
<div class="line"><span class="lineno">  997</span>    pos_label = _check_pos_label_consistency(pos_label, y_true)</div>
<div class="line"><span class="lineno">  998</span> </div>
<div class="line"><span class="lineno">  999</span>    <span class="comment"># TODO(1.3): Remove normalize conditional block.</span></div>
<div class="line"><span class="lineno"> 1000</span>    <span class="keywordflow">if</span> normalize != <span class="stringliteral">&quot;deprecated&quot;</span>:</div>
<div class="line"><span class="lineno"> 1001</span>        warnings.warn(</div>
<div class="line"><span class="lineno"> 1002</span>            <span class="stringliteral">&quot;The normalize argument is deprecated in v1.1 and will be removed in v1.3.&quot;</span></div>
<div class="line"><span class="lineno"> 1003</span>            <span class="stringliteral">&quot; Explicitly normalizing y_prob will reproduce this behavior, but it is&quot;</span></div>
<div class="line"><span class="lineno"> 1004</span>            <span class="stringliteral">&quot; recommended that a proper probability is used (i.e. a classifier&#39;s&quot;</span></div>
<div class="line"><span class="lineno"> 1005</span>            <span class="stringliteral">&quot; `predict_proba` positive class or `decision_function` output calibrated&quot;</span></div>
<div class="line"><span class="lineno"> 1006</span>            <span class="stringliteral">&quot; with `CalibratedClassifierCV`).&quot;</span>,</div>
<div class="line"><span class="lineno"> 1007</span>            FutureWarning,</div>
<div class="line"><span class="lineno"> 1008</span>        )</div>
<div class="line"><span class="lineno"> 1009</span>        <span class="keywordflow">if</span> normalize:  <span class="comment"># Normalize predicted values into interval [0, 1]</span></div>
<div class="line"><span class="lineno"> 1010</span>            y_prob = (y_prob - y_prob.min()) / (y_prob.max() - y_prob.min())</div>
<div class="line"><span class="lineno"> 1011</span> </div>
<div class="line"><span class="lineno"> 1012</span>    <span class="keywordflow">if</span> y_prob.min() &lt; 0 <span class="keywordflow">or</span> y_prob.max() &gt; 1:</div>
<div class="line"><span class="lineno"> 1013</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;y_prob has values outside [0, 1].&quot;</span>)</div>
<div class="line"><span class="lineno"> 1014</span> </div>
<div class="line"><span class="lineno"> 1015</span>    labels = np.unique(y_true)</div>
<div class="line"><span class="lineno"> 1016</span>    <span class="keywordflow">if</span> len(labels) &gt; 2:</div>
<div class="line"><span class="lineno"> 1017</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1018</span>            f<span class="stringliteral">&quot;Only binary classification is supported. Provided labels {labels}.&quot;</span></div>
<div class="line"><span class="lineno"> 1019</span>        )</div>
<div class="line"><span class="lineno"> 1020</span>    y_true = y_true == pos_label</div>
<div class="line"><span class="lineno"> 1021</span> </div>
<div class="line"><span class="lineno"> 1022</span>    <span class="keywordflow">if</span> strategy == <span class="stringliteral">&quot;quantile&quot;</span>:  <span class="comment"># Determine bin edges by distribution of data</span></div>
<div class="line"><span class="lineno"> 1023</span>        quantiles = np.linspace(0, 1, n_bins + 1)</div>
<div class="line"><span class="lineno"> 1024</span>        bins = np.percentile(y_prob, quantiles * 100)</div>
<div class="line"><span class="lineno"> 1025</span>    <span class="keywordflow">elif</span> strategy == <span class="stringliteral">&quot;uniform&quot;</span>:</div>
<div class="line"><span class="lineno"> 1026</span>        bins = np.linspace(0.0, 1.0, n_bins + 1)</div>
<div class="line"><span class="lineno"> 1027</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1028</span>        <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno"> 1029</span>            <span class="stringliteral">&quot;Invalid entry to &#39;strategy&#39; input. Strategy &quot;</span></div>
<div class="line"><span class="lineno"> 1030</span>            <span class="stringliteral">&quot;must be either &#39;quantile&#39; or &#39;uniform&#39;.&quot;</span></div>
<div class="line"><span class="lineno"> 1031</span>        )</div>
<div class="line"><span class="lineno"> 1032</span> </div>
<div class="line"><span class="lineno"> 1033</span>    binids = np.searchsorted(bins[1:-1], y_prob)</div>
<div class="line"><span class="lineno"> 1034</span> </div>
<div class="line"><span class="lineno"> 1035</span>    bin_sums = np.bincount(binids, weights=y_prob, minlength=len(bins))</div>
<div class="line"><span class="lineno"> 1036</span>    bin_true = np.bincount(binids, weights=y_true, minlength=len(bins))</div>
<div class="line"><span class="lineno"> 1037</span>    bin_total = np.bincount(binids, minlength=len(bins))</div>
<div class="line"><span class="lineno"> 1038</span> </div>
<div class="line"><span class="lineno"> 1039</span>    nonzero = bin_total != 0</div>
<div class="line"><span class="lineno"> 1040</span>    prob_true = bin_true[nonzero] / bin_total[nonzero]</div>
<div class="line"><span class="lineno"> 1041</span>    prob_pred = bin_sums[nonzero] / bin_total[nonzero]</div>
<div class="line"><span class="lineno"> 1042</span> </div>
<div class="line"><span class="lineno"> 1043</span>    <span class="keywordflow">return</span> prob_true, prob_pred</div>
<div class="line"><span class="lineno"> 1044</span> </div>
<div class="line"><span class="lineno"> 1045</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
