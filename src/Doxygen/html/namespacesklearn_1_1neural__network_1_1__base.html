<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: sklearn.neural_network._base Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacesklearn.html">sklearn</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1neural__network.html">neural_network</a></li><li class="navelem"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html">_base</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">sklearn.neural_network._base Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:abd773b27e38652bd5e569fec7f5f3bfe" id="r_abd773b27e38652bd5e569fec7f5f3bfe"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#abd773b27e38652bd5e569fec7f5f3bfe">inplace_identity</a> (X)</td></tr>
<tr class="separator:abd773b27e38652bd5e569fec7f5f3bfe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a441c6cede976b16945f2295a2a858ae6" id="r_a441c6cede976b16945f2295a2a858ae6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a441c6cede976b16945f2295a2a858ae6">inplace_logistic</a> (X)</td></tr>
<tr class="separator:a441c6cede976b16945f2295a2a858ae6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54e94c50758828317afc2623c8c624a9" id="r_a54e94c50758828317afc2623c8c624a9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a54e94c50758828317afc2623c8c624a9">inplace_tanh</a> (X)</td></tr>
<tr class="separator:a54e94c50758828317afc2623c8c624a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a741e5a1f3eca3a4edd15eb6aa7186274" id="r_a741e5a1f3eca3a4edd15eb6aa7186274"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a741e5a1f3eca3a4edd15eb6aa7186274">inplace_relu</a> (X)</td></tr>
<tr class="separator:a741e5a1f3eca3a4edd15eb6aa7186274"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69172d11735085e9dac5b6334bd77082" id="r_a69172d11735085e9dac5b6334bd77082"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a69172d11735085e9dac5b6334bd77082">inplace_softmax</a> (X)</td></tr>
<tr class="separator:a69172d11735085e9dac5b6334bd77082"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3cf16c0a300ff34c77d0f22901389cdb" id="r_a3cf16c0a300ff34c77d0f22901389cdb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a3cf16c0a300ff34c77d0f22901389cdb">inplace_identity_derivative</a> (Z, <a class="el" href="__lapack__subroutines_8h.html#a98105e47e00b222e3c47bfe371fa4925">delta</a>)</td></tr>
<tr class="separator:a3cf16c0a300ff34c77d0f22901389cdb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3acfc92f66a2b3046cb0c10d76784d5a" id="r_a3acfc92f66a2b3046cb0c10d76784d5a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a3acfc92f66a2b3046cb0c10d76784d5a">inplace_logistic_derivative</a> (Z, <a class="el" href="__lapack__subroutines_8h.html#a98105e47e00b222e3c47bfe371fa4925">delta</a>)</td></tr>
<tr class="separator:a3acfc92f66a2b3046cb0c10d76784d5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8948759bb7486dc5810e7cf80a5da83" id="r_ae8948759bb7486dc5810e7cf80a5da83"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#ae8948759bb7486dc5810e7cf80a5da83">inplace_tanh_derivative</a> (Z, <a class="el" href="__lapack__subroutines_8h.html#a98105e47e00b222e3c47bfe371fa4925">delta</a>)</td></tr>
<tr class="separator:ae8948759bb7486dc5810e7cf80a5da83"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e296a7d51d41314b31657972d366c93" id="r_a1e296a7d51d41314b31657972d366c93"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a1e296a7d51d41314b31657972d366c93">inplace_relu_derivative</a> (Z, <a class="el" href="__lapack__subroutines_8h.html#a98105e47e00b222e3c47bfe371fa4925">delta</a>)</td></tr>
<tr class="separator:a1e296a7d51d41314b31657972d366c93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1eeccdf3432c165b71fe1a45d4589fe" id="r_ac1eeccdf3432c165b71fe1a45d4589fe"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#ac1eeccdf3432c165b71fe1a45d4589fe">squared_loss</a> (y_true, y_pred)</td></tr>
<tr class="separator:ac1eeccdf3432c165b71fe1a45d4589fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ddcb9b2add86e9948c94c7e34fab4cd" id="r_a4ddcb9b2add86e9948c94c7e34fab4cd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a4ddcb9b2add86e9948c94c7e34fab4cd">log_loss</a> (y_true, y_prob)</td></tr>
<tr class="separator:a4ddcb9b2add86e9948c94c7e34fab4cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a334e260bc318e23417b97fc3feee2ae4" id="r_a334e260bc318e23417b97fc3feee2ae4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a334e260bc318e23417b97fc3feee2ae4">binary_log_loss</a> (y_true, y_prob)</td></tr>
<tr class="separator:a334e260bc318e23417b97fc3feee2ae4"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a3470f871309c2c25acf19e2c8e129176" id="r_a3470f871309c2c25acf19e2c8e129176"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a3470f871309c2c25acf19e2c8e129176">ACTIVATIONS</a></td></tr>
<tr class="separator:a3470f871309c2c25acf19e2c8e129176"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4debc5c7b65bc52decc4aef1a8866239" id="r_a4debc5c7b65bc52decc4aef1a8866239"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a4debc5c7b65bc52decc4aef1a8866239">DERIVATIVES</a></td></tr>
<tr class="separator:a4debc5c7b65bc52decc4aef1a8866239"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a782d13a30e8c639281a64505574724c3" id="r_a782d13a30e8c639281a64505574724c3"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesklearn_1_1neural__network_1_1__base.html#a782d13a30e8c639281a64505574724c3">LOSS_FUNCTIONS</a></td></tr>
<tr class="separator:a782d13a30e8c639281a64505574724c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Utilities for the neural network modules
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a334e260bc318e23417b97fc3feee2ae4" name="a334e260bc318e23417b97fc3feee2ae4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a334e260bc318e23417b97fc3feee2ae4">&#9670;&#160;</a></span>binary_log_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.binary_log_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_prob</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute binary logistic loss for classification.

This is identical to log_loss in binary classification case,
but is kept for its use in multilabel case.

Parameters
----------
y_true : array-like or label indicator matrix
    Ground truth (correct) labels.

y_prob : array-like of float, shape = (n_samples, 1)
    Predicted probabilities, as returned by a classifier's
    predict_proba method.

Returns
-------
loss : float
    The degree to which the samples are correctly predicted.
</pre> <div class="fragment"><div class="line"><span class="lineno">  205</span><span class="keyword">def </span>binary_log_loss(y_true, y_prob):</div>
<div class="line"><span class="lineno">  206</span>    <span class="stringliteral">&quot;&quot;&quot;Compute binary logistic loss for classification.</span></div>
<div class="line"><span class="lineno">  207</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  208</span><span class="stringliteral">    This is identical to log_loss in binary classification case,</span></div>
<div class="line"><span class="lineno">  209</span><span class="stringliteral">    but is kept for its use in multilabel case.</span></div>
<div class="line"><span class="lineno">  210</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  211</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  212</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  213</span><span class="stringliteral">    y_true : array-like or label indicator matrix</span></div>
<div class="line"><span class="lineno">  214</span><span class="stringliteral">        Ground truth (correct) labels.</span></div>
<div class="line"><span class="lineno">  215</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">    y_prob : array-like of float, shape = (n_samples, 1)</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral">        Predicted probabilities, as returned by a classifier&#39;s</span></div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">        predict_proba method.</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">    loss : float</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral">        The degree to which the samples are correctly predicted.</span></div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  225</span>    eps = np.finfo(y_prob.dtype).eps</div>
<div class="line"><span class="lineno">  226</span>    y_prob = np.clip(y_prob, eps, 1 - eps)</div>
<div class="line"><span class="lineno">  227</span>    <span class="keywordflow">return</span> (</div>
<div class="line"><span class="lineno">  228</span>        -(xlogy(y_true, y_prob).sum() + xlogy(1 - y_true, 1 - y_prob).sum())</div>
<div class="line"><span class="lineno">  229</span>        / y_prob.shape[0]</div>
<div class="line"><span class="lineno">  230</span>    )</div>
<div class="line"><span class="lineno">  231</span> </div>
<div class="line"><span class="lineno">  232</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="abd773b27e38652bd5e569fec7f5f3bfe" name="abd773b27e38652bd5e569fec7f5f3bfe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd773b27e38652bd5e569fec7f5f3bfe">&#9670;&#160;</a></span>inplace_identity()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.inplace_identity </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Simply leave the input array unchanged.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    Data, where `n_samples` is the number of samples
    and `n_features` is the number of features.
</pre> <div class="fragment"><div class="line"><span class="lineno">   13</span><span class="keyword">def </span>inplace_identity(X):</div>
<div class="line"><span class="lineno">   14</span>    <span class="stringliteral">&quot;&quot;&quot;Simply leave the input array unchanged.</span></div>
<div class="line"><span class="lineno">   15</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   16</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   17</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   18</span><span class="stringliteral">    X : {array-like, sparse matrix}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">   19</span><span class="stringliteral">        Data, where `n_samples` is the number of samples</span></div>
<div class="line"><span class="lineno">   20</span><span class="stringliteral">        and `n_features` is the number of features.</span></div>
<div class="line"><span class="lineno">   21</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   22</span>    <span class="comment"># Nothing to do</span></div>
<div class="line"><span class="lineno">   23</span> </div>
<div class="line"><span class="lineno">   24</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3cf16c0a300ff34c77d0f22901389cdb" name="a3cf16c0a300ff34c77d0f22901389cdb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3cf16c0a300ff34c77d0f22901389cdb">&#9670;&#160;</a></span>inplace_identity_derivative()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.inplace_identity_derivative </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Z</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>delta</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Apply the derivative of the identity function: do nothing.

Parameters
----------
Z : {array-like, sparse matrix}, shape (n_samples, n_features)
    The data which was output from the identity activation function during
    the forward pass.

delta : {array-like}, shape (n_samples, n_features)
     The backpropagated error signal to be modified inplace.
</pre> <div class="fragment"><div class="line"><span class="lineno">   80</span><span class="keyword">def </span>inplace_identity_derivative(Z, delta):</div>
<div class="line"><span class="lineno">   81</span>    <span class="stringliteral">&quot;&quot;&quot;Apply the derivative of the identity function: do nothing.</span></div>
<div class="line"><span class="lineno">   82</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   83</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">    Z : {array-like, sparse matrix}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">        The data which was output from the identity activation function during</span></div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral">        the forward pass.</span></div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">    delta : {array-like}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">         The backpropagated error signal to be modified inplace.</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   92</span>    <span class="comment"># Nothing to do</span></div>
<div class="line"><span class="lineno">   93</span> </div>
<div class="line"><span class="lineno">   94</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a441c6cede976b16945f2295a2a858ae6" name="a441c6cede976b16945f2295a2a858ae6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a441c6cede976b16945f2295a2a858ae6">&#9670;&#160;</a></span>inplace_logistic()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.inplace_logistic </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the logistic function inplace.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    The input data.
</pre> <div class="fragment"><div class="line"><span class="lineno">   25</span><span class="keyword">def </span>inplace_logistic(X):</div>
<div class="line"><span class="lineno">   26</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the logistic function inplace.</span></div>
<div class="line"><span class="lineno">   27</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   28</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   29</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   30</span><span class="stringliteral">    X : {array-like, sparse matrix}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">   31</span><span class="stringliteral">        The input data.</span></div>
<div class="line"><span class="lineno">   32</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   33</span>    logistic_sigmoid(X, out=X)</div>
<div class="line"><span class="lineno">   34</span> </div>
<div class="line"><span class="lineno">   35</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a3acfc92f66a2b3046cb0c10d76784d5a" name="a3acfc92f66a2b3046cb0c10d76784d5a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3acfc92f66a2b3046cb0c10d76784d5a">&#9670;&#160;</a></span>inplace_logistic_derivative()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.inplace_logistic_derivative </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Z</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>delta</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Apply the derivative of the logistic sigmoid function.

It exploits the fact that the derivative is a simple function of the output
value from logistic function.

Parameters
----------
Z : {array-like, sparse matrix}, shape (n_samples, n_features)
    The data which was output from the logistic activation function during
    the forward pass.

delta : {array-like}, shape (n_samples, n_features)
     The backpropagated error signal to be modified inplace.
</pre> <div class="fragment"><div class="line"><span class="lineno">   95</span><span class="keyword">def </span>inplace_logistic_derivative(Z, delta):</div>
<div class="line"><span class="lineno">   96</span>    <span class="stringliteral">&quot;&quot;&quot;Apply the derivative of the logistic sigmoid function.</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">    It exploits the fact that the derivative is a simple function of the output</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">    value from logistic function.</span></div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  103</span><span class="stringliteral">    Z : {array-like, sparse matrix}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  104</span><span class="stringliteral">        The data which was output from the logistic activation function during</span></div>
<div class="line"><span class="lineno">  105</span><span class="stringliteral">        the forward pass.</span></div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral">    delta : {array-like}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">         The backpropagated error signal to be modified inplace.</span></div>
<div class="line"><span class="lineno">  109</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  110</span>    delta *= Z</div>
<div class="line"><span class="lineno">  111</span>    delta *= 1 - Z</div>
<div class="line"><span class="lineno">  112</span> </div>
<div class="line"><span class="lineno">  113</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a741e5a1f3eca3a4edd15eb6aa7186274" name="a741e5a1f3eca3a4edd15eb6aa7186274"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a741e5a1f3eca3a4edd15eb6aa7186274">&#9670;&#160;</a></span>inplace_relu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.inplace_relu </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the rectified linear unit function inplace.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    The input data.
</pre> <div class="fragment"><div class="line"><span class="lineno">   47</span><span class="keyword">def </span>inplace_relu(X):</div>
<div class="line"><span class="lineno">   48</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the rectified linear unit function inplace.</span></div>
<div class="line"><span class="lineno">   49</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   50</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   51</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   52</span><span class="stringliteral">    X : {array-like, sparse matrix}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">        The input data.</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   55</span>    np.maximum(X, 0, out=X)</div>
<div class="line"><span class="lineno">   56</span> </div>
<div class="line"><span class="lineno">   57</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1e296a7d51d41314b31657972d366c93" name="a1e296a7d51d41314b31657972d366c93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e296a7d51d41314b31657972d366c93">&#9670;&#160;</a></span>inplace_relu_derivative()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.inplace_relu_derivative </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Z</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>delta</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Apply the derivative of the relu function.

It exploits the fact that the derivative is a simple function of the output
value from rectified linear units activation function.

Parameters
----------
Z : {array-like, sparse matrix}, shape (n_samples, n_features)
    The data which was output from the rectified linear units activation
    function during the forward pass.

delta : {array-like}, shape (n_samples, n_features)
     The backpropagated error signal to be modified inplace.
</pre> <div class="fragment"><div class="line"><span class="lineno">  132</span><span class="keyword">def </span>inplace_relu_derivative(Z, delta):</div>
<div class="line"><span class="lineno">  133</span>    <span class="stringliteral">&quot;&quot;&quot;Apply the derivative of the relu function.</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">    It exploits the fact that the derivative is a simple function of the output</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">    value from rectified linear units activation function.</span></div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">    Z : {array-like, sparse matrix}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">        The data which was output from the rectified linear units activation</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">        function during the forward pass.</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">    delta : {array-like}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">         The backpropagated error signal to be modified inplace.</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  147</span>    delta[Z == 0] = 0</div>
<div class="line"><span class="lineno">  148</span> </div>
<div class="line"><span class="lineno">  149</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a69172d11735085e9dac5b6334bd77082" name="a69172d11735085e9dac5b6334bd77082"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a69172d11735085e9dac5b6334bd77082">&#9670;&#160;</a></span>inplace_softmax()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.inplace_softmax </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the K-way softmax function inplace.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    The input data.
</pre> <div class="fragment"><div class="line"><span class="lineno">   58</span><span class="keyword">def </span>inplace_softmax(X):</div>
<div class="line"><span class="lineno">   59</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the K-way softmax function inplace.</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">    X : {array-like, sparse matrix}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">        The input data.</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   66</span>    tmp = X - X.max(axis=1)[:, np.newaxis]</div>
<div class="line"><span class="lineno">   67</span>    np.exp(tmp, out=X)</div>
<div class="line"><span class="lineno">   68</span>    X /= X.sum(axis=1)[:, np.newaxis]</div>
<div class="line"><span class="lineno">   69</span> </div>
<div class="line"><span class="lineno">   70</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a54e94c50758828317afc2623c8c624a9" name="a54e94c50758828317afc2623c8c624a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54e94c50758828317afc2623c8c624a9">&#9670;&#160;</a></span>inplace_tanh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.inplace_tanh </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the hyperbolic tan function inplace.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    The input data.
</pre> <div class="fragment"><div class="line"><span class="lineno">   36</span><span class="keyword">def </span>inplace_tanh(X):</div>
<div class="line"><span class="lineno">   37</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the hyperbolic tan function inplace.</span></div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   39</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">   41</span><span class="stringliteral">    X : {array-like, sparse matrix}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral">        The input data.</span></div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   44</span>    np.tanh(X, out=X)</div>
<div class="line"><span class="lineno">   45</span> </div>
<div class="line"><span class="lineno">   46</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae8948759bb7486dc5810e7cf80a5da83" name="ae8948759bb7486dc5810e7cf80a5da83"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae8948759bb7486dc5810e7cf80a5da83">&#9670;&#160;</a></span>inplace_tanh_derivative()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.inplace_tanh_derivative </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Z</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>delta</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Apply the derivative of the hyperbolic tanh function.

It exploits the fact that the derivative is a simple function of the output
value from hyperbolic tangent.

Parameters
----------
Z : {array-like, sparse matrix}, shape (n_samples, n_features)
    The data which was output from the hyperbolic tangent activation
    function during the forward pass.

delta : {array-like}, shape (n_samples, n_features)
     The backpropagated error signal to be modified inplace.
</pre> <div class="fragment"><div class="line"><span class="lineno">  114</span><span class="keyword">def </span>inplace_tanh_derivative(Z, delta):</div>
<div class="line"><span class="lineno">  115</span>    <span class="stringliteral">&quot;&quot;&quot;Apply the derivative of the hyperbolic tanh function.</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">    It exploits the fact that the derivative is a simple function of the output</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">    value from hyperbolic tangent.</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">    Z : {array-like, sparse matrix}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">        The data which was output from the hyperbolic tangent activation</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">        function during the forward pass.</span></div>
<div class="line"><span class="lineno">  125</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  126</span><span class="stringliteral">    delta : {array-like}, shape (n_samples, n_features)</span></div>
<div class="line"><span class="lineno">  127</span><span class="stringliteral">         The backpropagated error signal to be modified inplace.</span></div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  129</span>    delta *= 1 - Z**2</div>
<div class="line"><span class="lineno">  130</span> </div>
<div class="line"><span class="lineno">  131</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4ddcb9b2add86e9948c94c7e34fab4cd" name="a4ddcb9b2add86e9948c94c7e34fab4cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4ddcb9b2add86e9948c94c7e34fab4cd">&#9670;&#160;</a></span>log_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.log_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_prob</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute Logistic loss for classification.

Parameters
----------
y_true : array-like or label indicator matrix
    Ground truth (correct) labels.

y_prob : array-like of float, shape = (n_samples, n_classes)
    Predicted probabilities, as returned by a classifier's
    predict_proba method.

Returns
-------
loss : float
    The degree to which the samples are correctly predicted.
</pre> <div class="fragment"><div class="line"><span class="lineno">  177</span><span class="keyword">def </span>log_loss(y_true, y_prob):</div>
<div class="line"><span class="lineno">  178</span>    <span class="stringliteral">&quot;&quot;&quot;Compute Logistic loss for classification.</span></div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral">    y_true : array-like or label indicator matrix</span></div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">        Ground truth (correct) labels.</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">    y_prob : array-like of float, shape = (n_samples, n_classes)</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral">        Predicted probabilities, as returned by a classifier&#39;s</span></div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">        predict_proba method.</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral">    loss : float</span></div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">        The degree to which the samples are correctly predicted.</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  194</span>    eps = np.finfo(y_prob.dtype).eps</div>
<div class="line"><span class="lineno">  195</span>    y_prob = np.clip(y_prob, eps, 1 - eps)</div>
<div class="line"><span class="lineno">  196</span>    <span class="keywordflow">if</span> y_prob.shape[1] == 1:</div>
<div class="line"><span class="lineno">  197</span>        y_prob = np.append(1 - y_prob, y_prob, axis=1)</div>
<div class="line"><span class="lineno">  198</span> </div>
<div class="line"><span class="lineno">  199</span>    <span class="keywordflow">if</span> y_true.shape[1] == 1:</div>
<div class="line"><span class="lineno">  200</span>        y_true = np.append(1 - y_true, y_true, axis=1)</div>
<div class="line"><span class="lineno">  201</span> </div>
<div class="line"><span class="lineno">  202</span>    <span class="keywordflow">return</span> -xlogy(y_true, y_prob).sum() / y_prob.shape[0]</div>
<div class="line"><span class="lineno">  203</span> </div>
<div class="line"><span class="lineno">  204</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac1eeccdf3432c165b71fe1a45d4589fe" name="ac1eeccdf3432c165b71fe1a45d4589fe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac1eeccdf3432c165b71fe1a45d4589fe">&#9670;&#160;</a></span>squared_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">sklearn.neural_network._base.squared_loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_true</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y_pred</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the squared loss for regression.

Parameters
----------
y_true : array-like or label indicator matrix
    Ground truth (correct) values.

y_pred : array-like or label indicator matrix
    Predicted values, as returned by a regression estimator.

Returns
-------
loss : float
    The degree to which the samples are correctly predicted.
</pre> <div class="fragment"><div class="line"><span class="lineno">  158</span><span class="keyword">def </span>squared_loss(y_true, y_pred):</div>
<div class="line"><span class="lineno">  159</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the squared loss for regression.</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">    ----------</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">    y_true : array-like or label indicator matrix</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        Ground truth (correct) values.</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">    y_pred : array-like or label indicator matrix</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">        Predicted values, as returned by a regression estimator.</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral">    Returns</span></div>
<div class="line"><span class="lineno">  170</span><span class="stringliteral">    -------</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">    loss : float</span></div>
<div class="line"><span class="lineno">  172</span><span class="stringliteral">        The degree to which the samples are correctly predicted.</span></div>
<div class="line"><span class="lineno">  173</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  174</span>    <span class="keywordflow">return</span> ((y_true - y_pred) ** 2).mean() / 2</div>
<div class="line"><span class="lineno">  175</span> </div>
<div class="line"><span class="lineno">  176</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a3470f871309c2c25acf19e2c8e129176" name="a3470f871309c2c25acf19e2c8e129176"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3470f871309c2c25acf19e2c8e129176">&#9670;&#160;</a></span>ACTIVATIONS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">dict sklearn.neural_network._base.ACTIVATIONS</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  {</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;identity&quot;</span>: inplace_identity,</div>
<div class="line"><span class="lineno">    3</span>    <span class="stringliteral">&quot;tanh&quot;</span>: inplace_tanh,</div>
<div class="line"><span class="lineno">    4</span>    <span class="stringliteral">&quot;logistic&quot;</span>: inplace_logistic,</div>
<div class="line"><span class="lineno">    5</span>    <span class="stringliteral">&quot;relu&quot;</span>: inplace_relu,</div>
<div class="line"><span class="lineno">    6</span>    <span class="stringliteral">&quot;softmax&quot;</span>: inplace_softmax,</div>
<div class="line"><span class="lineno">    7</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a4debc5c7b65bc52decc4aef1a8866239" name="a4debc5c7b65bc52decc4aef1a8866239"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4debc5c7b65bc52decc4aef1a8866239">&#9670;&#160;</a></span>DERIVATIVES</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">dict sklearn.neural_network._base.DERIVATIVES</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  {</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;identity&quot;</span>: inplace_identity_derivative,</div>
<div class="line"><span class="lineno">    3</span>    <span class="stringliteral">&quot;tanh&quot;</span>: inplace_tanh_derivative,</div>
<div class="line"><span class="lineno">    4</span>    <span class="stringliteral">&quot;logistic&quot;</span>: inplace_logistic_derivative,</div>
<div class="line"><span class="lineno">    5</span>    <span class="stringliteral">&quot;relu&quot;</span>: inplace_relu_derivative,</div>
<div class="line"><span class="lineno">    6</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a782d13a30e8c639281a64505574724c3" name="a782d13a30e8c639281a64505574724c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a782d13a30e8c639281a64505574724c3">&#9670;&#160;</a></span>LOSS_FUNCTIONS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">dict sklearn.neural_network._base.LOSS_FUNCTIONS</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  {</div>
<div class="line"><span class="lineno">    2</span>    <span class="stringliteral">&quot;squared_error&quot;</span>: squared_loss,</div>
<div class="line"><span class="lineno">    3</span>    <span class="stringliteral">&quot;log_loss&quot;</span>: log_loss,</div>
<div class="line"><span class="lineno">    4</span>    <span class="stringliteral">&quot;binary_log_loss&quot;</span>: binary_log_loss,</div>
<div class="line"><span class="lineno">    5</span>}</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
