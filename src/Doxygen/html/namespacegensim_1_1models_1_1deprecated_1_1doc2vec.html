<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tp_Gcs: gensim.models.deprecated.doc2vec Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tp_Gcs<span id="projectnumber">&#160;1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacegensim.html">gensim</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models.html">models</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1deprecated.html">deprecated</a></li><li class="navelem"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1doc2vec.html">doc2vec</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">gensim.models.deprecated.doc2vec Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doc2_vec.html">Doc2Vec</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_doctag.html">Doctag</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_docvecs_array.html">DocvecsArray</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_labeled_sentence.html">LabeledSentence</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_tagged_brown_corpus.html">TaggedBrownCorpus</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_tagged_document.html">TaggedDocument</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgensim_1_1models_1_1deprecated_1_1doc2vec_1_1_tagged_line_document.html">TaggedLineDocument</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a63eb3e67f4ff4b4b443dfa4f4b1a2f58" id="r_a63eb3e67f4ff4b4b443dfa4f4b1a2f58"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1doc2vec.html#a63eb3e67f4ff4b4b443dfa4f4b1a2f58">load_old_doc2vec</a> (*args, **kwargs)</td></tr>
<tr class="separator:a63eb3e67f4ff4b4b443dfa4f4b1a2f58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38e2c9fbc9677e3dc35263f992a2ca0d" id="r_a38e2c9fbc9677e3dc35263f992a2ca0d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1doc2vec.html#a38e2c9fbc9677e3dc35263f992a2ca0d">train_document_dbow</a> (model, doc_words, doctag_indexes, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, <a class="el" href="__lapack__subroutines_8h.html#ad2e2a6e930388ddee2f5afb58c5bf8ad">work</a>=None, train_words=False, learn_doctags=True, learn_words=True, learn_hidden=True, word_vectors=None, word_locks=None, doctag_vectors=None, doctag_locks=None)</td></tr>
<tr class="separator:a38e2c9fbc9677e3dc35263f992a2ca0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaad1fe545e6647b4b3a2897c190f2c9f" id="r_aaad1fe545e6647b4b3a2897c190f2c9f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1doc2vec.html#aaad1fe545e6647b4b3a2897c190f2c9f">train_document_dm</a> (model, doc_words, doctag_indexes, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, <a class="el" href="__lapack__subroutines_8h.html#ad2e2a6e930388ddee2f5afb58c5bf8ad">work</a>=None, neu1=None, learn_doctags=True, learn_words=True, learn_hidden=True, word_vectors=None, word_locks=None, doctag_vectors=None, doctag_locks=None)</td></tr>
<tr class="separator:aaad1fe545e6647b4b3a2897c190f2c9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a586c18966facf96e1dcb04b463eaf93d" id="r_a586c18966facf96e1dcb04b463eaf93d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1doc2vec.html#a586c18966facf96e1dcb04b463eaf93d">train_document_dm_concat</a> (model, doc_words, doctag_indexes, <a class="el" href="__blas__subroutines_8h.html#a29dda7d0819a860e921db821deb590c9">alpha</a>, <a class="el" href="__lapack__subroutines_8h.html#ad2e2a6e930388ddee2f5afb58c5bf8ad">work</a>=None, neu1=None, learn_doctags=True, learn_words=True, learn_hidden=True, word_vectors=None, word_locks=None, doctag_vectors=None, doctag_locks=None)</td></tr>
<tr class="separator:a586c18966facf96e1dcb04b463eaf93d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:aae993b667e4db8f1d233b77111faa3db" id="r_aae993b667e4db8f1d233b77111faa3db"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacegensim_1_1models_1_1deprecated_1_1doc2vec.html#aae993b667e4db8f1d233b77111faa3db">logger</a> = logging.getLogger(__name__)</td></tr>
<tr class="separator:aae993b667e4db8f1d233b77111faa3db"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Warnings
--------
.. deprecated:: 3.3.0
   Use :mod:`gensim.models.doc2vec` instead.



Deep learning via the distributed memory and distributed bag of words models from
[1]_, using either hierarchical softmax or negative sampling [2]_ [3]_. See [#tutorial]_

**Make sure you have a C compiler before installing gensim, to use optimized (compiled)
doc2vec training** (70x speedup [blog]_).

Initialize a model with e.g.::

.. sourcecode:: pycon

    &gt;&gt;&gt; model = Doc2Vec(documents, size=100, window=8, min_count=5, workers=4)

Persist a model to disk with::

.. sourcecode:: pycon

    &gt;&gt;&gt; model.save(fname)
    &gt;&gt;&gt; model = Doc2Vec.load(fname)  # you can continue training with the loaded model!

If you're finished training a model (=no more updates, only querying), you can do

.. sourcecode:: pycon

    &gt;&gt;&gt; model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True):

to trim unneeded model memory = use (much) less RAM.



.. [1] Quoc Le and Tomas Mikolov. Distributed Representations of Sentences and Documents.
       http://arxiv.org/pdf/1405.4053v2.pdf
.. [2] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
       Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR, 2013.
.. [3] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean.
       Distributed Representations of Words and Phrases and their Compositionality. In Proceedings of NIPS, 2013.
.. [blog] Optimizing word2vec in gensim, http://radimrehurek.com/2013/09/word2vec-in-python-part-two-optimizing/

.. [#tutorial] Doc2vec in gensim tutorial,
               https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a63eb3e67f4ff4b4b443dfa4f4b1a2f58" name="a63eb3e67f4ff4b4b443dfa4f4b1a2f58"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a63eb3e67f4ff4b4b443dfa4f4b1a2f58">&#9670;&#160;</a></span>load_old_doc2vec()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.doc2vec.load_old_doc2vec </td>
          <td>(</td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="fragment"><div class="line"><span class="lineno">   90</span><span class="keyword">def </span>load_old_doc2vec(*args, **kwargs):</div>
<div class="line"><span class="lineno">   91</span>    old_model = Doc2Vec.load(*args, **kwargs)</div>
<div class="line"><span class="lineno">   92</span>    params = {</div>
<div class="line"><span class="lineno">   93</span>        <span class="stringliteral">&#39;dm_mean&#39;</span>: old_model.__dict__.get(<span class="stringliteral">&#39;dm_mean&#39;</span>, <span class="keywordtype">None</span>),</div>
<div class="line"><span class="lineno">   94</span>        <span class="stringliteral">&#39;dm&#39;</span>: old_model.dm,</div>
<div class="line"><span class="lineno">   95</span>        <span class="stringliteral">&#39;dbow_words&#39;</span>: old_model.dbow_words,</div>
<div class="line"><span class="lineno">   96</span>        <span class="stringliteral">&#39;dm_concat&#39;</span>: old_model.dm_concat,</div>
<div class="line"><span class="lineno">   97</span>        <span class="stringliteral">&#39;dm_tag_count&#39;</span>: old_model.dm_tag_count,</div>
<div class="line"><span class="lineno">   98</span>        <span class="stringliteral">&#39;docvecs_mapfile&#39;</span>: old_model.__dict__.get(<span class="stringliteral">&#39;docvecs_mapfile&#39;</span>, <span class="keywordtype">None</span>),</div>
<div class="line"><span class="lineno">   99</span>        <span class="stringliteral">&#39;comment&#39;</span>: old_model.__dict__.get(<span class="stringliteral">&#39;comment&#39;</span>, <span class="keywordtype">None</span>),</div>
<div class="line"><span class="lineno">  100</span>        <span class="stringliteral">&#39;vector_size&#39;</span>: old_model.vector_size,</div>
<div class="line"><span class="lineno">  101</span>        <span class="stringliteral">&#39;alpha&#39;</span>: old_model.alpha,</div>
<div class="line"><span class="lineno">  102</span>        <span class="stringliteral">&#39;window&#39;</span>: old_model.window,</div>
<div class="line"><span class="lineno">  103</span>        <span class="stringliteral">&#39;min_count&#39;</span>: old_model.min_count,</div>
<div class="line"><span class="lineno">  104</span>        <span class="stringliteral">&#39;max_vocab_size&#39;</span>: old_model.__dict__.get(<span class="stringliteral">&#39;max_vocab_size&#39;</span>, <span class="keywordtype">None</span>),</div>
<div class="line"><span class="lineno">  105</span>        <span class="stringliteral">&#39;sample&#39;</span>: old_model.sample,</div>
<div class="line"><span class="lineno">  106</span>        <span class="stringliteral">&#39;seed&#39;</span>: old_model.seed,</div>
<div class="line"><span class="lineno">  107</span>        <span class="stringliteral">&#39;workers&#39;</span>: old_model.workers,</div>
<div class="line"><span class="lineno">  108</span>        <span class="stringliteral">&#39;min_alpha&#39;</span>: old_model.min_alpha,</div>
<div class="line"><span class="lineno">  109</span>        <span class="stringliteral">&#39;hs&#39;</span>: old_model.hs,</div>
<div class="line"><span class="lineno">  110</span>        <span class="stringliteral">&#39;negative&#39;</span>: old_model.negative,</div>
<div class="line"><span class="lineno">  111</span>        <span class="stringliteral">&#39;cbow_mean&#39;</span>: old_model.cbow_mean,</div>
<div class="line"><span class="lineno">  112</span>        <span class="stringliteral">&#39;hashfxn&#39;</span>: old_model.hashfxn,</div>
<div class="line"><span class="lineno">  113</span>        <span class="stringliteral">&#39;epochs&#39;</span>: old_model.iter,</div>
<div class="line"><span class="lineno">  114</span>        <span class="stringliteral">&#39;sorted_vocab&#39;</span>: old_model.__dict__.get(<span class="stringliteral">&#39;sorted_vocab&#39;</span>, 1),</div>
<div class="line"><span class="lineno">  115</span>        <span class="stringliteral">&#39;batch_words&#39;</span>: old_model.__dict__.get(<span class="stringliteral">&#39;batch_words&#39;</span>, MAX_WORDS_IN_BATCH),</div>
<div class="line"><span class="lineno">  116</span>        <span class="stringliteral">&#39;compute_loss&#39;</span>: old_model.__dict__.get(<span class="stringliteral">&#39;compute_loss&#39;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  117</span>    }</div>
<div class="line"><span class="lineno">  118</span>    new_model = NewDoc2Vec(**params)</div>
<div class="line"><span class="lineno">  119</span>    <span class="comment"># set word2vec trainables attributes</span></div>
<div class="line"><span class="lineno">  120</span>    new_model.wv.vectors = old_model.wv.syn0</div>
<div class="line"><span class="lineno">  121</span>    <span class="keywordflow">if</span> hasattr(old_model.wv, <span class="stringliteral">&#39;syn0norm&#39;</span>):</div>
<div class="line"><span class="lineno">  122</span>        new_model.docvecs.vectors_norm = old_model.wv.syn0norm</div>
<div class="line"><span class="lineno">  123</span>    <span class="keywordflow">if</span> hasattr(old_model, <span class="stringliteral">&#39;syn1&#39;</span>):</div>
<div class="line"><span class="lineno">  124</span>        new_model.trainables.syn1 = old_model.syn1</div>
<div class="line"><span class="lineno">  125</span>    <span class="keywordflow">if</span> hasattr(old_model, <span class="stringliteral">&#39;syn1neg&#39;</span>):</div>
<div class="line"><span class="lineno">  126</span>        new_model.trainables.syn1neg = old_model.syn1neg</div>
<div class="line"><span class="lineno">  127</span>    <span class="keywordflow">if</span> hasattr(old_model, <span class="stringliteral">&#39;syn0_lockf&#39;</span>):</div>
<div class="line"><span class="lineno">  128</span>        new_model.trainables.vectors_lockf = old_model.syn0_lockf</div>
<div class="line"><span class="lineno">  129</span> </div>
<div class="line"><span class="lineno">  130</span>    <span class="comment"># set doc2vec trainables attributes</span></div>
<div class="line"><span class="lineno">  131</span>    new_model.docvecs.vectors_docs = old_model.docvecs.doctag_syn0</div>
<div class="line"><span class="lineno">  132</span>    <span class="keywordflow">if</span> hasattr(old_model.docvecs, <span class="stringliteral">&#39;doctag_syn0norm&#39;</span>):</div>
<div class="line"><span class="lineno">  133</span>        new_model.docvecs.vectors_docs_norm = old_model.docvecs.doctag_syn0norm</div>
<div class="line"><span class="lineno">  134</span>    <span class="keywordflow">if</span> hasattr(old_model.docvecs, <span class="stringliteral">&#39;doctag_syn0_lockf&#39;</span>):</div>
<div class="line"><span class="lineno">  135</span>        new_model.trainables.vectors_docs_lockf = old_model.docvecs.doctag_syn0_lockf</div>
<div class="line"><span class="lineno">  136</span>    <span class="keywordflow">if</span> hasattr(old_model.docvecs, <span class="stringliteral">&#39;mapfile_path&#39;</span>):</div>
<div class="line"><span class="lineno">  137</span>        new_model.docvecs.mapfile_path = old_model.docvecs.mapfile_path</div>
<div class="line"><span class="lineno">  138</span> </div>
<div class="line"><span class="lineno">  139</span>    <span class="comment"># set word2vec vocabulary attributes</span></div>
<div class="line"><span class="lineno">  140</span>    new_model.wv.vocab = old_model.wv.vocab</div>
<div class="line"><span class="lineno">  141</span>    new_model.wv.index2word = old_model.wv.index2word</div>
<div class="line"><span class="lineno">  142</span>    new_model.vocabulary.cum_table = old_model.cum_table</div>
<div class="line"><span class="lineno">  143</span> </div>
<div class="line"><span class="lineno">  144</span>    <span class="comment"># set doc2vec vocabulary attributes</span></div>
<div class="line"><span class="lineno">  145</span>    new_model.docvecs.doctags = old_model.docvecs.doctags</div>
<div class="line"><span class="lineno">  146</span>    new_model.docvecs.count = old_model.docvecs.count</div>
<div class="line"><span class="lineno">  147</span>    <span class="keywordflow">if</span> hasattr(old_model.docvecs, <span class="stringliteral">&#39;max_rawint&#39;</span>):  <span class="comment"># `doc2vec` models before `0.12.3` do not have these 2 attributes</span></div>
<div class="line"><span class="lineno">  148</span>        new_model.docvecs.max_rawint = old_model.docvecs.__dict__.get(<span class="stringliteral">&#39;max_rawint&#39;</span>)</div>
<div class="line"><span class="lineno">  149</span>        new_model.docvecs.offset2doctag = old_model.docvecs.__dict__.get(<span class="stringliteral">&#39;offset2doctag&#39;</span>)</div>
<div class="line"><span class="lineno">  150</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  151</span>        <span class="comment"># Doc2Vec models before Gensim version 0.12.3 did not have `max_rawint` and `offset2doctag` as they did not</span></div>
<div class="line"><span class="lineno">  152</span>        <span class="comment"># mixing of string and int tags. This implies the new attribute `offset2doctag` equals the old `index2doctag`</span></div>
<div class="line"><span class="lineno">  153</span>        <span class="comment"># (which was only filled if the documents had string tags).</span></div>
<div class="line"><span class="lineno">  154</span>        <span class="comment"># This also implies that the new attribute, `max_rawint`(highest rawint-indexed doctag) would either be equal</span></div>
<div class="line"><span class="lineno">  155</span>        <span class="comment"># to the initial value -1, in case only string tags are used or would be equal to `count` if only int indexing</span></div>
<div class="line"><span class="lineno">  156</span>        <span class="comment"># was used.</span></div>
<div class="line"><span class="lineno">  157</span>        new_model.docvecs.max_rawint = -1 <span class="keywordflow">if</span> old_model.docvecs.index2doctag <span class="keywordflow">else</span> old_model.docvecs.count - 1</div>
<div class="line"><span class="lineno">  158</span>        new_model.docvecs.offset2doctag = old_model.docvecs.index2doctag</div>
<div class="line"><span class="lineno">  159</span> </div>
<div class="line"><span class="lineno">  160</span>    new_model.train_count = old_model.__dict__.get(<span class="stringliteral">&#39;train_count&#39;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  161</span>    new_model.corpus_count = old_model.__dict__.get(<span class="stringliteral">&#39;corpus_count&#39;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  162</span>    new_model.corpus_total_words = old_model.__dict__.get(<span class="stringliteral">&#39;corpus_total_words&#39;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  163</span>    new_model.running_training_loss = old_model.__dict__.get(<span class="stringliteral">&#39;running_training_loss&#39;</span>, 0)</div>
<div class="line"><span class="lineno">  164</span>    new_model.total_train_time = old_model.__dict__.get(<span class="stringliteral">&#39;total_train_time&#39;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  165</span>    new_model.min_alpha_yet_reached = old_model.__dict__.get(<span class="stringliteral">&#39;min_alpha_yet_reached&#39;</span>, old_model.alpha)</div>
<div class="line"><span class="lineno">  166</span>    new_model.model_trimmed_post_training = old_model.__dict__.get(<span class="stringliteral">&#39;model_trimmed_post_training&#39;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  167</span> </div>
<div class="line"><span class="lineno">  168</span>    <span class="keywordflow">return</span> new_model</div>
<div class="line"><span class="lineno">  169</span> </div>
<div class="line"><span class="lineno">  170</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a38e2c9fbc9677e3dc35263f992a2ca0d" name="a38e2c9fbc9677e3dc35263f992a2ca0d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38e2c9fbc9677e3dc35263f992a2ca0d">&#9670;&#160;</a></span>train_document_dbow()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.doc2vec.train_document_dbow </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doc_words</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doctag_indexes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>work</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>train_words</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_doctags</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_words</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_hidden</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_vectors</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_locks</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doctag_vectors</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doctag_locks</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update distributed bag of words model ("PV-DBOW") by training on a single document.

Called internally from `Doc2Vec.train()` and `Doc2Vec.infer_vector()`.

The document is provided as `doc_words`, a list of word tokens which are looked up
in the model's vocab dictionary, and `doctag_indexes`, which provide indexes
into the doctag_vectors array.

If `train_words` is True, simultaneously train word-to-word (not just doc-to-word)
examples, exactly as per Word2Vec skip-gram training. (Without this option,
word vectors are neither consulted nor updated during DBOW doc vector training.)

Any of `learn_doctags', `learn_words`, and `learn_hidden` may be set False to
prevent learning-updates to those respective model weights, as if using the
(partially-)frozen model to infer other compatible vectors.

This is the non-optimized, Python version. If you have cython installed, gensim
will use the optimized version from doc2vec_inner instead.</pre> <div class="fragment"><div class="line"><span class="lineno">  173</span>                        word_vectors=<span class="keywordtype">None</span>, word_locks=<span class="keywordtype">None</span>, doctag_vectors=<span class="keywordtype">None</span>, doctag_locks=<span class="keywordtype">None</span>):</div>
<div class="line"><span class="lineno">  174</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">    Update distributed bag of words model (&quot;PV-DBOW&quot;) by training on a single document.</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">    Called internally from `Doc2Vec.train()` and `Doc2Vec.infer_vector()`.</span></div>
<div class="line"><span class="lineno">  178</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  179</span><span class="stringliteral">    The document is provided as `doc_words`, a list of word tokens which are looked up</span></div>
<div class="line"><span class="lineno">  180</span><span class="stringliteral">    in the model&#39;s vocab dictionary, and `doctag_indexes`, which provide indexes</span></div>
<div class="line"><span class="lineno">  181</span><span class="stringliteral">    into the doctag_vectors array.</span></div>
<div class="line"><span class="lineno">  182</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  183</span><span class="stringliteral">    If `train_words` is True, simultaneously train word-to-word (not just doc-to-word)</span></div>
<div class="line"><span class="lineno">  184</span><span class="stringliteral">    examples, exactly as per Word2Vec skip-gram training. (Without this option,</span></div>
<div class="line"><span class="lineno">  185</span><span class="stringliteral">    word vectors are neither consulted nor updated during DBOW doc vector training.)</span></div>
<div class="line"><span class="lineno">  186</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  187</span><span class="stringliteral">    Any of `learn_doctags&#39;, `learn_words`, and `learn_hidden` may be set False to</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral">    prevent learning-updates to those respective model weights, as if using the</span></div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">    (partially-)frozen model to infer other compatible vectors.</span></div>
<div class="line"><span class="lineno">  190</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral">    This is the non-optimized, Python version. If you have cython installed, gensim</span></div>
<div class="line"><span class="lineno">  192</span><span class="stringliteral">    will use the optimized version from doc2vec_inner instead.</span></div>
<div class="line"><span class="lineno">  193</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  194</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  195</span>    <span class="keywordflow">if</span> doctag_vectors <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  196</span>        doctag_vectors = model.docvecs.doctag_syn0</div>
<div class="line"><span class="lineno">  197</span>    <span class="keywordflow">if</span> doctag_locks <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  198</span>        doctag_locks = model.docvecs.doctag_syn0_lockf</div>
<div class="line"><span class="lineno">  199</span> </div>
<div class="line"><span class="lineno">  200</span>    <span class="keywordflow">if</span> train_words <span class="keywordflow">and</span> learn_words:</div>
<div class="line"><span class="lineno">  201</span>        train_batch_sg(model, [doc_words], alpha, work)</div>
<div class="line"><span class="lineno">  202</span>    <span class="keywordflow">for</span> doctag_index <span class="keywordflow">in</span> doctag_indexes:</div>
<div class="line"><span class="lineno">  203</span>        <span class="keywordflow">for</span> word <span class="keywordflow">in</span> doc_words:</div>
<div class="line"><span class="lineno">  204</span>            train_sg_pair(</div>
<div class="line"><span class="lineno">  205</span>                model, word, doctag_index, alpha, learn_vectors=learn_doctags, learn_hidden=learn_hidden,</div>
<div class="line"><span class="lineno">  206</span>                context_vectors=doctag_vectors, context_locks=doctag_locks</div>
<div class="line"><span class="lineno">  207</span>            )</div>
<div class="line"><span class="lineno">  208</span> </div>
<div class="line"><span class="lineno">  209</span>    <span class="keywordflow">return</span> len(doc_words)</div>
<div class="line"><span class="lineno">  210</span> </div>
<div class="line"><span class="lineno">  211</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aaad1fe545e6647b4b3a2897c190f2c9f" name="aaad1fe545e6647b4b3a2897c190f2c9f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaad1fe545e6647b4b3a2897c190f2c9f">&#9670;&#160;</a></span>train_document_dm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.doc2vec.train_document_dm </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doc_words</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doctag_indexes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>work</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>neu1</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_doctags</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_words</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_hidden</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_vectors</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_locks</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doctag_vectors</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doctag_locks</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update distributed memory model ("PV-DM") by training on a single document.

Called internally from `Doc2Vec.train()` and `Doc2Vec.infer_vector()`. This
method implements the DM model with a projection (input) layer that is
either the sum or mean of the context vectors, depending on the model's
`dm_mean` configuration field.  See `train_document_dm_concat()` for the DM
model with a concatenated input layer.

The document is provided as `doc_words`, a list of word tokens which are looked up
in the model's vocab dictionary, and `doctag_indexes`, which provide indexes
into the doctag_vectors array.

Any of `learn_doctags', `learn_words`, and `learn_hidden` may be set False to
prevent learning-updates to those respective model weights, as if using the
(partially-)frozen model to infer other compatible vectors.

This is the non-optimized, Python version. If you have a C compiler, gensim
will use the optimized version from doc2vec_inner instead.</pre> <div class="fragment"><div class="line"><span class="lineno">  214</span>                      word_vectors=<span class="keywordtype">None</span>, word_locks=<span class="keywordtype">None</span>, doctag_vectors=<span class="keywordtype">None</span>, doctag_locks=<span class="keywordtype">None</span>):</div>
<div class="line"><span class="lineno">  215</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  216</span><span class="stringliteral">    Update distributed memory model (&quot;PV-DM&quot;) by training on a single document.</span></div>
<div class="line"><span class="lineno">  217</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  218</span><span class="stringliteral">    Called internally from `Doc2Vec.train()` and `Doc2Vec.infer_vector()`. This</span></div>
<div class="line"><span class="lineno">  219</span><span class="stringliteral">    method implements the DM model with a projection (input) layer that is</span></div>
<div class="line"><span class="lineno">  220</span><span class="stringliteral">    either the sum or mean of the context vectors, depending on the model&#39;s</span></div>
<div class="line"><span class="lineno">  221</span><span class="stringliteral">    `dm_mean` configuration field.  See `train_document_dm_concat()` for the DM</span></div>
<div class="line"><span class="lineno">  222</span><span class="stringliteral">    model with a concatenated input layer.</span></div>
<div class="line"><span class="lineno">  223</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  224</span><span class="stringliteral">    The document is provided as `doc_words`, a list of word tokens which are looked up</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">    in the model&#39;s vocab dictionary, and `doctag_indexes`, which provide indexes</span></div>
<div class="line"><span class="lineno">  226</span><span class="stringliteral">    into the doctag_vectors array.</span></div>
<div class="line"><span class="lineno">  227</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  228</span><span class="stringliteral">    Any of `learn_doctags&#39;, `learn_words`, and `learn_hidden` may be set False to</span></div>
<div class="line"><span class="lineno">  229</span><span class="stringliteral">    prevent learning-updates to those respective model weights, as if using the</span></div>
<div class="line"><span class="lineno">  230</span><span class="stringliteral">    (partially-)frozen model to infer other compatible vectors.</span></div>
<div class="line"><span class="lineno">  231</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  232</span><span class="stringliteral">    This is the non-optimized, Python version. If you have a C compiler, gensim</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral">    will use the optimized version from doc2vec_inner instead.</span></div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  236</span>    <span class="keywordflow">if</span> word_vectors <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  237</span>        word_vectors = model.wv.syn0</div>
<div class="line"><span class="lineno">  238</span>    <span class="keywordflow">if</span> word_locks <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  239</span>        word_locks = model.syn0_lockf</div>
<div class="line"><span class="lineno">  240</span>    <span class="keywordflow">if</span> doctag_vectors <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  241</span>        doctag_vectors = model.docvecs.doctag_syn0</div>
<div class="line"><span class="lineno">  242</span>    <span class="keywordflow">if</span> doctag_locks <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  243</span>        doctag_locks = model.docvecs.doctag_syn0_lockf</div>
<div class="line"><span class="lineno">  244</span> </div>
<div class="line"><span class="lineno">  245</span>    word_vocabs = [model.wv.vocab[w] <span class="keywordflow">for</span> w <span class="keywordflow">in</span> doc_words <span class="keywordflow">if</span> w <span class="keywordflow">in</span> model.wv.vocab</div>
<div class="line"><span class="lineno">  246</span>                   <span class="keywordflow">and</span> model.wv.vocab[w].sample_int &gt; model.random.rand() * 2**32]</div>
<div class="line"><span class="lineno">  247</span> </div>
<div class="line"><span class="lineno">  248</span>    <span class="keywordflow">for</span> pos, word <span class="keywordflow">in</span> enumerate(word_vocabs):</div>
<div class="line"><span class="lineno">  249</span>        reduced_window = model.random.randint(model.window)  <span class="comment"># `b` in the original doc2vec code</span></div>
<div class="line"><span class="lineno">  250</span>        start = max(0, pos - model.window + reduced_window)</div>
<div class="line"><span class="lineno">  251</span>        window_pos = enumerate(word_vocabs[start:(pos + model.window + 1 - reduced_window)], start)</div>
<div class="line"><span class="lineno">  252</span>        word2_indexes = [word2.index <span class="keywordflow">for</span> pos2, word2 <span class="keywordflow">in</span> window_pos <span class="keywordflow">if</span> pos2 != pos]</div>
<div class="line"><span class="lineno">  253</span>        l1 = np_sum(word_vectors[word2_indexes], axis=0) + np_sum(doctag_vectors[doctag_indexes], axis=0)</div>
<div class="line"><span class="lineno">  254</span>        count = len(word2_indexes) + len(doctag_indexes)</div>
<div class="line"><span class="lineno">  255</span>        <span class="keywordflow">if</span> model.cbow_mean <span class="keywordflow">and</span> count &gt; 1:</div>
<div class="line"><span class="lineno">  256</span>            l1 /= count</div>
<div class="line"><span class="lineno">  257</span>        neu1e = train_cbow_pair(model, word, word2_indexes, l1, alpha,</div>
<div class="line"><span class="lineno">  258</span>                                learn_vectors=<span class="keyword">False</span>, learn_hidden=learn_hidden)</div>
<div class="line"><span class="lineno">  259</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> model.cbow_mean <span class="keywordflow">and</span> count &gt; 1:</div>
<div class="line"><span class="lineno">  260</span>            neu1e /= count</div>
<div class="line"><span class="lineno">  261</span>        <span class="keywordflow">if</span> learn_doctags:</div>
<div class="line"><span class="lineno">  262</span>            <span class="keywordflow">for</span> i <span class="keywordflow">in</span> doctag_indexes:</div>
<div class="line"><span class="lineno">  263</span>                doctag_vectors[i] += neu1e * doctag_locks[i]</div>
<div class="line"><span class="lineno">  264</span>        <span class="keywordflow">if</span> learn_words:</div>
<div class="line"><span class="lineno">  265</span>            <span class="keywordflow">for</span> i <span class="keywordflow">in</span> word2_indexes:</div>
<div class="line"><span class="lineno">  266</span>                word_vectors[i] += neu1e * word_locks[i]</div>
<div class="line"><span class="lineno">  267</span> </div>
<div class="line"><span class="lineno">  268</span>    <span class="keywordflow">return</span> len(word_vocabs)</div>
<div class="line"><span class="lineno">  269</span> </div>
<div class="line"><span class="lineno">  270</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a586c18966facf96e1dcb04b463eaf93d" name="a586c18966facf96e1dcb04b463eaf93d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a586c18966facf96e1dcb04b463eaf93d">&#9670;&#160;</a></span>train_document_dm_concat()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.doc2vec.train_document_dm_concat </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doc_words</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doctag_indexes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>work</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>neu1</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_doctags</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_words</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_hidden</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_vectors</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>word_locks</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doctag_vectors</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>doctag_locks</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update distributed memory model ("PV-DM") by training on a single document, using a
concatenation of the context window word vectors (rather than a sum or average).

Called internally from `Doc2Vec.train()` and `Doc2Vec.infer_vector()`.

The document is provided as `doc_words`, a list of word tokens which are looked up
in the model's vocab dictionary, and `doctag_indexes`, which provide indexes
into the doctag_vectors array.

Any of `learn_doctags', `learn_words`, and `learn_hidden` may be set False to
prevent learning-updates to those respective model weights, as if using the
(partially-)frozen model to infer other compatible vectors.

This is the non-optimized, Python version. If you have a C compiler, gensim
will use the optimized version from doc2vec_inner instead.</pre> <div class="fragment"><div class="line"><span class="lineno">  273</span>                             doctag_vectors=<span class="keywordtype">None</span>, doctag_locks=<span class="keywordtype">None</span>):</div>
<div class="line"><span class="lineno">  274</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  275</span><span class="stringliteral">    Update distributed memory model (&quot;PV-DM&quot;) by training on a single document, using a</span></div>
<div class="line"><span class="lineno">  276</span><span class="stringliteral">    concatenation of the context window word vectors (rather than a sum or average).</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">    Called internally from `Doc2Vec.train()` and `Doc2Vec.infer_vector()`.</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">    The document is provided as `doc_words`, a list of word tokens which are looked up</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">    in the model&#39;s vocab dictionary, and `doctag_indexes`, which provide indexes</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral">    into the doctag_vectors array.</span></div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">    Any of `learn_doctags&#39;, `learn_words`, and `learn_hidden` may be set False to</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">    prevent learning-updates to those respective model weights, as if using the</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral">    (partially-)frozen model to infer other compatible vectors.</span></div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">    This is the non-optimized, Python version. If you have a C compiler, gensim</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">    will use the optimized version from doc2vec_inner instead.</span></div>
<div class="line"><span class="lineno">  290</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  291</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  292</span>    <span class="keywordflow">if</span> word_vectors <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  293</span>        word_vectors = model.wv.syn0</div>
<div class="line"><span class="lineno">  294</span>    <span class="keywordflow">if</span> word_locks <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  295</span>        word_locks = model.syn0_lockf</div>
<div class="line"><span class="lineno">  296</span>    <span class="keywordflow">if</span> doctag_vectors <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  297</span>        doctag_vectors = model.docvecs.doctag_syn0</div>
<div class="line"><span class="lineno">  298</span>    <span class="keywordflow">if</span> doctag_locks <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  299</span>        doctag_locks = model.docvecs.doctag_syn0_lockf</div>
<div class="line"><span class="lineno">  300</span> </div>
<div class="line"><span class="lineno">  301</span>    word_vocabs = [model.wv.vocab[w] <span class="keywordflow">for</span> w <span class="keywordflow">in</span> doc_words <span class="keywordflow">if</span> w <span class="keywordflow">in</span> model.wv.vocab</div>
<div class="line"><span class="lineno">  302</span>                   <span class="keywordflow">and</span> model.wv.vocab[w].sample_int &gt; model.random.rand() * 2**32]</div>
<div class="line"><span class="lineno">  303</span>    doctag_len = len(doctag_indexes)</div>
<div class="line"><span class="lineno">  304</span>    <span class="keywordflow">if</span> doctag_len != model.dm_tag_count:</div>
<div class="line"><span class="lineno">  305</span>        <span class="keywordflow">return</span> 0  <span class="comment"># skip doc without expected number of doctag(s) (TODO: warn/pad?)</span></div>
<div class="line"><span class="lineno">  306</span> </div>
<div class="line"><span class="lineno">  307</span>    null_word = model.wv.vocab[<span class="stringliteral">&#39;\0&#39;</span>]</div>
<div class="line"><span class="lineno">  308</span>    pre_pad_count = model.window</div>
<div class="line"><span class="lineno">  309</span>    post_pad_count = model.window</div>
<div class="line"><span class="lineno">  310</span>    padded_document_indexes = (</div>
<div class="line"><span class="lineno">  311</span>        (pre_pad_count * [null_word.index])  <span class="comment"># pre-padding</span></div>
<div class="line"><span class="lineno">  312</span>        + [word.index <span class="keywordflow">for</span> word <span class="keywordflow">in</span> word_vocabs <span class="keywordflow">if</span> word <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>]  <span class="comment"># elide out-of-Vocabulary words</span></div>
<div class="line"><span class="lineno">  313</span>        + (post_pad_count * [null_word.index])  <span class="comment"># post-padding</span></div>
<div class="line"><span class="lineno">  314</span>    )</div>
<div class="line"><span class="lineno">  315</span> </div>
<div class="line"><span class="lineno">  316</span>    <span class="keywordflow">for</span> pos <span class="keywordflow">in</span> range(pre_pad_count, len(padded_document_indexes) - post_pad_count):</div>
<div class="line"><span class="lineno">  317</span>        word_context_indexes = (</div>
<div class="line"><span class="lineno">  318</span>            padded_document_indexes[(pos - pre_pad_count): pos]  <span class="comment"># preceding words</span></div>
<div class="line"><span class="lineno">  319</span>            + padded_document_indexes[(pos + 1):(pos + 1 + post_pad_count)]  <span class="comment"># following words</span></div>
<div class="line"><span class="lineno">  320</span>        )</div>
<div class="line"><span class="lineno">  321</span>        predict_word = model.wv.vocab[model.wv.index2word[padded_document_indexes[pos]]]</div>
<div class="line"><span class="lineno">  322</span>        <span class="comment"># numpy advanced-indexing copies; concatenate, flatten to 1d</span></div>
<div class="line"><span class="lineno">  323</span>        l1 = concatenate((doctag_vectors[doctag_indexes], word_vectors[word_context_indexes])).ravel()</div>
<div class="line"><span class="lineno">  324</span>        neu1e = train_cbow_pair(model, predict_word, <span class="keywordtype">None</span>, l1, alpha,</div>
<div class="line"><span class="lineno">  325</span>                                learn_hidden=learn_hidden, learn_vectors=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  326</span> </div>
<div class="line"><span class="lineno">  327</span>        <span class="comment"># filter by locks and shape for addition to source vectors</span></div>
<div class="line"><span class="lineno">  328</span>        e_locks = concatenate((doctag_locks[doctag_indexes], word_locks[word_context_indexes]))</div>
<div class="line"><span class="lineno">  329</span>        neu1e_r = (neu1e.reshape(-1, model.vector_size)</div>
<div class="line"><span class="lineno">  330</span>                   * np_repeat(e_locks, model.vector_size).reshape(-1, model.vector_size))</div>
<div class="line"><span class="lineno">  331</span> </div>
<div class="line"><span class="lineno">  332</span>        <span class="keywordflow">if</span> learn_doctags:</div>
<div class="line"><span class="lineno">  333</span>            np_add.at(doctag_vectors, doctag_indexes, neu1e_r[:doctag_len])</div>
<div class="line"><span class="lineno">  334</span>        <span class="keywordflow">if</span> learn_words:</div>
<div class="line"><span class="lineno">  335</span>            np_add.at(word_vectors, word_context_indexes, neu1e_r[doctag_len:])</div>
<div class="line"><span class="lineno">  336</span> </div>
<div class="line"><span class="lineno">  337</span>    <span class="keywordflow">return</span> len(padded_document_indexes) - pre_pad_count - post_pad_count</div>
<div class="line"><span class="lineno">  338</span> </div>
<div class="line"><span class="lineno">  339</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="aae993b667e4db8f1d233b77111faa3db" name="aae993b667e4db8f1d233b77111faa3db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae993b667e4db8f1d233b77111faa3db">&#9670;&#160;</a></span>logger</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">gensim.models.deprecated.doc2vec.logger = logging.getLogger(__name__)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
